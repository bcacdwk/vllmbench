
========== M=16 ==========
Time: 2026-01-25 18:45:58
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4
Params: prompt_len=16, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4 --dataset-name random --input-len 16 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 17 --max-num-batched-tokens 17 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Llama3.2-1B-FP8_M16.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 18:46:02 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 18:46:02 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=297856) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=297856) 
(EngineCore_DP0 pid=297856) 
(EngineCore_DP0 pid=297856) ================================================================
(EngineCore_DP0 pid=297856) Internal Triton PTX codegen error
(EngineCore_DP0 pid=297856) `ptxas` stderr:
(EngineCore_DP0 pid=297856) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=297856) 
(EngineCore_DP0 pid=297856) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpohcg6u17.ptx -o /tmp/tmpohcg6u17.ptx.o
(EngineCore_DP0 pid=297856) 
(EngineCore_DP0 pid=297856) 
(EngineCore_DP0 pid=297856) //
(EngineCore_DP0 pid=297856) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=297856) //
(EngineCore_DP0 pid=297856) 
(EngineCore_DP0 pid=297856) .version 8.7
(EngineCore_DP0 pid=297856) .target sm_121a
(EngineCore_DP0 pid=297856) .address_size 64
(EngineCore_DP0 pid=297856) 
(EngineCore_DP0 pid=297856) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=297856) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=297856)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=297856) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=297856) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=297856) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=297856) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=297856) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=297856) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=297856) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=297856) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=297856) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=297856) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=297856) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=297856) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=297856) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=297856) )
(EngineCore_DP0 pid=297856) .reqntid 512
(EngineCore_DP0 pid=297856) {
(EngineCore_DP0 pid=297856) 	.reg .pred 	%p<20>;
(EngineCore_DP0 pid=297856) 	.reg .b16 	%rs<37>;
(EngineCore_DP0 pid=297856) 	.reg .b32 	%r<112>;
(EngineCore_DP0 pid=297856) 	.reg .b64 	%rd<13>;
(EngineCore_DP0 pid=297856) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=297856) $L__func_begin0:
(EngineCore_DP0 pid=297856) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=297856) 
(EngineCore_DP0 pid=297856) // %bb.0:
(EngineCore_DP0 pid=297856) 	ld.param.b32 	%r22, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=297856) 	ld.param.b32 	%r21, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=297856) 	ld.param.b32 	%r20, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=297856) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=297856) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=297856) $L__tmp0:
(EngineCore_DP0 pid=297856) 	.loc	1 177 24                        // quant_slide_tuned_Llama3.2-1B.py:177:24
(EngineCore_DP0 pid=297856) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=297856) 	ld.param.b32 	%r24, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=297856) 	.loc	1 182 26                        // quant_slide_tuned_Llama3.2-1B.py:182:26
(EngineCore_DP0 pid=297856) 	mul.lo.s32 	%r25, %r24, %r1;
(EngineCore_DP0 pid=297856) 	.loc	1 182 20                        // quant_slide_tuned_Llama3.2-1B.py:182:20
(EngineCore_DP0 pid=297856) 	mad.wide.s32 	%rd1, %r25, 2, %rd4;
(EngineCore_DP0 pid=297856) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=297856) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=297856) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=297856) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=297856) 	setp.lt.s32 	%p1, %r21, 1;
(EngineCore_DP0 pid=297856) 	mov.b32 	%r109, 0f2B8CBCCC;
(EngineCore_DP0 pid=297856) 	setp.eq.b32 	%p19, %r2, 0;
(EngineCore_DP0 pid=297856) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=297856) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=297856) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=297856) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=297856) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=297856) 	shr.u32 	%r34, %r2, 3;
(EngineCore_DP0 pid=297856) 	and.b32 	%r35, %r34, 60;
(EngineCore_DP0 pid=297856) 	mov.b32 	%r36, global_smem;
(EngineCore_DP0 pid=297856) 	add.s32 	%r46, %r36, %r35;
(EngineCore_DP0 pid=297856) 	shl.b32 	%r37, %r2, 2;
(EngineCore_DP0 pid=297856) 	add.s32 	%r49, %r36, %r37;
(EngineCore_DP0 pid=297856) 	mov.b32 	%r42, 0;
(EngineCore_DP0 pid=297856) 	mov.b32 	%r107, 0f00000000;
(EngineCore_DP0 pid=297856) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=297856) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=297856) 	mov.b32 	%r108, %r42;
(EngineCore_DP0 pid=297856) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=297856) 	.loc	1 189 22                        // quant_slide_tuned_Llama3.2-1B.py:189:22
(EngineCore_DP0 pid=297856) 	add.s32 	%r52, %r4, %r108;
(EngineCore_DP0 pid=297856) 	setp.lt.s32 	%p2, %r52, %r20;
(EngineCore_DP0 pid=297856) 	.loc	1 190 29                        // quant_slide_tuned_Llama3.2-1B.py:190:29
(EngineCore_DP0 pid=297856) 	mad.wide.s32 	%rd6, %r52, 2, %rd1;
(EngineCore_DP0 pid=297856) 	.loc	1 190 21                        // quant_slide_tuned_Llama3.2-1B.py:190:21
(EngineCore_DP0 pid=297856) 	// begin inline asm
(EngineCore_DP0 pid=297856) 	mov.u32 %r38, %r42;
(EngineCore_DP0 pid=297856) 	mov.u32 %r39, %r42;
(EngineCore_DP0 pid=297856) 	mov.u32 %r40, %r42;
(EngineCore_DP0 pid=297856) 	mov.u32 %r41, %r42;
(EngineCore_DP0 pid=297856) 	@%p2 ld.global.v4.b32 { %r38, %r39, %r40, %r41 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=297856) 	// end inline asm
(EngineCore_DP0 pid=297856) 	mov.b32 	{%rs1, %rs2}, %r38;
(EngineCore_DP0 pid=297856) 	mov.b32 	{%rs3, %rs4}, %r39;
(EngineCore_DP0 pid=297856) 	mov.b32 	{%rs5, %rs6}, %r40;
(EngineCore_DP0 pid=297856) 	mov.b32 	{%rs7, %rs8}, %r41;
(EngineCore_DP0 pid=297856) 	.loc	1 191 50                        // quant_slide_tuned_Llama3.2-1B.py:191:50
(EngineCore_DP0 pid=297856) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=297856) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=297856) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=297856) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=297856) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=297856) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=297856) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=297856) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=297856) $L__tmp1:
(EngineCore_DP0 pid=297856) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=297856) 	bar.sync 	0;
(EngineCore_DP0 pid=297856) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=297856) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=297856) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=297856) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=297856) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=297856) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=297856) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=297856) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=297856) 	cvt.f32.bf16 	%r53, %rs23;
(EngineCore_DP0 pid=297856) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=297856) 	shfl.sync.bfly.b32 	%r54, %r53, 16, 31, -1;
(EngineCore_DP0 pid=297856) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=297856) 	max.f32 	%r55, %r53, %r54;
(EngineCore_DP0 pid=297856) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=297856) 	shfl.sync.bfly.b32 	%r56, %r55, 8, 31, -1;
(EngineCore_DP0 pid=297856) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=297856) 	max.f32 	%r57, %r55, %r56;
(EngineCore_DP0 pid=297856) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=297856) 	shfl.sync.bfly.b32 	%r58, %r57, 4, 31, -1;
(EngineCore_DP0 pid=297856) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=297856) 	max.f32 	%r59, %r57, %r58;
(EngineCore_DP0 pid=297856) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=297856) 	shfl.sync.bfly.b32 	%r60, %r59, 2, 31, -1;
(EngineCore_DP0 pid=297856) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=297856) 	max.f32 	%r61, %r59, %r60;
(EngineCore_DP0 pid=297856) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=297856) 	shfl.sync.bfly.b32 	%r62, %r61, 1, 31, -1;
(EngineCore_DP0 pid=297856) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=297856) 	max.f32 	%r47, %r61, %r62;
(EngineCore_DP0 pid=297856) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=297856) 	// begin inline asm
(EngineCore_DP0 pid=297856) 	@%p3 st.shared.b32 [ %r46 + 0 ], %r47;
(EngineCore_DP0 pid=297856) 	// end inline asm
(EngineCore_DP0 pid=297856) 	bar.sync 	0;
(EngineCore_DP0 pid=297856) 	// begin inline asm
(EngineCore_DP0 pid=297856) 	@%p4 ld.shared.b32 %r48, [ %r49 + 0 ];
(EngineCore_DP0 pid=297856) 	// end inline asm
(EngineCore_DP0 pid=297856) 	shfl.sync.bfly.b32 	%r63, %r48, 8, 31, -1;
(EngineCore_DP0 pid=297856) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=297856) 	max.f32 	%r64, %r48, %r63;
(EngineCore_DP0 pid=297856) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=297856) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=297856) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=297856) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=297856) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=297856) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=297856) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=297856) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=297856) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=297856) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=297856) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=297856) 	max.f32 	%r51, %r68, %r69;
(EngineCore_DP0 pid=297856) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=297856) 	// begin inline asm
(EngineCore_DP0 pid=297856) 	@%p19 st.shared.b32 [ %r49 + 0 ], %r51;
(EngineCore_DP0 pid=297856) 	// end inline asm
(EngineCore_DP0 pid=297856) 	bar.sync 	0;
(EngineCore_DP0 pid=297856) 	ld.shared.b32 	%r70, [global_smem];
(EngineCore_DP0 pid=297856) $L__tmp2:
(EngineCore_DP0 pid=297856) 	.loc	1 191 36                        // quant_slide_tuned_Llama3.2-1B.py:191:36
(EngineCore_DP0 pid=297856) 	max.f32 	%r107, %r107, %r70;
(EngineCore_DP0 pid=297856) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=297856) 	add.s32 	%r108, %r108, 4096;
(EngineCore_DP0 pid=297856) 	setp.lt.s32 	%p6, %r108, %r21;
(EngineCore_DP0 pid=297856) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=297856) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=297856) 	.loc	1 193 32                        // quant_slide_tuned_Llama3.2-1B.py:193:32
(EngineCore_DP0 pid=297856) 	max.f32 	%r109, %r107, 0f2B8CBCCC;
(EngineCore_DP0 pid=297856) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=297856) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=297856) 	mov.b32 	%r72, 0f43E00000;
(EngineCore_DP0 pid=297856) 	.loc	1 194 32                        // quant_slide_tuned_Llama3.2-1B.py:194:32
(EngineCore_DP0 pid=297856) 	div.full.f32 	%r73, %r109, %r72;
(EngineCore_DP0 pid=297856) 	.loc	1 194 41                        // quant_slide_tuned_Llama3.2-1B.py:194:41
(EngineCore_DP0 pid=297856) 	max.f32 	%r71, %r73, 0f36924925;
(EngineCore_DP0 pid=297856) 	.loc	1 196 25                        // quant_slide_tuned_Llama3.2-1B.py:196:25
(EngineCore_DP0 pid=297856) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=297856) 	.loc	1 196 30                        // quant_slide_tuned_Llama3.2-1B.py:196:30
(EngineCore_DP0 pid=297856) 	// begin inline asm
(EngineCore_DP0 pid=297856) 	@%p19 st.global.b32 [ %rd7 + 0 ], { %r71 };
(EngineCore_DP0 pid=297856) 	// end inline asm
(EngineCore_DP0 pid=297856) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=297856) 	setp.lt.s32 	%p8, %r22, 1;
(EngineCore_DP0 pid=297856) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=297856) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=297856) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=297856) 	ld.param.b32 	%r26, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=297856) 	shr.s32 	%r27, %r26, 31;
(EngineCore_DP0 pid=297856) 	shr.u32 	%r28, %r27, 30;
(EngineCore_DP0 pid=297856) 	add.s32 	%r29, %r26, %r28;
(EngineCore_DP0 pid=297856) 	shr.s32 	%r30, %r29, 2;
(EngineCore_DP0 pid=297856) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=297856) 	mul.lo.s32 	%r31, %r30, %r1;
(EngineCore_DP0 pid=297856) 	mad.wide.s32 	%rd2, %r31, 4, %rd5;
(EngineCore_DP0 pid=297856) 	div.full.f32 	%r14, %r72, %r109;
(EngineCore_DP0 pid=297856) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=297856) 	shl.b32 	%r110, %r3, 2;
(EngineCore_DP0 pid=297856) 	mov.b32 	%r111, 0;
(EngineCore_DP0 pid=297856) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=297856)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=297856) 	.loc	1 203 30                        // quant_slide_tuned_Llama3.2-1B.py:203:30
(EngineCore_DP0 pid=297856) 	add.s32 	%r84, %r3, %r111;
(EngineCore_DP0 pid=297856) 	setp.lt.s32 	%p13, %r84, %r22;
(EngineCore_DP0 pid=297856) 	.loc	1 211 53                        // quant_slide_tuned_Llama3.2-1B.py:211:53
(EngineCore_DP0 pid=297856) 	setp.lt.s32 	%p14, %r110, %r20;
(EngineCore_DP0 pid=297856) 	.loc	1 211 37                        // quant_slide_tuned_Llama3.2-1B.py:211:37
(EngineCore_DP0 pid=297856) 	and.pred 	%p9, %p13, %p14;
(EngineCore_DP0 pid=297856) 	.loc	1 210 29                        // quant_slide_tuned_Llama3.2-1B.py:210:29
(EngineCore_DP0 pid=297856) 	mad.wide.s32 	%rd8, %r110, 2, %rd1;
(EngineCore_DP0 pid=297856) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=297856) 	.loc	1 210 21                        // quant_slide_tuned_Llama3.2-1B.py:210:21
(EngineCore_DP0 pid=297856) 	// begin inline asm
(EngineCore_DP0 pid=297856) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=297856) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=297856) 	// end inline asm
(EngineCore_DP0 pid=297856) 	.loc	1 211 79                        // quant_slide_tuned_Llama3.2-1B.py:211:79
(EngineCore_DP0 pid=297856) 	cvt.f32.bf16 	%r85, %rs24;
(EngineCore_DP0 pid=297856) 	.loc	1 213 53                        // quant_slide_tuned_Llama3.2-1B.py:213:53
(EngineCore_DP0 pid=297856) 	add.s32 	%r86, %r110, 1;
(EngineCore_DP0 pid=297856) 	setp.lt.s32 	%p15, %r86, %r20;
(EngineCore_DP0 pid=297856) 	.loc	1 213 37                        // quant_slide_tuned_Llama3.2-1B.py:213:37
(EngineCore_DP0 pid=297856) 	and.pred 	%p10, %p13, %p15;
(EngineCore_DP0 pid=297856) 	.loc	1 212 39                        // quant_slide_tuned_Llama3.2-1B.py:212:39
(EngineCore_DP0 pid=297856) 	add.s64 	%rd9, %rd8, 2;
(EngineCore_DP0 pid=297856) 	.loc	1 212 21                        // quant_slide_tuned_Llama3.2-1B.py:212:21
(EngineCore_DP0 pid=297856) 	// begin inline asm
(EngineCore_DP0 pid=297856) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=297856) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=297856) 	// end inline asm
(EngineCore_DP0 pid=297856) 	.loc	1 213 79                        // quant_slide_tuned_Llama3.2-1B.py:213:79
(EngineCore_DP0 pid=297856) 	cvt.f32.bf16 	%r87, %rs26;
(EngineCore_DP0 pid=297856) 	.loc	1 215 53                        // quant_slide_tuned_Llama3.2-1B.py:215:53
(EngineCore_DP0 pid=297856) 	add.s32 	%r88, %r110, 2;
(EngineCore_DP0 pid=297856) 	setp.lt.s32 	%p16, %r88, %r20;
(EngineCore_DP0 pid=297856) 	.loc	1 215 37                        // quant_slide_tuned_Llama3.2-1B.py:215:37
(EngineCore_DP0 pid=297856) 	and.pred 	%p11, %p13, %p16;
(EngineCore_DP0 pid=297856) 	.loc	1 214 39                        // quant_slide_tuned_Llama3.2-1B.py:214:39
(EngineCore_DP0 pid=297856) 	add.s64 	%rd10, %rd8, 4;
(EngineCore_DP0 pid=297856) 	.loc	1 214 21                        // quant_slide_tuned_Llama3.2-1B.py:214:21
(EngineCore_DP0 pid=297856) 	// begin inline asm
(EngineCore_DP0 pid=297856) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=297856) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=297856) 	// end inline asm
(EngineCore_DP0 pid=297856) 	.loc	1 215 79                        // quant_slide_tuned_Llama3.2-1B.py:215:79
(EngineCore_DP0 pid=297856) 	cvt.f32.bf16 	%r89, %rs28;
(EngineCore_DP0 pid=297856) 	.loc	1 217 53                        // quant_slide_tuned_Llama3.2-1B.py:217:53
(EngineCore_DP0 pid=297856) 	add.s32 	%r90, %r110, 3;
(EngineCore_DP0 pid=297856) 	setp.lt.s32 	%p17, %r90, %r20;
(EngineCore_DP0 pid=297856) 	.loc	1 217 37                        // quant_slide_tuned_Llama3.2-1B.py:217:37
(EngineCore_DP0 pid=297856) 	and.pred 	%p12, %p13, %p17;
(EngineCore_DP0 pid=297856) 	.loc	1 216 39                        // quant_slide_tuned_Llama3.2-1B.py:216:39
(EngineCore_DP0 pid=297856) 	add.s64 	%rd11, %rd8, 6;
(EngineCore_DP0 pid=297856) 	.loc	1 216 21                        // quant_slide_tuned_Llama3.2-1B.py:216:21
(EngineCore_DP0 pid=297856) 	// begin inline asm
(EngineCore_DP0 pid=297856) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=297856) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=297856) 	// end inline asm
(EngineCore_DP0 pid=297856) 	.loc	1 217 79                        // quant_slide_tuned_Llama3.2-1B.py:217:79
(EngineCore_DP0 pid=297856) 	cvt.f32.bf16 	%r91, %rs30;
(EngineCore_DP0 pid=297856) 	.loc	1 219 27                        // quant_slide_tuned_Llama3.2-1B.py:219:27
(EngineCore_DP0 pid=297856) 	mul.f32 	%r92, %r14, %r85;
(EngineCore_DP0 pid=297856) 	mov.b32 	%r93, 0f43E00000;
(EngineCore_DP0 pid=297856) 	.loc	1 219 48                        // quant_slide_tuned_Llama3.2-1B.py:219:48
(EngineCore_DP0 pid=297856) 	min.xorsign.abs.f32 	%r75, %r92, %r93;
(EngineCore_DP0 pid=297856) 	.loc	1 219 60                        // quant_slide_tuned_Llama3.2-1B.py:219:60
(EngineCore_DP0 pid=297856) 	// begin inline asm
(EngineCore_DP0 pid=297856) 	cvt.rn.satfinite.e4m3x2.f32  %rs32, %r76, %r75; 
(EngineCore_DP0 pid=297856) 
(EngineCore_DP0 pid=297856) 	// end inline asm
(EngineCore_DP0 pid=297856) 	.loc	1 220 27                        // quant_slide_tuned_Llama3.2-1B.py:220:27
(EngineCore_DP0 pid=297856) 	mul.f32 	%r94, %r14, %r87;
(EngineCore_DP0 pid=297856) 	.loc	1 220 48                        // quant_slide_tuned_Llama3.2-1B.py:220:48
(EngineCore_DP0 pid=297856) 	min.xorsign.abs.f32 	%r77, %r94, %r93;
(EngineCore_DP0 pid=297856) 	.loc	1 220 60                        // quant_slide_tuned_Llama3.2-1B.py:220:60
(EngineCore_DP0 pid=297856) 	// begin inline asm
(EngineCore_DP0 pid=297856) 	cvt.rn.satfinite.e4m3x2.f32  %rs33, %r78, %r77; 
(EngineCore_DP0 pid=297856) 
(EngineCore_DP0 pid=297856) 	// end inline asm
(EngineCore_DP0 pid=297856) 	.loc	1 221 27                        // quant_slide_tuned_Llama3.2-1B.py:221:27
(EngineCore_DP0 pid=297856) 	mul.f32 	%r95, %r14, %r89;
(EngineCore_DP0 pid=297856) 	.loc	1 221 48                        // quant_slide_tuned_Llama3.2-1B.py:221:48
(EngineCore_DP0 pid=297856) 	min.xorsign.abs.f32 	%r79, %r95, %r93;
(EngineCore_DP0 pid=297856) 	.loc	1 221 60                        // quant_slide_tuned_Llama3.2-1B.py:221:60
(EngineCore_DP0 pid=297856) 	// begin inline asm
(EngineCore_DP0 pid=297856) 	cvt.rn.satfinite.e4m3x2.f32  %rs34, %r80, %r79; 
(EngineCore_DP0 pid=297856) 
(EngineCore_DP0 pid=297856) 	// end inline asm
(EngineCore_DP0 pid=297856) 	.loc	1 222 27                        // quant_slide_tuned_Llama3.2-1B.py:222:27
(EngineCore_DP0 pid=297856) 	mul.f32 	%r96, %r14, %r91;
(EngineCore_DP0 pid=297856) 	.loc	1 222 48                        // quant_slide_tuned_Llama3.2-1B.py:222:48
(EngineCore_DP0 pid=297856) 	min.xorsign.abs.f32 	%r81, %r96, %r93;
(EngineCore_DP0 pid=297856) 	.loc	1 222 60                        // quant_slide_tuned_Llama3.2-1B.py:222:60
(EngineCore_DP0 pid=297856) 	// begin inline asm
(EngineCore_DP0 pid=297856) 	cvt.rn.satfinite.e4m3x2.f32  %rs35, %r82, %r81; 
(EngineCore_DP0 pid=297856) 
(EngineCore_DP0 pid=297856) 	// end inline asm
(EngineCore_DP0 pid=297856) 	.loc	1 224 45                        // quant_slide_tuned_Llama3.2-1B.py:224:45
(EngineCore_DP0 pid=297856) 	cvt.u32.u16 	%r97, %rs32;
(EngineCore_DP0 pid=297856) 	and.b32 	%r98, %r97, 255;
(EngineCore_DP0 pid=297856) 	.loc	1 226 45                        // quant_slide_tuned_Llama3.2-1B.py:226:45
(EngineCore_DP0 pid=297856) 	cvt.u32.u16 	%r99, %rs34;
(EngineCore_DP0 pid=297856) 	and.b32 	%r100, %r99, 255;
(EngineCore_DP0 pid=297856) 	.loc	1 227 45                        // quant_slide_tuned_Llama3.2-1B.py:227:45
(EngineCore_DP0 pid=297856) 	cvt.u32.u16 	%r101, %rs35;
(EngineCore_DP0 pid=297856) 	.loc	1 229 30                        // quant_slide_tuned_Llama3.2-1B.py:229:30
(EngineCore_DP0 pid=297856) 	and.b16 	%rs36, %rs33, 255;
(EngineCore_DP0 pid=297856) 	mul.wide.u16 	%r102, %rs36, 256;
(EngineCore_DP0 pid=297856) 	.loc	1 229 24                        // quant_slide_tuned_Llama3.2-1B.py:229:24
(EngineCore_DP0 pid=297856) 	or.b32 	%r103, %r102, %r98;
(EngineCore_DP0 pid=297856) 	.loc	1 229 42                        // quant_slide_tuned_Llama3.2-1B.py:229:42
(EngineCore_DP0 pid=297856) 	shl.b32 	%r104, %r100, 16;
(EngineCore_DP0 pid=297856) 	.loc	1 229 36                        // quant_slide_tuned_Llama3.2-1B.py:229:36
(EngineCore_DP0 pid=297856) 	or.b32 	%r105, %r103, %r104;
(EngineCore_DP0 pid=297856) 	.loc	1 229 55                        // quant_slide_tuned_Llama3.2-1B.py:229:55
(EngineCore_DP0 pid=297856) 	shl.b32 	%r106, %r101, 24;
(EngineCore_DP0 pid=297856) 	.loc	1 229 49                        // quant_slide_tuned_Llama3.2-1B.py:229:49
(EngineCore_DP0 pid=297856) 	or.b32 	%r83, %r105, %r106;
(EngineCore_DP0 pid=297856) 	.loc	1 230 29                        // quant_slide_tuned_Llama3.2-1B.py:230:29
(EngineCore_DP0 pid=297856) 	mad.wide.s32 	%rd12, %r84, 4, %rd2;
(EngineCore_DP0 pid=297856) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-1B.py:230:39
(EngineCore_DP0 pid=297856) 	// begin inline asm
(EngineCore_DP0 pid=297856) 	@%p13 st.global.b32 [ %rd12 + 0 ], { %r83 };
(EngineCore_DP0 pid=297856) 	// end inline asm
(EngineCore_DP0 pid=297856) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=297856) 	add.s32 	%r111, %r111, 512;
(EngineCore_DP0 pid=297856) 	add.s32 	%r110, %r110, 2048;
(EngineCore_DP0 pid=297856) 	setp.lt.s32 	%p18, %r111, %r22;
(EngineCore_DP0 pid=297856) 	@%p18 bra 	$L__BB0_6;
(EngineCore_DP0 pid=297856) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=297856) 	.loc	1 201 4                         // quant_slide_tuned_Llama3.2-1B.py:201:4
(EngineCore_DP0 pid=297856) 	ret;
(EngineCore_DP0 pid=297856) $L__tmp3:
(EngineCore_DP0 pid=297856) $L__func_end0:
(EngineCore_DP0 pid=297856)                                         // -- End function
(EngineCore_DP0 pid=297856) }
(EngineCore_DP0 pid=297856) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=297856) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=297856) 	.section	.debug_abbrev
(EngineCore_DP0 pid=297856) 	{
(EngineCore_DP0 pid=297856) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=297856) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=297856) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=297856) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=297856) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=297856) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=297856) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=297856) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=297856) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=297856) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=297856) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=297856) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=297856) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=297856) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=297856) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=297856) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=297856) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=297856) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=297856) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=297856) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=297856) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=297856) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=297856) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=297856) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=297856) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=297856) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=297856) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=297856) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=297856) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=297856) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=297856) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=297856) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=297856) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=297856) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=297856) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=297856) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=297856) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=297856) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=297856) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=297856) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=297856) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=297856) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=297856) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=297856) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=297856) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=297856) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=297856) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=297856) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=297856) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=297856) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=297856) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=297856) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=297856) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=297856) 	}
(EngineCore_DP0 pid=297856) 	.section	.debug_info
(EngineCore_DP0 pid=297856) 	{
(EngineCore_DP0 pid=297856) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=297856) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=297856) .b8 0
(EngineCore_DP0 pid=297856) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=297856) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=297856) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=297856) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=297856) .b8 114
(EngineCore_DP0 pid=297856) .b8 105
(EngineCore_DP0 pid=297856) .b8 116
(EngineCore_DP0 pid=297856) .b8 111
(EngineCore_DP0 pid=297856) .b8 110
(EngineCore_DP0 pid=297856) .b8 0
(EngineCore_DP0 pid=297856) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=297856) .b8 0
(EngineCore_DP0 pid=297856) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=297856) .b8 117
(EngineCore_DP0 pid=297856) .b8 97
(EngineCore_DP0 pid=297856) .b8 110
(EngineCore_DP0 pid=297856) .b8 116
(EngineCore_DP0 pid=297856) .b8 95
(EngineCore_DP0 pid=297856) .b8 115
(EngineCore_DP0 pid=297856) .b8 108
(EngineCore_DP0 pid=297856) .b8 105
(EngineCore_DP0 pid=297856) .b8 100
(EngineCore_DP0 pid=297856) .b8 101
(EngineCore_DP0 pid=297856) .b8 95
(EngineCore_DP0 pid=297856) .b8 116
(EngineCore_DP0 pid=297856) .b8 117
(EngineCore_DP0 pid=297856) .b8 110
(EngineCore_DP0 pid=297856) .b8 101
(EngineCore_DP0 pid=297856) .b8 100
(EngineCore_DP0 pid=297856) .b8 95
(EngineCore_DP0 pid=297856) .b8 76
(EngineCore_DP0 pid=297856) .b8 108
(EngineCore_DP0 pid=297856) .b8 97
(EngineCore_DP0 pid=297856) .b8 109
(EngineCore_DP0 pid=297856) .b8 97
(EngineCore_DP0 pid=297856) .b8 51
(EngineCore_DP0 pid=297856) .b8 46
(EngineCore_DP0 pid=297856) .b8 50
(EngineCore_DP0 pid=297856) .b8 45
(EngineCore_DP0 pid=297856) .b8 49
(EngineCore_DP0 pid=297856) .b8 66
(EngineCore_DP0 pid=297856) .b8 46
(EngineCore_DP0 pid=297856) .b8 112
(EngineCore_DP0 pid=297856) .b8 121
(EngineCore_DP0 pid=297856) .b8 0
(EngineCore_DP0 pid=297856) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=297856) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=297856) .b8 114
(EngineCore_DP0 pid=297856) .b8 111
(EngineCore_DP0 pid=297856) .b8 111
(EngineCore_DP0 pid=297856) .b8 116
(EngineCore_DP0 pid=297856) .b8 47
(EngineCore_DP0 pid=297856) .b8 118
(EngineCore_DP0 pid=297856) .b8 108
(EngineCore_DP0 pid=297856) .b8 108
(EngineCore_DP0 pid=297856) .b8 109
(EngineCore_DP0 pid=297856) .b8 98
(EngineCore_DP0 pid=297856) .b8 101
(EngineCore_DP0 pid=297856) .b8 110
(EngineCore_DP0 pid=297856) .b8 99
(EngineCore_DP0 pid=297856) .b8 104
(EngineCore_DP0 pid=297856) .b8 47
(EngineCore_DP0 pid=297856) .b8 115
(EngineCore_DP0 pid=297856) .b8 108
(EngineCore_DP0 pid=297856) .b8 105
(EngineCore_DP0 pid=297856) .b8 100
(EngineCore_DP0 pid=297856) .b8 101
(EngineCore_DP0 pid=297856) .b8 115
(EngineCore_DP0 pid=297856) .b8 112
(EngineCore_DP0 pid=297856) .b8 97
(EngineCore_DP0 pid=297856) .b8 114
(EngineCore_DP0 pid=297856) .b8 115
(EngineCore_DP0 pid=297856) .b8 101
(EngineCore_DP0 pid=297856) .b8 47
(EngineCore_DP0 pid=297856) .b8 99
(EngineCore_DP0 pid=297856) .b8 115
(EngineCore_DP0 pid=297856) .b8 114
(EngineCore_DP0 pid=297856) .b8 99
(EngineCore_DP0 pid=297856) .b8 47
(EngineCore_DP0 pid=297856) .b8 102
(EngineCore_DP0 pid=297856) .b8 117
(EngineCore_DP0 pid=297856) .b8 115
(EngineCore_DP0 pid=297856) .b8 101
(EngineCore_DP0 pid=297856) .b8 100
(EngineCore_DP0 pid=297856) .b8 95
(EngineCore_DP0 pid=297856) .b8 113
(EngineCore_DP0 pid=297856) .b8 117
(EngineCore_DP0 pid=297856) .b8 97
(EngineCore_DP0 pid=297856) .b8 110
(EngineCore_DP0 pid=297856) .b8 116
(EngineCore_DP0 pid=297856) .b8 95
(EngineCore_DP0 pid=297856) .b8 115
(EngineCore_DP0 pid=297856) .b8 108
(EngineCore_DP0 pid=297856) .b8 105
(EngineCore_DP0 pid=297856) .b8 100
(EngineCore_DP0 pid=297856) .b8 101
(EngineCore_DP0 pid=297856) .b8 95
(EngineCore_DP0 pid=297856) .b8 116
(EngineCore_DP0 pid=297856) .b8 114
(EngineCore_DP0 pid=297856) .b8 105
(EngineCore_DP0 pid=297856) .b8 116
(EngineCore_DP0 pid=297856) .b8 111
(EngineCore_DP0 pid=297856) .b8 110
(EngineCore_DP0 pid=297856) .b8 47
(EngineCore_DP0 pid=297856) .b8 98
(EngineCore_DP0 pid=297856) .b8 117
(EngineCore_DP0 pid=297856) .b8 105
(EngineCore_DP0 pid=297856) .b8 108
(EngineCore_DP0 pid=297856) .b8 100
(EngineCore_DP0 pid=297856) .b8 47
(EngineCore_DP0 pid=297856) .b8 71
(EngineCore_DP0 pid=297856) .b8 66
(EngineCore_DP0 pid=297856) .b8 49
(EngineCore_DP0 pid=297856) .b8 48
(EngineCore_DP0 pid=297856) .b8 95
(EngineCore_DP0 pid=297856) .b8 99
(EngineCore_DP0 pid=297856) .b8 99
(EngineCore_DP0 pid=297856) .b8 49
(EngineCore_DP0 pid=297856) .b8 50
(EngineCore_DP0 pid=297856) .b8 49
(EngineCore_DP0 pid=297856) .b8 95
(EngineCore_DP0 pid=297856) .b8 112
(EngineCore_DP0 pid=297856) .b8 121
(EngineCore_DP0 pid=297856) .b8 51
(EngineCore_DP0 pid=297856) .b8 49
(EngineCore_DP0 pid=297856) .b8 50
(EngineCore_DP0 pid=297856) .b8 95
(EngineCore_DP0 pid=297856) .b8 99
(EngineCore_DP0 pid=297856) .b8 117
(EngineCore_DP0 pid=297856) .b8 49
(EngineCore_DP0 pid=297856) .b8 50
(EngineCore_DP0 pid=297856) .b8 57
(EngineCore_DP0 pid=297856) .b8 95
(EngineCore_DP0 pid=297856) .b8 97
(EngineCore_DP0 pid=297856) .b8 97
(EngineCore_DP0 pid=297856) .b8 114
(EngineCore_DP0 pid=297856) .b8 99
(EngineCore_DP0 pid=297856) .b8 104
(EngineCore_DP0 pid=297856) .b8 54
(EngineCore_DP0 pid=297856) .b8 52
(EngineCore_DP0 pid=297856) .b8 0
(EngineCore_DP0 pid=297856) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=297856) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=297856) .b8 113
(EngineCore_DP0 pid=297856) .b8 117
(EngineCore_DP0 pid=297856) .b8 97
(EngineCore_DP0 pid=297856) .b8 110
(EngineCore_DP0 pid=297856) .b8 116
(EngineCore_DP0 pid=297856) .b8 95
(EngineCore_DP0 pid=297856) .b8 115
(EngineCore_DP0 pid=297856) .b8 108
(EngineCore_DP0 pid=297856) .b8 105
(EngineCore_DP0 pid=297856) .b8 100
(EngineCore_DP0 pid=297856) .b8 101
(EngineCore_DP0 pid=297856) .b8 95
(EngineCore_DP0 pid=297856) .b8 102
(EngineCore_DP0 pid=297856) .b8 112
(EngineCore_DP0 pid=297856) .b8 56
(EngineCore_DP0 pid=297856) .b8 95
(EngineCore_DP0 pid=297856) .b8 107
(EngineCore_DP0 pid=297856) .b8 101
(EngineCore_DP0 pid=297856) .b8 114
(EngineCore_DP0 pid=297856) .b8 110
(EngineCore_DP0 pid=297856) .b8 101
(EngineCore_DP0 pid=297856) .b8 108
(EngineCore_DP0 pid=297856) .b8 0
(EngineCore_DP0 pid=297856) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=297856) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=297856) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=297856) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=297856) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=297856) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=297856) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=297856) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=297856) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=297856) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=297856) .b8 191                                 // DW_AT_call_line
(EngineCore_DP0 pid=297856) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=297856) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=297856) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=297856) 	}
(EngineCore_DP0 pid=297856) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=297856) 
(EngineCore_DP0 pid=297856) ================================================================
(EngineCore_DP0 pid=297856) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=297856) 
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpohcg6u17.ptx', '-o', '/tmp/tmpohcg6u17.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866] 
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866] 
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866] 
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpohcg6u17.ptx -o /tmp/tmpohcg6u17.ptx.o
(EngineCore_DP0 pid=297856) ERROR 01-25 18:46:16 [core.py:866] 

STDERR:
[2026-01-25 18:46:02] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 18:46:02] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 18:46:02] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 18:46:02] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:46:02] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:46:02] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:46:02] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:46:02] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:46:02] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 18:46:02] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 18:46:02] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 18:46:02] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 18:46:02] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 18:46:02] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 18:46:05] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 18:46:05] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 18:46:05] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 18:46:05] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:46:05] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:46:05] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:46:05] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:46:05] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:46:05] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 18:46:05] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 18:46:05] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 18:46:05] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 18:46:05] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 18:46:05] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=297856) [2026-01-25 18:46:06] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=297856) [2026-01-25 18:46:06] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=297856) [2026-01-25 18:46:06] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=297856) [2026-01-25 18:46:06] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=297856) [2026-01-25 18:46:06] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=297856) [2026-01-25 18:46:06] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=297856) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=297856) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.24s/it]
(EngineCore_DP0 pid=297856) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.24s/it]
(EngineCore_DP0 pid=297856) 
(EngineCore_DP0 pid=297856) [2026-01-25 18:46:15] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=297856) [2026-01-25 18:46:15] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=297856) [2026-01-25 18:46:15] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=297856) [2026-01-25 18:46:15] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 2621440 bytes
(EngineCore_DP0 pid=297856) [2026-01-25 18:46:15] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=297856) [2026-01-25 18:46:15] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 20971520 bytes
(EngineCore_DP0 pid=297856) [2026-01-25 18:46:15] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=297856) [2026-01-25 18:46:15] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10485760 bytes
(EngineCore_DP0 pid=297856) Process EngineCore_DP0:
(EngineCore_DP0 pid=297856) Traceback (most recent call last):
(EngineCore_DP0 pid=297856)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=297856)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=297856)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=297856)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=297856) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpohcg6u17.ptx', '-o', '/tmp/tmpohcg6u17.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=297856) 
(EngineCore_DP0 pid=297856) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=297856) 
(EngineCore_DP0 pid=297856) Traceback (most recent call last):
(EngineCore_DP0 pid=297856)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=297856)     self.run()
(EngineCore_DP0 pid=297856)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=297856)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=297856)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=297856)     raise e
(EngineCore_DP0 pid=297856)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=297856)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=297856)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=297856)     super().__init__(
(EngineCore_DP0 pid=297856)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=297856)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=297856)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=297856)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=297856)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=297856)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=297856)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=297856)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=297856)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=297856)     return func(*args, **kwargs)
(EngineCore_DP0 pid=297856)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=297856)     return func(*args, **kwargs)
(EngineCore_DP0 pid=297856)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=297856)     self.model_runner.profile_run()
(EngineCore_DP0 pid=297856)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=297856)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=297856)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=297856)     return func(*args, **kwargs)
(EngineCore_DP0 pid=297856)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=297856)     outputs = self.model(
(EngineCore_DP0 pid=297856)               ^^^^^^^^^^^
(EngineCore_DP0 pid=297856)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=297856)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=297856)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=297856)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=297856)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=297856)     model_output = self.model(
(EngineCore_DP0 pid=297856)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=297856)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=297856)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=297856)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=297856)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=297856)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=297856)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=297856)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=297856)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=297856)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=297856)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=297856)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=297856)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=297856)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=297856)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=297856)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=297856)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=297856)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=297856)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=297856)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=297856)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=297856)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=297856)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=297856)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=297856)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=297856)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=297856)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=297856)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=297856)     return self._linear_fn(
(EngineCore_DP0 pid=297856)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=297856)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=297856)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=297856)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=297856)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=297856)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=297856)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=297856)     return fn(input, L)
(EngineCore_DP0 pid=297856)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=297856)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=297856)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=297856)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=297856)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=297856)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=297856)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=297856)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=297856)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=297856)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=297856)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=297856)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=297856)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=297856)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=297856)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=297856)     raise PTXASError(error)
(EngineCore_DP0 pid=297856) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=297856) `ptxas` stderr:
(EngineCore_DP0 pid=297856) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=297856) 
(EngineCore_DP0 pid=297856) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpohcg6u17.ptx -o /tmp/tmpohcg6u17.ptx.o
(EngineCore_DP0 pid=297856) 
[rank0]:[W125 18:46:16.860849836 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=16

========== M=128 ==========
Time: 2026-01-25 18:46:18
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4
Params: prompt_len=128, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4 --dataset-name random --input-len 128 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 129 --max-num-batched-tokens 129 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Llama3.2-1B-FP8_M128.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 18:46:21 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 18:46:21 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=298316) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=298316) 
(EngineCore_DP0 pid=298316) 
(EngineCore_DP0 pid=298316) ================================================================
(EngineCore_DP0 pid=298316) Internal Triton PTX codegen error
(EngineCore_DP0 pid=298316) `ptxas` stderr:
(EngineCore_DP0 pid=298316) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=298316) 
(EngineCore_DP0 pid=298316) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpe4bzlvq6.ptx -o /tmp/tmpe4bzlvq6.ptx.o
(EngineCore_DP0 pid=298316) 
(EngineCore_DP0 pid=298316) 
(EngineCore_DP0 pid=298316) //
(EngineCore_DP0 pid=298316) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=298316) //
(EngineCore_DP0 pid=298316) 
(EngineCore_DP0 pid=298316) .version 8.7
(EngineCore_DP0 pid=298316) .target sm_121a
(EngineCore_DP0 pid=298316) .address_size 64
(EngineCore_DP0 pid=298316) 
(EngineCore_DP0 pid=298316) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=298316) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=298316)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=298316) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=298316) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=298316) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=298316) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=298316) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=298316) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=298316) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=298316) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=298316) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=298316) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=298316) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=298316) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=298316) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=298316) )
(EngineCore_DP0 pid=298316) .reqntid 128
(EngineCore_DP0 pid=298316) {
(EngineCore_DP0 pid=298316) 	.reg .pred 	%p<29>;
(EngineCore_DP0 pid=298316) 	.reg .b16 	%rs<73>;
(EngineCore_DP0 pid=298316) 	.reg .b32 	%r<139>;
(EngineCore_DP0 pid=298316) 	.reg .b64 	%rd<18>;
(EngineCore_DP0 pid=298316) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=298316) $L__func_begin0:
(EngineCore_DP0 pid=298316) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=298316) 
(EngineCore_DP0 pid=298316) // %bb.0:
(EngineCore_DP0 pid=298316) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=298316) 	ld.param.b32 	%r22, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=298316) 	ld.param.b32 	%r21, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=298316) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=298316) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=298316) $L__tmp0:
(EngineCore_DP0 pid=298316) 	.loc	1 177 24                        // quant_slide_tuned_Llama3.2-1B.py:177:24
(EngineCore_DP0 pid=298316) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=298316) 	ld.param.b32 	%r25, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=298316) 	.loc	1 182 26                        // quant_slide_tuned_Llama3.2-1B.py:182:26
(EngineCore_DP0 pid=298316) 	mul.lo.s32 	%r26, %r25, %r1;
(EngineCore_DP0 pid=298316) 	.loc	1 182 20                        // quant_slide_tuned_Llama3.2-1B.py:182:20
(EngineCore_DP0 pid=298316) 	mad.wide.s32 	%rd1, %r26, 2, %rd4;
(EngineCore_DP0 pid=298316) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=298316) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=298316) 	and.b32 	%r3, %r2, 127;
(EngineCore_DP0 pid=298316) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=298316) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=298316) 	setp.lt.s32 	%p1, %r22, 1;
(EngineCore_DP0 pid=298316) 	mov.b32 	%r136, 0f2B8CBCCC;
(EngineCore_DP0 pid=298316) 	setp.eq.b32 	%p28, %r2, 0;
(EngineCore_DP0 pid=298316) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=298316) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=298316) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=298316) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=298316) 	shr.u32 	%r35, %r2, 3;
(EngineCore_DP0 pid=298316) 	and.b32 	%r36, %r35, 12;
(EngineCore_DP0 pid=298316) 	mov.b32 	%r37, global_smem;
(EngineCore_DP0 pid=298316) 	add.s32 	%r55, %r37, %r36;
(EngineCore_DP0 pid=298316) 	shl.b32 	%r38, %r2, 2;
(EngineCore_DP0 pid=298316) 	add.s32 	%r58, %r37, %r38;
(EngineCore_DP0 pid=298316) 	mov.b32 	%r43, 0;
(EngineCore_DP0 pid=298316) 	mov.b32 	%r134, 0f00000000;
(EngineCore_DP0 pid=298316) 	setp.lt.u32 	%p5, %r2, 4;
(EngineCore_DP0 pid=298316) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=298316) 	mov.b32 	%r135, %r43;
(EngineCore_DP0 pid=298316) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=298316) 	.loc	1 188 19                        // quant_slide_tuned_Llama3.2-1B.py:188:19
(EngineCore_DP0 pid=298316) 	add.s32 	%r61, %r4, %r135;
(EngineCore_DP0 pid=298316) 	.loc	1 189 22                        // quant_slide_tuned_Llama3.2-1B.py:189:22
(EngineCore_DP0 pid=298316) 	add.s32 	%r62, %r61, 1024;
(EngineCore_DP0 pid=298316) 	setp.lt.s32 	%p2, %r61, %r21;
(EngineCore_DP0 pid=298316) 	setp.lt.s32 	%p3, %r62, %r21;
(EngineCore_DP0 pid=298316) 	.loc	1 190 29                        // quant_slide_tuned_Llama3.2-1B.py:190:29
(EngineCore_DP0 pid=298316) 	mad.wide.s32 	%rd6, %r61, 2, %rd1;
(EngineCore_DP0 pid=298316) 	add.s64 	%rd7, %rd6, 2048;
(EngineCore_DP0 pid=298316) 	.loc	1 190 21                        // quant_slide_tuned_Llama3.2-1B.py:190:21
(EngineCore_DP0 pid=298316) 	// begin inline asm
(EngineCore_DP0 pid=298316) 	mov.u32 %r39, %r43;
(EngineCore_DP0 pid=298316) 	mov.u32 %r40, %r43;
(EngineCore_DP0 pid=298316) 	mov.u32 %r41, %r43;
(EngineCore_DP0 pid=298316) 	mov.u32 %r42, %r43;
(EngineCore_DP0 pid=298316) 	@%p2 ld.global.v4.b32 { %r39, %r40, %r41, %r42 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=298316) 	// end inline asm
(EngineCore_DP0 pid=298316) 	mov.b32 	{%rs1, %rs2}, %r39;
(EngineCore_DP0 pid=298316) 	mov.b32 	{%rs3, %rs4}, %r40;
(EngineCore_DP0 pid=298316) 	mov.b32 	{%rs5, %rs6}, %r41;
(EngineCore_DP0 pid=298316) 	mov.b32 	{%rs7, %rs8}, %r42;
(EngineCore_DP0 pid=298316) 	// begin inline asm
(EngineCore_DP0 pid=298316) 	mov.u32 %r47, %r43;
(EngineCore_DP0 pid=298316) 	mov.u32 %r48, %r43;
(EngineCore_DP0 pid=298316) 	mov.u32 %r49, %r43;
(EngineCore_DP0 pid=298316) 	mov.u32 %r50, %r43;
(EngineCore_DP0 pid=298316) 	@%p3 ld.global.v4.b32 { %r47, %r48, %r49, %r50 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=298316) 	// end inline asm
(EngineCore_DP0 pid=298316) 	mov.b32 	{%rs9, %rs10}, %r47;
(EngineCore_DP0 pid=298316) 	mov.b32 	{%rs11, %rs12}, %r48;
(EngineCore_DP0 pid=298316) 	mov.b32 	{%rs13, %rs14}, %r49;
(EngineCore_DP0 pid=298316) 	mov.b32 	{%rs15, %rs16}, %r50;
(EngineCore_DP0 pid=298316) 	.loc	1 191 50                        // quant_slide_tuned_Llama3.2-1B.py:191:50
(EngineCore_DP0 pid=298316) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=298316) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=298316) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=298316) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=298316) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=298316) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=298316) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=298316) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=298316) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=298316) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=298316) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=298316) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=298316) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=298316) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=298316) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=298316) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=298316) $L__tmp1:
(EngineCore_DP0 pid=298316) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=298316) 	bar.sync 	0;
(EngineCore_DP0 pid=298316) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=298316) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=298316) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=298316) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=298316) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=298316) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=298316) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=298316) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=298316) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=298316) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=298316) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=298316) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=298316) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=298316) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=298316) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=298316) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=298316) 	cvt.f32.bf16 	%r63, %rs47;
(EngineCore_DP0 pid=298316) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=298316) 	shfl.sync.bfly.b32 	%r64, %r63, 16, 31, -1;
(EngineCore_DP0 pid=298316) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=298316) 	max.f32 	%r65, %r63, %r64;
(EngineCore_DP0 pid=298316) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=298316) 	shfl.sync.bfly.b32 	%r66, %r65, 8, 31, -1;
(EngineCore_DP0 pid=298316) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=298316) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=298316) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=298316) 	shfl.sync.bfly.b32 	%r68, %r67, 4, 31, -1;
(EngineCore_DP0 pid=298316) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=298316) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=298316) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=298316) 	shfl.sync.bfly.b32 	%r70, %r69, 2, 31, -1;
(EngineCore_DP0 pid=298316) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=298316) 	max.f32 	%r71, %r69, %r70;
(EngineCore_DP0 pid=298316) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=298316) 	shfl.sync.bfly.b32 	%r72, %r71, 1, 31, -1;
(EngineCore_DP0 pid=298316) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=298316) 	max.f32 	%r56, %r71, %r72;
(EngineCore_DP0 pid=298316) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=298316) 	// begin inline asm
(EngineCore_DP0 pid=298316) 	@%p4 st.shared.b32 [ %r55 + 0 ], %r56;
(EngineCore_DP0 pid=298316) 	// end inline asm
(EngineCore_DP0 pid=298316) 	bar.sync 	0;
(EngineCore_DP0 pid=298316) 	// begin inline asm
(EngineCore_DP0 pid=298316) 	@%p5 ld.shared.b32 %r57, [ %r58 + 0 ];
(EngineCore_DP0 pid=298316) 	// end inline asm
(EngineCore_DP0 pid=298316) 	shfl.sync.bfly.b32 	%r73, %r57, 2, 31, -1;
(EngineCore_DP0 pid=298316) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=298316) 	max.f32 	%r74, %r57, %r73;
(EngineCore_DP0 pid=298316) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=298316) 	shfl.sync.bfly.b32 	%r75, %r74, 1, 31, -1;
(EngineCore_DP0 pid=298316) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=298316) 	max.f32 	%r60, %r74, %r75;
(EngineCore_DP0 pid=298316) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=298316) 	// begin inline asm
(EngineCore_DP0 pid=298316) 	@%p28 st.shared.b32 [ %r58 + 0 ], %r60;
(EngineCore_DP0 pid=298316) 	// end inline asm
(EngineCore_DP0 pid=298316) 	bar.sync 	0;
(EngineCore_DP0 pid=298316) 	ld.shared.b32 	%r76, [global_smem];
(EngineCore_DP0 pid=298316) $L__tmp2:
(EngineCore_DP0 pid=298316) 	.loc	1 191 36                        // quant_slide_tuned_Llama3.2-1B.py:191:36
(EngineCore_DP0 pid=298316) 	max.f32 	%r134, %r134, %r76;
(EngineCore_DP0 pid=298316) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=298316) 	add.s32 	%r135, %r135, 2048;
(EngineCore_DP0 pid=298316) 	setp.lt.s32 	%p7, %r135, %r22;
(EngineCore_DP0 pid=298316) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=298316) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=298316) 	.loc	1 193 32                        // quant_slide_tuned_Llama3.2-1B.py:193:32
(EngineCore_DP0 pid=298316) 	max.f32 	%r136, %r134, 0f2B8CBCCC;
(EngineCore_DP0 pid=298316) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=298316) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=298316) 	mov.b32 	%r78, 0f43E00000;
(EngineCore_DP0 pid=298316) 	.loc	1 194 32                        // quant_slide_tuned_Llama3.2-1B.py:194:32
(EngineCore_DP0 pid=298316) 	div.full.f32 	%r79, %r136, %r78;
(EngineCore_DP0 pid=298316) 	.loc	1 194 41                        // quant_slide_tuned_Llama3.2-1B.py:194:41
(EngineCore_DP0 pid=298316) 	max.f32 	%r77, %r79, 0f36924925;
(EngineCore_DP0 pid=298316) 	.loc	1 196 25                        // quant_slide_tuned_Llama3.2-1B.py:196:25
(EngineCore_DP0 pid=298316) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=298316) 	.loc	1 196 30                        // quant_slide_tuned_Llama3.2-1B.py:196:30
(EngineCore_DP0 pid=298316) 	// begin inline asm
(EngineCore_DP0 pid=298316) 	@%p28 st.global.b32 [ %rd8 + 0 ], { %r77 };
(EngineCore_DP0 pid=298316) 	// end inline asm
(EngineCore_DP0 pid=298316) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=298316) 	setp.lt.s32 	%p9, %r23, 1;
(EngineCore_DP0 pid=298316) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=298316) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=298316) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=298316) 	ld.param.b32 	%r27, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=298316) 	shr.s32 	%r28, %r27, 31;
(EngineCore_DP0 pid=298316) 	shr.u32 	%r29, %r28, 30;
(EngineCore_DP0 pid=298316) 	add.s32 	%r30, %r27, %r29;
(EngineCore_DP0 pid=298316) 	shr.s32 	%r31, %r30, 2;
(EngineCore_DP0 pid=298316) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=298316) 	mul.lo.s32 	%r32, %r31, %r1;
(EngineCore_DP0 pid=298316) 	mad.wide.s32 	%rd2, %r32, 4, %rd5;
(EngineCore_DP0 pid=298316) 	div.full.f32 	%r14, %r78, %r136;
(EngineCore_DP0 pid=298316) 	shl.b32 	%r15, %r3, 1;
(EngineCore_DP0 pid=298316) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=298316) 	add.s32 	%r137, %r4, 7;
(EngineCore_DP0 pid=298316) 	mov.b32 	%r138, 0;
(EngineCore_DP0 pid=298316) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=298316)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=298316) 	.loc	1 203 30                        // quant_slide_tuned_Llama3.2-1B.py:203:30
(EngineCore_DP0 pid=298316) 	add.s32 	%r91, %r15, %r138;
(EngineCore_DP0 pid=298316) 	setp.lt.s32 	%p18, %r91, %r23;
(EngineCore_DP0 pid=298316) 	.loc	1 208 22                        // quant_slide_tuned_Llama3.2-1B.py:208:22
(EngineCore_DP0 pid=298316) 	add.s32 	%r92, %r137, -7;
(EngineCore_DP0 pid=298316) 	.loc	1 211 53                        // quant_slide_tuned_Llama3.2-1B.py:211:53
(EngineCore_DP0 pid=298316) 	add.s32 	%r93, %r137, -3;
(EngineCore_DP0 pid=298316) 	setp.lt.s32 	%p19, %r92, %r21;
(EngineCore_DP0 pid=298316) 	setp.lt.s32 	%p20, %r93, %r21;
(EngineCore_DP0 pid=298316) 	.loc	1 211 37                        // quant_slide_tuned_Llama3.2-1B.py:211:37
(EngineCore_DP0 pid=298316) 	and.pred 	%p10, %p18, %p19;
(EngineCore_DP0 pid=298316) 	and.pred 	%p11, %p18, %p20;
(EngineCore_DP0 pid=298316) 	.loc	1 210 29                        // quant_slide_tuned_Llama3.2-1B.py:210:29
(EngineCore_DP0 pid=298316) 	mad.wide.s32 	%rd9, %r92, 2, %rd1;
(EngineCore_DP0 pid=298316) 	add.s64 	%rd10, %rd9, 8;
(EngineCore_DP0 pid=298316) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=298316) 	.loc	1 210 21                        // quant_slide_tuned_Llama3.2-1B.py:210:21
(EngineCore_DP0 pid=298316) 	// begin inline asm
(EngineCore_DP0 pid=298316) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=298316) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=298316) 	// end inline asm
(EngineCore_DP0 pid=298316) 	// begin inline asm
(EngineCore_DP0 pid=298316) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=298316) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=298316) 	// end inline asm
(EngineCore_DP0 pid=298316) 	.loc	1 211 79                        // quant_slide_tuned_Llama3.2-1B.py:211:79
(EngineCore_DP0 pid=298316) 	cvt.f32.bf16 	%r94, %rs48;
(EngineCore_DP0 pid=298316) 	cvt.f32.bf16 	%r95, %rs50;
(EngineCore_DP0 pid=298316) 	.loc	1 213 48                        // quant_slide_tuned_Llama3.2-1B.py:213:48
(EngineCore_DP0 pid=298316) 	add.s32 	%r96, %r137, -6;
(EngineCore_DP0 pid=298316) 	.loc	1 213 53                        // quant_slide_tuned_Llama3.2-1B.py:213:53
(EngineCore_DP0 pid=298316) 	add.s32 	%r97, %r137, -2;
(EngineCore_DP0 pid=298316) 	setp.lt.s32 	%p21, %r96, %r21;
(EngineCore_DP0 pid=298316) 	setp.lt.s32 	%p22, %r97, %r21;
(EngineCore_DP0 pid=298316) 	.loc	1 213 37                        // quant_slide_tuned_Llama3.2-1B.py:213:37
(EngineCore_DP0 pid=298316) 	and.pred 	%p12, %p18, %p21;
(EngineCore_DP0 pid=298316) 	and.pred 	%p13, %p18, %p22;
(EngineCore_DP0 pid=298316) 	.loc	1 212 39                        // quant_slide_tuned_Llama3.2-1B.py:212:39
(EngineCore_DP0 pid=298316) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=298316) 	add.s64 	%rd12, %rd9, 10;
(EngineCore_DP0 pid=298316) 	.loc	1 212 21                        // quant_slide_tuned_Llama3.2-1B.py:212:21
(EngineCore_DP0 pid=298316) 	// begin inline asm
(EngineCore_DP0 pid=298316) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=298316) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=298316) 	// end inline asm
(EngineCore_DP0 pid=298316) 	// begin inline asm
(EngineCore_DP0 pid=298316) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=298316) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=298316) 	// end inline asm
(EngineCore_DP0 pid=298316) 	.loc	1 213 79                        // quant_slide_tuned_Llama3.2-1B.py:213:79
(EngineCore_DP0 pid=298316) 	cvt.f32.bf16 	%r98, %rs52;
(EngineCore_DP0 pid=298316) 	cvt.f32.bf16 	%r99, %rs54;
(EngineCore_DP0 pid=298316) 	.loc	1 215 48                        // quant_slide_tuned_Llama3.2-1B.py:215:48
(EngineCore_DP0 pid=298316) 	add.s32 	%r100, %r137, -5;
(EngineCore_DP0 pid=298316) 	.loc	1 215 53                        // quant_slide_tuned_Llama3.2-1B.py:215:53
(EngineCore_DP0 pid=298316) 	add.s32 	%r101, %r137, -1;
(EngineCore_DP0 pid=298316) 	setp.lt.s32 	%p23, %r100, %r21;
(EngineCore_DP0 pid=298316) 	setp.lt.s32 	%p24, %r101, %r21;
(EngineCore_DP0 pid=298316) 	.loc	1 215 37                        // quant_slide_tuned_Llama3.2-1B.py:215:37
(EngineCore_DP0 pid=298316) 	and.pred 	%p14, %p18, %p23;
(EngineCore_DP0 pid=298316) 	and.pred 	%p15, %p18, %p24;
(EngineCore_DP0 pid=298316) 	.loc	1 214 39                        // quant_slide_tuned_Llama3.2-1B.py:214:39
(EngineCore_DP0 pid=298316) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=298316) 	add.s64 	%rd14, %rd9, 12;
(EngineCore_DP0 pid=298316) 	.loc	1 214 21                        // quant_slide_tuned_Llama3.2-1B.py:214:21
(EngineCore_DP0 pid=298316) 	// begin inline asm
(EngineCore_DP0 pid=298316) 	mov.u16 %rs56, %rs49;
(EngineCore_DP0 pid=298316) 	@%p14 ld.global.b16 { %rs56 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=298316) 	// end inline asm
(EngineCore_DP0 pid=298316) 	// begin inline asm
(EngineCore_DP0 pid=298316) 	mov.u16 %rs58, %rs49;
(EngineCore_DP0 pid=298316) 	@%p15 ld.global.b16 { %rs58 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=298316) 	// end inline asm
(EngineCore_DP0 pid=298316) 	.loc	1 215 79                        // quant_slide_tuned_Llama3.2-1B.py:215:79
(EngineCore_DP0 pid=298316) 	cvt.f32.bf16 	%r102, %rs56;
(EngineCore_DP0 pid=298316) 	cvt.f32.bf16 	%r103, %rs58;
(EngineCore_DP0 pid=298316) 	.loc	1 217 48                        // quant_slide_tuned_Llama3.2-1B.py:217:48
(EngineCore_DP0 pid=298316) 	add.s32 	%r104, %r137, -4;
(EngineCore_DP0 pid=298316) 	.loc	1 217 53                        // quant_slide_tuned_Llama3.2-1B.py:217:53
(EngineCore_DP0 pid=298316) 	setp.lt.s32 	%p25, %r104, %r21;
(EngineCore_DP0 pid=298316) 	setp.lt.s32 	%p26, %r137, %r21;
(EngineCore_DP0 pid=298316) 	.loc	1 217 37                        // quant_slide_tuned_Llama3.2-1B.py:217:37
(EngineCore_DP0 pid=298316) 	and.pred 	%p16, %p18, %p25;
(EngineCore_DP0 pid=298316) 	and.pred 	%p17, %p18, %p26;
(EngineCore_DP0 pid=298316) 	.loc	1 216 39                        // quant_slide_tuned_Llama3.2-1B.py:216:39
(EngineCore_DP0 pid=298316) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=298316) 	add.s64 	%rd16, %rd9, 14;
(EngineCore_DP0 pid=298316) 	.loc	1 216 21                        // quant_slide_tuned_Llama3.2-1B.py:216:21
(EngineCore_DP0 pid=298316) 	// begin inline asm
(EngineCore_DP0 pid=298316) 	mov.u16 %rs60, %rs49;
(EngineCore_DP0 pid=298316) 	@%p16 ld.global.b16 { %rs60 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=298316) 	// end inline asm
(EngineCore_DP0 pid=298316) 	// begin inline asm
(EngineCore_DP0 pid=298316) 	mov.u16 %rs62, %rs49;
(EngineCore_DP0 pid=298316) 	@%p17 ld.global.b16 { %rs62 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=298316) 	// end inline asm
(EngineCore_DP0 pid=298316) 	.loc	1 217 79                        // quant_slide_tuned_Llama3.2-1B.py:217:79
(EngineCore_DP0 pid=298316) 	cvt.f32.bf16 	%r105, %rs60;
(EngineCore_DP0 pid=298316) 	cvt.f32.bf16 	%r106, %rs62;
(EngineCore_DP0 pid=298316) 	.loc	1 219 27                        // quant_slide_tuned_Llama3.2-1B.py:219:27
(EngineCore_DP0 pid=298316) 	mul.f32 	%r107, %r14, %r94;
(EngineCore_DP0 pid=298316) 	mul.f32 	%r108, %r14, %r95;
(EngineCore_DP0 pid=298316) 	mov.b32 	%r109, 0f43E00000;
(EngineCore_DP0 pid=298316) 	.loc	1 219 48                        // quant_slide_tuned_Llama3.2-1B.py:219:48
(EngineCore_DP0 pid=298316) 	min.xorsign.abs.f32 	%r81, %r107, %r109;
(EngineCore_DP0 pid=298316) 	min.xorsign.abs.f32 	%r82, %r108, %r109;
(EngineCore_DP0 pid=298316) 	.loc	1 219 60                        // quant_slide_tuned_Llama3.2-1B.py:219:60
(EngineCore_DP0 pid=298316) 	// begin inline asm
(EngineCore_DP0 pid=298316) 	cvt.rn.satfinite.e4m3x2.f32  %rs64, %r82, %r81; 
(EngineCore_DP0 pid=298316) 
(EngineCore_DP0 pid=298316) 	// end inline asm
(EngineCore_DP0 pid=298316) 	shr.u16 	%rs68, %rs64, 8;
(EngineCore_DP0 pid=298316) 	.loc	1 220 27                        // quant_slide_tuned_Llama3.2-1B.py:220:27
(EngineCore_DP0 pid=298316) 	mul.f32 	%r110, %r14, %r98;
(EngineCore_DP0 pid=298316) 	mul.f32 	%r111, %r14, %r99;
(EngineCore_DP0 pid=298316) 	.loc	1 220 48                        // quant_slide_tuned_Llama3.2-1B.py:220:48
(EngineCore_DP0 pid=298316) 	min.xorsign.abs.f32 	%r83, %r110, %r109;
(EngineCore_DP0 pid=298316) 	min.xorsign.abs.f32 	%r84, %r111, %r109;
(EngineCore_DP0 pid=298316) 	.loc	1 220 60                        // quant_slide_tuned_Llama3.2-1B.py:220:60
(EngineCore_DP0 pid=298316) 	// begin inline asm
(EngineCore_DP0 pid=298316) 	cvt.rn.satfinite.e4m3x2.f32  %rs65, %r84, %r83; 
(EngineCore_DP0 pid=298316) 
(EngineCore_DP0 pid=298316) 	// end inline asm
(EngineCore_DP0 pid=298316) 	shr.u16 	%rs69, %rs65, 8;
(EngineCore_DP0 pid=298316) 	.loc	1 221 27                        // quant_slide_tuned_Llama3.2-1B.py:221:27
(EngineCore_DP0 pid=298316) 	mul.f32 	%r112, %r14, %r102;
(EngineCore_DP0 pid=298316) 	mul.f32 	%r113, %r14, %r103;
(EngineCore_DP0 pid=298316) 	.loc	1 221 48                        // quant_slide_tuned_Llama3.2-1B.py:221:48
(EngineCore_DP0 pid=298316) 	min.xorsign.abs.f32 	%r85, %r112, %r109;
(EngineCore_DP0 pid=298316) 	min.xorsign.abs.f32 	%r86, %r113, %r109;
(EngineCore_DP0 pid=298316) 	.loc	1 221 60                        // quant_slide_tuned_Llama3.2-1B.py:221:60
(EngineCore_DP0 pid=298316) 	// begin inline asm
(EngineCore_DP0 pid=298316) 	cvt.rn.satfinite.e4m3x2.f32  %rs66, %r86, %r85; 
(EngineCore_DP0 pid=298316) 
(EngineCore_DP0 pid=298316) 	// end inline asm
(EngineCore_DP0 pid=298316) 	shr.u16 	%rs70, %rs66, 8;
(EngineCore_DP0 pid=298316) 	.loc	1 222 27                        // quant_slide_tuned_Llama3.2-1B.py:222:27
(EngineCore_DP0 pid=298316) 	mul.f32 	%r114, %r14, %r105;
(EngineCore_DP0 pid=298316) 	mul.f32 	%r115, %r14, %r106;
(EngineCore_DP0 pid=298316) 	.loc	1 222 48                        // quant_slide_tuned_Llama3.2-1B.py:222:48
(EngineCore_DP0 pid=298316) 	min.xorsign.abs.f32 	%r87, %r114, %r109;
(EngineCore_DP0 pid=298316) 	min.xorsign.abs.f32 	%r88, %r115, %r109;
(EngineCore_DP0 pid=298316) 	.loc	1 222 60                        // quant_slide_tuned_Llama3.2-1B.py:222:60
(EngineCore_DP0 pid=298316) 	// begin inline asm
(EngineCore_DP0 pid=298316) 	cvt.rn.satfinite.e4m3x2.f32  %rs67, %r88, %r87; 
(EngineCore_DP0 pid=298316) 
(EngineCore_DP0 pid=298316) 	// end inline asm
(EngineCore_DP0 pid=298316) 	shr.u16 	%rs71, %rs67, 8;
(EngineCore_DP0 pid=298316) 	.loc	1 224 45                        // quant_slide_tuned_Llama3.2-1B.py:224:45
(EngineCore_DP0 pid=298316) 	cvt.u32.u16 	%r116, %rs64;
(EngineCore_DP0 pid=298316) 	and.b32 	%r117, %r116, 255;
(EngineCore_DP0 pid=298316) 	cvt.u32.u16 	%r118, %rs68;
(EngineCore_DP0 pid=298316) 	.loc	1 226 45                        // quant_slide_tuned_Llama3.2-1B.py:226:45
(EngineCore_DP0 pid=298316) 	cvt.u32.u16 	%r119, %rs66;
(EngineCore_DP0 pid=298316) 	and.b32 	%r120, %r119, 255;
(EngineCore_DP0 pid=298316) 	cvt.u32.u16 	%r121, %rs70;
(EngineCore_DP0 pid=298316) 	.loc	1 227 45                        // quant_slide_tuned_Llama3.2-1B.py:227:45
(EngineCore_DP0 pid=298316) 	cvt.u32.u16 	%r122, %rs67;
(EngineCore_DP0 pid=298316) 	cvt.u32.u16 	%r123, %rs71;
(EngineCore_DP0 pid=298316) 	.loc	1 229 30                        // quant_slide_tuned_Llama3.2-1B.py:229:30
(EngineCore_DP0 pid=298316) 	and.b16 	%rs72, %rs65, 255;
(EngineCore_DP0 pid=298316) 	mul.wide.u16 	%r124, %rs72, 256;
(EngineCore_DP0 pid=298316) 	mul.wide.u16 	%r125, %rs69, 256;
(EngineCore_DP0 pid=298316) 	.loc	1 229 24                        // quant_slide_tuned_Llama3.2-1B.py:229:24
(EngineCore_DP0 pid=298316) 	or.b32 	%r126, %r124, %r117;
(EngineCore_DP0 pid=298316) 	or.b32 	%r127, %r125, %r118;
(EngineCore_DP0 pid=298316) 	.loc	1 229 42                        // quant_slide_tuned_Llama3.2-1B.py:229:42
(EngineCore_DP0 pid=298316) 	shl.b32 	%r128, %r120, 16;
(EngineCore_DP0 pid=298316) 	shl.b32 	%r129, %r121, 16;
(EngineCore_DP0 pid=298316) 	.loc	1 229 36                        // quant_slide_tuned_Llama3.2-1B.py:229:36
(EngineCore_DP0 pid=298316) 	or.b32 	%r130, %r126, %r128;
(EngineCore_DP0 pid=298316) 	or.b32 	%r131, %r127, %r129;
(EngineCore_DP0 pid=298316) 	.loc	1 229 55                        // quant_slide_tuned_Llama3.2-1B.py:229:55
(EngineCore_DP0 pid=298316) 	shl.b32 	%r132, %r122, 24;
(EngineCore_DP0 pid=298316) 	shl.b32 	%r133, %r123, 24;
(EngineCore_DP0 pid=298316) 	.loc	1 229 49                        // quant_slide_tuned_Llama3.2-1B.py:229:49
(EngineCore_DP0 pid=298316) 	or.b32 	%r89, %r130, %r132;
(EngineCore_DP0 pid=298316) 	or.b32 	%r90, %r131, %r133;
(EngineCore_DP0 pid=298316) 	.loc	1 230 29                        // quant_slide_tuned_Llama3.2-1B.py:230:29
(EngineCore_DP0 pid=298316) 	mad.wide.s32 	%rd17, %r91, 4, %rd2;
(EngineCore_DP0 pid=298316) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-1B.py:230:39
(EngineCore_DP0 pid=298316) 	// begin inline asm
(EngineCore_DP0 pid=298316) 	@%p18 st.global.v2.b32 [ %rd17 + 0 ], { %r89, %r90 };
(EngineCore_DP0 pid=298316) 	// end inline asm
(EngineCore_DP0 pid=298316) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=298316) 	add.s32 	%r138, %r138, 256;
(EngineCore_DP0 pid=298316) 	add.s32 	%r137, %r137, 1024;
(EngineCore_DP0 pid=298316) 	setp.lt.s32 	%p27, %r138, %r23;
(EngineCore_DP0 pid=298316) 	@%p27 bra 	$L__BB0_6;
(EngineCore_DP0 pid=298316) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=298316) 	.loc	1 201 4                         // quant_slide_tuned_Llama3.2-1B.py:201:4
(EngineCore_DP0 pid=298316) 	ret;
(EngineCore_DP0 pid=298316) $L__tmp3:
(EngineCore_DP0 pid=298316) $L__func_end0:
(EngineCore_DP0 pid=298316)                                         // -- End function
(EngineCore_DP0 pid=298316) }
(EngineCore_DP0 pid=298316) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=298316) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=298316) 	.section	.debug_abbrev
(EngineCore_DP0 pid=298316) 	{
(EngineCore_DP0 pid=298316) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=298316) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=298316) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=298316) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=298316) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=298316) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=298316) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=298316) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=298316) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=298316) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=298316) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=298316) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=298316) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=298316) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=298316) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=298316) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=298316) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=298316) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=298316) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=298316) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=298316) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=298316) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=298316) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=298316) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=298316) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=298316) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=298316) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=298316) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=298316) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=298316) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=298316) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=298316) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=298316) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=298316) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=298316) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=298316) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=298316) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=298316) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=298316) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=298316) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=298316) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=298316) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=298316) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=298316) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=298316) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=298316) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=298316) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=298316) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=298316) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=298316) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=298316) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=298316) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=298316) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=298316) 	}
(EngineCore_DP0 pid=298316) 	.section	.debug_info
(EngineCore_DP0 pid=298316) 	{
(EngineCore_DP0 pid=298316) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=298316) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=298316) .b8 0
(EngineCore_DP0 pid=298316) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=298316) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=298316) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=298316) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=298316) .b8 114
(EngineCore_DP0 pid=298316) .b8 105
(EngineCore_DP0 pid=298316) .b8 116
(EngineCore_DP0 pid=298316) .b8 111
(EngineCore_DP0 pid=298316) .b8 110
(EngineCore_DP0 pid=298316) .b8 0
(EngineCore_DP0 pid=298316) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=298316) .b8 0
(EngineCore_DP0 pid=298316) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=298316) .b8 117
(EngineCore_DP0 pid=298316) .b8 97
(EngineCore_DP0 pid=298316) .b8 110
(EngineCore_DP0 pid=298316) .b8 116
(EngineCore_DP0 pid=298316) .b8 95
(EngineCore_DP0 pid=298316) .b8 115
(EngineCore_DP0 pid=298316) .b8 108
(EngineCore_DP0 pid=298316) .b8 105
(EngineCore_DP0 pid=298316) .b8 100
(EngineCore_DP0 pid=298316) .b8 101
(EngineCore_DP0 pid=298316) .b8 95
(EngineCore_DP0 pid=298316) .b8 116
(EngineCore_DP0 pid=298316) .b8 117
(EngineCore_DP0 pid=298316) .b8 110
(EngineCore_DP0 pid=298316) .b8 101
(EngineCore_DP0 pid=298316) .b8 100
(EngineCore_DP0 pid=298316) .b8 95
(EngineCore_DP0 pid=298316) .b8 76
(EngineCore_DP0 pid=298316) .b8 108
(EngineCore_DP0 pid=298316) .b8 97
(EngineCore_DP0 pid=298316) .b8 109
(EngineCore_DP0 pid=298316) .b8 97
(EngineCore_DP0 pid=298316) .b8 51
(EngineCore_DP0 pid=298316) .b8 46
(EngineCore_DP0 pid=298316) .b8 50
(EngineCore_DP0 pid=298316) .b8 45
(EngineCore_DP0 pid=298316) .b8 49
(EngineCore_DP0 pid=298316) .b8 66
(EngineCore_DP0 pid=298316) .b8 46
(EngineCore_DP0 pid=298316) .b8 112
(EngineCore_DP0 pid=298316) .b8 121
(EngineCore_DP0 pid=298316) .b8 0
(EngineCore_DP0 pid=298316) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=298316) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=298316) .b8 114
(EngineCore_DP0 pid=298316) .b8 111
(EngineCore_DP0 pid=298316) .b8 111
(EngineCore_DP0 pid=298316) .b8 116
(EngineCore_DP0 pid=298316) .b8 47
(EngineCore_DP0 pid=298316) .b8 118
(EngineCore_DP0 pid=298316) .b8 108
(EngineCore_DP0 pid=298316) .b8 108
(EngineCore_DP0 pid=298316) .b8 109
(EngineCore_DP0 pid=298316) .b8 98
(EngineCore_DP0 pid=298316) .b8 101
(EngineCore_DP0 pid=298316) .b8 110
(EngineCore_DP0 pid=298316) .b8 99
(EngineCore_DP0 pid=298316) .b8 104
(EngineCore_DP0 pid=298316) .b8 47
(EngineCore_DP0 pid=298316) .b8 115
(EngineCore_DP0 pid=298316) .b8 108
(EngineCore_DP0 pid=298316) .b8 105
(EngineCore_DP0 pid=298316) .b8 100
(EngineCore_DP0 pid=298316) .b8 101
(EngineCore_DP0 pid=298316) .b8 115
(EngineCore_DP0 pid=298316) .b8 112
(EngineCore_DP0 pid=298316) .b8 97
(EngineCore_DP0 pid=298316) .b8 114
(EngineCore_DP0 pid=298316) .b8 115
(EngineCore_DP0 pid=298316) .b8 101
(EngineCore_DP0 pid=298316) .b8 47
(EngineCore_DP0 pid=298316) .b8 99
(EngineCore_DP0 pid=298316) .b8 115
(EngineCore_DP0 pid=298316) .b8 114
(EngineCore_DP0 pid=298316) .b8 99
(EngineCore_DP0 pid=298316) .b8 47
(EngineCore_DP0 pid=298316) .b8 102
(EngineCore_DP0 pid=298316) .b8 117
(EngineCore_DP0 pid=298316) .b8 115
(EngineCore_DP0 pid=298316) .b8 101
(EngineCore_DP0 pid=298316) .b8 100
(EngineCore_DP0 pid=298316) .b8 95
(EngineCore_DP0 pid=298316) .b8 113
(EngineCore_DP0 pid=298316) .b8 117
(EngineCore_DP0 pid=298316) .b8 97
(EngineCore_DP0 pid=298316) .b8 110
(EngineCore_DP0 pid=298316) .b8 116
(EngineCore_DP0 pid=298316) .b8 95
(EngineCore_DP0 pid=298316) .b8 115
(EngineCore_DP0 pid=298316) .b8 108
(EngineCore_DP0 pid=298316) .b8 105
(EngineCore_DP0 pid=298316) .b8 100
(EngineCore_DP0 pid=298316) .b8 101
(EngineCore_DP0 pid=298316) .b8 95
(EngineCore_DP0 pid=298316) .b8 116
(EngineCore_DP0 pid=298316) .b8 114
(EngineCore_DP0 pid=298316) .b8 105
(EngineCore_DP0 pid=298316) .b8 116
(EngineCore_DP0 pid=298316) .b8 111
(EngineCore_DP0 pid=298316) .b8 110
(EngineCore_DP0 pid=298316) .b8 47
(EngineCore_DP0 pid=298316) .b8 98
(EngineCore_DP0 pid=298316) .b8 117
(EngineCore_DP0 pid=298316) .b8 105
(EngineCore_DP0 pid=298316) .b8 108
(EngineCore_DP0 pid=298316) .b8 100
(EngineCore_DP0 pid=298316) .b8 47
(EngineCore_DP0 pid=298316) .b8 71
(EngineCore_DP0 pid=298316) .b8 66
(EngineCore_DP0 pid=298316) .b8 49
(EngineCore_DP0 pid=298316) .b8 48
(EngineCore_DP0 pid=298316) .b8 95
(EngineCore_DP0 pid=298316) .b8 99
(EngineCore_DP0 pid=298316) .b8 99
(EngineCore_DP0 pid=298316) .b8 49
(EngineCore_DP0 pid=298316) .b8 50
(EngineCore_DP0 pid=298316) .b8 49
(EngineCore_DP0 pid=298316) .b8 95
(EngineCore_DP0 pid=298316) .b8 112
(EngineCore_DP0 pid=298316) .b8 121
(EngineCore_DP0 pid=298316) .b8 51
(EngineCore_DP0 pid=298316) .b8 49
(EngineCore_DP0 pid=298316) .b8 50
(EngineCore_DP0 pid=298316) .b8 95
(EngineCore_DP0 pid=298316) .b8 99
(EngineCore_DP0 pid=298316) .b8 117
(EngineCore_DP0 pid=298316) .b8 49
(EngineCore_DP0 pid=298316) .b8 50
(EngineCore_DP0 pid=298316) .b8 57
(EngineCore_DP0 pid=298316) .b8 95
(EngineCore_DP0 pid=298316) .b8 97
(EngineCore_DP0 pid=298316) .b8 97
(EngineCore_DP0 pid=298316) .b8 114
(EngineCore_DP0 pid=298316) .b8 99
(EngineCore_DP0 pid=298316) .b8 104
(EngineCore_DP0 pid=298316) .b8 54
(EngineCore_DP0 pid=298316) .b8 52
(EngineCore_DP0 pid=298316) .b8 0
(EngineCore_DP0 pid=298316) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=298316) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=298316) .b8 113
(EngineCore_DP0 pid=298316) .b8 117
(EngineCore_DP0 pid=298316) .b8 97
(EngineCore_DP0 pid=298316) .b8 110
(EngineCore_DP0 pid=298316) .b8 116
(EngineCore_DP0 pid=298316) .b8 95
(EngineCore_DP0 pid=298316) .b8 115
(EngineCore_DP0 pid=298316) .b8 108
(EngineCore_DP0 pid=298316) .b8 105
(EngineCore_DP0 pid=298316) .b8 100
(EngineCore_DP0 pid=298316) .b8 101
(EngineCore_DP0 pid=298316) .b8 95
(EngineCore_DP0 pid=298316) .b8 102
(EngineCore_DP0 pid=298316) .b8 112
(EngineCore_DP0 pid=298316) .b8 56
(EngineCore_DP0 pid=298316) .b8 95
(EngineCore_DP0 pid=298316) .b8 107
(EngineCore_DP0 pid=298316) .b8 101
(EngineCore_DP0 pid=298316) .b8 114
(EngineCore_DP0 pid=298316) .b8 110
(EngineCore_DP0 pid=298316) .b8 101
(EngineCore_DP0 pid=298316) .b8 108
(EngineCore_DP0 pid=298316) .b8 0
(EngineCore_DP0 pid=298316) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=298316) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=298316) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=298316) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=298316) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=298316) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=298316) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=298316) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=298316) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=298316) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=298316) .b8 191                                 // DW_AT_call_line
(EngineCore_DP0 pid=298316) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=298316) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=298316) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=298316) 	}
(EngineCore_DP0 pid=298316) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=298316) 
(EngineCore_DP0 pid=298316) ================================================================
(EngineCore_DP0 pid=298316) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=298316) 
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpe4bzlvq6.ptx', '-o', '/tmp/tmpe4bzlvq6.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866] 
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866] 
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866] 
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpe4bzlvq6.ptx -o /tmp/tmpe4bzlvq6.ptx.o
(EngineCore_DP0 pid=298316) ERROR 01-25 18:46:35 [core.py:866] 

STDERR:
[2026-01-25 18:46:21] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 18:46:21] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 18:46:21] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 18:46:21] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:46:21] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:46:21] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:46:21] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:46:21] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:46:21] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 18:46:21] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 18:46:21] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 18:46:21] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 18:46:21] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 18:46:21] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 18:46:25] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 18:46:25] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 18:46:25] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 18:46:25] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:46:25] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:46:25] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:46:25] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:46:25] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:46:25] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 18:46:25] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 18:46:25] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 18:46:25] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 18:46:25] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 18:46:25] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=298316) [2026-01-25 18:46:26] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=298316) [2026-01-25 18:46:26] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=298316) [2026-01-25 18:46:26] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=298316) [2026-01-25 18:46:26] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=298316) [2026-01-25 18:46:26] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=298316) [2026-01-25 18:46:26] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=298316) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=298316) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.15s/it]
(EngineCore_DP0 pid=298316) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.15s/it]
(EngineCore_DP0 pid=298316) 
(EngineCore_DP0 pid=298316) [2026-01-25 18:46:34] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=298316) [2026-01-25 18:46:34] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=298316) [2026-01-25 18:46:34] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=298316) [2026-01-25 18:46:34] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 2621440 bytes
(EngineCore_DP0 pid=298316) [2026-01-25 18:46:34] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=298316) [2026-01-25 18:46:34] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 20971520 bytes
(EngineCore_DP0 pid=298316) [2026-01-25 18:46:34] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=298316) [2026-01-25 18:46:34] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10485760 bytes
(EngineCore_DP0 pid=298316) Process EngineCore_DP0:
(EngineCore_DP0 pid=298316) Traceback (most recent call last):
(EngineCore_DP0 pid=298316)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=298316)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=298316)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=298316)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=298316) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpe4bzlvq6.ptx', '-o', '/tmp/tmpe4bzlvq6.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=298316) 
(EngineCore_DP0 pid=298316) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=298316) 
(EngineCore_DP0 pid=298316) Traceback (most recent call last):
(EngineCore_DP0 pid=298316)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=298316)     self.run()
(EngineCore_DP0 pid=298316)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=298316)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=298316)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=298316)     raise e
(EngineCore_DP0 pid=298316)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=298316)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=298316)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=298316)     super().__init__(
(EngineCore_DP0 pid=298316)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=298316)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=298316)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=298316)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=298316)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=298316)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=298316)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=298316)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=298316)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=298316)     return func(*args, **kwargs)
(EngineCore_DP0 pid=298316)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=298316)     return func(*args, **kwargs)
(EngineCore_DP0 pid=298316)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=298316)     self.model_runner.profile_run()
(EngineCore_DP0 pid=298316)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=298316)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=298316)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=298316)     return func(*args, **kwargs)
(EngineCore_DP0 pid=298316)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=298316)     outputs = self.model(
(EngineCore_DP0 pid=298316)               ^^^^^^^^^^^
(EngineCore_DP0 pid=298316)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=298316)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=298316)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=298316)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=298316)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=298316)     model_output = self.model(
(EngineCore_DP0 pid=298316)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=298316)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=298316)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=298316)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=298316)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=298316)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=298316)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=298316)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=298316)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=298316)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=298316)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=298316)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=298316)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=298316)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=298316)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=298316)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=298316)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=298316)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=298316)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=298316)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=298316)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=298316)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=298316)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=298316)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=298316)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=298316)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=298316)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=298316)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=298316)     return self._linear_fn(
(EngineCore_DP0 pid=298316)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=298316)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=298316)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=298316)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=298316)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=298316)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=298316)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=298316)     return fn(input, L)
(EngineCore_DP0 pid=298316)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=298316)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=298316)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=298316)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=298316)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=298316)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=298316)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=298316)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=298316)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=298316)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=298316)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=298316)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=298316)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=298316)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298316)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=298316)     raise PTXASError(error)
(EngineCore_DP0 pid=298316) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=298316) `ptxas` stderr:
(EngineCore_DP0 pid=298316) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=298316) 
(EngineCore_DP0 pid=298316) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpe4bzlvq6.ptx -o /tmp/tmpe4bzlvq6.ptx.o
(EngineCore_DP0 pid=298316) 
[rank0]:[W125 18:46:35.077118775 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=128

========== M=256 ==========
Time: 2026-01-25 18:46:37
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4
Params: prompt_len=256, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4 --dataset-name random --input-len 256 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 257 --max-num-batched-tokens 257 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Llama3.2-1B-FP8_M256.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 18:46:41 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 18:46:41 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=298769) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=298769) 
(EngineCore_DP0 pid=298769) 
(EngineCore_DP0 pid=298769) ================================================================
(EngineCore_DP0 pid=298769) Internal Triton PTX codegen error
(EngineCore_DP0 pid=298769) `ptxas` stderr:
(EngineCore_DP0 pid=298769) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=298769) 
(EngineCore_DP0 pid=298769) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp3syqbto5.ptx -o /tmp/tmp3syqbto5.ptx.o
(EngineCore_DP0 pid=298769) 
(EngineCore_DP0 pid=298769) 
(EngineCore_DP0 pid=298769) //
(EngineCore_DP0 pid=298769) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=298769) //
(EngineCore_DP0 pid=298769) 
(EngineCore_DP0 pid=298769) .version 8.7
(EngineCore_DP0 pid=298769) .target sm_121a
(EngineCore_DP0 pid=298769) .address_size 64
(EngineCore_DP0 pid=298769) 
(EngineCore_DP0 pid=298769) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=298769) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=298769)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=298769) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=298769) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=298769) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=298769) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=298769) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=298769) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=298769) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=298769) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=298769) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=298769) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=298769) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=298769) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=298769) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=298769) )
(EngineCore_DP0 pid=298769) .reqntid 1024
(EngineCore_DP0 pid=298769) {
(EngineCore_DP0 pid=298769) 	.reg .pred 	%p<20>;
(EngineCore_DP0 pid=298769) 	.reg .b16 	%rs<25>;
(EngineCore_DP0 pid=298769) 	.reg .b32 	%r<108>;
(EngineCore_DP0 pid=298769) 	.reg .b64 	%rd<13>;
(EngineCore_DP0 pid=298769) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=298769) $L__func_begin0:
(EngineCore_DP0 pid=298769) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=298769) 
(EngineCore_DP0 pid=298769) // %bb.0:
(EngineCore_DP0 pid=298769) 	ld.param.b32 	%r20, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=298769) 	ld.param.b32 	%r19, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=298769) 	ld.param.b32 	%r18, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=298769) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=298769) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=298769) $L__tmp0:
(EngineCore_DP0 pid=298769) 	.loc	1 177 24                        // quant_slide_tuned_Llama3.2-1B.py:177:24
(EngineCore_DP0 pid=298769) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=298769) 	ld.param.b32 	%r22, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=298769) 	.loc	1 182 26                        // quant_slide_tuned_Llama3.2-1B.py:182:26
(EngineCore_DP0 pid=298769) 	mul.lo.s32 	%r23, %r22, %r1;
(EngineCore_DP0 pid=298769) 	.loc	1 182 20                        // quant_slide_tuned_Llama3.2-1B.py:182:20
(EngineCore_DP0 pid=298769) 	mad.wide.s32 	%rd1, %r23, 2, %rd4;
(EngineCore_DP0 pid=298769) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=298769) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=298769) 	shl.b32 	%r106, %r2, 2;
(EngineCore_DP0 pid=298769) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=298769) 	setp.lt.s32 	%p1, %r19, 1;
(EngineCore_DP0 pid=298769) 	mov.b32 	%r105, 0f2B8CBCCC;
(EngineCore_DP0 pid=298769) 	setp.eq.b32 	%p19, %r2, 0;
(EngineCore_DP0 pid=298769) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=298769) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=298769) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=298769) 	and.b32 	%r4, %r2, 31;
(EngineCore_DP0 pid=298769) 	shr.u32 	%r32, %r2, 3;
(EngineCore_DP0 pid=298769) 	and.b32 	%r33, %r32, 124;
(EngineCore_DP0 pid=298769) 	mov.b32 	%r34, global_smem;
(EngineCore_DP0 pid=298769) 	add.s32 	%r40, %r34, %r33;
(EngineCore_DP0 pid=298769) 	shl.b32 	%r35, %r2, 2;
(EngineCore_DP0 pid=298769) 	add.s32 	%r43, %r34, %r35;
(EngineCore_DP0 pid=298769) 	mov.b32 	%r38, 0;
(EngineCore_DP0 pid=298769) 	mov.b32 	%r103, 0f00000000;
(EngineCore_DP0 pid=298769) 	setp.lt.u32 	%p4, %r2, 32;
(EngineCore_DP0 pid=298769) 	setp.eq.b32 	%p3, %r4, 0;
(EngineCore_DP0 pid=298769) 	mov.b32 	%r104, %r38;
(EngineCore_DP0 pid=298769) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=298769) 	.loc	1 189 22                        // quant_slide_tuned_Llama3.2-1B.py:189:22
(EngineCore_DP0 pid=298769) 	add.s32 	%r46, %r106, %r104;
(EngineCore_DP0 pid=298769) 	setp.lt.s32 	%p2, %r46, %r18;
(EngineCore_DP0 pid=298769) 	.loc	1 190 29                        // quant_slide_tuned_Llama3.2-1B.py:190:29
(EngineCore_DP0 pid=298769) 	mad.wide.s32 	%rd6, %r46, 2, %rd1;
(EngineCore_DP0 pid=298769) 	.loc	1 190 21                        // quant_slide_tuned_Llama3.2-1B.py:190:21
(EngineCore_DP0 pid=298769) 	// begin inline asm
(EngineCore_DP0 pid=298769) 	mov.u32 %r36, %r38;
(EngineCore_DP0 pid=298769) 	mov.u32 %r37, %r38;
(EngineCore_DP0 pid=298769) 	@%p2 ld.global.v2.b32 { %r36, %r37 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=298769) 	// end inline asm
(EngineCore_DP0 pid=298769) 	mov.b32 	{%rs1, %rs2}, %r36;
(EngineCore_DP0 pid=298769) 	mov.b32 	{%rs3, %rs4}, %r37;
(EngineCore_DP0 pid=298769) 	.loc	1 191 50                        // quant_slide_tuned_Llama3.2-1B.py:191:50
(EngineCore_DP0 pid=298769) 	abs.bf16 	%rs5, %rs1;
(EngineCore_DP0 pid=298769) 	abs.bf16 	%rs6, %rs2;
(EngineCore_DP0 pid=298769) 	abs.bf16 	%rs7, %rs3;
(EngineCore_DP0 pid=298769) 	abs.bf16 	%rs8, %rs4;
(EngineCore_DP0 pid=298769) $L__tmp1:
(EngineCore_DP0 pid=298769) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=298769) 	bar.sync 	0;
(EngineCore_DP0 pid=298769) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=298769) 	max.bf16 	%rs9, %rs5, %rs6;
(EngineCore_DP0 pid=298769) 	max.bf16 	%rs10, %rs9, %rs7;
(EngineCore_DP0 pid=298769) 	max.bf16 	%rs11, %rs10, %rs8;
(EngineCore_DP0 pid=298769) 	cvt.f32.bf16 	%r47, %rs11;
(EngineCore_DP0 pid=298769) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=298769) 	shfl.sync.bfly.b32 	%r48, %r47, 16, 31, -1;
(EngineCore_DP0 pid=298769) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=298769) 	max.f32 	%r49, %r47, %r48;
(EngineCore_DP0 pid=298769) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=298769) 	shfl.sync.bfly.b32 	%r50, %r49, 8, 31, -1;
(EngineCore_DP0 pid=298769) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=298769) 	max.f32 	%r51, %r49, %r50;
(EngineCore_DP0 pid=298769) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=298769) 	shfl.sync.bfly.b32 	%r52, %r51, 4, 31, -1;
(EngineCore_DP0 pid=298769) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=298769) 	max.f32 	%r53, %r51, %r52;
(EngineCore_DP0 pid=298769) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=298769) 	shfl.sync.bfly.b32 	%r54, %r53, 2, 31, -1;
(EngineCore_DP0 pid=298769) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=298769) 	max.f32 	%r55, %r53, %r54;
(EngineCore_DP0 pid=298769) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=298769) 	shfl.sync.bfly.b32 	%r56, %r55, 1, 31, -1;
(EngineCore_DP0 pid=298769) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=298769) 	max.f32 	%r41, %r55, %r56;
(EngineCore_DP0 pid=298769) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=298769) 	// begin inline asm
(EngineCore_DP0 pid=298769) 	@%p3 st.shared.b32 [ %r40 + 0 ], %r41;
(EngineCore_DP0 pid=298769) 	// end inline asm
(EngineCore_DP0 pid=298769) 	bar.sync 	0;
(EngineCore_DP0 pid=298769) 	// begin inline asm
(EngineCore_DP0 pid=298769) 	@%p4 ld.shared.b32 %r42, [ %r43 + 0 ];
(EngineCore_DP0 pid=298769) 	// end inline asm
(EngineCore_DP0 pid=298769) 	shfl.sync.bfly.b32 	%r57, %r42, 16, 31, -1;
(EngineCore_DP0 pid=298769) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=298769) 	max.f32 	%r58, %r42, %r57;
(EngineCore_DP0 pid=298769) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=298769) 	shfl.sync.bfly.b32 	%r59, %r58, 8, 31, -1;
(EngineCore_DP0 pid=298769) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=298769) 	max.f32 	%r60, %r58, %r59;
(EngineCore_DP0 pid=298769) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=298769) 	shfl.sync.bfly.b32 	%r61, %r60, 4, 31, -1;
(EngineCore_DP0 pid=298769) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=298769) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=298769) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=298769) 	shfl.sync.bfly.b32 	%r63, %r62, 2, 31, -1;
(EngineCore_DP0 pid=298769) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=298769) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=298769) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=298769) 	shfl.sync.bfly.b32 	%r65, %r64, 1, 31, -1;
(EngineCore_DP0 pid=298769) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=298769) 	max.f32 	%r45, %r64, %r65;
(EngineCore_DP0 pid=298769) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=298769) 	// begin inline asm
(EngineCore_DP0 pid=298769) 	@%p19 st.shared.b32 [ %r43 + 0 ], %r45;
(EngineCore_DP0 pid=298769) 	// end inline asm
(EngineCore_DP0 pid=298769) 	bar.sync 	0;
(EngineCore_DP0 pid=298769) 	ld.shared.b32 	%r66, [global_smem];
(EngineCore_DP0 pid=298769) $L__tmp2:
(EngineCore_DP0 pid=298769) 	.loc	1 191 36                        // quant_slide_tuned_Llama3.2-1B.py:191:36
(EngineCore_DP0 pid=298769) 	max.f32 	%r103, %r103, %r66;
(EngineCore_DP0 pid=298769) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=298769) 	add.s32 	%r104, %r104, 4096;
(EngineCore_DP0 pid=298769) 	setp.lt.s32 	%p6, %r104, %r19;
(EngineCore_DP0 pid=298769) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=298769) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=298769) 	.loc	1 193 32                        // quant_slide_tuned_Llama3.2-1B.py:193:32
(EngineCore_DP0 pid=298769) 	max.f32 	%r105, %r103, 0f2B8CBCCC;
(EngineCore_DP0 pid=298769) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=298769) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=298769) 	mov.b32 	%r68, 0f43E00000;
(EngineCore_DP0 pid=298769) 	.loc	1 194 32                        // quant_slide_tuned_Llama3.2-1B.py:194:32
(EngineCore_DP0 pid=298769) 	div.full.f32 	%r69, %r105, %r68;
(EngineCore_DP0 pid=298769) 	.loc	1 194 41                        // quant_slide_tuned_Llama3.2-1B.py:194:41
(EngineCore_DP0 pid=298769) 	max.f32 	%r67, %r69, 0f36924925;
(EngineCore_DP0 pid=298769) 	.loc	1 196 25                        // quant_slide_tuned_Llama3.2-1B.py:196:25
(EngineCore_DP0 pid=298769) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=298769) 	.loc	1 196 30                        // quant_slide_tuned_Llama3.2-1B.py:196:30
(EngineCore_DP0 pid=298769) 	// begin inline asm
(EngineCore_DP0 pid=298769) 	@%p19 st.global.b32 [ %rd7 + 0 ], { %r67 };
(EngineCore_DP0 pid=298769) 	// end inline asm
(EngineCore_DP0 pid=298769) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=298769) 	setp.lt.s32 	%p8, %r20, 1;
(EngineCore_DP0 pid=298769) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=298769) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=298769) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=298769) 	ld.param.b32 	%r24, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=298769) 	shr.s32 	%r25, %r24, 31;
(EngineCore_DP0 pid=298769) 	shr.u32 	%r26, %r25, 30;
(EngineCore_DP0 pid=298769) 	add.s32 	%r27, %r24, %r26;
(EngineCore_DP0 pid=298769) 	shr.s32 	%r28, %r27, 2;
(EngineCore_DP0 pid=298769) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=298769) 	mul.lo.s32 	%r29, %r28, %r1;
(EngineCore_DP0 pid=298769) 	mad.wide.s32 	%rd2, %r29, 4, %rd5;
(EngineCore_DP0 pid=298769) 	div.full.f32 	%r13, %r68, %r105;
(EngineCore_DP0 pid=298769) 	mov.b32 	%r107, 0;
(EngineCore_DP0 pid=298769) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=298769)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=298769) 	.loc	1 203 30                        // quant_slide_tuned_Llama3.2-1B.py:203:30
(EngineCore_DP0 pid=298769) 	add.s32 	%r80, %r2, %r107;
(EngineCore_DP0 pid=298769) 	setp.lt.s32 	%p13, %r80, %r20;
(EngineCore_DP0 pid=298769) 	.loc	1 211 53                        // quant_slide_tuned_Llama3.2-1B.py:211:53
(EngineCore_DP0 pid=298769) 	setp.lt.s32 	%p14, %r106, %r18;
(EngineCore_DP0 pid=298769) 	.loc	1 211 37                        // quant_slide_tuned_Llama3.2-1B.py:211:37
(EngineCore_DP0 pid=298769) 	and.pred 	%p9, %p13, %p14;
(EngineCore_DP0 pid=298769) 	.loc	1 210 29                        // quant_slide_tuned_Llama3.2-1B.py:210:29
(EngineCore_DP0 pid=298769) 	mad.wide.s32 	%rd8, %r106, 2, %rd1;
(EngineCore_DP0 pid=298769) 	mov.b16 	%rs13, 0;
(EngineCore_DP0 pid=298769) 	.loc	1 210 21                        // quant_slide_tuned_Llama3.2-1B.py:210:21
(EngineCore_DP0 pid=298769) 	// begin inline asm
(EngineCore_DP0 pid=298769) 	mov.u16 %rs12, %rs13;
(EngineCore_DP0 pid=298769) 	@%p9 ld.global.b16 { %rs12 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=298769) 	// end inline asm
(EngineCore_DP0 pid=298769) 	.loc	1 211 79                        // quant_slide_tuned_Llama3.2-1B.py:211:79
(EngineCore_DP0 pid=298769) 	cvt.f32.bf16 	%r81, %rs12;
(EngineCore_DP0 pid=298769) 	.loc	1 213 53                        // quant_slide_tuned_Llama3.2-1B.py:213:53
(EngineCore_DP0 pid=298769) 	add.s32 	%r82, %r106, 1;
(EngineCore_DP0 pid=298769) 	setp.lt.s32 	%p15, %r82, %r18;
(EngineCore_DP0 pid=298769) 	.loc	1 213 37                        // quant_slide_tuned_Llama3.2-1B.py:213:37
(EngineCore_DP0 pid=298769) 	and.pred 	%p10, %p13, %p15;
(EngineCore_DP0 pid=298769) 	.loc	1 212 39                        // quant_slide_tuned_Llama3.2-1B.py:212:39
(EngineCore_DP0 pid=298769) 	add.s64 	%rd9, %rd8, 2;
(EngineCore_DP0 pid=298769) 	.loc	1 212 21                        // quant_slide_tuned_Llama3.2-1B.py:212:21
(EngineCore_DP0 pid=298769) 	// begin inline asm
(EngineCore_DP0 pid=298769) 	mov.u16 %rs14, %rs13;
(EngineCore_DP0 pid=298769) 	@%p10 ld.global.b16 { %rs14 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=298769) 	// end inline asm
(EngineCore_DP0 pid=298769) 	.loc	1 213 79                        // quant_slide_tuned_Llama3.2-1B.py:213:79
(EngineCore_DP0 pid=298769) 	cvt.f32.bf16 	%r83, %rs14;
(EngineCore_DP0 pid=298769) 	.loc	1 215 53                        // quant_slide_tuned_Llama3.2-1B.py:215:53
(EngineCore_DP0 pid=298769) 	add.s32 	%r84, %r106, 2;
(EngineCore_DP0 pid=298769) 	setp.lt.s32 	%p16, %r84, %r18;
(EngineCore_DP0 pid=298769) 	.loc	1 215 37                        // quant_slide_tuned_Llama3.2-1B.py:215:37
(EngineCore_DP0 pid=298769) 	and.pred 	%p11, %p13, %p16;
(EngineCore_DP0 pid=298769) 	.loc	1 214 39                        // quant_slide_tuned_Llama3.2-1B.py:214:39
(EngineCore_DP0 pid=298769) 	add.s64 	%rd10, %rd8, 4;
(EngineCore_DP0 pid=298769) 	.loc	1 214 21                        // quant_slide_tuned_Llama3.2-1B.py:214:21
(EngineCore_DP0 pid=298769) 	// begin inline asm
(EngineCore_DP0 pid=298769) 	mov.u16 %rs16, %rs13;
(EngineCore_DP0 pid=298769) 	@%p11 ld.global.b16 { %rs16 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=298769) 	// end inline asm
(EngineCore_DP0 pid=298769) 	.loc	1 215 79                        // quant_slide_tuned_Llama3.2-1B.py:215:79
(EngineCore_DP0 pid=298769) 	cvt.f32.bf16 	%r85, %rs16;
(EngineCore_DP0 pid=298769) 	.loc	1 217 53                        // quant_slide_tuned_Llama3.2-1B.py:217:53
(EngineCore_DP0 pid=298769) 	add.s32 	%r86, %r106, 3;
(EngineCore_DP0 pid=298769) 	setp.lt.s32 	%p17, %r86, %r18;
(EngineCore_DP0 pid=298769) 	.loc	1 217 37                        // quant_slide_tuned_Llama3.2-1B.py:217:37
(EngineCore_DP0 pid=298769) 	and.pred 	%p12, %p13, %p17;
(EngineCore_DP0 pid=298769) 	.loc	1 216 39                        // quant_slide_tuned_Llama3.2-1B.py:216:39
(EngineCore_DP0 pid=298769) 	add.s64 	%rd11, %rd8, 6;
(EngineCore_DP0 pid=298769) 	.loc	1 216 21                        // quant_slide_tuned_Llama3.2-1B.py:216:21
(EngineCore_DP0 pid=298769) 	// begin inline asm
(EngineCore_DP0 pid=298769) 	mov.u16 %rs18, %rs13;
(EngineCore_DP0 pid=298769) 	@%p12 ld.global.b16 { %rs18 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=298769) 	// end inline asm
(EngineCore_DP0 pid=298769) 	.loc	1 217 79                        // quant_slide_tuned_Llama3.2-1B.py:217:79
(EngineCore_DP0 pid=298769) 	cvt.f32.bf16 	%r87, %rs18;
(EngineCore_DP0 pid=298769) 	.loc	1 219 27                        // quant_slide_tuned_Llama3.2-1B.py:219:27
(EngineCore_DP0 pid=298769) 	mul.f32 	%r88, %r13, %r81;
(EngineCore_DP0 pid=298769) 	mov.b32 	%r89, 0f43E00000;
(EngineCore_DP0 pid=298769) 	.loc	1 219 48                        // quant_slide_tuned_Llama3.2-1B.py:219:48
(EngineCore_DP0 pid=298769) 	min.xorsign.abs.f32 	%r71, %r88, %r89;
(EngineCore_DP0 pid=298769) 	.loc	1 219 60                        // quant_slide_tuned_Llama3.2-1B.py:219:60
(EngineCore_DP0 pid=298769) 	// begin inline asm
(EngineCore_DP0 pid=298769) 	cvt.rn.satfinite.e4m3x2.f32  %rs20, %r72, %r71; 
(EngineCore_DP0 pid=298769) 
(EngineCore_DP0 pid=298769) 	// end inline asm
(EngineCore_DP0 pid=298769) 	.loc	1 220 27                        // quant_slide_tuned_Llama3.2-1B.py:220:27
(EngineCore_DP0 pid=298769) 	mul.f32 	%r90, %r13, %r83;
(EngineCore_DP0 pid=298769) 	.loc	1 220 48                        // quant_slide_tuned_Llama3.2-1B.py:220:48
(EngineCore_DP0 pid=298769) 	min.xorsign.abs.f32 	%r73, %r90, %r89;
(EngineCore_DP0 pid=298769) 	.loc	1 220 60                        // quant_slide_tuned_Llama3.2-1B.py:220:60
(EngineCore_DP0 pid=298769) 	// begin inline asm
(EngineCore_DP0 pid=298769) 	cvt.rn.satfinite.e4m3x2.f32  %rs21, %r74, %r73; 
(EngineCore_DP0 pid=298769) 
(EngineCore_DP0 pid=298769) 	// end inline asm
(EngineCore_DP0 pid=298769) 	.loc	1 221 27                        // quant_slide_tuned_Llama3.2-1B.py:221:27
(EngineCore_DP0 pid=298769) 	mul.f32 	%r91, %r13, %r85;
(EngineCore_DP0 pid=298769) 	.loc	1 221 48                        // quant_slide_tuned_Llama3.2-1B.py:221:48
(EngineCore_DP0 pid=298769) 	min.xorsign.abs.f32 	%r75, %r91, %r89;
(EngineCore_DP0 pid=298769) 	.loc	1 221 60                        // quant_slide_tuned_Llama3.2-1B.py:221:60
(EngineCore_DP0 pid=298769) 	// begin inline asm
(EngineCore_DP0 pid=298769) 	cvt.rn.satfinite.e4m3x2.f32  %rs22, %r76, %r75; 
(EngineCore_DP0 pid=298769) 
(EngineCore_DP0 pid=298769) 	// end inline asm
(EngineCore_DP0 pid=298769) 	.loc	1 222 27                        // quant_slide_tuned_Llama3.2-1B.py:222:27
(EngineCore_DP0 pid=298769) 	mul.f32 	%r92, %r13, %r87;
(EngineCore_DP0 pid=298769) 	.loc	1 222 48                        // quant_slide_tuned_Llama3.2-1B.py:222:48
(EngineCore_DP0 pid=298769) 	min.xorsign.abs.f32 	%r77, %r92, %r89;
(EngineCore_DP0 pid=298769) 	.loc	1 222 60                        // quant_slide_tuned_Llama3.2-1B.py:222:60
(EngineCore_DP0 pid=298769) 	// begin inline asm
(EngineCore_DP0 pid=298769) 	cvt.rn.satfinite.e4m3x2.f32  %rs23, %r78, %r77; 
(EngineCore_DP0 pid=298769) 
(EngineCore_DP0 pid=298769) 	// end inline asm
(EngineCore_DP0 pid=298769) 	.loc	1 224 45                        // quant_slide_tuned_Llama3.2-1B.py:224:45
(EngineCore_DP0 pid=298769) 	cvt.u32.u16 	%r93, %rs20;
(EngineCore_DP0 pid=298769) 	and.b32 	%r94, %r93, 255;
(EngineCore_DP0 pid=298769) 	.loc	1 226 45                        // quant_slide_tuned_Llama3.2-1B.py:226:45
(EngineCore_DP0 pid=298769) 	cvt.u32.u16 	%r95, %rs22;
(EngineCore_DP0 pid=298769) 	and.b32 	%r96, %r95, 255;
(EngineCore_DP0 pid=298769) 	.loc	1 227 45                        // quant_slide_tuned_Llama3.2-1B.py:227:45
(EngineCore_DP0 pid=298769) 	cvt.u32.u16 	%r97, %rs23;
(EngineCore_DP0 pid=298769) 	.loc	1 229 30                        // quant_slide_tuned_Llama3.2-1B.py:229:30
(EngineCore_DP0 pid=298769) 	and.b16 	%rs24, %rs21, 255;
(EngineCore_DP0 pid=298769) 	mul.wide.u16 	%r98, %rs24, 256;
(EngineCore_DP0 pid=298769) 	.loc	1 229 24                        // quant_slide_tuned_Llama3.2-1B.py:229:24
(EngineCore_DP0 pid=298769) 	or.b32 	%r99, %r98, %r94;
(EngineCore_DP0 pid=298769) 	.loc	1 229 42                        // quant_slide_tuned_Llama3.2-1B.py:229:42
(EngineCore_DP0 pid=298769) 	shl.b32 	%r100, %r96, 16;
(EngineCore_DP0 pid=298769) 	.loc	1 229 36                        // quant_slide_tuned_Llama3.2-1B.py:229:36
(EngineCore_DP0 pid=298769) 	or.b32 	%r101, %r99, %r100;
(EngineCore_DP0 pid=298769) 	.loc	1 229 55                        // quant_slide_tuned_Llama3.2-1B.py:229:55
(EngineCore_DP0 pid=298769) 	shl.b32 	%r102, %r97, 24;
(EngineCore_DP0 pid=298769) 	.loc	1 229 49                        // quant_slide_tuned_Llama3.2-1B.py:229:49
(EngineCore_DP0 pid=298769) 	or.b32 	%r79, %r101, %r102;
(EngineCore_DP0 pid=298769) 	.loc	1 230 29                        // quant_slide_tuned_Llama3.2-1B.py:230:29
(EngineCore_DP0 pid=298769) 	mad.wide.s32 	%rd12, %r80, 4, %rd2;
(EngineCore_DP0 pid=298769) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-1B.py:230:39
(EngineCore_DP0 pid=298769) 	// begin inline asm
(EngineCore_DP0 pid=298769) 	@%p13 st.global.b32 [ %rd12 + 0 ], { %r79 };
(EngineCore_DP0 pid=298769) 	// end inline asm
(EngineCore_DP0 pid=298769) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=298769) 	add.s32 	%r107, %r107, 1024;
(EngineCore_DP0 pid=298769) 	add.s32 	%r106, %r106, 4096;
(EngineCore_DP0 pid=298769) 	setp.lt.s32 	%p18, %r107, %r20;
(EngineCore_DP0 pid=298769) 	@%p18 bra 	$L__BB0_6;
(EngineCore_DP0 pid=298769) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=298769) 	.loc	1 201 4                         // quant_slide_tuned_Llama3.2-1B.py:201:4
(EngineCore_DP0 pid=298769) 	ret;
(EngineCore_DP0 pid=298769) $L__tmp3:
(EngineCore_DP0 pid=298769) $L__func_end0:
(EngineCore_DP0 pid=298769)                                         // -- End function
(EngineCore_DP0 pid=298769) }
(EngineCore_DP0 pid=298769) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=298769) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=298769) 	.section	.debug_abbrev
(EngineCore_DP0 pid=298769) 	{
(EngineCore_DP0 pid=298769) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=298769) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=298769) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=298769) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=298769) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=298769) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=298769) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=298769) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=298769) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=298769) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=298769) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=298769) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=298769) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=298769) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=298769) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=298769) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=298769) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=298769) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=298769) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=298769) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=298769) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=298769) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=298769) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=298769) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=298769) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=298769) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=298769) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=298769) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=298769) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=298769) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=298769) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=298769) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=298769) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=298769) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=298769) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=298769) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=298769) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=298769) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=298769) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=298769) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=298769) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=298769) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=298769) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=298769) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=298769) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=298769) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=298769) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=298769) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=298769) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=298769) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=298769) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=298769) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=298769) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=298769) 	}
(EngineCore_DP0 pid=298769) 	.section	.debug_info
(EngineCore_DP0 pid=298769) 	{
(EngineCore_DP0 pid=298769) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=298769) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=298769) .b8 0
(EngineCore_DP0 pid=298769) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=298769) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=298769) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=298769) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=298769) .b8 114
(EngineCore_DP0 pid=298769) .b8 105
(EngineCore_DP0 pid=298769) .b8 116
(EngineCore_DP0 pid=298769) .b8 111
(EngineCore_DP0 pid=298769) .b8 110
(EngineCore_DP0 pid=298769) .b8 0
(EngineCore_DP0 pid=298769) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=298769) .b8 0
(EngineCore_DP0 pid=298769) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=298769) .b8 117
(EngineCore_DP0 pid=298769) .b8 97
(EngineCore_DP0 pid=298769) .b8 110
(EngineCore_DP0 pid=298769) .b8 116
(EngineCore_DP0 pid=298769) .b8 95
(EngineCore_DP0 pid=298769) .b8 115
(EngineCore_DP0 pid=298769) .b8 108
(EngineCore_DP0 pid=298769) .b8 105
(EngineCore_DP0 pid=298769) .b8 100
(EngineCore_DP0 pid=298769) .b8 101
(EngineCore_DP0 pid=298769) .b8 95
(EngineCore_DP0 pid=298769) .b8 116
(EngineCore_DP0 pid=298769) .b8 117
(EngineCore_DP0 pid=298769) .b8 110
(EngineCore_DP0 pid=298769) .b8 101
(EngineCore_DP0 pid=298769) .b8 100
(EngineCore_DP0 pid=298769) .b8 95
(EngineCore_DP0 pid=298769) .b8 76
(EngineCore_DP0 pid=298769) .b8 108
(EngineCore_DP0 pid=298769) .b8 97
(EngineCore_DP0 pid=298769) .b8 109
(EngineCore_DP0 pid=298769) .b8 97
(EngineCore_DP0 pid=298769) .b8 51
(EngineCore_DP0 pid=298769) .b8 46
(EngineCore_DP0 pid=298769) .b8 50
(EngineCore_DP0 pid=298769) .b8 45
(EngineCore_DP0 pid=298769) .b8 49
(EngineCore_DP0 pid=298769) .b8 66
(EngineCore_DP0 pid=298769) .b8 46
(EngineCore_DP0 pid=298769) .b8 112
(EngineCore_DP0 pid=298769) .b8 121
(EngineCore_DP0 pid=298769) .b8 0
(EngineCore_DP0 pid=298769) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=298769) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=298769) .b8 114
(EngineCore_DP0 pid=298769) .b8 111
(EngineCore_DP0 pid=298769) .b8 111
(EngineCore_DP0 pid=298769) .b8 116
(EngineCore_DP0 pid=298769) .b8 47
(EngineCore_DP0 pid=298769) .b8 118
(EngineCore_DP0 pid=298769) .b8 108
(EngineCore_DP0 pid=298769) .b8 108
(EngineCore_DP0 pid=298769) .b8 109
(EngineCore_DP0 pid=298769) .b8 98
(EngineCore_DP0 pid=298769) .b8 101
(EngineCore_DP0 pid=298769) .b8 110
(EngineCore_DP0 pid=298769) .b8 99
(EngineCore_DP0 pid=298769) .b8 104
(EngineCore_DP0 pid=298769) .b8 47
(EngineCore_DP0 pid=298769) .b8 115
(EngineCore_DP0 pid=298769) .b8 108
(EngineCore_DP0 pid=298769) .b8 105
(EngineCore_DP0 pid=298769) .b8 100
(EngineCore_DP0 pid=298769) .b8 101
(EngineCore_DP0 pid=298769) .b8 115
(EngineCore_DP0 pid=298769) .b8 112
(EngineCore_DP0 pid=298769) .b8 97
(EngineCore_DP0 pid=298769) .b8 114
(EngineCore_DP0 pid=298769) .b8 115
(EngineCore_DP0 pid=298769) .b8 101
(EngineCore_DP0 pid=298769) .b8 47
(EngineCore_DP0 pid=298769) .b8 99
(EngineCore_DP0 pid=298769) .b8 115
(EngineCore_DP0 pid=298769) .b8 114
(EngineCore_DP0 pid=298769) .b8 99
(EngineCore_DP0 pid=298769) .b8 47
(EngineCore_DP0 pid=298769) .b8 102
(EngineCore_DP0 pid=298769) .b8 117
(EngineCore_DP0 pid=298769) .b8 115
(EngineCore_DP0 pid=298769) .b8 101
(EngineCore_DP0 pid=298769) .b8 100
(EngineCore_DP0 pid=298769) .b8 95
(EngineCore_DP0 pid=298769) .b8 113
(EngineCore_DP0 pid=298769) .b8 117
(EngineCore_DP0 pid=298769) .b8 97
(EngineCore_DP0 pid=298769) .b8 110
(EngineCore_DP0 pid=298769) .b8 116
(EngineCore_DP0 pid=298769) .b8 95
(EngineCore_DP0 pid=298769) .b8 115
(EngineCore_DP0 pid=298769) .b8 108
(EngineCore_DP0 pid=298769) .b8 105
(EngineCore_DP0 pid=298769) .b8 100
(EngineCore_DP0 pid=298769) .b8 101
(EngineCore_DP0 pid=298769) .b8 95
(EngineCore_DP0 pid=298769) .b8 116
(EngineCore_DP0 pid=298769) .b8 114
(EngineCore_DP0 pid=298769) .b8 105
(EngineCore_DP0 pid=298769) .b8 116
(EngineCore_DP0 pid=298769) .b8 111
(EngineCore_DP0 pid=298769) .b8 110
(EngineCore_DP0 pid=298769) .b8 47
(EngineCore_DP0 pid=298769) .b8 98
(EngineCore_DP0 pid=298769) .b8 117
(EngineCore_DP0 pid=298769) .b8 105
(EngineCore_DP0 pid=298769) .b8 108
(EngineCore_DP0 pid=298769) .b8 100
(EngineCore_DP0 pid=298769) .b8 47
(EngineCore_DP0 pid=298769) .b8 71
(EngineCore_DP0 pid=298769) .b8 66
(EngineCore_DP0 pid=298769) .b8 49
(EngineCore_DP0 pid=298769) .b8 48
(EngineCore_DP0 pid=298769) .b8 95
(EngineCore_DP0 pid=298769) .b8 99
(EngineCore_DP0 pid=298769) .b8 99
(EngineCore_DP0 pid=298769) .b8 49
(EngineCore_DP0 pid=298769) .b8 50
(EngineCore_DP0 pid=298769) .b8 49
(EngineCore_DP0 pid=298769) .b8 95
(EngineCore_DP0 pid=298769) .b8 112
(EngineCore_DP0 pid=298769) .b8 121
(EngineCore_DP0 pid=298769) .b8 51
(EngineCore_DP0 pid=298769) .b8 49
(EngineCore_DP0 pid=298769) .b8 50
(EngineCore_DP0 pid=298769) .b8 95
(EngineCore_DP0 pid=298769) .b8 99
(EngineCore_DP0 pid=298769) .b8 117
(EngineCore_DP0 pid=298769) .b8 49
(EngineCore_DP0 pid=298769) .b8 50
(EngineCore_DP0 pid=298769) .b8 57
(EngineCore_DP0 pid=298769) .b8 95
(EngineCore_DP0 pid=298769) .b8 97
(EngineCore_DP0 pid=298769) .b8 97
(EngineCore_DP0 pid=298769) .b8 114
(EngineCore_DP0 pid=298769) .b8 99
(EngineCore_DP0 pid=298769) .b8 104
(EngineCore_DP0 pid=298769) .b8 54
(EngineCore_DP0 pid=298769) .b8 52
(EngineCore_DP0 pid=298769) .b8 0
(EngineCore_DP0 pid=298769) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=298769) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=298769) .b8 113
(EngineCore_DP0 pid=298769) .b8 117
(EngineCore_DP0 pid=298769) .b8 97
(EngineCore_DP0 pid=298769) .b8 110
(EngineCore_DP0 pid=298769) .b8 116
(EngineCore_DP0 pid=298769) .b8 95
(EngineCore_DP0 pid=298769) .b8 115
(EngineCore_DP0 pid=298769) .b8 108
(EngineCore_DP0 pid=298769) .b8 105
(EngineCore_DP0 pid=298769) .b8 100
(EngineCore_DP0 pid=298769) .b8 101
(EngineCore_DP0 pid=298769) .b8 95
(EngineCore_DP0 pid=298769) .b8 102
(EngineCore_DP0 pid=298769) .b8 112
(EngineCore_DP0 pid=298769) .b8 56
(EngineCore_DP0 pid=298769) .b8 95
(EngineCore_DP0 pid=298769) .b8 107
(EngineCore_DP0 pid=298769) .b8 101
(EngineCore_DP0 pid=298769) .b8 114
(EngineCore_DP0 pid=298769) .b8 110
(EngineCore_DP0 pid=298769) .b8 101
(EngineCore_DP0 pid=298769) .b8 108
(EngineCore_DP0 pid=298769) .b8 0
(EngineCore_DP0 pid=298769) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=298769) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=298769) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=298769) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=298769) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=298769) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=298769) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=298769) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=298769) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=298769) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=298769) .b8 191                                 // DW_AT_call_line
(EngineCore_DP0 pid=298769) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=298769) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=298769) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=298769) 	}
(EngineCore_DP0 pid=298769) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=298769) 
(EngineCore_DP0 pid=298769) ================================================================
(EngineCore_DP0 pid=298769) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=298769) 
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp3syqbto5.ptx', '-o', '/tmp/tmp3syqbto5.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866] 
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866] 
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866] 
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp3syqbto5.ptx -o /tmp/tmp3syqbto5.ptx.o
(EngineCore_DP0 pid=298769) ERROR 01-25 18:46:54 [core.py:866] 

STDERR:
[2026-01-25 18:46:40] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 18:46:41] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 18:46:41] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 18:46:41] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:46:41] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:46:41] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:46:41] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:46:41] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:46:41] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 18:46:41] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 18:46:41] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 18:46:41] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 18:46:41] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 18:46:41] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 18:46:44] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 18:46:44] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 18:46:44] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 18:46:44] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:46:44] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:46:44] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:46:44] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:46:44] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:46:44] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 18:46:44] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 18:46:44] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 18:46:44] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 18:46:44] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 18:46:44] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=298769) [2026-01-25 18:46:45] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=298769) [2026-01-25 18:46:45] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=298769) [2026-01-25 18:46:45] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=298769) [2026-01-25 18:46:45] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=298769) [2026-01-25 18:46:45] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=298769) [2026-01-25 18:46:45] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=298769) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=298769) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.24s/it]
(EngineCore_DP0 pid=298769) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.24s/it]
(EngineCore_DP0 pid=298769) 
(EngineCore_DP0 pid=298769) [2026-01-25 18:46:54] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=298769) [2026-01-25 18:46:54] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=298769) [2026-01-25 18:46:54] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=298769) [2026-01-25 18:46:54] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 2621440 bytes
(EngineCore_DP0 pid=298769) [2026-01-25 18:46:54] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=298769) [2026-01-25 18:46:54] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 20971520 bytes
(EngineCore_DP0 pid=298769) [2026-01-25 18:46:54] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=298769) [2026-01-25 18:46:54] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10485760 bytes
(EngineCore_DP0 pid=298769) Process EngineCore_DP0:
(EngineCore_DP0 pid=298769) Traceback (most recent call last):
(EngineCore_DP0 pid=298769)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=298769)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=298769)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=298769)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=298769) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp3syqbto5.ptx', '-o', '/tmp/tmp3syqbto5.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=298769) 
(EngineCore_DP0 pid=298769) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=298769) 
(EngineCore_DP0 pid=298769) Traceback (most recent call last):
(EngineCore_DP0 pid=298769)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=298769)     self.run()
(EngineCore_DP0 pid=298769)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=298769)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=298769)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=298769)     raise e
(EngineCore_DP0 pid=298769)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=298769)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=298769)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=298769)     super().__init__(
(EngineCore_DP0 pid=298769)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=298769)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=298769)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=298769)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=298769)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=298769)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=298769)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=298769)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=298769)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=298769)     return func(*args, **kwargs)
(EngineCore_DP0 pid=298769)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=298769)     return func(*args, **kwargs)
(EngineCore_DP0 pid=298769)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=298769)     self.model_runner.profile_run()
(EngineCore_DP0 pid=298769)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=298769)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=298769)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=298769)     return func(*args, **kwargs)
(EngineCore_DP0 pid=298769)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=298769)     outputs = self.model(
(EngineCore_DP0 pid=298769)               ^^^^^^^^^^^
(EngineCore_DP0 pid=298769)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=298769)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=298769)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=298769)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=298769)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=298769)     model_output = self.model(
(EngineCore_DP0 pid=298769)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=298769)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=298769)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=298769)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=298769)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=298769)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=298769)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=298769)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=298769)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=298769)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=298769)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=298769)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=298769)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=298769)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=298769)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=298769)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=298769)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=298769)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=298769)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=298769)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=298769)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=298769)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=298769)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=298769)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=298769)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=298769)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=298769)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=298769)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=298769)     return self._linear_fn(
(EngineCore_DP0 pid=298769)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=298769)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=298769)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=298769)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=298769)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=298769)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=298769)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=298769)     return fn(input, L)
(EngineCore_DP0 pid=298769)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=298769)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=298769)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=298769)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=298769)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=298769)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=298769)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=298769)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=298769)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=298769)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=298769)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=298769)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=298769)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=298769)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=298769)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=298769)     raise PTXASError(error)
(EngineCore_DP0 pid=298769) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=298769) `ptxas` stderr:
(EngineCore_DP0 pid=298769) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=298769) 
(EngineCore_DP0 pid=298769) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp3syqbto5.ptx -o /tmp/tmp3syqbto5.ptx.o
(EngineCore_DP0 pid=298769) 
[rank0]:[W125 18:46:55.413411032 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=256

========== M=512 ==========
Time: 2026-01-25 19:13:11
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Llama3.2-1B-FP8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:13:14 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:13:14 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=333099) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=333099) 
(EngineCore_DP0 pid=333099) 
(EngineCore_DP0 pid=333099) ================================================================
(EngineCore_DP0 pid=333099) Internal Triton PTX codegen error
(EngineCore_DP0 pid=333099) `ptxas` stderr:
(EngineCore_DP0 pid=333099) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=333099) 
(EngineCore_DP0 pid=333099) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpp7grma7w.ptx -o /tmp/tmpp7grma7w.ptx.o
(EngineCore_DP0 pid=333099) 
(EngineCore_DP0 pid=333099) 
(EngineCore_DP0 pid=333099) //
(EngineCore_DP0 pid=333099) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=333099) //
(EngineCore_DP0 pid=333099) 
(EngineCore_DP0 pid=333099) .version 8.7
(EngineCore_DP0 pid=333099) .target sm_121a
(EngineCore_DP0 pid=333099) .address_size 64
(EngineCore_DP0 pid=333099) 
(EngineCore_DP0 pid=333099) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=333099) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=333099)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=333099) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=333099) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=333099) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=333099) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=333099) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=333099) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=333099) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=333099) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=333099) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=333099) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=333099) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=333099) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=333099) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=333099) )
(EngineCore_DP0 pid=333099) .reqntid 1024
(EngineCore_DP0 pid=333099) {
(EngineCore_DP0 pid=333099) 	.reg .pred 	%p<20>;
(EngineCore_DP0 pid=333099) 	.reg .b16 	%rs<25>;
(EngineCore_DP0 pid=333099) 	.reg .b32 	%r<108>;
(EngineCore_DP0 pid=333099) 	.reg .b64 	%rd<13>;
(EngineCore_DP0 pid=333099) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=333099) $L__func_begin0:
(EngineCore_DP0 pid=333099) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=333099) 
(EngineCore_DP0 pid=333099) // %bb.0:
(EngineCore_DP0 pid=333099) 	ld.param.b32 	%r20, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=333099) 	ld.param.b32 	%r19, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=333099) 	ld.param.b32 	%r18, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=333099) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=333099) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=333099) $L__tmp0:
(EngineCore_DP0 pid=333099) 	.loc	1 177 24                        // quant_slide_tuned_Llama3.2-1B.py:177:24
(EngineCore_DP0 pid=333099) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=333099) 	ld.param.b32 	%r22, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=333099) 	.loc	1 182 26                        // quant_slide_tuned_Llama3.2-1B.py:182:26
(EngineCore_DP0 pid=333099) 	mul.lo.s32 	%r23, %r22, %r1;
(EngineCore_DP0 pid=333099) 	.loc	1 182 20                        // quant_slide_tuned_Llama3.2-1B.py:182:20
(EngineCore_DP0 pid=333099) 	mad.wide.s32 	%rd1, %r23, 2, %rd4;
(EngineCore_DP0 pid=333099) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=333099) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=333099) 	shl.b32 	%r106, %r2, 2;
(EngineCore_DP0 pid=333099) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=333099) 	setp.lt.s32 	%p1, %r19, 1;
(EngineCore_DP0 pid=333099) 	mov.b32 	%r105, 0f2B8CBCCC;
(EngineCore_DP0 pid=333099) 	setp.eq.b32 	%p19, %r2, 0;
(EngineCore_DP0 pid=333099) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=333099) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=333099) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=333099) 	and.b32 	%r4, %r2, 31;
(EngineCore_DP0 pid=333099) 	shr.u32 	%r32, %r2, 3;
(EngineCore_DP0 pid=333099) 	and.b32 	%r33, %r32, 124;
(EngineCore_DP0 pid=333099) 	mov.b32 	%r34, global_smem;
(EngineCore_DP0 pid=333099) 	add.s32 	%r40, %r34, %r33;
(EngineCore_DP0 pid=333099) 	shl.b32 	%r35, %r2, 2;
(EngineCore_DP0 pid=333099) 	add.s32 	%r43, %r34, %r35;
(EngineCore_DP0 pid=333099) 	mov.b32 	%r38, 0;
(EngineCore_DP0 pid=333099) 	mov.b32 	%r103, 0f00000000;
(EngineCore_DP0 pid=333099) 	setp.lt.u32 	%p4, %r2, 32;
(EngineCore_DP0 pid=333099) 	setp.eq.b32 	%p3, %r4, 0;
(EngineCore_DP0 pid=333099) 	mov.b32 	%r104, %r38;
(EngineCore_DP0 pid=333099) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=333099) 	.loc	1 189 22                        // quant_slide_tuned_Llama3.2-1B.py:189:22
(EngineCore_DP0 pid=333099) 	add.s32 	%r46, %r106, %r104;
(EngineCore_DP0 pid=333099) 	setp.lt.s32 	%p2, %r46, %r18;
(EngineCore_DP0 pid=333099) 	.loc	1 190 29                        // quant_slide_tuned_Llama3.2-1B.py:190:29
(EngineCore_DP0 pid=333099) 	mad.wide.s32 	%rd6, %r46, 2, %rd1;
(EngineCore_DP0 pid=333099) 	.loc	1 190 21                        // quant_slide_tuned_Llama3.2-1B.py:190:21
(EngineCore_DP0 pid=333099) 	// begin inline asm
(EngineCore_DP0 pid=333099) 	mov.u32 %r36, %r38;
(EngineCore_DP0 pid=333099) 	mov.u32 %r37, %r38;
(EngineCore_DP0 pid=333099) 	@%p2 ld.global.v2.b32 { %r36, %r37 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=333099) 	// end inline asm
(EngineCore_DP0 pid=333099) 	mov.b32 	{%rs1, %rs2}, %r36;
(EngineCore_DP0 pid=333099) 	mov.b32 	{%rs3, %rs4}, %r37;
(EngineCore_DP0 pid=333099) 	.loc	1 191 50                        // quant_slide_tuned_Llama3.2-1B.py:191:50
(EngineCore_DP0 pid=333099) 	abs.bf16 	%rs5, %rs1;
(EngineCore_DP0 pid=333099) 	abs.bf16 	%rs6, %rs2;
(EngineCore_DP0 pid=333099) 	abs.bf16 	%rs7, %rs3;
(EngineCore_DP0 pid=333099) 	abs.bf16 	%rs8, %rs4;
(EngineCore_DP0 pid=333099) $L__tmp1:
(EngineCore_DP0 pid=333099) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=333099) 	bar.sync 	0;
(EngineCore_DP0 pid=333099) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=333099) 	max.bf16 	%rs9, %rs5, %rs6;
(EngineCore_DP0 pid=333099) 	max.bf16 	%rs10, %rs9, %rs7;
(EngineCore_DP0 pid=333099) 	max.bf16 	%rs11, %rs10, %rs8;
(EngineCore_DP0 pid=333099) 	cvt.f32.bf16 	%r47, %rs11;
(EngineCore_DP0 pid=333099) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=333099) 	shfl.sync.bfly.b32 	%r48, %r47, 16, 31, -1;
(EngineCore_DP0 pid=333099) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=333099) 	max.f32 	%r49, %r47, %r48;
(EngineCore_DP0 pid=333099) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=333099) 	shfl.sync.bfly.b32 	%r50, %r49, 8, 31, -1;
(EngineCore_DP0 pid=333099) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=333099) 	max.f32 	%r51, %r49, %r50;
(EngineCore_DP0 pid=333099) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=333099) 	shfl.sync.bfly.b32 	%r52, %r51, 4, 31, -1;
(EngineCore_DP0 pid=333099) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=333099) 	max.f32 	%r53, %r51, %r52;
(EngineCore_DP0 pid=333099) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=333099) 	shfl.sync.bfly.b32 	%r54, %r53, 2, 31, -1;
(EngineCore_DP0 pid=333099) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=333099) 	max.f32 	%r55, %r53, %r54;
(EngineCore_DP0 pid=333099) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=333099) 	shfl.sync.bfly.b32 	%r56, %r55, 1, 31, -1;
(EngineCore_DP0 pid=333099) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=333099) 	max.f32 	%r41, %r55, %r56;
(EngineCore_DP0 pid=333099) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=333099) 	// begin inline asm
(EngineCore_DP0 pid=333099) 	@%p3 st.shared.b32 [ %r40 + 0 ], %r41;
(EngineCore_DP0 pid=333099) 	// end inline asm
(EngineCore_DP0 pid=333099) 	bar.sync 	0;
(EngineCore_DP0 pid=333099) 	// begin inline asm
(EngineCore_DP0 pid=333099) 	@%p4 ld.shared.b32 %r42, [ %r43 + 0 ];
(EngineCore_DP0 pid=333099) 	// end inline asm
(EngineCore_DP0 pid=333099) 	shfl.sync.bfly.b32 	%r57, %r42, 16, 31, -1;
(EngineCore_DP0 pid=333099) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=333099) 	max.f32 	%r58, %r42, %r57;
(EngineCore_DP0 pid=333099) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=333099) 	shfl.sync.bfly.b32 	%r59, %r58, 8, 31, -1;
(EngineCore_DP0 pid=333099) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=333099) 	max.f32 	%r60, %r58, %r59;
(EngineCore_DP0 pid=333099) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=333099) 	shfl.sync.bfly.b32 	%r61, %r60, 4, 31, -1;
(EngineCore_DP0 pid=333099) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=333099) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=333099) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=333099) 	shfl.sync.bfly.b32 	%r63, %r62, 2, 31, -1;
(EngineCore_DP0 pid=333099) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=333099) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=333099) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=333099) 	shfl.sync.bfly.b32 	%r65, %r64, 1, 31, -1;
(EngineCore_DP0 pid=333099) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=333099) 	max.f32 	%r45, %r64, %r65;
(EngineCore_DP0 pid=333099) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=333099) 	// begin inline asm
(EngineCore_DP0 pid=333099) 	@%p19 st.shared.b32 [ %r43 + 0 ], %r45;
(EngineCore_DP0 pid=333099) 	// end inline asm
(EngineCore_DP0 pid=333099) 	bar.sync 	0;
(EngineCore_DP0 pid=333099) 	ld.shared.b32 	%r66, [global_smem];
(EngineCore_DP0 pid=333099) $L__tmp2:
(EngineCore_DP0 pid=333099) 	.loc	1 191 36                        // quant_slide_tuned_Llama3.2-1B.py:191:36
(EngineCore_DP0 pid=333099) 	max.f32 	%r103, %r103, %r66;
(EngineCore_DP0 pid=333099) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=333099) 	add.s32 	%r104, %r104, 4096;
(EngineCore_DP0 pid=333099) 	setp.lt.s32 	%p6, %r104, %r19;
(EngineCore_DP0 pid=333099) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=333099) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=333099) 	.loc	1 193 32                        // quant_slide_tuned_Llama3.2-1B.py:193:32
(EngineCore_DP0 pid=333099) 	max.f32 	%r105, %r103, 0f2B8CBCCC;
(EngineCore_DP0 pid=333099) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=333099) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=333099) 	mov.b32 	%r68, 0f43E00000;
(EngineCore_DP0 pid=333099) 	.loc	1 194 32                        // quant_slide_tuned_Llama3.2-1B.py:194:32
(EngineCore_DP0 pid=333099) 	div.full.f32 	%r69, %r105, %r68;
(EngineCore_DP0 pid=333099) 	.loc	1 194 41                        // quant_slide_tuned_Llama3.2-1B.py:194:41
(EngineCore_DP0 pid=333099) 	max.f32 	%r67, %r69, 0f36924925;
(EngineCore_DP0 pid=333099) 	.loc	1 196 25                        // quant_slide_tuned_Llama3.2-1B.py:196:25
(EngineCore_DP0 pid=333099) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=333099) 	.loc	1 196 30                        // quant_slide_tuned_Llama3.2-1B.py:196:30
(EngineCore_DP0 pid=333099) 	// begin inline asm
(EngineCore_DP0 pid=333099) 	@%p19 st.global.b32 [ %rd7 + 0 ], { %r67 };
(EngineCore_DP0 pid=333099) 	// end inline asm
(EngineCore_DP0 pid=333099) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=333099) 	setp.lt.s32 	%p8, %r20, 1;
(EngineCore_DP0 pid=333099) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=333099) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=333099) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=333099) 	ld.param.b32 	%r24, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=333099) 	shr.s32 	%r25, %r24, 31;
(EngineCore_DP0 pid=333099) 	shr.u32 	%r26, %r25, 30;
(EngineCore_DP0 pid=333099) 	add.s32 	%r27, %r24, %r26;
(EngineCore_DP0 pid=333099) 	shr.s32 	%r28, %r27, 2;
(EngineCore_DP0 pid=333099) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=333099) 	mul.lo.s32 	%r29, %r28, %r1;
(EngineCore_DP0 pid=333099) 	mad.wide.s32 	%rd2, %r29, 4, %rd5;
(EngineCore_DP0 pid=333099) 	div.full.f32 	%r13, %r68, %r105;
(EngineCore_DP0 pid=333099) 	mov.b32 	%r107, 0;
(EngineCore_DP0 pid=333099) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=333099)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=333099) 	.loc	1 203 30                        // quant_slide_tuned_Llama3.2-1B.py:203:30
(EngineCore_DP0 pid=333099) 	add.s32 	%r80, %r2, %r107;
(EngineCore_DP0 pid=333099) 	setp.lt.s32 	%p13, %r80, %r20;
(EngineCore_DP0 pid=333099) 	.loc	1 211 53                        // quant_slide_tuned_Llama3.2-1B.py:211:53
(EngineCore_DP0 pid=333099) 	setp.lt.s32 	%p14, %r106, %r18;
(EngineCore_DP0 pid=333099) 	.loc	1 211 37                        // quant_slide_tuned_Llama3.2-1B.py:211:37
(EngineCore_DP0 pid=333099) 	and.pred 	%p9, %p13, %p14;
(EngineCore_DP0 pid=333099) 	.loc	1 210 29                        // quant_slide_tuned_Llama3.2-1B.py:210:29
(EngineCore_DP0 pid=333099) 	mad.wide.s32 	%rd8, %r106, 2, %rd1;
(EngineCore_DP0 pid=333099) 	mov.b16 	%rs13, 0;
(EngineCore_DP0 pid=333099) 	.loc	1 210 21                        // quant_slide_tuned_Llama3.2-1B.py:210:21
(EngineCore_DP0 pid=333099) 	// begin inline asm
(EngineCore_DP0 pid=333099) 	mov.u16 %rs12, %rs13;
(EngineCore_DP0 pid=333099) 	@%p9 ld.global.b16 { %rs12 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=333099) 	// end inline asm
(EngineCore_DP0 pid=333099) 	.loc	1 211 79                        // quant_slide_tuned_Llama3.2-1B.py:211:79
(EngineCore_DP0 pid=333099) 	cvt.f32.bf16 	%r81, %rs12;
(EngineCore_DP0 pid=333099) 	.loc	1 213 53                        // quant_slide_tuned_Llama3.2-1B.py:213:53
(EngineCore_DP0 pid=333099) 	add.s32 	%r82, %r106, 1;
(EngineCore_DP0 pid=333099) 	setp.lt.s32 	%p15, %r82, %r18;
(EngineCore_DP0 pid=333099) 	.loc	1 213 37                        // quant_slide_tuned_Llama3.2-1B.py:213:37
(EngineCore_DP0 pid=333099) 	and.pred 	%p10, %p13, %p15;
(EngineCore_DP0 pid=333099) 	.loc	1 212 39                        // quant_slide_tuned_Llama3.2-1B.py:212:39
(EngineCore_DP0 pid=333099) 	add.s64 	%rd9, %rd8, 2;
(EngineCore_DP0 pid=333099) 	.loc	1 212 21                        // quant_slide_tuned_Llama3.2-1B.py:212:21
(EngineCore_DP0 pid=333099) 	// begin inline asm
(EngineCore_DP0 pid=333099) 	mov.u16 %rs14, %rs13;
(EngineCore_DP0 pid=333099) 	@%p10 ld.global.b16 { %rs14 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=333099) 	// end inline asm
(EngineCore_DP0 pid=333099) 	.loc	1 213 79                        // quant_slide_tuned_Llama3.2-1B.py:213:79
(EngineCore_DP0 pid=333099) 	cvt.f32.bf16 	%r83, %rs14;
(EngineCore_DP0 pid=333099) 	.loc	1 215 53                        // quant_slide_tuned_Llama3.2-1B.py:215:53
(EngineCore_DP0 pid=333099) 	add.s32 	%r84, %r106, 2;
(EngineCore_DP0 pid=333099) 	setp.lt.s32 	%p16, %r84, %r18;
(EngineCore_DP0 pid=333099) 	.loc	1 215 37                        // quant_slide_tuned_Llama3.2-1B.py:215:37
(EngineCore_DP0 pid=333099) 	and.pred 	%p11, %p13, %p16;
(EngineCore_DP0 pid=333099) 	.loc	1 214 39                        // quant_slide_tuned_Llama3.2-1B.py:214:39
(EngineCore_DP0 pid=333099) 	add.s64 	%rd10, %rd8, 4;
(EngineCore_DP0 pid=333099) 	.loc	1 214 21                        // quant_slide_tuned_Llama3.2-1B.py:214:21
(EngineCore_DP0 pid=333099) 	// begin inline asm
(EngineCore_DP0 pid=333099) 	mov.u16 %rs16, %rs13;
(EngineCore_DP0 pid=333099) 	@%p11 ld.global.b16 { %rs16 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=333099) 	// end inline asm
(EngineCore_DP0 pid=333099) 	.loc	1 215 79                        // quant_slide_tuned_Llama3.2-1B.py:215:79
(EngineCore_DP0 pid=333099) 	cvt.f32.bf16 	%r85, %rs16;
(EngineCore_DP0 pid=333099) 	.loc	1 217 53                        // quant_slide_tuned_Llama3.2-1B.py:217:53
(EngineCore_DP0 pid=333099) 	add.s32 	%r86, %r106, 3;
(EngineCore_DP0 pid=333099) 	setp.lt.s32 	%p17, %r86, %r18;
(EngineCore_DP0 pid=333099) 	.loc	1 217 37                        // quant_slide_tuned_Llama3.2-1B.py:217:37
(EngineCore_DP0 pid=333099) 	and.pred 	%p12, %p13, %p17;
(EngineCore_DP0 pid=333099) 	.loc	1 216 39                        // quant_slide_tuned_Llama3.2-1B.py:216:39
(EngineCore_DP0 pid=333099) 	add.s64 	%rd11, %rd8, 6;
(EngineCore_DP0 pid=333099) 	.loc	1 216 21                        // quant_slide_tuned_Llama3.2-1B.py:216:21
(EngineCore_DP0 pid=333099) 	// begin inline asm
(EngineCore_DP0 pid=333099) 	mov.u16 %rs18, %rs13;
(EngineCore_DP0 pid=333099) 	@%p12 ld.global.b16 { %rs18 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=333099) 	// end inline asm
(EngineCore_DP0 pid=333099) 	.loc	1 217 79                        // quant_slide_tuned_Llama3.2-1B.py:217:79
(EngineCore_DP0 pid=333099) 	cvt.f32.bf16 	%r87, %rs18;
(EngineCore_DP0 pid=333099) 	.loc	1 219 27                        // quant_slide_tuned_Llama3.2-1B.py:219:27
(EngineCore_DP0 pid=333099) 	mul.f32 	%r88, %r13, %r81;
(EngineCore_DP0 pid=333099) 	mov.b32 	%r89, 0f43E00000;
(EngineCore_DP0 pid=333099) 	.loc	1 219 48                        // quant_slide_tuned_Llama3.2-1B.py:219:48
(EngineCore_DP0 pid=333099) 	min.xorsign.abs.f32 	%r71, %r88, %r89;
(EngineCore_DP0 pid=333099) 	.loc	1 219 60                        // quant_slide_tuned_Llama3.2-1B.py:219:60
(EngineCore_DP0 pid=333099) 	// begin inline asm
(EngineCore_DP0 pid=333099) 	cvt.rn.satfinite.e4m3x2.f32  %rs20, %r72, %r71; 
(EngineCore_DP0 pid=333099) 
(EngineCore_DP0 pid=333099) 	// end inline asm
(EngineCore_DP0 pid=333099) 	.loc	1 220 27                        // quant_slide_tuned_Llama3.2-1B.py:220:27
(EngineCore_DP0 pid=333099) 	mul.f32 	%r90, %r13, %r83;
(EngineCore_DP0 pid=333099) 	.loc	1 220 48                        // quant_slide_tuned_Llama3.2-1B.py:220:48
(EngineCore_DP0 pid=333099) 	min.xorsign.abs.f32 	%r73, %r90, %r89;
(EngineCore_DP0 pid=333099) 	.loc	1 220 60                        // quant_slide_tuned_Llama3.2-1B.py:220:60
(EngineCore_DP0 pid=333099) 	// begin inline asm
(EngineCore_DP0 pid=333099) 	cvt.rn.satfinite.e4m3x2.f32  %rs21, %r74, %r73; 
(EngineCore_DP0 pid=333099) 
(EngineCore_DP0 pid=333099) 	// end inline asm
(EngineCore_DP0 pid=333099) 	.loc	1 221 27                        // quant_slide_tuned_Llama3.2-1B.py:221:27
(EngineCore_DP0 pid=333099) 	mul.f32 	%r91, %r13, %r85;
(EngineCore_DP0 pid=333099) 	.loc	1 221 48                        // quant_slide_tuned_Llama3.2-1B.py:221:48
(EngineCore_DP0 pid=333099) 	min.xorsign.abs.f32 	%r75, %r91, %r89;
(EngineCore_DP0 pid=333099) 	.loc	1 221 60                        // quant_slide_tuned_Llama3.2-1B.py:221:60
(EngineCore_DP0 pid=333099) 	// begin inline asm
(EngineCore_DP0 pid=333099) 	cvt.rn.satfinite.e4m3x2.f32  %rs22, %r76, %r75; 
(EngineCore_DP0 pid=333099) 
(EngineCore_DP0 pid=333099) 	// end inline asm
(EngineCore_DP0 pid=333099) 	.loc	1 222 27                        // quant_slide_tuned_Llama3.2-1B.py:222:27
(EngineCore_DP0 pid=333099) 	mul.f32 	%r92, %r13, %r87;
(EngineCore_DP0 pid=333099) 	.loc	1 222 48                        // quant_slide_tuned_Llama3.2-1B.py:222:48
(EngineCore_DP0 pid=333099) 	min.xorsign.abs.f32 	%r77, %r92, %r89;
(EngineCore_DP0 pid=333099) 	.loc	1 222 60                        // quant_slide_tuned_Llama3.2-1B.py:222:60
(EngineCore_DP0 pid=333099) 	// begin inline asm
(EngineCore_DP0 pid=333099) 	cvt.rn.satfinite.e4m3x2.f32  %rs23, %r78, %r77; 
(EngineCore_DP0 pid=333099) 
(EngineCore_DP0 pid=333099) 	// end inline asm
(EngineCore_DP0 pid=333099) 	.loc	1 224 45                        // quant_slide_tuned_Llama3.2-1B.py:224:45
(EngineCore_DP0 pid=333099) 	cvt.u32.u16 	%r93, %rs20;
(EngineCore_DP0 pid=333099) 	and.b32 	%r94, %r93, 255;
(EngineCore_DP0 pid=333099) 	.loc	1 226 45                        // quant_slide_tuned_Llama3.2-1B.py:226:45
(EngineCore_DP0 pid=333099) 	cvt.u32.u16 	%r95, %rs22;
(EngineCore_DP0 pid=333099) 	and.b32 	%r96, %r95, 255;
(EngineCore_DP0 pid=333099) 	.loc	1 227 45                        // quant_slide_tuned_Llama3.2-1B.py:227:45
(EngineCore_DP0 pid=333099) 	cvt.u32.u16 	%r97, %rs23;
(EngineCore_DP0 pid=333099) 	.loc	1 229 30                        // quant_slide_tuned_Llama3.2-1B.py:229:30
(EngineCore_DP0 pid=333099) 	and.b16 	%rs24, %rs21, 255;
(EngineCore_DP0 pid=333099) 	mul.wide.u16 	%r98, %rs24, 256;
(EngineCore_DP0 pid=333099) 	.loc	1 229 24                        // quant_slide_tuned_Llama3.2-1B.py:229:24
(EngineCore_DP0 pid=333099) 	or.b32 	%r99, %r98, %r94;
(EngineCore_DP0 pid=333099) 	.loc	1 229 42                        // quant_slide_tuned_Llama3.2-1B.py:229:42
(EngineCore_DP0 pid=333099) 	shl.b32 	%r100, %r96, 16;
(EngineCore_DP0 pid=333099) 	.loc	1 229 36                        // quant_slide_tuned_Llama3.2-1B.py:229:36
(EngineCore_DP0 pid=333099) 	or.b32 	%r101, %r99, %r100;
(EngineCore_DP0 pid=333099) 	.loc	1 229 55                        // quant_slide_tuned_Llama3.2-1B.py:229:55
(EngineCore_DP0 pid=333099) 	shl.b32 	%r102, %r97, 24;
(EngineCore_DP0 pid=333099) 	.loc	1 229 49                        // quant_slide_tuned_Llama3.2-1B.py:229:49
(EngineCore_DP0 pid=333099) 	or.b32 	%r79, %r101, %r102;
(EngineCore_DP0 pid=333099) 	.loc	1 230 29                        // quant_slide_tuned_Llama3.2-1B.py:230:29
(EngineCore_DP0 pid=333099) 	mad.wide.s32 	%rd12, %r80, 4, %rd2;
(EngineCore_DP0 pid=333099) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-1B.py:230:39
(EngineCore_DP0 pid=333099) 	// begin inline asm
(EngineCore_DP0 pid=333099) 	@%p13 st.global.b32 [ %rd12 + 0 ], { %r79 };
(EngineCore_DP0 pid=333099) 	// end inline asm
(EngineCore_DP0 pid=333099) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=333099) 	add.s32 	%r107, %r107, 1024;
(EngineCore_DP0 pid=333099) 	add.s32 	%r106, %r106, 4096;
(EngineCore_DP0 pid=333099) 	setp.lt.s32 	%p18, %r107, %r20;
(EngineCore_DP0 pid=333099) 	@%p18 bra 	$L__BB0_6;
(EngineCore_DP0 pid=333099) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=333099) 	.loc	1 201 4                         // quant_slide_tuned_Llama3.2-1B.py:201:4
(EngineCore_DP0 pid=333099) 	ret;
(EngineCore_DP0 pid=333099) $L__tmp3:
(EngineCore_DP0 pid=333099) $L__func_end0:
(EngineCore_DP0 pid=333099)                                         // -- End function
(EngineCore_DP0 pid=333099) }
(EngineCore_DP0 pid=333099) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=333099) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=333099) 	.section	.debug_abbrev
(EngineCore_DP0 pid=333099) 	{
(EngineCore_DP0 pid=333099) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=333099) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=333099) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=333099) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=333099) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=333099) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=333099) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=333099) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=333099) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=333099) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=333099) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=333099) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=333099) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=333099) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=333099) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=333099) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=333099) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=333099) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=333099) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=333099) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=333099) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=333099) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=333099) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=333099) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=333099) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=333099) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=333099) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=333099) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=333099) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=333099) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=333099) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=333099) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=333099) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=333099) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=333099) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=333099) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=333099) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=333099) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=333099) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=333099) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=333099) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=333099) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=333099) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=333099) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=333099) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=333099) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=333099) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=333099) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=333099) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=333099) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=333099) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=333099) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=333099) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=333099) 	}
(EngineCore_DP0 pid=333099) 	.section	.debug_info
(EngineCore_DP0 pid=333099) 	{
(EngineCore_DP0 pid=333099) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=333099) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=333099) .b8 0
(EngineCore_DP0 pid=333099) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=333099) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=333099) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=333099) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=333099) .b8 114
(EngineCore_DP0 pid=333099) .b8 105
(EngineCore_DP0 pid=333099) .b8 116
(EngineCore_DP0 pid=333099) .b8 111
(EngineCore_DP0 pid=333099) .b8 110
(EngineCore_DP0 pid=333099) .b8 0
(EngineCore_DP0 pid=333099) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=333099) .b8 0
(EngineCore_DP0 pid=333099) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=333099) .b8 117
(EngineCore_DP0 pid=333099) .b8 97
(EngineCore_DP0 pid=333099) .b8 110
(EngineCore_DP0 pid=333099) .b8 116
(EngineCore_DP0 pid=333099) .b8 95
(EngineCore_DP0 pid=333099) .b8 115
(EngineCore_DP0 pid=333099) .b8 108
(EngineCore_DP0 pid=333099) .b8 105
(EngineCore_DP0 pid=333099) .b8 100
(EngineCore_DP0 pid=333099) .b8 101
(EngineCore_DP0 pid=333099) .b8 95
(EngineCore_DP0 pid=333099) .b8 116
(EngineCore_DP0 pid=333099) .b8 117
(EngineCore_DP0 pid=333099) .b8 110
(EngineCore_DP0 pid=333099) .b8 101
(EngineCore_DP0 pid=333099) .b8 100
(EngineCore_DP0 pid=333099) .b8 95
(EngineCore_DP0 pid=333099) .b8 76
(EngineCore_DP0 pid=333099) .b8 108
(EngineCore_DP0 pid=333099) .b8 97
(EngineCore_DP0 pid=333099) .b8 109
(EngineCore_DP0 pid=333099) .b8 97
(EngineCore_DP0 pid=333099) .b8 51
(EngineCore_DP0 pid=333099) .b8 46
(EngineCore_DP0 pid=333099) .b8 50
(EngineCore_DP0 pid=333099) .b8 45
(EngineCore_DP0 pid=333099) .b8 49
(EngineCore_DP0 pid=333099) .b8 66
(EngineCore_DP0 pid=333099) .b8 46
(EngineCore_DP0 pid=333099) .b8 112
(EngineCore_DP0 pid=333099) .b8 121
(EngineCore_DP0 pid=333099) .b8 0
(EngineCore_DP0 pid=333099) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=333099) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=333099) .b8 114
(EngineCore_DP0 pid=333099) .b8 111
(EngineCore_DP0 pid=333099) .b8 111
(EngineCore_DP0 pid=333099) .b8 116
(EngineCore_DP0 pid=333099) .b8 47
(EngineCore_DP0 pid=333099) .b8 118
(EngineCore_DP0 pid=333099) .b8 108
(EngineCore_DP0 pid=333099) .b8 108
(EngineCore_DP0 pid=333099) .b8 109
(EngineCore_DP0 pid=333099) .b8 98
(EngineCore_DP0 pid=333099) .b8 101
(EngineCore_DP0 pid=333099) .b8 110
(EngineCore_DP0 pid=333099) .b8 99
(EngineCore_DP0 pid=333099) .b8 104
(EngineCore_DP0 pid=333099) .b8 47
(EngineCore_DP0 pid=333099) .b8 115
(EngineCore_DP0 pid=333099) .b8 108
(EngineCore_DP0 pid=333099) .b8 105
(EngineCore_DP0 pid=333099) .b8 100
(EngineCore_DP0 pid=333099) .b8 101
(EngineCore_DP0 pid=333099) .b8 115
(EngineCore_DP0 pid=333099) .b8 112
(EngineCore_DP0 pid=333099) .b8 97
(EngineCore_DP0 pid=333099) .b8 114
(EngineCore_DP0 pid=333099) .b8 115
(EngineCore_DP0 pid=333099) .b8 101
(EngineCore_DP0 pid=333099) .b8 47
(EngineCore_DP0 pid=333099) .b8 99
(EngineCore_DP0 pid=333099) .b8 115
(EngineCore_DP0 pid=333099) .b8 114
(EngineCore_DP0 pid=333099) .b8 99
(EngineCore_DP0 pid=333099) .b8 47
(EngineCore_DP0 pid=333099) .b8 102
(EngineCore_DP0 pid=333099) .b8 117
(EngineCore_DP0 pid=333099) .b8 115
(EngineCore_DP0 pid=333099) .b8 101
(EngineCore_DP0 pid=333099) .b8 100
(EngineCore_DP0 pid=333099) .b8 95
(EngineCore_DP0 pid=333099) .b8 113
(EngineCore_DP0 pid=333099) .b8 117
(EngineCore_DP0 pid=333099) .b8 97
(EngineCore_DP0 pid=333099) .b8 110
(EngineCore_DP0 pid=333099) .b8 116
(EngineCore_DP0 pid=333099) .b8 95
(EngineCore_DP0 pid=333099) .b8 115
(EngineCore_DP0 pid=333099) .b8 108
(EngineCore_DP0 pid=333099) .b8 105
(EngineCore_DP0 pid=333099) .b8 100
(EngineCore_DP0 pid=333099) .b8 101
(EngineCore_DP0 pid=333099) .b8 95
(EngineCore_DP0 pid=333099) .b8 116
(EngineCore_DP0 pid=333099) .b8 114
(EngineCore_DP0 pid=333099) .b8 105
(EngineCore_DP0 pid=333099) .b8 116
(EngineCore_DP0 pid=333099) .b8 111
(EngineCore_DP0 pid=333099) .b8 110
(EngineCore_DP0 pid=333099) .b8 47
(EngineCore_DP0 pid=333099) .b8 98
(EngineCore_DP0 pid=333099) .b8 117
(EngineCore_DP0 pid=333099) .b8 105
(EngineCore_DP0 pid=333099) .b8 108
(EngineCore_DP0 pid=333099) .b8 100
(EngineCore_DP0 pid=333099) .b8 47
(EngineCore_DP0 pid=333099) .b8 71
(EngineCore_DP0 pid=333099) .b8 66
(EngineCore_DP0 pid=333099) .b8 49
(EngineCore_DP0 pid=333099) .b8 48
(EngineCore_DP0 pid=333099) .b8 95
(EngineCore_DP0 pid=333099) .b8 99
(EngineCore_DP0 pid=333099) .b8 99
(EngineCore_DP0 pid=333099) .b8 49
(EngineCore_DP0 pid=333099) .b8 50
(EngineCore_DP0 pid=333099) .b8 49
(EngineCore_DP0 pid=333099) .b8 95
(EngineCore_DP0 pid=333099) .b8 112
(EngineCore_DP0 pid=333099) .b8 121
(EngineCore_DP0 pid=333099) .b8 51
(EngineCore_DP0 pid=333099) .b8 49
(EngineCore_DP0 pid=333099) .b8 50
(EngineCore_DP0 pid=333099) .b8 95
(EngineCore_DP0 pid=333099) .b8 99
(EngineCore_DP0 pid=333099) .b8 117
(EngineCore_DP0 pid=333099) .b8 49
(EngineCore_DP0 pid=333099) .b8 50
(EngineCore_DP0 pid=333099) .b8 57
(EngineCore_DP0 pid=333099) .b8 95
(EngineCore_DP0 pid=333099) .b8 97
(EngineCore_DP0 pid=333099) .b8 97
(EngineCore_DP0 pid=333099) .b8 114
(EngineCore_DP0 pid=333099) .b8 99
(EngineCore_DP0 pid=333099) .b8 104
(EngineCore_DP0 pid=333099) .b8 54
(EngineCore_DP0 pid=333099) .b8 52
(EngineCore_DP0 pid=333099) .b8 0
(EngineCore_DP0 pid=333099) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=333099) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=333099) .b8 113
(EngineCore_DP0 pid=333099) .b8 117
(EngineCore_DP0 pid=333099) .b8 97
(EngineCore_DP0 pid=333099) .b8 110
(EngineCore_DP0 pid=333099) .b8 116
(EngineCore_DP0 pid=333099) .b8 95
(EngineCore_DP0 pid=333099) .b8 115
(EngineCore_DP0 pid=333099) .b8 108
(EngineCore_DP0 pid=333099) .b8 105
(EngineCore_DP0 pid=333099) .b8 100
(EngineCore_DP0 pid=333099) .b8 101
(EngineCore_DP0 pid=333099) .b8 95
(EngineCore_DP0 pid=333099) .b8 102
(EngineCore_DP0 pid=333099) .b8 112
(EngineCore_DP0 pid=333099) .b8 56
(EngineCore_DP0 pid=333099) .b8 95
(EngineCore_DP0 pid=333099) .b8 107
(EngineCore_DP0 pid=333099) .b8 101
(EngineCore_DP0 pid=333099) .b8 114
(EngineCore_DP0 pid=333099) .b8 110
(EngineCore_DP0 pid=333099) .b8 101
(EngineCore_DP0 pid=333099) .b8 108
(EngineCore_DP0 pid=333099) .b8 0
(EngineCore_DP0 pid=333099) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=333099) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=333099) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=333099) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=333099) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=333099) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=333099) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=333099) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=333099) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=333099) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=333099) .b8 191                                 // DW_AT_call_line
(EngineCore_DP0 pid=333099) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=333099) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=333099) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=333099) 	}
(EngineCore_DP0 pid=333099) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=333099) 
(EngineCore_DP0 pid=333099) ================================================================
(EngineCore_DP0 pid=333099) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=333099) 
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpp7grma7w.ptx', '-o', '/tmp/tmpp7grma7w.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866] 
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866] 
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866] 
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpp7grma7w.ptx -o /tmp/tmpp7grma7w.ptx.o
(EngineCore_DP0 pid=333099) ERROR 01-25 19:13:28 [core.py:866] 

STDERR:
[2026-01-25 19:13:14] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:13:14] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:13:14] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:13:14] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:13:14] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:13:14] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:13:14] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:13:14] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:13:14] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:13:14] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:13:14] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:13:14] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:13:14] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:13:14] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:13:18] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:13:18] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:13:18] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:13:18] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:13:18] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:13:18] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:13:18] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:13:18] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:13:18] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:13:18] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:13:18] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:13:18] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:13:18] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:13:18] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=333099) [2026-01-25 19:13:19] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=333099) [2026-01-25 19:13:19] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=333099) [2026-01-25 19:13:19] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=333099) [2026-01-25 19:13:19] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=333099) [2026-01-25 19:13:19] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=333099) [2026-01-25 19:13:19] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=333099) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=333099) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.27s/it]
(EngineCore_DP0 pid=333099) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.27s/it]
(EngineCore_DP0 pid=333099) 
(EngineCore_DP0 pid=333099) [2026-01-25 19:13:28] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=333099) [2026-01-25 19:13:28] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=333099) [2026-01-25 19:13:28] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=333099) [2026-01-25 19:13:28] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 2621440 bytes
(EngineCore_DP0 pid=333099) [2026-01-25 19:13:28] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=333099) [2026-01-25 19:13:28] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 20971520 bytes
(EngineCore_DP0 pid=333099) [2026-01-25 19:13:28] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=333099) [2026-01-25 19:13:28] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10485760 bytes
(EngineCore_DP0 pid=333099) Process EngineCore_DP0:
(EngineCore_DP0 pid=333099) Traceback (most recent call last):
(EngineCore_DP0 pid=333099)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=333099)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=333099)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=333099)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=333099) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpp7grma7w.ptx', '-o', '/tmp/tmpp7grma7w.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=333099) 
(EngineCore_DP0 pid=333099) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=333099) 
(EngineCore_DP0 pid=333099) Traceback (most recent call last):
(EngineCore_DP0 pid=333099)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=333099)     self.run()
(EngineCore_DP0 pid=333099)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=333099)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=333099)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=333099)     raise e
(EngineCore_DP0 pid=333099)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=333099)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=333099)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=333099)     super().__init__(
(EngineCore_DP0 pid=333099)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=333099)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=333099)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=333099)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=333099)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=333099)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=333099)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=333099)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=333099)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=333099)     return func(*args, **kwargs)
(EngineCore_DP0 pid=333099)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=333099)     return func(*args, **kwargs)
(EngineCore_DP0 pid=333099)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=333099)     self.model_runner.profile_run()
(EngineCore_DP0 pid=333099)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=333099)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=333099)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=333099)     return func(*args, **kwargs)
(EngineCore_DP0 pid=333099)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=333099)     outputs = self.model(
(EngineCore_DP0 pid=333099)               ^^^^^^^^^^^
(EngineCore_DP0 pid=333099)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=333099)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=333099)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=333099)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=333099)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=333099)     model_output = self.model(
(EngineCore_DP0 pid=333099)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=333099)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=333099)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=333099)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=333099)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=333099)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=333099)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=333099)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=333099)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=333099)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=333099)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=333099)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=333099)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=333099)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=333099)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=333099)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=333099)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=333099)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=333099)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=333099)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=333099)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=333099)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=333099)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=333099)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=333099)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=333099)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=333099)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=333099)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=333099)     return self._linear_fn(
(EngineCore_DP0 pid=333099)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=333099)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=333099)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=333099)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=333099)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=333099)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=333099)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=333099)     return fn(input, L)
(EngineCore_DP0 pid=333099)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=333099)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=333099)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=333099)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=333099)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=333099)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=333099)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=333099)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=333099)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=333099)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=333099)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=333099)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=333099)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=333099)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333099)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=333099)     raise PTXASError(error)
(EngineCore_DP0 pid=333099) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=333099) `ptxas` stderr:
(EngineCore_DP0 pid=333099) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=333099) 
(EngineCore_DP0 pid=333099) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpp7grma7w.ptx -o /tmp/tmpp7grma7w.ptx.o
(EngineCore_DP0 pid=333099) 
[rank0]:[W125 19:13:29.322295257 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=512

========== M=1024 ==========
Time: 2026-01-25 19:13:30
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Llama3.2-1B-FP8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:13:34 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:13:34 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=333562) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=333562) 
(EngineCore_DP0 pid=333562) 
(EngineCore_DP0 pid=333562) ================================================================
(EngineCore_DP0 pid=333562) Internal Triton PTX codegen error
(EngineCore_DP0 pid=333562) `ptxas` stderr:
(EngineCore_DP0 pid=333562) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=333562) 
(EngineCore_DP0 pid=333562) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpvd8a6g7h.ptx -o /tmp/tmpvd8a6g7h.ptx.o
(EngineCore_DP0 pid=333562) 
(EngineCore_DP0 pid=333562) 
(EngineCore_DP0 pid=333562) //
(EngineCore_DP0 pid=333562) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=333562) //
(EngineCore_DP0 pid=333562) 
(EngineCore_DP0 pid=333562) .version 8.7
(EngineCore_DP0 pid=333562) .target sm_121a
(EngineCore_DP0 pid=333562) .address_size 64
(EngineCore_DP0 pid=333562) 
(EngineCore_DP0 pid=333562) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=333562) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=333562)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=333562) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=333562) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=333562) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=333562) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=333562) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=333562) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=333562) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=333562) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=333562) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=333562) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=333562) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=333562) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=333562) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=333562) )
(EngineCore_DP0 pid=333562) .reqntid 512
(EngineCore_DP0 pid=333562) {
(EngineCore_DP0 pid=333562) 	.reg .pred 	%p<21>;
(EngineCore_DP0 pid=333562) 	.reg .b16 	%rs<61>;
(EngineCore_DP0 pid=333562) 	.reg .b32 	%r<121>;
(EngineCore_DP0 pid=333562) 	.reg .b64 	%rd<14>;
(EngineCore_DP0 pid=333562) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=333562) $L__func_begin0:
(EngineCore_DP0 pid=333562) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=333562) 
(EngineCore_DP0 pid=333562) // %bb.0:
(EngineCore_DP0 pid=333562) 	ld.param.b32 	%r22, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=333562) 	ld.param.b32 	%r21, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=333562) 	ld.param.b32 	%r20, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=333562) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=333562) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=333562) $L__tmp0:
(EngineCore_DP0 pid=333562) 	.loc	1 177 24                        // quant_slide_tuned_Llama3.2-1B.py:177:24
(EngineCore_DP0 pid=333562) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=333562) 	ld.param.b32 	%r24, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=333562) 	.loc	1 182 26                        // quant_slide_tuned_Llama3.2-1B.py:182:26
(EngineCore_DP0 pid=333562) 	mul.lo.s32 	%r25, %r24, %r1;
(EngineCore_DP0 pid=333562) 	.loc	1 182 20                        // quant_slide_tuned_Llama3.2-1B.py:182:20
(EngineCore_DP0 pid=333562) 	mad.wide.s32 	%rd1, %r25, 2, %rd4;
(EngineCore_DP0 pid=333562) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=333562) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=333562) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=333562) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=333562) 	setp.lt.s32 	%p1, %r21, 1;
(EngineCore_DP0 pid=333562) 	mov.b32 	%r118, 0f2B8CBCCC;
(EngineCore_DP0 pid=333562) 	setp.eq.b32 	%p20, %r2, 0;
(EngineCore_DP0 pid=333562) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=333562) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=333562) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=333562) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=333562) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=333562) 	shr.u32 	%r34, %r2, 3;
(EngineCore_DP0 pid=333562) 	and.b32 	%r35, %r34, 60;
(EngineCore_DP0 pid=333562) 	mov.b32 	%r36, global_smem;
(EngineCore_DP0 pid=333562) 	add.s32 	%r54, %r36, %r35;
(EngineCore_DP0 pid=333562) 	shl.b32 	%r37, %r2, 2;
(EngineCore_DP0 pid=333562) 	add.s32 	%r57, %r36, %r37;
(EngineCore_DP0 pid=333562) 	mov.b32 	%r42, 0;
(EngineCore_DP0 pid=333562) 	mov.b32 	%r116, 0f00000000;
(EngineCore_DP0 pid=333562) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=333562) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=333562) 	mov.b32 	%r117, %r42;
(EngineCore_DP0 pid=333562) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=333562) 	.loc	1 188 19                        // quant_slide_tuned_Llama3.2-1B.py:188:19
(EngineCore_DP0 pid=333562) 	add.s32 	%r60, %r4, %r117;
(EngineCore_DP0 pid=333562) 	.loc	1 189 22                        // quant_slide_tuned_Llama3.2-1B.py:189:22
(EngineCore_DP0 pid=333562) 	add.s32 	%r61, %r60, 4096;
(EngineCore_DP0 pid=333562) 	setp.lt.s32 	%p2, %r60, %r20;
(EngineCore_DP0 pid=333562) 	setp.lt.s32 	%p3, %r61, %r20;
(EngineCore_DP0 pid=333562) 	.loc	1 190 29                        // quant_slide_tuned_Llama3.2-1B.py:190:29
(EngineCore_DP0 pid=333562) 	mad.wide.s32 	%rd6, %r60, 2, %rd1;
(EngineCore_DP0 pid=333562) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=333562) 	.loc	1 190 21                        // quant_slide_tuned_Llama3.2-1B.py:190:21
(EngineCore_DP0 pid=333562) 	// begin inline asm
(EngineCore_DP0 pid=333562) 	mov.u32 %r38, %r42;
(EngineCore_DP0 pid=333562) 	mov.u32 %r39, %r42;
(EngineCore_DP0 pid=333562) 	mov.u32 %r40, %r42;
(EngineCore_DP0 pid=333562) 	mov.u32 %r41, %r42;
(EngineCore_DP0 pid=333562) 	@%p2 ld.global.v4.b32 { %r38, %r39, %r40, %r41 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=333562) 	// end inline asm
(EngineCore_DP0 pid=333562) 	mov.b32 	{%rs1, %rs2}, %r38;
(EngineCore_DP0 pid=333562) 	mov.b32 	{%rs3, %rs4}, %r39;
(EngineCore_DP0 pid=333562) 	mov.b32 	{%rs5, %rs6}, %r40;
(EngineCore_DP0 pid=333562) 	mov.b32 	{%rs7, %rs8}, %r41;
(EngineCore_DP0 pid=333562) 	// begin inline asm
(EngineCore_DP0 pid=333562) 	mov.u32 %r46, %r42;
(EngineCore_DP0 pid=333562) 	mov.u32 %r47, %r42;
(EngineCore_DP0 pid=333562) 	mov.u32 %r48, %r42;
(EngineCore_DP0 pid=333562) 	mov.u32 %r49, %r42;
(EngineCore_DP0 pid=333562) 	@%p3 ld.global.v4.b32 { %r46, %r47, %r48, %r49 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=333562) 	// end inline asm
(EngineCore_DP0 pid=333562) 	mov.b32 	{%rs9, %rs10}, %r46;
(EngineCore_DP0 pid=333562) 	mov.b32 	{%rs11, %rs12}, %r47;
(EngineCore_DP0 pid=333562) 	mov.b32 	{%rs13, %rs14}, %r48;
(EngineCore_DP0 pid=333562) 	mov.b32 	{%rs15, %rs16}, %r49;
(EngineCore_DP0 pid=333562) 	.loc	1 191 50                        // quant_slide_tuned_Llama3.2-1B.py:191:50
(EngineCore_DP0 pid=333562) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=333562) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=333562) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=333562) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=333562) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=333562) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=333562) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=333562) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=333562) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=333562) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=333562) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=333562) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=333562) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=333562) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=333562) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=333562) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=333562) $L__tmp1:
(EngineCore_DP0 pid=333562) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=333562) 	bar.sync 	0;
(EngineCore_DP0 pid=333562) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=333562) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=333562) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=333562) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=333562) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=333562) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=333562) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=333562) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=333562) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=333562) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=333562) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=333562) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=333562) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=333562) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=333562) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=333562) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=333562) 	cvt.f32.bf16 	%r62, %rs47;
(EngineCore_DP0 pid=333562) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=333562) 	shfl.sync.bfly.b32 	%r63, %r62, 16, 31, -1;
(EngineCore_DP0 pid=333562) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=333562) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=333562) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=333562) 	shfl.sync.bfly.b32 	%r65, %r64, 8, 31, -1;
(EngineCore_DP0 pid=333562) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=333562) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=333562) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=333562) 	shfl.sync.bfly.b32 	%r67, %r66, 4, 31, -1;
(EngineCore_DP0 pid=333562) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=333562) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=333562) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=333562) 	shfl.sync.bfly.b32 	%r69, %r68, 2, 31, -1;
(EngineCore_DP0 pid=333562) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=333562) 	max.f32 	%r70, %r68, %r69;
(EngineCore_DP0 pid=333562) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=333562) 	shfl.sync.bfly.b32 	%r71, %r70, 1, 31, -1;
(EngineCore_DP0 pid=333562) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=333562) 	max.f32 	%r55, %r70, %r71;
(EngineCore_DP0 pid=333562) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=333562) 	// begin inline asm
(EngineCore_DP0 pid=333562) 	@%p4 st.shared.b32 [ %r54 + 0 ], %r55;
(EngineCore_DP0 pid=333562) 	// end inline asm
(EngineCore_DP0 pid=333562) 	bar.sync 	0;
(EngineCore_DP0 pid=333562) 	// begin inline asm
(EngineCore_DP0 pid=333562) 	@%p5 ld.shared.b32 %r56, [ %r57 + 0 ];
(EngineCore_DP0 pid=333562) 	// end inline asm
(EngineCore_DP0 pid=333562) 	shfl.sync.bfly.b32 	%r72, %r56, 8, 31, -1;
(EngineCore_DP0 pid=333562) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=333562) 	max.f32 	%r73, %r56, %r72;
(EngineCore_DP0 pid=333562) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=333562) 	shfl.sync.bfly.b32 	%r74, %r73, 4, 31, -1;
(EngineCore_DP0 pid=333562) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=333562) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=333562) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=333562) 	shfl.sync.bfly.b32 	%r76, %r75, 2, 31, -1;
(EngineCore_DP0 pid=333562) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=333562) 	max.f32 	%r77, %r75, %r76;
(EngineCore_DP0 pid=333562) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=333562) 	shfl.sync.bfly.b32 	%r78, %r77, 1, 31, -1;
(EngineCore_DP0 pid=333562) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=333562) 	max.f32 	%r59, %r77, %r78;
(EngineCore_DP0 pid=333562) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=333562) 	// begin inline asm
(EngineCore_DP0 pid=333562) 	@%p20 st.shared.b32 [ %r57 + 0 ], %r59;
(EngineCore_DP0 pid=333562) 	// end inline asm
(EngineCore_DP0 pid=333562) 	bar.sync 	0;
(EngineCore_DP0 pid=333562) 	ld.shared.b32 	%r79, [global_smem];
(EngineCore_DP0 pid=333562) $L__tmp2:
(EngineCore_DP0 pid=333562) 	.loc	1 191 36                        // quant_slide_tuned_Llama3.2-1B.py:191:36
(EngineCore_DP0 pid=333562) 	max.f32 	%r116, %r116, %r79;
(EngineCore_DP0 pid=333562) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=333562) 	add.s32 	%r117, %r117, 8192;
(EngineCore_DP0 pid=333562) 	setp.lt.s32 	%p7, %r117, %r21;
(EngineCore_DP0 pid=333562) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=333562) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=333562) 	.loc	1 193 32                        // quant_slide_tuned_Llama3.2-1B.py:193:32
(EngineCore_DP0 pid=333562) 	max.f32 	%r118, %r116, 0f2B8CBCCC;
(EngineCore_DP0 pid=333562) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=333562) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=333562) 	mov.b32 	%r81, 0f43E00000;
(EngineCore_DP0 pid=333562) 	.loc	1 194 32                        // quant_slide_tuned_Llama3.2-1B.py:194:32
(EngineCore_DP0 pid=333562) 	div.full.f32 	%r82, %r118, %r81;
(EngineCore_DP0 pid=333562) 	.loc	1 194 41                        // quant_slide_tuned_Llama3.2-1B.py:194:41
(EngineCore_DP0 pid=333562) 	max.f32 	%r80, %r82, 0f36924925;
(EngineCore_DP0 pid=333562) 	.loc	1 196 25                        // quant_slide_tuned_Llama3.2-1B.py:196:25
(EngineCore_DP0 pid=333562) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=333562) 	.loc	1 196 30                        // quant_slide_tuned_Llama3.2-1B.py:196:30
(EngineCore_DP0 pid=333562) 	// begin inline asm
(EngineCore_DP0 pid=333562) 	@%p20 st.global.b32 [ %rd8 + 0 ], { %r80 };
(EngineCore_DP0 pid=333562) 	// end inline asm
(EngineCore_DP0 pid=333562) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=333562) 	setp.lt.s32 	%p9, %r22, 1;
(EngineCore_DP0 pid=333562) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=333562) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=333562) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=333562) 	ld.param.b32 	%r26, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=333562) 	shr.s32 	%r27, %r26, 31;
(EngineCore_DP0 pid=333562) 	shr.u32 	%r28, %r27, 30;
(EngineCore_DP0 pid=333562) 	add.s32 	%r29, %r26, %r28;
(EngineCore_DP0 pid=333562) 	shr.s32 	%r30, %r29, 2;
(EngineCore_DP0 pid=333562) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=333562) 	mul.lo.s32 	%r31, %r30, %r1;
(EngineCore_DP0 pid=333562) 	mad.wide.s32 	%rd2, %r31, 4, %rd5;
(EngineCore_DP0 pid=333562) 	div.full.f32 	%r14, %r81, %r118;
(EngineCore_DP0 pid=333562) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=333562) 	shl.b32 	%r119, %r3, 2;
(EngineCore_DP0 pid=333562) 	mov.b32 	%r120, 0;
(EngineCore_DP0 pid=333562) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=333562)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=333562) 	.loc	1 203 30                        // quant_slide_tuned_Llama3.2-1B.py:203:30
(EngineCore_DP0 pid=333562) 	add.s32 	%r93, %r3, %r120;
(EngineCore_DP0 pid=333562) 	setp.lt.s32 	%p14, %r93, %r22;
(EngineCore_DP0 pid=333562) 	.loc	1 211 53                        // quant_slide_tuned_Llama3.2-1B.py:211:53
(EngineCore_DP0 pid=333562) 	setp.lt.s32 	%p15, %r119, %r20;
(EngineCore_DP0 pid=333562) 	.loc	1 211 37                        // quant_slide_tuned_Llama3.2-1B.py:211:37
(EngineCore_DP0 pid=333562) 	and.pred 	%p10, %p14, %p15;
(EngineCore_DP0 pid=333562) 	.loc	1 210 29                        // quant_slide_tuned_Llama3.2-1B.py:210:29
(EngineCore_DP0 pid=333562) 	mad.wide.s32 	%rd9, %r119, 2, %rd1;
(EngineCore_DP0 pid=333562) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=333562) 	.loc	1 210 21                        // quant_slide_tuned_Llama3.2-1B.py:210:21
(EngineCore_DP0 pid=333562) 	// begin inline asm
(EngineCore_DP0 pid=333562) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=333562) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=333562) 	// end inline asm
(EngineCore_DP0 pid=333562) 	.loc	1 211 79                        // quant_slide_tuned_Llama3.2-1B.py:211:79
(EngineCore_DP0 pid=333562) 	cvt.f32.bf16 	%r94, %rs48;
(EngineCore_DP0 pid=333562) 	.loc	1 213 53                        // quant_slide_tuned_Llama3.2-1B.py:213:53
(EngineCore_DP0 pid=333562) 	add.s32 	%r95, %r119, 1;
(EngineCore_DP0 pid=333562) 	setp.lt.s32 	%p16, %r95, %r20;
(EngineCore_DP0 pid=333562) 	.loc	1 213 37                        // quant_slide_tuned_Llama3.2-1B.py:213:37
(EngineCore_DP0 pid=333562) 	and.pred 	%p11, %p14, %p16;
(EngineCore_DP0 pid=333562) 	.loc	1 212 39                        // quant_slide_tuned_Llama3.2-1B.py:212:39
(EngineCore_DP0 pid=333562) 	add.s64 	%rd10, %rd9, 2;
(EngineCore_DP0 pid=333562) 	.loc	1 212 21                        // quant_slide_tuned_Llama3.2-1B.py:212:21
(EngineCore_DP0 pid=333562) 	// begin inline asm
(EngineCore_DP0 pid=333562) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=333562) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=333562) 	// end inline asm
(EngineCore_DP0 pid=333562) 	.loc	1 213 79                        // quant_slide_tuned_Llama3.2-1B.py:213:79
(EngineCore_DP0 pid=333562) 	cvt.f32.bf16 	%r96, %rs50;
(EngineCore_DP0 pid=333562) 	.loc	1 215 53                        // quant_slide_tuned_Llama3.2-1B.py:215:53
(EngineCore_DP0 pid=333562) 	add.s32 	%r97, %r119, 2;
(EngineCore_DP0 pid=333562) 	setp.lt.s32 	%p17, %r97, %r20;
(EngineCore_DP0 pid=333562) 	.loc	1 215 37                        // quant_slide_tuned_Llama3.2-1B.py:215:37
(EngineCore_DP0 pid=333562) 	and.pred 	%p12, %p14, %p17;
(EngineCore_DP0 pid=333562) 	.loc	1 214 39                        // quant_slide_tuned_Llama3.2-1B.py:214:39
(EngineCore_DP0 pid=333562) 	add.s64 	%rd11, %rd9, 4;
(EngineCore_DP0 pid=333562) 	.loc	1 214 21                        // quant_slide_tuned_Llama3.2-1B.py:214:21
(EngineCore_DP0 pid=333562) 	// begin inline asm
(EngineCore_DP0 pid=333562) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=333562) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=333562) 	// end inline asm
(EngineCore_DP0 pid=333562) 	.loc	1 215 79                        // quant_slide_tuned_Llama3.2-1B.py:215:79
(EngineCore_DP0 pid=333562) 	cvt.f32.bf16 	%r98, %rs52;
(EngineCore_DP0 pid=333562) 	.loc	1 217 53                        // quant_slide_tuned_Llama3.2-1B.py:217:53
(EngineCore_DP0 pid=333562) 	add.s32 	%r99, %r119, 3;
(EngineCore_DP0 pid=333562) 	setp.lt.s32 	%p18, %r99, %r20;
(EngineCore_DP0 pid=333562) 	.loc	1 217 37                        // quant_slide_tuned_Llama3.2-1B.py:217:37
(EngineCore_DP0 pid=333562) 	and.pred 	%p13, %p14, %p18;
(EngineCore_DP0 pid=333562) 	.loc	1 216 39                        // quant_slide_tuned_Llama3.2-1B.py:216:39
(EngineCore_DP0 pid=333562) 	add.s64 	%rd12, %rd9, 6;
(EngineCore_DP0 pid=333562) 	.loc	1 216 21                        // quant_slide_tuned_Llama3.2-1B.py:216:21
(EngineCore_DP0 pid=333562) 	// begin inline asm
(EngineCore_DP0 pid=333562) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=333562) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=333562) 	// end inline asm
(EngineCore_DP0 pid=333562) 	.loc	1 217 79                        // quant_slide_tuned_Llama3.2-1B.py:217:79
(EngineCore_DP0 pid=333562) 	cvt.f32.bf16 	%r100, %rs54;
(EngineCore_DP0 pid=333562) 	.loc	1 219 27                        // quant_slide_tuned_Llama3.2-1B.py:219:27
(EngineCore_DP0 pid=333562) 	mul.f32 	%r101, %r14, %r94;
(EngineCore_DP0 pid=333562) 	mov.b32 	%r102, 0f43E00000;
(EngineCore_DP0 pid=333562) 	.loc	1 219 48                        // quant_slide_tuned_Llama3.2-1B.py:219:48
(EngineCore_DP0 pid=333562) 	min.xorsign.abs.f32 	%r84, %r101, %r102;
(EngineCore_DP0 pid=333562) 	.loc	1 219 60                        // quant_slide_tuned_Llama3.2-1B.py:219:60
(EngineCore_DP0 pid=333562) 	// begin inline asm
(EngineCore_DP0 pid=333562) 	cvt.rn.satfinite.e4m3x2.f32  %rs56, %r85, %r84; 
(EngineCore_DP0 pid=333562) 
(EngineCore_DP0 pid=333562) 	// end inline asm
(EngineCore_DP0 pid=333562) 	.loc	1 220 27                        // quant_slide_tuned_Llama3.2-1B.py:220:27
(EngineCore_DP0 pid=333562) 	mul.f32 	%r103, %r14, %r96;
(EngineCore_DP0 pid=333562) 	.loc	1 220 48                        // quant_slide_tuned_Llama3.2-1B.py:220:48
(EngineCore_DP0 pid=333562) 	min.xorsign.abs.f32 	%r86, %r103, %r102;
(EngineCore_DP0 pid=333562) 	.loc	1 220 60                        // quant_slide_tuned_Llama3.2-1B.py:220:60
(EngineCore_DP0 pid=333562) 	// begin inline asm
(EngineCore_DP0 pid=333562) 	cvt.rn.satfinite.e4m3x2.f32  %rs57, %r87, %r86; 
(EngineCore_DP0 pid=333562) 
(EngineCore_DP0 pid=333562) 	// end inline asm
(EngineCore_DP0 pid=333562) 	.loc	1 221 27                        // quant_slide_tuned_Llama3.2-1B.py:221:27
(EngineCore_DP0 pid=333562) 	mul.f32 	%r104, %r14, %r98;
(EngineCore_DP0 pid=333562) 	.loc	1 221 48                        // quant_slide_tuned_Llama3.2-1B.py:221:48
(EngineCore_DP0 pid=333562) 	min.xorsign.abs.f32 	%r88, %r104, %r102;
(EngineCore_DP0 pid=333562) 	.loc	1 221 60                        // quant_slide_tuned_Llama3.2-1B.py:221:60
(EngineCore_DP0 pid=333562) 	// begin inline asm
(EngineCore_DP0 pid=333562) 	cvt.rn.satfinite.e4m3x2.f32  %rs58, %r89, %r88; 
(EngineCore_DP0 pid=333562) 
(EngineCore_DP0 pid=333562) 	// end inline asm
(EngineCore_DP0 pid=333562) 	.loc	1 222 27                        // quant_slide_tuned_Llama3.2-1B.py:222:27
(EngineCore_DP0 pid=333562) 	mul.f32 	%r105, %r14, %r100;
(EngineCore_DP0 pid=333562) 	.loc	1 222 48                        // quant_slide_tuned_Llama3.2-1B.py:222:48
(EngineCore_DP0 pid=333562) 	min.xorsign.abs.f32 	%r90, %r105, %r102;
(EngineCore_DP0 pid=333562) 	.loc	1 222 60                        // quant_slide_tuned_Llama3.2-1B.py:222:60
(EngineCore_DP0 pid=333562) 	// begin inline asm
(EngineCore_DP0 pid=333562) 	cvt.rn.satfinite.e4m3x2.f32  %rs59, %r91, %r90; 
(EngineCore_DP0 pid=333562) 
(EngineCore_DP0 pid=333562) 	// end inline asm
(EngineCore_DP0 pid=333562) 	.loc	1 224 45                        // quant_slide_tuned_Llama3.2-1B.py:224:45
(EngineCore_DP0 pid=333562) 	cvt.u32.u16 	%r106, %rs56;
(EngineCore_DP0 pid=333562) 	and.b32 	%r107, %r106, 255;
(EngineCore_DP0 pid=333562) 	.loc	1 226 45                        // quant_slide_tuned_Llama3.2-1B.py:226:45
(EngineCore_DP0 pid=333562) 	cvt.u32.u16 	%r108, %rs58;
(EngineCore_DP0 pid=333562) 	and.b32 	%r109, %r108, 255;
(EngineCore_DP0 pid=333562) 	.loc	1 227 45                        // quant_slide_tuned_Llama3.2-1B.py:227:45
(EngineCore_DP0 pid=333562) 	cvt.u32.u16 	%r110, %rs59;
(EngineCore_DP0 pid=333562) 	.loc	1 229 30                        // quant_slide_tuned_Llama3.2-1B.py:229:30
(EngineCore_DP0 pid=333562) 	and.b16 	%rs60, %rs57, 255;
(EngineCore_DP0 pid=333562) 	mul.wide.u16 	%r111, %rs60, 256;
(EngineCore_DP0 pid=333562) 	.loc	1 229 24                        // quant_slide_tuned_Llama3.2-1B.py:229:24
(EngineCore_DP0 pid=333562) 	or.b32 	%r112, %r111, %r107;
(EngineCore_DP0 pid=333562) 	.loc	1 229 42                        // quant_slide_tuned_Llama3.2-1B.py:229:42
(EngineCore_DP0 pid=333562) 	shl.b32 	%r113, %r109, 16;
(EngineCore_DP0 pid=333562) 	.loc	1 229 36                        // quant_slide_tuned_Llama3.2-1B.py:229:36
(EngineCore_DP0 pid=333562) 	or.b32 	%r114, %r112, %r113;
(EngineCore_DP0 pid=333562) 	.loc	1 229 55                        // quant_slide_tuned_Llama3.2-1B.py:229:55
(EngineCore_DP0 pid=333562) 	shl.b32 	%r115, %r110, 24;
(EngineCore_DP0 pid=333562) 	.loc	1 229 49                        // quant_slide_tuned_Llama3.2-1B.py:229:49
(EngineCore_DP0 pid=333562) 	or.b32 	%r92, %r114, %r115;
(EngineCore_DP0 pid=333562) 	.loc	1 230 29                        // quant_slide_tuned_Llama3.2-1B.py:230:29
(EngineCore_DP0 pid=333562) 	mad.wide.s32 	%rd13, %r93, 4, %rd2;
(EngineCore_DP0 pid=333562) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-1B.py:230:39
(EngineCore_DP0 pid=333562) 	// begin inline asm
(EngineCore_DP0 pid=333562) 	@%p14 st.global.b32 [ %rd13 + 0 ], { %r92 };
(EngineCore_DP0 pid=333562) 	// end inline asm
(EngineCore_DP0 pid=333562) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=333562) 	add.s32 	%r120, %r120, 512;
(EngineCore_DP0 pid=333562) 	add.s32 	%r119, %r119, 2048;
(EngineCore_DP0 pid=333562) 	setp.lt.s32 	%p19, %r120, %r22;
(EngineCore_DP0 pid=333562) 	@%p19 bra 	$L__BB0_6;
(EngineCore_DP0 pid=333562) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=333562) 	.loc	1 201 4                         // quant_slide_tuned_Llama3.2-1B.py:201:4
(EngineCore_DP0 pid=333562) 	ret;
(EngineCore_DP0 pid=333562) $L__tmp3:
(EngineCore_DP0 pid=333562) $L__func_end0:
(EngineCore_DP0 pid=333562)                                         // -- End function
(EngineCore_DP0 pid=333562) }
(EngineCore_DP0 pid=333562) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=333562) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=333562) 	.section	.debug_abbrev
(EngineCore_DP0 pid=333562) 	{
(EngineCore_DP0 pid=333562) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=333562) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=333562) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=333562) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=333562) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=333562) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=333562) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=333562) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=333562) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=333562) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=333562) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=333562) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=333562) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=333562) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=333562) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=333562) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=333562) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=333562) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=333562) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=333562) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=333562) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=333562) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=333562) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=333562) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=333562) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=333562) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=333562) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=333562) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=333562) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=333562) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=333562) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=333562) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=333562) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=333562) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=333562) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=333562) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=333562) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=333562) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=333562) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=333562) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=333562) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=333562) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=333562) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=333562) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=333562) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=333562) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=333562) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=333562) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=333562) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=333562) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=333562) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=333562) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=333562) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=333562) 	}
(EngineCore_DP0 pid=333562) 	.section	.debug_info
(EngineCore_DP0 pid=333562) 	{
(EngineCore_DP0 pid=333562) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=333562) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=333562) .b8 0
(EngineCore_DP0 pid=333562) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=333562) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=333562) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=333562) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=333562) .b8 114
(EngineCore_DP0 pid=333562) .b8 105
(EngineCore_DP0 pid=333562) .b8 116
(EngineCore_DP0 pid=333562) .b8 111
(EngineCore_DP0 pid=333562) .b8 110
(EngineCore_DP0 pid=333562) .b8 0
(EngineCore_DP0 pid=333562) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=333562) .b8 0
(EngineCore_DP0 pid=333562) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=333562) .b8 117
(EngineCore_DP0 pid=333562) .b8 97
(EngineCore_DP0 pid=333562) .b8 110
(EngineCore_DP0 pid=333562) .b8 116
(EngineCore_DP0 pid=333562) .b8 95
(EngineCore_DP0 pid=333562) .b8 115
(EngineCore_DP0 pid=333562) .b8 108
(EngineCore_DP0 pid=333562) .b8 105
(EngineCore_DP0 pid=333562) .b8 100
(EngineCore_DP0 pid=333562) .b8 101
(EngineCore_DP0 pid=333562) .b8 95
(EngineCore_DP0 pid=333562) .b8 116
(EngineCore_DP0 pid=333562) .b8 117
(EngineCore_DP0 pid=333562) .b8 110
(EngineCore_DP0 pid=333562) .b8 101
(EngineCore_DP0 pid=333562) .b8 100
(EngineCore_DP0 pid=333562) .b8 95
(EngineCore_DP0 pid=333562) .b8 76
(EngineCore_DP0 pid=333562) .b8 108
(EngineCore_DP0 pid=333562) .b8 97
(EngineCore_DP0 pid=333562) .b8 109
(EngineCore_DP0 pid=333562) .b8 97
(EngineCore_DP0 pid=333562) .b8 51
(EngineCore_DP0 pid=333562) .b8 46
(EngineCore_DP0 pid=333562) .b8 50
(EngineCore_DP0 pid=333562) .b8 45
(EngineCore_DP0 pid=333562) .b8 49
(EngineCore_DP0 pid=333562) .b8 66
(EngineCore_DP0 pid=333562) .b8 46
(EngineCore_DP0 pid=333562) .b8 112
(EngineCore_DP0 pid=333562) .b8 121
(EngineCore_DP0 pid=333562) .b8 0
(EngineCore_DP0 pid=333562) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=333562) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=333562) .b8 114
(EngineCore_DP0 pid=333562) .b8 111
(EngineCore_DP0 pid=333562) .b8 111
(EngineCore_DP0 pid=333562) .b8 116
(EngineCore_DP0 pid=333562) .b8 47
(EngineCore_DP0 pid=333562) .b8 118
(EngineCore_DP0 pid=333562) .b8 108
(EngineCore_DP0 pid=333562) .b8 108
(EngineCore_DP0 pid=333562) .b8 109
(EngineCore_DP0 pid=333562) .b8 98
(EngineCore_DP0 pid=333562) .b8 101
(EngineCore_DP0 pid=333562) .b8 110
(EngineCore_DP0 pid=333562) .b8 99
(EngineCore_DP0 pid=333562) .b8 104
(EngineCore_DP0 pid=333562) .b8 47
(EngineCore_DP0 pid=333562) .b8 115
(EngineCore_DP0 pid=333562) .b8 108
(EngineCore_DP0 pid=333562) .b8 105
(EngineCore_DP0 pid=333562) .b8 100
(EngineCore_DP0 pid=333562) .b8 101
(EngineCore_DP0 pid=333562) .b8 115
(EngineCore_DP0 pid=333562) .b8 112
(EngineCore_DP0 pid=333562) .b8 97
(EngineCore_DP0 pid=333562) .b8 114
(EngineCore_DP0 pid=333562) .b8 115
(EngineCore_DP0 pid=333562) .b8 101
(EngineCore_DP0 pid=333562) .b8 47
(EngineCore_DP0 pid=333562) .b8 99
(EngineCore_DP0 pid=333562) .b8 115
(EngineCore_DP0 pid=333562) .b8 114
(EngineCore_DP0 pid=333562) .b8 99
(EngineCore_DP0 pid=333562) .b8 47
(EngineCore_DP0 pid=333562) .b8 102
(EngineCore_DP0 pid=333562) .b8 117
(EngineCore_DP0 pid=333562) .b8 115
(EngineCore_DP0 pid=333562) .b8 101
(EngineCore_DP0 pid=333562) .b8 100
(EngineCore_DP0 pid=333562) .b8 95
(EngineCore_DP0 pid=333562) .b8 113
(EngineCore_DP0 pid=333562) .b8 117
(EngineCore_DP0 pid=333562) .b8 97
(EngineCore_DP0 pid=333562) .b8 110
(EngineCore_DP0 pid=333562) .b8 116
(EngineCore_DP0 pid=333562) .b8 95
(EngineCore_DP0 pid=333562) .b8 115
(EngineCore_DP0 pid=333562) .b8 108
(EngineCore_DP0 pid=333562) .b8 105
(EngineCore_DP0 pid=333562) .b8 100
(EngineCore_DP0 pid=333562) .b8 101
(EngineCore_DP0 pid=333562) .b8 95
(EngineCore_DP0 pid=333562) .b8 116
(EngineCore_DP0 pid=333562) .b8 114
(EngineCore_DP0 pid=333562) .b8 105
(EngineCore_DP0 pid=333562) .b8 116
(EngineCore_DP0 pid=333562) .b8 111
(EngineCore_DP0 pid=333562) .b8 110
(EngineCore_DP0 pid=333562) .b8 47
(EngineCore_DP0 pid=333562) .b8 98
(EngineCore_DP0 pid=333562) .b8 117
(EngineCore_DP0 pid=333562) .b8 105
(EngineCore_DP0 pid=333562) .b8 108
(EngineCore_DP0 pid=333562) .b8 100
(EngineCore_DP0 pid=333562) .b8 47
(EngineCore_DP0 pid=333562) .b8 71
(EngineCore_DP0 pid=333562) .b8 66
(EngineCore_DP0 pid=333562) .b8 49
(EngineCore_DP0 pid=333562) .b8 48
(EngineCore_DP0 pid=333562) .b8 95
(EngineCore_DP0 pid=333562) .b8 99
(EngineCore_DP0 pid=333562) .b8 99
(EngineCore_DP0 pid=333562) .b8 49
(EngineCore_DP0 pid=333562) .b8 50
(EngineCore_DP0 pid=333562) .b8 49
(EngineCore_DP0 pid=333562) .b8 95
(EngineCore_DP0 pid=333562) .b8 112
(EngineCore_DP0 pid=333562) .b8 121
(EngineCore_DP0 pid=333562) .b8 51
(EngineCore_DP0 pid=333562) .b8 49
(EngineCore_DP0 pid=333562) .b8 50
(EngineCore_DP0 pid=333562) .b8 95
(EngineCore_DP0 pid=333562) .b8 99
(EngineCore_DP0 pid=333562) .b8 117
(EngineCore_DP0 pid=333562) .b8 49
(EngineCore_DP0 pid=333562) .b8 50
(EngineCore_DP0 pid=333562) .b8 57
(EngineCore_DP0 pid=333562) .b8 95
(EngineCore_DP0 pid=333562) .b8 97
(EngineCore_DP0 pid=333562) .b8 97
(EngineCore_DP0 pid=333562) .b8 114
(EngineCore_DP0 pid=333562) .b8 99
(EngineCore_DP0 pid=333562) .b8 104
(EngineCore_DP0 pid=333562) .b8 54
(EngineCore_DP0 pid=333562) .b8 52
(EngineCore_DP0 pid=333562) .b8 0
(EngineCore_DP0 pid=333562) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=333562) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=333562) .b8 113
(EngineCore_DP0 pid=333562) .b8 117
(EngineCore_DP0 pid=333562) .b8 97
(EngineCore_DP0 pid=333562) .b8 110
(EngineCore_DP0 pid=333562) .b8 116
(EngineCore_DP0 pid=333562) .b8 95
(EngineCore_DP0 pid=333562) .b8 115
(EngineCore_DP0 pid=333562) .b8 108
(EngineCore_DP0 pid=333562) .b8 105
(EngineCore_DP0 pid=333562) .b8 100
(EngineCore_DP0 pid=333562) .b8 101
(EngineCore_DP0 pid=333562) .b8 95
(EngineCore_DP0 pid=333562) .b8 102
(EngineCore_DP0 pid=333562) .b8 112
(EngineCore_DP0 pid=333562) .b8 56
(EngineCore_DP0 pid=333562) .b8 95
(EngineCore_DP0 pid=333562) .b8 107
(EngineCore_DP0 pid=333562) .b8 101
(EngineCore_DP0 pid=333562) .b8 114
(EngineCore_DP0 pid=333562) .b8 110
(EngineCore_DP0 pid=333562) .b8 101
(EngineCore_DP0 pid=333562) .b8 108
(EngineCore_DP0 pid=333562) .b8 0
(EngineCore_DP0 pid=333562) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=333562) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=333562) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=333562) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=333562) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=333562) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=333562) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=333562) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=333562) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=333562) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=333562) .b8 191                                 // DW_AT_call_line
(EngineCore_DP0 pid=333562) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=333562) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=333562) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=333562) 	}
(EngineCore_DP0 pid=333562) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=333562) 
(EngineCore_DP0 pid=333562) ================================================================
(EngineCore_DP0 pid=333562) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=333562) 
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpvd8a6g7h.ptx', '-o', '/tmp/tmpvd8a6g7h.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866] 
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866] 
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866] 
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpvd8a6g7h.ptx -o /tmp/tmpvd8a6g7h.ptx.o
(EngineCore_DP0 pid=333562) ERROR 01-25 19:13:48 [core.py:866] 

STDERR:
[2026-01-25 19:13:34] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:13:34] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:13:34] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:13:34] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:13:34] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:13:34] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:13:34] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:13:34] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:13:34] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:13:34] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:13:34] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:13:34] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:13:34] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:13:34] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:13:38] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:13:38] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:13:38] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:13:38] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:13:38] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:13:38] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:13:38] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:13:38] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:13:38] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:13:38] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:13:38] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:13:38] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:13:38] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:13:38] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=333562) [2026-01-25 19:13:38] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=333562) [2026-01-25 19:13:38] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=333562) [2026-01-25 19:13:38] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=333562) [2026-01-25 19:13:38] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=333562) [2026-01-25 19:13:38] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=333562) [2026-01-25 19:13:38] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=333562) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=333562) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.34s/it]
(EngineCore_DP0 pid=333562) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.34s/it]
(EngineCore_DP0 pid=333562) 
(EngineCore_DP0 pid=333562) [2026-01-25 19:13:47] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=333562) [2026-01-25 19:13:47] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=333562) [2026-01-25 19:13:47] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=333562) [2026-01-25 19:13:47] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 2621440 bytes
(EngineCore_DP0 pid=333562) [2026-01-25 19:13:47] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=333562) [2026-01-25 19:13:47] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 20971520 bytes
(EngineCore_DP0 pid=333562) [2026-01-25 19:13:47] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=333562) [2026-01-25 19:13:47] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10485760 bytes
(EngineCore_DP0 pid=333562) Process EngineCore_DP0:
(EngineCore_DP0 pid=333562) Traceback (most recent call last):
(EngineCore_DP0 pid=333562)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=333562)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=333562)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=333562)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=333562) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpvd8a6g7h.ptx', '-o', '/tmp/tmpvd8a6g7h.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=333562) 
(EngineCore_DP0 pid=333562) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=333562) 
(EngineCore_DP0 pid=333562) Traceback (most recent call last):
(EngineCore_DP0 pid=333562)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=333562)     self.run()
(EngineCore_DP0 pid=333562)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=333562)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=333562)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=333562)     raise e
(EngineCore_DP0 pid=333562)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=333562)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=333562)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=333562)     super().__init__(
(EngineCore_DP0 pid=333562)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=333562)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=333562)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=333562)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=333562)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=333562)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=333562)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=333562)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=333562)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=333562)     return func(*args, **kwargs)
(EngineCore_DP0 pid=333562)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=333562)     return func(*args, **kwargs)
(EngineCore_DP0 pid=333562)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=333562)     self.model_runner.profile_run()
(EngineCore_DP0 pid=333562)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=333562)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=333562)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=333562)     return func(*args, **kwargs)
(EngineCore_DP0 pid=333562)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=333562)     outputs = self.model(
(EngineCore_DP0 pid=333562)               ^^^^^^^^^^^
(EngineCore_DP0 pid=333562)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=333562)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=333562)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=333562)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=333562)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=333562)     model_output = self.model(
(EngineCore_DP0 pid=333562)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=333562)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=333562)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=333562)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=333562)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=333562)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=333562)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=333562)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=333562)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=333562)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=333562)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=333562)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=333562)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=333562)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=333562)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=333562)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=333562)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=333562)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=333562)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=333562)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=333562)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=333562)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=333562)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=333562)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=333562)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=333562)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=333562)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=333562)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=333562)     return self._linear_fn(
(EngineCore_DP0 pid=333562)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=333562)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=333562)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=333562)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=333562)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=333562)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=333562)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=333562)     return fn(input, L)
(EngineCore_DP0 pid=333562)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=333562)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=333562)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=333562)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=333562)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=333562)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=333562)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=333562)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=333562)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=333562)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=333562)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=333562)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=333562)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=333562)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=333562)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=333562)     raise PTXASError(error)
(EngineCore_DP0 pid=333562) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=333562) `ptxas` stderr:
(EngineCore_DP0 pid=333562) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=333562) 
(EngineCore_DP0 pid=333562) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpvd8a6g7h.ptx -o /tmp/tmpvd8a6g7h.ptx.o
(EngineCore_DP0 pid=333562) 
[rank0]:[W125 19:13:48.114177730 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=1024

========== M=2048 ==========
Time: 2026-01-25 19:13:50
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Llama3.2-1B-FP8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:13:54 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:13:54 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=334031) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=334031) 
(EngineCore_DP0 pid=334031) 
(EngineCore_DP0 pid=334031) ================================================================
(EngineCore_DP0 pid=334031) Internal Triton PTX codegen error
(EngineCore_DP0 pid=334031) `ptxas` stderr:
(EngineCore_DP0 pid=334031) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=334031) 
(EngineCore_DP0 pid=334031) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpoq2gu842.ptx -o /tmp/tmpoq2gu842.ptx.o
(EngineCore_DP0 pid=334031) 
(EngineCore_DP0 pid=334031) 
(EngineCore_DP0 pid=334031) //
(EngineCore_DP0 pid=334031) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=334031) //
(EngineCore_DP0 pid=334031) 
(EngineCore_DP0 pid=334031) .version 8.7
(EngineCore_DP0 pid=334031) .target sm_121a
(EngineCore_DP0 pid=334031) .address_size 64
(EngineCore_DP0 pid=334031) 
(EngineCore_DP0 pid=334031) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=334031) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=334031)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=334031) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=334031) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=334031) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=334031) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=334031) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=334031) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=334031) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=334031) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=334031) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=334031) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=334031) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=334031) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=334031) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=334031) )
(EngineCore_DP0 pid=334031) .reqntid 512
(EngineCore_DP0 pid=334031) {
(EngineCore_DP0 pid=334031) 	.reg .pred 	%p<21>;
(EngineCore_DP0 pid=334031) 	.reg .b16 	%rs<61>;
(EngineCore_DP0 pid=334031) 	.reg .b32 	%r<121>;
(EngineCore_DP0 pid=334031) 	.reg .b64 	%rd<14>;
(EngineCore_DP0 pid=334031) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=334031) $L__func_begin0:
(EngineCore_DP0 pid=334031) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=334031) 
(EngineCore_DP0 pid=334031) // %bb.0:
(EngineCore_DP0 pid=334031) 	ld.param.b32 	%r22, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=334031) 	ld.param.b32 	%r21, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=334031) 	ld.param.b32 	%r20, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=334031) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=334031) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=334031) $L__tmp0:
(EngineCore_DP0 pid=334031) 	.loc	1 177 24                        // quant_slide_tuned_Llama3.2-1B.py:177:24
(EngineCore_DP0 pid=334031) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=334031) 	ld.param.b32 	%r24, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=334031) 	.loc	1 182 26                        // quant_slide_tuned_Llama3.2-1B.py:182:26
(EngineCore_DP0 pid=334031) 	mul.lo.s32 	%r25, %r24, %r1;
(EngineCore_DP0 pid=334031) 	.loc	1 182 20                        // quant_slide_tuned_Llama3.2-1B.py:182:20
(EngineCore_DP0 pid=334031) 	mad.wide.s32 	%rd1, %r25, 2, %rd4;
(EngineCore_DP0 pid=334031) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=334031) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=334031) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=334031) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=334031) 	setp.lt.s32 	%p1, %r21, 1;
(EngineCore_DP0 pid=334031) 	mov.b32 	%r118, 0f2B8CBCCC;
(EngineCore_DP0 pid=334031) 	setp.eq.b32 	%p20, %r2, 0;
(EngineCore_DP0 pid=334031) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=334031) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=334031) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=334031) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=334031) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=334031) 	shr.u32 	%r34, %r2, 3;
(EngineCore_DP0 pid=334031) 	and.b32 	%r35, %r34, 60;
(EngineCore_DP0 pid=334031) 	mov.b32 	%r36, global_smem;
(EngineCore_DP0 pid=334031) 	add.s32 	%r54, %r36, %r35;
(EngineCore_DP0 pid=334031) 	shl.b32 	%r37, %r2, 2;
(EngineCore_DP0 pid=334031) 	add.s32 	%r57, %r36, %r37;
(EngineCore_DP0 pid=334031) 	mov.b32 	%r42, 0;
(EngineCore_DP0 pid=334031) 	mov.b32 	%r116, 0f00000000;
(EngineCore_DP0 pid=334031) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=334031) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=334031) 	mov.b32 	%r117, %r42;
(EngineCore_DP0 pid=334031) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=334031) 	.loc	1 188 19                        // quant_slide_tuned_Llama3.2-1B.py:188:19
(EngineCore_DP0 pid=334031) 	add.s32 	%r60, %r4, %r117;
(EngineCore_DP0 pid=334031) 	.loc	1 189 22                        // quant_slide_tuned_Llama3.2-1B.py:189:22
(EngineCore_DP0 pid=334031) 	add.s32 	%r61, %r60, 4096;
(EngineCore_DP0 pid=334031) 	setp.lt.s32 	%p2, %r60, %r20;
(EngineCore_DP0 pid=334031) 	setp.lt.s32 	%p3, %r61, %r20;
(EngineCore_DP0 pid=334031) 	.loc	1 190 29                        // quant_slide_tuned_Llama3.2-1B.py:190:29
(EngineCore_DP0 pid=334031) 	mad.wide.s32 	%rd6, %r60, 2, %rd1;
(EngineCore_DP0 pid=334031) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=334031) 	.loc	1 190 21                        // quant_slide_tuned_Llama3.2-1B.py:190:21
(EngineCore_DP0 pid=334031) 	// begin inline asm
(EngineCore_DP0 pid=334031) 	mov.u32 %r38, %r42;
(EngineCore_DP0 pid=334031) 	mov.u32 %r39, %r42;
(EngineCore_DP0 pid=334031) 	mov.u32 %r40, %r42;
(EngineCore_DP0 pid=334031) 	mov.u32 %r41, %r42;
(EngineCore_DP0 pid=334031) 	@%p2 ld.global.v4.b32 { %r38, %r39, %r40, %r41 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=334031) 	// end inline asm
(EngineCore_DP0 pid=334031) 	mov.b32 	{%rs1, %rs2}, %r38;
(EngineCore_DP0 pid=334031) 	mov.b32 	{%rs3, %rs4}, %r39;
(EngineCore_DP0 pid=334031) 	mov.b32 	{%rs5, %rs6}, %r40;
(EngineCore_DP0 pid=334031) 	mov.b32 	{%rs7, %rs8}, %r41;
(EngineCore_DP0 pid=334031) 	// begin inline asm
(EngineCore_DP0 pid=334031) 	mov.u32 %r46, %r42;
(EngineCore_DP0 pid=334031) 	mov.u32 %r47, %r42;
(EngineCore_DP0 pid=334031) 	mov.u32 %r48, %r42;
(EngineCore_DP0 pid=334031) 	mov.u32 %r49, %r42;
(EngineCore_DP0 pid=334031) 	@%p3 ld.global.v4.b32 { %r46, %r47, %r48, %r49 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=334031) 	// end inline asm
(EngineCore_DP0 pid=334031) 	mov.b32 	{%rs9, %rs10}, %r46;
(EngineCore_DP0 pid=334031) 	mov.b32 	{%rs11, %rs12}, %r47;
(EngineCore_DP0 pid=334031) 	mov.b32 	{%rs13, %rs14}, %r48;
(EngineCore_DP0 pid=334031) 	mov.b32 	{%rs15, %rs16}, %r49;
(EngineCore_DP0 pid=334031) 	.loc	1 191 50                        // quant_slide_tuned_Llama3.2-1B.py:191:50
(EngineCore_DP0 pid=334031) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=334031) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=334031) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=334031) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=334031) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=334031) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=334031) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=334031) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=334031) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=334031) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=334031) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=334031) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=334031) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=334031) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=334031) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=334031) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=334031) $L__tmp1:
(EngineCore_DP0 pid=334031) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=334031) 	bar.sync 	0;
(EngineCore_DP0 pid=334031) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=334031) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=334031) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=334031) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=334031) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=334031) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=334031) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=334031) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=334031) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=334031) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=334031) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=334031) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=334031) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=334031) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=334031) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=334031) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=334031) 	cvt.f32.bf16 	%r62, %rs47;
(EngineCore_DP0 pid=334031) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=334031) 	shfl.sync.bfly.b32 	%r63, %r62, 16, 31, -1;
(EngineCore_DP0 pid=334031) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=334031) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=334031) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=334031) 	shfl.sync.bfly.b32 	%r65, %r64, 8, 31, -1;
(EngineCore_DP0 pid=334031) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=334031) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=334031) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=334031) 	shfl.sync.bfly.b32 	%r67, %r66, 4, 31, -1;
(EngineCore_DP0 pid=334031) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=334031) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=334031) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=334031) 	shfl.sync.bfly.b32 	%r69, %r68, 2, 31, -1;
(EngineCore_DP0 pid=334031) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=334031) 	max.f32 	%r70, %r68, %r69;
(EngineCore_DP0 pid=334031) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=334031) 	shfl.sync.bfly.b32 	%r71, %r70, 1, 31, -1;
(EngineCore_DP0 pid=334031) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=334031) 	max.f32 	%r55, %r70, %r71;
(EngineCore_DP0 pid=334031) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=334031) 	// begin inline asm
(EngineCore_DP0 pid=334031) 	@%p4 st.shared.b32 [ %r54 + 0 ], %r55;
(EngineCore_DP0 pid=334031) 	// end inline asm
(EngineCore_DP0 pid=334031) 	bar.sync 	0;
(EngineCore_DP0 pid=334031) 	// begin inline asm
(EngineCore_DP0 pid=334031) 	@%p5 ld.shared.b32 %r56, [ %r57 + 0 ];
(EngineCore_DP0 pid=334031) 	// end inline asm
(EngineCore_DP0 pid=334031) 	shfl.sync.bfly.b32 	%r72, %r56, 8, 31, -1;
(EngineCore_DP0 pid=334031) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=334031) 	max.f32 	%r73, %r56, %r72;
(EngineCore_DP0 pid=334031) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=334031) 	shfl.sync.bfly.b32 	%r74, %r73, 4, 31, -1;
(EngineCore_DP0 pid=334031) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=334031) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=334031) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=334031) 	shfl.sync.bfly.b32 	%r76, %r75, 2, 31, -1;
(EngineCore_DP0 pid=334031) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=334031) 	max.f32 	%r77, %r75, %r76;
(EngineCore_DP0 pid=334031) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=334031) 	shfl.sync.bfly.b32 	%r78, %r77, 1, 31, -1;
(EngineCore_DP0 pid=334031) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=334031) 	max.f32 	%r59, %r77, %r78;
(EngineCore_DP0 pid=334031) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=334031) 	// begin inline asm
(EngineCore_DP0 pid=334031) 	@%p20 st.shared.b32 [ %r57 + 0 ], %r59;
(EngineCore_DP0 pid=334031) 	// end inline asm
(EngineCore_DP0 pid=334031) 	bar.sync 	0;
(EngineCore_DP0 pid=334031) 	ld.shared.b32 	%r79, [global_smem];
(EngineCore_DP0 pid=334031) $L__tmp2:
(EngineCore_DP0 pid=334031) 	.loc	1 191 36                        // quant_slide_tuned_Llama3.2-1B.py:191:36
(EngineCore_DP0 pid=334031) 	max.f32 	%r116, %r116, %r79;
(EngineCore_DP0 pid=334031) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=334031) 	add.s32 	%r117, %r117, 8192;
(EngineCore_DP0 pid=334031) 	setp.lt.s32 	%p7, %r117, %r21;
(EngineCore_DP0 pid=334031) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=334031) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=334031) 	.loc	1 193 32                        // quant_slide_tuned_Llama3.2-1B.py:193:32
(EngineCore_DP0 pid=334031) 	max.f32 	%r118, %r116, 0f2B8CBCCC;
(EngineCore_DP0 pid=334031) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=334031) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=334031) 	mov.b32 	%r81, 0f43E00000;
(EngineCore_DP0 pid=334031) 	.loc	1 194 32                        // quant_slide_tuned_Llama3.2-1B.py:194:32
(EngineCore_DP0 pid=334031) 	div.full.f32 	%r82, %r118, %r81;
(EngineCore_DP0 pid=334031) 	.loc	1 194 41                        // quant_slide_tuned_Llama3.2-1B.py:194:41
(EngineCore_DP0 pid=334031) 	max.f32 	%r80, %r82, 0f36924925;
(EngineCore_DP0 pid=334031) 	.loc	1 196 25                        // quant_slide_tuned_Llama3.2-1B.py:196:25
(EngineCore_DP0 pid=334031) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=334031) 	.loc	1 196 30                        // quant_slide_tuned_Llama3.2-1B.py:196:30
(EngineCore_DP0 pid=334031) 	// begin inline asm
(EngineCore_DP0 pid=334031) 	@%p20 st.global.b32 [ %rd8 + 0 ], { %r80 };
(EngineCore_DP0 pid=334031) 	// end inline asm
(EngineCore_DP0 pid=334031) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=334031) 	setp.lt.s32 	%p9, %r22, 1;
(EngineCore_DP0 pid=334031) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=334031) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=334031) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=334031) 	ld.param.b32 	%r26, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=334031) 	shr.s32 	%r27, %r26, 31;
(EngineCore_DP0 pid=334031) 	shr.u32 	%r28, %r27, 30;
(EngineCore_DP0 pid=334031) 	add.s32 	%r29, %r26, %r28;
(EngineCore_DP0 pid=334031) 	shr.s32 	%r30, %r29, 2;
(EngineCore_DP0 pid=334031) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=334031) 	mul.lo.s32 	%r31, %r30, %r1;
(EngineCore_DP0 pid=334031) 	mad.wide.s32 	%rd2, %r31, 4, %rd5;
(EngineCore_DP0 pid=334031) 	div.full.f32 	%r14, %r81, %r118;
(EngineCore_DP0 pid=334031) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=334031) 	shl.b32 	%r119, %r3, 2;
(EngineCore_DP0 pid=334031) 	mov.b32 	%r120, 0;
(EngineCore_DP0 pid=334031) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=334031)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=334031) 	.loc	1 203 30                        // quant_slide_tuned_Llama3.2-1B.py:203:30
(EngineCore_DP0 pid=334031) 	add.s32 	%r93, %r3, %r120;
(EngineCore_DP0 pid=334031) 	setp.lt.s32 	%p14, %r93, %r22;
(EngineCore_DP0 pid=334031) 	.loc	1 211 53                        // quant_slide_tuned_Llama3.2-1B.py:211:53
(EngineCore_DP0 pid=334031) 	setp.lt.s32 	%p15, %r119, %r20;
(EngineCore_DP0 pid=334031) 	.loc	1 211 37                        // quant_slide_tuned_Llama3.2-1B.py:211:37
(EngineCore_DP0 pid=334031) 	and.pred 	%p10, %p14, %p15;
(EngineCore_DP0 pid=334031) 	.loc	1 210 29                        // quant_slide_tuned_Llama3.2-1B.py:210:29
(EngineCore_DP0 pid=334031) 	mad.wide.s32 	%rd9, %r119, 2, %rd1;
(EngineCore_DP0 pid=334031) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=334031) 	.loc	1 210 21                        // quant_slide_tuned_Llama3.2-1B.py:210:21
(EngineCore_DP0 pid=334031) 	// begin inline asm
(EngineCore_DP0 pid=334031) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=334031) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=334031) 	// end inline asm
(EngineCore_DP0 pid=334031) 	.loc	1 211 79                        // quant_slide_tuned_Llama3.2-1B.py:211:79
(EngineCore_DP0 pid=334031) 	cvt.f32.bf16 	%r94, %rs48;
(EngineCore_DP0 pid=334031) 	.loc	1 213 53                        // quant_slide_tuned_Llama3.2-1B.py:213:53
(EngineCore_DP0 pid=334031) 	add.s32 	%r95, %r119, 1;
(EngineCore_DP0 pid=334031) 	setp.lt.s32 	%p16, %r95, %r20;
(EngineCore_DP0 pid=334031) 	.loc	1 213 37                        // quant_slide_tuned_Llama3.2-1B.py:213:37
(EngineCore_DP0 pid=334031) 	and.pred 	%p11, %p14, %p16;
(EngineCore_DP0 pid=334031) 	.loc	1 212 39                        // quant_slide_tuned_Llama3.2-1B.py:212:39
(EngineCore_DP0 pid=334031) 	add.s64 	%rd10, %rd9, 2;
(EngineCore_DP0 pid=334031) 	.loc	1 212 21                        // quant_slide_tuned_Llama3.2-1B.py:212:21
(EngineCore_DP0 pid=334031) 	// begin inline asm
(EngineCore_DP0 pid=334031) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=334031) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=334031) 	// end inline asm
(EngineCore_DP0 pid=334031) 	.loc	1 213 79                        // quant_slide_tuned_Llama3.2-1B.py:213:79
(EngineCore_DP0 pid=334031) 	cvt.f32.bf16 	%r96, %rs50;
(EngineCore_DP0 pid=334031) 	.loc	1 215 53                        // quant_slide_tuned_Llama3.2-1B.py:215:53
(EngineCore_DP0 pid=334031) 	add.s32 	%r97, %r119, 2;
(EngineCore_DP0 pid=334031) 	setp.lt.s32 	%p17, %r97, %r20;
(EngineCore_DP0 pid=334031) 	.loc	1 215 37                        // quant_slide_tuned_Llama3.2-1B.py:215:37
(EngineCore_DP0 pid=334031) 	and.pred 	%p12, %p14, %p17;
(EngineCore_DP0 pid=334031) 	.loc	1 214 39                        // quant_slide_tuned_Llama3.2-1B.py:214:39
(EngineCore_DP0 pid=334031) 	add.s64 	%rd11, %rd9, 4;
(EngineCore_DP0 pid=334031) 	.loc	1 214 21                        // quant_slide_tuned_Llama3.2-1B.py:214:21
(EngineCore_DP0 pid=334031) 	// begin inline asm
(EngineCore_DP0 pid=334031) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=334031) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=334031) 	// end inline asm
(EngineCore_DP0 pid=334031) 	.loc	1 215 79                        // quant_slide_tuned_Llama3.2-1B.py:215:79
(EngineCore_DP0 pid=334031) 	cvt.f32.bf16 	%r98, %rs52;
(EngineCore_DP0 pid=334031) 	.loc	1 217 53                        // quant_slide_tuned_Llama3.2-1B.py:217:53
(EngineCore_DP0 pid=334031) 	add.s32 	%r99, %r119, 3;
(EngineCore_DP0 pid=334031) 	setp.lt.s32 	%p18, %r99, %r20;
(EngineCore_DP0 pid=334031) 	.loc	1 217 37                        // quant_slide_tuned_Llama3.2-1B.py:217:37
(EngineCore_DP0 pid=334031) 	and.pred 	%p13, %p14, %p18;
(EngineCore_DP0 pid=334031) 	.loc	1 216 39                        // quant_slide_tuned_Llama3.2-1B.py:216:39
(EngineCore_DP0 pid=334031) 	add.s64 	%rd12, %rd9, 6;
(EngineCore_DP0 pid=334031) 	.loc	1 216 21                        // quant_slide_tuned_Llama3.2-1B.py:216:21
(EngineCore_DP0 pid=334031) 	// begin inline asm
(EngineCore_DP0 pid=334031) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=334031) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=334031) 	// end inline asm
(EngineCore_DP0 pid=334031) 	.loc	1 217 79                        // quant_slide_tuned_Llama3.2-1B.py:217:79
(EngineCore_DP0 pid=334031) 	cvt.f32.bf16 	%r100, %rs54;
(EngineCore_DP0 pid=334031) 	.loc	1 219 27                        // quant_slide_tuned_Llama3.2-1B.py:219:27
(EngineCore_DP0 pid=334031) 	mul.f32 	%r101, %r14, %r94;
(EngineCore_DP0 pid=334031) 	mov.b32 	%r102, 0f43E00000;
(EngineCore_DP0 pid=334031) 	.loc	1 219 48                        // quant_slide_tuned_Llama3.2-1B.py:219:48
(EngineCore_DP0 pid=334031) 	min.xorsign.abs.f32 	%r84, %r101, %r102;
(EngineCore_DP0 pid=334031) 	.loc	1 219 60                        // quant_slide_tuned_Llama3.2-1B.py:219:60
(EngineCore_DP0 pid=334031) 	// begin inline asm
(EngineCore_DP0 pid=334031) 	cvt.rn.satfinite.e4m3x2.f32  %rs56, %r85, %r84; 
(EngineCore_DP0 pid=334031) 
(EngineCore_DP0 pid=334031) 	// end inline asm
(EngineCore_DP0 pid=334031) 	.loc	1 220 27                        // quant_slide_tuned_Llama3.2-1B.py:220:27
(EngineCore_DP0 pid=334031) 	mul.f32 	%r103, %r14, %r96;
(EngineCore_DP0 pid=334031) 	.loc	1 220 48                        // quant_slide_tuned_Llama3.2-1B.py:220:48
(EngineCore_DP0 pid=334031) 	min.xorsign.abs.f32 	%r86, %r103, %r102;
(EngineCore_DP0 pid=334031) 	.loc	1 220 60                        // quant_slide_tuned_Llama3.2-1B.py:220:60
(EngineCore_DP0 pid=334031) 	// begin inline asm
(EngineCore_DP0 pid=334031) 	cvt.rn.satfinite.e4m3x2.f32  %rs57, %r87, %r86; 
(EngineCore_DP0 pid=334031) 
(EngineCore_DP0 pid=334031) 	// end inline asm
(EngineCore_DP0 pid=334031) 	.loc	1 221 27                        // quant_slide_tuned_Llama3.2-1B.py:221:27
(EngineCore_DP0 pid=334031) 	mul.f32 	%r104, %r14, %r98;
(EngineCore_DP0 pid=334031) 	.loc	1 221 48                        // quant_slide_tuned_Llama3.2-1B.py:221:48
(EngineCore_DP0 pid=334031) 	min.xorsign.abs.f32 	%r88, %r104, %r102;
(EngineCore_DP0 pid=334031) 	.loc	1 221 60                        // quant_slide_tuned_Llama3.2-1B.py:221:60
(EngineCore_DP0 pid=334031) 	// begin inline asm
(EngineCore_DP0 pid=334031) 	cvt.rn.satfinite.e4m3x2.f32  %rs58, %r89, %r88; 
(EngineCore_DP0 pid=334031) 
(EngineCore_DP0 pid=334031) 	// end inline asm
(EngineCore_DP0 pid=334031) 	.loc	1 222 27                        // quant_slide_tuned_Llama3.2-1B.py:222:27
(EngineCore_DP0 pid=334031) 	mul.f32 	%r105, %r14, %r100;
(EngineCore_DP0 pid=334031) 	.loc	1 222 48                        // quant_slide_tuned_Llama3.2-1B.py:222:48
(EngineCore_DP0 pid=334031) 	min.xorsign.abs.f32 	%r90, %r105, %r102;
(EngineCore_DP0 pid=334031) 	.loc	1 222 60                        // quant_slide_tuned_Llama3.2-1B.py:222:60
(EngineCore_DP0 pid=334031) 	// begin inline asm
(EngineCore_DP0 pid=334031) 	cvt.rn.satfinite.e4m3x2.f32  %rs59, %r91, %r90; 
(EngineCore_DP0 pid=334031) 
(EngineCore_DP0 pid=334031) 	// end inline asm
(EngineCore_DP0 pid=334031) 	.loc	1 224 45                        // quant_slide_tuned_Llama3.2-1B.py:224:45
(EngineCore_DP0 pid=334031) 	cvt.u32.u16 	%r106, %rs56;
(EngineCore_DP0 pid=334031) 	and.b32 	%r107, %r106, 255;
(EngineCore_DP0 pid=334031) 	.loc	1 226 45                        // quant_slide_tuned_Llama3.2-1B.py:226:45
(EngineCore_DP0 pid=334031) 	cvt.u32.u16 	%r108, %rs58;
(EngineCore_DP0 pid=334031) 	and.b32 	%r109, %r108, 255;
(EngineCore_DP0 pid=334031) 	.loc	1 227 45                        // quant_slide_tuned_Llama3.2-1B.py:227:45
(EngineCore_DP0 pid=334031) 	cvt.u32.u16 	%r110, %rs59;
(EngineCore_DP0 pid=334031) 	.loc	1 229 30                        // quant_slide_tuned_Llama3.2-1B.py:229:30
(EngineCore_DP0 pid=334031) 	and.b16 	%rs60, %rs57, 255;
(EngineCore_DP0 pid=334031) 	mul.wide.u16 	%r111, %rs60, 256;
(EngineCore_DP0 pid=334031) 	.loc	1 229 24                        // quant_slide_tuned_Llama3.2-1B.py:229:24
(EngineCore_DP0 pid=334031) 	or.b32 	%r112, %r111, %r107;
(EngineCore_DP0 pid=334031) 	.loc	1 229 42                        // quant_slide_tuned_Llama3.2-1B.py:229:42
(EngineCore_DP0 pid=334031) 	shl.b32 	%r113, %r109, 16;
(EngineCore_DP0 pid=334031) 	.loc	1 229 36                        // quant_slide_tuned_Llama3.2-1B.py:229:36
(EngineCore_DP0 pid=334031) 	or.b32 	%r114, %r112, %r113;
(EngineCore_DP0 pid=334031) 	.loc	1 229 55                        // quant_slide_tuned_Llama3.2-1B.py:229:55
(EngineCore_DP0 pid=334031) 	shl.b32 	%r115, %r110, 24;
(EngineCore_DP0 pid=334031) 	.loc	1 229 49                        // quant_slide_tuned_Llama3.2-1B.py:229:49
(EngineCore_DP0 pid=334031) 	or.b32 	%r92, %r114, %r115;
(EngineCore_DP0 pid=334031) 	.loc	1 230 29                        // quant_slide_tuned_Llama3.2-1B.py:230:29
(EngineCore_DP0 pid=334031) 	mad.wide.s32 	%rd13, %r93, 4, %rd2;
(EngineCore_DP0 pid=334031) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-1B.py:230:39
(EngineCore_DP0 pid=334031) 	// begin inline asm
(EngineCore_DP0 pid=334031) 	@%p14 st.global.b32 [ %rd13 + 0 ], { %r92 };
(EngineCore_DP0 pid=334031) 	// end inline asm
(EngineCore_DP0 pid=334031) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=334031) 	add.s32 	%r120, %r120, 512;
(EngineCore_DP0 pid=334031) 	add.s32 	%r119, %r119, 2048;
(EngineCore_DP0 pid=334031) 	setp.lt.s32 	%p19, %r120, %r22;
(EngineCore_DP0 pid=334031) 	@%p19 bra 	$L__BB0_6;
(EngineCore_DP0 pid=334031) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=334031) 	.loc	1 201 4                         // quant_slide_tuned_Llama3.2-1B.py:201:4
(EngineCore_DP0 pid=334031) 	ret;
(EngineCore_DP0 pid=334031) $L__tmp3:
(EngineCore_DP0 pid=334031) $L__func_end0:
(EngineCore_DP0 pid=334031)                                         // -- End function
(EngineCore_DP0 pid=334031) }
(EngineCore_DP0 pid=334031) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=334031) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=334031) 	.section	.debug_abbrev
(EngineCore_DP0 pid=334031) 	{
(EngineCore_DP0 pid=334031) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=334031) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=334031) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=334031) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=334031) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=334031) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=334031) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=334031) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=334031) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=334031) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=334031) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=334031) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=334031) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=334031) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=334031) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=334031) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=334031) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=334031) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=334031) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=334031) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=334031) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=334031) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=334031) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=334031) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=334031) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=334031) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=334031) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=334031) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=334031) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=334031) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=334031) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=334031) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=334031) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=334031) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=334031) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=334031) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=334031) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=334031) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=334031) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=334031) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=334031) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=334031) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=334031) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=334031) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=334031) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=334031) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=334031) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=334031) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=334031) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=334031) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=334031) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=334031) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=334031) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=334031) 	}
(EngineCore_DP0 pid=334031) 	.section	.debug_info
(EngineCore_DP0 pid=334031) 	{
(EngineCore_DP0 pid=334031) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=334031) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=334031) .b8 0
(EngineCore_DP0 pid=334031) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=334031) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=334031) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=334031) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=334031) .b8 114
(EngineCore_DP0 pid=334031) .b8 105
(EngineCore_DP0 pid=334031) .b8 116
(EngineCore_DP0 pid=334031) .b8 111
(EngineCore_DP0 pid=334031) .b8 110
(EngineCore_DP0 pid=334031) .b8 0
(EngineCore_DP0 pid=334031) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=334031) .b8 0
(EngineCore_DP0 pid=334031) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=334031) .b8 117
(EngineCore_DP0 pid=334031) .b8 97
(EngineCore_DP0 pid=334031) .b8 110
(EngineCore_DP0 pid=334031) .b8 116
(EngineCore_DP0 pid=334031) .b8 95
(EngineCore_DP0 pid=334031) .b8 115
(EngineCore_DP0 pid=334031) .b8 108
(EngineCore_DP0 pid=334031) .b8 105
(EngineCore_DP0 pid=334031) .b8 100
(EngineCore_DP0 pid=334031) .b8 101
(EngineCore_DP0 pid=334031) .b8 95
(EngineCore_DP0 pid=334031) .b8 116
(EngineCore_DP0 pid=334031) .b8 117
(EngineCore_DP0 pid=334031) .b8 110
(EngineCore_DP0 pid=334031) .b8 101
(EngineCore_DP0 pid=334031) .b8 100
(EngineCore_DP0 pid=334031) .b8 95
(EngineCore_DP0 pid=334031) .b8 76
(EngineCore_DP0 pid=334031) .b8 108
(EngineCore_DP0 pid=334031) .b8 97
(EngineCore_DP0 pid=334031) .b8 109
(EngineCore_DP0 pid=334031) .b8 97
(EngineCore_DP0 pid=334031) .b8 51
(EngineCore_DP0 pid=334031) .b8 46
(EngineCore_DP0 pid=334031) .b8 50
(EngineCore_DP0 pid=334031) .b8 45
(EngineCore_DP0 pid=334031) .b8 49
(EngineCore_DP0 pid=334031) .b8 66
(EngineCore_DP0 pid=334031) .b8 46
(EngineCore_DP0 pid=334031) .b8 112
(EngineCore_DP0 pid=334031) .b8 121
(EngineCore_DP0 pid=334031) .b8 0
(EngineCore_DP0 pid=334031) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=334031) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=334031) .b8 114
(EngineCore_DP0 pid=334031) .b8 111
(EngineCore_DP0 pid=334031) .b8 111
(EngineCore_DP0 pid=334031) .b8 116
(EngineCore_DP0 pid=334031) .b8 47
(EngineCore_DP0 pid=334031) .b8 118
(EngineCore_DP0 pid=334031) .b8 108
(EngineCore_DP0 pid=334031) .b8 108
(EngineCore_DP0 pid=334031) .b8 109
(EngineCore_DP0 pid=334031) .b8 98
(EngineCore_DP0 pid=334031) .b8 101
(EngineCore_DP0 pid=334031) .b8 110
(EngineCore_DP0 pid=334031) .b8 99
(EngineCore_DP0 pid=334031) .b8 104
(EngineCore_DP0 pid=334031) .b8 47
(EngineCore_DP0 pid=334031) .b8 115
(EngineCore_DP0 pid=334031) .b8 108
(EngineCore_DP0 pid=334031) .b8 105
(EngineCore_DP0 pid=334031) .b8 100
(EngineCore_DP0 pid=334031) .b8 101
(EngineCore_DP0 pid=334031) .b8 115
(EngineCore_DP0 pid=334031) .b8 112
(EngineCore_DP0 pid=334031) .b8 97
(EngineCore_DP0 pid=334031) .b8 114
(EngineCore_DP0 pid=334031) .b8 115
(EngineCore_DP0 pid=334031) .b8 101
(EngineCore_DP0 pid=334031) .b8 47
(EngineCore_DP0 pid=334031) .b8 99
(EngineCore_DP0 pid=334031) .b8 115
(EngineCore_DP0 pid=334031) .b8 114
(EngineCore_DP0 pid=334031) .b8 99
(EngineCore_DP0 pid=334031) .b8 47
(EngineCore_DP0 pid=334031) .b8 102
(EngineCore_DP0 pid=334031) .b8 117
(EngineCore_DP0 pid=334031) .b8 115
(EngineCore_DP0 pid=334031) .b8 101
(EngineCore_DP0 pid=334031) .b8 100
(EngineCore_DP0 pid=334031) .b8 95
(EngineCore_DP0 pid=334031) .b8 113
(EngineCore_DP0 pid=334031) .b8 117
(EngineCore_DP0 pid=334031) .b8 97
(EngineCore_DP0 pid=334031) .b8 110
(EngineCore_DP0 pid=334031) .b8 116
(EngineCore_DP0 pid=334031) .b8 95
(EngineCore_DP0 pid=334031) .b8 115
(EngineCore_DP0 pid=334031) .b8 108
(EngineCore_DP0 pid=334031) .b8 105
(EngineCore_DP0 pid=334031) .b8 100
(EngineCore_DP0 pid=334031) .b8 101
(EngineCore_DP0 pid=334031) .b8 95
(EngineCore_DP0 pid=334031) .b8 116
(EngineCore_DP0 pid=334031) .b8 114
(EngineCore_DP0 pid=334031) .b8 105
(EngineCore_DP0 pid=334031) .b8 116
(EngineCore_DP0 pid=334031) .b8 111
(EngineCore_DP0 pid=334031) .b8 110
(EngineCore_DP0 pid=334031) .b8 47
(EngineCore_DP0 pid=334031) .b8 98
(EngineCore_DP0 pid=334031) .b8 117
(EngineCore_DP0 pid=334031) .b8 105
(EngineCore_DP0 pid=334031) .b8 108
(EngineCore_DP0 pid=334031) .b8 100
(EngineCore_DP0 pid=334031) .b8 47
(EngineCore_DP0 pid=334031) .b8 71
(EngineCore_DP0 pid=334031) .b8 66
(EngineCore_DP0 pid=334031) .b8 49
(EngineCore_DP0 pid=334031) .b8 48
(EngineCore_DP0 pid=334031) .b8 95
(EngineCore_DP0 pid=334031) .b8 99
(EngineCore_DP0 pid=334031) .b8 99
(EngineCore_DP0 pid=334031) .b8 49
(EngineCore_DP0 pid=334031) .b8 50
(EngineCore_DP0 pid=334031) .b8 49
(EngineCore_DP0 pid=334031) .b8 95
(EngineCore_DP0 pid=334031) .b8 112
(EngineCore_DP0 pid=334031) .b8 121
(EngineCore_DP0 pid=334031) .b8 51
(EngineCore_DP0 pid=334031) .b8 49
(EngineCore_DP0 pid=334031) .b8 50
(EngineCore_DP0 pid=334031) .b8 95
(EngineCore_DP0 pid=334031) .b8 99
(EngineCore_DP0 pid=334031) .b8 117
(EngineCore_DP0 pid=334031) .b8 49
(EngineCore_DP0 pid=334031) .b8 50
(EngineCore_DP0 pid=334031) .b8 57
(EngineCore_DP0 pid=334031) .b8 95
(EngineCore_DP0 pid=334031) .b8 97
(EngineCore_DP0 pid=334031) .b8 97
(EngineCore_DP0 pid=334031) .b8 114
(EngineCore_DP0 pid=334031) .b8 99
(EngineCore_DP0 pid=334031) .b8 104
(EngineCore_DP0 pid=334031) .b8 54
(EngineCore_DP0 pid=334031) .b8 52
(EngineCore_DP0 pid=334031) .b8 0
(EngineCore_DP0 pid=334031) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=334031) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=334031) .b8 113
(EngineCore_DP0 pid=334031) .b8 117
(EngineCore_DP0 pid=334031) .b8 97
(EngineCore_DP0 pid=334031) .b8 110
(EngineCore_DP0 pid=334031) .b8 116
(EngineCore_DP0 pid=334031) .b8 95
(EngineCore_DP0 pid=334031) .b8 115
(EngineCore_DP0 pid=334031) .b8 108
(EngineCore_DP0 pid=334031) .b8 105
(EngineCore_DP0 pid=334031) .b8 100
(EngineCore_DP0 pid=334031) .b8 101
(EngineCore_DP0 pid=334031) .b8 95
(EngineCore_DP0 pid=334031) .b8 102
(EngineCore_DP0 pid=334031) .b8 112
(EngineCore_DP0 pid=334031) .b8 56
(EngineCore_DP0 pid=334031) .b8 95
(EngineCore_DP0 pid=334031) .b8 107
(EngineCore_DP0 pid=334031) .b8 101
(EngineCore_DP0 pid=334031) .b8 114
(EngineCore_DP0 pid=334031) .b8 110
(EngineCore_DP0 pid=334031) .b8 101
(EngineCore_DP0 pid=334031) .b8 108
(EngineCore_DP0 pid=334031) .b8 0
(EngineCore_DP0 pid=334031) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=334031) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=334031) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=334031) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=334031) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=334031) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=334031) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=334031) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=334031) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=334031) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=334031) .b8 191                                 // DW_AT_call_line
(EngineCore_DP0 pid=334031) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=334031) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=334031) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=334031) 	}
(EngineCore_DP0 pid=334031) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=334031) 
(EngineCore_DP0 pid=334031) ================================================================
(EngineCore_DP0 pid=334031) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=334031) 
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpoq2gu842.ptx', '-o', '/tmp/tmpoq2gu842.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866] 
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866] 
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866] 
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpoq2gu842.ptx -o /tmp/tmpoq2gu842.ptx.o
(EngineCore_DP0 pid=334031) ERROR 01-25 19:14:08 [core.py:866] 

STDERR:
[2026-01-25 19:13:54] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:13:54] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:13:54] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:13:54] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:13:54] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:13:54] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:13:54] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:13:54] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:13:54] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:13:54] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:13:54] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:13:54] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:13:54] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:13:54] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:13:58] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:13:58] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:13:58] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:13:58] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:13:58] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:13:58] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:13:58] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:13:58] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:13:58] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:13:58] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:13:58] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:13:58] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:13:58] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:13:58] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=334031) [2026-01-25 19:13:59] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=334031) [2026-01-25 19:13:59] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=334031) [2026-01-25 19:13:59] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=334031) [2026-01-25 19:13:59] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=334031) [2026-01-25 19:13:59] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=334031) [2026-01-25 19:13:59] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=334031) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=334031) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.23s/it]
(EngineCore_DP0 pid=334031) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.23s/it]
(EngineCore_DP0 pid=334031) 
(EngineCore_DP0 pid=334031) [2026-01-25 19:14:07] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=334031) [2026-01-25 19:14:07] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=334031) [2026-01-25 19:14:07] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=334031) [2026-01-25 19:14:07] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 2621440 bytes
(EngineCore_DP0 pid=334031) [2026-01-25 19:14:07] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=334031) [2026-01-25 19:14:07] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 20971520 bytes
(EngineCore_DP0 pid=334031) [2026-01-25 19:14:07] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=334031) [2026-01-25 19:14:07] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10485760 bytes
(EngineCore_DP0 pid=334031) Process EngineCore_DP0:
(EngineCore_DP0 pid=334031) Traceback (most recent call last):
(EngineCore_DP0 pid=334031)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=334031)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=334031)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=334031)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=334031) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpoq2gu842.ptx', '-o', '/tmp/tmpoq2gu842.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=334031) 
(EngineCore_DP0 pid=334031) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=334031) 
(EngineCore_DP0 pid=334031) Traceback (most recent call last):
(EngineCore_DP0 pid=334031)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=334031)     self.run()
(EngineCore_DP0 pid=334031)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=334031)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=334031)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=334031)     raise e
(EngineCore_DP0 pid=334031)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=334031)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=334031)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=334031)     super().__init__(
(EngineCore_DP0 pid=334031)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=334031)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=334031)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=334031)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=334031)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=334031)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=334031)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=334031)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=334031)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=334031)     return func(*args, **kwargs)
(EngineCore_DP0 pid=334031)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=334031)     return func(*args, **kwargs)
(EngineCore_DP0 pid=334031)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=334031)     self.model_runner.profile_run()
(EngineCore_DP0 pid=334031)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=334031)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=334031)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=334031)     return func(*args, **kwargs)
(EngineCore_DP0 pid=334031)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=334031)     outputs = self.model(
(EngineCore_DP0 pid=334031)               ^^^^^^^^^^^
(EngineCore_DP0 pid=334031)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=334031)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=334031)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=334031)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=334031)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=334031)     model_output = self.model(
(EngineCore_DP0 pid=334031)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=334031)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=334031)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=334031)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=334031)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=334031)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=334031)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=334031)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=334031)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=334031)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=334031)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=334031)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=334031)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=334031)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=334031)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=334031)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=334031)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=334031)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=334031)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=334031)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=334031)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=334031)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=334031)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=334031)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=334031)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=334031)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=334031)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=334031)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=334031)     return self._linear_fn(
(EngineCore_DP0 pid=334031)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=334031)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=334031)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=334031)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=334031)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=334031)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=334031)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=334031)     return fn(input, L)
(EngineCore_DP0 pid=334031)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=334031)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=334031)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=334031)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=334031)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=334031)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=334031)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=334031)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=334031)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=334031)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=334031)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=334031)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=334031)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=334031)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334031)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=334031)     raise PTXASError(error)
(EngineCore_DP0 pid=334031) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=334031) `ptxas` stderr:
(EngineCore_DP0 pid=334031) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=334031) 
(EngineCore_DP0 pid=334031) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpoq2gu842.ptx -o /tmp/tmpoq2gu842.ptx.o
(EngineCore_DP0 pid=334031) 
[rank0]:[W125 19:14:08.159356120 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=2048

========== M=4096 ==========
Time: 2026-01-25 19:14:10
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Llama3.2-1B-FP8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:14:15 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:14:15 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=334505) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=334505) 
(EngineCore_DP0 pid=334505) 
(EngineCore_DP0 pid=334505) ================================================================
(EngineCore_DP0 pid=334505) Internal Triton PTX codegen error
(EngineCore_DP0 pid=334505) `ptxas` stderr:
(EngineCore_DP0 pid=334505) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=334505) 
(EngineCore_DP0 pid=334505) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpngopbul7.ptx -o /tmp/tmpngopbul7.ptx.o
(EngineCore_DP0 pid=334505) 
(EngineCore_DP0 pid=334505) 
(EngineCore_DP0 pid=334505) //
(EngineCore_DP0 pid=334505) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=334505) //
(EngineCore_DP0 pid=334505) 
(EngineCore_DP0 pid=334505) .version 8.7
(EngineCore_DP0 pid=334505) .target sm_121a
(EngineCore_DP0 pid=334505) .address_size 64
(EngineCore_DP0 pid=334505) 
(EngineCore_DP0 pid=334505) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=334505) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=334505)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=334505) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=334505) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=334505) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=334505) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=334505) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=334505) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=334505) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=334505) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=334505) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=334505) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=334505) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=334505) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=334505) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=334505) )
(EngineCore_DP0 pid=334505) .reqntid 512
(EngineCore_DP0 pid=334505) {
(EngineCore_DP0 pid=334505) 	.reg .pred 	%p<21>;
(EngineCore_DP0 pid=334505) 	.reg .b16 	%rs<61>;
(EngineCore_DP0 pid=334505) 	.reg .b32 	%r<121>;
(EngineCore_DP0 pid=334505) 	.reg .b64 	%rd<14>;
(EngineCore_DP0 pid=334505) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=334505) $L__func_begin0:
(EngineCore_DP0 pid=334505) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=334505) 
(EngineCore_DP0 pid=334505) // %bb.0:
(EngineCore_DP0 pid=334505) 	ld.param.b32 	%r22, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=334505) 	ld.param.b32 	%r21, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=334505) 	ld.param.b32 	%r20, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=334505) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=334505) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=334505) $L__tmp0:
(EngineCore_DP0 pid=334505) 	.loc	1 177 24                        // quant_slide_tuned_Llama3.2-1B.py:177:24
(EngineCore_DP0 pid=334505) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=334505) 	ld.param.b32 	%r24, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=334505) 	.loc	1 182 26                        // quant_slide_tuned_Llama3.2-1B.py:182:26
(EngineCore_DP0 pid=334505) 	mul.lo.s32 	%r25, %r24, %r1;
(EngineCore_DP0 pid=334505) 	.loc	1 182 20                        // quant_slide_tuned_Llama3.2-1B.py:182:20
(EngineCore_DP0 pid=334505) 	mad.wide.s32 	%rd1, %r25, 2, %rd4;
(EngineCore_DP0 pid=334505) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=334505) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=334505) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=334505) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=334505) 	setp.lt.s32 	%p1, %r21, 1;
(EngineCore_DP0 pid=334505) 	mov.b32 	%r118, 0f2B8CBCCC;
(EngineCore_DP0 pid=334505) 	setp.eq.b32 	%p20, %r2, 0;
(EngineCore_DP0 pid=334505) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=334505) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=334505) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=334505) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=334505) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=334505) 	shr.u32 	%r34, %r2, 3;
(EngineCore_DP0 pid=334505) 	and.b32 	%r35, %r34, 60;
(EngineCore_DP0 pid=334505) 	mov.b32 	%r36, global_smem;
(EngineCore_DP0 pid=334505) 	add.s32 	%r54, %r36, %r35;
(EngineCore_DP0 pid=334505) 	shl.b32 	%r37, %r2, 2;
(EngineCore_DP0 pid=334505) 	add.s32 	%r57, %r36, %r37;
(EngineCore_DP0 pid=334505) 	mov.b32 	%r42, 0;
(EngineCore_DP0 pid=334505) 	mov.b32 	%r116, 0f00000000;
(EngineCore_DP0 pid=334505) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=334505) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=334505) 	mov.b32 	%r117, %r42;
(EngineCore_DP0 pid=334505) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=334505) 	.loc	1 188 19                        // quant_slide_tuned_Llama3.2-1B.py:188:19
(EngineCore_DP0 pid=334505) 	add.s32 	%r60, %r4, %r117;
(EngineCore_DP0 pid=334505) 	.loc	1 189 22                        // quant_slide_tuned_Llama3.2-1B.py:189:22
(EngineCore_DP0 pid=334505) 	add.s32 	%r61, %r60, 4096;
(EngineCore_DP0 pid=334505) 	setp.lt.s32 	%p2, %r60, %r20;
(EngineCore_DP0 pid=334505) 	setp.lt.s32 	%p3, %r61, %r20;
(EngineCore_DP0 pid=334505) 	.loc	1 190 29                        // quant_slide_tuned_Llama3.2-1B.py:190:29
(EngineCore_DP0 pid=334505) 	mad.wide.s32 	%rd6, %r60, 2, %rd1;
(EngineCore_DP0 pid=334505) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=334505) 	.loc	1 190 21                        // quant_slide_tuned_Llama3.2-1B.py:190:21
(EngineCore_DP0 pid=334505) 	// begin inline asm
(EngineCore_DP0 pid=334505) 	mov.u32 %r38, %r42;
(EngineCore_DP0 pid=334505) 	mov.u32 %r39, %r42;
(EngineCore_DP0 pid=334505) 	mov.u32 %r40, %r42;
(EngineCore_DP0 pid=334505) 	mov.u32 %r41, %r42;
(EngineCore_DP0 pid=334505) 	@%p2 ld.global.v4.b32 { %r38, %r39, %r40, %r41 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=334505) 	// end inline asm
(EngineCore_DP0 pid=334505) 	mov.b32 	{%rs1, %rs2}, %r38;
(EngineCore_DP0 pid=334505) 	mov.b32 	{%rs3, %rs4}, %r39;
(EngineCore_DP0 pid=334505) 	mov.b32 	{%rs5, %rs6}, %r40;
(EngineCore_DP0 pid=334505) 	mov.b32 	{%rs7, %rs8}, %r41;
(EngineCore_DP0 pid=334505) 	// begin inline asm
(EngineCore_DP0 pid=334505) 	mov.u32 %r46, %r42;
(EngineCore_DP0 pid=334505) 	mov.u32 %r47, %r42;
(EngineCore_DP0 pid=334505) 	mov.u32 %r48, %r42;
(EngineCore_DP0 pid=334505) 	mov.u32 %r49, %r42;
(EngineCore_DP0 pid=334505) 	@%p3 ld.global.v4.b32 { %r46, %r47, %r48, %r49 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=334505) 	// end inline asm
(EngineCore_DP0 pid=334505) 	mov.b32 	{%rs9, %rs10}, %r46;
(EngineCore_DP0 pid=334505) 	mov.b32 	{%rs11, %rs12}, %r47;
(EngineCore_DP0 pid=334505) 	mov.b32 	{%rs13, %rs14}, %r48;
(EngineCore_DP0 pid=334505) 	mov.b32 	{%rs15, %rs16}, %r49;
(EngineCore_DP0 pid=334505) 	.loc	1 191 50                        // quant_slide_tuned_Llama3.2-1B.py:191:50
(EngineCore_DP0 pid=334505) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=334505) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=334505) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=334505) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=334505) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=334505) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=334505) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=334505) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=334505) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=334505) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=334505) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=334505) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=334505) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=334505) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=334505) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=334505) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=334505) $L__tmp1:
(EngineCore_DP0 pid=334505) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=334505) 	bar.sync 	0;
(EngineCore_DP0 pid=334505) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=334505) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=334505) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=334505) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=334505) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=334505) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=334505) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=334505) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=334505) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=334505) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=334505) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=334505) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=334505) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=334505) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=334505) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=334505) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=334505) 	cvt.f32.bf16 	%r62, %rs47;
(EngineCore_DP0 pid=334505) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=334505) 	shfl.sync.bfly.b32 	%r63, %r62, 16, 31, -1;
(EngineCore_DP0 pid=334505) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=334505) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=334505) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=334505) 	shfl.sync.bfly.b32 	%r65, %r64, 8, 31, -1;
(EngineCore_DP0 pid=334505) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=334505) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=334505) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=334505) 	shfl.sync.bfly.b32 	%r67, %r66, 4, 31, -1;
(EngineCore_DP0 pid=334505) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=334505) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=334505) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=334505) 	shfl.sync.bfly.b32 	%r69, %r68, 2, 31, -1;
(EngineCore_DP0 pid=334505) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=334505) 	max.f32 	%r70, %r68, %r69;
(EngineCore_DP0 pid=334505) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=334505) 	shfl.sync.bfly.b32 	%r71, %r70, 1, 31, -1;
(EngineCore_DP0 pid=334505) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=334505) 	max.f32 	%r55, %r70, %r71;
(EngineCore_DP0 pid=334505) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=334505) 	// begin inline asm
(EngineCore_DP0 pid=334505) 	@%p4 st.shared.b32 [ %r54 + 0 ], %r55;
(EngineCore_DP0 pid=334505) 	// end inline asm
(EngineCore_DP0 pid=334505) 	bar.sync 	0;
(EngineCore_DP0 pid=334505) 	// begin inline asm
(EngineCore_DP0 pid=334505) 	@%p5 ld.shared.b32 %r56, [ %r57 + 0 ];
(EngineCore_DP0 pid=334505) 	// end inline asm
(EngineCore_DP0 pid=334505) 	shfl.sync.bfly.b32 	%r72, %r56, 8, 31, -1;
(EngineCore_DP0 pid=334505) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=334505) 	max.f32 	%r73, %r56, %r72;
(EngineCore_DP0 pid=334505) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=334505) 	shfl.sync.bfly.b32 	%r74, %r73, 4, 31, -1;
(EngineCore_DP0 pid=334505) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=334505) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=334505) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=334505) 	shfl.sync.bfly.b32 	%r76, %r75, 2, 31, -1;
(EngineCore_DP0 pid=334505) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=334505) 	max.f32 	%r77, %r75, %r76;
(EngineCore_DP0 pid=334505) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=334505) 	shfl.sync.bfly.b32 	%r78, %r77, 1, 31, -1;
(EngineCore_DP0 pid=334505) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=334505) 	max.f32 	%r59, %r77, %r78;
(EngineCore_DP0 pid=334505) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=334505) 	// begin inline asm
(EngineCore_DP0 pid=334505) 	@%p20 st.shared.b32 [ %r57 + 0 ], %r59;
(EngineCore_DP0 pid=334505) 	// end inline asm
(EngineCore_DP0 pid=334505) 	bar.sync 	0;
(EngineCore_DP0 pid=334505) 	ld.shared.b32 	%r79, [global_smem];
(EngineCore_DP0 pid=334505) $L__tmp2:
(EngineCore_DP0 pid=334505) 	.loc	1 191 36                        // quant_slide_tuned_Llama3.2-1B.py:191:36
(EngineCore_DP0 pid=334505) 	max.f32 	%r116, %r116, %r79;
(EngineCore_DP0 pid=334505) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=334505) 	add.s32 	%r117, %r117, 8192;
(EngineCore_DP0 pid=334505) 	setp.lt.s32 	%p7, %r117, %r21;
(EngineCore_DP0 pid=334505) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=334505) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=334505) 	.loc	1 193 32                        // quant_slide_tuned_Llama3.2-1B.py:193:32
(EngineCore_DP0 pid=334505) 	max.f32 	%r118, %r116, 0f2B8CBCCC;
(EngineCore_DP0 pid=334505) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=334505) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=334505) 	mov.b32 	%r81, 0f43E00000;
(EngineCore_DP0 pid=334505) 	.loc	1 194 32                        // quant_slide_tuned_Llama3.2-1B.py:194:32
(EngineCore_DP0 pid=334505) 	div.full.f32 	%r82, %r118, %r81;
(EngineCore_DP0 pid=334505) 	.loc	1 194 41                        // quant_slide_tuned_Llama3.2-1B.py:194:41
(EngineCore_DP0 pid=334505) 	max.f32 	%r80, %r82, 0f36924925;
(EngineCore_DP0 pid=334505) 	.loc	1 196 25                        // quant_slide_tuned_Llama3.2-1B.py:196:25
(EngineCore_DP0 pid=334505) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=334505) 	.loc	1 196 30                        // quant_slide_tuned_Llama3.2-1B.py:196:30
(EngineCore_DP0 pid=334505) 	// begin inline asm
(EngineCore_DP0 pid=334505) 	@%p20 st.global.b32 [ %rd8 + 0 ], { %r80 };
(EngineCore_DP0 pid=334505) 	// end inline asm
(EngineCore_DP0 pid=334505) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=334505) 	setp.lt.s32 	%p9, %r22, 1;
(EngineCore_DP0 pid=334505) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=334505) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=334505) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=334505) 	ld.param.b32 	%r26, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=334505) 	shr.s32 	%r27, %r26, 31;
(EngineCore_DP0 pid=334505) 	shr.u32 	%r28, %r27, 30;
(EngineCore_DP0 pid=334505) 	add.s32 	%r29, %r26, %r28;
(EngineCore_DP0 pid=334505) 	shr.s32 	%r30, %r29, 2;
(EngineCore_DP0 pid=334505) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=334505) 	mul.lo.s32 	%r31, %r30, %r1;
(EngineCore_DP0 pid=334505) 	mad.wide.s32 	%rd2, %r31, 4, %rd5;
(EngineCore_DP0 pid=334505) 	div.full.f32 	%r14, %r81, %r118;
(EngineCore_DP0 pid=334505) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=334505) 	shl.b32 	%r119, %r3, 2;
(EngineCore_DP0 pid=334505) 	mov.b32 	%r120, 0;
(EngineCore_DP0 pid=334505) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=334505)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=334505) 	.loc	1 203 30                        // quant_slide_tuned_Llama3.2-1B.py:203:30
(EngineCore_DP0 pid=334505) 	add.s32 	%r93, %r3, %r120;
(EngineCore_DP0 pid=334505) 	setp.lt.s32 	%p14, %r93, %r22;
(EngineCore_DP0 pid=334505) 	.loc	1 211 53                        // quant_slide_tuned_Llama3.2-1B.py:211:53
(EngineCore_DP0 pid=334505) 	setp.lt.s32 	%p15, %r119, %r20;
(EngineCore_DP0 pid=334505) 	.loc	1 211 37                        // quant_slide_tuned_Llama3.2-1B.py:211:37
(EngineCore_DP0 pid=334505) 	and.pred 	%p10, %p14, %p15;
(EngineCore_DP0 pid=334505) 	.loc	1 210 29                        // quant_slide_tuned_Llama3.2-1B.py:210:29
(EngineCore_DP0 pid=334505) 	mad.wide.s32 	%rd9, %r119, 2, %rd1;
(EngineCore_DP0 pid=334505) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=334505) 	.loc	1 210 21                        // quant_slide_tuned_Llama3.2-1B.py:210:21
(EngineCore_DP0 pid=334505) 	// begin inline asm
(EngineCore_DP0 pid=334505) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=334505) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=334505) 	// end inline asm
(EngineCore_DP0 pid=334505) 	.loc	1 211 79                        // quant_slide_tuned_Llama3.2-1B.py:211:79
(EngineCore_DP0 pid=334505) 	cvt.f32.bf16 	%r94, %rs48;
(EngineCore_DP0 pid=334505) 	.loc	1 213 53                        // quant_slide_tuned_Llama3.2-1B.py:213:53
(EngineCore_DP0 pid=334505) 	add.s32 	%r95, %r119, 1;
(EngineCore_DP0 pid=334505) 	setp.lt.s32 	%p16, %r95, %r20;
(EngineCore_DP0 pid=334505) 	.loc	1 213 37                        // quant_slide_tuned_Llama3.2-1B.py:213:37
(EngineCore_DP0 pid=334505) 	and.pred 	%p11, %p14, %p16;
(EngineCore_DP0 pid=334505) 	.loc	1 212 39                        // quant_slide_tuned_Llama3.2-1B.py:212:39
(EngineCore_DP0 pid=334505) 	add.s64 	%rd10, %rd9, 2;
(EngineCore_DP0 pid=334505) 	.loc	1 212 21                        // quant_slide_tuned_Llama3.2-1B.py:212:21
(EngineCore_DP0 pid=334505) 	// begin inline asm
(EngineCore_DP0 pid=334505) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=334505) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=334505) 	// end inline asm
(EngineCore_DP0 pid=334505) 	.loc	1 213 79                        // quant_slide_tuned_Llama3.2-1B.py:213:79
(EngineCore_DP0 pid=334505) 	cvt.f32.bf16 	%r96, %rs50;
(EngineCore_DP0 pid=334505) 	.loc	1 215 53                        // quant_slide_tuned_Llama3.2-1B.py:215:53
(EngineCore_DP0 pid=334505) 	add.s32 	%r97, %r119, 2;
(EngineCore_DP0 pid=334505) 	setp.lt.s32 	%p17, %r97, %r20;
(EngineCore_DP0 pid=334505) 	.loc	1 215 37                        // quant_slide_tuned_Llama3.2-1B.py:215:37
(EngineCore_DP0 pid=334505) 	and.pred 	%p12, %p14, %p17;
(EngineCore_DP0 pid=334505) 	.loc	1 214 39                        // quant_slide_tuned_Llama3.2-1B.py:214:39
(EngineCore_DP0 pid=334505) 	add.s64 	%rd11, %rd9, 4;
(EngineCore_DP0 pid=334505) 	.loc	1 214 21                        // quant_slide_tuned_Llama3.2-1B.py:214:21
(EngineCore_DP0 pid=334505) 	// begin inline asm
(EngineCore_DP0 pid=334505) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=334505) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=334505) 	// end inline asm
(EngineCore_DP0 pid=334505) 	.loc	1 215 79                        // quant_slide_tuned_Llama3.2-1B.py:215:79
(EngineCore_DP0 pid=334505) 	cvt.f32.bf16 	%r98, %rs52;
(EngineCore_DP0 pid=334505) 	.loc	1 217 53                        // quant_slide_tuned_Llama3.2-1B.py:217:53
(EngineCore_DP0 pid=334505) 	add.s32 	%r99, %r119, 3;
(EngineCore_DP0 pid=334505) 	setp.lt.s32 	%p18, %r99, %r20;
(EngineCore_DP0 pid=334505) 	.loc	1 217 37                        // quant_slide_tuned_Llama3.2-1B.py:217:37
(EngineCore_DP0 pid=334505) 	and.pred 	%p13, %p14, %p18;
(EngineCore_DP0 pid=334505) 	.loc	1 216 39                        // quant_slide_tuned_Llama3.2-1B.py:216:39
(EngineCore_DP0 pid=334505) 	add.s64 	%rd12, %rd9, 6;
(EngineCore_DP0 pid=334505) 	.loc	1 216 21                        // quant_slide_tuned_Llama3.2-1B.py:216:21
(EngineCore_DP0 pid=334505) 	// begin inline asm
(EngineCore_DP0 pid=334505) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=334505) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=334505) 	// end inline asm
(EngineCore_DP0 pid=334505) 	.loc	1 217 79                        // quant_slide_tuned_Llama3.2-1B.py:217:79
(EngineCore_DP0 pid=334505) 	cvt.f32.bf16 	%r100, %rs54;
(EngineCore_DP0 pid=334505) 	.loc	1 219 27                        // quant_slide_tuned_Llama3.2-1B.py:219:27
(EngineCore_DP0 pid=334505) 	mul.f32 	%r101, %r14, %r94;
(EngineCore_DP0 pid=334505) 	mov.b32 	%r102, 0f43E00000;
(EngineCore_DP0 pid=334505) 	.loc	1 219 48                        // quant_slide_tuned_Llama3.2-1B.py:219:48
(EngineCore_DP0 pid=334505) 	min.xorsign.abs.f32 	%r84, %r101, %r102;
(EngineCore_DP0 pid=334505) 	.loc	1 219 60                        // quant_slide_tuned_Llama3.2-1B.py:219:60
(EngineCore_DP0 pid=334505) 	// begin inline asm
(EngineCore_DP0 pid=334505) 	cvt.rn.satfinite.e4m3x2.f32  %rs56, %r85, %r84; 
(EngineCore_DP0 pid=334505) 
(EngineCore_DP0 pid=334505) 	// end inline asm
(EngineCore_DP0 pid=334505) 	.loc	1 220 27                        // quant_slide_tuned_Llama3.2-1B.py:220:27
(EngineCore_DP0 pid=334505) 	mul.f32 	%r103, %r14, %r96;
(EngineCore_DP0 pid=334505) 	.loc	1 220 48                        // quant_slide_tuned_Llama3.2-1B.py:220:48
(EngineCore_DP0 pid=334505) 	min.xorsign.abs.f32 	%r86, %r103, %r102;
(EngineCore_DP0 pid=334505) 	.loc	1 220 60                        // quant_slide_tuned_Llama3.2-1B.py:220:60
(EngineCore_DP0 pid=334505) 	// begin inline asm
(EngineCore_DP0 pid=334505) 	cvt.rn.satfinite.e4m3x2.f32  %rs57, %r87, %r86; 
(EngineCore_DP0 pid=334505) 
(EngineCore_DP0 pid=334505) 	// end inline asm
(EngineCore_DP0 pid=334505) 	.loc	1 221 27                        // quant_slide_tuned_Llama3.2-1B.py:221:27
(EngineCore_DP0 pid=334505) 	mul.f32 	%r104, %r14, %r98;
(EngineCore_DP0 pid=334505) 	.loc	1 221 48                        // quant_slide_tuned_Llama3.2-1B.py:221:48
(EngineCore_DP0 pid=334505) 	min.xorsign.abs.f32 	%r88, %r104, %r102;
(EngineCore_DP0 pid=334505) 	.loc	1 221 60                        // quant_slide_tuned_Llama3.2-1B.py:221:60
(EngineCore_DP0 pid=334505) 	// begin inline asm
(EngineCore_DP0 pid=334505) 	cvt.rn.satfinite.e4m3x2.f32  %rs58, %r89, %r88; 
(EngineCore_DP0 pid=334505) 
(EngineCore_DP0 pid=334505) 	// end inline asm
(EngineCore_DP0 pid=334505) 	.loc	1 222 27                        // quant_slide_tuned_Llama3.2-1B.py:222:27
(EngineCore_DP0 pid=334505) 	mul.f32 	%r105, %r14, %r100;
(EngineCore_DP0 pid=334505) 	.loc	1 222 48                        // quant_slide_tuned_Llama3.2-1B.py:222:48
(EngineCore_DP0 pid=334505) 	min.xorsign.abs.f32 	%r90, %r105, %r102;
(EngineCore_DP0 pid=334505) 	.loc	1 222 60                        // quant_slide_tuned_Llama3.2-1B.py:222:60
(EngineCore_DP0 pid=334505) 	// begin inline asm
(EngineCore_DP0 pid=334505) 	cvt.rn.satfinite.e4m3x2.f32  %rs59, %r91, %r90; 
(EngineCore_DP0 pid=334505) 
(EngineCore_DP0 pid=334505) 	// end inline asm
(EngineCore_DP0 pid=334505) 	.loc	1 224 45                        // quant_slide_tuned_Llama3.2-1B.py:224:45
(EngineCore_DP0 pid=334505) 	cvt.u32.u16 	%r106, %rs56;
(EngineCore_DP0 pid=334505) 	and.b32 	%r107, %r106, 255;
(EngineCore_DP0 pid=334505) 	.loc	1 226 45                        // quant_slide_tuned_Llama3.2-1B.py:226:45
(EngineCore_DP0 pid=334505) 	cvt.u32.u16 	%r108, %rs58;
(EngineCore_DP0 pid=334505) 	and.b32 	%r109, %r108, 255;
(EngineCore_DP0 pid=334505) 	.loc	1 227 45                        // quant_slide_tuned_Llama3.2-1B.py:227:45
(EngineCore_DP0 pid=334505) 	cvt.u32.u16 	%r110, %rs59;
(EngineCore_DP0 pid=334505) 	.loc	1 229 30                        // quant_slide_tuned_Llama3.2-1B.py:229:30
(EngineCore_DP0 pid=334505) 	and.b16 	%rs60, %rs57, 255;
(EngineCore_DP0 pid=334505) 	mul.wide.u16 	%r111, %rs60, 256;
(EngineCore_DP0 pid=334505) 	.loc	1 229 24                        // quant_slide_tuned_Llama3.2-1B.py:229:24
(EngineCore_DP0 pid=334505) 	or.b32 	%r112, %r111, %r107;
(EngineCore_DP0 pid=334505) 	.loc	1 229 42                        // quant_slide_tuned_Llama3.2-1B.py:229:42
(EngineCore_DP0 pid=334505) 	shl.b32 	%r113, %r109, 16;
(EngineCore_DP0 pid=334505) 	.loc	1 229 36                        // quant_slide_tuned_Llama3.2-1B.py:229:36
(EngineCore_DP0 pid=334505) 	or.b32 	%r114, %r112, %r113;
(EngineCore_DP0 pid=334505) 	.loc	1 229 55                        // quant_slide_tuned_Llama3.2-1B.py:229:55
(EngineCore_DP0 pid=334505) 	shl.b32 	%r115, %r110, 24;
(EngineCore_DP0 pid=334505) 	.loc	1 229 49                        // quant_slide_tuned_Llama3.2-1B.py:229:49
(EngineCore_DP0 pid=334505) 	or.b32 	%r92, %r114, %r115;
(EngineCore_DP0 pid=334505) 	.loc	1 230 29                        // quant_slide_tuned_Llama3.2-1B.py:230:29
(EngineCore_DP0 pid=334505) 	mad.wide.s32 	%rd13, %r93, 4, %rd2;
(EngineCore_DP0 pid=334505) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-1B.py:230:39
(EngineCore_DP0 pid=334505) 	// begin inline asm
(EngineCore_DP0 pid=334505) 	@%p14 st.global.b32 [ %rd13 + 0 ], { %r92 };
(EngineCore_DP0 pid=334505) 	// end inline asm
(EngineCore_DP0 pid=334505) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=334505) 	add.s32 	%r120, %r120, 512;
(EngineCore_DP0 pid=334505) 	add.s32 	%r119, %r119, 2048;
(EngineCore_DP0 pid=334505) 	setp.lt.s32 	%p19, %r120, %r22;
(EngineCore_DP0 pid=334505) 	@%p19 bra 	$L__BB0_6;
(EngineCore_DP0 pid=334505) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=334505) 	.loc	1 201 4                         // quant_slide_tuned_Llama3.2-1B.py:201:4
(EngineCore_DP0 pid=334505) 	ret;
(EngineCore_DP0 pid=334505) $L__tmp3:
(EngineCore_DP0 pid=334505) $L__func_end0:
(EngineCore_DP0 pid=334505)                                         // -- End function
(EngineCore_DP0 pid=334505) }
(EngineCore_DP0 pid=334505) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=334505) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=334505) 	.section	.debug_abbrev
(EngineCore_DP0 pid=334505) 	{
(EngineCore_DP0 pid=334505) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=334505) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=334505) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=334505) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=334505) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=334505) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=334505) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=334505) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=334505) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=334505) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=334505) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=334505) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=334505) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=334505) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=334505) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=334505) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=334505) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=334505) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=334505) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=334505) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=334505) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=334505) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=334505) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=334505) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=334505) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=334505) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=334505) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=334505) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=334505) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=334505) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=334505) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=334505) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=334505) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=334505) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=334505) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=334505) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=334505) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=334505) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=334505) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=334505) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=334505) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=334505) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=334505) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=334505) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=334505) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=334505) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=334505) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=334505) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=334505) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=334505) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=334505) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=334505) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=334505) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=334505) 	}
(EngineCore_DP0 pid=334505) 	.section	.debug_info
(EngineCore_DP0 pid=334505) 	{
(EngineCore_DP0 pid=334505) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=334505) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=334505) .b8 0
(EngineCore_DP0 pid=334505) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=334505) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=334505) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=334505) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=334505) .b8 114
(EngineCore_DP0 pid=334505) .b8 105
(EngineCore_DP0 pid=334505) .b8 116
(EngineCore_DP0 pid=334505) .b8 111
(EngineCore_DP0 pid=334505) .b8 110
(EngineCore_DP0 pid=334505) .b8 0
(EngineCore_DP0 pid=334505) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=334505) .b8 0
(EngineCore_DP0 pid=334505) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=334505) .b8 117
(EngineCore_DP0 pid=334505) .b8 97
(EngineCore_DP0 pid=334505) .b8 110
(EngineCore_DP0 pid=334505) .b8 116
(EngineCore_DP0 pid=334505) .b8 95
(EngineCore_DP0 pid=334505) .b8 115
(EngineCore_DP0 pid=334505) .b8 108
(EngineCore_DP0 pid=334505) .b8 105
(EngineCore_DP0 pid=334505) .b8 100
(EngineCore_DP0 pid=334505) .b8 101
(EngineCore_DP0 pid=334505) .b8 95
(EngineCore_DP0 pid=334505) .b8 116
(EngineCore_DP0 pid=334505) .b8 117
(EngineCore_DP0 pid=334505) .b8 110
(EngineCore_DP0 pid=334505) .b8 101
(EngineCore_DP0 pid=334505) .b8 100
(EngineCore_DP0 pid=334505) .b8 95
(EngineCore_DP0 pid=334505) .b8 76
(EngineCore_DP0 pid=334505) .b8 108
(EngineCore_DP0 pid=334505) .b8 97
(EngineCore_DP0 pid=334505) .b8 109
(EngineCore_DP0 pid=334505) .b8 97
(EngineCore_DP0 pid=334505) .b8 51
(EngineCore_DP0 pid=334505) .b8 46
(EngineCore_DP0 pid=334505) .b8 50
(EngineCore_DP0 pid=334505) .b8 45
(EngineCore_DP0 pid=334505) .b8 49
(EngineCore_DP0 pid=334505) .b8 66
(EngineCore_DP0 pid=334505) .b8 46
(EngineCore_DP0 pid=334505) .b8 112
(EngineCore_DP0 pid=334505) .b8 121
(EngineCore_DP0 pid=334505) .b8 0
(EngineCore_DP0 pid=334505) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=334505) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=334505) .b8 114
(EngineCore_DP0 pid=334505) .b8 111
(EngineCore_DP0 pid=334505) .b8 111
(EngineCore_DP0 pid=334505) .b8 116
(EngineCore_DP0 pid=334505) .b8 47
(EngineCore_DP0 pid=334505) .b8 118
(EngineCore_DP0 pid=334505) .b8 108
(EngineCore_DP0 pid=334505) .b8 108
(EngineCore_DP0 pid=334505) .b8 109
(EngineCore_DP0 pid=334505) .b8 98
(EngineCore_DP0 pid=334505) .b8 101
(EngineCore_DP0 pid=334505) .b8 110
(EngineCore_DP0 pid=334505) .b8 99
(EngineCore_DP0 pid=334505) .b8 104
(EngineCore_DP0 pid=334505) .b8 47
(EngineCore_DP0 pid=334505) .b8 115
(EngineCore_DP0 pid=334505) .b8 108
(EngineCore_DP0 pid=334505) .b8 105
(EngineCore_DP0 pid=334505) .b8 100
(EngineCore_DP0 pid=334505) .b8 101
(EngineCore_DP0 pid=334505) .b8 115
(EngineCore_DP0 pid=334505) .b8 112
(EngineCore_DP0 pid=334505) .b8 97
(EngineCore_DP0 pid=334505) .b8 114
(EngineCore_DP0 pid=334505) .b8 115
(EngineCore_DP0 pid=334505) .b8 101
(EngineCore_DP0 pid=334505) .b8 47
(EngineCore_DP0 pid=334505) .b8 99
(EngineCore_DP0 pid=334505) .b8 115
(EngineCore_DP0 pid=334505) .b8 114
(EngineCore_DP0 pid=334505) .b8 99
(EngineCore_DP0 pid=334505) .b8 47
(EngineCore_DP0 pid=334505) .b8 102
(EngineCore_DP0 pid=334505) .b8 117
(EngineCore_DP0 pid=334505) .b8 115
(EngineCore_DP0 pid=334505) .b8 101
(EngineCore_DP0 pid=334505) .b8 100
(EngineCore_DP0 pid=334505) .b8 95
(EngineCore_DP0 pid=334505) .b8 113
(EngineCore_DP0 pid=334505) .b8 117
(EngineCore_DP0 pid=334505) .b8 97
(EngineCore_DP0 pid=334505) .b8 110
(EngineCore_DP0 pid=334505) .b8 116
(EngineCore_DP0 pid=334505) .b8 95
(EngineCore_DP0 pid=334505) .b8 115
(EngineCore_DP0 pid=334505) .b8 108
(EngineCore_DP0 pid=334505) .b8 105
(EngineCore_DP0 pid=334505) .b8 100
(EngineCore_DP0 pid=334505) .b8 101
(EngineCore_DP0 pid=334505) .b8 95
(EngineCore_DP0 pid=334505) .b8 116
(EngineCore_DP0 pid=334505) .b8 114
(EngineCore_DP0 pid=334505) .b8 105
(EngineCore_DP0 pid=334505) .b8 116
(EngineCore_DP0 pid=334505) .b8 111
(EngineCore_DP0 pid=334505) .b8 110
(EngineCore_DP0 pid=334505) .b8 47
(EngineCore_DP0 pid=334505) .b8 98
(EngineCore_DP0 pid=334505) .b8 117
(EngineCore_DP0 pid=334505) .b8 105
(EngineCore_DP0 pid=334505) .b8 108
(EngineCore_DP0 pid=334505) .b8 100
(EngineCore_DP0 pid=334505) .b8 47
(EngineCore_DP0 pid=334505) .b8 71
(EngineCore_DP0 pid=334505) .b8 66
(EngineCore_DP0 pid=334505) .b8 49
(EngineCore_DP0 pid=334505) .b8 48
(EngineCore_DP0 pid=334505) .b8 95
(EngineCore_DP0 pid=334505) .b8 99
(EngineCore_DP0 pid=334505) .b8 99
(EngineCore_DP0 pid=334505) .b8 49
(EngineCore_DP0 pid=334505) .b8 50
(EngineCore_DP0 pid=334505) .b8 49
(EngineCore_DP0 pid=334505) .b8 95
(EngineCore_DP0 pid=334505) .b8 112
(EngineCore_DP0 pid=334505) .b8 121
(EngineCore_DP0 pid=334505) .b8 51
(EngineCore_DP0 pid=334505) .b8 49
(EngineCore_DP0 pid=334505) .b8 50
(EngineCore_DP0 pid=334505) .b8 95
(EngineCore_DP0 pid=334505) .b8 99
(EngineCore_DP0 pid=334505) .b8 117
(EngineCore_DP0 pid=334505) .b8 49
(EngineCore_DP0 pid=334505) .b8 50
(EngineCore_DP0 pid=334505) .b8 57
(EngineCore_DP0 pid=334505) .b8 95
(EngineCore_DP0 pid=334505) .b8 97
(EngineCore_DP0 pid=334505) .b8 97
(EngineCore_DP0 pid=334505) .b8 114
(EngineCore_DP0 pid=334505) .b8 99
(EngineCore_DP0 pid=334505) .b8 104
(EngineCore_DP0 pid=334505) .b8 54
(EngineCore_DP0 pid=334505) .b8 52
(EngineCore_DP0 pid=334505) .b8 0
(EngineCore_DP0 pid=334505) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=334505) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=334505) .b8 113
(EngineCore_DP0 pid=334505) .b8 117
(EngineCore_DP0 pid=334505) .b8 97
(EngineCore_DP0 pid=334505) .b8 110
(EngineCore_DP0 pid=334505) .b8 116
(EngineCore_DP0 pid=334505) .b8 95
(EngineCore_DP0 pid=334505) .b8 115
(EngineCore_DP0 pid=334505) .b8 108
(EngineCore_DP0 pid=334505) .b8 105
(EngineCore_DP0 pid=334505) .b8 100
(EngineCore_DP0 pid=334505) .b8 101
(EngineCore_DP0 pid=334505) .b8 95
(EngineCore_DP0 pid=334505) .b8 102
(EngineCore_DP0 pid=334505) .b8 112
(EngineCore_DP0 pid=334505) .b8 56
(EngineCore_DP0 pid=334505) .b8 95
(EngineCore_DP0 pid=334505) .b8 107
(EngineCore_DP0 pid=334505) .b8 101
(EngineCore_DP0 pid=334505) .b8 114
(EngineCore_DP0 pid=334505) .b8 110
(EngineCore_DP0 pid=334505) .b8 101
(EngineCore_DP0 pid=334505) .b8 108
(EngineCore_DP0 pid=334505) .b8 0
(EngineCore_DP0 pid=334505) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=334505) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=334505) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=334505) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=334505) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=334505) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=334505) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=334505) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=334505) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=334505) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=334505) .b8 191                                 // DW_AT_call_line
(EngineCore_DP0 pid=334505) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=334505) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=334505) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=334505) 	}
(EngineCore_DP0 pid=334505) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=334505) 
(EngineCore_DP0 pid=334505) ================================================================
(EngineCore_DP0 pid=334505) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=334505) 
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpngopbul7.ptx', '-o', '/tmp/tmpngopbul7.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866] 
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866] 
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866] 
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpngopbul7.ptx -o /tmp/tmpngopbul7.ptx.o
(EngineCore_DP0 pid=334505) ERROR 01-25 19:14:29 [core.py:866] 

STDERR:
[2026-01-25 19:14:15] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:14:15] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:14:15] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:14:15] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:14:15] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:14:15] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:14:15] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:14:15] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:14:15] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:14:15] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:14:15] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:14:15] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:14:15] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:14:15] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:14:18] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:14:18] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:14:18] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:14:18] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:14:18] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:14:18] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:14:18] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:14:18] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:14:18] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:14:18] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:14:18] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:14:18] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:14:18] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:14:18] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=334505) [2026-01-25 19:14:19] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=334505) [2026-01-25 19:14:19] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=334505) [2026-01-25 19:14:19] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=334505) [2026-01-25 19:14:19] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=334505) [2026-01-25 19:14:19] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=334505) [2026-01-25 19:14:19] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=334505) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=334505) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.11s/it]
(EngineCore_DP0 pid=334505) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.11s/it]
(EngineCore_DP0 pid=334505) 
(EngineCore_DP0 pid=334505) [2026-01-25 19:14:28] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=334505) [2026-01-25 19:14:28] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=334505) [2026-01-25 19:14:28] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=334505) [2026-01-25 19:14:28] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 2621440 bytes
(EngineCore_DP0 pid=334505) [2026-01-25 19:14:28] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=334505) [2026-01-25 19:14:28] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 20971520 bytes
(EngineCore_DP0 pid=334505) [2026-01-25 19:14:28] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=334505) [2026-01-25 19:14:28] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10485760 bytes
(EngineCore_DP0 pid=334505) Process EngineCore_DP0:
(EngineCore_DP0 pid=334505) Traceback (most recent call last):
(EngineCore_DP0 pid=334505)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=334505)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=334505)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=334505)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=334505) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpngopbul7.ptx', '-o', '/tmp/tmpngopbul7.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=334505) 
(EngineCore_DP0 pid=334505) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=334505) 
(EngineCore_DP0 pid=334505) Traceback (most recent call last):
(EngineCore_DP0 pid=334505)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=334505)     self.run()
(EngineCore_DP0 pid=334505)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=334505)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=334505)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=334505)     raise e
(EngineCore_DP0 pid=334505)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=334505)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=334505)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=334505)     super().__init__(
(EngineCore_DP0 pid=334505)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=334505)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=334505)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=334505)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=334505)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=334505)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=334505)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=334505)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=334505)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=334505)     return func(*args, **kwargs)
(EngineCore_DP0 pid=334505)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=334505)     return func(*args, **kwargs)
(EngineCore_DP0 pid=334505)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=334505)     self.model_runner.profile_run()
(EngineCore_DP0 pid=334505)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=334505)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=334505)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=334505)     return func(*args, **kwargs)
(EngineCore_DP0 pid=334505)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=334505)     outputs = self.model(
(EngineCore_DP0 pid=334505)               ^^^^^^^^^^^
(EngineCore_DP0 pid=334505)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=334505)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=334505)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=334505)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=334505)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=334505)     model_output = self.model(
(EngineCore_DP0 pid=334505)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=334505)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=334505)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=334505)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=334505)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=334505)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=334505)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=334505)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=334505)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=334505)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=334505)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=334505)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=334505)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=334505)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=334505)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=334505)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=334505)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=334505)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=334505)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=334505)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=334505)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=334505)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=334505)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=334505)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=334505)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=334505)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=334505)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=334505)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=334505)     return self._linear_fn(
(EngineCore_DP0 pid=334505)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=334505)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=334505)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=334505)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=334505)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=334505)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=334505)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=334505)     return fn(input, L)
(EngineCore_DP0 pid=334505)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=334505)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=334505)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=334505)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=334505)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=334505)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=334505)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=334505)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=334505)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=334505)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=334505)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=334505)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=334505)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=334505)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=334505)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=334505)     raise PTXASError(error)
(EngineCore_DP0 pid=334505) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=334505) `ptxas` stderr:
(EngineCore_DP0 pid=334505) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=334505) 
(EngineCore_DP0 pid=334505) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpngopbul7.ptx -o /tmp/tmpngopbul7.ptx.o
(EngineCore_DP0 pid=334505) 
[rank0]:[W125 19:14:29.845969502 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=4096

========== M=8192 ==========
Time: 2026-01-25 19:14:31
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Llama3.2-1B-FP8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:14:37 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:14:37 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=335014) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=335014) 
(EngineCore_DP0 pid=335014) 
(EngineCore_DP0 pid=335014) ================================================================
(EngineCore_DP0 pid=335014) Internal Triton PTX codegen error
(EngineCore_DP0 pid=335014) `ptxas` stderr:
(EngineCore_DP0 pid=335014) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=335014) 
(EngineCore_DP0 pid=335014) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpdqxd71zi.ptx -o /tmp/tmpdqxd71zi.ptx.o
(EngineCore_DP0 pid=335014) 
(EngineCore_DP0 pid=335014) 
(EngineCore_DP0 pid=335014) //
(EngineCore_DP0 pid=335014) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=335014) //
(EngineCore_DP0 pid=335014) 
(EngineCore_DP0 pid=335014) .version 8.7
(EngineCore_DP0 pid=335014) .target sm_121a
(EngineCore_DP0 pid=335014) .address_size 64
(EngineCore_DP0 pid=335014) 
(EngineCore_DP0 pid=335014) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=335014) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=335014)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=335014) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=335014) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=335014) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=335014) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=335014) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=335014) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=335014) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=335014) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=335014) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=335014) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=335014) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=335014) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=335014) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=335014) )
(EngineCore_DP0 pid=335014) .reqntid 512
(EngineCore_DP0 pid=335014) {
(EngineCore_DP0 pid=335014) 	.reg .pred 	%p<44>;
(EngineCore_DP0 pid=335014) 	.reg .b16 	%rs<74>;
(EngineCore_DP0 pid=335014) 	.reg .b32 	%r<187>;
(EngineCore_DP0 pid=335014) 	.reg .b64 	%rd<25>;
(EngineCore_DP0 pid=335014) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=335014) $L__func_begin0:
(EngineCore_DP0 pid=335014) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=335014) 
(EngineCore_DP0 pid=335014) // %bb.0:
(EngineCore_DP0 pid=335014) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=335014) 	ld.param.b32 	%r22, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=335014) 	ld.param.b32 	%r21, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=335014) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=335014) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=335014) $L__tmp0:
(EngineCore_DP0 pid=335014) 	.loc	1 177 24                        // quant_slide_tuned_Llama3.2-1B.py:177:24
(EngineCore_DP0 pid=335014) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=335014) 	ld.param.b32 	%r25, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=335014) 	.loc	1 182 26                        // quant_slide_tuned_Llama3.2-1B.py:182:26
(EngineCore_DP0 pid=335014) 	mul.lo.s32 	%r26, %r25, %r1;
(EngineCore_DP0 pid=335014) 	.loc	1 182 20                        // quant_slide_tuned_Llama3.2-1B.py:182:20
(EngineCore_DP0 pid=335014) 	mad.wide.s32 	%rd1, %r26, 2, %rd4;
(EngineCore_DP0 pid=335014) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=335014) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=335014) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=335014) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=335014) 	setp.lt.s32 	%p1, %r22, 1;
(EngineCore_DP0 pid=335014) 	mov.b32 	%r184, 0f2B8CBCCC;
(EngineCore_DP0 pid=335014) 	setp.eq.b32 	%p43, %r2, 0;
(EngineCore_DP0 pid=335014) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=335014) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=335014) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=335014) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=335014) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=335014) 	shr.u32 	%r35, %r2, 3;
(EngineCore_DP0 pid=335014) 	and.b32 	%r36, %r35, 60;
(EngineCore_DP0 pid=335014) 	mov.b32 	%r37, global_smem;
(EngineCore_DP0 pid=335014) 	add.s32 	%r47, %r37, %r36;
(EngineCore_DP0 pid=335014) 	shl.b32 	%r38, %r2, 2;
(EngineCore_DP0 pid=335014) 	add.s32 	%r50, %r37, %r38;
(EngineCore_DP0 pid=335014) 	mov.b32 	%r43, 0;
(EngineCore_DP0 pid=335014) 	mov.b32 	%r182, 0f00000000;
(EngineCore_DP0 pid=335014) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=335014) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=335014) 	mov.b32 	%r183, %r43;
(EngineCore_DP0 pid=335014) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=335014) 	.loc	1 189 22                        // quant_slide_tuned_Llama3.2-1B.py:189:22
(EngineCore_DP0 pid=335014) 	add.s32 	%r53, %r4, %r183;
(EngineCore_DP0 pid=335014) 	setp.lt.s32 	%p2, %r53, %r21;
(EngineCore_DP0 pid=335014) 	.loc	1 190 29                        // quant_slide_tuned_Llama3.2-1B.py:190:29
(EngineCore_DP0 pid=335014) 	mad.wide.s32 	%rd6, %r53, 2, %rd1;
(EngineCore_DP0 pid=335014) 	.loc	1 190 21                        // quant_slide_tuned_Llama3.2-1B.py:190:21
(EngineCore_DP0 pid=335014) 	// begin inline asm
(EngineCore_DP0 pid=335014) 	mov.u32 %r39, %r43;
(EngineCore_DP0 pid=335014) 	mov.u32 %r40, %r43;
(EngineCore_DP0 pid=335014) 	mov.u32 %r41, %r43;
(EngineCore_DP0 pid=335014) 	mov.u32 %r42, %r43;
(EngineCore_DP0 pid=335014) 	@%p2 ld.global.v4.b32 { %r39, %r40, %r41, %r42 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=335014) 	// end inline asm
(EngineCore_DP0 pid=335014) 	mov.b32 	{%rs1, %rs2}, %r39;
(EngineCore_DP0 pid=335014) 	mov.b32 	{%rs3, %rs4}, %r40;
(EngineCore_DP0 pid=335014) 	mov.b32 	{%rs5, %rs6}, %r41;
(EngineCore_DP0 pid=335014) 	mov.b32 	{%rs7, %rs8}, %r42;
(EngineCore_DP0 pid=335014) 	.loc	1 191 50                        // quant_slide_tuned_Llama3.2-1B.py:191:50
(EngineCore_DP0 pid=335014) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=335014) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=335014) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=335014) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=335014) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=335014) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=335014) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=335014) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=335014) $L__tmp1:
(EngineCore_DP0 pid=335014) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=335014) 	bar.sync 	0;
(EngineCore_DP0 pid=335014) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=335014) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=335014) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=335014) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=335014) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=335014) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=335014) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=335014) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=335014) 	cvt.f32.bf16 	%r54, %rs23;
(EngineCore_DP0 pid=335014) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=335014) 	shfl.sync.bfly.b32 	%r55, %r54, 16, 31, -1;
(EngineCore_DP0 pid=335014) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=335014) 	max.f32 	%r56, %r54, %r55;
(EngineCore_DP0 pid=335014) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=335014) 	shfl.sync.bfly.b32 	%r57, %r56, 8, 31, -1;
(EngineCore_DP0 pid=335014) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=335014) 	max.f32 	%r58, %r56, %r57;
(EngineCore_DP0 pid=335014) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=335014) 	shfl.sync.bfly.b32 	%r59, %r58, 4, 31, -1;
(EngineCore_DP0 pid=335014) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=335014) 	max.f32 	%r60, %r58, %r59;
(EngineCore_DP0 pid=335014) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=335014) 	shfl.sync.bfly.b32 	%r61, %r60, 2, 31, -1;
(EngineCore_DP0 pid=335014) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=335014) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=335014) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=335014) 	shfl.sync.bfly.b32 	%r63, %r62, 1, 31, -1;
(EngineCore_DP0 pid=335014) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=335014) 	max.f32 	%r48, %r62, %r63;
(EngineCore_DP0 pid=335014) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=335014) 	// begin inline asm
(EngineCore_DP0 pid=335014) 	@%p3 st.shared.b32 [ %r47 + 0 ], %r48;
(EngineCore_DP0 pid=335014) 	// end inline asm
(EngineCore_DP0 pid=335014) 	bar.sync 	0;
(EngineCore_DP0 pid=335014) 	// begin inline asm
(EngineCore_DP0 pid=335014) 	@%p4 ld.shared.b32 %r49, [ %r50 + 0 ];
(EngineCore_DP0 pid=335014) 	// end inline asm
(EngineCore_DP0 pid=335014) 	shfl.sync.bfly.b32 	%r64, %r49, 8, 31, -1;
(EngineCore_DP0 pid=335014) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=335014) 	max.f32 	%r65, %r49, %r64;
(EngineCore_DP0 pid=335014) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=335014) 	shfl.sync.bfly.b32 	%r66, %r65, 4, 31, -1;
(EngineCore_DP0 pid=335014) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=335014) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=335014) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=335014) 	shfl.sync.bfly.b32 	%r68, %r67, 2, 31, -1;
(EngineCore_DP0 pid=335014) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=335014) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=335014) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=335014) 	shfl.sync.bfly.b32 	%r70, %r69, 1, 31, -1;
(EngineCore_DP0 pid=335014) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=335014) 	max.f32 	%r52, %r69, %r70;
(EngineCore_DP0 pid=335014) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=335014) 	// begin inline asm
(EngineCore_DP0 pid=335014) 	@%p43 st.shared.b32 [ %r50 + 0 ], %r52;
(EngineCore_DP0 pid=335014) 	// end inline asm
(EngineCore_DP0 pid=335014) 	bar.sync 	0;
(EngineCore_DP0 pid=335014) 	ld.shared.b32 	%r71, [global_smem];
(EngineCore_DP0 pid=335014) $L__tmp2:
(EngineCore_DP0 pid=335014) 	.loc	1 191 36                        // quant_slide_tuned_Llama3.2-1B.py:191:36
(EngineCore_DP0 pid=335014) 	max.f32 	%r182, %r182, %r71;
(EngineCore_DP0 pid=335014) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=335014) 	add.s32 	%r183, %r183, 4096;
(EngineCore_DP0 pid=335014) 	setp.lt.s32 	%p6, %r183, %r22;
(EngineCore_DP0 pid=335014) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=335014) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=335014) 	.loc	1 193 32                        // quant_slide_tuned_Llama3.2-1B.py:193:32
(EngineCore_DP0 pid=335014) 	max.f32 	%r184, %r182, 0f2B8CBCCC;
(EngineCore_DP0 pid=335014) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=335014) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=335014) 	mov.b32 	%r73, 0f43E00000;
(EngineCore_DP0 pid=335014) 	.loc	1 194 32                        // quant_slide_tuned_Llama3.2-1B.py:194:32
(EngineCore_DP0 pid=335014) 	div.full.f32 	%r74, %r184, %r73;
(EngineCore_DP0 pid=335014) 	.loc	1 194 41                        // quant_slide_tuned_Llama3.2-1B.py:194:41
(EngineCore_DP0 pid=335014) 	max.f32 	%r72, %r74, 0f36924925;
(EngineCore_DP0 pid=335014) 	.loc	1 196 25                        // quant_slide_tuned_Llama3.2-1B.py:196:25
(EngineCore_DP0 pid=335014) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=335014) 	.loc	1 196 30                        // quant_slide_tuned_Llama3.2-1B.py:196:30
(EngineCore_DP0 pid=335014) 	// begin inline asm
(EngineCore_DP0 pid=335014) 	@%p43 st.global.b32 [ %rd7 + 0 ], { %r72 };
(EngineCore_DP0 pid=335014) 	// end inline asm
(EngineCore_DP0 pid=335014) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=335014) 	setp.lt.s32 	%p8, %r23, 1;
(EngineCore_DP0 pid=335014) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=335014) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=335014) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=335014) 	ld.param.b32 	%r27, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=335014) 	shr.s32 	%r28, %r27, 31;
(EngineCore_DP0 pid=335014) 	shr.u32 	%r29, %r28, 30;
(EngineCore_DP0 pid=335014) 	add.s32 	%r30, %r27, %r29;
(EngineCore_DP0 pid=335014) 	shr.s32 	%r31, %r30, 2;
(EngineCore_DP0 pid=335014) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=335014) 	mul.lo.s32 	%r32, %r31, %r1;
(EngineCore_DP0 pid=335014) 	mad.wide.s32 	%rd2, %r32, 4, %rd5;
(EngineCore_DP0 pid=335014) 	div.full.f32 	%r14, %r73, %r184;
(EngineCore_DP0 pid=335014) 	shl.b32 	%r15, %r3, 2;
(EngineCore_DP0 pid=335014) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=335014) 	shl.b32 	%r76, %r3, 4;
(EngineCore_DP0 pid=335014) 	or.b32 	%r185, %r76, 15;
(EngineCore_DP0 pid=335014) 	mov.b32 	%r186, 0;
(EngineCore_DP0 pid=335014) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=335014)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=335014) 	.loc	1 203 30                        // quant_slide_tuned_Llama3.2-1B.py:203:30
(EngineCore_DP0 pid=335014) 	add.s32 	%r97, %r15, %r186;
(EngineCore_DP0 pid=335014) 	setp.lt.s32 	%p25, %r97, %r23;
(EngineCore_DP0 pid=335014) 	.loc	1 208 22                        // quant_slide_tuned_Llama3.2-1B.py:208:22
(EngineCore_DP0 pid=335014) 	add.s32 	%r98, %r185, -15;
(EngineCore_DP0 pid=335014) 	add.s32 	%r99, %r185, -11;
(EngineCore_DP0 pid=335014) 	add.s32 	%r100, %r185, -7;
(EngineCore_DP0 pid=335014) 	.loc	1 211 53                        // quant_slide_tuned_Llama3.2-1B.py:211:53
(EngineCore_DP0 pid=335014) 	add.s32 	%r101, %r185, -3;
(EngineCore_DP0 pid=335014) 	setp.lt.s32 	%p26, %r98, %r21;
(EngineCore_DP0 pid=335014) 	setp.lt.s32 	%p27, %r99, %r21;
(EngineCore_DP0 pid=335014) 	setp.lt.s32 	%p28, %r100, %r21;
(EngineCore_DP0 pid=335014) 	setp.lt.s32 	%p29, %r101, %r21;
(EngineCore_DP0 pid=335014) 	.loc	1 211 37                        // quant_slide_tuned_Llama3.2-1B.py:211:37
(EngineCore_DP0 pid=335014) 	and.pred 	%p9, %p25, %p26;
(EngineCore_DP0 pid=335014) 	and.pred 	%p10, %p25, %p27;
(EngineCore_DP0 pid=335014) 	and.pred 	%p11, %p25, %p28;
(EngineCore_DP0 pid=335014) 	and.pred 	%p12, %p25, %p29;
(EngineCore_DP0 pid=335014) 	.loc	1 210 29                        // quant_slide_tuned_Llama3.2-1B.py:210:29
(EngineCore_DP0 pid=335014) 	mad.wide.s32 	%rd8, %r98, 2, %rd1;
(EngineCore_DP0 pid=335014) 	add.s64 	%rd9, %rd8, 8;
(EngineCore_DP0 pid=335014) 	add.s64 	%rd10, %rd8, 16;
(EngineCore_DP0 pid=335014) 	add.s64 	%rd11, %rd8, 24;
(EngineCore_DP0 pid=335014) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=335014) 	.loc	1 210 21                        // quant_slide_tuned_Llama3.2-1B.py:210:21
(EngineCore_DP0 pid=335014) 	// begin inline asm
(EngineCore_DP0 pid=335014) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=335014) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=335014) 	// end inline asm
(EngineCore_DP0 pid=335014) 	// begin inline asm
(EngineCore_DP0 pid=335014) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=335014) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=335014) 	// end inline asm
(EngineCore_DP0 pid=335014) 	// begin inline asm
(EngineCore_DP0 pid=335014) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=335014) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=335014) 	// end inline asm
(EngineCore_DP0 pid=335014) 	// begin inline asm
(EngineCore_DP0 pid=335014) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=335014) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=335014) 	// end inline asm
(EngineCore_DP0 pid=335014) 	.loc	1 211 79                        // quant_slide_tuned_Llama3.2-1B.py:211:79
(EngineCore_DP0 pid=335014) 	cvt.f32.bf16 	%r102, %rs24;
(EngineCore_DP0 pid=335014) 	cvt.f32.bf16 	%r103, %rs26;
(EngineCore_DP0 pid=335014) 	cvt.f32.bf16 	%r104, %rs28;
(EngineCore_DP0 pid=335014) 	cvt.f32.bf16 	%r105, %rs30;
(EngineCore_DP0 pid=335014) 	.loc	1 213 48                        // quant_slide_tuned_Llama3.2-1B.py:213:48
(EngineCore_DP0 pid=335014) 	add.s32 	%r106, %r185, -14;
(EngineCore_DP0 pid=335014) 	add.s32 	%r107, %r185, -10;
(EngineCore_DP0 pid=335014) 	add.s32 	%r108, %r185, -6;
(EngineCore_DP0 pid=335014) 	.loc	1 213 53                        // quant_slide_tuned_Llama3.2-1B.py:213:53
(EngineCore_DP0 pid=335014) 	add.s32 	%r109, %r185, -2;
(EngineCore_DP0 pid=335014) 	setp.lt.s32 	%p30, %r106, %r21;
(EngineCore_DP0 pid=335014) 	setp.lt.s32 	%p31, %r107, %r21;
(EngineCore_DP0 pid=335014) 	setp.lt.s32 	%p32, %r108, %r21;
(EngineCore_DP0 pid=335014) 	setp.lt.s32 	%p33, %r109, %r21;
(EngineCore_DP0 pid=335014) 	.loc	1 213 37                        // quant_slide_tuned_Llama3.2-1B.py:213:37
(EngineCore_DP0 pid=335014) 	and.pred 	%p13, %p25, %p30;
(EngineCore_DP0 pid=335014) 	and.pred 	%p14, %p25, %p31;
(EngineCore_DP0 pid=335014) 	and.pred 	%p15, %p25, %p32;
(EngineCore_DP0 pid=335014) 	and.pred 	%p16, %p25, %p33;
(EngineCore_DP0 pid=335014) 	.loc	1 212 39                        // quant_slide_tuned_Llama3.2-1B.py:212:39
(EngineCore_DP0 pid=335014) 	add.s64 	%rd12, %rd8, 2;
(EngineCore_DP0 pid=335014) 	add.s64 	%rd13, %rd8, 10;
(EngineCore_DP0 pid=335014) 	add.s64 	%rd14, %rd8, 18;
(EngineCore_DP0 pid=335014) 	add.s64 	%rd15, %rd8, 26;
(EngineCore_DP0 pid=335014) 	.loc	1 212 21                        // quant_slide_tuned_Llama3.2-1B.py:212:21
(EngineCore_DP0 pid=335014) 	// begin inline asm
(EngineCore_DP0 pid=335014) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=335014) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=335014) 	// end inline asm
(EngineCore_DP0 pid=335014) 	// begin inline asm
(EngineCore_DP0 pid=335014) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=335014) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=335014) 	// end inline asm
(EngineCore_DP0 pid=335014) 	// begin inline asm
(EngineCore_DP0 pid=335014) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=335014) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=335014) 	// end inline asm
(EngineCore_DP0 pid=335014) 	// begin inline asm
(EngineCore_DP0 pid=335014) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=335014) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=335014) 	// end inline asm
(EngineCore_DP0 pid=335014) 	.loc	1 213 79                        // quant_slide_tuned_Llama3.2-1B.py:213:79
(EngineCore_DP0 pid=335014) 	cvt.f32.bf16 	%r110, %rs32;
(EngineCore_DP0 pid=335014) 	cvt.f32.bf16 	%r111, %rs34;
(EngineCore_DP0 pid=335014) 	cvt.f32.bf16 	%r112, %rs36;
(EngineCore_DP0 pid=335014) 	cvt.f32.bf16 	%r113, %rs38;
(EngineCore_DP0 pid=335014) 	.loc	1 215 48                        // quant_slide_tuned_Llama3.2-1B.py:215:48
(EngineCore_DP0 pid=335014) 	add.s32 	%r114, %r185, -13;
(EngineCore_DP0 pid=335014) 	add.s32 	%r115, %r185, -9;
(EngineCore_DP0 pid=335014) 	add.s32 	%r116, %r185, -5;
(EngineCore_DP0 pid=335014) 	.loc	1 215 53                        // quant_slide_tuned_Llama3.2-1B.py:215:53
(EngineCore_DP0 pid=335014) 	add.s32 	%r117, %r185, -1;
(EngineCore_DP0 pid=335014) 	setp.lt.s32 	%p34, %r114, %r21;
(EngineCore_DP0 pid=335014) 	setp.lt.s32 	%p35, %r115, %r21;
(EngineCore_DP0 pid=335014) 	setp.lt.s32 	%p36, %r116, %r21;
(EngineCore_DP0 pid=335014) 	setp.lt.s32 	%p37, %r117, %r21;
(EngineCore_DP0 pid=335014) 	.loc	1 215 37                        // quant_slide_tuned_Llama3.2-1B.py:215:37
(EngineCore_DP0 pid=335014) 	and.pred 	%p17, %p25, %p34;
(EngineCore_DP0 pid=335014) 	and.pred 	%p18, %p25, %p35;
(EngineCore_DP0 pid=335014) 	and.pred 	%p19, %p25, %p36;
(EngineCore_DP0 pid=335014) 	and.pred 	%p20, %p25, %p37;
(EngineCore_DP0 pid=335014) 	.loc	1 214 39                        // quant_slide_tuned_Llama3.2-1B.py:214:39
(EngineCore_DP0 pid=335014) 	add.s64 	%rd16, %rd8, 4;
(EngineCore_DP0 pid=335014) 	add.s64 	%rd17, %rd8, 12;
(EngineCore_DP0 pid=335014) 	add.s64 	%rd18, %rd8, 20;
(EngineCore_DP0 pid=335014) 	add.s64 	%rd19, %rd8, 28;
(EngineCore_DP0 pid=335014) 	.loc	1 214 21                        // quant_slide_tuned_Llama3.2-1B.py:214:21
(EngineCore_DP0 pid=335014) 	// begin inline asm
(EngineCore_DP0 pid=335014) 	mov.u16 %rs40, %rs25;
(EngineCore_DP0 pid=335014) 	@%p17 ld.global.b16 { %rs40 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=335014) 	// end inline asm
(EngineCore_DP0 pid=335014) 	// begin inline asm
(EngineCore_DP0 pid=335014) 	mov.u16 %rs42, %rs25;
(EngineCore_DP0 pid=335014) 	@%p18 ld.global.b16 { %rs42 }, [ %rd17 + 0 ];
(EngineCore_DP0 pid=335014) 	// end inline asm
(EngineCore_DP0 pid=335014) 	// begin inline asm
(EngineCore_DP0 pid=335014) 	mov.u16 %rs44, %rs25;
(EngineCore_DP0 pid=335014) 	@%p19 ld.global.b16 { %rs44 }, [ %rd18 + 0 ];
(EngineCore_DP0 pid=335014) 	// end inline asm
(EngineCore_DP0 pid=335014) 	// begin inline asm
(EngineCore_DP0 pid=335014) 	mov.u16 %rs46, %rs25;
(EngineCore_DP0 pid=335014) 	@%p20 ld.global.b16 { %rs46 }, [ %rd19 + 0 ];
(EngineCore_DP0 pid=335014) 	// end inline asm
(EngineCore_DP0 pid=335014) 	.loc	1 215 79                        // quant_slide_tuned_Llama3.2-1B.py:215:79
(EngineCore_DP0 pid=335014) 	cvt.f32.bf16 	%r118, %rs40;
(EngineCore_DP0 pid=335014) 	cvt.f32.bf16 	%r119, %rs42;
(EngineCore_DP0 pid=335014) 	cvt.f32.bf16 	%r120, %rs44;
(EngineCore_DP0 pid=335014) 	cvt.f32.bf16 	%r121, %rs46;
(EngineCore_DP0 pid=335014) 	.loc	1 217 48                        // quant_slide_tuned_Llama3.2-1B.py:217:48
(EngineCore_DP0 pid=335014) 	add.s32 	%r122, %r185, -12;
(EngineCore_DP0 pid=335014) 	add.s32 	%r123, %r185, -8;
(EngineCore_DP0 pid=335014) 	add.s32 	%r124, %r185, -4;
(EngineCore_DP0 pid=335014) 	.loc	1 217 53                        // quant_slide_tuned_Llama3.2-1B.py:217:53
(EngineCore_DP0 pid=335014) 	setp.lt.s32 	%p38, %r122, %r21;
(EngineCore_DP0 pid=335014) 	setp.lt.s32 	%p39, %r123, %r21;
(EngineCore_DP0 pid=335014) 	setp.lt.s32 	%p40, %r124, %r21;
(EngineCore_DP0 pid=335014) 	setp.lt.s32 	%p41, %r185, %r21;
(EngineCore_DP0 pid=335014) 	.loc	1 217 37                        // quant_slide_tuned_Llama3.2-1B.py:217:37
(EngineCore_DP0 pid=335014) 	and.pred 	%p21, %p25, %p38;
(EngineCore_DP0 pid=335014) 	and.pred 	%p22, %p25, %p39;
(EngineCore_DP0 pid=335014) 	and.pred 	%p23, %p25, %p40;
(EngineCore_DP0 pid=335014) 	and.pred 	%p24, %p25, %p41;
(EngineCore_DP0 pid=335014) 	.loc	1 216 39                        // quant_slide_tuned_Llama3.2-1B.py:216:39
(EngineCore_DP0 pid=335014) 	add.s64 	%rd20, %rd8, 6;
(EngineCore_DP0 pid=335014) 	add.s64 	%rd21, %rd8, 14;
(EngineCore_DP0 pid=335014) 	add.s64 	%rd22, %rd8, 22;
(EngineCore_DP0 pid=335014) 	add.s64 	%rd23, %rd8, 30;
(EngineCore_DP0 pid=335014) 	.loc	1 216 21                        // quant_slide_tuned_Llama3.2-1B.py:216:21
(EngineCore_DP0 pid=335014) 	// begin inline asm
(EngineCore_DP0 pid=335014) 	mov.u16 %rs48, %rs25;
(EngineCore_DP0 pid=335014) 	@%p21 ld.global.b16 { %rs48 }, [ %rd20 + 0 ];
(EngineCore_DP0 pid=335014) 	// end inline asm
(EngineCore_DP0 pid=335014) 	// begin inline asm
(EngineCore_DP0 pid=335014) 	mov.u16 %rs50, %rs25;
(EngineCore_DP0 pid=335014) 	@%p22 ld.global.b16 { %rs50 }, [ %rd21 + 0 ];
(EngineCore_DP0 pid=335014) 	// end inline asm
(EngineCore_DP0 pid=335014) 	// begin inline asm
(EngineCore_DP0 pid=335014) 	mov.u16 %rs52, %rs25;
(EngineCore_DP0 pid=335014) 	@%p23 ld.global.b16 { %rs52 }, [ %rd22 + 0 ];
(EngineCore_DP0 pid=335014) 	// end inline asm
(EngineCore_DP0 pid=335014) 	// begin inline asm
(EngineCore_DP0 pid=335014) 	mov.u16 %rs54, %rs25;
(EngineCore_DP0 pid=335014) 	@%p24 ld.global.b16 { %rs54 }, [ %rd23 + 0 ];
(EngineCore_DP0 pid=335014) 	// end inline asm
(EngineCore_DP0 pid=335014) 	.loc	1 217 79                        // quant_slide_tuned_Llama3.2-1B.py:217:79
(EngineCore_DP0 pid=335014) 	cvt.f32.bf16 	%r125, %rs48;
(EngineCore_DP0 pid=335014) 	cvt.f32.bf16 	%r126, %rs50;
(EngineCore_DP0 pid=335014) 	cvt.f32.bf16 	%r127, %rs52;
(EngineCore_DP0 pid=335014) 	cvt.f32.bf16 	%r128, %rs54;
(EngineCore_DP0 pid=335014) 	.loc	1 219 27                        // quant_slide_tuned_Llama3.2-1B.py:219:27
(EngineCore_DP0 pid=335014) 	mul.f32 	%r129, %r14, %r102;
(EngineCore_DP0 pid=335014) 	mul.f32 	%r130, %r14, %r103;
(EngineCore_DP0 pid=335014) 	mul.f32 	%r131, %r14, %r104;
(EngineCore_DP0 pid=335014) 	mul.f32 	%r132, %r14, %r105;
(EngineCore_DP0 pid=335014) 	mov.b32 	%r133, 0f43E00000;
(EngineCore_DP0 pid=335014) 	.loc	1 219 48                        // quant_slide_tuned_Llama3.2-1B.py:219:48
(EngineCore_DP0 pid=335014) 	min.xorsign.abs.f32 	%r77, %r129, %r133;
(EngineCore_DP0 pid=335014) 	min.xorsign.abs.f32 	%r78, %r130, %r133;
(EngineCore_DP0 pid=335014) 	min.xorsign.abs.f32 	%r79, %r131, %r133;
(EngineCore_DP0 pid=335014) 	min.xorsign.abs.f32 	%r80, %r132, %r133;
(EngineCore_DP0 pid=335014) 	.loc	1 219 60                        // quant_slide_tuned_Llama3.2-1B.py:219:60
(EngineCore_DP0 pid=335014) 	// begin inline asm
(EngineCore_DP0 pid=335014) 	cvt.rn.satfinite.e4m3x2.f32  %rs56, %r78, %r77; 
(EngineCore_DP0 pid=335014) 
(EngineCore_DP0 pid=335014) 	// end inline asm
(EngineCore_DP0 pid=335014) 	shr.u16 	%rs64, %rs56, 8;
(EngineCore_DP0 pid=335014) 	// begin inline asm
(EngineCore_DP0 pid=335014) 	cvt.rn.satfinite.e4m3x2.f32  %rs57, %r80, %r79; 
(EngineCore_DP0 pid=335014) 
(EngineCore_DP0 pid=335014) 	// end inline asm
(EngineCore_DP0 pid=335014) 	shr.u16 	%rs65, %rs57, 8;
(EngineCore_DP0 pid=335014) 	.loc	1 220 27                        // quant_slide_tuned_Llama3.2-1B.py:220:27
(EngineCore_DP0 pid=335014) 	mul.f32 	%r134, %r14, %r110;
(EngineCore_DP0 pid=335014) 	mul.f32 	%r135, %r14, %r111;
(EngineCore_DP0 pid=335014) 	mul.f32 	%r136, %r14, %r112;
(EngineCore_DP0 pid=335014) 	mul.f32 	%r137, %r14, %r113;
(EngineCore_DP0 pid=335014) 	.loc	1 220 48                        // quant_slide_tuned_Llama3.2-1B.py:220:48
(EngineCore_DP0 pid=335014) 	min.xorsign.abs.f32 	%r81, %r134, %r133;
(EngineCore_DP0 pid=335014) 	min.xorsign.abs.f32 	%r82, %r135, %r133;
(EngineCore_DP0 pid=335014) 	min.xorsign.abs.f32 	%r83, %r136, %r133;
(EngineCore_DP0 pid=335014) 	min.xorsign.abs.f32 	%r84, %r137, %r133;
(EngineCore_DP0 pid=335014) 	.loc	1 220 60                        // quant_slide_tuned_Llama3.2-1B.py:220:60
(EngineCore_DP0 pid=335014) 	// begin inline asm
(EngineCore_DP0 pid=335014) 	cvt.rn.satfinite.e4m3x2.f32  %rs58, %r82, %r81; 
(EngineCore_DP0 pid=335014) 
(EngineCore_DP0 pid=335014) 	// end inline asm
(EngineCore_DP0 pid=335014) 	shr.u16 	%rs66, %rs58, 8;
(EngineCore_DP0 pid=335014) 	// begin inline asm
(EngineCore_DP0 pid=335014) 	cvt.rn.satfinite.e4m3x2.f32  %rs59, %r84, %r83; 
(EngineCore_DP0 pid=335014) 
(EngineCore_DP0 pid=335014) 	// end inline asm
(EngineCore_DP0 pid=335014) 	shr.u16 	%rs67, %rs59, 8;
(EngineCore_DP0 pid=335014) 	.loc	1 221 27                        // quant_slide_tuned_Llama3.2-1B.py:221:27
(EngineCore_DP0 pid=335014) 	mul.f32 	%r138, %r14, %r118;
(EngineCore_DP0 pid=335014) 	mul.f32 	%r139, %r14, %r119;
(EngineCore_DP0 pid=335014) 	mul.f32 	%r140, %r14, %r120;
(EngineCore_DP0 pid=335014) 	mul.f32 	%r141, %r14, %r121;
(EngineCore_DP0 pid=335014) 	.loc	1 221 48                        // quant_slide_tuned_Llama3.2-1B.py:221:48
(EngineCore_DP0 pid=335014) 	min.xorsign.abs.f32 	%r85, %r138, %r133;
(EngineCore_DP0 pid=335014) 	min.xorsign.abs.f32 	%r86, %r139, %r133;
(EngineCore_DP0 pid=335014) 	min.xorsign.abs.f32 	%r87, %r140, %r133;
(EngineCore_DP0 pid=335014) 	min.xorsign.abs.f32 	%r88, %r141, %r133;
(EngineCore_DP0 pid=335014) 	.loc	1 221 60                        // quant_slide_tuned_Llama3.2-1B.py:221:60
(EngineCore_DP0 pid=335014) 	// begin inline asm
(EngineCore_DP0 pid=335014) 	cvt.rn.satfinite.e4m3x2.f32  %rs60, %r86, %r85; 
(EngineCore_DP0 pid=335014) 
(EngineCore_DP0 pid=335014) 	// end inline asm
(EngineCore_DP0 pid=335014) 	shr.u16 	%rs68, %rs60, 8;
(EngineCore_DP0 pid=335014) 	// begin inline asm
(EngineCore_DP0 pid=335014) 	cvt.rn.satfinite.e4m3x2.f32  %rs61, %r88, %r87; 
(EngineCore_DP0 pid=335014) 
(EngineCore_DP0 pid=335014) 	// end inline asm
(EngineCore_DP0 pid=335014) 	shr.u16 	%rs69, %rs61, 8;
(EngineCore_DP0 pid=335014) 	.loc	1 222 27                        // quant_slide_tuned_Llama3.2-1B.py:222:27
(EngineCore_DP0 pid=335014) 	mul.f32 	%r142, %r14, %r125;
(EngineCore_DP0 pid=335014) 	mul.f32 	%r143, %r14, %r126;
(EngineCore_DP0 pid=335014) 	mul.f32 	%r144, %r14, %r127;
(EngineCore_DP0 pid=335014) 	mul.f32 	%r145, %r14, %r128;
(EngineCore_DP0 pid=335014) 	.loc	1 222 48                        // quant_slide_tuned_Llama3.2-1B.py:222:48
(EngineCore_DP0 pid=335014) 	min.xorsign.abs.f32 	%r89, %r142, %r133;
(EngineCore_DP0 pid=335014) 	min.xorsign.abs.f32 	%r90, %r143, %r133;
(EngineCore_DP0 pid=335014) 	min.xorsign.abs.f32 	%r91, %r144, %r133;
(EngineCore_DP0 pid=335014) 	min.xorsign.abs.f32 	%r92, %r145, %r133;
(EngineCore_DP0 pid=335014) 	.loc	1 222 60                        // quant_slide_tuned_Llama3.2-1B.py:222:60
(EngineCore_DP0 pid=335014) 	// begin inline asm
(EngineCore_DP0 pid=335014) 	cvt.rn.satfinite.e4m3x2.f32  %rs62, %r90, %r89; 
(EngineCore_DP0 pid=335014) 
(EngineCore_DP0 pid=335014) 	// end inline asm
(EngineCore_DP0 pid=335014) 	shr.u16 	%rs70, %rs62, 8;
(EngineCore_DP0 pid=335014) 	// begin inline asm
(EngineCore_DP0 pid=335014) 	cvt.rn.satfinite.e4m3x2.f32  %rs63, %r92, %r91; 
(EngineCore_DP0 pid=335014) 
(EngineCore_DP0 pid=335014) 	// end inline asm
(EngineCore_DP0 pid=335014) 	shr.u16 	%rs71, %rs63, 8;
(EngineCore_DP0 pid=335014) 	.loc	1 224 45                        // quant_slide_tuned_Llama3.2-1B.py:224:45
(EngineCore_DP0 pid=335014) 	cvt.u32.u16 	%r146, %rs56;
(EngineCore_DP0 pid=335014) 	and.b32 	%r147, %r146, 255;
(EngineCore_DP0 pid=335014) 	cvt.u32.u16 	%r148, %rs64;
(EngineCore_DP0 pid=335014) 	cvt.u32.u16 	%r149, %rs57;
(EngineCore_DP0 pid=335014) 	and.b32 	%r150, %r149, 255;
(EngineCore_DP0 pid=335014) 	cvt.u32.u16 	%r151, %rs65;
(EngineCore_DP0 pid=335014) 	.loc	1 226 45                        // quant_slide_tuned_Llama3.2-1B.py:226:45
(EngineCore_DP0 pid=335014) 	cvt.u32.u16 	%r152, %rs60;
(EngineCore_DP0 pid=335014) 	and.b32 	%r153, %r152, 255;
(EngineCore_DP0 pid=335014) 	cvt.u32.u16 	%r154, %rs68;
(EngineCore_DP0 pid=335014) 	cvt.u32.u16 	%r155, %rs61;
(EngineCore_DP0 pid=335014) 	and.b32 	%r156, %r155, 255;
(EngineCore_DP0 pid=335014) 	cvt.u32.u16 	%r157, %rs69;
(EngineCore_DP0 pid=335014) 	.loc	1 227 45                        // quant_slide_tuned_Llama3.2-1B.py:227:45
(EngineCore_DP0 pid=335014) 	cvt.u32.u16 	%r158, %rs62;
(EngineCore_DP0 pid=335014) 	cvt.u32.u16 	%r159, %rs70;
(EngineCore_DP0 pid=335014) 	cvt.u32.u16 	%r160, %rs63;
(EngineCore_DP0 pid=335014) 	cvt.u32.u16 	%r161, %rs71;
(EngineCore_DP0 pid=335014) 	.loc	1 229 30                        // quant_slide_tuned_Llama3.2-1B.py:229:30
(EngineCore_DP0 pid=335014) 	and.b16 	%rs72, %rs58, 255;
(EngineCore_DP0 pid=335014) 	mul.wide.u16 	%r162, %rs72, 256;
(EngineCore_DP0 pid=335014) 	mul.wide.u16 	%r163, %rs66, 256;
(EngineCore_DP0 pid=335014) 	and.b16 	%rs73, %rs59, 255;
(EngineCore_DP0 pid=335014) 	mul.wide.u16 	%r164, %rs73, 256;
(EngineCore_DP0 pid=335014) 	mul.wide.u16 	%r165, %rs67, 256;
(EngineCore_DP0 pid=335014) 	.loc	1 229 24                        // quant_slide_tuned_Llama3.2-1B.py:229:24
(EngineCore_DP0 pid=335014) 	or.b32 	%r166, %r162, %r147;
(EngineCore_DP0 pid=335014) 	or.b32 	%r167, %r163, %r148;
(EngineCore_DP0 pid=335014) 	or.b32 	%r168, %r164, %r150;
(EngineCore_DP0 pid=335014) 	or.b32 	%r169, %r165, %r151;
(EngineCore_DP0 pid=335014) 	.loc	1 229 42                        // quant_slide_tuned_Llama3.2-1B.py:229:42
(EngineCore_DP0 pid=335014) 	shl.b32 	%r170, %r153, 16;
(EngineCore_DP0 pid=335014) 	shl.b32 	%r171, %r154, 16;
(EngineCore_DP0 pid=335014) 	shl.b32 	%r172, %r156, 16;
(EngineCore_DP0 pid=335014) 	shl.b32 	%r173, %r157, 16;
(EngineCore_DP0 pid=335014) 	.loc	1 229 36                        // quant_slide_tuned_Llama3.2-1B.py:229:36
(EngineCore_DP0 pid=335014) 	or.b32 	%r174, %r170, %r166;
(EngineCore_DP0 pid=335014) 	or.b32 	%r175, %r171, %r167;
(EngineCore_DP0 pid=335014) 	or.b32 	%r176, %r172, %r168;
(EngineCore_DP0 pid=335014) 	or.b32 	%r177, %r173, %r169;
(EngineCore_DP0 pid=335014) 	.loc	1 229 55                        // quant_slide_tuned_Llama3.2-1B.py:229:55
(EngineCore_DP0 pid=335014) 	shl.b32 	%r178, %r158, 24;
(EngineCore_DP0 pid=335014) 	shl.b32 	%r179, %r159, 24;
(EngineCore_DP0 pid=335014) 	shl.b32 	%r180, %r160, 24;
(EngineCore_DP0 pid=335014) 	shl.b32 	%r181, %r161, 24;
(EngineCore_DP0 pid=335014) 	.loc	1 229 49                        // quant_slide_tuned_Llama3.2-1B.py:229:49
(EngineCore_DP0 pid=335014) 	or.b32 	%r93, %r178, %r174;
(EngineCore_DP0 pid=335014) 	or.b32 	%r94, %r179, %r175;
(EngineCore_DP0 pid=335014) 	or.b32 	%r95, %r180, %r176;
(EngineCore_DP0 pid=335014) 	or.b32 	%r96, %r181, %r177;
(EngineCore_DP0 pid=335014) 	.loc	1 230 29                        // quant_slide_tuned_Llama3.2-1B.py:230:29
(EngineCore_DP0 pid=335014) 	mad.wide.s32 	%rd24, %r97, 4, %rd2;
(EngineCore_DP0 pid=335014) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-1B.py:230:39
(EngineCore_DP0 pid=335014) 	// begin inline asm
(EngineCore_DP0 pid=335014) 	@%p25 st.global.v4.b32 [ %rd24 + 0 ], { %r93, %r94, %r95, %r96 };
(EngineCore_DP0 pid=335014) 	// end inline asm
(EngineCore_DP0 pid=335014) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=335014) 	add.s32 	%r186, %r186, 2048;
(EngineCore_DP0 pid=335014) 	add.s32 	%r185, %r185, 8192;
(EngineCore_DP0 pid=335014) 	setp.lt.s32 	%p42, %r186, %r23;
(EngineCore_DP0 pid=335014) 	@%p42 bra 	$L__BB0_6;
(EngineCore_DP0 pid=335014) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=335014) 	.loc	1 201 4                         // quant_slide_tuned_Llama3.2-1B.py:201:4
(EngineCore_DP0 pid=335014) 	ret;
(EngineCore_DP0 pid=335014) $L__tmp3:
(EngineCore_DP0 pid=335014) $L__func_end0:
(EngineCore_DP0 pid=335014)                                         // -- End function
(EngineCore_DP0 pid=335014) }
(EngineCore_DP0 pid=335014) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=335014) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=335014) 	.section	.debug_abbrev
(EngineCore_DP0 pid=335014) 	{
(EngineCore_DP0 pid=335014) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=335014) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=335014) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=335014) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=335014) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=335014) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=335014) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=335014) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=335014) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=335014) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=335014) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=335014) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=335014) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=335014) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=335014) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=335014) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=335014) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=335014) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=335014) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=335014) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=335014) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=335014) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=335014) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=335014) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=335014) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=335014) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=335014) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=335014) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=335014) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=335014) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=335014) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=335014) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=335014) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=335014) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=335014) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=335014) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=335014) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=335014) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=335014) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=335014) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=335014) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=335014) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=335014) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=335014) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=335014) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=335014) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=335014) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=335014) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=335014) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=335014) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=335014) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=335014) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=335014) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=335014) 	}
(EngineCore_DP0 pid=335014) 	.section	.debug_info
(EngineCore_DP0 pid=335014) 	{
(EngineCore_DP0 pid=335014) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=335014) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=335014) .b8 0
(EngineCore_DP0 pid=335014) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=335014) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=335014) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=335014) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=335014) .b8 114
(EngineCore_DP0 pid=335014) .b8 105
(EngineCore_DP0 pid=335014) .b8 116
(EngineCore_DP0 pid=335014) .b8 111
(EngineCore_DP0 pid=335014) .b8 110
(EngineCore_DP0 pid=335014) .b8 0
(EngineCore_DP0 pid=335014) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=335014) .b8 0
(EngineCore_DP0 pid=335014) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=335014) .b8 117
(EngineCore_DP0 pid=335014) .b8 97
(EngineCore_DP0 pid=335014) .b8 110
(EngineCore_DP0 pid=335014) .b8 116
(EngineCore_DP0 pid=335014) .b8 95
(EngineCore_DP0 pid=335014) .b8 115
(EngineCore_DP0 pid=335014) .b8 108
(EngineCore_DP0 pid=335014) .b8 105
(EngineCore_DP0 pid=335014) .b8 100
(EngineCore_DP0 pid=335014) .b8 101
(EngineCore_DP0 pid=335014) .b8 95
(EngineCore_DP0 pid=335014) .b8 116
(EngineCore_DP0 pid=335014) .b8 117
(EngineCore_DP0 pid=335014) .b8 110
(EngineCore_DP0 pid=335014) .b8 101
(EngineCore_DP0 pid=335014) .b8 100
(EngineCore_DP0 pid=335014) .b8 95
(EngineCore_DP0 pid=335014) .b8 76
(EngineCore_DP0 pid=335014) .b8 108
(EngineCore_DP0 pid=335014) .b8 97
(EngineCore_DP0 pid=335014) .b8 109
(EngineCore_DP0 pid=335014) .b8 97
(EngineCore_DP0 pid=335014) .b8 51
(EngineCore_DP0 pid=335014) .b8 46
(EngineCore_DP0 pid=335014) .b8 50
(EngineCore_DP0 pid=335014) .b8 45
(EngineCore_DP0 pid=335014) .b8 49
(EngineCore_DP0 pid=335014) .b8 66
(EngineCore_DP0 pid=335014) .b8 46
(EngineCore_DP0 pid=335014) .b8 112
(EngineCore_DP0 pid=335014) .b8 121
(EngineCore_DP0 pid=335014) .b8 0
(EngineCore_DP0 pid=335014) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=335014) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=335014) .b8 114
(EngineCore_DP0 pid=335014) .b8 111
(EngineCore_DP0 pid=335014) .b8 111
(EngineCore_DP0 pid=335014) .b8 116
(EngineCore_DP0 pid=335014) .b8 47
(EngineCore_DP0 pid=335014) .b8 118
(EngineCore_DP0 pid=335014) .b8 108
(EngineCore_DP0 pid=335014) .b8 108
(EngineCore_DP0 pid=335014) .b8 109
(EngineCore_DP0 pid=335014) .b8 98
(EngineCore_DP0 pid=335014) .b8 101
(EngineCore_DP0 pid=335014) .b8 110
(EngineCore_DP0 pid=335014) .b8 99
(EngineCore_DP0 pid=335014) .b8 104
(EngineCore_DP0 pid=335014) .b8 47
(EngineCore_DP0 pid=335014) .b8 115
(EngineCore_DP0 pid=335014) .b8 108
(EngineCore_DP0 pid=335014) .b8 105
(EngineCore_DP0 pid=335014) .b8 100
(EngineCore_DP0 pid=335014) .b8 101
(EngineCore_DP0 pid=335014) .b8 115
(EngineCore_DP0 pid=335014) .b8 112
(EngineCore_DP0 pid=335014) .b8 97
(EngineCore_DP0 pid=335014) .b8 114
(EngineCore_DP0 pid=335014) .b8 115
(EngineCore_DP0 pid=335014) .b8 101
(EngineCore_DP0 pid=335014) .b8 47
(EngineCore_DP0 pid=335014) .b8 99
(EngineCore_DP0 pid=335014) .b8 115
(EngineCore_DP0 pid=335014) .b8 114
(EngineCore_DP0 pid=335014) .b8 99
(EngineCore_DP0 pid=335014) .b8 47
(EngineCore_DP0 pid=335014) .b8 102
(EngineCore_DP0 pid=335014) .b8 117
(EngineCore_DP0 pid=335014) .b8 115
(EngineCore_DP0 pid=335014) .b8 101
(EngineCore_DP0 pid=335014) .b8 100
(EngineCore_DP0 pid=335014) .b8 95
(EngineCore_DP0 pid=335014) .b8 113
(EngineCore_DP0 pid=335014) .b8 117
(EngineCore_DP0 pid=335014) .b8 97
(EngineCore_DP0 pid=335014) .b8 110
(EngineCore_DP0 pid=335014) .b8 116
(EngineCore_DP0 pid=335014) .b8 95
(EngineCore_DP0 pid=335014) .b8 115
(EngineCore_DP0 pid=335014) .b8 108
(EngineCore_DP0 pid=335014) .b8 105
(EngineCore_DP0 pid=335014) .b8 100
(EngineCore_DP0 pid=335014) .b8 101
(EngineCore_DP0 pid=335014) .b8 95
(EngineCore_DP0 pid=335014) .b8 116
(EngineCore_DP0 pid=335014) .b8 114
(EngineCore_DP0 pid=335014) .b8 105
(EngineCore_DP0 pid=335014) .b8 116
(EngineCore_DP0 pid=335014) .b8 111
(EngineCore_DP0 pid=335014) .b8 110
(EngineCore_DP0 pid=335014) .b8 47
(EngineCore_DP0 pid=335014) .b8 98
(EngineCore_DP0 pid=335014) .b8 117
(EngineCore_DP0 pid=335014) .b8 105
(EngineCore_DP0 pid=335014) .b8 108
(EngineCore_DP0 pid=335014) .b8 100
(EngineCore_DP0 pid=335014) .b8 47
(EngineCore_DP0 pid=335014) .b8 71
(EngineCore_DP0 pid=335014) .b8 66
(EngineCore_DP0 pid=335014) .b8 49
(EngineCore_DP0 pid=335014) .b8 48
(EngineCore_DP0 pid=335014) .b8 95
(EngineCore_DP0 pid=335014) .b8 99
(EngineCore_DP0 pid=335014) .b8 99
(EngineCore_DP0 pid=335014) .b8 49
(EngineCore_DP0 pid=335014) .b8 50
(EngineCore_DP0 pid=335014) .b8 49
(EngineCore_DP0 pid=335014) .b8 95
(EngineCore_DP0 pid=335014) .b8 112
(EngineCore_DP0 pid=335014) .b8 121
(EngineCore_DP0 pid=335014) .b8 51
(EngineCore_DP0 pid=335014) .b8 49
(EngineCore_DP0 pid=335014) .b8 50
(EngineCore_DP0 pid=335014) .b8 95
(EngineCore_DP0 pid=335014) .b8 99
(EngineCore_DP0 pid=335014) .b8 117
(EngineCore_DP0 pid=335014) .b8 49
(EngineCore_DP0 pid=335014) .b8 50
(EngineCore_DP0 pid=335014) .b8 57
(EngineCore_DP0 pid=335014) .b8 95
(EngineCore_DP0 pid=335014) .b8 97
(EngineCore_DP0 pid=335014) .b8 97
(EngineCore_DP0 pid=335014) .b8 114
(EngineCore_DP0 pid=335014) .b8 99
(EngineCore_DP0 pid=335014) .b8 104
(EngineCore_DP0 pid=335014) .b8 54
(EngineCore_DP0 pid=335014) .b8 52
(EngineCore_DP0 pid=335014) .b8 0
(EngineCore_DP0 pid=335014) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=335014) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=335014) .b8 113
(EngineCore_DP0 pid=335014) .b8 117
(EngineCore_DP0 pid=335014) .b8 97
(EngineCore_DP0 pid=335014) .b8 110
(EngineCore_DP0 pid=335014) .b8 116
(EngineCore_DP0 pid=335014) .b8 95
(EngineCore_DP0 pid=335014) .b8 115
(EngineCore_DP0 pid=335014) .b8 108
(EngineCore_DP0 pid=335014) .b8 105
(EngineCore_DP0 pid=335014) .b8 100
(EngineCore_DP0 pid=335014) .b8 101
(EngineCore_DP0 pid=335014) .b8 95
(EngineCore_DP0 pid=335014) .b8 102
(EngineCore_DP0 pid=335014) .b8 112
(EngineCore_DP0 pid=335014) .b8 56
(EngineCore_DP0 pid=335014) .b8 95
(EngineCore_DP0 pid=335014) .b8 107
(EngineCore_DP0 pid=335014) .b8 101
(EngineCore_DP0 pid=335014) .b8 114
(EngineCore_DP0 pid=335014) .b8 110
(EngineCore_DP0 pid=335014) .b8 101
(EngineCore_DP0 pid=335014) .b8 108
(EngineCore_DP0 pid=335014) .b8 0
(EngineCore_DP0 pid=335014) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=335014) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=335014) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=335014) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=335014) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=335014) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=335014) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=335014) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=335014) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=335014) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=335014) .b8 191                                 // DW_AT_call_line
(EngineCore_DP0 pid=335014) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=335014) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=335014) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=335014) 	}
(EngineCore_DP0 pid=335014) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=335014) 
(EngineCore_DP0 pid=335014) ================================================================
(EngineCore_DP0 pid=335014) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=335014) 
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpdqxd71zi.ptx', '-o', '/tmp/tmpdqxd71zi.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866] 
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866] 
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866] 
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpdqxd71zi.ptx -o /tmp/tmpdqxd71zi.ptx.o
(EngineCore_DP0 pid=335014) ERROR 01-25 19:14:51 [core.py:866] 

STDERR:
[2026-01-25 19:14:37] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:14:37] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:14:37] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:14:37] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:14:37] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:14:37] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:14:37] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:14:37] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:14:37] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:14:37] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:14:37] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:14:37] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:14:37] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:14:37] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:14:41] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:14:41] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:14:41] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:14:41] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:14:41] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:14:41] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:14:41] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:14:41] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:14:41] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:14:41] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:14:41] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:14:41] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:14:41] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:14:41] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=335014) [2026-01-25 19:14:42] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=335014) [2026-01-25 19:14:42] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=335014) [2026-01-25 19:14:42] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=335014) [2026-01-25 19:14:42] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=335014) [2026-01-25 19:14:42] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=335014) [2026-01-25 19:14:42] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=335014) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=335014) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.28s/it]
(EngineCore_DP0 pid=335014) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.28s/it]
(EngineCore_DP0 pid=335014) 
(EngineCore_DP0 pid=335014) [2026-01-25 19:14:50] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=335014) [2026-01-25 19:14:50] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=335014) [2026-01-25 19:14:50] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=335014) [2026-01-25 19:14:50] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 2621440 bytes
(EngineCore_DP0 pid=335014) [2026-01-25 19:14:50] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=335014) [2026-01-25 19:14:50] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 20971520 bytes
(EngineCore_DP0 pid=335014) [2026-01-25 19:14:50] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=335014) [2026-01-25 19:14:50] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10485760 bytes
(EngineCore_DP0 pid=335014) Process EngineCore_DP0:
(EngineCore_DP0 pid=335014) Traceback (most recent call last):
(EngineCore_DP0 pid=335014)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=335014)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=335014)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=335014)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=335014) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpdqxd71zi.ptx', '-o', '/tmp/tmpdqxd71zi.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=335014) 
(EngineCore_DP0 pid=335014) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=335014) 
(EngineCore_DP0 pid=335014) Traceback (most recent call last):
(EngineCore_DP0 pid=335014)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=335014)     self.run()
(EngineCore_DP0 pid=335014)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=335014)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=335014)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=335014)     raise e
(EngineCore_DP0 pid=335014)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=335014)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=335014)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=335014)     super().__init__(
(EngineCore_DP0 pid=335014)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=335014)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=335014)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=335014)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=335014)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=335014)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=335014)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=335014)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=335014)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=335014)     return func(*args, **kwargs)
(EngineCore_DP0 pid=335014)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=335014)     return func(*args, **kwargs)
(EngineCore_DP0 pid=335014)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=335014)     self.model_runner.profile_run()
(EngineCore_DP0 pid=335014)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=335014)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=335014)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=335014)     return func(*args, **kwargs)
(EngineCore_DP0 pid=335014)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=335014)     outputs = self.model(
(EngineCore_DP0 pid=335014)               ^^^^^^^^^^^
(EngineCore_DP0 pid=335014)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=335014)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=335014)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=335014)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=335014)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=335014)     model_output = self.model(
(EngineCore_DP0 pid=335014)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=335014)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=335014)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=335014)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=335014)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=335014)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=335014)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=335014)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=335014)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=335014)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=335014)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=335014)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=335014)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=335014)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=335014)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=335014)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=335014)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=335014)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=335014)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=335014)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=335014)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=335014)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=335014)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=335014)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=335014)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=335014)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=335014)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=335014)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=335014)     return self._linear_fn(
(EngineCore_DP0 pid=335014)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=335014)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=335014)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=335014)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=335014)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=335014)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=335014)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=335014)     return fn(input, L)
(EngineCore_DP0 pid=335014)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=335014)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=335014)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=335014)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=335014)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=335014)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=335014)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=335014)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=335014)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=335014)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=335014)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=335014)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=335014)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=335014)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335014)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=335014)     raise PTXASError(error)
(EngineCore_DP0 pid=335014) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=335014) `ptxas` stderr:
(EngineCore_DP0 pid=335014) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=335014) 
(EngineCore_DP0 pid=335014) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpdqxd71zi.ptx -o /tmp/tmpdqxd71zi.ptx.o
(EngineCore_DP0 pid=335014) 
[rank0]:[W125 19:14:51.084413852 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=8192

========== M=16384 ==========
Time: 2026-01-25 19:14:53
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Llama3.2-1B-FP8_M16384.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:15:02 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:15:02 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=335554) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=335554) 
(EngineCore_DP0 pid=335554) 
(EngineCore_DP0 pid=335554) ================================================================
(EngineCore_DP0 pid=335554) Internal Triton PTX codegen error
(EngineCore_DP0 pid=335554) `ptxas` stderr:
(EngineCore_DP0 pid=335554) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=335554) 
(EngineCore_DP0 pid=335554) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp2r_bx5js.ptx -o /tmp/tmp2r_bx5js.ptx.o
(EngineCore_DP0 pid=335554) 
(EngineCore_DP0 pid=335554) 
(EngineCore_DP0 pid=335554) //
(EngineCore_DP0 pid=335554) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=335554) //
(EngineCore_DP0 pid=335554) 
(EngineCore_DP0 pid=335554) .version 8.7
(EngineCore_DP0 pid=335554) .target sm_121a
(EngineCore_DP0 pid=335554) .address_size 64
(EngineCore_DP0 pid=335554) 
(EngineCore_DP0 pid=335554) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=335554) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=335554)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=335554) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=335554) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=335554) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=335554) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=335554) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=335554) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=335554) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=335554) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=335554) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=335554) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=335554) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=335554) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=335554) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=335554) )
(EngineCore_DP0 pid=335554) .reqntid 512
(EngineCore_DP0 pid=335554) {
(EngineCore_DP0 pid=335554) 	.reg .pred 	%p<44>;
(EngineCore_DP0 pid=335554) 	.reg .b16 	%rs<74>;
(EngineCore_DP0 pid=335554) 	.reg .b32 	%r<187>;
(EngineCore_DP0 pid=335554) 	.reg .b64 	%rd<25>;
(EngineCore_DP0 pid=335554) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=335554) $L__func_begin0:
(EngineCore_DP0 pid=335554) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=335554) 
(EngineCore_DP0 pid=335554) // %bb.0:
(EngineCore_DP0 pid=335554) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=335554) 	ld.param.b32 	%r22, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=335554) 	ld.param.b32 	%r21, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=335554) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=335554) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=335554) $L__tmp0:
(EngineCore_DP0 pid=335554) 	.loc	1 177 24                        // quant_slide_tuned_Llama3.2-1B.py:177:24
(EngineCore_DP0 pid=335554) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=335554) 	ld.param.b32 	%r25, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=335554) 	.loc	1 182 26                        // quant_slide_tuned_Llama3.2-1B.py:182:26
(EngineCore_DP0 pid=335554) 	mul.lo.s32 	%r26, %r25, %r1;
(EngineCore_DP0 pid=335554) 	.loc	1 182 20                        // quant_slide_tuned_Llama3.2-1B.py:182:20
(EngineCore_DP0 pid=335554) 	mad.wide.s32 	%rd1, %r26, 2, %rd4;
(EngineCore_DP0 pid=335554) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=335554) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=335554) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=335554) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=335554) 	setp.lt.s32 	%p1, %r22, 1;
(EngineCore_DP0 pid=335554) 	mov.b32 	%r184, 0f2B8CBCCC;
(EngineCore_DP0 pid=335554) 	setp.eq.b32 	%p43, %r2, 0;
(EngineCore_DP0 pid=335554) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=335554) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=335554) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=335554) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=335554) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=335554) 	shr.u32 	%r35, %r2, 3;
(EngineCore_DP0 pid=335554) 	and.b32 	%r36, %r35, 60;
(EngineCore_DP0 pid=335554) 	mov.b32 	%r37, global_smem;
(EngineCore_DP0 pid=335554) 	add.s32 	%r47, %r37, %r36;
(EngineCore_DP0 pid=335554) 	shl.b32 	%r38, %r2, 2;
(EngineCore_DP0 pid=335554) 	add.s32 	%r50, %r37, %r38;
(EngineCore_DP0 pid=335554) 	mov.b32 	%r43, 0;
(EngineCore_DP0 pid=335554) 	mov.b32 	%r182, 0f00000000;
(EngineCore_DP0 pid=335554) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=335554) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=335554) 	mov.b32 	%r183, %r43;
(EngineCore_DP0 pid=335554) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=335554) 	.loc	1 189 22                        // quant_slide_tuned_Llama3.2-1B.py:189:22
(EngineCore_DP0 pid=335554) 	add.s32 	%r53, %r4, %r183;
(EngineCore_DP0 pid=335554) 	setp.lt.s32 	%p2, %r53, %r21;
(EngineCore_DP0 pid=335554) 	.loc	1 190 29                        // quant_slide_tuned_Llama3.2-1B.py:190:29
(EngineCore_DP0 pid=335554) 	mad.wide.s32 	%rd6, %r53, 2, %rd1;
(EngineCore_DP0 pid=335554) 	.loc	1 190 21                        // quant_slide_tuned_Llama3.2-1B.py:190:21
(EngineCore_DP0 pid=335554) 	// begin inline asm
(EngineCore_DP0 pid=335554) 	mov.u32 %r39, %r43;
(EngineCore_DP0 pid=335554) 	mov.u32 %r40, %r43;
(EngineCore_DP0 pid=335554) 	mov.u32 %r41, %r43;
(EngineCore_DP0 pid=335554) 	mov.u32 %r42, %r43;
(EngineCore_DP0 pid=335554) 	@%p2 ld.global.v4.b32 { %r39, %r40, %r41, %r42 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=335554) 	// end inline asm
(EngineCore_DP0 pid=335554) 	mov.b32 	{%rs1, %rs2}, %r39;
(EngineCore_DP0 pid=335554) 	mov.b32 	{%rs3, %rs4}, %r40;
(EngineCore_DP0 pid=335554) 	mov.b32 	{%rs5, %rs6}, %r41;
(EngineCore_DP0 pid=335554) 	mov.b32 	{%rs7, %rs8}, %r42;
(EngineCore_DP0 pid=335554) 	.loc	1 191 50                        // quant_slide_tuned_Llama3.2-1B.py:191:50
(EngineCore_DP0 pid=335554) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=335554) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=335554) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=335554) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=335554) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=335554) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=335554) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=335554) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=335554) $L__tmp1:
(EngineCore_DP0 pid=335554) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=335554) 	bar.sync 	0;
(EngineCore_DP0 pid=335554) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=335554) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=335554) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=335554) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=335554) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=335554) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=335554) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=335554) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=335554) 	cvt.f32.bf16 	%r54, %rs23;
(EngineCore_DP0 pid=335554) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=335554) 	shfl.sync.bfly.b32 	%r55, %r54, 16, 31, -1;
(EngineCore_DP0 pid=335554) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=335554) 	max.f32 	%r56, %r54, %r55;
(EngineCore_DP0 pid=335554) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=335554) 	shfl.sync.bfly.b32 	%r57, %r56, 8, 31, -1;
(EngineCore_DP0 pid=335554) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=335554) 	max.f32 	%r58, %r56, %r57;
(EngineCore_DP0 pid=335554) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=335554) 	shfl.sync.bfly.b32 	%r59, %r58, 4, 31, -1;
(EngineCore_DP0 pid=335554) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=335554) 	max.f32 	%r60, %r58, %r59;
(EngineCore_DP0 pid=335554) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=335554) 	shfl.sync.bfly.b32 	%r61, %r60, 2, 31, -1;
(EngineCore_DP0 pid=335554) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=335554) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=335554) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=335554) 	shfl.sync.bfly.b32 	%r63, %r62, 1, 31, -1;
(EngineCore_DP0 pid=335554) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=335554) 	max.f32 	%r48, %r62, %r63;
(EngineCore_DP0 pid=335554) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=335554) 	// begin inline asm
(EngineCore_DP0 pid=335554) 	@%p3 st.shared.b32 [ %r47 + 0 ], %r48;
(EngineCore_DP0 pid=335554) 	// end inline asm
(EngineCore_DP0 pid=335554) 	bar.sync 	0;
(EngineCore_DP0 pid=335554) 	// begin inline asm
(EngineCore_DP0 pid=335554) 	@%p4 ld.shared.b32 %r49, [ %r50 + 0 ];
(EngineCore_DP0 pid=335554) 	// end inline asm
(EngineCore_DP0 pid=335554) 	shfl.sync.bfly.b32 	%r64, %r49, 8, 31, -1;
(EngineCore_DP0 pid=335554) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=335554) 	max.f32 	%r65, %r49, %r64;
(EngineCore_DP0 pid=335554) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=335554) 	shfl.sync.bfly.b32 	%r66, %r65, 4, 31, -1;
(EngineCore_DP0 pid=335554) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=335554) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=335554) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=335554) 	shfl.sync.bfly.b32 	%r68, %r67, 2, 31, -1;
(EngineCore_DP0 pid=335554) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=335554) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=335554) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=335554) 	shfl.sync.bfly.b32 	%r70, %r69, 1, 31, -1;
(EngineCore_DP0 pid=335554) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=335554) 	max.f32 	%r52, %r69, %r70;
(EngineCore_DP0 pid=335554) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=335554) 	// begin inline asm
(EngineCore_DP0 pid=335554) 	@%p43 st.shared.b32 [ %r50 + 0 ], %r52;
(EngineCore_DP0 pid=335554) 	// end inline asm
(EngineCore_DP0 pid=335554) 	bar.sync 	0;
(EngineCore_DP0 pid=335554) 	ld.shared.b32 	%r71, [global_smem];
(EngineCore_DP0 pid=335554) $L__tmp2:
(EngineCore_DP0 pid=335554) 	.loc	1 191 36                        // quant_slide_tuned_Llama3.2-1B.py:191:36
(EngineCore_DP0 pid=335554) 	max.f32 	%r182, %r182, %r71;
(EngineCore_DP0 pid=335554) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=335554) 	add.s32 	%r183, %r183, 4096;
(EngineCore_DP0 pid=335554) 	setp.lt.s32 	%p6, %r183, %r22;
(EngineCore_DP0 pid=335554) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=335554) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=335554) 	.loc	1 193 32                        // quant_slide_tuned_Llama3.2-1B.py:193:32
(EngineCore_DP0 pid=335554) 	max.f32 	%r184, %r182, 0f2B8CBCCC;
(EngineCore_DP0 pid=335554) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=335554) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=335554) 	mov.b32 	%r73, 0f43E00000;
(EngineCore_DP0 pid=335554) 	.loc	1 194 32                        // quant_slide_tuned_Llama3.2-1B.py:194:32
(EngineCore_DP0 pid=335554) 	div.full.f32 	%r74, %r184, %r73;
(EngineCore_DP0 pid=335554) 	.loc	1 194 41                        // quant_slide_tuned_Llama3.2-1B.py:194:41
(EngineCore_DP0 pid=335554) 	max.f32 	%r72, %r74, 0f36924925;
(EngineCore_DP0 pid=335554) 	.loc	1 196 25                        // quant_slide_tuned_Llama3.2-1B.py:196:25
(EngineCore_DP0 pid=335554) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=335554) 	.loc	1 196 30                        // quant_slide_tuned_Llama3.2-1B.py:196:30
(EngineCore_DP0 pid=335554) 	// begin inline asm
(EngineCore_DP0 pid=335554) 	@%p43 st.global.b32 [ %rd7 + 0 ], { %r72 };
(EngineCore_DP0 pid=335554) 	// end inline asm
(EngineCore_DP0 pid=335554) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=335554) 	setp.lt.s32 	%p8, %r23, 1;
(EngineCore_DP0 pid=335554) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=335554) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=335554) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=335554) 	ld.param.b32 	%r27, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=335554) 	shr.s32 	%r28, %r27, 31;
(EngineCore_DP0 pid=335554) 	shr.u32 	%r29, %r28, 30;
(EngineCore_DP0 pid=335554) 	add.s32 	%r30, %r27, %r29;
(EngineCore_DP0 pid=335554) 	shr.s32 	%r31, %r30, 2;
(EngineCore_DP0 pid=335554) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=335554) 	mul.lo.s32 	%r32, %r31, %r1;
(EngineCore_DP0 pid=335554) 	mad.wide.s32 	%rd2, %r32, 4, %rd5;
(EngineCore_DP0 pid=335554) 	div.full.f32 	%r14, %r73, %r184;
(EngineCore_DP0 pid=335554) 	shl.b32 	%r15, %r3, 2;
(EngineCore_DP0 pid=335554) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=335554) 	shl.b32 	%r76, %r3, 4;
(EngineCore_DP0 pid=335554) 	or.b32 	%r185, %r76, 15;
(EngineCore_DP0 pid=335554) 	mov.b32 	%r186, 0;
(EngineCore_DP0 pid=335554) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=335554)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=335554) 	.loc	1 203 30                        // quant_slide_tuned_Llama3.2-1B.py:203:30
(EngineCore_DP0 pid=335554) 	add.s32 	%r97, %r15, %r186;
(EngineCore_DP0 pid=335554) 	setp.lt.s32 	%p25, %r97, %r23;
(EngineCore_DP0 pid=335554) 	.loc	1 208 22                        // quant_slide_tuned_Llama3.2-1B.py:208:22
(EngineCore_DP0 pid=335554) 	add.s32 	%r98, %r185, -15;
(EngineCore_DP0 pid=335554) 	add.s32 	%r99, %r185, -11;
(EngineCore_DP0 pid=335554) 	add.s32 	%r100, %r185, -7;
(EngineCore_DP0 pid=335554) 	.loc	1 211 53                        // quant_slide_tuned_Llama3.2-1B.py:211:53
(EngineCore_DP0 pid=335554) 	add.s32 	%r101, %r185, -3;
(EngineCore_DP0 pid=335554) 	setp.lt.s32 	%p26, %r98, %r21;
(EngineCore_DP0 pid=335554) 	setp.lt.s32 	%p27, %r99, %r21;
(EngineCore_DP0 pid=335554) 	setp.lt.s32 	%p28, %r100, %r21;
(EngineCore_DP0 pid=335554) 	setp.lt.s32 	%p29, %r101, %r21;
(EngineCore_DP0 pid=335554) 	.loc	1 211 37                        // quant_slide_tuned_Llama3.2-1B.py:211:37
(EngineCore_DP0 pid=335554) 	and.pred 	%p9, %p25, %p26;
(EngineCore_DP0 pid=335554) 	and.pred 	%p10, %p25, %p27;
(EngineCore_DP0 pid=335554) 	and.pred 	%p11, %p25, %p28;
(EngineCore_DP0 pid=335554) 	and.pred 	%p12, %p25, %p29;
(EngineCore_DP0 pid=335554) 	.loc	1 210 29                        // quant_slide_tuned_Llama3.2-1B.py:210:29
(EngineCore_DP0 pid=335554) 	mad.wide.s32 	%rd8, %r98, 2, %rd1;
(EngineCore_DP0 pid=335554) 	add.s64 	%rd9, %rd8, 8;
(EngineCore_DP0 pid=335554) 	add.s64 	%rd10, %rd8, 16;
(EngineCore_DP0 pid=335554) 	add.s64 	%rd11, %rd8, 24;
(EngineCore_DP0 pid=335554) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=335554) 	.loc	1 210 21                        // quant_slide_tuned_Llama3.2-1B.py:210:21
(EngineCore_DP0 pid=335554) 	// begin inline asm
(EngineCore_DP0 pid=335554) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=335554) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=335554) 	// end inline asm
(EngineCore_DP0 pid=335554) 	// begin inline asm
(EngineCore_DP0 pid=335554) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=335554) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=335554) 	// end inline asm
(EngineCore_DP0 pid=335554) 	// begin inline asm
(EngineCore_DP0 pid=335554) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=335554) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=335554) 	// end inline asm
(EngineCore_DP0 pid=335554) 	// begin inline asm
(EngineCore_DP0 pid=335554) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=335554) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=335554) 	// end inline asm
(EngineCore_DP0 pid=335554) 	.loc	1 211 79                        // quant_slide_tuned_Llama3.2-1B.py:211:79
(EngineCore_DP0 pid=335554) 	cvt.f32.bf16 	%r102, %rs24;
(EngineCore_DP0 pid=335554) 	cvt.f32.bf16 	%r103, %rs26;
(EngineCore_DP0 pid=335554) 	cvt.f32.bf16 	%r104, %rs28;
(EngineCore_DP0 pid=335554) 	cvt.f32.bf16 	%r105, %rs30;
(EngineCore_DP0 pid=335554) 	.loc	1 213 48                        // quant_slide_tuned_Llama3.2-1B.py:213:48
(EngineCore_DP0 pid=335554) 	add.s32 	%r106, %r185, -14;
(EngineCore_DP0 pid=335554) 	add.s32 	%r107, %r185, -10;
(EngineCore_DP0 pid=335554) 	add.s32 	%r108, %r185, -6;
(EngineCore_DP0 pid=335554) 	.loc	1 213 53                        // quant_slide_tuned_Llama3.2-1B.py:213:53
(EngineCore_DP0 pid=335554) 	add.s32 	%r109, %r185, -2;
(EngineCore_DP0 pid=335554) 	setp.lt.s32 	%p30, %r106, %r21;
(EngineCore_DP0 pid=335554) 	setp.lt.s32 	%p31, %r107, %r21;
(EngineCore_DP0 pid=335554) 	setp.lt.s32 	%p32, %r108, %r21;
(EngineCore_DP0 pid=335554) 	setp.lt.s32 	%p33, %r109, %r21;
(EngineCore_DP0 pid=335554) 	.loc	1 213 37                        // quant_slide_tuned_Llama3.2-1B.py:213:37
(EngineCore_DP0 pid=335554) 	and.pred 	%p13, %p25, %p30;
(EngineCore_DP0 pid=335554) 	and.pred 	%p14, %p25, %p31;
(EngineCore_DP0 pid=335554) 	and.pred 	%p15, %p25, %p32;
(EngineCore_DP0 pid=335554) 	and.pred 	%p16, %p25, %p33;
(EngineCore_DP0 pid=335554) 	.loc	1 212 39                        // quant_slide_tuned_Llama3.2-1B.py:212:39
(EngineCore_DP0 pid=335554) 	add.s64 	%rd12, %rd8, 2;
(EngineCore_DP0 pid=335554) 	add.s64 	%rd13, %rd8, 10;
(EngineCore_DP0 pid=335554) 	add.s64 	%rd14, %rd8, 18;
(EngineCore_DP0 pid=335554) 	add.s64 	%rd15, %rd8, 26;
(EngineCore_DP0 pid=335554) 	.loc	1 212 21                        // quant_slide_tuned_Llama3.2-1B.py:212:21
(EngineCore_DP0 pid=335554) 	// begin inline asm
(EngineCore_DP0 pid=335554) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=335554) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=335554) 	// end inline asm
(EngineCore_DP0 pid=335554) 	// begin inline asm
(EngineCore_DP0 pid=335554) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=335554) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=335554) 	// end inline asm
(EngineCore_DP0 pid=335554) 	// begin inline asm
(EngineCore_DP0 pid=335554) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=335554) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=335554) 	// end inline asm
(EngineCore_DP0 pid=335554) 	// begin inline asm
(EngineCore_DP0 pid=335554) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=335554) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=335554) 	// end inline asm
(EngineCore_DP0 pid=335554) 	.loc	1 213 79                        // quant_slide_tuned_Llama3.2-1B.py:213:79
(EngineCore_DP0 pid=335554) 	cvt.f32.bf16 	%r110, %rs32;
(EngineCore_DP0 pid=335554) 	cvt.f32.bf16 	%r111, %rs34;
(EngineCore_DP0 pid=335554) 	cvt.f32.bf16 	%r112, %rs36;
(EngineCore_DP0 pid=335554) 	cvt.f32.bf16 	%r113, %rs38;
(EngineCore_DP0 pid=335554) 	.loc	1 215 48                        // quant_slide_tuned_Llama3.2-1B.py:215:48
(EngineCore_DP0 pid=335554) 	add.s32 	%r114, %r185, -13;
(EngineCore_DP0 pid=335554) 	add.s32 	%r115, %r185, -9;
(EngineCore_DP0 pid=335554) 	add.s32 	%r116, %r185, -5;
(EngineCore_DP0 pid=335554) 	.loc	1 215 53                        // quant_slide_tuned_Llama3.2-1B.py:215:53
(EngineCore_DP0 pid=335554) 	add.s32 	%r117, %r185, -1;
(EngineCore_DP0 pid=335554) 	setp.lt.s32 	%p34, %r114, %r21;
(EngineCore_DP0 pid=335554) 	setp.lt.s32 	%p35, %r115, %r21;
(EngineCore_DP0 pid=335554) 	setp.lt.s32 	%p36, %r116, %r21;
(EngineCore_DP0 pid=335554) 	setp.lt.s32 	%p37, %r117, %r21;
(EngineCore_DP0 pid=335554) 	.loc	1 215 37                        // quant_slide_tuned_Llama3.2-1B.py:215:37
(EngineCore_DP0 pid=335554) 	and.pred 	%p17, %p25, %p34;
(EngineCore_DP0 pid=335554) 	and.pred 	%p18, %p25, %p35;
(EngineCore_DP0 pid=335554) 	and.pred 	%p19, %p25, %p36;
(EngineCore_DP0 pid=335554) 	and.pred 	%p20, %p25, %p37;
(EngineCore_DP0 pid=335554) 	.loc	1 214 39                        // quant_slide_tuned_Llama3.2-1B.py:214:39
(EngineCore_DP0 pid=335554) 	add.s64 	%rd16, %rd8, 4;
(EngineCore_DP0 pid=335554) 	add.s64 	%rd17, %rd8, 12;
(EngineCore_DP0 pid=335554) 	add.s64 	%rd18, %rd8, 20;
(EngineCore_DP0 pid=335554) 	add.s64 	%rd19, %rd8, 28;
(EngineCore_DP0 pid=335554) 	.loc	1 214 21                        // quant_slide_tuned_Llama3.2-1B.py:214:21
(EngineCore_DP0 pid=335554) 	// begin inline asm
(EngineCore_DP0 pid=335554) 	mov.u16 %rs40, %rs25;
(EngineCore_DP0 pid=335554) 	@%p17 ld.global.b16 { %rs40 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=335554) 	// end inline asm
(EngineCore_DP0 pid=335554) 	// begin inline asm
(EngineCore_DP0 pid=335554) 	mov.u16 %rs42, %rs25;
(EngineCore_DP0 pid=335554) 	@%p18 ld.global.b16 { %rs42 }, [ %rd17 + 0 ];
(EngineCore_DP0 pid=335554) 	// end inline asm
(EngineCore_DP0 pid=335554) 	// begin inline asm
(EngineCore_DP0 pid=335554) 	mov.u16 %rs44, %rs25;
(EngineCore_DP0 pid=335554) 	@%p19 ld.global.b16 { %rs44 }, [ %rd18 + 0 ];
(EngineCore_DP0 pid=335554) 	// end inline asm
(EngineCore_DP0 pid=335554) 	// begin inline asm
(EngineCore_DP0 pid=335554) 	mov.u16 %rs46, %rs25;
(EngineCore_DP0 pid=335554) 	@%p20 ld.global.b16 { %rs46 }, [ %rd19 + 0 ];
(EngineCore_DP0 pid=335554) 	// end inline asm
(EngineCore_DP0 pid=335554) 	.loc	1 215 79                        // quant_slide_tuned_Llama3.2-1B.py:215:79
(EngineCore_DP0 pid=335554) 	cvt.f32.bf16 	%r118, %rs40;
(EngineCore_DP0 pid=335554) 	cvt.f32.bf16 	%r119, %rs42;
(EngineCore_DP0 pid=335554) 	cvt.f32.bf16 	%r120, %rs44;
(EngineCore_DP0 pid=335554) 	cvt.f32.bf16 	%r121, %rs46;
(EngineCore_DP0 pid=335554) 	.loc	1 217 48                        // quant_slide_tuned_Llama3.2-1B.py:217:48
(EngineCore_DP0 pid=335554) 	add.s32 	%r122, %r185, -12;
(EngineCore_DP0 pid=335554) 	add.s32 	%r123, %r185, -8;
(EngineCore_DP0 pid=335554) 	add.s32 	%r124, %r185, -4;
(EngineCore_DP0 pid=335554) 	.loc	1 217 53                        // quant_slide_tuned_Llama3.2-1B.py:217:53
(EngineCore_DP0 pid=335554) 	setp.lt.s32 	%p38, %r122, %r21;
(EngineCore_DP0 pid=335554) 	setp.lt.s32 	%p39, %r123, %r21;
(EngineCore_DP0 pid=335554) 	setp.lt.s32 	%p40, %r124, %r21;
(EngineCore_DP0 pid=335554) 	setp.lt.s32 	%p41, %r185, %r21;
(EngineCore_DP0 pid=335554) 	.loc	1 217 37                        // quant_slide_tuned_Llama3.2-1B.py:217:37
(EngineCore_DP0 pid=335554) 	and.pred 	%p21, %p25, %p38;
(EngineCore_DP0 pid=335554) 	and.pred 	%p22, %p25, %p39;
(EngineCore_DP0 pid=335554) 	and.pred 	%p23, %p25, %p40;
(EngineCore_DP0 pid=335554) 	and.pred 	%p24, %p25, %p41;
(EngineCore_DP0 pid=335554) 	.loc	1 216 39                        // quant_slide_tuned_Llama3.2-1B.py:216:39
(EngineCore_DP0 pid=335554) 	add.s64 	%rd20, %rd8, 6;
(EngineCore_DP0 pid=335554) 	add.s64 	%rd21, %rd8, 14;
(EngineCore_DP0 pid=335554) 	add.s64 	%rd22, %rd8, 22;
(EngineCore_DP0 pid=335554) 	add.s64 	%rd23, %rd8, 30;
(EngineCore_DP0 pid=335554) 	.loc	1 216 21                        // quant_slide_tuned_Llama3.2-1B.py:216:21
(EngineCore_DP0 pid=335554) 	// begin inline asm
(EngineCore_DP0 pid=335554) 	mov.u16 %rs48, %rs25;
(EngineCore_DP0 pid=335554) 	@%p21 ld.global.b16 { %rs48 }, [ %rd20 + 0 ];
(EngineCore_DP0 pid=335554) 	// end inline asm
(EngineCore_DP0 pid=335554) 	// begin inline asm
(EngineCore_DP0 pid=335554) 	mov.u16 %rs50, %rs25;
(EngineCore_DP0 pid=335554) 	@%p22 ld.global.b16 { %rs50 }, [ %rd21 + 0 ];
(EngineCore_DP0 pid=335554) 	// end inline asm
(EngineCore_DP0 pid=335554) 	// begin inline asm
(EngineCore_DP0 pid=335554) 	mov.u16 %rs52, %rs25;
(EngineCore_DP0 pid=335554) 	@%p23 ld.global.b16 { %rs52 }, [ %rd22 + 0 ];
(EngineCore_DP0 pid=335554) 	// end inline asm
(EngineCore_DP0 pid=335554) 	// begin inline asm
(EngineCore_DP0 pid=335554) 	mov.u16 %rs54, %rs25;
(EngineCore_DP0 pid=335554) 	@%p24 ld.global.b16 { %rs54 }, [ %rd23 + 0 ];
(EngineCore_DP0 pid=335554) 	// end inline asm
(EngineCore_DP0 pid=335554) 	.loc	1 217 79                        // quant_slide_tuned_Llama3.2-1B.py:217:79
(EngineCore_DP0 pid=335554) 	cvt.f32.bf16 	%r125, %rs48;
(EngineCore_DP0 pid=335554) 	cvt.f32.bf16 	%r126, %rs50;
(EngineCore_DP0 pid=335554) 	cvt.f32.bf16 	%r127, %rs52;
(EngineCore_DP0 pid=335554) 	cvt.f32.bf16 	%r128, %rs54;
(EngineCore_DP0 pid=335554) 	.loc	1 219 27                        // quant_slide_tuned_Llama3.2-1B.py:219:27
(EngineCore_DP0 pid=335554) 	mul.f32 	%r129, %r14, %r102;
(EngineCore_DP0 pid=335554) 	mul.f32 	%r130, %r14, %r103;
(EngineCore_DP0 pid=335554) 	mul.f32 	%r131, %r14, %r104;
(EngineCore_DP0 pid=335554) 	mul.f32 	%r132, %r14, %r105;
(EngineCore_DP0 pid=335554) 	mov.b32 	%r133, 0f43E00000;
(EngineCore_DP0 pid=335554) 	.loc	1 219 48                        // quant_slide_tuned_Llama3.2-1B.py:219:48
(EngineCore_DP0 pid=335554) 	min.xorsign.abs.f32 	%r77, %r129, %r133;
(EngineCore_DP0 pid=335554) 	min.xorsign.abs.f32 	%r78, %r130, %r133;
(EngineCore_DP0 pid=335554) 	min.xorsign.abs.f32 	%r79, %r131, %r133;
(EngineCore_DP0 pid=335554) 	min.xorsign.abs.f32 	%r80, %r132, %r133;
(EngineCore_DP0 pid=335554) 	.loc	1 219 60                        // quant_slide_tuned_Llama3.2-1B.py:219:60
(EngineCore_DP0 pid=335554) 	// begin inline asm
(EngineCore_DP0 pid=335554) 	cvt.rn.satfinite.e4m3x2.f32  %rs56, %r78, %r77; 
(EngineCore_DP0 pid=335554) 
(EngineCore_DP0 pid=335554) 	// end inline asm
(EngineCore_DP0 pid=335554) 	shr.u16 	%rs64, %rs56, 8;
(EngineCore_DP0 pid=335554) 	// begin inline asm
(EngineCore_DP0 pid=335554) 	cvt.rn.satfinite.e4m3x2.f32  %rs57, %r80, %r79; 
(EngineCore_DP0 pid=335554) 
(EngineCore_DP0 pid=335554) 	// end inline asm
(EngineCore_DP0 pid=335554) 	shr.u16 	%rs65, %rs57, 8;
(EngineCore_DP0 pid=335554) 	.loc	1 220 27                        // quant_slide_tuned_Llama3.2-1B.py:220:27
(EngineCore_DP0 pid=335554) 	mul.f32 	%r134, %r14, %r110;
(EngineCore_DP0 pid=335554) 	mul.f32 	%r135, %r14, %r111;
(EngineCore_DP0 pid=335554) 	mul.f32 	%r136, %r14, %r112;
(EngineCore_DP0 pid=335554) 	mul.f32 	%r137, %r14, %r113;
(EngineCore_DP0 pid=335554) 	.loc	1 220 48                        // quant_slide_tuned_Llama3.2-1B.py:220:48
(EngineCore_DP0 pid=335554) 	min.xorsign.abs.f32 	%r81, %r134, %r133;
(EngineCore_DP0 pid=335554) 	min.xorsign.abs.f32 	%r82, %r135, %r133;
(EngineCore_DP0 pid=335554) 	min.xorsign.abs.f32 	%r83, %r136, %r133;
(EngineCore_DP0 pid=335554) 	min.xorsign.abs.f32 	%r84, %r137, %r133;
(EngineCore_DP0 pid=335554) 	.loc	1 220 60                        // quant_slide_tuned_Llama3.2-1B.py:220:60
(EngineCore_DP0 pid=335554) 	// begin inline asm
(EngineCore_DP0 pid=335554) 	cvt.rn.satfinite.e4m3x2.f32  %rs58, %r82, %r81; 
(EngineCore_DP0 pid=335554) 
(EngineCore_DP0 pid=335554) 	// end inline asm
(EngineCore_DP0 pid=335554) 	shr.u16 	%rs66, %rs58, 8;
(EngineCore_DP0 pid=335554) 	// begin inline asm
(EngineCore_DP0 pid=335554) 	cvt.rn.satfinite.e4m3x2.f32  %rs59, %r84, %r83; 
(EngineCore_DP0 pid=335554) 
(EngineCore_DP0 pid=335554) 	// end inline asm
(EngineCore_DP0 pid=335554) 	shr.u16 	%rs67, %rs59, 8;
(EngineCore_DP0 pid=335554) 	.loc	1 221 27                        // quant_slide_tuned_Llama3.2-1B.py:221:27
(EngineCore_DP0 pid=335554) 	mul.f32 	%r138, %r14, %r118;
(EngineCore_DP0 pid=335554) 	mul.f32 	%r139, %r14, %r119;
(EngineCore_DP0 pid=335554) 	mul.f32 	%r140, %r14, %r120;
(EngineCore_DP0 pid=335554) 	mul.f32 	%r141, %r14, %r121;
(EngineCore_DP0 pid=335554) 	.loc	1 221 48                        // quant_slide_tuned_Llama3.2-1B.py:221:48
(EngineCore_DP0 pid=335554) 	min.xorsign.abs.f32 	%r85, %r138, %r133;
(EngineCore_DP0 pid=335554) 	min.xorsign.abs.f32 	%r86, %r139, %r133;
(EngineCore_DP0 pid=335554) 	min.xorsign.abs.f32 	%r87, %r140, %r133;
(EngineCore_DP0 pid=335554) 	min.xorsign.abs.f32 	%r88, %r141, %r133;
(EngineCore_DP0 pid=335554) 	.loc	1 221 60                        // quant_slide_tuned_Llama3.2-1B.py:221:60
(EngineCore_DP0 pid=335554) 	// begin inline asm
(EngineCore_DP0 pid=335554) 	cvt.rn.satfinite.e4m3x2.f32  %rs60, %r86, %r85; 
(EngineCore_DP0 pid=335554) 
(EngineCore_DP0 pid=335554) 	// end inline asm
(EngineCore_DP0 pid=335554) 	shr.u16 	%rs68, %rs60, 8;
(EngineCore_DP0 pid=335554) 	// begin inline asm
(EngineCore_DP0 pid=335554) 	cvt.rn.satfinite.e4m3x2.f32  %rs61, %r88, %r87; 
(EngineCore_DP0 pid=335554) 
(EngineCore_DP0 pid=335554) 	// end inline asm
(EngineCore_DP0 pid=335554) 	shr.u16 	%rs69, %rs61, 8;
(EngineCore_DP0 pid=335554) 	.loc	1 222 27                        // quant_slide_tuned_Llama3.2-1B.py:222:27
(EngineCore_DP0 pid=335554) 	mul.f32 	%r142, %r14, %r125;
(EngineCore_DP0 pid=335554) 	mul.f32 	%r143, %r14, %r126;
(EngineCore_DP0 pid=335554) 	mul.f32 	%r144, %r14, %r127;
(EngineCore_DP0 pid=335554) 	mul.f32 	%r145, %r14, %r128;
(EngineCore_DP0 pid=335554) 	.loc	1 222 48                        // quant_slide_tuned_Llama3.2-1B.py:222:48
(EngineCore_DP0 pid=335554) 	min.xorsign.abs.f32 	%r89, %r142, %r133;
(EngineCore_DP0 pid=335554) 	min.xorsign.abs.f32 	%r90, %r143, %r133;
(EngineCore_DP0 pid=335554) 	min.xorsign.abs.f32 	%r91, %r144, %r133;
(EngineCore_DP0 pid=335554) 	min.xorsign.abs.f32 	%r92, %r145, %r133;
(EngineCore_DP0 pid=335554) 	.loc	1 222 60                        // quant_slide_tuned_Llama3.2-1B.py:222:60
(EngineCore_DP0 pid=335554) 	// begin inline asm
(EngineCore_DP0 pid=335554) 	cvt.rn.satfinite.e4m3x2.f32  %rs62, %r90, %r89; 
(EngineCore_DP0 pid=335554) 
(EngineCore_DP0 pid=335554) 	// end inline asm
(EngineCore_DP0 pid=335554) 	shr.u16 	%rs70, %rs62, 8;
(EngineCore_DP0 pid=335554) 	// begin inline asm
(EngineCore_DP0 pid=335554) 	cvt.rn.satfinite.e4m3x2.f32  %rs63, %r92, %r91; 
(EngineCore_DP0 pid=335554) 
(EngineCore_DP0 pid=335554) 	// end inline asm
(EngineCore_DP0 pid=335554) 	shr.u16 	%rs71, %rs63, 8;
(EngineCore_DP0 pid=335554) 	.loc	1 224 45                        // quant_slide_tuned_Llama3.2-1B.py:224:45
(EngineCore_DP0 pid=335554) 	cvt.u32.u16 	%r146, %rs56;
(EngineCore_DP0 pid=335554) 	and.b32 	%r147, %r146, 255;
(EngineCore_DP0 pid=335554) 	cvt.u32.u16 	%r148, %rs64;
(EngineCore_DP0 pid=335554) 	cvt.u32.u16 	%r149, %rs57;
(EngineCore_DP0 pid=335554) 	and.b32 	%r150, %r149, 255;
(EngineCore_DP0 pid=335554) 	cvt.u32.u16 	%r151, %rs65;
(EngineCore_DP0 pid=335554) 	.loc	1 226 45                        // quant_slide_tuned_Llama3.2-1B.py:226:45
(EngineCore_DP0 pid=335554) 	cvt.u32.u16 	%r152, %rs60;
(EngineCore_DP0 pid=335554) 	and.b32 	%r153, %r152, 255;
(EngineCore_DP0 pid=335554) 	cvt.u32.u16 	%r154, %rs68;
(EngineCore_DP0 pid=335554) 	cvt.u32.u16 	%r155, %rs61;
(EngineCore_DP0 pid=335554) 	and.b32 	%r156, %r155, 255;
(EngineCore_DP0 pid=335554) 	cvt.u32.u16 	%r157, %rs69;
(EngineCore_DP0 pid=335554) 	.loc	1 227 45                        // quant_slide_tuned_Llama3.2-1B.py:227:45
(EngineCore_DP0 pid=335554) 	cvt.u32.u16 	%r158, %rs62;
(EngineCore_DP0 pid=335554) 	cvt.u32.u16 	%r159, %rs70;
(EngineCore_DP0 pid=335554) 	cvt.u32.u16 	%r160, %rs63;
(EngineCore_DP0 pid=335554) 	cvt.u32.u16 	%r161, %rs71;
(EngineCore_DP0 pid=335554) 	.loc	1 229 30                        // quant_slide_tuned_Llama3.2-1B.py:229:30
(EngineCore_DP0 pid=335554) 	and.b16 	%rs72, %rs58, 255;
(EngineCore_DP0 pid=335554) 	mul.wide.u16 	%r162, %rs72, 256;
(EngineCore_DP0 pid=335554) 	mul.wide.u16 	%r163, %rs66, 256;
(EngineCore_DP0 pid=335554) 	and.b16 	%rs73, %rs59, 255;
(EngineCore_DP0 pid=335554) 	mul.wide.u16 	%r164, %rs73, 256;
(EngineCore_DP0 pid=335554) 	mul.wide.u16 	%r165, %rs67, 256;
(EngineCore_DP0 pid=335554) 	.loc	1 229 24                        // quant_slide_tuned_Llama3.2-1B.py:229:24
(EngineCore_DP0 pid=335554) 	or.b32 	%r166, %r162, %r147;
(EngineCore_DP0 pid=335554) 	or.b32 	%r167, %r163, %r148;
(EngineCore_DP0 pid=335554) 	or.b32 	%r168, %r164, %r150;
(EngineCore_DP0 pid=335554) 	or.b32 	%r169, %r165, %r151;
(EngineCore_DP0 pid=335554) 	.loc	1 229 42                        // quant_slide_tuned_Llama3.2-1B.py:229:42
(EngineCore_DP0 pid=335554) 	shl.b32 	%r170, %r153, 16;
(EngineCore_DP0 pid=335554) 	shl.b32 	%r171, %r154, 16;
(EngineCore_DP0 pid=335554) 	shl.b32 	%r172, %r156, 16;
(EngineCore_DP0 pid=335554) 	shl.b32 	%r173, %r157, 16;
(EngineCore_DP0 pid=335554) 	.loc	1 229 36                        // quant_slide_tuned_Llama3.2-1B.py:229:36
(EngineCore_DP0 pid=335554) 	or.b32 	%r174, %r170, %r166;
(EngineCore_DP0 pid=335554) 	or.b32 	%r175, %r171, %r167;
(EngineCore_DP0 pid=335554) 	or.b32 	%r176, %r172, %r168;
(EngineCore_DP0 pid=335554) 	or.b32 	%r177, %r173, %r169;
(EngineCore_DP0 pid=335554) 	.loc	1 229 55                        // quant_slide_tuned_Llama3.2-1B.py:229:55
(EngineCore_DP0 pid=335554) 	shl.b32 	%r178, %r158, 24;
(EngineCore_DP0 pid=335554) 	shl.b32 	%r179, %r159, 24;
(EngineCore_DP0 pid=335554) 	shl.b32 	%r180, %r160, 24;
(EngineCore_DP0 pid=335554) 	shl.b32 	%r181, %r161, 24;
(EngineCore_DP0 pid=335554) 	.loc	1 229 49                        // quant_slide_tuned_Llama3.2-1B.py:229:49
(EngineCore_DP0 pid=335554) 	or.b32 	%r93, %r178, %r174;
(EngineCore_DP0 pid=335554) 	or.b32 	%r94, %r179, %r175;
(EngineCore_DP0 pid=335554) 	or.b32 	%r95, %r180, %r176;
(EngineCore_DP0 pid=335554) 	or.b32 	%r96, %r181, %r177;
(EngineCore_DP0 pid=335554) 	.loc	1 230 29                        // quant_slide_tuned_Llama3.2-1B.py:230:29
(EngineCore_DP0 pid=335554) 	mad.wide.s32 	%rd24, %r97, 4, %rd2;
(EngineCore_DP0 pid=335554) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-1B.py:230:39
(EngineCore_DP0 pid=335554) 	// begin inline asm
(EngineCore_DP0 pid=335554) 	@%p25 st.global.v4.b32 [ %rd24 + 0 ], { %r93, %r94, %r95, %r96 };
(EngineCore_DP0 pid=335554) 	// end inline asm
(EngineCore_DP0 pid=335554) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=335554) 	add.s32 	%r186, %r186, 2048;
(EngineCore_DP0 pid=335554) 	add.s32 	%r185, %r185, 8192;
(EngineCore_DP0 pid=335554) 	setp.lt.s32 	%p42, %r186, %r23;
(EngineCore_DP0 pid=335554) 	@%p42 bra 	$L__BB0_6;
(EngineCore_DP0 pid=335554) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=335554) 	.loc	1 201 4                         // quant_slide_tuned_Llama3.2-1B.py:201:4
(EngineCore_DP0 pid=335554) 	ret;
(EngineCore_DP0 pid=335554) $L__tmp3:
(EngineCore_DP0 pid=335554) $L__func_end0:
(EngineCore_DP0 pid=335554)                                         // -- End function
(EngineCore_DP0 pid=335554) }
(EngineCore_DP0 pid=335554) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=335554) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=335554) 	.section	.debug_abbrev
(EngineCore_DP0 pid=335554) 	{
(EngineCore_DP0 pid=335554) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=335554) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=335554) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=335554) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=335554) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=335554) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=335554) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=335554) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=335554) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=335554) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=335554) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=335554) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=335554) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=335554) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=335554) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=335554) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=335554) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=335554) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=335554) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=335554) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=335554) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=335554) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=335554) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=335554) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=335554) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=335554) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=335554) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=335554) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=335554) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=335554) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=335554) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=335554) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=335554) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=335554) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=335554) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=335554) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=335554) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=335554) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=335554) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=335554) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=335554) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=335554) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=335554) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=335554) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=335554) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=335554) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=335554) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=335554) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=335554) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=335554) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=335554) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=335554) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=335554) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=335554) 	}
(EngineCore_DP0 pid=335554) 	.section	.debug_info
(EngineCore_DP0 pid=335554) 	{
(EngineCore_DP0 pid=335554) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=335554) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=335554) .b8 0
(EngineCore_DP0 pid=335554) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=335554) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=335554) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=335554) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=335554) .b8 114
(EngineCore_DP0 pid=335554) .b8 105
(EngineCore_DP0 pid=335554) .b8 116
(EngineCore_DP0 pid=335554) .b8 111
(EngineCore_DP0 pid=335554) .b8 110
(EngineCore_DP0 pid=335554) .b8 0
(EngineCore_DP0 pid=335554) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=335554) .b8 0
(EngineCore_DP0 pid=335554) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=335554) .b8 117
(EngineCore_DP0 pid=335554) .b8 97
(EngineCore_DP0 pid=335554) .b8 110
(EngineCore_DP0 pid=335554) .b8 116
(EngineCore_DP0 pid=335554) .b8 95
(EngineCore_DP0 pid=335554) .b8 115
(EngineCore_DP0 pid=335554) .b8 108
(EngineCore_DP0 pid=335554) .b8 105
(EngineCore_DP0 pid=335554) .b8 100
(EngineCore_DP0 pid=335554) .b8 101
(EngineCore_DP0 pid=335554) .b8 95
(EngineCore_DP0 pid=335554) .b8 116
(EngineCore_DP0 pid=335554) .b8 117
(EngineCore_DP0 pid=335554) .b8 110
(EngineCore_DP0 pid=335554) .b8 101
(EngineCore_DP0 pid=335554) .b8 100
(EngineCore_DP0 pid=335554) .b8 95
(EngineCore_DP0 pid=335554) .b8 76
(EngineCore_DP0 pid=335554) .b8 108
(EngineCore_DP0 pid=335554) .b8 97
(EngineCore_DP0 pid=335554) .b8 109
(EngineCore_DP0 pid=335554) .b8 97
(EngineCore_DP0 pid=335554) .b8 51
(EngineCore_DP0 pid=335554) .b8 46
(EngineCore_DP0 pid=335554) .b8 50
(EngineCore_DP0 pid=335554) .b8 45
(EngineCore_DP0 pid=335554) .b8 49
(EngineCore_DP0 pid=335554) .b8 66
(EngineCore_DP0 pid=335554) .b8 46
(EngineCore_DP0 pid=335554) .b8 112
(EngineCore_DP0 pid=335554) .b8 121
(EngineCore_DP0 pid=335554) .b8 0
(EngineCore_DP0 pid=335554) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=335554) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=335554) .b8 114
(EngineCore_DP0 pid=335554) .b8 111
(EngineCore_DP0 pid=335554) .b8 111
(EngineCore_DP0 pid=335554) .b8 116
(EngineCore_DP0 pid=335554) .b8 47
(EngineCore_DP0 pid=335554) .b8 118
(EngineCore_DP0 pid=335554) .b8 108
(EngineCore_DP0 pid=335554) .b8 108
(EngineCore_DP0 pid=335554) .b8 109
(EngineCore_DP0 pid=335554) .b8 98
(EngineCore_DP0 pid=335554) .b8 101
(EngineCore_DP0 pid=335554) .b8 110
(EngineCore_DP0 pid=335554) .b8 99
(EngineCore_DP0 pid=335554) .b8 104
(EngineCore_DP0 pid=335554) .b8 47
(EngineCore_DP0 pid=335554) .b8 115
(EngineCore_DP0 pid=335554) .b8 108
(EngineCore_DP0 pid=335554) .b8 105
(EngineCore_DP0 pid=335554) .b8 100
(EngineCore_DP0 pid=335554) .b8 101
(EngineCore_DP0 pid=335554) .b8 115
(EngineCore_DP0 pid=335554) .b8 112
(EngineCore_DP0 pid=335554) .b8 97
(EngineCore_DP0 pid=335554) .b8 114
(EngineCore_DP0 pid=335554) .b8 115
(EngineCore_DP0 pid=335554) .b8 101
(EngineCore_DP0 pid=335554) .b8 47
(EngineCore_DP0 pid=335554) .b8 99
(EngineCore_DP0 pid=335554) .b8 115
(EngineCore_DP0 pid=335554) .b8 114
(EngineCore_DP0 pid=335554) .b8 99
(EngineCore_DP0 pid=335554) .b8 47
(EngineCore_DP0 pid=335554) .b8 102
(EngineCore_DP0 pid=335554) .b8 117
(EngineCore_DP0 pid=335554) .b8 115
(EngineCore_DP0 pid=335554) .b8 101
(EngineCore_DP0 pid=335554) .b8 100
(EngineCore_DP0 pid=335554) .b8 95
(EngineCore_DP0 pid=335554) .b8 113
(EngineCore_DP0 pid=335554) .b8 117
(EngineCore_DP0 pid=335554) .b8 97
(EngineCore_DP0 pid=335554) .b8 110
(EngineCore_DP0 pid=335554) .b8 116
(EngineCore_DP0 pid=335554) .b8 95
(EngineCore_DP0 pid=335554) .b8 115
(EngineCore_DP0 pid=335554) .b8 108
(EngineCore_DP0 pid=335554) .b8 105
(EngineCore_DP0 pid=335554) .b8 100
(EngineCore_DP0 pid=335554) .b8 101
(EngineCore_DP0 pid=335554) .b8 95
(EngineCore_DP0 pid=335554) .b8 116
(EngineCore_DP0 pid=335554) .b8 114
(EngineCore_DP0 pid=335554) .b8 105
(EngineCore_DP0 pid=335554) .b8 116
(EngineCore_DP0 pid=335554) .b8 111
(EngineCore_DP0 pid=335554) .b8 110
(EngineCore_DP0 pid=335554) .b8 47
(EngineCore_DP0 pid=335554) .b8 98
(EngineCore_DP0 pid=335554) .b8 117
(EngineCore_DP0 pid=335554) .b8 105
(EngineCore_DP0 pid=335554) .b8 108
(EngineCore_DP0 pid=335554) .b8 100
(EngineCore_DP0 pid=335554) .b8 47
(EngineCore_DP0 pid=335554) .b8 71
(EngineCore_DP0 pid=335554) .b8 66
(EngineCore_DP0 pid=335554) .b8 49
(EngineCore_DP0 pid=335554) .b8 48
(EngineCore_DP0 pid=335554) .b8 95
(EngineCore_DP0 pid=335554) .b8 99
(EngineCore_DP0 pid=335554) .b8 99
(EngineCore_DP0 pid=335554) .b8 49
(EngineCore_DP0 pid=335554) .b8 50
(EngineCore_DP0 pid=335554) .b8 49
(EngineCore_DP0 pid=335554) .b8 95
(EngineCore_DP0 pid=335554) .b8 112
(EngineCore_DP0 pid=335554) .b8 121
(EngineCore_DP0 pid=335554) .b8 51
(EngineCore_DP0 pid=335554) .b8 49
(EngineCore_DP0 pid=335554) .b8 50
(EngineCore_DP0 pid=335554) .b8 95
(EngineCore_DP0 pid=335554) .b8 99
(EngineCore_DP0 pid=335554) .b8 117
(EngineCore_DP0 pid=335554) .b8 49
(EngineCore_DP0 pid=335554) .b8 50
(EngineCore_DP0 pid=335554) .b8 57
(EngineCore_DP0 pid=335554) .b8 95
(EngineCore_DP0 pid=335554) .b8 97
(EngineCore_DP0 pid=335554) .b8 97
(EngineCore_DP0 pid=335554) .b8 114
(EngineCore_DP0 pid=335554) .b8 99
(EngineCore_DP0 pid=335554) .b8 104
(EngineCore_DP0 pid=335554) .b8 54
(EngineCore_DP0 pid=335554) .b8 52
(EngineCore_DP0 pid=335554) .b8 0
(EngineCore_DP0 pid=335554) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=335554) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=335554) .b8 113
(EngineCore_DP0 pid=335554) .b8 117
(EngineCore_DP0 pid=335554) .b8 97
(EngineCore_DP0 pid=335554) .b8 110
(EngineCore_DP0 pid=335554) .b8 116
(EngineCore_DP0 pid=335554) .b8 95
(EngineCore_DP0 pid=335554) .b8 115
(EngineCore_DP0 pid=335554) .b8 108
(EngineCore_DP0 pid=335554) .b8 105
(EngineCore_DP0 pid=335554) .b8 100
(EngineCore_DP0 pid=335554) .b8 101
(EngineCore_DP0 pid=335554) .b8 95
(EngineCore_DP0 pid=335554) .b8 102
(EngineCore_DP0 pid=335554) .b8 112
(EngineCore_DP0 pid=335554) .b8 56
(EngineCore_DP0 pid=335554) .b8 95
(EngineCore_DP0 pid=335554) .b8 107
(EngineCore_DP0 pid=335554) .b8 101
(EngineCore_DP0 pid=335554) .b8 114
(EngineCore_DP0 pid=335554) .b8 110
(EngineCore_DP0 pid=335554) .b8 101
(EngineCore_DP0 pid=335554) .b8 108
(EngineCore_DP0 pid=335554) .b8 0
(EngineCore_DP0 pid=335554) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=335554) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=335554) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=335554) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=335554) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=335554) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=335554) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=335554) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=335554) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=335554) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=335554) .b8 191                                 // DW_AT_call_line
(EngineCore_DP0 pid=335554) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=335554) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=335554) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=335554) 	}
(EngineCore_DP0 pid=335554) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=335554) 
(EngineCore_DP0 pid=335554) ================================================================
(EngineCore_DP0 pid=335554) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=335554) 
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp2r_bx5js.ptx', '-o', '/tmp/tmp2r_bx5js.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866] 
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866] 
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866] 
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp2r_bx5js.ptx -o /tmp/tmp2r_bx5js.ptx.o
(EngineCore_DP0 pid=335554) ERROR 01-25 19:15:16 [core.py:866] 

STDERR:
[2026-01-25 19:15:02] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:15:02] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:15:02] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:15:02] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:15:02] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:15:02] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:15:02] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:15:02] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:15:02] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:15:02] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:15:02] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:15:02] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:15:02] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:15:02] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:15:06] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:15:06] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:15:06] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:15:06] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:15:06] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:15:06] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:15:06] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:15:06] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:15:06] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:15:06] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:15:06] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:15:06] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:15:06] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:15:06] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=335554) [2026-01-25 19:15:07] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=335554) [2026-01-25 19:15:07] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=335554) [2026-01-25 19:15:07] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=335554) [2026-01-25 19:15:07] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=335554) [2026-01-25 19:15:07] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=335554) [2026-01-25 19:15:07] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=335554) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=335554) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.08s/it]
(EngineCore_DP0 pid=335554) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.08s/it]
(EngineCore_DP0 pid=335554) 
(EngineCore_DP0 pid=335554) [2026-01-25 19:15:15] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=335554) [2026-01-25 19:15:15] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=335554) [2026-01-25 19:15:15] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=335554) [2026-01-25 19:15:15] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 2621440 bytes
(EngineCore_DP0 pid=335554) [2026-01-25 19:15:15] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=335554) [2026-01-25 19:15:15] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 20971520 bytes
(EngineCore_DP0 pid=335554) [2026-01-25 19:15:15] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=335554) [2026-01-25 19:15:15] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10485760 bytes
(EngineCore_DP0 pid=335554) Process EngineCore_DP0:
(EngineCore_DP0 pid=335554) Traceback (most recent call last):
(EngineCore_DP0 pid=335554)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=335554)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=335554)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=335554)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=335554) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp2r_bx5js.ptx', '-o', '/tmp/tmp2r_bx5js.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=335554) 
(EngineCore_DP0 pid=335554) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=335554) 
(EngineCore_DP0 pid=335554) Traceback (most recent call last):
(EngineCore_DP0 pid=335554)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=335554)     self.run()
(EngineCore_DP0 pid=335554)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=335554)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=335554)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=335554)     raise e
(EngineCore_DP0 pid=335554)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=335554)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=335554)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=335554)     super().__init__(
(EngineCore_DP0 pid=335554)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=335554)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=335554)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=335554)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=335554)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=335554)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=335554)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=335554)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=335554)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=335554)     return func(*args, **kwargs)
(EngineCore_DP0 pid=335554)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=335554)     return func(*args, **kwargs)
(EngineCore_DP0 pid=335554)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=335554)     self.model_runner.profile_run()
(EngineCore_DP0 pid=335554)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=335554)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=335554)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=335554)     return func(*args, **kwargs)
(EngineCore_DP0 pid=335554)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=335554)     outputs = self.model(
(EngineCore_DP0 pid=335554)               ^^^^^^^^^^^
(EngineCore_DP0 pid=335554)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=335554)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=335554)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=335554)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=335554)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=335554)     model_output = self.model(
(EngineCore_DP0 pid=335554)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=335554)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=335554)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=335554)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=335554)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=335554)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=335554)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=335554)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=335554)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=335554)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=335554)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=335554)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=335554)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=335554)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=335554)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=335554)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=335554)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=335554)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=335554)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=335554)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=335554)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=335554)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=335554)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=335554)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=335554)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=335554)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=335554)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=335554)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=335554)     return self._linear_fn(
(EngineCore_DP0 pid=335554)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=335554)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=335554)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=335554)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=335554)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=335554)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=335554)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=335554)     return fn(input, L)
(EngineCore_DP0 pid=335554)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=335554)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=335554)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=335554)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=335554)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=335554)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=335554)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=335554)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=335554)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=335554)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=335554)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=335554)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=335554)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=335554)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=335554)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=335554)     raise PTXASError(error)
(EngineCore_DP0 pid=335554) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=335554) `ptxas` stderr:
(EngineCore_DP0 pid=335554) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=335554) 
(EngineCore_DP0 pid=335554) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp2r_bx5js.ptx -o /tmp/tmp2r_bx5js.ptx.o
(EngineCore_DP0 pid=335554) 
[rank0]:[W125 19:15:17.213825301 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=16384

========== M=32768 ==========
Time: 2026-01-25 19:15:18
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Llama3.2-1B-FP8_M32768.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:15:33 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:15:33 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=336164) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=336164) 
(EngineCore_DP0 pid=336164) 
(EngineCore_DP0 pid=336164) ================================================================
(EngineCore_DP0 pid=336164) Internal Triton PTX codegen error
(EngineCore_DP0 pid=336164) `ptxas` stderr:
(EngineCore_DP0 pid=336164) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=336164) 
(EngineCore_DP0 pid=336164) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpt3urcmss.ptx -o /tmp/tmpt3urcmss.ptx.o
(EngineCore_DP0 pid=336164) 
(EngineCore_DP0 pid=336164) 
(EngineCore_DP0 pid=336164) //
(EngineCore_DP0 pid=336164) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=336164) //
(EngineCore_DP0 pid=336164) 
(EngineCore_DP0 pid=336164) .version 8.7
(EngineCore_DP0 pid=336164) .target sm_121a
(EngineCore_DP0 pid=336164) .address_size 64
(EngineCore_DP0 pid=336164) 
(EngineCore_DP0 pid=336164) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=336164) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=336164)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=336164) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=336164) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=336164) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=336164) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=336164) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=336164) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=336164) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=336164) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=336164) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=336164) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=336164) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=336164) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=336164) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=336164) )
(EngineCore_DP0 pid=336164) .reqntid 512
(EngineCore_DP0 pid=336164) {
(EngineCore_DP0 pid=336164) 	.reg .pred 	%p<44>;
(EngineCore_DP0 pid=336164) 	.reg .b16 	%rs<74>;
(EngineCore_DP0 pid=336164) 	.reg .b32 	%r<187>;
(EngineCore_DP0 pid=336164) 	.reg .b64 	%rd<25>;
(EngineCore_DP0 pid=336164) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=336164) $L__func_begin0:
(EngineCore_DP0 pid=336164) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=336164) 
(EngineCore_DP0 pid=336164) // %bb.0:
(EngineCore_DP0 pid=336164) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=336164) 	ld.param.b32 	%r22, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=336164) 	ld.param.b32 	%r21, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=336164) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=336164) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=336164) $L__tmp0:
(EngineCore_DP0 pid=336164) 	.loc	1 177 24                        // quant_slide_tuned_Llama3.2-1B.py:177:24
(EngineCore_DP0 pid=336164) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=336164) 	ld.param.b32 	%r25, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=336164) 	.loc	1 182 26                        // quant_slide_tuned_Llama3.2-1B.py:182:26
(EngineCore_DP0 pid=336164) 	mul.lo.s32 	%r26, %r25, %r1;
(EngineCore_DP0 pid=336164) 	.loc	1 182 20                        // quant_slide_tuned_Llama3.2-1B.py:182:20
(EngineCore_DP0 pid=336164) 	mad.wide.s32 	%rd1, %r26, 2, %rd4;
(EngineCore_DP0 pid=336164) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=336164) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=336164) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=336164) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=336164) 	setp.lt.s32 	%p1, %r22, 1;
(EngineCore_DP0 pid=336164) 	mov.b32 	%r184, 0f2B8CBCCC;
(EngineCore_DP0 pid=336164) 	setp.eq.b32 	%p43, %r2, 0;
(EngineCore_DP0 pid=336164) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=336164) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=336164) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=336164) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=336164) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=336164) 	shr.u32 	%r35, %r2, 3;
(EngineCore_DP0 pid=336164) 	and.b32 	%r36, %r35, 60;
(EngineCore_DP0 pid=336164) 	mov.b32 	%r37, global_smem;
(EngineCore_DP0 pid=336164) 	add.s32 	%r47, %r37, %r36;
(EngineCore_DP0 pid=336164) 	shl.b32 	%r38, %r2, 2;
(EngineCore_DP0 pid=336164) 	add.s32 	%r50, %r37, %r38;
(EngineCore_DP0 pid=336164) 	mov.b32 	%r43, 0;
(EngineCore_DP0 pid=336164) 	mov.b32 	%r182, 0f00000000;
(EngineCore_DP0 pid=336164) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=336164) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=336164) 	mov.b32 	%r183, %r43;
(EngineCore_DP0 pid=336164) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=336164) 	.loc	1 189 22                        // quant_slide_tuned_Llama3.2-1B.py:189:22
(EngineCore_DP0 pid=336164) 	add.s32 	%r53, %r4, %r183;
(EngineCore_DP0 pid=336164) 	setp.lt.s32 	%p2, %r53, %r21;
(EngineCore_DP0 pid=336164) 	.loc	1 190 29                        // quant_slide_tuned_Llama3.2-1B.py:190:29
(EngineCore_DP0 pid=336164) 	mad.wide.s32 	%rd6, %r53, 2, %rd1;
(EngineCore_DP0 pid=336164) 	.loc	1 190 21                        // quant_slide_tuned_Llama3.2-1B.py:190:21
(EngineCore_DP0 pid=336164) 	// begin inline asm
(EngineCore_DP0 pid=336164) 	mov.u32 %r39, %r43;
(EngineCore_DP0 pid=336164) 	mov.u32 %r40, %r43;
(EngineCore_DP0 pid=336164) 	mov.u32 %r41, %r43;
(EngineCore_DP0 pid=336164) 	mov.u32 %r42, %r43;
(EngineCore_DP0 pid=336164) 	@%p2 ld.global.v4.b32 { %r39, %r40, %r41, %r42 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=336164) 	// end inline asm
(EngineCore_DP0 pid=336164) 	mov.b32 	{%rs1, %rs2}, %r39;
(EngineCore_DP0 pid=336164) 	mov.b32 	{%rs3, %rs4}, %r40;
(EngineCore_DP0 pid=336164) 	mov.b32 	{%rs5, %rs6}, %r41;
(EngineCore_DP0 pid=336164) 	mov.b32 	{%rs7, %rs8}, %r42;
(EngineCore_DP0 pid=336164) 	.loc	1 191 50                        // quant_slide_tuned_Llama3.2-1B.py:191:50
(EngineCore_DP0 pid=336164) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=336164) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=336164) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=336164) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=336164) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=336164) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=336164) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=336164) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=336164) $L__tmp1:
(EngineCore_DP0 pid=336164) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=336164) 	bar.sync 	0;
(EngineCore_DP0 pid=336164) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=336164) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=336164) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=336164) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=336164) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=336164) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=336164) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=336164) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=336164) 	cvt.f32.bf16 	%r54, %rs23;
(EngineCore_DP0 pid=336164) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=336164) 	shfl.sync.bfly.b32 	%r55, %r54, 16, 31, -1;
(EngineCore_DP0 pid=336164) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=336164) 	max.f32 	%r56, %r54, %r55;
(EngineCore_DP0 pid=336164) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=336164) 	shfl.sync.bfly.b32 	%r57, %r56, 8, 31, -1;
(EngineCore_DP0 pid=336164) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=336164) 	max.f32 	%r58, %r56, %r57;
(EngineCore_DP0 pid=336164) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=336164) 	shfl.sync.bfly.b32 	%r59, %r58, 4, 31, -1;
(EngineCore_DP0 pid=336164) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=336164) 	max.f32 	%r60, %r58, %r59;
(EngineCore_DP0 pid=336164) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=336164) 	shfl.sync.bfly.b32 	%r61, %r60, 2, 31, -1;
(EngineCore_DP0 pid=336164) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=336164) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=336164) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=336164) 	shfl.sync.bfly.b32 	%r63, %r62, 1, 31, -1;
(EngineCore_DP0 pid=336164) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=336164) 	max.f32 	%r48, %r62, %r63;
(EngineCore_DP0 pid=336164) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=336164) 	// begin inline asm
(EngineCore_DP0 pid=336164) 	@%p3 st.shared.b32 [ %r47 + 0 ], %r48;
(EngineCore_DP0 pid=336164) 	// end inline asm
(EngineCore_DP0 pid=336164) 	bar.sync 	0;
(EngineCore_DP0 pid=336164) 	// begin inline asm
(EngineCore_DP0 pid=336164) 	@%p4 ld.shared.b32 %r49, [ %r50 + 0 ];
(EngineCore_DP0 pid=336164) 	// end inline asm
(EngineCore_DP0 pid=336164) 	shfl.sync.bfly.b32 	%r64, %r49, 8, 31, -1;
(EngineCore_DP0 pid=336164) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=336164) 	max.f32 	%r65, %r49, %r64;
(EngineCore_DP0 pid=336164) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=336164) 	shfl.sync.bfly.b32 	%r66, %r65, 4, 31, -1;
(EngineCore_DP0 pid=336164) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=336164) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=336164) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=336164) 	shfl.sync.bfly.b32 	%r68, %r67, 2, 31, -1;
(EngineCore_DP0 pid=336164) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=336164) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=336164) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=336164) 	shfl.sync.bfly.b32 	%r70, %r69, 1, 31, -1;
(EngineCore_DP0 pid=336164) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=336164) 	max.f32 	%r52, %r69, %r70;
(EngineCore_DP0 pid=336164) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=336164) 	// begin inline asm
(EngineCore_DP0 pid=336164) 	@%p43 st.shared.b32 [ %r50 + 0 ], %r52;
(EngineCore_DP0 pid=336164) 	// end inline asm
(EngineCore_DP0 pid=336164) 	bar.sync 	0;
(EngineCore_DP0 pid=336164) 	ld.shared.b32 	%r71, [global_smem];
(EngineCore_DP0 pid=336164) $L__tmp2:
(EngineCore_DP0 pid=336164) 	.loc	1 191 36                        // quant_slide_tuned_Llama3.2-1B.py:191:36
(EngineCore_DP0 pid=336164) 	max.f32 	%r182, %r182, %r71;
(EngineCore_DP0 pid=336164) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=336164) 	add.s32 	%r183, %r183, 4096;
(EngineCore_DP0 pid=336164) 	setp.lt.s32 	%p6, %r183, %r22;
(EngineCore_DP0 pid=336164) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=336164) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=336164) 	.loc	1 193 32                        // quant_slide_tuned_Llama3.2-1B.py:193:32
(EngineCore_DP0 pid=336164) 	max.f32 	%r184, %r182, 0f2B8CBCCC;
(EngineCore_DP0 pid=336164) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=336164) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=336164) 	mov.b32 	%r73, 0f43E00000;
(EngineCore_DP0 pid=336164) 	.loc	1 194 32                        // quant_slide_tuned_Llama3.2-1B.py:194:32
(EngineCore_DP0 pid=336164) 	div.full.f32 	%r74, %r184, %r73;
(EngineCore_DP0 pid=336164) 	.loc	1 194 41                        // quant_slide_tuned_Llama3.2-1B.py:194:41
(EngineCore_DP0 pid=336164) 	max.f32 	%r72, %r74, 0f36924925;
(EngineCore_DP0 pid=336164) 	.loc	1 196 25                        // quant_slide_tuned_Llama3.2-1B.py:196:25
(EngineCore_DP0 pid=336164) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=336164) 	.loc	1 196 30                        // quant_slide_tuned_Llama3.2-1B.py:196:30
(EngineCore_DP0 pid=336164) 	// begin inline asm
(EngineCore_DP0 pid=336164) 	@%p43 st.global.b32 [ %rd7 + 0 ], { %r72 };
(EngineCore_DP0 pid=336164) 	// end inline asm
(EngineCore_DP0 pid=336164) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=336164) 	setp.lt.s32 	%p8, %r23, 1;
(EngineCore_DP0 pid=336164) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=336164) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=336164) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=336164) 	ld.param.b32 	%r27, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=336164) 	shr.s32 	%r28, %r27, 31;
(EngineCore_DP0 pid=336164) 	shr.u32 	%r29, %r28, 30;
(EngineCore_DP0 pid=336164) 	add.s32 	%r30, %r27, %r29;
(EngineCore_DP0 pid=336164) 	shr.s32 	%r31, %r30, 2;
(EngineCore_DP0 pid=336164) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=336164) 	mul.lo.s32 	%r32, %r31, %r1;
(EngineCore_DP0 pid=336164) 	mad.wide.s32 	%rd2, %r32, 4, %rd5;
(EngineCore_DP0 pid=336164) 	div.full.f32 	%r14, %r73, %r184;
(EngineCore_DP0 pid=336164) 	shl.b32 	%r15, %r3, 2;
(EngineCore_DP0 pid=336164) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=336164) 	shl.b32 	%r76, %r3, 4;
(EngineCore_DP0 pid=336164) 	or.b32 	%r185, %r76, 15;
(EngineCore_DP0 pid=336164) 	mov.b32 	%r186, 0;
(EngineCore_DP0 pid=336164) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=336164)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=336164) 	.loc	1 203 30                        // quant_slide_tuned_Llama3.2-1B.py:203:30
(EngineCore_DP0 pid=336164) 	add.s32 	%r97, %r15, %r186;
(EngineCore_DP0 pid=336164) 	setp.lt.s32 	%p25, %r97, %r23;
(EngineCore_DP0 pid=336164) 	.loc	1 208 22                        // quant_slide_tuned_Llama3.2-1B.py:208:22
(EngineCore_DP0 pid=336164) 	add.s32 	%r98, %r185, -15;
(EngineCore_DP0 pid=336164) 	add.s32 	%r99, %r185, -11;
(EngineCore_DP0 pid=336164) 	add.s32 	%r100, %r185, -7;
(EngineCore_DP0 pid=336164) 	.loc	1 211 53                        // quant_slide_tuned_Llama3.2-1B.py:211:53
(EngineCore_DP0 pid=336164) 	add.s32 	%r101, %r185, -3;
(EngineCore_DP0 pid=336164) 	setp.lt.s32 	%p26, %r98, %r21;
(EngineCore_DP0 pid=336164) 	setp.lt.s32 	%p27, %r99, %r21;
(EngineCore_DP0 pid=336164) 	setp.lt.s32 	%p28, %r100, %r21;
(EngineCore_DP0 pid=336164) 	setp.lt.s32 	%p29, %r101, %r21;
(EngineCore_DP0 pid=336164) 	.loc	1 211 37                        // quant_slide_tuned_Llama3.2-1B.py:211:37
(EngineCore_DP0 pid=336164) 	and.pred 	%p9, %p25, %p26;
(EngineCore_DP0 pid=336164) 	and.pred 	%p10, %p25, %p27;
(EngineCore_DP0 pid=336164) 	and.pred 	%p11, %p25, %p28;
(EngineCore_DP0 pid=336164) 	and.pred 	%p12, %p25, %p29;
(EngineCore_DP0 pid=336164) 	.loc	1 210 29                        // quant_slide_tuned_Llama3.2-1B.py:210:29
(EngineCore_DP0 pid=336164) 	mad.wide.s32 	%rd8, %r98, 2, %rd1;
(EngineCore_DP0 pid=336164) 	add.s64 	%rd9, %rd8, 8;
(EngineCore_DP0 pid=336164) 	add.s64 	%rd10, %rd8, 16;
(EngineCore_DP0 pid=336164) 	add.s64 	%rd11, %rd8, 24;
(EngineCore_DP0 pid=336164) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=336164) 	.loc	1 210 21                        // quant_slide_tuned_Llama3.2-1B.py:210:21
(EngineCore_DP0 pid=336164) 	// begin inline asm
(EngineCore_DP0 pid=336164) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=336164) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=336164) 	// end inline asm
(EngineCore_DP0 pid=336164) 	// begin inline asm
(EngineCore_DP0 pid=336164) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=336164) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=336164) 	// end inline asm
(EngineCore_DP0 pid=336164) 	// begin inline asm
(EngineCore_DP0 pid=336164) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=336164) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=336164) 	// end inline asm
(EngineCore_DP0 pid=336164) 	// begin inline asm
(EngineCore_DP0 pid=336164) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=336164) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=336164) 	// end inline asm
(EngineCore_DP0 pid=336164) 	.loc	1 211 79                        // quant_slide_tuned_Llama3.2-1B.py:211:79
(EngineCore_DP0 pid=336164) 	cvt.f32.bf16 	%r102, %rs24;
(EngineCore_DP0 pid=336164) 	cvt.f32.bf16 	%r103, %rs26;
(EngineCore_DP0 pid=336164) 	cvt.f32.bf16 	%r104, %rs28;
(EngineCore_DP0 pid=336164) 	cvt.f32.bf16 	%r105, %rs30;
(EngineCore_DP0 pid=336164) 	.loc	1 213 48                        // quant_slide_tuned_Llama3.2-1B.py:213:48
(EngineCore_DP0 pid=336164) 	add.s32 	%r106, %r185, -14;
(EngineCore_DP0 pid=336164) 	add.s32 	%r107, %r185, -10;
(EngineCore_DP0 pid=336164) 	add.s32 	%r108, %r185, -6;
(EngineCore_DP0 pid=336164) 	.loc	1 213 53                        // quant_slide_tuned_Llama3.2-1B.py:213:53
(EngineCore_DP0 pid=336164) 	add.s32 	%r109, %r185, -2;
(EngineCore_DP0 pid=336164) 	setp.lt.s32 	%p30, %r106, %r21;
(EngineCore_DP0 pid=336164) 	setp.lt.s32 	%p31, %r107, %r21;
(EngineCore_DP0 pid=336164) 	setp.lt.s32 	%p32, %r108, %r21;
(EngineCore_DP0 pid=336164) 	setp.lt.s32 	%p33, %r109, %r21;
(EngineCore_DP0 pid=336164) 	.loc	1 213 37                        // quant_slide_tuned_Llama3.2-1B.py:213:37
(EngineCore_DP0 pid=336164) 	and.pred 	%p13, %p25, %p30;
(EngineCore_DP0 pid=336164) 	and.pred 	%p14, %p25, %p31;
(EngineCore_DP0 pid=336164) 	and.pred 	%p15, %p25, %p32;
(EngineCore_DP0 pid=336164) 	and.pred 	%p16, %p25, %p33;
(EngineCore_DP0 pid=336164) 	.loc	1 212 39                        // quant_slide_tuned_Llama3.2-1B.py:212:39
(EngineCore_DP0 pid=336164) 	add.s64 	%rd12, %rd8, 2;
(EngineCore_DP0 pid=336164) 	add.s64 	%rd13, %rd8, 10;
(EngineCore_DP0 pid=336164) 	add.s64 	%rd14, %rd8, 18;
(EngineCore_DP0 pid=336164) 	add.s64 	%rd15, %rd8, 26;
(EngineCore_DP0 pid=336164) 	.loc	1 212 21                        // quant_slide_tuned_Llama3.2-1B.py:212:21
(EngineCore_DP0 pid=336164) 	// begin inline asm
(EngineCore_DP0 pid=336164) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=336164) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=336164) 	// end inline asm
(EngineCore_DP0 pid=336164) 	// begin inline asm
(EngineCore_DP0 pid=336164) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=336164) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=336164) 	// end inline asm
(EngineCore_DP0 pid=336164) 	// begin inline asm
(EngineCore_DP0 pid=336164) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=336164) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=336164) 	// end inline asm
(EngineCore_DP0 pid=336164) 	// begin inline asm
(EngineCore_DP0 pid=336164) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=336164) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=336164) 	// end inline asm
(EngineCore_DP0 pid=336164) 	.loc	1 213 79                        // quant_slide_tuned_Llama3.2-1B.py:213:79
(EngineCore_DP0 pid=336164) 	cvt.f32.bf16 	%r110, %rs32;
(EngineCore_DP0 pid=336164) 	cvt.f32.bf16 	%r111, %rs34;
(EngineCore_DP0 pid=336164) 	cvt.f32.bf16 	%r112, %rs36;
(EngineCore_DP0 pid=336164) 	cvt.f32.bf16 	%r113, %rs38;
(EngineCore_DP0 pid=336164) 	.loc	1 215 48                        // quant_slide_tuned_Llama3.2-1B.py:215:48
(EngineCore_DP0 pid=336164) 	add.s32 	%r114, %r185, -13;
(EngineCore_DP0 pid=336164) 	add.s32 	%r115, %r185, -9;
(EngineCore_DP0 pid=336164) 	add.s32 	%r116, %r185, -5;
(EngineCore_DP0 pid=336164) 	.loc	1 215 53                        // quant_slide_tuned_Llama3.2-1B.py:215:53
(EngineCore_DP0 pid=336164) 	add.s32 	%r117, %r185, -1;
(EngineCore_DP0 pid=336164) 	setp.lt.s32 	%p34, %r114, %r21;
(EngineCore_DP0 pid=336164) 	setp.lt.s32 	%p35, %r115, %r21;
(EngineCore_DP0 pid=336164) 	setp.lt.s32 	%p36, %r116, %r21;
(EngineCore_DP0 pid=336164) 	setp.lt.s32 	%p37, %r117, %r21;
(EngineCore_DP0 pid=336164) 	.loc	1 215 37                        // quant_slide_tuned_Llama3.2-1B.py:215:37
(EngineCore_DP0 pid=336164) 	and.pred 	%p17, %p25, %p34;
(EngineCore_DP0 pid=336164) 	and.pred 	%p18, %p25, %p35;
(EngineCore_DP0 pid=336164) 	and.pred 	%p19, %p25, %p36;
(EngineCore_DP0 pid=336164) 	and.pred 	%p20, %p25, %p37;
(EngineCore_DP0 pid=336164) 	.loc	1 214 39                        // quant_slide_tuned_Llama3.2-1B.py:214:39
(EngineCore_DP0 pid=336164) 	add.s64 	%rd16, %rd8, 4;
(EngineCore_DP0 pid=336164) 	add.s64 	%rd17, %rd8, 12;
(EngineCore_DP0 pid=336164) 	add.s64 	%rd18, %rd8, 20;
(EngineCore_DP0 pid=336164) 	add.s64 	%rd19, %rd8, 28;
(EngineCore_DP0 pid=336164) 	.loc	1 214 21                        // quant_slide_tuned_Llama3.2-1B.py:214:21
(EngineCore_DP0 pid=336164) 	// begin inline asm
(EngineCore_DP0 pid=336164) 	mov.u16 %rs40, %rs25;
(EngineCore_DP0 pid=336164) 	@%p17 ld.global.b16 { %rs40 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=336164) 	// end inline asm
(EngineCore_DP0 pid=336164) 	// begin inline asm
(EngineCore_DP0 pid=336164) 	mov.u16 %rs42, %rs25;
(EngineCore_DP0 pid=336164) 	@%p18 ld.global.b16 { %rs42 }, [ %rd17 + 0 ];
(EngineCore_DP0 pid=336164) 	// end inline asm
(EngineCore_DP0 pid=336164) 	// begin inline asm
(EngineCore_DP0 pid=336164) 	mov.u16 %rs44, %rs25;
(EngineCore_DP0 pid=336164) 	@%p19 ld.global.b16 { %rs44 }, [ %rd18 + 0 ];
(EngineCore_DP0 pid=336164) 	// end inline asm
(EngineCore_DP0 pid=336164) 	// begin inline asm
(EngineCore_DP0 pid=336164) 	mov.u16 %rs46, %rs25;
(EngineCore_DP0 pid=336164) 	@%p20 ld.global.b16 { %rs46 }, [ %rd19 + 0 ];
(EngineCore_DP0 pid=336164) 	// end inline asm
(EngineCore_DP0 pid=336164) 	.loc	1 215 79                        // quant_slide_tuned_Llama3.2-1B.py:215:79
(EngineCore_DP0 pid=336164) 	cvt.f32.bf16 	%r118, %rs40;
(EngineCore_DP0 pid=336164) 	cvt.f32.bf16 	%r119, %rs42;
(EngineCore_DP0 pid=336164) 	cvt.f32.bf16 	%r120, %rs44;
(EngineCore_DP0 pid=336164) 	cvt.f32.bf16 	%r121, %rs46;
(EngineCore_DP0 pid=336164) 	.loc	1 217 48                        // quant_slide_tuned_Llama3.2-1B.py:217:48
(EngineCore_DP0 pid=336164) 	add.s32 	%r122, %r185, -12;
(EngineCore_DP0 pid=336164) 	add.s32 	%r123, %r185, -8;
(EngineCore_DP0 pid=336164) 	add.s32 	%r124, %r185, -4;
(EngineCore_DP0 pid=336164) 	.loc	1 217 53                        // quant_slide_tuned_Llama3.2-1B.py:217:53
(EngineCore_DP0 pid=336164) 	setp.lt.s32 	%p38, %r122, %r21;
(EngineCore_DP0 pid=336164) 	setp.lt.s32 	%p39, %r123, %r21;
(EngineCore_DP0 pid=336164) 	setp.lt.s32 	%p40, %r124, %r21;
(EngineCore_DP0 pid=336164) 	setp.lt.s32 	%p41, %r185, %r21;
(EngineCore_DP0 pid=336164) 	.loc	1 217 37                        // quant_slide_tuned_Llama3.2-1B.py:217:37
(EngineCore_DP0 pid=336164) 	and.pred 	%p21, %p25, %p38;
(EngineCore_DP0 pid=336164) 	and.pred 	%p22, %p25, %p39;
(EngineCore_DP0 pid=336164) 	and.pred 	%p23, %p25, %p40;
(EngineCore_DP0 pid=336164) 	and.pred 	%p24, %p25, %p41;
(EngineCore_DP0 pid=336164) 	.loc	1 216 39                        // quant_slide_tuned_Llama3.2-1B.py:216:39
(EngineCore_DP0 pid=336164) 	add.s64 	%rd20, %rd8, 6;
(EngineCore_DP0 pid=336164) 	add.s64 	%rd21, %rd8, 14;
(EngineCore_DP0 pid=336164) 	add.s64 	%rd22, %rd8, 22;
(EngineCore_DP0 pid=336164) 	add.s64 	%rd23, %rd8, 30;
(EngineCore_DP0 pid=336164) 	.loc	1 216 21                        // quant_slide_tuned_Llama3.2-1B.py:216:21
(EngineCore_DP0 pid=336164) 	// begin inline asm
(EngineCore_DP0 pid=336164) 	mov.u16 %rs48, %rs25;
(EngineCore_DP0 pid=336164) 	@%p21 ld.global.b16 { %rs48 }, [ %rd20 + 0 ];
(EngineCore_DP0 pid=336164) 	// end inline asm
(EngineCore_DP0 pid=336164) 	// begin inline asm
(EngineCore_DP0 pid=336164) 	mov.u16 %rs50, %rs25;
(EngineCore_DP0 pid=336164) 	@%p22 ld.global.b16 { %rs50 }, [ %rd21 + 0 ];
(EngineCore_DP0 pid=336164) 	// end inline asm
(EngineCore_DP0 pid=336164) 	// begin inline asm
(EngineCore_DP0 pid=336164) 	mov.u16 %rs52, %rs25;
(EngineCore_DP0 pid=336164) 	@%p23 ld.global.b16 { %rs52 }, [ %rd22 + 0 ];
(EngineCore_DP0 pid=336164) 	// end inline asm
(EngineCore_DP0 pid=336164) 	// begin inline asm
(EngineCore_DP0 pid=336164) 	mov.u16 %rs54, %rs25;
(EngineCore_DP0 pid=336164) 	@%p24 ld.global.b16 { %rs54 }, [ %rd23 + 0 ];
(EngineCore_DP0 pid=336164) 	// end inline asm
(EngineCore_DP0 pid=336164) 	.loc	1 217 79                        // quant_slide_tuned_Llama3.2-1B.py:217:79
(EngineCore_DP0 pid=336164) 	cvt.f32.bf16 	%r125, %rs48;
(EngineCore_DP0 pid=336164) 	cvt.f32.bf16 	%r126, %rs50;
(EngineCore_DP0 pid=336164) 	cvt.f32.bf16 	%r127, %rs52;
(EngineCore_DP0 pid=336164) 	cvt.f32.bf16 	%r128, %rs54;
(EngineCore_DP0 pid=336164) 	.loc	1 219 27                        // quant_slide_tuned_Llama3.2-1B.py:219:27
(EngineCore_DP0 pid=336164) 	mul.f32 	%r129, %r14, %r102;
(EngineCore_DP0 pid=336164) 	mul.f32 	%r130, %r14, %r103;
(EngineCore_DP0 pid=336164) 	mul.f32 	%r131, %r14, %r104;
(EngineCore_DP0 pid=336164) 	mul.f32 	%r132, %r14, %r105;
(EngineCore_DP0 pid=336164) 	mov.b32 	%r133, 0f43E00000;
(EngineCore_DP0 pid=336164) 	.loc	1 219 48                        // quant_slide_tuned_Llama3.2-1B.py:219:48
(EngineCore_DP0 pid=336164) 	min.xorsign.abs.f32 	%r77, %r129, %r133;
(EngineCore_DP0 pid=336164) 	min.xorsign.abs.f32 	%r78, %r130, %r133;
(EngineCore_DP0 pid=336164) 	min.xorsign.abs.f32 	%r79, %r131, %r133;
(EngineCore_DP0 pid=336164) 	min.xorsign.abs.f32 	%r80, %r132, %r133;
(EngineCore_DP0 pid=336164) 	.loc	1 219 60                        // quant_slide_tuned_Llama3.2-1B.py:219:60
(EngineCore_DP0 pid=336164) 	// begin inline asm
(EngineCore_DP0 pid=336164) 	cvt.rn.satfinite.e4m3x2.f32  %rs56, %r78, %r77; 
(EngineCore_DP0 pid=336164) 
(EngineCore_DP0 pid=336164) 	// end inline asm
(EngineCore_DP0 pid=336164) 	shr.u16 	%rs64, %rs56, 8;
(EngineCore_DP0 pid=336164) 	// begin inline asm
(EngineCore_DP0 pid=336164) 	cvt.rn.satfinite.e4m3x2.f32  %rs57, %r80, %r79; 
(EngineCore_DP0 pid=336164) 
(EngineCore_DP0 pid=336164) 	// end inline asm
(EngineCore_DP0 pid=336164) 	shr.u16 	%rs65, %rs57, 8;
(EngineCore_DP0 pid=336164) 	.loc	1 220 27                        // quant_slide_tuned_Llama3.2-1B.py:220:27
(EngineCore_DP0 pid=336164) 	mul.f32 	%r134, %r14, %r110;
(EngineCore_DP0 pid=336164) 	mul.f32 	%r135, %r14, %r111;
(EngineCore_DP0 pid=336164) 	mul.f32 	%r136, %r14, %r112;
(EngineCore_DP0 pid=336164) 	mul.f32 	%r137, %r14, %r113;
(EngineCore_DP0 pid=336164) 	.loc	1 220 48                        // quant_slide_tuned_Llama3.2-1B.py:220:48
(EngineCore_DP0 pid=336164) 	min.xorsign.abs.f32 	%r81, %r134, %r133;
(EngineCore_DP0 pid=336164) 	min.xorsign.abs.f32 	%r82, %r135, %r133;
(EngineCore_DP0 pid=336164) 	min.xorsign.abs.f32 	%r83, %r136, %r133;
(EngineCore_DP0 pid=336164) 	min.xorsign.abs.f32 	%r84, %r137, %r133;
(EngineCore_DP0 pid=336164) 	.loc	1 220 60                        // quant_slide_tuned_Llama3.2-1B.py:220:60
(EngineCore_DP0 pid=336164) 	// begin inline asm
(EngineCore_DP0 pid=336164) 	cvt.rn.satfinite.e4m3x2.f32  %rs58, %r82, %r81; 
(EngineCore_DP0 pid=336164) 
(EngineCore_DP0 pid=336164) 	// end inline asm
(EngineCore_DP0 pid=336164) 	shr.u16 	%rs66, %rs58, 8;
(EngineCore_DP0 pid=336164) 	// begin inline asm
(EngineCore_DP0 pid=336164) 	cvt.rn.satfinite.e4m3x2.f32  %rs59, %r84, %r83; 
(EngineCore_DP0 pid=336164) 
(EngineCore_DP0 pid=336164) 	// end inline asm
(EngineCore_DP0 pid=336164) 	shr.u16 	%rs67, %rs59, 8;
(EngineCore_DP0 pid=336164) 	.loc	1 221 27                        // quant_slide_tuned_Llama3.2-1B.py:221:27
(EngineCore_DP0 pid=336164) 	mul.f32 	%r138, %r14, %r118;
(EngineCore_DP0 pid=336164) 	mul.f32 	%r139, %r14, %r119;
(EngineCore_DP0 pid=336164) 	mul.f32 	%r140, %r14, %r120;
(EngineCore_DP0 pid=336164) 	mul.f32 	%r141, %r14, %r121;
(EngineCore_DP0 pid=336164) 	.loc	1 221 48                        // quant_slide_tuned_Llama3.2-1B.py:221:48
(EngineCore_DP0 pid=336164) 	min.xorsign.abs.f32 	%r85, %r138, %r133;
(EngineCore_DP0 pid=336164) 	min.xorsign.abs.f32 	%r86, %r139, %r133;
(EngineCore_DP0 pid=336164) 	min.xorsign.abs.f32 	%r87, %r140, %r133;
(EngineCore_DP0 pid=336164) 	min.xorsign.abs.f32 	%r88, %r141, %r133;
(EngineCore_DP0 pid=336164) 	.loc	1 221 60                        // quant_slide_tuned_Llama3.2-1B.py:221:60
(EngineCore_DP0 pid=336164) 	// begin inline asm
(EngineCore_DP0 pid=336164) 	cvt.rn.satfinite.e4m3x2.f32  %rs60, %r86, %r85; 
(EngineCore_DP0 pid=336164) 
(EngineCore_DP0 pid=336164) 	// end inline asm
(EngineCore_DP0 pid=336164) 	shr.u16 	%rs68, %rs60, 8;
(EngineCore_DP0 pid=336164) 	// begin inline asm
(EngineCore_DP0 pid=336164) 	cvt.rn.satfinite.e4m3x2.f32  %rs61, %r88, %r87; 
(EngineCore_DP0 pid=336164) 
(EngineCore_DP0 pid=336164) 	// end inline asm
(EngineCore_DP0 pid=336164) 	shr.u16 	%rs69, %rs61, 8;
(EngineCore_DP0 pid=336164) 	.loc	1 222 27                        // quant_slide_tuned_Llama3.2-1B.py:222:27
(EngineCore_DP0 pid=336164) 	mul.f32 	%r142, %r14, %r125;
(EngineCore_DP0 pid=336164) 	mul.f32 	%r143, %r14, %r126;
(EngineCore_DP0 pid=336164) 	mul.f32 	%r144, %r14, %r127;
(EngineCore_DP0 pid=336164) 	mul.f32 	%r145, %r14, %r128;
(EngineCore_DP0 pid=336164) 	.loc	1 222 48                        // quant_slide_tuned_Llama3.2-1B.py:222:48
(EngineCore_DP0 pid=336164) 	min.xorsign.abs.f32 	%r89, %r142, %r133;
(EngineCore_DP0 pid=336164) 	min.xorsign.abs.f32 	%r90, %r143, %r133;
(EngineCore_DP0 pid=336164) 	min.xorsign.abs.f32 	%r91, %r144, %r133;
(EngineCore_DP0 pid=336164) 	min.xorsign.abs.f32 	%r92, %r145, %r133;
(EngineCore_DP0 pid=336164) 	.loc	1 222 60                        // quant_slide_tuned_Llama3.2-1B.py:222:60
(EngineCore_DP0 pid=336164) 	// begin inline asm
(EngineCore_DP0 pid=336164) 	cvt.rn.satfinite.e4m3x2.f32  %rs62, %r90, %r89; 
(EngineCore_DP0 pid=336164) 
(EngineCore_DP0 pid=336164) 	// end inline asm
(EngineCore_DP0 pid=336164) 	shr.u16 	%rs70, %rs62, 8;
(EngineCore_DP0 pid=336164) 	// begin inline asm
(EngineCore_DP0 pid=336164) 	cvt.rn.satfinite.e4m3x2.f32  %rs63, %r92, %r91; 
(EngineCore_DP0 pid=336164) 
(EngineCore_DP0 pid=336164) 	// end inline asm
(EngineCore_DP0 pid=336164) 	shr.u16 	%rs71, %rs63, 8;
(EngineCore_DP0 pid=336164) 	.loc	1 224 45                        // quant_slide_tuned_Llama3.2-1B.py:224:45
(EngineCore_DP0 pid=336164) 	cvt.u32.u16 	%r146, %rs56;
(EngineCore_DP0 pid=336164) 	and.b32 	%r147, %r146, 255;
(EngineCore_DP0 pid=336164) 	cvt.u32.u16 	%r148, %rs64;
(EngineCore_DP0 pid=336164) 	cvt.u32.u16 	%r149, %rs57;
(EngineCore_DP0 pid=336164) 	and.b32 	%r150, %r149, 255;
(EngineCore_DP0 pid=336164) 	cvt.u32.u16 	%r151, %rs65;
(EngineCore_DP0 pid=336164) 	.loc	1 226 45                        // quant_slide_tuned_Llama3.2-1B.py:226:45
(EngineCore_DP0 pid=336164) 	cvt.u32.u16 	%r152, %rs60;
(EngineCore_DP0 pid=336164) 	and.b32 	%r153, %r152, 255;
(EngineCore_DP0 pid=336164) 	cvt.u32.u16 	%r154, %rs68;
(EngineCore_DP0 pid=336164) 	cvt.u32.u16 	%r155, %rs61;
(EngineCore_DP0 pid=336164) 	and.b32 	%r156, %r155, 255;
(EngineCore_DP0 pid=336164) 	cvt.u32.u16 	%r157, %rs69;
(EngineCore_DP0 pid=336164) 	.loc	1 227 45                        // quant_slide_tuned_Llama3.2-1B.py:227:45
(EngineCore_DP0 pid=336164) 	cvt.u32.u16 	%r158, %rs62;
(EngineCore_DP0 pid=336164) 	cvt.u32.u16 	%r159, %rs70;
(EngineCore_DP0 pid=336164) 	cvt.u32.u16 	%r160, %rs63;
(EngineCore_DP0 pid=336164) 	cvt.u32.u16 	%r161, %rs71;
(EngineCore_DP0 pid=336164) 	.loc	1 229 30                        // quant_slide_tuned_Llama3.2-1B.py:229:30
(EngineCore_DP0 pid=336164) 	and.b16 	%rs72, %rs58, 255;
(EngineCore_DP0 pid=336164) 	mul.wide.u16 	%r162, %rs72, 256;
(EngineCore_DP0 pid=336164) 	mul.wide.u16 	%r163, %rs66, 256;
(EngineCore_DP0 pid=336164) 	and.b16 	%rs73, %rs59, 255;
(EngineCore_DP0 pid=336164) 	mul.wide.u16 	%r164, %rs73, 256;
(EngineCore_DP0 pid=336164) 	mul.wide.u16 	%r165, %rs67, 256;
(EngineCore_DP0 pid=336164) 	.loc	1 229 24                        // quant_slide_tuned_Llama3.2-1B.py:229:24
(EngineCore_DP0 pid=336164) 	or.b32 	%r166, %r162, %r147;
(EngineCore_DP0 pid=336164) 	or.b32 	%r167, %r163, %r148;
(EngineCore_DP0 pid=336164) 	or.b32 	%r168, %r164, %r150;
(EngineCore_DP0 pid=336164) 	or.b32 	%r169, %r165, %r151;
(EngineCore_DP0 pid=336164) 	.loc	1 229 42                        // quant_slide_tuned_Llama3.2-1B.py:229:42
(EngineCore_DP0 pid=336164) 	shl.b32 	%r170, %r153, 16;
(EngineCore_DP0 pid=336164) 	shl.b32 	%r171, %r154, 16;
(EngineCore_DP0 pid=336164) 	shl.b32 	%r172, %r156, 16;
(EngineCore_DP0 pid=336164) 	shl.b32 	%r173, %r157, 16;
(EngineCore_DP0 pid=336164) 	.loc	1 229 36                        // quant_slide_tuned_Llama3.2-1B.py:229:36
(EngineCore_DP0 pid=336164) 	or.b32 	%r174, %r170, %r166;
(EngineCore_DP0 pid=336164) 	or.b32 	%r175, %r171, %r167;
(EngineCore_DP0 pid=336164) 	or.b32 	%r176, %r172, %r168;
(EngineCore_DP0 pid=336164) 	or.b32 	%r177, %r173, %r169;
(EngineCore_DP0 pid=336164) 	.loc	1 229 55                        // quant_slide_tuned_Llama3.2-1B.py:229:55
(EngineCore_DP0 pid=336164) 	shl.b32 	%r178, %r158, 24;
(EngineCore_DP0 pid=336164) 	shl.b32 	%r179, %r159, 24;
(EngineCore_DP0 pid=336164) 	shl.b32 	%r180, %r160, 24;
(EngineCore_DP0 pid=336164) 	shl.b32 	%r181, %r161, 24;
(EngineCore_DP0 pid=336164) 	.loc	1 229 49                        // quant_slide_tuned_Llama3.2-1B.py:229:49
(EngineCore_DP0 pid=336164) 	or.b32 	%r93, %r178, %r174;
(EngineCore_DP0 pid=336164) 	or.b32 	%r94, %r179, %r175;
(EngineCore_DP0 pid=336164) 	or.b32 	%r95, %r180, %r176;
(EngineCore_DP0 pid=336164) 	or.b32 	%r96, %r181, %r177;
(EngineCore_DP0 pid=336164) 	.loc	1 230 29                        // quant_slide_tuned_Llama3.2-1B.py:230:29
(EngineCore_DP0 pid=336164) 	mad.wide.s32 	%rd24, %r97, 4, %rd2;
(EngineCore_DP0 pid=336164) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-1B.py:230:39
(EngineCore_DP0 pid=336164) 	// begin inline asm
(EngineCore_DP0 pid=336164) 	@%p25 st.global.v4.b32 [ %rd24 + 0 ], { %r93, %r94, %r95, %r96 };
(EngineCore_DP0 pid=336164) 	// end inline asm
(EngineCore_DP0 pid=336164) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=336164) 	add.s32 	%r186, %r186, 2048;
(EngineCore_DP0 pid=336164) 	add.s32 	%r185, %r185, 8192;
(EngineCore_DP0 pid=336164) 	setp.lt.s32 	%p42, %r186, %r23;
(EngineCore_DP0 pid=336164) 	@%p42 bra 	$L__BB0_6;
(EngineCore_DP0 pid=336164) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=336164) 	.loc	1 201 4                         // quant_slide_tuned_Llama3.2-1B.py:201:4
(EngineCore_DP0 pid=336164) 	ret;
(EngineCore_DP0 pid=336164) $L__tmp3:
(EngineCore_DP0 pid=336164) $L__func_end0:
(EngineCore_DP0 pid=336164)                                         // -- End function
(EngineCore_DP0 pid=336164) }
(EngineCore_DP0 pid=336164) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=336164) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=336164) 	.section	.debug_abbrev
(EngineCore_DP0 pid=336164) 	{
(EngineCore_DP0 pid=336164) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=336164) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=336164) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=336164) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=336164) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=336164) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=336164) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=336164) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=336164) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=336164) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=336164) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=336164) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=336164) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=336164) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=336164) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=336164) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=336164) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=336164) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=336164) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=336164) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=336164) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=336164) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=336164) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=336164) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=336164) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=336164) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=336164) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=336164) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=336164) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=336164) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=336164) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=336164) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=336164) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=336164) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=336164) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=336164) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=336164) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=336164) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=336164) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=336164) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=336164) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=336164) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=336164) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=336164) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=336164) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=336164) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=336164) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=336164) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=336164) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=336164) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=336164) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=336164) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=336164) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=336164) 	}
(EngineCore_DP0 pid=336164) 	.section	.debug_info
(EngineCore_DP0 pid=336164) 	{
(EngineCore_DP0 pid=336164) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=336164) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=336164) .b8 0
(EngineCore_DP0 pid=336164) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=336164) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=336164) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=336164) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=336164) .b8 114
(EngineCore_DP0 pid=336164) .b8 105
(EngineCore_DP0 pid=336164) .b8 116
(EngineCore_DP0 pid=336164) .b8 111
(EngineCore_DP0 pid=336164) .b8 110
(EngineCore_DP0 pid=336164) .b8 0
(EngineCore_DP0 pid=336164) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=336164) .b8 0
(EngineCore_DP0 pid=336164) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=336164) .b8 117
(EngineCore_DP0 pid=336164) .b8 97
(EngineCore_DP0 pid=336164) .b8 110
(EngineCore_DP0 pid=336164) .b8 116
(EngineCore_DP0 pid=336164) .b8 95
(EngineCore_DP0 pid=336164) .b8 115
(EngineCore_DP0 pid=336164) .b8 108
(EngineCore_DP0 pid=336164) .b8 105
(EngineCore_DP0 pid=336164) .b8 100
(EngineCore_DP0 pid=336164) .b8 101
(EngineCore_DP0 pid=336164) .b8 95
(EngineCore_DP0 pid=336164) .b8 116
(EngineCore_DP0 pid=336164) .b8 117
(EngineCore_DP0 pid=336164) .b8 110
(EngineCore_DP0 pid=336164) .b8 101
(EngineCore_DP0 pid=336164) .b8 100
(EngineCore_DP0 pid=336164) .b8 95
(EngineCore_DP0 pid=336164) .b8 76
(EngineCore_DP0 pid=336164) .b8 108
(EngineCore_DP0 pid=336164) .b8 97
(EngineCore_DP0 pid=336164) .b8 109
(EngineCore_DP0 pid=336164) .b8 97
(EngineCore_DP0 pid=336164) .b8 51
(EngineCore_DP0 pid=336164) .b8 46
(EngineCore_DP0 pid=336164) .b8 50
(EngineCore_DP0 pid=336164) .b8 45
(EngineCore_DP0 pid=336164) .b8 49
(EngineCore_DP0 pid=336164) .b8 66
(EngineCore_DP0 pid=336164) .b8 46
(EngineCore_DP0 pid=336164) .b8 112
(EngineCore_DP0 pid=336164) .b8 121
(EngineCore_DP0 pid=336164) .b8 0
(EngineCore_DP0 pid=336164) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=336164) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=336164) .b8 114
(EngineCore_DP0 pid=336164) .b8 111
(EngineCore_DP0 pid=336164) .b8 111
(EngineCore_DP0 pid=336164) .b8 116
(EngineCore_DP0 pid=336164) .b8 47
(EngineCore_DP0 pid=336164) .b8 118
(EngineCore_DP0 pid=336164) .b8 108
(EngineCore_DP0 pid=336164) .b8 108
(EngineCore_DP0 pid=336164) .b8 109
(EngineCore_DP0 pid=336164) .b8 98
(EngineCore_DP0 pid=336164) .b8 101
(EngineCore_DP0 pid=336164) .b8 110
(EngineCore_DP0 pid=336164) .b8 99
(EngineCore_DP0 pid=336164) .b8 104
(EngineCore_DP0 pid=336164) .b8 47
(EngineCore_DP0 pid=336164) .b8 115
(EngineCore_DP0 pid=336164) .b8 108
(EngineCore_DP0 pid=336164) .b8 105
(EngineCore_DP0 pid=336164) .b8 100
(EngineCore_DP0 pid=336164) .b8 101
(EngineCore_DP0 pid=336164) .b8 115
(EngineCore_DP0 pid=336164) .b8 112
(EngineCore_DP0 pid=336164) .b8 97
(EngineCore_DP0 pid=336164) .b8 114
(EngineCore_DP0 pid=336164) .b8 115
(EngineCore_DP0 pid=336164) .b8 101
(EngineCore_DP0 pid=336164) .b8 47
(EngineCore_DP0 pid=336164) .b8 99
(EngineCore_DP0 pid=336164) .b8 115
(EngineCore_DP0 pid=336164) .b8 114
(EngineCore_DP0 pid=336164) .b8 99
(EngineCore_DP0 pid=336164) .b8 47
(EngineCore_DP0 pid=336164) .b8 102
(EngineCore_DP0 pid=336164) .b8 117
(EngineCore_DP0 pid=336164) .b8 115
(EngineCore_DP0 pid=336164) .b8 101
(EngineCore_DP0 pid=336164) .b8 100
(EngineCore_DP0 pid=336164) .b8 95
(EngineCore_DP0 pid=336164) .b8 113
(EngineCore_DP0 pid=336164) .b8 117
(EngineCore_DP0 pid=336164) .b8 97
(EngineCore_DP0 pid=336164) .b8 110
(EngineCore_DP0 pid=336164) .b8 116
(EngineCore_DP0 pid=336164) .b8 95
(EngineCore_DP0 pid=336164) .b8 115
(EngineCore_DP0 pid=336164) .b8 108
(EngineCore_DP0 pid=336164) .b8 105
(EngineCore_DP0 pid=336164) .b8 100
(EngineCore_DP0 pid=336164) .b8 101
(EngineCore_DP0 pid=336164) .b8 95
(EngineCore_DP0 pid=336164) .b8 116
(EngineCore_DP0 pid=336164) .b8 114
(EngineCore_DP0 pid=336164) .b8 105
(EngineCore_DP0 pid=336164) .b8 116
(EngineCore_DP0 pid=336164) .b8 111
(EngineCore_DP0 pid=336164) .b8 110
(EngineCore_DP0 pid=336164) .b8 47
(EngineCore_DP0 pid=336164) .b8 98
(EngineCore_DP0 pid=336164) .b8 117
(EngineCore_DP0 pid=336164) .b8 105
(EngineCore_DP0 pid=336164) .b8 108
(EngineCore_DP0 pid=336164) .b8 100
(EngineCore_DP0 pid=336164) .b8 47
(EngineCore_DP0 pid=336164) .b8 71
(EngineCore_DP0 pid=336164) .b8 66
(EngineCore_DP0 pid=336164) .b8 49
(EngineCore_DP0 pid=336164) .b8 48
(EngineCore_DP0 pid=336164) .b8 95
(EngineCore_DP0 pid=336164) .b8 99
(EngineCore_DP0 pid=336164) .b8 99
(EngineCore_DP0 pid=336164) .b8 49
(EngineCore_DP0 pid=336164) .b8 50
(EngineCore_DP0 pid=336164) .b8 49
(EngineCore_DP0 pid=336164) .b8 95
(EngineCore_DP0 pid=336164) .b8 112
(EngineCore_DP0 pid=336164) .b8 121
(EngineCore_DP0 pid=336164) .b8 51
(EngineCore_DP0 pid=336164) .b8 49
(EngineCore_DP0 pid=336164) .b8 50
(EngineCore_DP0 pid=336164) .b8 95
(EngineCore_DP0 pid=336164) .b8 99
(EngineCore_DP0 pid=336164) .b8 117
(EngineCore_DP0 pid=336164) .b8 49
(EngineCore_DP0 pid=336164) .b8 50
(EngineCore_DP0 pid=336164) .b8 57
(EngineCore_DP0 pid=336164) .b8 95
(EngineCore_DP0 pid=336164) .b8 97
(EngineCore_DP0 pid=336164) .b8 97
(EngineCore_DP0 pid=336164) .b8 114
(EngineCore_DP0 pid=336164) .b8 99
(EngineCore_DP0 pid=336164) .b8 104
(EngineCore_DP0 pid=336164) .b8 54
(EngineCore_DP0 pid=336164) .b8 52
(EngineCore_DP0 pid=336164) .b8 0
(EngineCore_DP0 pid=336164) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=336164) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=336164) .b8 113
(EngineCore_DP0 pid=336164) .b8 117
(EngineCore_DP0 pid=336164) .b8 97
(EngineCore_DP0 pid=336164) .b8 110
(EngineCore_DP0 pid=336164) .b8 116
(EngineCore_DP0 pid=336164) .b8 95
(EngineCore_DP0 pid=336164) .b8 115
(EngineCore_DP0 pid=336164) .b8 108
(EngineCore_DP0 pid=336164) .b8 105
(EngineCore_DP0 pid=336164) .b8 100
(EngineCore_DP0 pid=336164) .b8 101
(EngineCore_DP0 pid=336164) .b8 95
(EngineCore_DP0 pid=336164) .b8 102
(EngineCore_DP0 pid=336164) .b8 112
(EngineCore_DP0 pid=336164) .b8 56
(EngineCore_DP0 pid=336164) .b8 95
(EngineCore_DP0 pid=336164) .b8 107
(EngineCore_DP0 pid=336164) .b8 101
(EngineCore_DP0 pid=336164) .b8 114
(EngineCore_DP0 pid=336164) .b8 110
(EngineCore_DP0 pid=336164) .b8 101
(EngineCore_DP0 pid=336164) .b8 108
(EngineCore_DP0 pid=336164) .b8 0
(EngineCore_DP0 pid=336164) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=336164) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=336164) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=336164) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=336164) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=336164) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=336164) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=336164) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=336164) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=336164) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=336164) .b8 191                                 // DW_AT_call_line
(EngineCore_DP0 pid=336164) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=336164) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=336164) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=336164) 	}
(EngineCore_DP0 pid=336164) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=336164) 
(EngineCore_DP0 pid=336164) ================================================================
(EngineCore_DP0 pid=336164) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=336164) 
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpt3urcmss.ptx', '-o', '/tmp/tmpt3urcmss.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866] 
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866] 
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866] 
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpt3urcmss.ptx -o /tmp/tmpt3urcmss.ptx.o
(EngineCore_DP0 pid=336164) ERROR 01-25 19:15:47 [core.py:866] 

STDERR:
[2026-01-25 19:15:33] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:15:33] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:15:33] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:15:33] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:15:33] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:15:33] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:15:33] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:15:33] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:15:33] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:15:33] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:15:33] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:15:33] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:15:33] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:15:33] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:15:37] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:15:37] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:15:37] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:15:37] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:15:37] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:15:37] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:15:37] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:15:37] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:15:37] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:15:37] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:15:37] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:15:37] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:15:37] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:15:37] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=336164) [2026-01-25 19:15:38] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=336164) [2026-01-25 19:15:38] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=336164) [2026-01-25 19:15:38] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=336164) [2026-01-25 19:15:38] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=336164) [2026-01-25 19:15:38] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=336164) [2026-01-25 19:15:38] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=336164) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=336164) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.19s/it]
(EngineCore_DP0 pid=336164) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.19s/it]
(EngineCore_DP0 pid=336164) 
(EngineCore_DP0 pid=336164) [2026-01-25 19:15:46] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=336164) [2026-01-25 19:15:46] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=336164) [2026-01-25 19:15:46] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=336164) [2026-01-25 19:15:46] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 2621440 bytes
(EngineCore_DP0 pid=336164) [2026-01-25 19:15:46] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=336164) [2026-01-25 19:15:47] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 20971520 bytes
(EngineCore_DP0 pid=336164) [2026-01-25 19:15:47] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=336164) [2026-01-25 19:15:47] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10485760 bytes
(EngineCore_DP0 pid=336164) Process EngineCore_DP0:
(EngineCore_DP0 pid=336164) Traceback (most recent call last):
(EngineCore_DP0 pid=336164)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=336164)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=336164)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=336164)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=336164) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpt3urcmss.ptx', '-o', '/tmp/tmpt3urcmss.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=336164) 
(EngineCore_DP0 pid=336164) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=336164) 
(EngineCore_DP0 pid=336164) Traceback (most recent call last):
(EngineCore_DP0 pid=336164)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=336164)     self.run()
(EngineCore_DP0 pid=336164)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=336164)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=336164)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=336164)     raise e
(EngineCore_DP0 pid=336164)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=336164)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=336164)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=336164)     super().__init__(
(EngineCore_DP0 pid=336164)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=336164)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=336164)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=336164)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=336164)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=336164)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=336164)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=336164)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=336164)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=336164)     return func(*args, **kwargs)
(EngineCore_DP0 pid=336164)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=336164)     return func(*args, **kwargs)
(EngineCore_DP0 pid=336164)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=336164)     self.model_runner.profile_run()
(EngineCore_DP0 pid=336164)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=336164)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=336164)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=336164)     return func(*args, **kwargs)
(EngineCore_DP0 pid=336164)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=336164)     outputs = self.model(
(EngineCore_DP0 pid=336164)               ^^^^^^^^^^^
(EngineCore_DP0 pid=336164)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=336164)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=336164)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=336164)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=336164)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=336164)     model_output = self.model(
(EngineCore_DP0 pid=336164)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=336164)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=336164)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=336164)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=336164)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=336164)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=336164)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=336164)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=336164)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=336164)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=336164)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=336164)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=336164)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=336164)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=336164)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=336164)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=336164)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=336164)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=336164)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=336164)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=336164)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=336164)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=336164)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=336164)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=336164)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=336164)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=336164)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=336164)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=336164)     return self._linear_fn(
(EngineCore_DP0 pid=336164)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=336164)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=336164)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=336164)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=336164)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=336164)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=336164)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=336164)     return fn(input, L)
(EngineCore_DP0 pid=336164)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=336164)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=336164)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=336164)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=336164)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=336164)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=336164)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=336164)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=336164)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=336164)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=336164)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=336164)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=336164)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=336164)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336164)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=336164)     raise PTXASError(error)
(EngineCore_DP0 pid=336164) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=336164) `ptxas` stderr:
(EngineCore_DP0 pid=336164) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=336164) 
(EngineCore_DP0 pid=336164) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpt3urcmss.ptx -o /tmp/tmpt3urcmss.ptx.o
(EngineCore_DP0 pid=336164) 
[rank0]:[W125 19:15:48.321472735 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=32768

========== M=65536 ==========
Time: 2026-01-25 19:15:49
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Llama3.2-1B-FP8_M65536.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:16:17 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:16:17 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=336967) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=336967) 
(EngineCore_DP0 pid=336967) 
(EngineCore_DP0 pid=336967) ================================================================
(EngineCore_DP0 pid=336967) Internal Triton PTX codegen error
(EngineCore_DP0 pid=336967) `ptxas` stderr:
(EngineCore_DP0 pid=336967) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=336967) 
(EngineCore_DP0 pid=336967) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmptxemmebv.ptx -o /tmp/tmptxemmebv.ptx.o
(EngineCore_DP0 pid=336967) 
(EngineCore_DP0 pid=336967) 
(EngineCore_DP0 pid=336967) //
(EngineCore_DP0 pid=336967) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=336967) //
(EngineCore_DP0 pid=336967) 
(EngineCore_DP0 pid=336967) .version 8.7
(EngineCore_DP0 pid=336967) .target sm_121a
(EngineCore_DP0 pid=336967) .address_size 64
(EngineCore_DP0 pid=336967) 
(EngineCore_DP0 pid=336967) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=336967) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=336967)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=336967) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=336967) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=336967) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=336967) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=336967) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=336967) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=336967) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=336967) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=336967) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=336967) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=336967) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=336967) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=336967) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=336967) )
(EngineCore_DP0 pid=336967) .reqntid 512
(EngineCore_DP0 pid=336967) {
(EngineCore_DP0 pid=336967) 	.reg .pred 	%p<44>;
(EngineCore_DP0 pid=336967) 	.reg .b16 	%rs<74>;
(EngineCore_DP0 pid=336967) 	.reg .b32 	%r<187>;
(EngineCore_DP0 pid=336967) 	.reg .b64 	%rd<25>;
(EngineCore_DP0 pid=336967) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=336967) $L__func_begin0:
(EngineCore_DP0 pid=336967) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=336967) 
(EngineCore_DP0 pid=336967) // %bb.0:
(EngineCore_DP0 pid=336967) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=336967) 	ld.param.b32 	%r22, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=336967) 	ld.param.b32 	%r21, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=336967) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=336967) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=336967) $L__tmp0:
(EngineCore_DP0 pid=336967) 	.loc	1 177 24                        // quant_slide_tuned_Llama3.2-1B.py:177:24
(EngineCore_DP0 pid=336967) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=336967) 	ld.param.b32 	%r25, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=336967) 	.loc	1 182 26                        // quant_slide_tuned_Llama3.2-1B.py:182:26
(EngineCore_DP0 pid=336967) 	mul.lo.s32 	%r26, %r25, %r1;
(EngineCore_DP0 pid=336967) 	.loc	1 182 20                        // quant_slide_tuned_Llama3.2-1B.py:182:20
(EngineCore_DP0 pid=336967) 	mad.wide.s32 	%rd1, %r26, 2, %rd4;
(EngineCore_DP0 pid=336967) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=336967) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=336967) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=336967) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=336967) 	setp.lt.s32 	%p1, %r22, 1;
(EngineCore_DP0 pid=336967) 	mov.b32 	%r184, 0f2B8CBCCC;
(EngineCore_DP0 pid=336967) 	setp.eq.b32 	%p43, %r2, 0;
(EngineCore_DP0 pid=336967) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=336967) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=336967) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=336967) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=336967) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=336967) 	shr.u32 	%r35, %r2, 3;
(EngineCore_DP0 pid=336967) 	and.b32 	%r36, %r35, 60;
(EngineCore_DP0 pid=336967) 	mov.b32 	%r37, global_smem;
(EngineCore_DP0 pid=336967) 	add.s32 	%r47, %r37, %r36;
(EngineCore_DP0 pid=336967) 	shl.b32 	%r38, %r2, 2;
(EngineCore_DP0 pid=336967) 	add.s32 	%r50, %r37, %r38;
(EngineCore_DP0 pid=336967) 	mov.b32 	%r43, 0;
(EngineCore_DP0 pid=336967) 	mov.b32 	%r182, 0f00000000;
(EngineCore_DP0 pid=336967) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=336967) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=336967) 	mov.b32 	%r183, %r43;
(EngineCore_DP0 pid=336967) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=336967) 	.loc	1 189 22                        // quant_slide_tuned_Llama3.2-1B.py:189:22
(EngineCore_DP0 pid=336967) 	add.s32 	%r53, %r4, %r183;
(EngineCore_DP0 pid=336967) 	setp.lt.s32 	%p2, %r53, %r21;
(EngineCore_DP0 pid=336967) 	.loc	1 190 29                        // quant_slide_tuned_Llama3.2-1B.py:190:29
(EngineCore_DP0 pid=336967) 	mad.wide.s32 	%rd6, %r53, 2, %rd1;
(EngineCore_DP0 pid=336967) 	.loc	1 190 21                        // quant_slide_tuned_Llama3.2-1B.py:190:21
(EngineCore_DP0 pid=336967) 	// begin inline asm
(EngineCore_DP0 pid=336967) 	mov.u32 %r39, %r43;
(EngineCore_DP0 pid=336967) 	mov.u32 %r40, %r43;
(EngineCore_DP0 pid=336967) 	mov.u32 %r41, %r43;
(EngineCore_DP0 pid=336967) 	mov.u32 %r42, %r43;
(EngineCore_DP0 pid=336967) 	@%p2 ld.global.v4.b32 { %r39, %r40, %r41, %r42 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=336967) 	// end inline asm
(EngineCore_DP0 pid=336967) 	mov.b32 	{%rs1, %rs2}, %r39;
(EngineCore_DP0 pid=336967) 	mov.b32 	{%rs3, %rs4}, %r40;
(EngineCore_DP0 pid=336967) 	mov.b32 	{%rs5, %rs6}, %r41;
(EngineCore_DP0 pid=336967) 	mov.b32 	{%rs7, %rs8}, %r42;
(EngineCore_DP0 pid=336967) 	.loc	1 191 50                        // quant_slide_tuned_Llama3.2-1B.py:191:50
(EngineCore_DP0 pid=336967) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=336967) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=336967) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=336967) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=336967) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=336967) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=336967) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=336967) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=336967) $L__tmp1:
(EngineCore_DP0 pid=336967) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=336967) 	bar.sync 	0;
(EngineCore_DP0 pid=336967) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=336967) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=336967) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=336967) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=336967) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=336967) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=336967) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=336967) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=336967) 	cvt.f32.bf16 	%r54, %rs23;
(EngineCore_DP0 pid=336967) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=336967) 	shfl.sync.bfly.b32 	%r55, %r54, 16, 31, -1;
(EngineCore_DP0 pid=336967) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=336967) 	max.f32 	%r56, %r54, %r55;
(EngineCore_DP0 pid=336967) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=336967) 	shfl.sync.bfly.b32 	%r57, %r56, 8, 31, -1;
(EngineCore_DP0 pid=336967) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=336967) 	max.f32 	%r58, %r56, %r57;
(EngineCore_DP0 pid=336967) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=336967) 	shfl.sync.bfly.b32 	%r59, %r58, 4, 31, -1;
(EngineCore_DP0 pid=336967) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=336967) 	max.f32 	%r60, %r58, %r59;
(EngineCore_DP0 pid=336967) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=336967) 	shfl.sync.bfly.b32 	%r61, %r60, 2, 31, -1;
(EngineCore_DP0 pid=336967) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=336967) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=336967) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=336967) 	shfl.sync.bfly.b32 	%r63, %r62, 1, 31, -1;
(EngineCore_DP0 pid=336967) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=336967) 	max.f32 	%r48, %r62, %r63;
(EngineCore_DP0 pid=336967) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=336967) 	// begin inline asm
(EngineCore_DP0 pid=336967) 	@%p3 st.shared.b32 [ %r47 + 0 ], %r48;
(EngineCore_DP0 pid=336967) 	// end inline asm
(EngineCore_DP0 pid=336967) 	bar.sync 	0;
(EngineCore_DP0 pid=336967) 	// begin inline asm
(EngineCore_DP0 pid=336967) 	@%p4 ld.shared.b32 %r49, [ %r50 + 0 ];
(EngineCore_DP0 pid=336967) 	// end inline asm
(EngineCore_DP0 pid=336967) 	shfl.sync.bfly.b32 	%r64, %r49, 8, 31, -1;
(EngineCore_DP0 pid=336967) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=336967) 	max.f32 	%r65, %r49, %r64;
(EngineCore_DP0 pid=336967) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=336967) 	shfl.sync.bfly.b32 	%r66, %r65, 4, 31, -1;
(EngineCore_DP0 pid=336967) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=336967) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=336967) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=336967) 	shfl.sync.bfly.b32 	%r68, %r67, 2, 31, -1;
(EngineCore_DP0 pid=336967) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=336967) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=336967) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=336967) 	shfl.sync.bfly.b32 	%r70, %r69, 1, 31, -1;
(EngineCore_DP0 pid=336967) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=336967) 	max.f32 	%r52, %r69, %r70;
(EngineCore_DP0 pid=336967) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=336967) 	// begin inline asm
(EngineCore_DP0 pid=336967) 	@%p43 st.shared.b32 [ %r50 + 0 ], %r52;
(EngineCore_DP0 pid=336967) 	// end inline asm
(EngineCore_DP0 pid=336967) 	bar.sync 	0;
(EngineCore_DP0 pid=336967) 	ld.shared.b32 	%r71, [global_smem];
(EngineCore_DP0 pid=336967) $L__tmp2:
(EngineCore_DP0 pid=336967) 	.loc	1 191 36                        // quant_slide_tuned_Llama3.2-1B.py:191:36
(EngineCore_DP0 pid=336967) 	max.f32 	%r182, %r182, %r71;
(EngineCore_DP0 pid=336967) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=336967) 	add.s32 	%r183, %r183, 4096;
(EngineCore_DP0 pid=336967) 	setp.lt.s32 	%p6, %r183, %r22;
(EngineCore_DP0 pid=336967) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=336967) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=336967) 	.loc	1 193 32                        // quant_slide_tuned_Llama3.2-1B.py:193:32
(EngineCore_DP0 pid=336967) 	max.f32 	%r184, %r182, 0f2B8CBCCC;
(EngineCore_DP0 pid=336967) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=336967) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=336967) 	mov.b32 	%r73, 0f43E00000;
(EngineCore_DP0 pid=336967) 	.loc	1 194 32                        // quant_slide_tuned_Llama3.2-1B.py:194:32
(EngineCore_DP0 pid=336967) 	div.full.f32 	%r74, %r184, %r73;
(EngineCore_DP0 pid=336967) 	.loc	1 194 41                        // quant_slide_tuned_Llama3.2-1B.py:194:41
(EngineCore_DP0 pid=336967) 	max.f32 	%r72, %r74, 0f36924925;
(EngineCore_DP0 pid=336967) 	.loc	1 196 25                        // quant_slide_tuned_Llama3.2-1B.py:196:25
(EngineCore_DP0 pid=336967) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=336967) 	.loc	1 196 30                        // quant_slide_tuned_Llama3.2-1B.py:196:30
(EngineCore_DP0 pid=336967) 	// begin inline asm
(EngineCore_DP0 pid=336967) 	@%p43 st.global.b32 [ %rd7 + 0 ], { %r72 };
(EngineCore_DP0 pid=336967) 	// end inline asm
(EngineCore_DP0 pid=336967) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=336967) 	setp.lt.s32 	%p8, %r23, 1;
(EngineCore_DP0 pid=336967) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=336967) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=336967) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=336967) 	ld.param.b32 	%r27, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=336967) 	shr.s32 	%r28, %r27, 31;
(EngineCore_DP0 pid=336967) 	shr.u32 	%r29, %r28, 30;
(EngineCore_DP0 pid=336967) 	add.s32 	%r30, %r27, %r29;
(EngineCore_DP0 pid=336967) 	shr.s32 	%r31, %r30, 2;
(EngineCore_DP0 pid=336967) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=336967) 	mul.lo.s32 	%r32, %r31, %r1;
(EngineCore_DP0 pid=336967) 	mad.wide.s32 	%rd2, %r32, 4, %rd5;
(EngineCore_DP0 pid=336967) 	div.full.f32 	%r14, %r73, %r184;
(EngineCore_DP0 pid=336967) 	shl.b32 	%r15, %r3, 2;
(EngineCore_DP0 pid=336967) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=336967) 	shl.b32 	%r76, %r3, 4;
(EngineCore_DP0 pid=336967) 	or.b32 	%r185, %r76, 15;
(EngineCore_DP0 pid=336967) 	mov.b32 	%r186, 0;
(EngineCore_DP0 pid=336967) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=336967)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=336967) 	.loc	1 203 30                        // quant_slide_tuned_Llama3.2-1B.py:203:30
(EngineCore_DP0 pid=336967) 	add.s32 	%r97, %r15, %r186;
(EngineCore_DP0 pid=336967) 	setp.lt.s32 	%p25, %r97, %r23;
(EngineCore_DP0 pid=336967) 	.loc	1 208 22                        // quant_slide_tuned_Llama3.2-1B.py:208:22
(EngineCore_DP0 pid=336967) 	add.s32 	%r98, %r185, -15;
(EngineCore_DP0 pid=336967) 	add.s32 	%r99, %r185, -11;
(EngineCore_DP0 pid=336967) 	add.s32 	%r100, %r185, -7;
(EngineCore_DP0 pid=336967) 	.loc	1 211 53                        // quant_slide_tuned_Llama3.2-1B.py:211:53
(EngineCore_DP0 pid=336967) 	add.s32 	%r101, %r185, -3;
(EngineCore_DP0 pid=336967) 	setp.lt.s32 	%p26, %r98, %r21;
(EngineCore_DP0 pid=336967) 	setp.lt.s32 	%p27, %r99, %r21;
(EngineCore_DP0 pid=336967) 	setp.lt.s32 	%p28, %r100, %r21;
(EngineCore_DP0 pid=336967) 	setp.lt.s32 	%p29, %r101, %r21;
(EngineCore_DP0 pid=336967) 	.loc	1 211 37                        // quant_slide_tuned_Llama3.2-1B.py:211:37
(EngineCore_DP0 pid=336967) 	and.pred 	%p9, %p25, %p26;
(EngineCore_DP0 pid=336967) 	and.pred 	%p10, %p25, %p27;
(EngineCore_DP0 pid=336967) 	and.pred 	%p11, %p25, %p28;
(EngineCore_DP0 pid=336967) 	and.pred 	%p12, %p25, %p29;
(EngineCore_DP0 pid=336967) 	.loc	1 210 29                        // quant_slide_tuned_Llama3.2-1B.py:210:29
(EngineCore_DP0 pid=336967) 	mad.wide.s32 	%rd8, %r98, 2, %rd1;
(EngineCore_DP0 pid=336967) 	add.s64 	%rd9, %rd8, 8;
(EngineCore_DP0 pid=336967) 	add.s64 	%rd10, %rd8, 16;
(EngineCore_DP0 pid=336967) 	add.s64 	%rd11, %rd8, 24;
(EngineCore_DP0 pid=336967) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=336967) 	.loc	1 210 21                        // quant_slide_tuned_Llama3.2-1B.py:210:21
(EngineCore_DP0 pid=336967) 	// begin inline asm
(EngineCore_DP0 pid=336967) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=336967) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=336967) 	// end inline asm
(EngineCore_DP0 pid=336967) 	// begin inline asm
(EngineCore_DP0 pid=336967) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=336967) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=336967) 	// end inline asm
(EngineCore_DP0 pid=336967) 	// begin inline asm
(EngineCore_DP0 pid=336967) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=336967) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=336967) 	// end inline asm
(EngineCore_DP0 pid=336967) 	// begin inline asm
(EngineCore_DP0 pid=336967) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=336967) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=336967) 	// end inline asm
(EngineCore_DP0 pid=336967) 	.loc	1 211 79                        // quant_slide_tuned_Llama3.2-1B.py:211:79
(EngineCore_DP0 pid=336967) 	cvt.f32.bf16 	%r102, %rs24;
(EngineCore_DP0 pid=336967) 	cvt.f32.bf16 	%r103, %rs26;
(EngineCore_DP0 pid=336967) 	cvt.f32.bf16 	%r104, %rs28;
(EngineCore_DP0 pid=336967) 	cvt.f32.bf16 	%r105, %rs30;
(EngineCore_DP0 pid=336967) 	.loc	1 213 48                        // quant_slide_tuned_Llama3.2-1B.py:213:48
(EngineCore_DP0 pid=336967) 	add.s32 	%r106, %r185, -14;
(EngineCore_DP0 pid=336967) 	add.s32 	%r107, %r185, -10;
(EngineCore_DP0 pid=336967) 	add.s32 	%r108, %r185, -6;
(EngineCore_DP0 pid=336967) 	.loc	1 213 53                        // quant_slide_tuned_Llama3.2-1B.py:213:53
(EngineCore_DP0 pid=336967) 	add.s32 	%r109, %r185, -2;
(EngineCore_DP0 pid=336967) 	setp.lt.s32 	%p30, %r106, %r21;
(EngineCore_DP0 pid=336967) 	setp.lt.s32 	%p31, %r107, %r21;
(EngineCore_DP0 pid=336967) 	setp.lt.s32 	%p32, %r108, %r21;
(EngineCore_DP0 pid=336967) 	setp.lt.s32 	%p33, %r109, %r21;
(EngineCore_DP0 pid=336967) 	.loc	1 213 37                        // quant_slide_tuned_Llama3.2-1B.py:213:37
(EngineCore_DP0 pid=336967) 	and.pred 	%p13, %p25, %p30;
(EngineCore_DP0 pid=336967) 	and.pred 	%p14, %p25, %p31;
(EngineCore_DP0 pid=336967) 	and.pred 	%p15, %p25, %p32;
(EngineCore_DP0 pid=336967) 	and.pred 	%p16, %p25, %p33;
(EngineCore_DP0 pid=336967) 	.loc	1 212 39                        // quant_slide_tuned_Llama3.2-1B.py:212:39
(EngineCore_DP0 pid=336967) 	add.s64 	%rd12, %rd8, 2;
(EngineCore_DP0 pid=336967) 	add.s64 	%rd13, %rd8, 10;
(EngineCore_DP0 pid=336967) 	add.s64 	%rd14, %rd8, 18;
(EngineCore_DP0 pid=336967) 	add.s64 	%rd15, %rd8, 26;
(EngineCore_DP0 pid=336967) 	.loc	1 212 21                        // quant_slide_tuned_Llama3.2-1B.py:212:21
(EngineCore_DP0 pid=336967) 	// begin inline asm
(EngineCore_DP0 pid=336967) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=336967) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=336967) 	// end inline asm
(EngineCore_DP0 pid=336967) 	// begin inline asm
(EngineCore_DP0 pid=336967) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=336967) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=336967) 	// end inline asm
(EngineCore_DP0 pid=336967) 	// begin inline asm
(EngineCore_DP0 pid=336967) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=336967) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=336967) 	// end inline asm
(EngineCore_DP0 pid=336967) 	// begin inline asm
(EngineCore_DP0 pid=336967) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=336967) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=336967) 	// end inline asm
(EngineCore_DP0 pid=336967) 	.loc	1 213 79                        // quant_slide_tuned_Llama3.2-1B.py:213:79
(EngineCore_DP0 pid=336967) 	cvt.f32.bf16 	%r110, %rs32;
(EngineCore_DP0 pid=336967) 	cvt.f32.bf16 	%r111, %rs34;
(EngineCore_DP0 pid=336967) 	cvt.f32.bf16 	%r112, %rs36;
(EngineCore_DP0 pid=336967) 	cvt.f32.bf16 	%r113, %rs38;
(EngineCore_DP0 pid=336967) 	.loc	1 215 48                        // quant_slide_tuned_Llama3.2-1B.py:215:48
(EngineCore_DP0 pid=336967) 	add.s32 	%r114, %r185, -13;
(EngineCore_DP0 pid=336967) 	add.s32 	%r115, %r185, -9;
(EngineCore_DP0 pid=336967) 	add.s32 	%r116, %r185, -5;
(EngineCore_DP0 pid=336967) 	.loc	1 215 53                        // quant_slide_tuned_Llama3.2-1B.py:215:53
(EngineCore_DP0 pid=336967) 	add.s32 	%r117, %r185, -1;
(EngineCore_DP0 pid=336967) 	setp.lt.s32 	%p34, %r114, %r21;
(EngineCore_DP0 pid=336967) 	setp.lt.s32 	%p35, %r115, %r21;
(EngineCore_DP0 pid=336967) 	setp.lt.s32 	%p36, %r116, %r21;
(EngineCore_DP0 pid=336967) 	setp.lt.s32 	%p37, %r117, %r21;
(EngineCore_DP0 pid=336967) 	.loc	1 215 37                        // quant_slide_tuned_Llama3.2-1B.py:215:37
(EngineCore_DP0 pid=336967) 	and.pred 	%p17, %p25, %p34;
(EngineCore_DP0 pid=336967) 	and.pred 	%p18, %p25, %p35;
(EngineCore_DP0 pid=336967) 	and.pred 	%p19, %p25, %p36;
(EngineCore_DP0 pid=336967) 	and.pred 	%p20, %p25, %p37;
(EngineCore_DP0 pid=336967) 	.loc	1 214 39                        // quant_slide_tuned_Llama3.2-1B.py:214:39
(EngineCore_DP0 pid=336967) 	add.s64 	%rd16, %rd8, 4;
(EngineCore_DP0 pid=336967) 	add.s64 	%rd17, %rd8, 12;
(EngineCore_DP0 pid=336967) 	add.s64 	%rd18, %rd8, 20;
(EngineCore_DP0 pid=336967) 	add.s64 	%rd19, %rd8, 28;
(EngineCore_DP0 pid=336967) 	.loc	1 214 21                        // quant_slide_tuned_Llama3.2-1B.py:214:21
(EngineCore_DP0 pid=336967) 	// begin inline asm
(EngineCore_DP0 pid=336967) 	mov.u16 %rs40, %rs25;
(EngineCore_DP0 pid=336967) 	@%p17 ld.global.b16 { %rs40 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=336967) 	// end inline asm
(EngineCore_DP0 pid=336967) 	// begin inline asm
(EngineCore_DP0 pid=336967) 	mov.u16 %rs42, %rs25;
(EngineCore_DP0 pid=336967) 	@%p18 ld.global.b16 { %rs42 }, [ %rd17 + 0 ];
(EngineCore_DP0 pid=336967) 	// end inline asm
(EngineCore_DP0 pid=336967) 	// begin inline asm
(EngineCore_DP0 pid=336967) 	mov.u16 %rs44, %rs25;
(EngineCore_DP0 pid=336967) 	@%p19 ld.global.b16 { %rs44 }, [ %rd18 + 0 ];
(EngineCore_DP0 pid=336967) 	// end inline asm
(EngineCore_DP0 pid=336967) 	// begin inline asm
(EngineCore_DP0 pid=336967) 	mov.u16 %rs46, %rs25;
(EngineCore_DP0 pid=336967) 	@%p20 ld.global.b16 { %rs46 }, [ %rd19 + 0 ];
(EngineCore_DP0 pid=336967) 	// end inline asm
(EngineCore_DP0 pid=336967) 	.loc	1 215 79                        // quant_slide_tuned_Llama3.2-1B.py:215:79
(EngineCore_DP0 pid=336967) 	cvt.f32.bf16 	%r118, %rs40;
(EngineCore_DP0 pid=336967) 	cvt.f32.bf16 	%r119, %rs42;
(EngineCore_DP0 pid=336967) 	cvt.f32.bf16 	%r120, %rs44;
(EngineCore_DP0 pid=336967) 	cvt.f32.bf16 	%r121, %rs46;
(EngineCore_DP0 pid=336967) 	.loc	1 217 48                        // quant_slide_tuned_Llama3.2-1B.py:217:48
(EngineCore_DP0 pid=336967) 	add.s32 	%r122, %r185, -12;
(EngineCore_DP0 pid=336967) 	add.s32 	%r123, %r185, -8;
(EngineCore_DP0 pid=336967) 	add.s32 	%r124, %r185, -4;
(EngineCore_DP0 pid=336967) 	.loc	1 217 53                        // quant_slide_tuned_Llama3.2-1B.py:217:53
(EngineCore_DP0 pid=336967) 	setp.lt.s32 	%p38, %r122, %r21;
(EngineCore_DP0 pid=336967) 	setp.lt.s32 	%p39, %r123, %r21;
(EngineCore_DP0 pid=336967) 	setp.lt.s32 	%p40, %r124, %r21;
(EngineCore_DP0 pid=336967) 	setp.lt.s32 	%p41, %r185, %r21;
(EngineCore_DP0 pid=336967) 	.loc	1 217 37                        // quant_slide_tuned_Llama3.2-1B.py:217:37
(EngineCore_DP0 pid=336967) 	and.pred 	%p21, %p25, %p38;
(EngineCore_DP0 pid=336967) 	and.pred 	%p22, %p25, %p39;
(EngineCore_DP0 pid=336967) 	and.pred 	%p23, %p25, %p40;
(EngineCore_DP0 pid=336967) 	and.pred 	%p24, %p25, %p41;
(EngineCore_DP0 pid=336967) 	.loc	1 216 39                        // quant_slide_tuned_Llama3.2-1B.py:216:39
(EngineCore_DP0 pid=336967) 	add.s64 	%rd20, %rd8, 6;
(EngineCore_DP0 pid=336967) 	add.s64 	%rd21, %rd8, 14;
(EngineCore_DP0 pid=336967) 	add.s64 	%rd22, %rd8, 22;
(EngineCore_DP0 pid=336967) 	add.s64 	%rd23, %rd8, 30;
(EngineCore_DP0 pid=336967) 	.loc	1 216 21                        // quant_slide_tuned_Llama3.2-1B.py:216:21
(EngineCore_DP0 pid=336967) 	// begin inline asm
(EngineCore_DP0 pid=336967) 	mov.u16 %rs48, %rs25;
(EngineCore_DP0 pid=336967) 	@%p21 ld.global.b16 { %rs48 }, [ %rd20 + 0 ];
(EngineCore_DP0 pid=336967) 	// end inline asm
(EngineCore_DP0 pid=336967) 	// begin inline asm
(EngineCore_DP0 pid=336967) 	mov.u16 %rs50, %rs25;
(EngineCore_DP0 pid=336967) 	@%p22 ld.global.b16 { %rs50 }, [ %rd21 + 0 ];
(EngineCore_DP0 pid=336967) 	// end inline asm
(EngineCore_DP0 pid=336967) 	// begin inline asm
(EngineCore_DP0 pid=336967) 	mov.u16 %rs52, %rs25;
(EngineCore_DP0 pid=336967) 	@%p23 ld.global.b16 { %rs52 }, [ %rd22 + 0 ];
(EngineCore_DP0 pid=336967) 	// end inline asm
(EngineCore_DP0 pid=336967) 	// begin inline asm
(EngineCore_DP0 pid=336967) 	mov.u16 %rs54, %rs25;
(EngineCore_DP0 pid=336967) 	@%p24 ld.global.b16 { %rs54 }, [ %rd23 + 0 ];
(EngineCore_DP0 pid=336967) 	// end inline asm
(EngineCore_DP0 pid=336967) 	.loc	1 217 79                        // quant_slide_tuned_Llama3.2-1B.py:217:79
(EngineCore_DP0 pid=336967) 	cvt.f32.bf16 	%r125, %rs48;
(EngineCore_DP0 pid=336967) 	cvt.f32.bf16 	%r126, %rs50;
(EngineCore_DP0 pid=336967) 	cvt.f32.bf16 	%r127, %rs52;
(EngineCore_DP0 pid=336967) 	cvt.f32.bf16 	%r128, %rs54;
(EngineCore_DP0 pid=336967) 	.loc	1 219 27                        // quant_slide_tuned_Llama3.2-1B.py:219:27
(EngineCore_DP0 pid=336967) 	mul.f32 	%r129, %r14, %r102;
(EngineCore_DP0 pid=336967) 	mul.f32 	%r130, %r14, %r103;
(EngineCore_DP0 pid=336967) 	mul.f32 	%r131, %r14, %r104;
(EngineCore_DP0 pid=336967) 	mul.f32 	%r132, %r14, %r105;
(EngineCore_DP0 pid=336967) 	mov.b32 	%r133, 0f43E00000;
(EngineCore_DP0 pid=336967) 	.loc	1 219 48                        // quant_slide_tuned_Llama3.2-1B.py:219:48
(EngineCore_DP0 pid=336967) 	min.xorsign.abs.f32 	%r77, %r129, %r133;
(EngineCore_DP0 pid=336967) 	min.xorsign.abs.f32 	%r78, %r130, %r133;
(EngineCore_DP0 pid=336967) 	min.xorsign.abs.f32 	%r79, %r131, %r133;
(EngineCore_DP0 pid=336967) 	min.xorsign.abs.f32 	%r80, %r132, %r133;
(EngineCore_DP0 pid=336967) 	.loc	1 219 60                        // quant_slide_tuned_Llama3.2-1B.py:219:60
(EngineCore_DP0 pid=336967) 	// begin inline asm
(EngineCore_DP0 pid=336967) 	cvt.rn.satfinite.e4m3x2.f32  %rs56, %r78, %r77; 
(EngineCore_DP0 pid=336967) 
(EngineCore_DP0 pid=336967) 	// end inline asm
(EngineCore_DP0 pid=336967) 	shr.u16 	%rs64, %rs56, 8;
(EngineCore_DP0 pid=336967) 	// begin inline asm
(EngineCore_DP0 pid=336967) 	cvt.rn.satfinite.e4m3x2.f32  %rs57, %r80, %r79; 
(EngineCore_DP0 pid=336967) 
(EngineCore_DP0 pid=336967) 	// end inline asm
(EngineCore_DP0 pid=336967) 	shr.u16 	%rs65, %rs57, 8;
(EngineCore_DP0 pid=336967) 	.loc	1 220 27                        // quant_slide_tuned_Llama3.2-1B.py:220:27
(EngineCore_DP0 pid=336967) 	mul.f32 	%r134, %r14, %r110;
(EngineCore_DP0 pid=336967) 	mul.f32 	%r135, %r14, %r111;
(EngineCore_DP0 pid=336967) 	mul.f32 	%r136, %r14, %r112;
(EngineCore_DP0 pid=336967) 	mul.f32 	%r137, %r14, %r113;
(EngineCore_DP0 pid=336967) 	.loc	1 220 48                        // quant_slide_tuned_Llama3.2-1B.py:220:48
(EngineCore_DP0 pid=336967) 	min.xorsign.abs.f32 	%r81, %r134, %r133;
(EngineCore_DP0 pid=336967) 	min.xorsign.abs.f32 	%r82, %r135, %r133;
(EngineCore_DP0 pid=336967) 	min.xorsign.abs.f32 	%r83, %r136, %r133;
(EngineCore_DP0 pid=336967) 	min.xorsign.abs.f32 	%r84, %r137, %r133;
(EngineCore_DP0 pid=336967) 	.loc	1 220 60                        // quant_slide_tuned_Llama3.2-1B.py:220:60
(EngineCore_DP0 pid=336967) 	// begin inline asm
(EngineCore_DP0 pid=336967) 	cvt.rn.satfinite.e4m3x2.f32  %rs58, %r82, %r81; 
(EngineCore_DP0 pid=336967) 
(EngineCore_DP0 pid=336967) 	// end inline asm
(EngineCore_DP0 pid=336967) 	shr.u16 	%rs66, %rs58, 8;
(EngineCore_DP0 pid=336967) 	// begin inline asm
(EngineCore_DP0 pid=336967) 	cvt.rn.satfinite.e4m3x2.f32  %rs59, %r84, %r83; 
(EngineCore_DP0 pid=336967) 
(EngineCore_DP0 pid=336967) 	// end inline asm
(EngineCore_DP0 pid=336967) 	shr.u16 	%rs67, %rs59, 8;
(EngineCore_DP0 pid=336967) 	.loc	1 221 27                        // quant_slide_tuned_Llama3.2-1B.py:221:27
(EngineCore_DP0 pid=336967) 	mul.f32 	%r138, %r14, %r118;
(EngineCore_DP0 pid=336967) 	mul.f32 	%r139, %r14, %r119;
(EngineCore_DP0 pid=336967) 	mul.f32 	%r140, %r14, %r120;
(EngineCore_DP0 pid=336967) 	mul.f32 	%r141, %r14, %r121;
(EngineCore_DP0 pid=336967) 	.loc	1 221 48                        // quant_slide_tuned_Llama3.2-1B.py:221:48
(EngineCore_DP0 pid=336967) 	min.xorsign.abs.f32 	%r85, %r138, %r133;
(EngineCore_DP0 pid=336967) 	min.xorsign.abs.f32 	%r86, %r139, %r133;
(EngineCore_DP0 pid=336967) 	min.xorsign.abs.f32 	%r87, %r140, %r133;
(EngineCore_DP0 pid=336967) 	min.xorsign.abs.f32 	%r88, %r141, %r133;
(EngineCore_DP0 pid=336967) 	.loc	1 221 60                        // quant_slide_tuned_Llama3.2-1B.py:221:60
(EngineCore_DP0 pid=336967) 	// begin inline asm
(EngineCore_DP0 pid=336967) 	cvt.rn.satfinite.e4m3x2.f32  %rs60, %r86, %r85; 
(EngineCore_DP0 pid=336967) 
(EngineCore_DP0 pid=336967) 	// end inline asm
(EngineCore_DP0 pid=336967) 	shr.u16 	%rs68, %rs60, 8;
(EngineCore_DP0 pid=336967) 	// begin inline asm
(EngineCore_DP0 pid=336967) 	cvt.rn.satfinite.e4m3x2.f32  %rs61, %r88, %r87; 
(EngineCore_DP0 pid=336967) 
(EngineCore_DP0 pid=336967) 	// end inline asm
(EngineCore_DP0 pid=336967) 	shr.u16 	%rs69, %rs61, 8;
(EngineCore_DP0 pid=336967) 	.loc	1 222 27                        // quant_slide_tuned_Llama3.2-1B.py:222:27
(EngineCore_DP0 pid=336967) 	mul.f32 	%r142, %r14, %r125;
(EngineCore_DP0 pid=336967) 	mul.f32 	%r143, %r14, %r126;
(EngineCore_DP0 pid=336967) 	mul.f32 	%r144, %r14, %r127;
(EngineCore_DP0 pid=336967) 	mul.f32 	%r145, %r14, %r128;
(EngineCore_DP0 pid=336967) 	.loc	1 222 48                        // quant_slide_tuned_Llama3.2-1B.py:222:48
(EngineCore_DP0 pid=336967) 	min.xorsign.abs.f32 	%r89, %r142, %r133;
(EngineCore_DP0 pid=336967) 	min.xorsign.abs.f32 	%r90, %r143, %r133;
(EngineCore_DP0 pid=336967) 	min.xorsign.abs.f32 	%r91, %r144, %r133;
(EngineCore_DP0 pid=336967) 	min.xorsign.abs.f32 	%r92, %r145, %r133;
(EngineCore_DP0 pid=336967) 	.loc	1 222 60                        // quant_slide_tuned_Llama3.2-1B.py:222:60
(EngineCore_DP0 pid=336967) 	// begin inline asm
(EngineCore_DP0 pid=336967) 	cvt.rn.satfinite.e4m3x2.f32  %rs62, %r90, %r89; 
(EngineCore_DP0 pid=336967) 
(EngineCore_DP0 pid=336967) 	// end inline asm
(EngineCore_DP0 pid=336967) 	shr.u16 	%rs70, %rs62, 8;
(EngineCore_DP0 pid=336967) 	// begin inline asm
(EngineCore_DP0 pid=336967) 	cvt.rn.satfinite.e4m3x2.f32  %rs63, %r92, %r91; 
(EngineCore_DP0 pid=336967) 
(EngineCore_DP0 pid=336967) 	// end inline asm
(EngineCore_DP0 pid=336967) 	shr.u16 	%rs71, %rs63, 8;
(EngineCore_DP0 pid=336967) 	.loc	1 224 45                        // quant_slide_tuned_Llama3.2-1B.py:224:45
(EngineCore_DP0 pid=336967) 	cvt.u32.u16 	%r146, %rs56;
(EngineCore_DP0 pid=336967) 	and.b32 	%r147, %r146, 255;
(EngineCore_DP0 pid=336967) 	cvt.u32.u16 	%r148, %rs64;
(EngineCore_DP0 pid=336967) 	cvt.u32.u16 	%r149, %rs57;
(EngineCore_DP0 pid=336967) 	and.b32 	%r150, %r149, 255;
(EngineCore_DP0 pid=336967) 	cvt.u32.u16 	%r151, %rs65;
(EngineCore_DP0 pid=336967) 	.loc	1 226 45                        // quant_slide_tuned_Llama3.2-1B.py:226:45
(EngineCore_DP0 pid=336967) 	cvt.u32.u16 	%r152, %rs60;
(EngineCore_DP0 pid=336967) 	and.b32 	%r153, %r152, 255;
(EngineCore_DP0 pid=336967) 	cvt.u32.u16 	%r154, %rs68;
(EngineCore_DP0 pid=336967) 	cvt.u32.u16 	%r155, %rs61;
(EngineCore_DP0 pid=336967) 	and.b32 	%r156, %r155, 255;
(EngineCore_DP0 pid=336967) 	cvt.u32.u16 	%r157, %rs69;
(EngineCore_DP0 pid=336967) 	.loc	1 227 45                        // quant_slide_tuned_Llama3.2-1B.py:227:45
(EngineCore_DP0 pid=336967) 	cvt.u32.u16 	%r158, %rs62;
(EngineCore_DP0 pid=336967) 	cvt.u32.u16 	%r159, %rs70;
(EngineCore_DP0 pid=336967) 	cvt.u32.u16 	%r160, %rs63;
(EngineCore_DP0 pid=336967) 	cvt.u32.u16 	%r161, %rs71;
(EngineCore_DP0 pid=336967) 	.loc	1 229 30                        // quant_slide_tuned_Llama3.2-1B.py:229:30
(EngineCore_DP0 pid=336967) 	and.b16 	%rs72, %rs58, 255;
(EngineCore_DP0 pid=336967) 	mul.wide.u16 	%r162, %rs72, 256;
(EngineCore_DP0 pid=336967) 	mul.wide.u16 	%r163, %rs66, 256;
(EngineCore_DP0 pid=336967) 	and.b16 	%rs73, %rs59, 255;
(EngineCore_DP0 pid=336967) 	mul.wide.u16 	%r164, %rs73, 256;
(EngineCore_DP0 pid=336967) 	mul.wide.u16 	%r165, %rs67, 256;
(EngineCore_DP0 pid=336967) 	.loc	1 229 24                        // quant_slide_tuned_Llama3.2-1B.py:229:24
(EngineCore_DP0 pid=336967) 	or.b32 	%r166, %r162, %r147;
(EngineCore_DP0 pid=336967) 	or.b32 	%r167, %r163, %r148;
(EngineCore_DP0 pid=336967) 	or.b32 	%r168, %r164, %r150;
(EngineCore_DP0 pid=336967) 	or.b32 	%r169, %r165, %r151;
(EngineCore_DP0 pid=336967) 	.loc	1 229 42                        // quant_slide_tuned_Llama3.2-1B.py:229:42
(EngineCore_DP0 pid=336967) 	shl.b32 	%r170, %r153, 16;
(EngineCore_DP0 pid=336967) 	shl.b32 	%r171, %r154, 16;
(EngineCore_DP0 pid=336967) 	shl.b32 	%r172, %r156, 16;
(EngineCore_DP0 pid=336967) 	shl.b32 	%r173, %r157, 16;
(EngineCore_DP0 pid=336967) 	.loc	1 229 36                        // quant_slide_tuned_Llama3.2-1B.py:229:36
(EngineCore_DP0 pid=336967) 	or.b32 	%r174, %r170, %r166;
(EngineCore_DP0 pid=336967) 	or.b32 	%r175, %r171, %r167;
(EngineCore_DP0 pid=336967) 	or.b32 	%r176, %r172, %r168;
(EngineCore_DP0 pid=336967) 	or.b32 	%r177, %r173, %r169;
(EngineCore_DP0 pid=336967) 	.loc	1 229 55                        // quant_slide_tuned_Llama3.2-1B.py:229:55
(EngineCore_DP0 pid=336967) 	shl.b32 	%r178, %r158, 24;
(EngineCore_DP0 pid=336967) 	shl.b32 	%r179, %r159, 24;
(EngineCore_DP0 pid=336967) 	shl.b32 	%r180, %r160, 24;
(EngineCore_DP0 pid=336967) 	shl.b32 	%r181, %r161, 24;
(EngineCore_DP0 pid=336967) 	.loc	1 229 49                        // quant_slide_tuned_Llama3.2-1B.py:229:49
(EngineCore_DP0 pid=336967) 	or.b32 	%r93, %r178, %r174;
(EngineCore_DP0 pid=336967) 	or.b32 	%r94, %r179, %r175;
(EngineCore_DP0 pid=336967) 	or.b32 	%r95, %r180, %r176;
(EngineCore_DP0 pid=336967) 	or.b32 	%r96, %r181, %r177;
(EngineCore_DP0 pid=336967) 	.loc	1 230 29                        // quant_slide_tuned_Llama3.2-1B.py:230:29
(EngineCore_DP0 pid=336967) 	mad.wide.s32 	%rd24, %r97, 4, %rd2;
(EngineCore_DP0 pid=336967) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-1B.py:230:39
(EngineCore_DP0 pid=336967) 	// begin inline asm
(EngineCore_DP0 pid=336967) 	@%p25 st.global.v4.b32 [ %rd24 + 0 ], { %r93, %r94, %r95, %r96 };
(EngineCore_DP0 pid=336967) 	// end inline asm
(EngineCore_DP0 pid=336967) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=336967) 	add.s32 	%r186, %r186, 2048;
(EngineCore_DP0 pid=336967) 	add.s32 	%r185, %r185, 8192;
(EngineCore_DP0 pid=336967) 	setp.lt.s32 	%p42, %r186, %r23;
(EngineCore_DP0 pid=336967) 	@%p42 bra 	$L__BB0_6;
(EngineCore_DP0 pid=336967) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=336967) 	.loc	1 201 4                         // quant_slide_tuned_Llama3.2-1B.py:201:4
(EngineCore_DP0 pid=336967) 	ret;
(EngineCore_DP0 pid=336967) $L__tmp3:
(EngineCore_DP0 pid=336967) $L__func_end0:
(EngineCore_DP0 pid=336967)                                         // -- End function
(EngineCore_DP0 pid=336967) }
(EngineCore_DP0 pid=336967) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=336967) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=336967) 	.section	.debug_abbrev
(EngineCore_DP0 pid=336967) 	{
(EngineCore_DP0 pid=336967) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=336967) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=336967) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=336967) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=336967) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=336967) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=336967) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=336967) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=336967) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=336967) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=336967) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=336967) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=336967) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=336967) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=336967) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=336967) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=336967) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=336967) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=336967) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=336967) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=336967) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=336967) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=336967) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=336967) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=336967) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=336967) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=336967) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=336967) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=336967) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=336967) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=336967) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=336967) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=336967) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=336967) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=336967) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=336967) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=336967) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=336967) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=336967) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=336967) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=336967) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=336967) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=336967) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=336967) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=336967) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=336967) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=336967) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=336967) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=336967) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=336967) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=336967) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=336967) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=336967) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=336967) 	}
(EngineCore_DP0 pid=336967) 	.section	.debug_info
(EngineCore_DP0 pid=336967) 	{
(EngineCore_DP0 pid=336967) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=336967) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=336967) .b8 0
(EngineCore_DP0 pid=336967) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=336967) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=336967) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=336967) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=336967) .b8 114
(EngineCore_DP0 pid=336967) .b8 105
(EngineCore_DP0 pid=336967) .b8 116
(EngineCore_DP0 pid=336967) .b8 111
(EngineCore_DP0 pid=336967) .b8 110
(EngineCore_DP0 pid=336967) .b8 0
(EngineCore_DP0 pid=336967) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=336967) .b8 0
(EngineCore_DP0 pid=336967) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=336967) .b8 117
(EngineCore_DP0 pid=336967) .b8 97
(EngineCore_DP0 pid=336967) .b8 110
(EngineCore_DP0 pid=336967) .b8 116
(EngineCore_DP0 pid=336967) .b8 95
(EngineCore_DP0 pid=336967) .b8 115
(EngineCore_DP0 pid=336967) .b8 108
(EngineCore_DP0 pid=336967) .b8 105
(EngineCore_DP0 pid=336967) .b8 100
(EngineCore_DP0 pid=336967) .b8 101
(EngineCore_DP0 pid=336967) .b8 95
(EngineCore_DP0 pid=336967) .b8 116
(EngineCore_DP0 pid=336967) .b8 117
(EngineCore_DP0 pid=336967) .b8 110
(EngineCore_DP0 pid=336967) .b8 101
(EngineCore_DP0 pid=336967) .b8 100
(EngineCore_DP0 pid=336967) .b8 95
(EngineCore_DP0 pid=336967) .b8 76
(EngineCore_DP0 pid=336967) .b8 108
(EngineCore_DP0 pid=336967) .b8 97
(EngineCore_DP0 pid=336967) .b8 109
(EngineCore_DP0 pid=336967) .b8 97
(EngineCore_DP0 pid=336967) .b8 51
(EngineCore_DP0 pid=336967) .b8 46
(EngineCore_DP0 pid=336967) .b8 50
(EngineCore_DP0 pid=336967) .b8 45
(EngineCore_DP0 pid=336967) .b8 49
(EngineCore_DP0 pid=336967) .b8 66
(EngineCore_DP0 pid=336967) .b8 46
(EngineCore_DP0 pid=336967) .b8 112
(EngineCore_DP0 pid=336967) .b8 121
(EngineCore_DP0 pid=336967) .b8 0
(EngineCore_DP0 pid=336967) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=336967) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=336967) .b8 114
(EngineCore_DP0 pid=336967) .b8 111
(EngineCore_DP0 pid=336967) .b8 111
(EngineCore_DP0 pid=336967) .b8 116
(EngineCore_DP0 pid=336967) .b8 47
(EngineCore_DP0 pid=336967) .b8 118
(EngineCore_DP0 pid=336967) .b8 108
(EngineCore_DP0 pid=336967) .b8 108
(EngineCore_DP0 pid=336967) .b8 109
(EngineCore_DP0 pid=336967) .b8 98
(EngineCore_DP0 pid=336967) .b8 101
(EngineCore_DP0 pid=336967) .b8 110
(EngineCore_DP0 pid=336967) .b8 99
(EngineCore_DP0 pid=336967) .b8 104
(EngineCore_DP0 pid=336967) .b8 47
(EngineCore_DP0 pid=336967) .b8 115
(EngineCore_DP0 pid=336967) .b8 108
(EngineCore_DP0 pid=336967) .b8 105
(EngineCore_DP0 pid=336967) .b8 100
(EngineCore_DP0 pid=336967) .b8 101
(EngineCore_DP0 pid=336967) .b8 115
(EngineCore_DP0 pid=336967) .b8 112
(EngineCore_DP0 pid=336967) .b8 97
(EngineCore_DP0 pid=336967) .b8 114
(EngineCore_DP0 pid=336967) .b8 115
(EngineCore_DP0 pid=336967) .b8 101
(EngineCore_DP0 pid=336967) .b8 47
(EngineCore_DP0 pid=336967) .b8 99
(EngineCore_DP0 pid=336967) .b8 115
(EngineCore_DP0 pid=336967) .b8 114
(EngineCore_DP0 pid=336967) .b8 99
(EngineCore_DP0 pid=336967) .b8 47
(EngineCore_DP0 pid=336967) .b8 102
(EngineCore_DP0 pid=336967) .b8 117
(EngineCore_DP0 pid=336967) .b8 115
(EngineCore_DP0 pid=336967) .b8 101
(EngineCore_DP0 pid=336967) .b8 100
(EngineCore_DP0 pid=336967) .b8 95
(EngineCore_DP0 pid=336967) .b8 113
(EngineCore_DP0 pid=336967) .b8 117
(EngineCore_DP0 pid=336967) .b8 97
(EngineCore_DP0 pid=336967) .b8 110
(EngineCore_DP0 pid=336967) .b8 116
(EngineCore_DP0 pid=336967) .b8 95
(EngineCore_DP0 pid=336967) .b8 115
(EngineCore_DP0 pid=336967) .b8 108
(EngineCore_DP0 pid=336967) .b8 105
(EngineCore_DP0 pid=336967) .b8 100
(EngineCore_DP0 pid=336967) .b8 101
(EngineCore_DP0 pid=336967) .b8 95
(EngineCore_DP0 pid=336967) .b8 116
(EngineCore_DP0 pid=336967) .b8 114
(EngineCore_DP0 pid=336967) .b8 105
(EngineCore_DP0 pid=336967) .b8 116
(EngineCore_DP0 pid=336967) .b8 111
(EngineCore_DP0 pid=336967) .b8 110
(EngineCore_DP0 pid=336967) .b8 47
(EngineCore_DP0 pid=336967) .b8 98
(EngineCore_DP0 pid=336967) .b8 117
(EngineCore_DP0 pid=336967) .b8 105
(EngineCore_DP0 pid=336967) .b8 108
(EngineCore_DP0 pid=336967) .b8 100
(EngineCore_DP0 pid=336967) .b8 47
(EngineCore_DP0 pid=336967) .b8 71
(EngineCore_DP0 pid=336967) .b8 66
(EngineCore_DP0 pid=336967) .b8 49
(EngineCore_DP0 pid=336967) .b8 48
(EngineCore_DP0 pid=336967) .b8 95
(EngineCore_DP0 pid=336967) .b8 99
(EngineCore_DP0 pid=336967) .b8 99
(EngineCore_DP0 pid=336967) .b8 49
(EngineCore_DP0 pid=336967) .b8 50
(EngineCore_DP0 pid=336967) .b8 49
(EngineCore_DP0 pid=336967) .b8 95
(EngineCore_DP0 pid=336967) .b8 112
(EngineCore_DP0 pid=336967) .b8 121
(EngineCore_DP0 pid=336967) .b8 51
(EngineCore_DP0 pid=336967) .b8 49
(EngineCore_DP0 pid=336967) .b8 50
(EngineCore_DP0 pid=336967) .b8 95
(EngineCore_DP0 pid=336967) .b8 99
(EngineCore_DP0 pid=336967) .b8 117
(EngineCore_DP0 pid=336967) .b8 49
(EngineCore_DP0 pid=336967) .b8 50
(EngineCore_DP0 pid=336967) .b8 57
(EngineCore_DP0 pid=336967) .b8 95
(EngineCore_DP0 pid=336967) .b8 97
(EngineCore_DP0 pid=336967) .b8 97
(EngineCore_DP0 pid=336967) .b8 114
(EngineCore_DP0 pid=336967) .b8 99
(EngineCore_DP0 pid=336967) .b8 104
(EngineCore_DP0 pid=336967) .b8 54
(EngineCore_DP0 pid=336967) .b8 52
(EngineCore_DP0 pid=336967) .b8 0
(EngineCore_DP0 pid=336967) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=336967) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=336967) .b8 113
(EngineCore_DP0 pid=336967) .b8 117
(EngineCore_DP0 pid=336967) .b8 97
(EngineCore_DP0 pid=336967) .b8 110
(EngineCore_DP0 pid=336967) .b8 116
(EngineCore_DP0 pid=336967) .b8 95
(EngineCore_DP0 pid=336967) .b8 115
(EngineCore_DP0 pid=336967) .b8 108
(EngineCore_DP0 pid=336967) .b8 105
(EngineCore_DP0 pid=336967) .b8 100
(EngineCore_DP0 pid=336967) .b8 101
(EngineCore_DP0 pid=336967) .b8 95
(EngineCore_DP0 pid=336967) .b8 102
(EngineCore_DP0 pid=336967) .b8 112
(EngineCore_DP0 pid=336967) .b8 56
(EngineCore_DP0 pid=336967) .b8 95
(EngineCore_DP0 pid=336967) .b8 107
(EngineCore_DP0 pid=336967) .b8 101
(EngineCore_DP0 pid=336967) .b8 114
(EngineCore_DP0 pid=336967) .b8 110
(EngineCore_DP0 pid=336967) .b8 101
(EngineCore_DP0 pid=336967) .b8 108
(EngineCore_DP0 pid=336967) .b8 0
(EngineCore_DP0 pid=336967) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=336967) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=336967) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=336967) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=336967) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=336967) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=336967) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=336967) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=336967) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=336967) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=336967) .b8 191                                 // DW_AT_call_line
(EngineCore_DP0 pid=336967) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=336967) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=336967) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=336967) 	}
(EngineCore_DP0 pid=336967) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=336967) 
(EngineCore_DP0 pid=336967) ================================================================
(EngineCore_DP0 pid=336967) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=336967) 
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmptxemmebv.ptx', '-o', '/tmp/tmptxemmebv.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866] 
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866] 
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866] 
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmptxemmebv.ptx -o /tmp/tmptxemmebv.ptx.o
(EngineCore_DP0 pid=336967) ERROR 01-25 19:16:31 [core.py:866] 

STDERR:
[2026-01-25 19:16:17] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:16:17] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:16:17] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:16:17] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:16:17] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:16:17] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:16:17] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:16:17] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:16:17] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:16:17] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:16:17] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:16:17] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:16:17] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:16:17] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:16:20] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:16:20] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:16:20] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:16:20] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:16:20] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:16:20] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:16:20] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:16:20] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:16:20] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:16:20] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:16:20] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:16:20] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:16:20] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:16:20] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=336967) [2026-01-25 19:16:21] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=336967) [2026-01-25 19:16:21] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=336967) [2026-01-25 19:16:21] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=336967) [2026-01-25 19:16:21] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=336967) [2026-01-25 19:16:21] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=336967) [2026-01-25 19:16:21] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=336967) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=336967) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.26s/it]
(EngineCore_DP0 pid=336967) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.26s/it]
(EngineCore_DP0 pid=336967) 
(EngineCore_DP0 pid=336967) [2026-01-25 19:16:30] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=336967) [2026-01-25 19:16:30] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=336967) [2026-01-25 19:16:30] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=336967) [2026-01-25 19:16:30] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 2621440 bytes
(EngineCore_DP0 pid=336967) [2026-01-25 19:16:30] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=336967) [2026-01-25 19:16:30] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 20971520 bytes
(EngineCore_DP0 pid=336967) [2026-01-25 19:16:30] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=336967) [2026-01-25 19:16:30] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10485760 bytes
(EngineCore_DP0 pid=336967) Process EngineCore_DP0:
(EngineCore_DP0 pid=336967) Traceback (most recent call last):
(EngineCore_DP0 pid=336967)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=336967)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=336967)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=336967)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=336967) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmptxemmebv.ptx', '-o', '/tmp/tmptxemmebv.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=336967) 
(EngineCore_DP0 pid=336967) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=336967) 
(EngineCore_DP0 pid=336967) Traceback (most recent call last):
(EngineCore_DP0 pid=336967)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=336967)     self.run()
(EngineCore_DP0 pid=336967)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=336967)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=336967)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=336967)     raise e
(EngineCore_DP0 pid=336967)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=336967)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=336967)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=336967)     super().__init__(
(EngineCore_DP0 pid=336967)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=336967)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=336967)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=336967)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=336967)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=336967)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=336967)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=336967)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=336967)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=336967)     return func(*args, **kwargs)
(EngineCore_DP0 pid=336967)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=336967)     return func(*args, **kwargs)
(EngineCore_DP0 pid=336967)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=336967)     self.model_runner.profile_run()
(EngineCore_DP0 pid=336967)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=336967)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=336967)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=336967)     return func(*args, **kwargs)
(EngineCore_DP0 pid=336967)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=336967)     outputs = self.model(
(EngineCore_DP0 pid=336967)               ^^^^^^^^^^^
(EngineCore_DP0 pid=336967)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=336967)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=336967)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=336967)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=336967)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=336967)     model_output = self.model(
(EngineCore_DP0 pid=336967)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=336967)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=336967)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=336967)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=336967)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=336967)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=336967)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=336967)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=336967)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=336967)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=336967)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=336967)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=336967)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=336967)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=336967)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=336967)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=336967)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=336967)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=336967)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=336967)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=336967)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=336967)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=336967)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=336967)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=336967)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=336967)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=336967)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=336967)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=336967)     return self._linear_fn(
(EngineCore_DP0 pid=336967)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=336967)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=336967)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=336967)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=336967)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=336967)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=336967)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=336967)     return fn(input, L)
(EngineCore_DP0 pid=336967)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=336967)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=336967)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=336967)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=336967)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=336967)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=336967)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=336967)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=336967)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=336967)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=336967)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=336967)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=336967)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=336967)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=336967)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=336967)     raise PTXASError(error)
(EngineCore_DP0 pid=336967) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=336967) `ptxas` stderr:
(EngineCore_DP0 pid=336967) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=336967) 
(EngineCore_DP0 pid=336967) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmptxemmebv.ptx -o /tmp/tmptxemmebv.ptx.o
(EngineCore_DP0 pid=336967) 
[rank0]:[W125 19:16:31.640779041 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=65536

========== M=512 ==========
Time: 2026-01-25 19:59:53
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_4
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_4 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Llama3.2-3B-FP8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:59:57 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:59:57 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=387223) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=387223) 
(EngineCore_DP0 pid=387223) 
(EngineCore_DP0 pid=387223) ================================================================
(EngineCore_DP0 pid=387223) Internal Triton PTX codegen error
(EngineCore_DP0 pid=387223) `ptxas` stderr:
(EngineCore_DP0 pid=387223) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=387223) 
(EngineCore_DP0 pid=387223) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpz0ih65vn.ptx -o /tmp/tmpz0ih65vn.ptx.o
(EngineCore_DP0 pid=387223) 
(EngineCore_DP0 pid=387223) 
(EngineCore_DP0 pid=387223) //
(EngineCore_DP0 pid=387223) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=387223) //
(EngineCore_DP0 pid=387223) 
(EngineCore_DP0 pid=387223) .version 8.7
(EngineCore_DP0 pid=387223) .target sm_121a
(EngineCore_DP0 pid=387223) .address_size 64
(EngineCore_DP0 pid=387223) 
(EngineCore_DP0 pid=387223) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=387223) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=387223)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=387223) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=387223) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=387223) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=387223) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=387223) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=387223) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=387223) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=387223) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=387223) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=387223) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=387223) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=387223) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=387223) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=387223) )
(EngineCore_DP0 pid=387223) .reqntid 1024
(EngineCore_DP0 pid=387223) {
(EngineCore_DP0 pid=387223) 	.reg .pred 	%p<20>;
(EngineCore_DP0 pid=387223) 	.reg .b16 	%rs<25>;
(EngineCore_DP0 pid=387223) 	.reg .b32 	%r<108>;
(EngineCore_DP0 pid=387223) 	.reg .b64 	%rd<13>;
(EngineCore_DP0 pid=387223) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=387223) $L__func_begin0:
(EngineCore_DP0 pid=387223) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=387223) 
(EngineCore_DP0 pid=387223) // %bb.0:
(EngineCore_DP0 pid=387223) 	ld.param.b32 	%r20, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=387223) 	ld.param.b32 	%r19, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=387223) 	ld.param.b32 	%r18, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=387223) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=387223) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=387223) $L__tmp0:
(EngineCore_DP0 pid=387223) 	.loc	1 191 24                        // quant_slide_tuned_Llama3.2-3B.py:191:24
(EngineCore_DP0 pid=387223) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=387223) 	ld.param.b32 	%r22, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=387223) 	.loc	1 196 26                        // quant_slide_tuned_Llama3.2-3B.py:196:26
(EngineCore_DP0 pid=387223) 	mul.lo.s32 	%r23, %r22, %r1;
(EngineCore_DP0 pid=387223) 	.loc	1 196 20                        // quant_slide_tuned_Llama3.2-3B.py:196:20
(EngineCore_DP0 pid=387223) 	mad.wide.s32 	%rd1, %r23, 2, %rd4;
(EngineCore_DP0 pid=387223) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=387223) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=387223) 	shl.b32 	%r106, %r2, 2;
(EngineCore_DP0 pid=387223) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=387223) 	setp.lt.s32 	%p1, %r19, 1;
(EngineCore_DP0 pid=387223) 	mov.b32 	%r105, 0f2B8CBCCC;
(EngineCore_DP0 pid=387223) 	setp.eq.b32 	%p19, %r2, 0;
(EngineCore_DP0 pid=387223) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=387223) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=387223) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=387223) 	and.b32 	%r4, %r2, 31;
(EngineCore_DP0 pid=387223) 	shr.u32 	%r32, %r2, 3;
(EngineCore_DP0 pid=387223) 	and.b32 	%r33, %r32, 124;
(EngineCore_DP0 pid=387223) 	mov.b32 	%r34, global_smem;
(EngineCore_DP0 pid=387223) 	add.s32 	%r40, %r34, %r33;
(EngineCore_DP0 pid=387223) 	shl.b32 	%r35, %r2, 2;
(EngineCore_DP0 pid=387223) 	add.s32 	%r43, %r34, %r35;
(EngineCore_DP0 pid=387223) 	mov.b32 	%r38, 0;
(EngineCore_DP0 pid=387223) 	mov.b32 	%r103, 0f00000000;
(EngineCore_DP0 pid=387223) 	setp.lt.u32 	%p4, %r2, 32;
(EngineCore_DP0 pid=387223) 	setp.eq.b32 	%p3, %r4, 0;
(EngineCore_DP0 pid=387223) 	mov.b32 	%r104, %r38;
(EngineCore_DP0 pid=387223) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=387223) 	.loc	1 203 22                        // quant_slide_tuned_Llama3.2-3B.py:203:22
(EngineCore_DP0 pid=387223) 	add.s32 	%r46, %r106, %r104;
(EngineCore_DP0 pid=387223) 	setp.lt.s32 	%p2, %r46, %r18;
(EngineCore_DP0 pid=387223) 	.loc	1 204 29                        // quant_slide_tuned_Llama3.2-3B.py:204:29
(EngineCore_DP0 pid=387223) 	mad.wide.s32 	%rd6, %r46, 2, %rd1;
(EngineCore_DP0 pid=387223) 	.loc	1 204 21                        // quant_slide_tuned_Llama3.2-3B.py:204:21
(EngineCore_DP0 pid=387223) 	// begin inline asm
(EngineCore_DP0 pid=387223) 	mov.u32 %r36, %r38;
(EngineCore_DP0 pid=387223) 	mov.u32 %r37, %r38;
(EngineCore_DP0 pid=387223) 	@%p2 ld.global.v2.b32 { %r36, %r37 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=387223) 	// end inline asm
(EngineCore_DP0 pid=387223) 	mov.b32 	{%rs1, %rs2}, %r36;
(EngineCore_DP0 pid=387223) 	mov.b32 	{%rs3, %rs4}, %r37;
(EngineCore_DP0 pid=387223) 	.loc	1 205 50                        // quant_slide_tuned_Llama3.2-3B.py:205:50
(EngineCore_DP0 pid=387223) 	abs.bf16 	%rs5, %rs1;
(EngineCore_DP0 pid=387223) 	abs.bf16 	%rs6, %rs2;
(EngineCore_DP0 pid=387223) 	abs.bf16 	%rs7, %rs3;
(EngineCore_DP0 pid=387223) 	abs.bf16 	%rs8, %rs4;
(EngineCore_DP0 pid=387223) $L__tmp1:
(EngineCore_DP0 pid=387223) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=387223) 	bar.sync 	0;
(EngineCore_DP0 pid=387223) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=387223) 	max.bf16 	%rs9, %rs5, %rs6;
(EngineCore_DP0 pid=387223) 	max.bf16 	%rs10, %rs9, %rs7;
(EngineCore_DP0 pid=387223) 	max.bf16 	%rs11, %rs10, %rs8;
(EngineCore_DP0 pid=387223) 	cvt.f32.bf16 	%r47, %rs11;
(EngineCore_DP0 pid=387223) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=387223) 	shfl.sync.bfly.b32 	%r48, %r47, 16, 31, -1;
(EngineCore_DP0 pid=387223) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=387223) 	max.f32 	%r49, %r47, %r48;
(EngineCore_DP0 pid=387223) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=387223) 	shfl.sync.bfly.b32 	%r50, %r49, 8, 31, -1;
(EngineCore_DP0 pid=387223) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=387223) 	max.f32 	%r51, %r49, %r50;
(EngineCore_DP0 pid=387223) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=387223) 	shfl.sync.bfly.b32 	%r52, %r51, 4, 31, -1;
(EngineCore_DP0 pid=387223) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=387223) 	max.f32 	%r53, %r51, %r52;
(EngineCore_DP0 pid=387223) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=387223) 	shfl.sync.bfly.b32 	%r54, %r53, 2, 31, -1;
(EngineCore_DP0 pid=387223) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=387223) 	max.f32 	%r55, %r53, %r54;
(EngineCore_DP0 pid=387223) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=387223) 	shfl.sync.bfly.b32 	%r56, %r55, 1, 31, -1;
(EngineCore_DP0 pid=387223) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=387223) 	max.f32 	%r41, %r55, %r56;
(EngineCore_DP0 pid=387223) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=387223) 	// begin inline asm
(EngineCore_DP0 pid=387223) 	@%p3 st.shared.b32 [ %r40 + 0 ], %r41;
(EngineCore_DP0 pid=387223) 	// end inline asm
(EngineCore_DP0 pid=387223) 	bar.sync 	0;
(EngineCore_DP0 pid=387223) 	// begin inline asm
(EngineCore_DP0 pid=387223) 	@%p4 ld.shared.b32 %r42, [ %r43 + 0 ];
(EngineCore_DP0 pid=387223) 	// end inline asm
(EngineCore_DP0 pid=387223) 	shfl.sync.bfly.b32 	%r57, %r42, 16, 31, -1;
(EngineCore_DP0 pid=387223) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=387223) 	max.f32 	%r58, %r42, %r57;
(EngineCore_DP0 pid=387223) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=387223) 	shfl.sync.bfly.b32 	%r59, %r58, 8, 31, -1;
(EngineCore_DP0 pid=387223) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=387223) 	max.f32 	%r60, %r58, %r59;
(EngineCore_DP0 pid=387223) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=387223) 	shfl.sync.bfly.b32 	%r61, %r60, 4, 31, -1;
(EngineCore_DP0 pid=387223) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=387223) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=387223) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=387223) 	shfl.sync.bfly.b32 	%r63, %r62, 2, 31, -1;
(EngineCore_DP0 pid=387223) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=387223) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=387223) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=387223) 	shfl.sync.bfly.b32 	%r65, %r64, 1, 31, -1;
(EngineCore_DP0 pid=387223) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=387223) 	max.f32 	%r45, %r64, %r65;
(EngineCore_DP0 pid=387223) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=387223) 	// begin inline asm
(EngineCore_DP0 pid=387223) 	@%p19 st.shared.b32 [ %r43 + 0 ], %r45;
(EngineCore_DP0 pid=387223) 	// end inline asm
(EngineCore_DP0 pid=387223) 	bar.sync 	0;
(EngineCore_DP0 pid=387223) 	ld.shared.b32 	%r66, [global_smem];
(EngineCore_DP0 pid=387223) $L__tmp2:
(EngineCore_DP0 pid=387223) 	.loc	1 205 36                        // quant_slide_tuned_Llama3.2-3B.py:205:36
(EngineCore_DP0 pid=387223) 	max.f32 	%r103, %r103, %r66;
(EngineCore_DP0 pid=387223) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=387223) 	add.s32 	%r104, %r104, 4096;
(EngineCore_DP0 pid=387223) 	setp.lt.s32 	%p6, %r104, %r19;
(EngineCore_DP0 pid=387223) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=387223) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=387223) 	.loc	1 207 32                        // quant_slide_tuned_Llama3.2-3B.py:207:32
(EngineCore_DP0 pid=387223) 	max.f32 	%r105, %r103, 0f2B8CBCCC;
(EngineCore_DP0 pid=387223) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=387223) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-3B.py:0:32
(EngineCore_DP0 pid=387223) 	mov.b32 	%r68, 0f43E00000;
(EngineCore_DP0 pid=387223) 	.loc	1 208 32                        // quant_slide_tuned_Llama3.2-3B.py:208:32
(EngineCore_DP0 pid=387223) 	div.full.f32 	%r69, %r105, %r68;
(EngineCore_DP0 pid=387223) 	.loc	1 208 41                        // quant_slide_tuned_Llama3.2-3B.py:208:41
(EngineCore_DP0 pid=387223) 	max.f32 	%r67, %r69, 0f36924925;
(EngineCore_DP0 pid=387223) 	.loc	1 210 25                        // quant_slide_tuned_Llama3.2-3B.py:210:25
(EngineCore_DP0 pid=387223) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=387223) 	.loc	1 210 30                        // quant_slide_tuned_Llama3.2-3B.py:210:30
(EngineCore_DP0 pid=387223) 	// begin inline asm
(EngineCore_DP0 pid=387223) 	@%p19 st.global.b32 [ %rd7 + 0 ], { %r67 };
(EngineCore_DP0 pid=387223) 	// end inline asm
(EngineCore_DP0 pid=387223) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=387223) 	setp.lt.s32 	%p8, %r20, 1;
(EngineCore_DP0 pid=387223) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=387223) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=387223) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-3B.py:0:41
(EngineCore_DP0 pid=387223) 	ld.param.b32 	%r24, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=387223) 	shr.s32 	%r25, %r24, 31;
(EngineCore_DP0 pid=387223) 	shr.u32 	%r26, %r25, 30;
(EngineCore_DP0 pid=387223) 	add.s32 	%r27, %r24, %r26;
(EngineCore_DP0 pid=387223) 	shr.s32 	%r28, %r27, 2;
(EngineCore_DP0 pid=387223) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=387223) 	mul.lo.s32 	%r29, %r28, %r1;
(EngineCore_DP0 pid=387223) 	mad.wide.s32 	%rd2, %r29, 4, %rd5;
(EngineCore_DP0 pid=387223) 	div.full.f32 	%r13, %r68, %r105;
(EngineCore_DP0 pid=387223) 	mov.b32 	%r107, 0;
(EngineCore_DP0 pid=387223) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=387223)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=387223) 	.loc	1 217 30                        // quant_slide_tuned_Llama3.2-3B.py:217:30
(EngineCore_DP0 pid=387223) 	add.s32 	%r80, %r2, %r107;
(EngineCore_DP0 pid=387223) 	setp.lt.s32 	%p13, %r80, %r20;
(EngineCore_DP0 pid=387223) 	.loc	1 225 53                        // quant_slide_tuned_Llama3.2-3B.py:225:53
(EngineCore_DP0 pid=387223) 	setp.lt.s32 	%p14, %r106, %r18;
(EngineCore_DP0 pid=387223) 	.loc	1 225 37                        // quant_slide_tuned_Llama3.2-3B.py:225:37
(EngineCore_DP0 pid=387223) 	and.pred 	%p9, %p13, %p14;
(EngineCore_DP0 pid=387223) 	.loc	1 224 29                        // quant_slide_tuned_Llama3.2-3B.py:224:29
(EngineCore_DP0 pid=387223) 	mad.wide.s32 	%rd8, %r106, 2, %rd1;
(EngineCore_DP0 pid=387223) 	mov.b16 	%rs13, 0;
(EngineCore_DP0 pid=387223) 	.loc	1 224 21                        // quant_slide_tuned_Llama3.2-3B.py:224:21
(EngineCore_DP0 pid=387223) 	// begin inline asm
(EngineCore_DP0 pid=387223) 	mov.u16 %rs12, %rs13;
(EngineCore_DP0 pid=387223) 	@%p9 ld.global.b16 { %rs12 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=387223) 	// end inline asm
(EngineCore_DP0 pid=387223) 	.loc	1 225 79                        // quant_slide_tuned_Llama3.2-3B.py:225:79
(EngineCore_DP0 pid=387223) 	cvt.f32.bf16 	%r81, %rs12;
(EngineCore_DP0 pid=387223) 	.loc	1 227 53                        // quant_slide_tuned_Llama3.2-3B.py:227:53
(EngineCore_DP0 pid=387223) 	add.s32 	%r82, %r106, 1;
(EngineCore_DP0 pid=387223) 	setp.lt.s32 	%p15, %r82, %r18;
(EngineCore_DP0 pid=387223) 	.loc	1 227 37                        // quant_slide_tuned_Llama3.2-3B.py:227:37
(EngineCore_DP0 pid=387223) 	and.pred 	%p10, %p13, %p15;
(EngineCore_DP0 pid=387223) 	.loc	1 226 39                        // quant_slide_tuned_Llama3.2-3B.py:226:39
(EngineCore_DP0 pid=387223) 	add.s64 	%rd9, %rd8, 2;
(EngineCore_DP0 pid=387223) 	.loc	1 226 21                        // quant_slide_tuned_Llama3.2-3B.py:226:21
(EngineCore_DP0 pid=387223) 	// begin inline asm
(EngineCore_DP0 pid=387223) 	mov.u16 %rs14, %rs13;
(EngineCore_DP0 pid=387223) 	@%p10 ld.global.b16 { %rs14 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=387223) 	// end inline asm
(EngineCore_DP0 pid=387223) 	.loc	1 227 79                        // quant_slide_tuned_Llama3.2-3B.py:227:79
(EngineCore_DP0 pid=387223) 	cvt.f32.bf16 	%r83, %rs14;
(EngineCore_DP0 pid=387223) 	.loc	1 229 53                        // quant_slide_tuned_Llama3.2-3B.py:229:53
(EngineCore_DP0 pid=387223) 	add.s32 	%r84, %r106, 2;
(EngineCore_DP0 pid=387223) 	setp.lt.s32 	%p16, %r84, %r18;
(EngineCore_DP0 pid=387223) 	.loc	1 229 37                        // quant_slide_tuned_Llama3.2-3B.py:229:37
(EngineCore_DP0 pid=387223) 	and.pred 	%p11, %p13, %p16;
(EngineCore_DP0 pid=387223) 	.loc	1 228 39                        // quant_slide_tuned_Llama3.2-3B.py:228:39
(EngineCore_DP0 pid=387223) 	add.s64 	%rd10, %rd8, 4;
(EngineCore_DP0 pid=387223) 	.loc	1 228 21                        // quant_slide_tuned_Llama3.2-3B.py:228:21
(EngineCore_DP0 pid=387223) 	// begin inline asm
(EngineCore_DP0 pid=387223) 	mov.u16 %rs16, %rs13;
(EngineCore_DP0 pid=387223) 	@%p11 ld.global.b16 { %rs16 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=387223) 	// end inline asm
(EngineCore_DP0 pid=387223) 	.loc	1 229 79                        // quant_slide_tuned_Llama3.2-3B.py:229:79
(EngineCore_DP0 pid=387223) 	cvt.f32.bf16 	%r85, %rs16;
(EngineCore_DP0 pid=387223) 	.loc	1 231 53                        // quant_slide_tuned_Llama3.2-3B.py:231:53
(EngineCore_DP0 pid=387223) 	add.s32 	%r86, %r106, 3;
(EngineCore_DP0 pid=387223) 	setp.lt.s32 	%p17, %r86, %r18;
(EngineCore_DP0 pid=387223) 	.loc	1 231 37                        // quant_slide_tuned_Llama3.2-3B.py:231:37
(EngineCore_DP0 pid=387223) 	and.pred 	%p12, %p13, %p17;
(EngineCore_DP0 pid=387223) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-3B.py:230:39
(EngineCore_DP0 pid=387223) 	add.s64 	%rd11, %rd8, 6;
(EngineCore_DP0 pid=387223) 	.loc	1 230 21                        // quant_slide_tuned_Llama3.2-3B.py:230:21
(EngineCore_DP0 pid=387223) 	// begin inline asm
(EngineCore_DP0 pid=387223) 	mov.u16 %rs18, %rs13;
(EngineCore_DP0 pid=387223) 	@%p12 ld.global.b16 { %rs18 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=387223) 	// end inline asm
(EngineCore_DP0 pid=387223) 	.loc	1 231 79                        // quant_slide_tuned_Llama3.2-3B.py:231:79
(EngineCore_DP0 pid=387223) 	cvt.f32.bf16 	%r87, %rs18;
(EngineCore_DP0 pid=387223) 	.loc	1 233 27                        // quant_slide_tuned_Llama3.2-3B.py:233:27
(EngineCore_DP0 pid=387223) 	mul.f32 	%r88, %r13, %r81;
(EngineCore_DP0 pid=387223) 	mov.b32 	%r89, 0f43E00000;
(EngineCore_DP0 pid=387223) 	.loc	1 233 48                        // quant_slide_tuned_Llama3.2-3B.py:233:48
(EngineCore_DP0 pid=387223) 	min.xorsign.abs.f32 	%r71, %r88, %r89;
(EngineCore_DP0 pid=387223) 	.loc	1 233 60                        // quant_slide_tuned_Llama3.2-3B.py:233:60
(EngineCore_DP0 pid=387223) 	// begin inline asm
(EngineCore_DP0 pid=387223) 	cvt.rn.satfinite.e4m3x2.f32  %rs20, %r72, %r71; 
(EngineCore_DP0 pid=387223) 
(EngineCore_DP0 pid=387223) 	// end inline asm
(EngineCore_DP0 pid=387223) 	.loc	1 234 27                        // quant_slide_tuned_Llama3.2-3B.py:234:27
(EngineCore_DP0 pid=387223) 	mul.f32 	%r90, %r13, %r83;
(EngineCore_DP0 pid=387223) 	.loc	1 234 48                        // quant_slide_tuned_Llama3.2-3B.py:234:48
(EngineCore_DP0 pid=387223) 	min.xorsign.abs.f32 	%r73, %r90, %r89;
(EngineCore_DP0 pid=387223) 	.loc	1 234 60                        // quant_slide_tuned_Llama3.2-3B.py:234:60
(EngineCore_DP0 pid=387223) 	// begin inline asm
(EngineCore_DP0 pid=387223) 	cvt.rn.satfinite.e4m3x2.f32  %rs21, %r74, %r73; 
(EngineCore_DP0 pid=387223) 
(EngineCore_DP0 pid=387223) 	// end inline asm
(EngineCore_DP0 pid=387223) 	.loc	1 235 27                        // quant_slide_tuned_Llama3.2-3B.py:235:27
(EngineCore_DP0 pid=387223) 	mul.f32 	%r91, %r13, %r85;
(EngineCore_DP0 pid=387223) 	.loc	1 235 48                        // quant_slide_tuned_Llama3.2-3B.py:235:48
(EngineCore_DP0 pid=387223) 	min.xorsign.abs.f32 	%r75, %r91, %r89;
(EngineCore_DP0 pid=387223) 	.loc	1 235 60                        // quant_slide_tuned_Llama3.2-3B.py:235:60
(EngineCore_DP0 pid=387223) 	// begin inline asm
(EngineCore_DP0 pid=387223) 	cvt.rn.satfinite.e4m3x2.f32  %rs22, %r76, %r75; 
(EngineCore_DP0 pid=387223) 
(EngineCore_DP0 pid=387223) 	// end inline asm
(EngineCore_DP0 pid=387223) 	.loc	1 236 27                        // quant_slide_tuned_Llama3.2-3B.py:236:27
(EngineCore_DP0 pid=387223) 	mul.f32 	%r92, %r13, %r87;
(EngineCore_DP0 pid=387223) 	.loc	1 236 48                        // quant_slide_tuned_Llama3.2-3B.py:236:48
(EngineCore_DP0 pid=387223) 	min.xorsign.abs.f32 	%r77, %r92, %r89;
(EngineCore_DP0 pid=387223) 	.loc	1 236 60                        // quant_slide_tuned_Llama3.2-3B.py:236:60
(EngineCore_DP0 pid=387223) 	// begin inline asm
(EngineCore_DP0 pid=387223) 	cvt.rn.satfinite.e4m3x2.f32  %rs23, %r78, %r77; 
(EngineCore_DP0 pid=387223) 
(EngineCore_DP0 pid=387223) 	// end inline asm
(EngineCore_DP0 pid=387223) 	.loc	1 238 45                        // quant_slide_tuned_Llama3.2-3B.py:238:45
(EngineCore_DP0 pid=387223) 	cvt.u32.u16 	%r93, %rs20;
(EngineCore_DP0 pid=387223) 	and.b32 	%r94, %r93, 255;
(EngineCore_DP0 pid=387223) 	.loc	1 240 45                        // quant_slide_tuned_Llama3.2-3B.py:240:45
(EngineCore_DP0 pid=387223) 	cvt.u32.u16 	%r95, %rs22;
(EngineCore_DP0 pid=387223) 	and.b32 	%r96, %r95, 255;
(EngineCore_DP0 pid=387223) 	.loc	1 241 45                        // quant_slide_tuned_Llama3.2-3B.py:241:45
(EngineCore_DP0 pid=387223) 	cvt.u32.u16 	%r97, %rs23;
(EngineCore_DP0 pid=387223) 	.loc	1 243 30                        // quant_slide_tuned_Llama3.2-3B.py:243:30
(EngineCore_DP0 pid=387223) 	and.b16 	%rs24, %rs21, 255;
(EngineCore_DP0 pid=387223) 	mul.wide.u16 	%r98, %rs24, 256;
(EngineCore_DP0 pid=387223) 	.loc	1 243 24                        // quant_slide_tuned_Llama3.2-3B.py:243:24
(EngineCore_DP0 pid=387223) 	or.b32 	%r99, %r98, %r94;
(EngineCore_DP0 pid=387223) 	.loc	1 243 42                        // quant_slide_tuned_Llama3.2-3B.py:243:42
(EngineCore_DP0 pid=387223) 	shl.b32 	%r100, %r96, 16;
(EngineCore_DP0 pid=387223) 	.loc	1 243 36                        // quant_slide_tuned_Llama3.2-3B.py:243:36
(EngineCore_DP0 pid=387223) 	or.b32 	%r101, %r99, %r100;
(EngineCore_DP0 pid=387223) 	.loc	1 243 55                        // quant_slide_tuned_Llama3.2-3B.py:243:55
(EngineCore_DP0 pid=387223) 	shl.b32 	%r102, %r97, 24;
(EngineCore_DP0 pid=387223) 	.loc	1 243 49                        // quant_slide_tuned_Llama3.2-3B.py:243:49
(EngineCore_DP0 pid=387223) 	or.b32 	%r79, %r101, %r102;
(EngineCore_DP0 pid=387223) 	.loc	1 244 29                        // quant_slide_tuned_Llama3.2-3B.py:244:29
(EngineCore_DP0 pid=387223) 	mad.wide.s32 	%rd12, %r80, 4, %rd2;
(EngineCore_DP0 pid=387223) 	.loc	1 244 39                        // quant_slide_tuned_Llama3.2-3B.py:244:39
(EngineCore_DP0 pid=387223) 	// begin inline asm
(EngineCore_DP0 pid=387223) 	@%p13 st.global.b32 [ %rd12 + 0 ], { %r79 };
(EngineCore_DP0 pid=387223) 	// end inline asm
(EngineCore_DP0 pid=387223) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=387223) 	add.s32 	%r107, %r107, 1024;
(EngineCore_DP0 pid=387223) 	add.s32 	%r106, %r106, 4096;
(EngineCore_DP0 pid=387223) 	setp.lt.s32 	%p18, %r107, %r20;
(EngineCore_DP0 pid=387223) 	@%p18 bra 	$L__BB0_6;
(EngineCore_DP0 pid=387223) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=387223) 	.loc	1 215 4                         // quant_slide_tuned_Llama3.2-3B.py:215:4
(EngineCore_DP0 pid=387223) 	ret;
(EngineCore_DP0 pid=387223) $L__tmp3:
(EngineCore_DP0 pid=387223) $L__func_end0:
(EngineCore_DP0 pid=387223)                                         // -- End function
(EngineCore_DP0 pid=387223) }
(EngineCore_DP0 pid=387223) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py"
(EngineCore_DP0 pid=387223) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=387223) 	.section	.debug_abbrev
(EngineCore_DP0 pid=387223) 	{
(EngineCore_DP0 pid=387223) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=387223) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=387223) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=387223) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=387223) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=387223) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=387223) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=387223) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=387223) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=387223) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=387223) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=387223) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=387223) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=387223) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=387223) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=387223) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=387223) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=387223) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=387223) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=387223) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=387223) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=387223) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=387223) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=387223) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=387223) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=387223) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=387223) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=387223) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=387223) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=387223) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=387223) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=387223) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=387223) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=387223) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=387223) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=387223) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=387223) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=387223) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=387223) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=387223) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=387223) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=387223) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=387223) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=387223) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=387223) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=387223) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=387223) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=387223) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=387223) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=387223) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=387223) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=387223) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=387223) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=387223) 	}
(EngineCore_DP0 pid=387223) 	.section	.debug_info
(EngineCore_DP0 pid=387223) 	{
(EngineCore_DP0 pid=387223) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=387223) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=387223) .b8 0
(EngineCore_DP0 pid=387223) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=387223) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=387223) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=387223) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=387223) .b8 114
(EngineCore_DP0 pid=387223) .b8 105
(EngineCore_DP0 pid=387223) .b8 116
(EngineCore_DP0 pid=387223) .b8 111
(EngineCore_DP0 pid=387223) .b8 110
(EngineCore_DP0 pid=387223) .b8 0
(EngineCore_DP0 pid=387223) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=387223) .b8 0
(EngineCore_DP0 pid=387223) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=387223) .b8 117
(EngineCore_DP0 pid=387223) .b8 97
(EngineCore_DP0 pid=387223) .b8 110
(EngineCore_DP0 pid=387223) .b8 116
(EngineCore_DP0 pid=387223) .b8 95
(EngineCore_DP0 pid=387223) .b8 115
(EngineCore_DP0 pid=387223) .b8 108
(EngineCore_DP0 pid=387223) .b8 105
(EngineCore_DP0 pid=387223) .b8 100
(EngineCore_DP0 pid=387223) .b8 101
(EngineCore_DP0 pid=387223) .b8 95
(EngineCore_DP0 pid=387223) .b8 116
(EngineCore_DP0 pid=387223) .b8 117
(EngineCore_DP0 pid=387223) .b8 110
(EngineCore_DP0 pid=387223) .b8 101
(EngineCore_DP0 pid=387223) .b8 100
(EngineCore_DP0 pid=387223) .b8 95
(EngineCore_DP0 pid=387223) .b8 76
(EngineCore_DP0 pid=387223) .b8 108
(EngineCore_DP0 pid=387223) .b8 97
(EngineCore_DP0 pid=387223) .b8 109
(EngineCore_DP0 pid=387223) .b8 97
(EngineCore_DP0 pid=387223) .b8 51
(EngineCore_DP0 pid=387223) .b8 46
(EngineCore_DP0 pid=387223) .b8 50
(EngineCore_DP0 pid=387223) .b8 45
(EngineCore_DP0 pid=387223) .b8 51
(EngineCore_DP0 pid=387223) .b8 66
(EngineCore_DP0 pid=387223) .b8 46
(EngineCore_DP0 pid=387223) .b8 112
(EngineCore_DP0 pid=387223) .b8 121
(EngineCore_DP0 pid=387223) .b8 0
(EngineCore_DP0 pid=387223) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=387223) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=387223) .b8 114
(EngineCore_DP0 pid=387223) .b8 111
(EngineCore_DP0 pid=387223) .b8 111
(EngineCore_DP0 pid=387223) .b8 116
(EngineCore_DP0 pid=387223) .b8 47
(EngineCore_DP0 pid=387223) .b8 118
(EngineCore_DP0 pid=387223) .b8 108
(EngineCore_DP0 pid=387223) .b8 108
(EngineCore_DP0 pid=387223) .b8 109
(EngineCore_DP0 pid=387223) .b8 98
(EngineCore_DP0 pid=387223) .b8 101
(EngineCore_DP0 pid=387223) .b8 110
(EngineCore_DP0 pid=387223) .b8 99
(EngineCore_DP0 pid=387223) .b8 104
(EngineCore_DP0 pid=387223) .b8 47
(EngineCore_DP0 pid=387223) .b8 115
(EngineCore_DP0 pid=387223) .b8 108
(EngineCore_DP0 pid=387223) .b8 105
(EngineCore_DP0 pid=387223) .b8 100
(EngineCore_DP0 pid=387223) .b8 101
(EngineCore_DP0 pid=387223) .b8 115
(EngineCore_DP0 pid=387223) .b8 112
(EngineCore_DP0 pid=387223) .b8 97
(EngineCore_DP0 pid=387223) .b8 114
(EngineCore_DP0 pid=387223) .b8 115
(EngineCore_DP0 pid=387223) .b8 101
(EngineCore_DP0 pid=387223) .b8 47
(EngineCore_DP0 pid=387223) .b8 99
(EngineCore_DP0 pid=387223) .b8 115
(EngineCore_DP0 pid=387223) .b8 114
(EngineCore_DP0 pid=387223) .b8 99
(EngineCore_DP0 pid=387223) .b8 47
(EngineCore_DP0 pid=387223) .b8 102
(EngineCore_DP0 pid=387223) .b8 117
(EngineCore_DP0 pid=387223) .b8 115
(EngineCore_DP0 pid=387223) .b8 101
(EngineCore_DP0 pid=387223) .b8 100
(EngineCore_DP0 pid=387223) .b8 95
(EngineCore_DP0 pid=387223) .b8 113
(EngineCore_DP0 pid=387223) .b8 117
(EngineCore_DP0 pid=387223) .b8 97
(EngineCore_DP0 pid=387223) .b8 110
(EngineCore_DP0 pid=387223) .b8 116
(EngineCore_DP0 pid=387223) .b8 95
(EngineCore_DP0 pid=387223) .b8 115
(EngineCore_DP0 pid=387223) .b8 108
(EngineCore_DP0 pid=387223) .b8 105
(EngineCore_DP0 pid=387223) .b8 100
(EngineCore_DP0 pid=387223) .b8 101
(EngineCore_DP0 pid=387223) .b8 95
(EngineCore_DP0 pid=387223) .b8 116
(EngineCore_DP0 pid=387223) .b8 114
(EngineCore_DP0 pid=387223) .b8 105
(EngineCore_DP0 pid=387223) .b8 116
(EngineCore_DP0 pid=387223) .b8 111
(EngineCore_DP0 pid=387223) .b8 110
(EngineCore_DP0 pid=387223) .b8 47
(EngineCore_DP0 pid=387223) .b8 98
(EngineCore_DP0 pid=387223) .b8 117
(EngineCore_DP0 pid=387223) .b8 105
(EngineCore_DP0 pid=387223) .b8 108
(EngineCore_DP0 pid=387223) .b8 100
(EngineCore_DP0 pid=387223) .b8 47
(EngineCore_DP0 pid=387223) .b8 71
(EngineCore_DP0 pid=387223) .b8 66
(EngineCore_DP0 pid=387223) .b8 49
(EngineCore_DP0 pid=387223) .b8 48
(EngineCore_DP0 pid=387223) .b8 95
(EngineCore_DP0 pid=387223) .b8 99
(EngineCore_DP0 pid=387223) .b8 99
(EngineCore_DP0 pid=387223) .b8 49
(EngineCore_DP0 pid=387223) .b8 50
(EngineCore_DP0 pid=387223) .b8 49
(EngineCore_DP0 pid=387223) .b8 95
(EngineCore_DP0 pid=387223) .b8 112
(EngineCore_DP0 pid=387223) .b8 121
(EngineCore_DP0 pid=387223) .b8 51
(EngineCore_DP0 pid=387223) .b8 49
(EngineCore_DP0 pid=387223) .b8 50
(EngineCore_DP0 pid=387223) .b8 95
(EngineCore_DP0 pid=387223) .b8 99
(EngineCore_DP0 pid=387223) .b8 117
(EngineCore_DP0 pid=387223) .b8 49
(EngineCore_DP0 pid=387223) .b8 50
(EngineCore_DP0 pid=387223) .b8 57
(EngineCore_DP0 pid=387223) .b8 95
(EngineCore_DP0 pid=387223) .b8 97
(EngineCore_DP0 pid=387223) .b8 97
(EngineCore_DP0 pid=387223) .b8 114
(EngineCore_DP0 pid=387223) .b8 99
(EngineCore_DP0 pid=387223) .b8 104
(EngineCore_DP0 pid=387223) .b8 54
(EngineCore_DP0 pid=387223) .b8 52
(EngineCore_DP0 pid=387223) .b8 0
(EngineCore_DP0 pid=387223) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=387223) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=387223) .b8 113
(EngineCore_DP0 pid=387223) .b8 117
(EngineCore_DP0 pid=387223) .b8 97
(EngineCore_DP0 pid=387223) .b8 110
(EngineCore_DP0 pid=387223) .b8 116
(EngineCore_DP0 pid=387223) .b8 95
(EngineCore_DP0 pid=387223) .b8 115
(EngineCore_DP0 pid=387223) .b8 108
(EngineCore_DP0 pid=387223) .b8 105
(EngineCore_DP0 pid=387223) .b8 100
(EngineCore_DP0 pid=387223) .b8 101
(EngineCore_DP0 pid=387223) .b8 95
(EngineCore_DP0 pid=387223) .b8 102
(EngineCore_DP0 pid=387223) .b8 112
(EngineCore_DP0 pid=387223) .b8 56
(EngineCore_DP0 pid=387223) .b8 95
(EngineCore_DP0 pid=387223) .b8 107
(EngineCore_DP0 pid=387223) .b8 101
(EngineCore_DP0 pid=387223) .b8 114
(EngineCore_DP0 pid=387223) .b8 110
(EngineCore_DP0 pid=387223) .b8 101
(EngineCore_DP0 pid=387223) .b8 108
(EngineCore_DP0 pid=387223) .b8 0
(EngineCore_DP0 pid=387223) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=387223) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=387223) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=387223) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=387223) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=387223) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=387223) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=387223) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=387223) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=387223) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=387223) .b8 205                                 // DW_AT_call_line
(EngineCore_DP0 pid=387223) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=387223) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=387223) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=387223) 	}
(EngineCore_DP0 pid=387223) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=387223) 
(EngineCore_DP0 pid=387223) ================================================================
(EngineCore_DP0 pid=387223) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=387223) 
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpz0ih65vn.ptx', '-o', '/tmp/tmpz0ih65vn.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866] 
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866] 
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866] 
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpz0ih65vn.ptx -o /tmp/tmpz0ih65vn.ptx.o
(EngineCore_DP0 pid=387223) ERROR 01-25 20:00:20 [core.py:866] 

STDERR:
[2026-01-25 19:59:57] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:59:57] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 19:59:57] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 19:59:57] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 19:59:57] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 19:59:57] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 19:59:57] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 19:59:57] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 19:59:57] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 19:59:57] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:59:57] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:59:57] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:59:57] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:59:57] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:00:01] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:00:01] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:00:01] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:00:01] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:00:01] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:00:01] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:00:01] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:00:01] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:00:01] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:00:01] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:00:01] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:00:01] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:00:01] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:00:01] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=387223) [2026-01-25 20:00:02] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=387223) [2026-01-25 20:00:02] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=387223) [2026-01-25 20:00:02] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=387223) [2026-01-25 20:00:02] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=387223) [2026-01-25 20:00:02] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=387223) [2026-01-25 20:00:02] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=387223) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=387223) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:16<00:00, 16.62s/it]
(EngineCore_DP0 pid=387223) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:16<00:00, 16.62s/it]
(EngineCore_DP0 pid=387223) 
(EngineCore_DP0 pid=387223) [2026-01-25 20:00:19] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 3072] -> 1D uint8
(EngineCore_DP0 pid=387223) [2026-01-25 20:00:19] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9830400 bytes
(EngineCore_DP0 pid=387223) [2026-01-25 20:00:19] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=387223) [2026-01-25 20:00:19] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5898240 bytes
(EngineCore_DP0 pid=387223) [2026-01-25 20:00:19] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=387223) [2026-01-25 20:00:19] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 31457280 bytes
(EngineCore_DP0 pid=387223) [2026-01-25 20:00:19] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 8192] -> 1D uint8
(EngineCore_DP0 pid=387223) [2026-01-25 20:00:19] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15728640 bytes
(EngineCore_DP0 pid=387223) Process EngineCore_DP0:
(EngineCore_DP0 pid=387223) Traceback (most recent call last):
(EngineCore_DP0 pid=387223)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=387223)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=387223)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=387223)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=387223) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpz0ih65vn.ptx', '-o', '/tmp/tmpz0ih65vn.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=387223) 
(EngineCore_DP0 pid=387223) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=387223) 
(EngineCore_DP0 pid=387223) Traceback (most recent call last):
(EngineCore_DP0 pid=387223)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=387223)     self.run()
(EngineCore_DP0 pid=387223)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=387223)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=387223)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=387223)     raise e
(EngineCore_DP0 pid=387223)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=387223)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=387223)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=387223)     super().__init__(
(EngineCore_DP0 pid=387223)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=387223)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=387223)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=387223)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=387223)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=387223)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=387223)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=387223)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=387223)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=387223)     return func(*args, **kwargs)
(EngineCore_DP0 pid=387223)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=387223)     return func(*args, **kwargs)
(EngineCore_DP0 pid=387223)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=387223)     self.model_runner.profile_run()
(EngineCore_DP0 pid=387223)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=387223)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=387223)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=387223)     return func(*args, **kwargs)
(EngineCore_DP0 pid=387223)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=387223)     outputs = self.model(
(EngineCore_DP0 pid=387223)               ^^^^^^^^^^^
(EngineCore_DP0 pid=387223)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=387223)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=387223)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=387223)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=387223)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=387223)     model_output = self.model(
(EngineCore_DP0 pid=387223)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=387223)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=387223)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=387223)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=387223)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=387223)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=387223)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=387223)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=387223)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=387223)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=387223)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=387223)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=387223)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=387223)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=387223)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=387223)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=387223)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=387223)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=387223)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=387223)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=387223)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=387223)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=387223)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=387223)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=387223)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=387223)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=387223)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=387223)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=387223)     return self._linear_fn(
(EngineCore_DP0 pid=387223)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=387223)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=387223)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=387223)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=387223)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=387223)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=387223)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=387223)     return fn(input, L)
(EngineCore_DP0 pid=387223)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=387223)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=387223)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=387223)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=387223)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=387223)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=387223)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=387223)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=387223)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=387223)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=387223)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=387223)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=387223)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=387223)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387223)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=387223)     raise PTXASError(error)
(EngineCore_DP0 pid=387223) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=387223) `ptxas` stderr:
(EngineCore_DP0 pid=387223) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=387223) 
(EngineCore_DP0 pid=387223) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpz0ih65vn.ptx -o /tmp/tmpz0ih65vn.ptx.o
(EngineCore_DP0 pid=387223) 
[rank0]:[W125 20:00:20.796978545 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=512

========== M=1024 ==========
Time: 2026-01-25 20:00:22
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Llama3.2-3B-FP8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:00:26 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 20:00:26 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=387806) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=387806) 
(EngineCore_DP0 pid=387806) 
(EngineCore_DP0 pid=387806) ================================================================
(EngineCore_DP0 pid=387806) Internal Triton PTX codegen error
(EngineCore_DP0 pid=387806) `ptxas` stderr:
(EngineCore_DP0 pid=387806) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=387806) 
(EngineCore_DP0 pid=387806) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmphb0sjptm.ptx -o /tmp/tmphb0sjptm.ptx.o
(EngineCore_DP0 pid=387806) 
(EngineCore_DP0 pid=387806) 
(EngineCore_DP0 pid=387806) //
(EngineCore_DP0 pid=387806) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=387806) //
(EngineCore_DP0 pid=387806) 
(EngineCore_DP0 pid=387806) .version 8.7
(EngineCore_DP0 pid=387806) .target sm_121a
(EngineCore_DP0 pid=387806) .address_size 64
(EngineCore_DP0 pid=387806) 
(EngineCore_DP0 pid=387806) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=387806) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=387806)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=387806) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=387806) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=387806) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=387806) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=387806) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=387806) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=387806) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=387806) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=387806) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=387806) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=387806) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=387806) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=387806) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=387806) )
(EngineCore_DP0 pid=387806) .reqntid 512
(EngineCore_DP0 pid=387806) {
(EngineCore_DP0 pid=387806) 	.reg .pred 	%p<20>;
(EngineCore_DP0 pid=387806) 	.reg .b16 	%rs<37>;
(EngineCore_DP0 pid=387806) 	.reg .b32 	%r<112>;
(EngineCore_DP0 pid=387806) 	.reg .b64 	%rd<13>;
(EngineCore_DP0 pid=387806) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=387806) $L__func_begin0:
(EngineCore_DP0 pid=387806) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=387806) 
(EngineCore_DP0 pid=387806) // %bb.0:
(EngineCore_DP0 pid=387806) 	ld.param.b32 	%r22, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=387806) 	ld.param.b32 	%r21, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=387806) 	ld.param.b32 	%r20, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=387806) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=387806) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=387806) $L__tmp0:
(EngineCore_DP0 pid=387806) 	.loc	1 191 24                        // quant_slide_tuned_Llama3.2-3B.py:191:24
(EngineCore_DP0 pid=387806) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=387806) 	ld.param.b32 	%r24, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=387806) 	.loc	1 196 26                        // quant_slide_tuned_Llama3.2-3B.py:196:26
(EngineCore_DP0 pid=387806) 	mul.lo.s32 	%r25, %r24, %r1;
(EngineCore_DP0 pid=387806) 	.loc	1 196 20                        // quant_slide_tuned_Llama3.2-3B.py:196:20
(EngineCore_DP0 pid=387806) 	mad.wide.s32 	%rd1, %r25, 2, %rd4;
(EngineCore_DP0 pid=387806) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=387806) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=387806) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=387806) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=387806) 	setp.lt.s32 	%p1, %r21, 1;
(EngineCore_DP0 pid=387806) 	mov.b32 	%r109, 0f2B8CBCCC;
(EngineCore_DP0 pid=387806) 	setp.eq.b32 	%p19, %r2, 0;
(EngineCore_DP0 pid=387806) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=387806) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=387806) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=387806) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=387806) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=387806) 	shr.u32 	%r34, %r2, 3;
(EngineCore_DP0 pid=387806) 	and.b32 	%r35, %r34, 60;
(EngineCore_DP0 pid=387806) 	mov.b32 	%r36, global_smem;
(EngineCore_DP0 pid=387806) 	add.s32 	%r46, %r36, %r35;
(EngineCore_DP0 pid=387806) 	shl.b32 	%r37, %r2, 2;
(EngineCore_DP0 pid=387806) 	add.s32 	%r49, %r36, %r37;
(EngineCore_DP0 pid=387806) 	mov.b32 	%r42, 0;
(EngineCore_DP0 pid=387806) 	mov.b32 	%r107, 0f00000000;
(EngineCore_DP0 pid=387806) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=387806) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=387806) 	mov.b32 	%r108, %r42;
(EngineCore_DP0 pid=387806) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=387806) 	.loc	1 203 22                        // quant_slide_tuned_Llama3.2-3B.py:203:22
(EngineCore_DP0 pid=387806) 	add.s32 	%r52, %r4, %r108;
(EngineCore_DP0 pid=387806) 	setp.lt.s32 	%p2, %r52, %r20;
(EngineCore_DP0 pid=387806) 	.loc	1 204 29                        // quant_slide_tuned_Llama3.2-3B.py:204:29
(EngineCore_DP0 pid=387806) 	mad.wide.s32 	%rd6, %r52, 2, %rd1;
(EngineCore_DP0 pid=387806) 	.loc	1 204 21                        // quant_slide_tuned_Llama3.2-3B.py:204:21
(EngineCore_DP0 pid=387806) 	// begin inline asm
(EngineCore_DP0 pid=387806) 	mov.u32 %r38, %r42;
(EngineCore_DP0 pid=387806) 	mov.u32 %r39, %r42;
(EngineCore_DP0 pid=387806) 	mov.u32 %r40, %r42;
(EngineCore_DP0 pid=387806) 	mov.u32 %r41, %r42;
(EngineCore_DP0 pid=387806) 	@%p2 ld.global.v4.b32 { %r38, %r39, %r40, %r41 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=387806) 	// end inline asm
(EngineCore_DP0 pid=387806) 	mov.b32 	{%rs1, %rs2}, %r38;
(EngineCore_DP0 pid=387806) 	mov.b32 	{%rs3, %rs4}, %r39;
(EngineCore_DP0 pid=387806) 	mov.b32 	{%rs5, %rs6}, %r40;
(EngineCore_DP0 pid=387806) 	mov.b32 	{%rs7, %rs8}, %r41;
(EngineCore_DP0 pid=387806) 	.loc	1 205 50                        // quant_slide_tuned_Llama3.2-3B.py:205:50
(EngineCore_DP0 pid=387806) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=387806) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=387806) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=387806) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=387806) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=387806) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=387806) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=387806) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=387806) $L__tmp1:
(EngineCore_DP0 pid=387806) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=387806) 	bar.sync 	0;
(EngineCore_DP0 pid=387806) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=387806) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=387806) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=387806) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=387806) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=387806) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=387806) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=387806) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=387806) 	cvt.f32.bf16 	%r53, %rs23;
(EngineCore_DP0 pid=387806) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=387806) 	shfl.sync.bfly.b32 	%r54, %r53, 16, 31, -1;
(EngineCore_DP0 pid=387806) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=387806) 	max.f32 	%r55, %r53, %r54;
(EngineCore_DP0 pid=387806) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=387806) 	shfl.sync.bfly.b32 	%r56, %r55, 8, 31, -1;
(EngineCore_DP0 pid=387806) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=387806) 	max.f32 	%r57, %r55, %r56;
(EngineCore_DP0 pid=387806) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=387806) 	shfl.sync.bfly.b32 	%r58, %r57, 4, 31, -1;
(EngineCore_DP0 pid=387806) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=387806) 	max.f32 	%r59, %r57, %r58;
(EngineCore_DP0 pid=387806) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=387806) 	shfl.sync.bfly.b32 	%r60, %r59, 2, 31, -1;
(EngineCore_DP0 pid=387806) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=387806) 	max.f32 	%r61, %r59, %r60;
(EngineCore_DP0 pid=387806) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=387806) 	shfl.sync.bfly.b32 	%r62, %r61, 1, 31, -1;
(EngineCore_DP0 pid=387806) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=387806) 	max.f32 	%r47, %r61, %r62;
(EngineCore_DP0 pid=387806) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=387806) 	// begin inline asm
(EngineCore_DP0 pid=387806) 	@%p3 st.shared.b32 [ %r46 + 0 ], %r47;
(EngineCore_DP0 pid=387806) 	// end inline asm
(EngineCore_DP0 pid=387806) 	bar.sync 	0;
(EngineCore_DP0 pid=387806) 	// begin inline asm
(EngineCore_DP0 pid=387806) 	@%p4 ld.shared.b32 %r48, [ %r49 + 0 ];
(EngineCore_DP0 pid=387806) 	// end inline asm
(EngineCore_DP0 pid=387806) 	shfl.sync.bfly.b32 	%r63, %r48, 8, 31, -1;
(EngineCore_DP0 pid=387806) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=387806) 	max.f32 	%r64, %r48, %r63;
(EngineCore_DP0 pid=387806) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=387806) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=387806) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=387806) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=387806) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=387806) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=387806) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=387806) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=387806) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=387806) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=387806) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=387806) 	max.f32 	%r51, %r68, %r69;
(EngineCore_DP0 pid=387806) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=387806) 	// begin inline asm
(EngineCore_DP0 pid=387806) 	@%p19 st.shared.b32 [ %r49 + 0 ], %r51;
(EngineCore_DP0 pid=387806) 	// end inline asm
(EngineCore_DP0 pid=387806) 	bar.sync 	0;
(EngineCore_DP0 pid=387806) 	ld.shared.b32 	%r70, [global_smem];
(EngineCore_DP0 pid=387806) $L__tmp2:
(EngineCore_DP0 pid=387806) 	.loc	1 205 36                        // quant_slide_tuned_Llama3.2-3B.py:205:36
(EngineCore_DP0 pid=387806) 	max.f32 	%r107, %r107, %r70;
(EngineCore_DP0 pid=387806) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=387806) 	add.s32 	%r108, %r108, 4096;
(EngineCore_DP0 pid=387806) 	setp.lt.s32 	%p6, %r108, %r21;
(EngineCore_DP0 pid=387806) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=387806) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=387806) 	.loc	1 207 32                        // quant_slide_tuned_Llama3.2-3B.py:207:32
(EngineCore_DP0 pid=387806) 	max.f32 	%r109, %r107, 0f2B8CBCCC;
(EngineCore_DP0 pid=387806) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=387806) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-3B.py:0:32
(EngineCore_DP0 pid=387806) 	mov.b32 	%r72, 0f43E00000;
(EngineCore_DP0 pid=387806) 	.loc	1 208 32                        // quant_slide_tuned_Llama3.2-3B.py:208:32
(EngineCore_DP0 pid=387806) 	div.full.f32 	%r73, %r109, %r72;
(EngineCore_DP0 pid=387806) 	.loc	1 208 41                        // quant_slide_tuned_Llama3.2-3B.py:208:41
(EngineCore_DP0 pid=387806) 	max.f32 	%r71, %r73, 0f36924925;
(EngineCore_DP0 pid=387806) 	.loc	1 210 25                        // quant_slide_tuned_Llama3.2-3B.py:210:25
(EngineCore_DP0 pid=387806) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=387806) 	.loc	1 210 30                        // quant_slide_tuned_Llama3.2-3B.py:210:30
(EngineCore_DP0 pid=387806) 	// begin inline asm
(EngineCore_DP0 pid=387806) 	@%p19 st.global.b32 [ %rd7 + 0 ], { %r71 };
(EngineCore_DP0 pid=387806) 	// end inline asm
(EngineCore_DP0 pid=387806) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=387806) 	setp.lt.s32 	%p8, %r22, 1;
(EngineCore_DP0 pid=387806) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=387806) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=387806) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-3B.py:0:41
(EngineCore_DP0 pid=387806) 	ld.param.b32 	%r26, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=387806) 	shr.s32 	%r27, %r26, 31;
(EngineCore_DP0 pid=387806) 	shr.u32 	%r28, %r27, 30;
(EngineCore_DP0 pid=387806) 	add.s32 	%r29, %r26, %r28;
(EngineCore_DP0 pid=387806) 	shr.s32 	%r30, %r29, 2;
(EngineCore_DP0 pid=387806) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=387806) 	mul.lo.s32 	%r31, %r30, %r1;
(EngineCore_DP0 pid=387806) 	mad.wide.s32 	%rd2, %r31, 4, %rd5;
(EngineCore_DP0 pid=387806) 	div.full.f32 	%r14, %r72, %r109;
(EngineCore_DP0 pid=387806) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=387806) 	shl.b32 	%r110, %r3, 2;
(EngineCore_DP0 pid=387806) 	mov.b32 	%r111, 0;
(EngineCore_DP0 pid=387806) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=387806)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=387806) 	.loc	1 217 30                        // quant_slide_tuned_Llama3.2-3B.py:217:30
(EngineCore_DP0 pid=387806) 	add.s32 	%r84, %r3, %r111;
(EngineCore_DP0 pid=387806) 	setp.lt.s32 	%p13, %r84, %r22;
(EngineCore_DP0 pid=387806) 	.loc	1 225 53                        // quant_slide_tuned_Llama3.2-3B.py:225:53
(EngineCore_DP0 pid=387806) 	setp.lt.s32 	%p14, %r110, %r20;
(EngineCore_DP0 pid=387806) 	.loc	1 225 37                        // quant_slide_tuned_Llama3.2-3B.py:225:37
(EngineCore_DP0 pid=387806) 	and.pred 	%p9, %p13, %p14;
(EngineCore_DP0 pid=387806) 	.loc	1 224 29                        // quant_slide_tuned_Llama3.2-3B.py:224:29
(EngineCore_DP0 pid=387806) 	mad.wide.s32 	%rd8, %r110, 2, %rd1;
(EngineCore_DP0 pid=387806) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=387806) 	.loc	1 224 21                        // quant_slide_tuned_Llama3.2-3B.py:224:21
(EngineCore_DP0 pid=387806) 	// begin inline asm
(EngineCore_DP0 pid=387806) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=387806) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=387806) 	// end inline asm
(EngineCore_DP0 pid=387806) 	.loc	1 225 79                        // quant_slide_tuned_Llama3.2-3B.py:225:79
(EngineCore_DP0 pid=387806) 	cvt.f32.bf16 	%r85, %rs24;
(EngineCore_DP0 pid=387806) 	.loc	1 227 53                        // quant_slide_tuned_Llama3.2-3B.py:227:53
(EngineCore_DP0 pid=387806) 	add.s32 	%r86, %r110, 1;
(EngineCore_DP0 pid=387806) 	setp.lt.s32 	%p15, %r86, %r20;
(EngineCore_DP0 pid=387806) 	.loc	1 227 37                        // quant_slide_tuned_Llama3.2-3B.py:227:37
(EngineCore_DP0 pid=387806) 	and.pred 	%p10, %p13, %p15;
(EngineCore_DP0 pid=387806) 	.loc	1 226 39                        // quant_slide_tuned_Llama3.2-3B.py:226:39
(EngineCore_DP0 pid=387806) 	add.s64 	%rd9, %rd8, 2;
(EngineCore_DP0 pid=387806) 	.loc	1 226 21                        // quant_slide_tuned_Llama3.2-3B.py:226:21
(EngineCore_DP0 pid=387806) 	// begin inline asm
(EngineCore_DP0 pid=387806) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=387806) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=387806) 	// end inline asm
(EngineCore_DP0 pid=387806) 	.loc	1 227 79                        // quant_slide_tuned_Llama3.2-3B.py:227:79
(EngineCore_DP0 pid=387806) 	cvt.f32.bf16 	%r87, %rs26;
(EngineCore_DP0 pid=387806) 	.loc	1 229 53                        // quant_slide_tuned_Llama3.2-3B.py:229:53
(EngineCore_DP0 pid=387806) 	add.s32 	%r88, %r110, 2;
(EngineCore_DP0 pid=387806) 	setp.lt.s32 	%p16, %r88, %r20;
(EngineCore_DP0 pid=387806) 	.loc	1 229 37                        // quant_slide_tuned_Llama3.2-3B.py:229:37
(EngineCore_DP0 pid=387806) 	and.pred 	%p11, %p13, %p16;
(EngineCore_DP0 pid=387806) 	.loc	1 228 39                        // quant_slide_tuned_Llama3.2-3B.py:228:39
(EngineCore_DP0 pid=387806) 	add.s64 	%rd10, %rd8, 4;
(EngineCore_DP0 pid=387806) 	.loc	1 228 21                        // quant_slide_tuned_Llama3.2-3B.py:228:21
(EngineCore_DP0 pid=387806) 	// begin inline asm
(EngineCore_DP0 pid=387806) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=387806) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=387806) 	// end inline asm
(EngineCore_DP0 pid=387806) 	.loc	1 229 79                        // quant_slide_tuned_Llama3.2-3B.py:229:79
(EngineCore_DP0 pid=387806) 	cvt.f32.bf16 	%r89, %rs28;
(EngineCore_DP0 pid=387806) 	.loc	1 231 53                        // quant_slide_tuned_Llama3.2-3B.py:231:53
(EngineCore_DP0 pid=387806) 	add.s32 	%r90, %r110, 3;
(EngineCore_DP0 pid=387806) 	setp.lt.s32 	%p17, %r90, %r20;
(EngineCore_DP0 pid=387806) 	.loc	1 231 37                        // quant_slide_tuned_Llama3.2-3B.py:231:37
(EngineCore_DP0 pid=387806) 	and.pred 	%p12, %p13, %p17;
(EngineCore_DP0 pid=387806) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-3B.py:230:39
(EngineCore_DP0 pid=387806) 	add.s64 	%rd11, %rd8, 6;
(EngineCore_DP0 pid=387806) 	.loc	1 230 21                        // quant_slide_tuned_Llama3.2-3B.py:230:21
(EngineCore_DP0 pid=387806) 	// begin inline asm
(EngineCore_DP0 pid=387806) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=387806) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=387806) 	// end inline asm
(EngineCore_DP0 pid=387806) 	.loc	1 231 79                        // quant_slide_tuned_Llama3.2-3B.py:231:79
(EngineCore_DP0 pid=387806) 	cvt.f32.bf16 	%r91, %rs30;
(EngineCore_DP0 pid=387806) 	.loc	1 233 27                        // quant_slide_tuned_Llama3.2-3B.py:233:27
(EngineCore_DP0 pid=387806) 	mul.f32 	%r92, %r14, %r85;
(EngineCore_DP0 pid=387806) 	mov.b32 	%r93, 0f43E00000;
(EngineCore_DP0 pid=387806) 	.loc	1 233 48                        // quant_slide_tuned_Llama3.2-3B.py:233:48
(EngineCore_DP0 pid=387806) 	min.xorsign.abs.f32 	%r75, %r92, %r93;
(EngineCore_DP0 pid=387806) 	.loc	1 233 60                        // quant_slide_tuned_Llama3.2-3B.py:233:60
(EngineCore_DP0 pid=387806) 	// begin inline asm
(EngineCore_DP0 pid=387806) 	cvt.rn.satfinite.e4m3x2.f32  %rs32, %r76, %r75; 
(EngineCore_DP0 pid=387806) 
(EngineCore_DP0 pid=387806) 	// end inline asm
(EngineCore_DP0 pid=387806) 	.loc	1 234 27                        // quant_slide_tuned_Llama3.2-3B.py:234:27
(EngineCore_DP0 pid=387806) 	mul.f32 	%r94, %r14, %r87;
(EngineCore_DP0 pid=387806) 	.loc	1 234 48                        // quant_slide_tuned_Llama3.2-3B.py:234:48
(EngineCore_DP0 pid=387806) 	min.xorsign.abs.f32 	%r77, %r94, %r93;
(EngineCore_DP0 pid=387806) 	.loc	1 234 60                        // quant_slide_tuned_Llama3.2-3B.py:234:60
(EngineCore_DP0 pid=387806) 	// begin inline asm
(EngineCore_DP0 pid=387806) 	cvt.rn.satfinite.e4m3x2.f32  %rs33, %r78, %r77; 
(EngineCore_DP0 pid=387806) 
(EngineCore_DP0 pid=387806) 	// end inline asm
(EngineCore_DP0 pid=387806) 	.loc	1 235 27                        // quant_slide_tuned_Llama3.2-3B.py:235:27
(EngineCore_DP0 pid=387806) 	mul.f32 	%r95, %r14, %r89;
(EngineCore_DP0 pid=387806) 	.loc	1 235 48                        // quant_slide_tuned_Llama3.2-3B.py:235:48
(EngineCore_DP0 pid=387806) 	min.xorsign.abs.f32 	%r79, %r95, %r93;
(EngineCore_DP0 pid=387806) 	.loc	1 235 60                        // quant_slide_tuned_Llama3.2-3B.py:235:60
(EngineCore_DP0 pid=387806) 	// begin inline asm
(EngineCore_DP0 pid=387806) 	cvt.rn.satfinite.e4m3x2.f32  %rs34, %r80, %r79; 
(EngineCore_DP0 pid=387806) 
(EngineCore_DP0 pid=387806) 	// end inline asm
(EngineCore_DP0 pid=387806) 	.loc	1 236 27                        // quant_slide_tuned_Llama3.2-3B.py:236:27
(EngineCore_DP0 pid=387806) 	mul.f32 	%r96, %r14, %r91;
(EngineCore_DP0 pid=387806) 	.loc	1 236 48                        // quant_slide_tuned_Llama3.2-3B.py:236:48
(EngineCore_DP0 pid=387806) 	min.xorsign.abs.f32 	%r81, %r96, %r93;
(EngineCore_DP0 pid=387806) 	.loc	1 236 60                        // quant_slide_tuned_Llama3.2-3B.py:236:60
(EngineCore_DP0 pid=387806) 	// begin inline asm
(EngineCore_DP0 pid=387806) 	cvt.rn.satfinite.e4m3x2.f32  %rs35, %r82, %r81; 
(EngineCore_DP0 pid=387806) 
(EngineCore_DP0 pid=387806) 	// end inline asm
(EngineCore_DP0 pid=387806) 	.loc	1 238 45                        // quant_slide_tuned_Llama3.2-3B.py:238:45
(EngineCore_DP0 pid=387806) 	cvt.u32.u16 	%r97, %rs32;
(EngineCore_DP0 pid=387806) 	and.b32 	%r98, %r97, 255;
(EngineCore_DP0 pid=387806) 	.loc	1 240 45                        // quant_slide_tuned_Llama3.2-3B.py:240:45
(EngineCore_DP0 pid=387806) 	cvt.u32.u16 	%r99, %rs34;
(EngineCore_DP0 pid=387806) 	and.b32 	%r100, %r99, 255;
(EngineCore_DP0 pid=387806) 	.loc	1 241 45                        // quant_slide_tuned_Llama3.2-3B.py:241:45
(EngineCore_DP0 pid=387806) 	cvt.u32.u16 	%r101, %rs35;
(EngineCore_DP0 pid=387806) 	.loc	1 243 30                        // quant_slide_tuned_Llama3.2-3B.py:243:30
(EngineCore_DP0 pid=387806) 	and.b16 	%rs36, %rs33, 255;
(EngineCore_DP0 pid=387806) 	mul.wide.u16 	%r102, %rs36, 256;
(EngineCore_DP0 pid=387806) 	.loc	1 243 24                        // quant_slide_tuned_Llama3.2-3B.py:243:24
(EngineCore_DP0 pid=387806) 	or.b32 	%r103, %r102, %r98;
(EngineCore_DP0 pid=387806) 	.loc	1 243 42                        // quant_slide_tuned_Llama3.2-3B.py:243:42
(EngineCore_DP0 pid=387806) 	shl.b32 	%r104, %r100, 16;
(EngineCore_DP0 pid=387806) 	.loc	1 243 36                        // quant_slide_tuned_Llama3.2-3B.py:243:36
(EngineCore_DP0 pid=387806) 	or.b32 	%r105, %r103, %r104;
(EngineCore_DP0 pid=387806) 	.loc	1 243 55                        // quant_slide_tuned_Llama3.2-3B.py:243:55
(EngineCore_DP0 pid=387806) 	shl.b32 	%r106, %r101, 24;
(EngineCore_DP0 pid=387806) 	.loc	1 243 49                        // quant_slide_tuned_Llama3.2-3B.py:243:49
(EngineCore_DP0 pid=387806) 	or.b32 	%r83, %r105, %r106;
(EngineCore_DP0 pid=387806) 	.loc	1 244 29                        // quant_slide_tuned_Llama3.2-3B.py:244:29
(EngineCore_DP0 pid=387806) 	mad.wide.s32 	%rd12, %r84, 4, %rd2;
(EngineCore_DP0 pid=387806) 	.loc	1 244 39                        // quant_slide_tuned_Llama3.2-3B.py:244:39
(EngineCore_DP0 pid=387806) 	// begin inline asm
(EngineCore_DP0 pid=387806) 	@%p13 st.global.b32 [ %rd12 + 0 ], { %r83 };
(EngineCore_DP0 pid=387806) 	// end inline asm
(EngineCore_DP0 pid=387806) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=387806) 	add.s32 	%r111, %r111, 512;
(EngineCore_DP0 pid=387806) 	add.s32 	%r110, %r110, 2048;
(EngineCore_DP0 pid=387806) 	setp.lt.s32 	%p18, %r111, %r22;
(EngineCore_DP0 pid=387806) 	@%p18 bra 	$L__BB0_6;
(EngineCore_DP0 pid=387806) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=387806) 	.loc	1 215 4                         // quant_slide_tuned_Llama3.2-3B.py:215:4
(EngineCore_DP0 pid=387806) 	ret;
(EngineCore_DP0 pid=387806) $L__tmp3:
(EngineCore_DP0 pid=387806) $L__func_end0:
(EngineCore_DP0 pid=387806)                                         // -- End function
(EngineCore_DP0 pid=387806) }
(EngineCore_DP0 pid=387806) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py"
(EngineCore_DP0 pid=387806) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=387806) 	.section	.debug_abbrev
(EngineCore_DP0 pid=387806) 	{
(EngineCore_DP0 pid=387806) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=387806) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=387806) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=387806) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=387806) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=387806) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=387806) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=387806) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=387806) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=387806) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=387806) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=387806) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=387806) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=387806) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=387806) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=387806) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=387806) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=387806) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=387806) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=387806) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=387806) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=387806) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=387806) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=387806) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=387806) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=387806) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=387806) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=387806) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=387806) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=387806) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=387806) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=387806) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=387806) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=387806) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=387806) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=387806) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=387806) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=387806) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=387806) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=387806) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=387806) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=387806) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=387806) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=387806) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=387806) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=387806) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=387806) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=387806) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=387806) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=387806) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=387806) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=387806) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=387806) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=387806) 	}
(EngineCore_DP0 pid=387806) 	.section	.debug_info
(EngineCore_DP0 pid=387806) 	{
(EngineCore_DP0 pid=387806) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=387806) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=387806) .b8 0
(EngineCore_DP0 pid=387806) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=387806) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=387806) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=387806) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=387806) .b8 114
(EngineCore_DP0 pid=387806) .b8 105
(EngineCore_DP0 pid=387806) .b8 116
(EngineCore_DP0 pid=387806) .b8 111
(EngineCore_DP0 pid=387806) .b8 110
(EngineCore_DP0 pid=387806) .b8 0
(EngineCore_DP0 pid=387806) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=387806) .b8 0
(EngineCore_DP0 pid=387806) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=387806) .b8 117
(EngineCore_DP0 pid=387806) .b8 97
(EngineCore_DP0 pid=387806) .b8 110
(EngineCore_DP0 pid=387806) .b8 116
(EngineCore_DP0 pid=387806) .b8 95
(EngineCore_DP0 pid=387806) .b8 115
(EngineCore_DP0 pid=387806) .b8 108
(EngineCore_DP0 pid=387806) .b8 105
(EngineCore_DP0 pid=387806) .b8 100
(EngineCore_DP0 pid=387806) .b8 101
(EngineCore_DP0 pid=387806) .b8 95
(EngineCore_DP0 pid=387806) .b8 116
(EngineCore_DP0 pid=387806) .b8 117
(EngineCore_DP0 pid=387806) .b8 110
(EngineCore_DP0 pid=387806) .b8 101
(EngineCore_DP0 pid=387806) .b8 100
(EngineCore_DP0 pid=387806) .b8 95
(EngineCore_DP0 pid=387806) .b8 76
(EngineCore_DP0 pid=387806) .b8 108
(EngineCore_DP0 pid=387806) .b8 97
(EngineCore_DP0 pid=387806) .b8 109
(EngineCore_DP0 pid=387806) .b8 97
(EngineCore_DP0 pid=387806) .b8 51
(EngineCore_DP0 pid=387806) .b8 46
(EngineCore_DP0 pid=387806) .b8 50
(EngineCore_DP0 pid=387806) .b8 45
(EngineCore_DP0 pid=387806) .b8 51
(EngineCore_DP0 pid=387806) .b8 66
(EngineCore_DP0 pid=387806) .b8 46
(EngineCore_DP0 pid=387806) .b8 112
(EngineCore_DP0 pid=387806) .b8 121
(EngineCore_DP0 pid=387806) .b8 0
(EngineCore_DP0 pid=387806) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=387806) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=387806) .b8 114
(EngineCore_DP0 pid=387806) .b8 111
(EngineCore_DP0 pid=387806) .b8 111
(EngineCore_DP0 pid=387806) .b8 116
(EngineCore_DP0 pid=387806) .b8 47
(EngineCore_DP0 pid=387806) .b8 118
(EngineCore_DP0 pid=387806) .b8 108
(EngineCore_DP0 pid=387806) .b8 108
(EngineCore_DP0 pid=387806) .b8 109
(EngineCore_DP0 pid=387806) .b8 98
(EngineCore_DP0 pid=387806) .b8 101
(EngineCore_DP0 pid=387806) .b8 110
(EngineCore_DP0 pid=387806) .b8 99
(EngineCore_DP0 pid=387806) .b8 104
(EngineCore_DP0 pid=387806) .b8 47
(EngineCore_DP0 pid=387806) .b8 115
(EngineCore_DP0 pid=387806) .b8 108
(EngineCore_DP0 pid=387806) .b8 105
(EngineCore_DP0 pid=387806) .b8 100
(EngineCore_DP0 pid=387806) .b8 101
(EngineCore_DP0 pid=387806) .b8 115
(EngineCore_DP0 pid=387806) .b8 112
(EngineCore_DP0 pid=387806) .b8 97
(EngineCore_DP0 pid=387806) .b8 114
(EngineCore_DP0 pid=387806) .b8 115
(EngineCore_DP0 pid=387806) .b8 101
(EngineCore_DP0 pid=387806) .b8 47
(EngineCore_DP0 pid=387806) .b8 99
(EngineCore_DP0 pid=387806) .b8 115
(EngineCore_DP0 pid=387806) .b8 114
(EngineCore_DP0 pid=387806) .b8 99
(EngineCore_DP0 pid=387806) .b8 47
(EngineCore_DP0 pid=387806) .b8 102
(EngineCore_DP0 pid=387806) .b8 117
(EngineCore_DP0 pid=387806) .b8 115
(EngineCore_DP0 pid=387806) .b8 101
(EngineCore_DP0 pid=387806) .b8 100
(EngineCore_DP0 pid=387806) .b8 95
(EngineCore_DP0 pid=387806) .b8 113
(EngineCore_DP0 pid=387806) .b8 117
(EngineCore_DP0 pid=387806) .b8 97
(EngineCore_DP0 pid=387806) .b8 110
(EngineCore_DP0 pid=387806) .b8 116
(EngineCore_DP0 pid=387806) .b8 95
(EngineCore_DP0 pid=387806) .b8 115
(EngineCore_DP0 pid=387806) .b8 108
(EngineCore_DP0 pid=387806) .b8 105
(EngineCore_DP0 pid=387806) .b8 100
(EngineCore_DP0 pid=387806) .b8 101
(EngineCore_DP0 pid=387806) .b8 95
(EngineCore_DP0 pid=387806) .b8 116
(EngineCore_DP0 pid=387806) .b8 114
(EngineCore_DP0 pid=387806) .b8 105
(EngineCore_DP0 pid=387806) .b8 116
(EngineCore_DP0 pid=387806) .b8 111
(EngineCore_DP0 pid=387806) .b8 110
(EngineCore_DP0 pid=387806) .b8 47
(EngineCore_DP0 pid=387806) .b8 98
(EngineCore_DP0 pid=387806) .b8 117
(EngineCore_DP0 pid=387806) .b8 105
(EngineCore_DP0 pid=387806) .b8 108
(EngineCore_DP0 pid=387806) .b8 100
(EngineCore_DP0 pid=387806) .b8 47
(EngineCore_DP0 pid=387806) .b8 71
(EngineCore_DP0 pid=387806) .b8 66
(EngineCore_DP0 pid=387806) .b8 49
(EngineCore_DP0 pid=387806) .b8 48
(EngineCore_DP0 pid=387806) .b8 95
(EngineCore_DP0 pid=387806) .b8 99
(EngineCore_DP0 pid=387806) .b8 99
(EngineCore_DP0 pid=387806) .b8 49
(EngineCore_DP0 pid=387806) .b8 50
(EngineCore_DP0 pid=387806) .b8 49
(EngineCore_DP0 pid=387806) .b8 95
(EngineCore_DP0 pid=387806) .b8 112
(EngineCore_DP0 pid=387806) .b8 121
(EngineCore_DP0 pid=387806) .b8 51
(EngineCore_DP0 pid=387806) .b8 49
(EngineCore_DP0 pid=387806) .b8 50
(EngineCore_DP0 pid=387806) .b8 95
(EngineCore_DP0 pid=387806) .b8 99
(EngineCore_DP0 pid=387806) .b8 117
(EngineCore_DP0 pid=387806) .b8 49
(EngineCore_DP0 pid=387806) .b8 50
(EngineCore_DP0 pid=387806) .b8 57
(EngineCore_DP0 pid=387806) .b8 95
(EngineCore_DP0 pid=387806) .b8 97
(EngineCore_DP0 pid=387806) .b8 97
(EngineCore_DP0 pid=387806) .b8 114
(EngineCore_DP0 pid=387806) .b8 99
(EngineCore_DP0 pid=387806) .b8 104
(EngineCore_DP0 pid=387806) .b8 54
(EngineCore_DP0 pid=387806) .b8 52
(EngineCore_DP0 pid=387806) .b8 0
(EngineCore_DP0 pid=387806) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=387806) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=387806) .b8 113
(EngineCore_DP0 pid=387806) .b8 117
(EngineCore_DP0 pid=387806) .b8 97
(EngineCore_DP0 pid=387806) .b8 110
(EngineCore_DP0 pid=387806) .b8 116
(EngineCore_DP0 pid=387806) .b8 95
(EngineCore_DP0 pid=387806) .b8 115
(EngineCore_DP0 pid=387806) .b8 108
(EngineCore_DP0 pid=387806) .b8 105
(EngineCore_DP0 pid=387806) .b8 100
(EngineCore_DP0 pid=387806) .b8 101
(EngineCore_DP0 pid=387806) .b8 95
(EngineCore_DP0 pid=387806) .b8 102
(EngineCore_DP0 pid=387806) .b8 112
(EngineCore_DP0 pid=387806) .b8 56
(EngineCore_DP0 pid=387806) .b8 95
(EngineCore_DP0 pid=387806) .b8 107
(EngineCore_DP0 pid=387806) .b8 101
(EngineCore_DP0 pid=387806) .b8 114
(EngineCore_DP0 pid=387806) .b8 110
(EngineCore_DP0 pid=387806) .b8 101
(EngineCore_DP0 pid=387806) .b8 108
(EngineCore_DP0 pid=387806) .b8 0
(EngineCore_DP0 pid=387806) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=387806) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=387806) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=387806) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=387806) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=387806) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=387806) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=387806) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=387806) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=387806) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=387806) .b8 205                                 // DW_AT_call_line
(EngineCore_DP0 pid=387806) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=387806) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=387806) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=387806) 	}
(EngineCore_DP0 pid=387806) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=387806) 
(EngineCore_DP0 pid=387806) ================================================================
(EngineCore_DP0 pid=387806) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=387806) 
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmphb0sjptm.ptx', '-o', '/tmp/tmphb0sjptm.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866] 
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866] 
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866] 
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmphb0sjptm.ptx -o /tmp/tmphb0sjptm.ptx.o
(EngineCore_DP0 pid=387806) ERROR 01-25 20:00:47 [core.py:866] 

STDERR:
[2026-01-25 20:00:26] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:00:26] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:00:26] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:00:26] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:00:26] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:00:26] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:00:26] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:00:26] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:00:26] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:00:26] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:00:26] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:00:26] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:00:26] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:00:26] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:00:29] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:00:29] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:00:29] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:00:29] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:00:29] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:00:29] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:00:29] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:00:29] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:00:29] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:00:29] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:00:29] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:00:29] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:00:29] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:00:29] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=387806) [2026-01-25 20:00:30] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=387806) [2026-01-25 20:00:30] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=387806) [2026-01-25 20:00:30] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=387806) [2026-01-25 20:00:30] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=387806) [2026-01-25 20:00:30] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=387806) [2026-01-25 20:00:30] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=387806) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=387806) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:15<00:00, 15.66s/it]
(EngineCore_DP0 pid=387806) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:15<00:00, 15.66s/it]
(EngineCore_DP0 pid=387806) 
(EngineCore_DP0 pid=387806) [2026-01-25 20:00:47] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 3072] -> 1D uint8
(EngineCore_DP0 pid=387806) [2026-01-25 20:00:47] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9830400 bytes
(EngineCore_DP0 pid=387806) [2026-01-25 20:00:47] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=387806) [2026-01-25 20:00:47] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5898240 bytes
(EngineCore_DP0 pid=387806) [2026-01-25 20:00:47] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=387806) [2026-01-25 20:00:47] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 31457280 bytes
(EngineCore_DP0 pid=387806) [2026-01-25 20:00:47] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 8192] -> 1D uint8
(EngineCore_DP0 pid=387806) [2026-01-25 20:00:47] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15728640 bytes
(EngineCore_DP0 pid=387806) Process EngineCore_DP0:
(EngineCore_DP0 pid=387806) Traceback (most recent call last):
(EngineCore_DP0 pid=387806)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=387806)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=387806)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=387806)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=387806) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmphb0sjptm.ptx', '-o', '/tmp/tmphb0sjptm.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=387806) 
(EngineCore_DP0 pid=387806) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=387806) 
(EngineCore_DP0 pid=387806) Traceback (most recent call last):
(EngineCore_DP0 pid=387806)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=387806)     self.run()
(EngineCore_DP0 pid=387806)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=387806)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=387806)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=387806)     raise e
(EngineCore_DP0 pid=387806)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=387806)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=387806)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=387806)     super().__init__(
(EngineCore_DP0 pid=387806)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=387806)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=387806)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=387806)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=387806)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=387806)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=387806)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=387806)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=387806)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=387806)     return func(*args, **kwargs)
(EngineCore_DP0 pid=387806)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=387806)     return func(*args, **kwargs)
(EngineCore_DP0 pid=387806)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=387806)     self.model_runner.profile_run()
(EngineCore_DP0 pid=387806)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=387806)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=387806)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=387806)     return func(*args, **kwargs)
(EngineCore_DP0 pid=387806)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=387806)     outputs = self.model(
(EngineCore_DP0 pid=387806)               ^^^^^^^^^^^
(EngineCore_DP0 pid=387806)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=387806)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=387806)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=387806)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=387806)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=387806)     model_output = self.model(
(EngineCore_DP0 pid=387806)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=387806)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=387806)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=387806)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=387806)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=387806)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=387806)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=387806)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=387806)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=387806)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=387806)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=387806)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=387806)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=387806)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=387806)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=387806)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=387806)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=387806)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=387806)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=387806)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=387806)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=387806)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=387806)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=387806)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=387806)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=387806)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=387806)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=387806)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=387806)     return self._linear_fn(
(EngineCore_DP0 pid=387806)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=387806)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=387806)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=387806)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=387806)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=387806)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=387806)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=387806)     return fn(input, L)
(EngineCore_DP0 pid=387806)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=387806)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=387806)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=387806)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=387806)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=387806)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=387806)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=387806)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=387806)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=387806)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=387806)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=387806)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=387806)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=387806)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=387806)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=387806)     raise PTXASError(error)
(EngineCore_DP0 pid=387806) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=387806) `ptxas` stderr:
(EngineCore_DP0 pid=387806) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=387806) 
(EngineCore_DP0 pid=387806) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmphb0sjptm.ptx -o /tmp/tmphb0sjptm.ptx.o
(EngineCore_DP0 pid=387806) 
[rank0]:[W125 20:00:48.419847422 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=1024

========== M=2048 ==========
Time: 2026-01-25 20:00:49
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Llama3.2-3B-FP8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:00:54 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 20:00:54 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=388373) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=388373) 
(EngineCore_DP0 pid=388373) 
(EngineCore_DP0 pid=388373) ================================================================
(EngineCore_DP0 pid=388373) Internal Triton PTX codegen error
(EngineCore_DP0 pid=388373) `ptxas` stderr:
(EngineCore_DP0 pid=388373) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=388373) 
(EngineCore_DP0 pid=388373) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpxg0o7vx2.ptx -o /tmp/tmpxg0o7vx2.ptx.o
(EngineCore_DP0 pid=388373) 
(EngineCore_DP0 pid=388373) 
(EngineCore_DP0 pid=388373) //
(EngineCore_DP0 pid=388373) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=388373) //
(EngineCore_DP0 pid=388373) 
(EngineCore_DP0 pid=388373) .version 8.7
(EngineCore_DP0 pid=388373) .target sm_121a
(EngineCore_DP0 pid=388373) .address_size 64
(EngineCore_DP0 pid=388373) 
(EngineCore_DP0 pid=388373) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=388373) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=388373)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=388373) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=388373) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=388373) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=388373) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=388373) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=388373) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=388373) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=388373) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=388373) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=388373) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=388373) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=388373) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=388373) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=388373) )
(EngineCore_DP0 pid=388373) .reqntid 512
(EngineCore_DP0 pid=388373) {
(EngineCore_DP0 pid=388373) 	.reg .pred 	%p<20>;
(EngineCore_DP0 pid=388373) 	.reg .b16 	%rs<37>;
(EngineCore_DP0 pid=388373) 	.reg .b32 	%r<112>;
(EngineCore_DP0 pid=388373) 	.reg .b64 	%rd<13>;
(EngineCore_DP0 pid=388373) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=388373) $L__func_begin0:
(EngineCore_DP0 pid=388373) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=388373) 
(EngineCore_DP0 pid=388373) // %bb.0:
(EngineCore_DP0 pid=388373) 	ld.param.b32 	%r22, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=388373) 	ld.param.b32 	%r21, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=388373) 	ld.param.b32 	%r20, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=388373) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=388373) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=388373) $L__tmp0:
(EngineCore_DP0 pid=388373) 	.loc	1 191 24                        // quant_slide_tuned_Llama3.2-3B.py:191:24
(EngineCore_DP0 pid=388373) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=388373) 	ld.param.b32 	%r24, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=388373) 	.loc	1 196 26                        // quant_slide_tuned_Llama3.2-3B.py:196:26
(EngineCore_DP0 pid=388373) 	mul.lo.s32 	%r25, %r24, %r1;
(EngineCore_DP0 pid=388373) 	.loc	1 196 20                        // quant_slide_tuned_Llama3.2-3B.py:196:20
(EngineCore_DP0 pid=388373) 	mad.wide.s32 	%rd1, %r25, 2, %rd4;
(EngineCore_DP0 pid=388373) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=388373) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=388373) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=388373) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=388373) 	setp.lt.s32 	%p1, %r21, 1;
(EngineCore_DP0 pid=388373) 	mov.b32 	%r109, 0f2B8CBCCC;
(EngineCore_DP0 pid=388373) 	setp.eq.b32 	%p19, %r2, 0;
(EngineCore_DP0 pid=388373) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=388373) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=388373) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=388373) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=388373) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=388373) 	shr.u32 	%r34, %r2, 3;
(EngineCore_DP0 pid=388373) 	and.b32 	%r35, %r34, 60;
(EngineCore_DP0 pid=388373) 	mov.b32 	%r36, global_smem;
(EngineCore_DP0 pid=388373) 	add.s32 	%r46, %r36, %r35;
(EngineCore_DP0 pid=388373) 	shl.b32 	%r37, %r2, 2;
(EngineCore_DP0 pid=388373) 	add.s32 	%r49, %r36, %r37;
(EngineCore_DP0 pid=388373) 	mov.b32 	%r42, 0;
(EngineCore_DP0 pid=388373) 	mov.b32 	%r107, 0f00000000;
(EngineCore_DP0 pid=388373) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=388373) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=388373) 	mov.b32 	%r108, %r42;
(EngineCore_DP0 pid=388373) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=388373) 	.loc	1 203 22                        // quant_slide_tuned_Llama3.2-3B.py:203:22
(EngineCore_DP0 pid=388373) 	add.s32 	%r52, %r4, %r108;
(EngineCore_DP0 pid=388373) 	setp.lt.s32 	%p2, %r52, %r20;
(EngineCore_DP0 pid=388373) 	.loc	1 204 29                        // quant_slide_tuned_Llama3.2-3B.py:204:29
(EngineCore_DP0 pid=388373) 	mad.wide.s32 	%rd6, %r52, 2, %rd1;
(EngineCore_DP0 pid=388373) 	.loc	1 204 21                        // quant_slide_tuned_Llama3.2-3B.py:204:21
(EngineCore_DP0 pid=388373) 	// begin inline asm
(EngineCore_DP0 pid=388373) 	mov.u32 %r38, %r42;
(EngineCore_DP0 pid=388373) 	mov.u32 %r39, %r42;
(EngineCore_DP0 pid=388373) 	mov.u32 %r40, %r42;
(EngineCore_DP0 pid=388373) 	mov.u32 %r41, %r42;
(EngineCore_DP0 pid=388373) 	@%p2 ld.global.v4.b32 { %r38, %r39, %r40, %r41 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=388373) 	// end inline asm
(EngineCore_DP0 pid=388373) 	mov.b32 	{%rs1, %rs2}, %r38;
(EngineCore_DP0 pid=388373) 	mov.b32 	{%rs3, %rs4}, %r39;
(EngineCore_DP0 pid=388373) 	mov.b32 	{%rs5, %rs6}, %r40;
(EngineCore_DP0 pid=388373) 	mov.b32 	{%rs7, %rs8}, %r41;
(EngineCore_DP0 pid=388373) 	.loc	1 205 50                        // quant_slide_tuned_Llama3.2-3B.py:205:50
(EngineCore_DP0 pid=388373) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=388373) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=388373) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=388373) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=388373) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=388373) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=388373) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=388373) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=388373) $L__tmp1:
(EngineCore_DP0 pid=388373) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=388373) 	bar.sync 	0;
(EngineCore_DP0 pid=388373) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=388373) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=388373) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=388373) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=388373) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=388373) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=388373) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=388373) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=388373) 	cvt.f32.bf16 	%r53, %rs23;
(EngineCore_DP0 pid=388373) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=388373) 	shfl.sync.bfly.b32 	%r54, %r53, 16, 31, -1;
(EngineCore_DP0 pid=388373) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=388373) 	max.f32 	%r55, %r53, %r54;
(EngineCore_DP0 pid=388373) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=388373) 	shfl.sync.bfly.b32 	%r56, %r55, 8, 31, -1;
(EngineCore_DP0 pid=388373) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=388373) 	max.f32 	%r57, %r55, %r56;
(EngineCore_DP0 pid=388373) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=388373) 	shfl.sync.bfly.b32 	%r58, %r57, 4, 31, -1;
(EngineCore_DP0 pid=388373) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=388373) 	max.f32 	%r59, %r57, %r58;
(EngineCore_DP0 pid=388373) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=388373) 	shfl.sync.bfly.b32 	%r60, %r59, 2, 31, -1;
(EngineCore_DP0 pid=388373) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=388373) 	max.f32 	%r61, %r59, %r60;
(EngineCore_DP0 pid=388373) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=388373) 	shfl.sync.bfly.b32 	%r62, %r61, 1, 31, -1;
(EngineCore_DP0 pid=388373) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=388373) 	max.f32 	%r47, %r61, %r62;
(EngineCore_DP0 pid=388373) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=388373) 	// begin inline asm
(EngineCore_DP0 pid=388373) 	@%p3 st.shared.b32 [ %r46 + 0 ], %r47;
(EngineCore_DP0 pid=388373) 	// end inline asm
(EngineCore_DP0 pid=388373) 	bar.sync 	0;
(EngineCore_DP0 pid=388373) 	// begin inline asm
(EngineCore_DP0 pid=388373) 	@%p4 ld.shared.b32 %r48, [ %r49 + 0 ];
(EngineCore_DP0 pid=388373) 	// end inline asm
(EngineCore_DP0 pid=388373) 	shfl.sync.bfly.b32 	%r63, %r48, 8, 31, -1;
(EngineCore_DP0 pid=388373) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=388373) 	max.f32 	%r64, %r48, %r63;
(EngineCore_DP0 pid=388373) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=388373) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=388373) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=388373) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=388373) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=388373) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=388373) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=388373) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=388373) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=388373) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=388373) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=388373) 	max.f32 	%r51, %r68, %r69;
(EngineCore_DP0 pid=388373) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=388373) 	// begin inline asm
(EngineCore_DP0 pid=388373) 	@%p19 st.shared.b32 [ %r49 + 0 ], %r51;
(EngineCore_DP0 pid=388373) 	// end inline asm
(EngineCore_DP0 pid=388373) 	bar.sync 	0;
(EngineCore_DP0 pid=388373) 	ld.shared.b32 	%r70, [global_smem];
(EngineCore_DP0 pid=388373) $L__tmp2:
(EngineCore_DP0 pid=388373) 	.loc	1 205 36                        // quant_slide_tuned_Llama3.2-3B.py:205:36
(EngineCore_DP0 pid=388373) 	max.f32 	%r107, %r107, %r70;
(EngineCore_DP0 pid=388373) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=388373) 	add.s32 	%r108, %r108, 4096;
(EngineCore_DP0 pid=388373) 	setp.lt.s32 	%p6, %r108, %r21;
(EngineCore_DP0 pid=388373) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=388373) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=388373) 	.loc	1 207 32                        // quant_slide_tuned_Llama3.2-3B.py:207:32
(EngineCore_DP0 pid=388373) 	max.f32 	%r109, %r107, 0f2B8CBCCC;
(EngineCore_DP0 pid=388373) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=388373) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-3B.py:0:32
(EngineCore_DP0 pid=388373) 	mov.b32 	%r72, 0f43E00000;
(EngineCore_DP0 pid=388373) 	.loc	1 208 32                        // quant_slide_tuned_Llama3.2-3B.py:208:32
(EngineCore_DP0 pid=388373) 	div.full.f32 	%r73, %r109, %r72;
(EngineCore_DP0 pid=388373) 	.loc	1 208 41                        // quant_slide_tuned_Llama3.2-3B.py:208:41
(EngineCore_DP0 pid=388373) 	max.f32 	%r71, %r73, 0f36924925;
(EngineCore_DP0 pid=388373) 	.loc	1 210 25                        // quant_slide_tuned_Llama3.2-3B.py:210:25
(EngineCore_DP0 pid=388373) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=388373) 	.loc	1 210 30                        // quant_slide_tuned_Llama3.2-3B.py:210:30
(EngineCore_DP0 pid=388373) 	// begin inline asm
(EngineCore_DP0 pid=388373) 	@%p19 st.global.b32 [ %rd7 + 0 ], { %r71 };
(EngineCore_DP0 pid=388373) 	// end inline asm
(EngineCore_DP0 pid=388373) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=388373) 	setp.lt.s32 	%p8, %r22, 1;
(EngineCore_DP0 pid=388373) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=388373) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=388373) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-3B.py:0:41
(EngineCore_DP0 pid=388373) 	ld.param.b32 	%r26, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=388373) 	shr.s32 	%r27, %r26, 31;
(EngineCore_DP0 pid=388373) 	shr.u32 	%r28, %r27, 30;
(EngineCore_DP0 pid=388373) 	add.s32 	%r29, %r26, %r28;
(EngineCore_DP0 pid=388373) 	shr.s32 	%r30, %r29, 2;
(EngineCore_DP0 pid=388373) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=388373) 	mul.lo.s32 	%r31, %r30, %r1;
(EngineCore_DP0 pid=388373) 	mad.wide.s32 	%rd2, %r31, 4, %rd5;
(EngineCore_DP0 pid=388373) 	div.full.f32 	%r14, %r72, %r109;
(EngineCore_DP0 pid=388373) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=388373) 	shl.b32 	%r110, %r3, 2;
(EngineCore_DP0 pid=388373) 	mov.b32 	%r111, 0;
(EngineCore_DP0 pid=388373) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=388373)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=388373) 	.loc	1 217 30                        // quant_slide_tuned_Llama3.2-3B.py:217:30
(EngineCore_DP0 pid=388373) 	add.s32 	%r84, %r3, %r111;
(EngineCore_DP0 pid=388373) 	setp.lt.s32 	%p13, %r84, %r22;
(EngineCore_DP0 pid=388373) 	.loc	1 225 53                        // quant_slide_tuned_Llama3.2-3B.py:225:53
(EngineCore_DP0 pid=388373) 	setp.lt.s32 	%p14, %r110, %r20;
(EngineCore_DP0 pid=388373) 	.loc	1 225 37                        // quant_slide_tuned_Llama3.2-3B.py:225:37
(EngineCore_DP0 pid=388373) 	and.pred 	%p9, %p13, %p14;
(EngineCore_DP0 pid=388373) 	.loc	1 224 29                        // quant_slide_tuned_Llama3.2-3B.py:224:29
(EngineCore_DP0 pid=388373) 	mad.wide.s32 	%rd8, %r110, 2, %rd1;
(EngineCore_DP0 pid=388373) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=388373) 	.loc	1 224 21                        // quant_slide_tuned_Llama3.2-3B.py:224:21
(EngineCore_DP0 pid=388373) 	// begin inline asm
(EngineCore_DP0 pid=388373) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=388373) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=388373) 	// end inline asm
(EngineCore_DP0 pid=388373) 	.loc	1 225 79                        // quant_slide_tuned_Llama3.2-3B.py:225:79
(EngineCore_DP0 pid=388373) 	cvt.f32.bf16 	%r85, %rs24;
(EngineCore_DP0 pid=388373) 	.loc	1 227 53                        // quant_slide_tuned_Llama3.2-3B.py:227:53
(EngineCore_DP0 pid=388373) 	add.s32 	%r86, %r110, 1;
(EngineCore_DP0 pid=388373) 	setp.lt.s32 	%p15, %r86, %r20;
(EngineCore_DP0 pid=388373) 	.loc	1 227 37                        // quant_slide_tuned_Llama3.2-3B.py:227:37
(EngineCore_DP0 pid=388373) 	and.pred 	%p10, %p13, %p15;
(EngineCore_DP0 pid=388373) 	.loc	1 226 39                        // quant_slide_tuned_Llama3.2-3B.py:226:39
(EngineCore_DP0 pid=388373) 	add.s64 	%rd9, %rd8, 2;
(EngineCore_DP0 pid=388373) 	.loc	1 226 21                        // quant_slide_tuned_Llama3.2-3B.py:226:21
(EngineCore_DP0 pid=388373) 	// begin inline asm
(EngineCore_DP0 pid=388373) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=388373) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=388373) 	// end inline asm
(EngineCore_DP0 pid=388373) 	.loc	1 227 79                        // quant_slide_tuned_Llama3.2-3B.py:227:79
(EngineCore_DP0 pid=388373) 	cvt.f32.bf16 	%r87, %rs26;
(EngineCore_DP0 pid=388373) 	.loc	1 229 53                        // quant_slide_tuned_Llama3.2-3B.py:229:53
(EngineCore_DP0 pid=388373) 	add.s32 	%r88, %r110, 2;
(EngineCore_DP0 pid=388373) 	setp.lt.s32 	%p16, %r88, %r20;
(EngineCore_DP0 pid=388373) 	.loc	1 229 37                        // quant_slide_tuned_Llama3.2-3B.py:229:37
(EngineCore_DP0 pid=388373) 	and.pred 	%p11, %p13, %p16;
(EngineCore_DP0 pid=388373) 	.loc	1 228 39                        // quant_slide_tuned_Llama3.2-3B.py:228:39
(EngineCore_DP0 pid=388373) 	add.s64 	%rd10, %rd8, 4;
(EngineCore_DP0 pid=388373) 	.loc	1 228 21                        // quant_slide_tuned_Llama3.2-3B.py:228:21
(EngineCore_DP0 pid=388373) 	// begin inline asm
(EngineCore_DP0 pid=388373) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=388373) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=388373) 	// end inline asm
(EngineCore_DP0 pid=388373) 	.loc	1 229 79                        // quant_slide_tuned_Llama3.2-3B.py:229:79
(EngineCore_DP0 pid=388373) 	cvt.f32.bf16 	%r89, %rs28;
(EngineCore_DP0 pid=388373) 	.loc	1 231 53                        // quant_slide_tuned_Llama3.2-3B.py:231:53
(EngineCore_DP0 pid=388373) 	add.s32 	%r90, %r110, 3;
(EngineCore_DP0 pid=388373) 	setp.lt.s32 	%p17, %r90, %r20;
(EngineCore_DP0 pid=388373) 	.loc	1 231 37                        // quant_slide_tuned_Llama3.2-3B.py:231:37
(EngineCore_DP0 pid=388373) 	and.pred 	%p12, %p13, %p17;
(EngineCore_DP0 pid=388373) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-3B.py:230:39
(EngineCore_DP0 pid=388373) 	add.s64 	%rd11, %rd8, 6;
(EngineCore_DP0 pid=388373) 	.loc	1 230 21                        // quant_slide_tuned_Llama3.2-3B.py:230:21
(EngineCore_DP0 pid=388373) 	// begin inline asm
(EngineCore_DP0 pid=388373) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=388373) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=388373) 	// end inline asm
(EngineCore_DP0 pid=388373) 	.loc	1 231 79                        // quant_slide_tuned_Llama3.2-3B.py:231:79
(EngineCore_DP0 pid=388373) 	cvt.f32.bf16 	%r91, %rs30;
(EngineCore_DP0 pid=388373) 	.loc	1 233 27                        // quant_slide_tuned_Llama3.2-3B.py:233:27
(EngineCore_DP0 pid=388373) 	mul.f32 	%r92, %r14, %r85;
(EngineCore_DP0 pid=388373) 	mov.b32 	%r93, 0f43E00000;
(EngineCore_DP0 pid=388373) 	.loc	1 233 48                        // quant_slide_tuned_Llama3.2-3B.py:233:48
(EngineCore_DP0 pid=388373) 	min.xorsign.abs.f32 	%r75, %r92, %r93;
(EngineCore_DP0 pid=388373) 	.loc	1 233 60                        // quant_slide_tuned_Llama3.2-3B.py:233:60
(EngineCore_DP0 pid=388373) 	// begin inline asm
(EngineCore_DP0 pid=388373) 	cvt.rn.satfinite.e4m3x2.f32  %rs32, %r76, %r75; 
(EngineCore_DP0 pid=388373) 
(EngineCore_DP0 pid=388373) 	// end inline asm
(EngineCore_DP0 pid=388373) 	.loc	1 234 27                        // quant_slide_tuned_Llama3.2-3B.py:234:27
(EngineCore_DP0 pid=388373) 	mul.f32 	%r94, %r14, %r87;
(EngineCore_DP0 pid=388373) 	.loc	1 234 48                        // quant_slide_tuned_Llama3.2-3B.py:234:48
(EngineCore_DP0 pid=388373) 	min.xorsign.abs.f32 	%r77, %r94, %r93;
(EngineCore_DP0 pid=388373) 	.loc	1 234 60                        // quant_slide_tuned_Llama3.2-3B.py:234:60
(EngineCore_DP0 pid=388373) 	// begin inline asm
(EngineCore_DP0 pid=388373) 	cvt.rn.satfinite.e4m3x2.f32  %rs33, %r78, %r77; 
(EngineCore_DP0 pid=388373) 
(EngineCore_DP0 pid=388373) 	// end inline asm
(EngineCore_DP0 pid=388373) 	.loc	1 235 27                        // quant_slide_tuned_Llama3.2-3B.py:235:27
(EngineCore_DP0 pid=388373) 	mul.f32 	%r95, %r14, %r89;
(EngineCore_DP0 pid=388373) 	.loc	1 235 48                        // quant_slide_tuned_Llama3.2-3B.py:235:48
(EngineCore_DP0 pid=388373) 	min.xorsign.abs.f32 	%r79, %r95, %r93;
(EngineCore_DP0 pid=388373) 	.loc	1 235 60                        // quant_slide_tuned_Llama3.2-3B.py:235:60
(EngineCore_DP0 pid=388373) 	// begin inline asm
(EngineCore_DP0 pid=388373) 	cvt.rn.satfinite.e4m3x2.f32  %rs34, %r80, %r79; 
(EngineCore_DP0 pid=388373) 
(EngineCore_DP0 pid=388373) 	// end inline asm
(EngineCore_DP0 pid=388373) 	.loc	1 236 27                        // quant_slide_tuned_Llama3.2-3B.py:236:27
(EngineCore_DP0 pid=388373) 	mul.f32 	%r96, %r14, %r91;
(EngineCore_DP0 pid=388373) 	.loc	1 236 48                        // quant_slide_tuned_Llama3.2-3B.py:236:48
(EngineCore_DP0 pid=388373) 	min.xorsign.abs.f32 	%r81, %r96, %r93;
(EngineCore_DP0 pid=388373) 	.loc	1 236 60                        // quant_slide_tuned_Llama3.2-3B.py:236:60
(EngineCore_DP0 pid=388373) 	// begin inline asm
(EngineCore_DP0 pid=388373) 	cvt.rn.satfinite.e4m3x2.f32  %rs35, %r82, %r81; 
(EngineCore_DP0 pid=388373) 
(EngineCore_DP0 pid=388373) 	// end inline asm
(EngineCore_DP0 pid=388373) 	.loc	1 238 45                        // quant_slide_tuned_Llama3.2-3B.py:238:45
(EngineCore_DP0 pid=388373) 	cvt.u32.u16 	%r97, %rs32;
(EngineCore_DP0 pid=388373) 	and.b32 	%r98, %r97, 255;
(EngineCore_DP0 pid=388373) 	.loc	1 240 45                        // quant_slide_tuned_Llama3.2-3B.py:240:45
(EngineCore_DP0 pid=388373) 	cvt.u32.u16 	%r99, %rs34;
(EngineCore_DP0 pid=388373) 	and.b32 	%r100, %r99, 255;
(EngineCore_DP0 pid=388373) 	.loc	1 241 45                        // quant_slide_tuned_Llama3.2-3B.py:241:45
(EngineCore_DP0 pid=388373) 	cvt.u32.u16 	%r101, %rs35;
(EngineCore_DP0 pid=388373) 	.loc	1 243 30                        // quant_slide_tuned_Llama3.2-3B.py:243:30
(EngineCore_DP0 pid=388373) 	and.b16 	%rs36, %rs33, 255;
(EngineCore_DP0 pid=388373) 	mul.wide.u16 	%r102, %rs36, 256;
(EngineCore_DP0 pid=388373) 	.loc	1 243 24                        // quant_slide_tuned_Llama3.2-3B.py:243:24
(EngineCore_DP0 pid=388373) 	or.b32 	%r103, %r102, %r98;
(EngineCore_DP0 pid=388373) 	.loc	1 243 42                        // quant_slide_tuned_Llama3.2-3B.py:243:42
(EngineCore_DP0 pid=388373) 	shl.b32 	%r104, %r100, 16;
(EngineCore_DP0 pid=388373) 	.loc	1 243 36                        // quant_slide_tuned_Llama3.2-3B.py:243:36
(EngineCore_DP0 pid=388373) 	or.b32 	%r105, %r103, %r104;
(EngineCore_DP0 pid=388373) 	.loc	1 243 55                        // quant_slide_tuned_Llama3.2-3B.py:243:55
(EngineCore_DP0 pid=388373) 	shl.b32 	%r106, %r101, 24;
(EngineCore_DP0 pid=388373) 	.loc	1 243 49                        // quant_slide_tuned_Llama3.2-3B.py:243:49
(EngineCore_DP0 pid=388373) 	or.b32 	%r83, %r105, %r106;
(EngineCore_DP0 pid=388373) 	.loc	1 244 29                        // quant_slide_tuned_Llama3.2-3B.py:244:29
(EngineCore_DP0 pid=388373) 	mad.wide.s32 	%rd12, %r84, 4, %rd2;
(EngineCore_DP0 pid=388373) 	.loc	1 244 39                        // quant_slide_tuned_Llama3.2-3B.py:244:39
(EngineCore_DP0 pid=388373) 	// begin inline asm
(EngineCore_DP0 pid=388373) 	@%p13 st.global.b32 [ %rd12 + 0 ], { %r83 };
(EngineCore_DP0 pid=388373) 	// end inline asm
(EngineCore_DP0 pid=388373) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=388373) 	add.s32 	%r111, %r111, 512;
(EngineCore_DP0 pid=388373) 	add.s32 	%r110, %r110, 2048;
(EngineCore_DP0 pid=388373) 	setp.lt.s32 	%p18, %r111, %r22;
(EngineCore_DP0 pid=388373) 	@%p18 bra 	$L__BB0_6;
(EngineCore_DP0 pid=388373) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=388373) 	.loc	1 215 4                         // quant_slide_tuned_Llama3.2-3B.py:215:4
(EngineCore_DP0 pid=388373) 	ret;
(EngineCore_DP0 pid=388373) $L__tmp3:
(EngineCore_DP0 pid=388373) $L__func_end0:
(EngineCore_DP0 pid=388373)                                         // -- End function
(EngineCore_DP0 pid=388373) }
(EngineCore_DP0 pid=388373) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py"
(EngineCore_DP0 pid=388373) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=388373) 	.section	.debug_abbrev
(EngineCore_DP0 pid=388373) 	{
(EngineCore_DP0 pid=388373) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=388373) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=388373) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=388373) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=388373) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=388373) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=388373) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=388373) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=388373) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=388373) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=388373) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=388373) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=388373) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=388373) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=388373) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=388373) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=388373) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=388373) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=388373) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=388373) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=388373) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=388373) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=388373) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=388373) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=388373) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=388373) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=388373) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=388373) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=388373) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=388373) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=388373) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=388373) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=388373) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=388373) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=388373) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=388373) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=388373) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=388373) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=388373) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=388373) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=388373) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=388373) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=388373) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=388373) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=388373) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=388373) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=388373) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=388373) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=388373) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=388373) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=388373) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=388373) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=388373) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=388373) 	}
(EngineCore_DP0 pid=388373) 	.section	.debug_info
(EngineCore_DP0 pid=388373) 	{
(EngineCore_DP0 pid=388373) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=388373) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=388373) .b8 0
(EngineCore_DP0 pid=388373) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=388373) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=388373) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=388373) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=388373) .b8 114
(EngineCore_DP0 pid=388373) .b8 105
(EngineCore_DP0 pid=388373) .b8 116
(EngineCore_DP0 pid=388373) .b8 111
(EngineCore_DP0 pid=388373) .b8 110
(EngineCore_DP0 pid=388373) .b8 0
(EngineCore_DP0 pid=388373) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=388373) .b8 0
(EngineCore_DP0 pid=388373) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=388373) .b8 117
(EngineCore_DP0 pid=388373) .b8 97
(EngineCore_DP0 pid=388373) .b8 110
(EngineCore_DP0 pid=388373) .b8 116
(EngineCore_DP0 pid=388373) .b8 95
(EngineCore_DP0 pid=388373) .b8 115
(EngineCore_DP0 pid=388373) .b8 108
(EngineCore_DP0 pid=388373) .b8 105
(EngineCore_DP0 pid=388373) .b8 100
(EngineCore_DP0 pid=388373) .b8 101
(EngineCore_DP0 pid=388373) .b8 95
(EngineCore_DP0 pid=388373) .b8 116
(EngineCore_DP0 pid=388373) .b8 117
(EngineCore_DP0 pid=388373) .b8 110
(EngineCore_DP0 pid=388373) .b8 101
(EngineCore_DP0 pid=388373) .b8 100
(EngineCore_DP0 pid=388373) .b8 95
(EngineCore_DP0 pid=388373) .b8 76
(EngineCore_DP0 pid=388373) .b8 108
(EngineCore_DP0 pid=388373) .b8 97
(EngineCore_DP0 pid=388373) .b8 109
(EngineCore_DP0 pid=388373) .b8 97
(EngineCore_DP0 pid=388373) .b8 51
(EngineCore_DP0 pid=388373) .b8 46
(EngineCore_DP0 pid=388373) .b8 50
(EngineCore_DP0 pid=388373) .b8 45
(EngineCore_DP0 pid=388373) .b8 51
(EngineCore_DP0 pid=388373) .b8 66
(EngineCore_DP0 pid=388373) .b8 46
(EngineCore_DP0 pid=388373) .b8 112
(EngineCore_DP0 pid=388373) .b8 121
(EngineCore_DP0 pid=388373) .b8 0
(EngineCore_DP0 pid=388373) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=388373) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=388373) .b8 114
(EngineCore_DP0 pid=388373) .b8 111
(EngineCore_DP0 pid=388373) .b8 111
(EngineCore_DP0 pid=388373) .b8 116
(EngineCore_DP0 pid=388373) .b8 47
(EngineCore_DP0 pid=388373) .b8 118
(EngineCore_DP0 pid=388373) .b8 108
(EngineCore_DP0 pid=388373) .b8 108
(EngineCore_DP0 pid=388373) .b8 109
(EngineCore_DP0 pid=388373) .b8 98
(EngineCore_DP0 pid=388373) .b8 101
(EngineCore_DP0 pid=388373) .b8 110
(EngineCore_DP0 pid=388373) .b8 99
(EngineCore_DP0 pid=388373) .b8 104
(EngineCore_DP0 pid=388373) .b8 47
(EngineCore_DP0 pid=388373) .b8 115
(EngineCore_DP0 pid=388373) .b8 108
(EngineCore_DP0 pid=388373) .b8 105
(EngineCore_DP0 pid=388373) .b8 100
(EngineCore_DP0 pid=388373) .b8 101
(EngineCore_DP0 pid=388373) .b8 115
(EngineCore_DP0 pid=388373) .b8 112
(EngineCore_DP0 pid=388373) .b8 97
(EngineCore_DP0 pid=388373) .b8 114
(EngineCore_DP0 pid=388373) .b8 115
(EngineCore_DP0 pid=388373) .b8 101
(EngineCore_DP0 pid=388373) .b8 47
(EngineCore_DP0 pid=388373) .b8 99
(EngineCore_DP0 pid=388373) .b8 115
(EngineCore_DP0 pid=388373) .b8 114
(EngineCore_DP0 pid=388373) .b8 99
(EngineCore_DP0 pid=388373) .b8 47
(EngineCore_DP0 pid=388373) .b8 102
(EngineCore_DP0 pid=388373) .b8 117
(EngineCore_DP0 pid=388373) .b8 115
(EngineCore_DP0 pid=388373) .b8 101
(EngineCore_DP0 pid=388373) .b8 100
(EngineCore_DP0 pid=388373) .b8 95
(EngineCore_DP0 pid=388373) .b8 113
(EngineCore_DP0 pid=388373) .b8 117
(EngineCore_DP0 pid=388373) .b8 97
(EngineCore_DP0 pid=388373) .b8 110
(EngineCore_DP0 pid=388373) .b8 116
(EngineCore_DP0 pid=388373) .b8 95
(EngineCore_DP0 pid=388373) .b8 115
(EngineCore_DP0 pid=388373) .b8 108
(EngineCore_DP0 pid=388373) .b8 105
(EngineCore_DP0 pid=388373) .b8 100
(EngineCore_DP0 pid=388373) .b8 101
(EngineCore_DP0 pid=388373) .b8 95
(EngineCore_DP0 pid=388373) .b8 116
(EngineCore_DP0 pid=388373) .b8 114
(EngineCore_DP0 pid=388373) .b8 105
(EngineCore_DP0 pid=388373) .b8 116
(EngineCore_DP0 pid=388373) .b8 111
(EngineCore_DP0 pid=388373) .b8 110
(EngineCore_DP0 pid=388373) .b8 47
(EngineCore_DP0 pid=388373) .b8 98
(EngineCore_DP0 pid=388373) .b8 117
(EngineCore_DP0 pid=388373) .b8 105
(EngineCore_DP0 pid=388373) .b8 108
(EngineCore_DP0 pid=388373) .b8 100
(EngineCore_DP0 pid=388373) .b8 47
(EngineCore_DP0 pid=388373) .b8 71
(EngineCore_DP0 pid=388373) .b8 66
(EngineCore_DP0 pid=388373) .b8 49
(EngineCore_DP0 pid=388373) .b8 48
(EngineCore_DP0 pid=388373) .b8 95
(EngineCore_DP0 pid=388373) .b8 99
(EngineCore_DP0 pid=388373) .b8 99
(EngineCore_DP0 pid=388373) .b8 49
(EngineCore_DP0 pid=388373) .b8 50
(EngineCore_DP0 pid=388373) .b8 49
(EngineCore_DP0 pid=388373) .b8 95
(EngineCore_DP0 pid=388373) .b8 112
(EngineCore_DP0 pid=388373) .b8 121
(EngineCore_DP0 pid=388373) .b8 51
(EngineCore_DP0 pid=388373) .b8 49
(EngineCore_DP0 pid=388373) .b8 50
(EngineCore_DP0 pid=388373) .b8 95
(EngineCore_DP0 pid=388373) .b8 99
(EngineCore_DP0 pid=388373) .b8 117
(EngineCore_DP0 pid=388373) .b8 49
(EngineCore_DP0 pid=388373) .b8 50
(EngineCore_DP0 pid=388373) .b8 57
(EngineCore_DP0 pid=388373) .b8 95
(EngineCore_DP0 pid=388373) .b8 97
(EngineCore_DP0 pid=388373) .b8 97
(EngineCore_DP0 pid=388373) .b8 114
(EngineCore_DP0 pid=388373) .b8 99
(EngineCore_DP0 pid=388373) .b8 104
(EngineCore_DP0 pid=388373) .b8 54
(EngineCore_DP0 pid=388373) .b8 52
(EngineCore_DP0 pid=388373) .b8 0
(EngineCore_DP0 pid=388373) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=388373) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=388373) .b8 113
(EngineCore_DP0 pid=388373) .b8 117
(EngineCore_DP0 pid=388373) .b8 97
(EngineCore_DP0 pid=388373) .b8 110
(EngineCore_DP0 pid=388373) .b8 116
(EngineCore_DP0 pid=388373) .b8 95
(EngineCore_DP0 pid=388373) .b8 115
(EngineCore_DP0 pid=388373) .b8 108
(EngineCore_DP0 pid=388373) .b8 105
(EngineCore_DP0 pid=388373) .b8 100
(EngineCore_DP0 pid=388373) .b8 101
(EngineCore_DP0 pid=388373) .b8 95
(EngineCore_DP0 pid=388373) .b8 102
(EngineCore_DP0 pid=388373) .b8 112
(EngineCore_DP0 pid=388373) .b8 56
(EngineCore_DP0 pid=388373) .b8 95
(EngineCore_DP0 pid=388373) .b8 107
(EngineCore_DP0 pid=388373) .b8 101
(EngineCore_DP0 pid=388373) .b8 114
(EngineCore_DP0 pid=388373) .b8 110
(EngineCore_DP0 pid=388373) .b8 101
(EngineCore_DP0 pid=388373) .b8 108
(EngineCore_DP0 pid=388373) .b8 0
(EngineCore_DP0 pid=388373) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=388373) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=388373) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=388373) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=388373) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=388373) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=388373) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=388373) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=388373) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=388373) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=388373) .b8 205                                 // DW_AT_call_line
(EngineCore_DP0 pid=388373) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=388373) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=388373) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=388373) 	}
(EngineCore_DP0 pid=388373) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=388373) 
(EngineCore_DP0 pid=388373) ================================================================
(EngineCore_DP0 pid=388373) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=388373) 
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpxg0o7vx2.ptx', '-o', '/tmp/tmpxg0o7vx2.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866] 
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866] 
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866] 
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpxg0o7vx2.ptx -o /tmp/tmpxg0o7vx2.ptx.o
(EngineCore_DP0 pid=388373) ERROR 01-25 20:01:16 [core.py:866] 

STDERR:
[2026-01-25 20:00:54] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:00:54] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:00:54] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:00:54] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:00:54] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:00:54] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:00:54] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:00:54] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:00:54] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:00:54] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:00:54] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:00:54] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:00:54] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:00:54] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:00:57] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:00:57] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:00:57] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:00:57] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:00:57] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:00:57] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:00:57] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:00:57] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:00:57] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:00:57] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:00:57] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:00:57] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:00:57] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:00:57] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=388373) [2026-01-25 20:00:58] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=388373) [2026-01-25 20:00:58] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=388373) [2026-01-25 20:00:58] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=388373) [2026-01-25 20:00:58] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=388373) [2026-01-25 20:00:58] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=388373) [2026-01-25 20:00:58] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=388373) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=388373) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:16<00:00, 16.01s/it]
(EngineCore_DP0 pid=388373) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:16<00:00, 16.01s/it]
(EngineCore_DP0 pid=388373) 
(EngineCore_DP0 pid=388373) [2026-01-25 20:01:15] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 3072] -> 1D uint8
(EngineCore_DP0 pid=388373) [2026-01-25 20:01:15] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9830400 bytes
(EngineCore_DP0 pid=388373) [2026-01-25 20:01:15] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=388373) [2026-01-25 20:01:15] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5898240 bytes
(EngineCore_DP0 pid=388373) [2026-01-25 20:01:15] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=388373) [2026-01-25 20:01:15] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 31457280 bytes
(EngineCore_DP0 pid=388373) [2026-01-25 20:01:15] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 8192] -> 1D uint8
(EngineCore_DP0 pid=388373) [2026-01-25 20:01:15] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15728640 bytes
(EngineCore_DP0 pid=388373) Process EngineCore_DP0:
(EngineCore_DP0 pid=388373) Traceback (most recent call last):
(EngineCore_DP0 pid=388373)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=388373)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=388373)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=388373)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=388373) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpxg0o7vx2.ptx', '-o', '/tmp/tmpxg0o7vx2.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=388373) 
(EngineCore_DP0 pid=388373) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=388373) 
(EngineCore_DP0 pid=388373) Traceback (most recent call last):
(EngineCore_DP0 pid=388373)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=388373)     self.run()
(EngineCore_DP0 pid=388373)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=388373)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=388373)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=388373)     raise e
(EngineCore_DP0 pid=388373)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=388373)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=388373)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=388373)     super().__init__(
(EngineCore_DP0 pid=388373)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=388373)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=388373)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=388373)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=388373)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=388373)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=388373)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=388373)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=388373)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=388373)     return func(*args, **kwargs)
(EngineCore_DP0 pid=388373)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=388373)     return func(*args, **kwargs)
(EngineCore_DP0 pid=388373)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=388373)     self.model_runner.profile_run()
(EngineCore_DP0 pid=388373)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=388373)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=388373)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=388373)     return func(*args, **kwargs)
(EngineCore_DP0 pid=388373)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=388373)     outputs = self.model(
(EngineCore_DP0 pid=388373)               ^^^^^^^^^^^
(EngineCore_DP0 pid=388373)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=388373)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=388373)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=388373)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=388373)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=388373)     model_output = self.model(
(EngineCore_DP0 pid=388373)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=388373)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=388373)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=388373)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=388373)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=388373)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=388373)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=388373)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=388373)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=388373)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=388373)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=388373)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=388373)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=388373)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=388373)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=388373)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=388373)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=388373)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=388373)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=388373)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=388373)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=388373)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=388373)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=388373)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=388373)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=388373)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=388373)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=388373)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=388373)     return self._linear_fn(
(EngineCore_DP0 pid=388373)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=388373)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=388373)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=388373)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=388373)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=388373)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=388373)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=388373)     return fn(input, L)
(EngineCore_DP0 pid=388373)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=388373)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=388373)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=388373)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=388373)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=388373)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=388373)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=388373)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=388373)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=388373)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=388373)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=388373)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=388373)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=388373)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388373)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=388373)     raise PTXASError(error)
(EngineCore_DP0 pid=388373) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=388373) `ptxas` stderr:
(EngineCore_DP0 pid=388373) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=388373) 
(EngineCore_DP0 pid=388373) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpxg0o7vx2.ptx -o /tmp/tmpxg0o7vx2.ptx.o
(EngineCore_DP0 pid=388373) 
[rank0]:[W125 20:01:16.587508663 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=2048

========== M=4096 ==========
Time: 2026-01-25 20:01:18
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Llama3.2-3B-FP8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:01:23 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 20:01:23 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=388971) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=388971) 
(EngineCore_DP0 pid=388971) 
(EngineCore_DP0 pid=388971) ================================================================
(EngineCore_DP0 pid=388971) Internal Triton PTX codegen error
(EngineCore_DP0 pid=388971) `ptxas` stderr:
(EngineCore_DP0 pid=388971) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=388971) 
(EngineCore_DP0 pid=388971) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpsthh78p_.ptx -o /tmp/tmpsthh78p_.ptx.o
(EngineCore_DP0 pid=388971) 
(EngineCore_DP0 pid=388971) 
(EngineCore_DP0 pid=388971) //
(EngineCore_DP0 pid=388971) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=388971) //
(EngineCore_DP0 pid=388971) 
(EngineCore_DP0 pid=388971) .version 8.7
(EngineCore_DP0 pid=388971) .target sm_121a
(EngineCore_DP0 pid=388971) .address_size 64
(EngineCore_DP0 pid=388971) 
(EngineCore_DP0 pid=388971) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=388971) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=388971)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=388971) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=388971) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=388971) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=388971) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=388971) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=388971) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=388971) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=388971) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=388971) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=388971) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=388971) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=388971) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=388971) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=388971) )
(EngineCore_DP0 pid=388971) .reqntid 512
(EngineCore_DP0 pid=388971) {
(EngineCore_DP0 pid=388971) 	.reg .pred 	%p<28>;
(EngineCore_DP0 pid=388971) 	.reg .b16 	%rs<49>;
(EngineCore_DP0 pid=388971) 	.reg .b32 	%r<134>;
(EngineCore_DP0 pid=388971) 	.reg .b64 	%rd<17>;
(EngineCore_DP0 pid=388971) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=388971) $L__func_begin0:
(EngineCore_DP0 pid=388971) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=388971) 
(EngineCore_DP0 pid=388971) // %bb.0:
(EngineCore_DP0 pid=388971) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=388971) 	ld.param.b32 	%r22, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=388971) 	ld.param.b32 	%r21, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=388971) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=388971) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=388971) $L__tmp0:
(EngineCore_DP0 pid=388971) 	.loc	1 191 24                        // quant_slide_tuned_Llama3.2-3B.py:191:24
(EngineCore_DP0 pid=388971) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=388971) 	ld.param.b32 	%r25, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=388971) 	.loc	1 196 26                        // quant_slide_tuned_Llama3.2-3B.py:196:26
(EngineCore_DP0 pid=388971) 	mul.lo.s32 	%r26, %r25, %r1;
(EngineCore_DP0 pid=388971) 	.loc	1 196 20                        // quant_slide_tuned_Llama3.2-3B.py:196:20
(EngineCore_DP0 pid=388971) 	mad.wide.s32 	%rd1, %r26, 2, %rd4;
(EngineCore_DP0 pid=388971) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=388971) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=388971) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=388971) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=388971) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=388971) 	setp.lt.s32 	%p1, %r22, 1;
(EngineCore_DP0 pid=388971) 	mov.b32 	%r131, 0f2B8CBCCC;
(EngineCore_DP0 pid=388971) 	setp.eq.b32 	%p27, %r2, 0;
(EngineCore_DP0 pid=388971) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=388971) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=388971) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=388971) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=388971) 	shr.u32 	%r35, %r2, 3;
(EngineCore_DP0 pid=388971) 	and.b32 	%r36, %r35, 60;
(EngineCore_DP0 pid=388971) 	mov.b32 	%r37, global_smem;
(EngineCore_DP0 pid=388971) 	add.s32 	%r47, %r37, %r36;
(EngineCore_DP0 pid=388971) 	shl.b32 	%r38, %r2, 2;
(EngineCore_DP0 pid=388971) 	add.s32 	%r50, %r37, %r38;
(EngineCore_DP0 pid=388971) 	mov.b32 	%r43, 0;
(EngineCore_DP0 pid=388971) 	mov.b32 	%r129, 0f00000000;
(EngineCore_DP0 pid=388971) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=388971) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=388971) 	mov.b32 	%r130, %r43;
(EngineCore_DP0 pid=388971) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=388971) 	.loc	1 203 22                        // quant_slide_tuned_Llama3.2-3B.py:203:22
(EngineCore_DP0 pid=388971) 	add.s32 	%r53, %r4, %r130;
(EngineCore_DP0 pid=388971) 	setp.lt.s32 	%p2, %r53, %r21;
(EngineCore_DP0 pid=388971) 	.loc	1 204 29                        // quant_slide_tuned_Llama3.2-3B.py:204:29
(EngineCore_DP0 pid=388971) 	mad.wide.s32 	%rd6, %r53, 2, %rd1;
(EngineCore_DP0 pid=388971) 	.loc	1 204 21                        // quant_slide_tuned_Llama3.2-3B.py:204:21
(EngineCore_DP0 pid=388971) 	// begin inline asm
(EngineCore_DP0 pid=388971) 	mov.u32 %r39, %r43;
(EngineCore_DP0 pid=388971) 	mov.u32 %r40, %r43;
(EngineCore_DP0 pid=388971) 	mov.u32 %r41, %r43;
(EngineCore_DP0 pid=388971) 	mov.u32 %r42, %r43;
(EngineCore_DP0 pid=388971) 	@%p2 ld.global.v4.b32 { %r39, %r40, %r41, %r42 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=388971) 	// end inline asm
(EngineCore_DP0 pid=388971) 	mov.b32 	{%rs1, %rs2}, %r39;
(EngineCore_DP0 pid=388971) 	mov.b32 	{%rs3, %rs4}, %r40;
(EngineCore_DP0 pid=388971) 	mov.b32 	{%rs5, %rs6}, %r41;
(EngineCore_DP0 pid=388971) 	mov.b32 	{%rs7, %rs8}, %r42;
(EngineCore_DP0 pid=388971) 	.loc	1 205 50                        // quant_slide_tuned_Llama3.2-3B.py:205:50
(EngineCore_DP0 pid=388971) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=388971) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=388971) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=388971) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=388971) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=388971) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=388971) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=388971) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=388971) $L__tmp1:
(EngineCore_DP0 pid=388971) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=388971) 	bar.sync 	0;
(EngineCore_DP0 pid=388971) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=388971) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=388971) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=388971) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=388971) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=388971) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=388971) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=388971) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=388971) 	cvt.f32.bf16 	%r54, %rs23;
(EngineCore_DP0 pid=388971) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=388971) 	shfl.sync.bfly.b32 	%r55, %r54, 16, 31, -1;
(EngineCore_DP0 pid=388971) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=388971) 	max.f32 	%r56, %r54, %r55;
(EngineCore_DP0 pid=388971) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=388971) 	shfl.sync.bfly.b32 	%r57, %r56, 8, 31, -1;
(EngineCore_DP0 pid=388971) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=388971) 	max.f32 	%r58, %r56, %r57;
(EngineCore_DP0 pid=388971) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=388971) 	shfl.sync.bfly.b32 	%r59, %r58, 4, 31, -1;
(EngineCore_DP0 pid=388971) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=388971) 	max.f32 	%r60, %r58, %r59;
(EngineCore_DP0 pid=388971) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=388971) 	shfl.sync.bfly.b32 	%r61, %r60, 2, 31, -1;
(EngineCore_DP0 pid=388971) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=388971) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=388971) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=388971) 	shfl.sync.bfly.b32 	%r63, %r62, 1, 31, -1;
(EngineCore_DP0 pid=388971) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=388971) 	max.f32 	%r48, %r62, %r63;
(EngineCore_DP0 pid=388971) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=388971) 	// begin inline asm
(EngineCore_DP0 pid=388971) 	@%p3 st.shared.b32 [ %r47 + 0 ], %r48;
(EngineCore_DP0 pid=388971) 	// end inline asm
(EngineCore_DP0 pid=388971) 	bar.sync 	0;
(EngineCore_DP0 pid=388971) 	// begin inline asm
(EngineCore_DP0 pid=388971) 	@%p4 ld.shared.b32 %r49, [ %r50 + 0 ];
(EngineCore_DP0 pid=388971) 	// end inline asm
(EngineCore_DP0 pid=388971) 	shfl.sync.bfly.b32 	%r64, %r49, 8, 31, -1;
(EngineCore_DP0 pid=388971) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=388971) 	max.f32 	%r65, %r49, %r64;
(EngineCore_DP0 pid=388971) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=388971) 	shfl.sync.bfly.b32 	%r66, %r65, 4, 31, -1;
(EngineCore_DP0 pid=388971) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=388971) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=388971) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=388971) 	shfl.sync.bfly.b32 	%r68, %r67, 2, 31, -1;
(EngineCore_DP0 pid=388971) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=388971) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=388971) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=388971) 	shfl.sync.bfly.b32 	%r70, %r69, 1, 31, -1;
(EngineCore_DP0 pid=388971) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=388971) 	max.f32 	%r52, %r69, %r70;
(EngineCore_DP0 pid=388971) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=388971) 	// begin inline asm
(EngineCore_DP0 pid=388971) 	@%p27 st.shared.b32 [ %r50 + 0 ], %r52;
(EngineCore_DP0 pid=388971) 	// end inline asm
(EngineCore_DP0 pid=388971) 	bar.sync 	0;
(EngineCore_DP0 pid=388971) 	ld.shared.b32 	%r71, [global_smem];
(EngineCore_DP0 pid=388971) $L__tmp2:
(EngineCore_DP0 pid=388971) 	.loc	1 205 36                        // quant_slide_tuned_Llama3.2-3B.py:205:36
(EngineCore_DP0 pid=388971) 	max.f32 	%r129, %r129, %r71;
(EngineCore_DP0 pid=388971) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=388971) 	add.s32 	%r130, %r130, 4096;
(EngineCore_DP0 pid=388971) 	setp.lt.s32 	%p6, %r130, %r22;
(EngineCore_DP0 pid=388971) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=388971) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=388971) 	.loc	1 207 32                        // quant_slide_tuned_Llama3.2-3B.py:207:32
(EngineCore_DP0 pid=388971) 	max.f32 	%r131, %r129, 0f2B8CBCCC;
(EngineCore_DP0 pid=388971) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=388971) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-3B.py:0:32
(EngineCore_DP0 pid=388971) 	mov.b32 	%r73, 0f43E00000;
(EngineCore_DP0 pid=388971) 	.loc	1 208 32                        // quant_slide_tuned_Llama3.2-3B.py:208:32
(EngineCore_DP0 pid=388971) 	div.full.f32 	%r74, %r131, %r73;
(EngineCore_DP0 pid=388971) 	.loc	1 208 41                        // quant_slide_tuned_Llama3.2-3B.py:208:41
(EngineCore_DP0 pid=388971) 	max.f32 	%r72, %r74, 0f36924925;
(EngineCore_DP0 pid=388971) 	.loc	1 210 25                        // quant_slide_tuned_Llama3.2-3B.py:210:25
(EngineCore_DP0 pid=388971) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=388971) 	.loc	1 210 30                        // quant_slide_tuned_Llama3.2-3B.py:210:30
(EngineCore_DP0 pid=388971) 	// begin inline asm
(EngineCore_DP0 pid=388971) 	@%p27 st.global.b32 [ %rd7 + 0 ], { %r72 };
(EngineCore_DP0 pid=388971) 	// end inline asm
(EngineCore_DP0 pid=388971) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=388971) 	setp.lt.s32 	%p8, %r23, 1;
(EngineCore_DP0 pid=388971) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=388971) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=388971) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-3B.py:0:41
(EngineCore_DP0 pid=388971) 	ld.param.b32 	%r27, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=388971) 	shr.s32 	%r28, %r27, 31;
(EngineCore_DP0 pid=388971) 	shr.u32 	%r29, %r28, 30;
(EngineCore_DP0 pid=388971) 	add.s32 	%r30, %r27, %r29;
(EngineCore_DP0 pid=388971) 	shr.s32 	%r31, %r30, 2;
(EngineCore_DP0 pid=388971) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=388971) 	mul.lo.s32 	%r32, %r31, %r1;
(EngineCore_DP0 pid=388971) 	mad.wide.s32 	%rd2, %r32, 4, %rd5;
(EngineCore_DP0 pid=388971) 	div.full.f32 	%r14, %r73, %r131;
(EngineCore_DP0 pid=388971) 	shl.b32 	%r15, %r3, 1;
(EngineCore_DP0 pid=388971) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=388971) 	add.s32 	%r132, %r4, 7;
(EngineCore_DP0 pid=388971) 	mov.b32 	%r133, 0;
(EngineCore_DP0 pid=388971) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=388971)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=388971) 	.loc	1 217 30                        // quant_slide_tuned_Llama3.2-3B.py:217:30
(EngineCore_DP0 pid=388971) 	add.s32 	%r86, %r15, %r133;
(EngineCore_DP0 pid=388971) 	setp.lt.s32 	%p17, %r86, %r23;
(EngineCore_DP0 pid=388971) 	.loc	1 222 22                        // quant_slide_tuned_Llama3.2-3B.py:222:22
(EngineCore_DP0 pid=388971) 	add.s32 	%r87, %r132, -7;
(EngineCore_DP0 pid=388971) 	.loc	1 225 53                        // quant_slide_tuned_Llama3.2-3B.py:225:53
(EngineCore_DP0 pid=388971) 	add.s32 	%r88, %r132, -3;
(EngineCore_DP0 pid=388971) 	setp.lt.s32 	%p18, %r87, %r21;
(EngineCore_DP0 pid=388971) 	setp.lt.s32 	%p19, %r88, %r21;
(EngineCore_DP0 pid=388971) 	.loc	1 225 37                        // quant_slide_tuned_Llama3.2-3B.py:225:37
(EngineCore_DP0 pid=388971) 	and.pred 	%p9, %p17, %p18;
(EngineCore_DP0 pid=388971) 	and.pred 	%p10, %p17, %p19;
(EngineCore_DP0 pid=388971) 	.loc	1 224 29                        // quant_slide_tuned_Llama3.2-3B.py:224:29
(EngineCore_DP0 pid=388971) 	mad.wide.s32 	%rd8, %r87, 2, %rd1;
(EngineCore_DP0 pid=388971) 	add.s64 	%rd9, %rd8, 8;
(EngineCore_DP0 pid=388971) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=388971) 	.loc	1 224 21                        // quant_slide_tuned_Llama3.2-3B.py:224:21
(EngineCore_DP0 pid=388971) 	// begin inline asm
(EngineCore_DP0 pid=388971) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=388971) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=388971) 	// end inline asm
(EngineCore_DP0 pid=388971) 	// begin inline asm
(EngineCore_DP0 pid=388971) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=388971) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=388971) 	// end inline asm
(EngineCore_DP0 pid=388971) 	.loc	1 225 79                        // quant_slide_tuned_Llama3.2-3B.py:225:79
(EngineCore_DP0 pid=388971) 	cvt.f32.bf16 	%r89, %rs24;
(EngineCore_DP0 pid=388971) 	cvt.f32.bf16 	%r90, %rs26;
(EngineCore_DP0 pid=388971) 	.loc	1 227 48                        // quant_slide_tuned_Llama3.2-3B.py:227:48
(EngineCore_DP0 pid=388971) 	add.s32 	%r91, %r132, -6;
(EngineCore_DP0 pid=388971) 	.loc	1 227 53                        // quant_slide_tuned_Llama3.2-3B.py:227:53
(EngineCore_DP0 pid=388971) 	add.s32 	%r92, %r132, -2;
(EngineCore_DP0 pid=388971) 	setp.lt.s32 	%p20, %r91, %r21;
(EngineCore_DP0 pid=388971) 	setp.lt.s32 	%p21, %r92, %r21;
(EngineCore_DP0 pid=388971) 	.loc	1 227 37                        // quant_slide_tuned_Llama3.2-3B.py:227:37
(EngineCore_DP0 pid=388971) 	and.pred 	%p11, %p17, %p20;
(EngineCore_DP0 pid=388971) 	and.pred 	%p12, %p17, %p21;
(EngineCore_DP0 pid=388971) 	.loc	1 226 39                        // quant_slide_tuned_Llama3.2-3B.py:226:39
(EngineCore_DP0 pid=388971) 	add.s64 	%rd10, %rd8, 2;
(EngineCore_DP0 pid=388971) 	add.s64 	%rd11, %rd8, 10;
(EngineCore_DP0 pid=388971) 	.loc	1 226 21                        // quant_slide_tuned_Llama3.2-3B.py:226:21
(EngineCore_DP0 pid=388971) 	// begin inline asm
(EngineCore_DP0 pid=388971) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=388971) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=388971) 	// end inline asm
(EngineCore_DP0 pid=388971) 	// begin inline asm
(EngineCore_DP0 pid=388971) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=388971) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=388971) 	// end inline asm
(EngineCore_DP0 pid=388971) 	.loc	1 227 79                        // quant_slide_tuned_Llama3.2-3B.py:227:79
(EngineCore_DP0 pid=388971) 	cvt.f32.bf16 	%r93, %rs28;
(EngineCore_DP0 pid=388971) 	cvt.f32.bf16 	%r94, %rs30;
(EngineCore_DP0 pid=388971) 	.loc	1 229 48                        // quant_slide_tuned_Llama3.2-3B.py:229:48
(EngineCore_DP0 pid=388971) 	add.s32 	%r95, %r132, -5;
(EngineCore_DP0 pid=388971) 	.loc	1 229 53                        // quant_slide_tuned_Llama3.2-3B.py:229:53
(EngineCore_DP0 pid=388971) 	add.s32 	%r96, %r132, -1;
(EngineCore_DP0 pid=388971) 	setp.lt.s32 	%p22, %r95, %r21;
(EngineCore_DP0 pid=388971) 	setp.lt.s32 	%p23, %r96, %r21;
(EngineCore_DP0 pid=388971) 	.loc	1 229 37                        // quant_slide_tuned_Llama3.2-3B.py:229:37
(EngineCore_DP0 pid=388971) 	and.pred 	%p13, %p17, %p22;
(EngineCore_DP0 pid=388971) 	and.pred 	%p14, %p17, %p23;
(EngineCore_DP0 pid=388971) 	.loc	1 228 39                        // quant_slide_tuned_Llama3.2-3B.py:228:39
(EngineCore_DP0 pid=388971) 	add.s64 	%rd12, %rd8, 4;
(EngineCore_DP0 pid=388971) 	add.s64 	%rd13, %rd8, 12;
(EngineCore_DP0 pid=388971) 	.loc	1 228 21                        // quant_slide_tuned_Llama3.2-3B.py:228:21
(EngineCore_DP0 pid=388971) 	// begin inline asm
(EngineCore_DP0 pid=388971) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=388971) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=388971) 	// end inline asm
(EngineCore_DP0 pid=388971) 	// begin inline asm
(EngineCore_DP0 pid=388971) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=388971) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=388971) 	// end inline asm
(EngineCore_DP0 pid=388971) 	.loc	1 229 79                        // quant_slide_tuned_Llama3.2-3B.py:229:79
(EngineCore_DP0 pid=388971) 	cvt.f32.bf16 	%r97, %rs32;
(EngineCore_DP0 pid=388971) 	cvt.f32.bf16 	%r98, %rs34;
(EngineCore_DP0 pid=388971) 	.loc	1 231 48                        // quant_slide_tuned_Llama3.2-3B.py:231:48
(EngineCore_DP0 pid=388971) 	add.s32 	%r99, %r132, -4;
(EngineCore_DP0 pid=388971) 	.loc	1 231 53                        // quant_slide_tuned_Llama3.2-3B.py:231:53
(EngineCore_DP0 pid=388971) 	setp.lt.s32 	%p24, %r99, %r21;
(EngineCore_DP0 pid=388971) 	setp.lt.s32 	%p25, %r132, %r21;
(EngineCore_DP0 pid=388971) 	.loc	1 231 37                        // quant_slide_tuned_Llama3.2-3B.py:231:37
(EngineCore_DP0 pid=388971) 	and.pred 	%p15, %p17, %p24;
(EngineCore_DP0 pid=388971) 	and.pred 	%p16, %p17, %p25;
(EngineCore_DP0 pid=388971) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-3B.py:230:39
(EngineCore_DP0 pid=388971) 	add.s64 	%rd14, %rd8, 6;
(EngineCore_DP0 pid=388971) 	add.s64 	%rd15, %rd8, 14;
(EngineCore_DP0 pid=388971) 	.loc	1 230 21                        // quant_slide_tuned_Llama3.2-3B.py:230:21
(EngineCore_DP0 pid=388971) 	// begin inline asm
(EngineCore_DP0 pid=388971) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=388971) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=388971) 	// end inline asm
(EngineCore_DP0 pid=388971) 	// begin inline asm
(EngineCore_DP0 pid=388971) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=388971) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=388971) 	// end inline asm
(EngineCore_DP0 pid=388971) 	.loc	1 231 79                        // quant_slide_tuned_Llama3.2-3B.py:231:79
(EngineCore_DP0 pid=388971) 	cvt.f32.bf16 	%r100, %rs36;
(EngineCore_DP0 pid=388971) 	cvt.f32.bf16 	%r101, %rs38;
(EngineCore_DP0 pid=388971) 	.loc	1 233 27                        // quant_slide_tuned_Llama3.2-3B.py:233:27
(EngineCore_DP0 pid=388971) 	mul.f32 	%r102, %r14, %r89;
(EngineCore_DP0 pid=388971) 	mul.f32 	%r103, %r14, %r90;
(EngineCore_DP0 pid=388971) 	mov.b32 	%r104, 0f43E00000;
(EngineCore_DP0 pid=388971) 	.loc	1 233 48                        // quant_slide_tuned_Llama3.2-3B.py:233:48
(EngineCore_DP0 pid=388971) 	min.xorsign.abs.f32 	%r76, %r102, %r104;
(EngineCore_DP0 pid=388971) 	min.xorsign.abs.f32 	%r77, %r103, %r104;
(EngineCore_DP0 pid=388971) 	.loc	1 233 60                        // quant_slide_tuned_Llama3.2-3B.py:233:60
(EngineCore_DP0 pid=388971) 	// begin inline asm
(EngineCore_DP0 pid=388971) 	cvt.rn.satfinite.e4m3x2.f32  %rs40, %r77, %r76; 
(EngineCore_DP0 pid=388971) 
(EngineCore_DP0 pid=388971) 	// end inline asm
(EngineCore_DP0 pid=388971) 	shr.u16 	%rs44, %rs40, 8;
(EngineCore_DP0 pid=388971) 	.loc	1 234 27                        // quant_slide_tuned_Llama3.2-3B.py:234:27
(EngineCore_DP0 pid=388971) 	mul.f32 	%r105, %r14, %r93;
(EngineCore_DP0 pid=388971) 	mul.f32 	%r106, %r14, %r94;
(EngineCore_DP0 pid=388971) 	.loc	1 234 48                        // quant_slide_tuned_Llama3.2-3B.py:234:48
(EngineCore_DP0 pid=388971) 	min.xorsign.abs.f32 	%r78, %r105, %r104;
(EngineCore_DP0 pid=388971) 	min.xorsign.abs.f32 	%r79, %r106, %r104;
(EngineCore_DP0 pid=388971) 	.loc	1 234 60                        // quant_slide_tuned_Llama3.2-3B.py:234:60
(EngineCore_DP0 pid=388971) 	// begin inline asm
(EngineCore_DP0 pid=388971) 	cvt.rn.satfinite.e4m3x2.f32  %rs41, %r79, %r78; 
(EngineCore_DP0 pid=388971) 
(EngineCore_DP0 pid=388971) 	// end inline asm
(EngineCore_DP0 pid=388971) 	shr.u16 	%rs45, %rs41, 8;
(EngineCore_DP0 pid=388971) 	.loc	1 235 27                        // quant_slide_tuned_Llama3.2-3B.py:235:27
(EngineCore_DP0 pid=388971) 	mul.f32 	%r107, %r14, %r97;
(EngineCore_DP0 pid=388971) 	mul.f32 	%r108, %r14, %r98;
(EngineCore_DP0 pid=388971) 	.loc	1 235 48                        // quant_slide_tuned_Llama3.2-3B.py:235:48
(EngineCore_DP0 pid=388971) 	min.xorsign.abs.f32 	%r80, %r107, %r104;
(EngineCore_DP0 pid=388971) 	min.xorsign.abs.f32 	%r81, %r108, %r104;
(EngineCore_DP0 pid=388971) 	.loc	1 235 60                        // quant_slide_tuned_Llama3.2-3B.py:235:60
(EngineCore_DP0 pid=388971) 	// begin inline asm
(EngineCore_DP0 pid=388971) 	cvt.rn.satfinite.e4m3x2.f32  %rs42, %r81, %r80; 
(EngineCore_DP0 pid=388971) 
(EngineCore_DP0 pid=388971) 	// end inline asm
(EngineCore_DP0 pid=388971) 	shr.u16 	%rs46, %rs42, 8;
(EngineCore_DP0 pid=388971) 	.loc	1 236 27                        // quant_slide_tuned_Llama3.2-3B.py:236:27
(EngineCore_DP0 pid=388971) 	mul.f32 	%r109, %r14, %r100;
(EngineCore_DP0 pid=388971) 	mul.f32 	%r110, %r14, %r101;
(EngineCore_DP0 pid=388971) 	.loc	1 236 48                        // quant_slide_tuned_Llama3.2-3B.py:236:48
(EngineCore_DP0 pid=388971) 	min.xorsign.abs.f32 	%r82, %r109, %r104;
(EngineCore_DP0 pid=388971) 	min.xorsign.abs.f32 	%r83, %r110, %r104;
(EngineCore_DP0 pid=388971) 	.loc	1 236 60                        // quant_slide_tuned_Llama3.2-3B.py:236:60
(EngineCore_DP0 pid=388971) 	// begin inline asm
(EngineCore_DP0 pid=388971) 	cvt.rn.satfinite.e4m3x2.f32  %rs43, %r83, %r82; 
(EngineCore_DP0 pid=388971) 
(EngineCore_DP0 pid=388971) 	// end inline asm
(EngineCore_DP0 pid=388971) 	shr.u16 	%rs47, %rs43, 8;
(EngineCore_DP0 pid=388971) 	.loc	1 238 45                        // quant_slide_tuned_Llama3.2-3B.py:238:45
(EngineCore_DP0 pid=388971) 	cvt.u32.u16 	%r111, %rs40;
(EngineCore_DP0 pid=388971) 	and.b32 	%r112, %r111, 255;
(EngineCore_DP0 pid=388971) 	cvt.u32.u16 	%r113, %rs44;
(EngineCore_DP0 pid=388971) 	.loc	1 240 45                        // quant_slide_tuned_Llama3.2-3B.py:240:45
(EngineCore_DP0 pid=388971) 	cvt.u32.u16 	%r114, %rs42;
(EngineCore_DP0 pid=388971) 	and.b32 	%r115, %r114, 255;
(EngineCore_DP0 pid=388971) 	cvt.u32.u16 	%r116, %rs46;
(EngineCore_DP0 pid=388971) 	.loc	1 241 45                        // quant_slide_tuned_Llama3.2-3B.py:241:45
(EngineCore_DP0 pid=388971) 	cvt.u32.u16 	%r117, %rs43;
(EngineCore_DP0 pid=388971) 	cvt.u32.u16 	%r118, %rs47;
(EngineCore_DP0 pid=388971) 	.loc	1 243 30                        // quant_slide_tuned_Llama3.2-3B.py:243:30
(EngineCore_DP0 pid=388971) 	and.b16 	%rs48, %rs41, 255;
(EngineCore_DP0 pid=388971) 	mul.wide.u16 	%r119, %rs48, 256;
(EngineCore_DP0 pid=388971) 	mul.wide.u16 	%r120, %rs45, 256;
(EngineCore_DP0 pid=388971) 	.loc	1 243 24                        // quant_slide_tuned_Llama3.2-3B.py:243:24
(EngineCore_DP0 pid=388971) 	or.b32 	%r121, %r119, %r112;
(EngineCore_DP0 pid=388971) 	or.b32 	%r122, %r120, %r113;
(EngineCore_DP0 pid=388971) 	.loc	1 243 42                        // quant_slide_tuned_Llama3.2-3B.py:243:42
(EngineCore_DP0 pid=388971) 	shl.b32 	%r123, %r115, 16;
(EngineCore_DP0 pid=388971) 	shl.b32 	%r124, %r116, 16;
(EngineCore_DP0 pid=388971) 	.loc	1 243 36                        // quant_slide_tuned_Llama3.2-3B.py:243:36
(EngineCore_DP0 pid=388971) 	or.b32 	%r125, %r121, %r123;
(EngineCore_DP0 pid=388971) 	or.b32 	%r126, %r122, %r124;
(EngineCore_DP0 pid=388971) 	.loc	1 243 55                        // quant_slide_tuned_Llama3.2-3B.py:243:55
(EngineCore_DP0 pid=388971) 	shl.b32 	%r127, %r117, 24;
(EngineCore_DP0 pid=388971) 	shl.b32 	%r128, %r118, 24;
(EngineCore_DP0 pid=388971) 	.loc	1 243 49                        // quant_slide_tuned_Llama3.2-3B.py:243:49
(EngineCore_DP0 pid=388971) 	or.b32 	%r84, %r125, %r127;
(EngineCore_DP0 pid=388971) 	or.b32 	%r85, %r126, %r128;
(EngineCore_DP0 pid=388971) 	.loc	1 244 29                        // quant_slide_tuned_Llama3.2-3B.py:244:29
(EngineCore_DP0 pid=388971) 	mad.wide.s32 	%rd16, %r86, 4, %rd2;
(EngineCore_DP0 pid=388971) 	.loc	1 244 39                        // quant_slide_tuned_Llama3.2-3B.py:244:39
(EngineCore_DP0 pid=388971) 	// begin inline asm
(EngineCore_DP0 pid=388971) 	@%p17 st.global.v2.b32 [ %rd16 + 0 ], { %r84, %r85 };
(EngineCore_DP0 pid=388971) 	// end inline asm
(EngineCore_DP0 pid=388971) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=388971) 	add.s32 	%r133, %r133, 1024;
(EngineCore_DP0 pid=388971) 	add.s32 	%r132, %r132, 4096;
(EngineCore_DP0 pid=388971) 	setp.lt.s32 	%p26, %r133, %r23;
(EngineCore_DP0 pid=388971) 	@%p26 bra 	$L__BB0_6;
(EngineCore_DP0 pid=388971) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=388971) 	.loc	1 215 4                         // quant_slide_tuned_Llama3.2-3B.py:215:4
(EngineCore_DP0 pid=388971) 	ret;
(EngineCore_DP0 pid=388971) $L__tmp3:
(EngineCore_DP0 pid=388971) $L__func_end0:
(EngineCore_DP0 pid=388971)                                         // -- End function
(EngineCore_DP0 pid=388971) }
(EngineCore_DP0 pid=388971) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py"
(EngineCore_DP0 pid=388971) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=388971) 	.section	.debug_abbrev
(EngineCore_DP0 pid=388971) 	{
(EngineCore_DP0 pid=388971) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=388971) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=388971) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=388971) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=388971) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=388971) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=388971) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=388971) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=388971) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=388971) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=388971) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=388971) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=388971) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=388971) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=388971) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=388971) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=388971) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=388971) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=388971) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=388971) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=388971) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=388971) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=388971) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=388971) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=388971) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=388971) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=388971) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=388971) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=388971) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=388971) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=388971) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=388971) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=388971) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=388971) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=388971) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=388971) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=388971) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=388971) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=388971) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=388971) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=388971) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=388971) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=388971) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=388971) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=388971) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=388971) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=388971) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=388971) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=388971) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=388971) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=388971) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=388971) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=388971) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=388971) 	}
(EngineCore_DP0 pid=388971) 	.section	.debug_info
(EngineCore_DP0 pid=388971) 	{
(EngineCore_DP0 pid=388971) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=388971) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=388971) .b8 0
(EngineCore_DP0 pid=388971) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=388971) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=388971) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=388971) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=388971) .b8 114
(EngineCore_DP0 pid=388971) .b8 105
(EngineCore_DP0 pid=388971) .b8 116
(EngineCore_DP0 pid=388971) .b8 111
(EngineCore_DP0 pid=388971) .b8 110
(EngineCore_DP0 pid=388971) .b8 0
(EngineCore_DP0 pid=388971) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=388971) .b8 0
(EngineCore_DP0 pid=388971) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=388971) .b8 117
(EngineCore_DP0 pid=388971) .b8 97
(EngineCore_DP0 pid=388971) .b8 110
(EngineCore_DP0 pid=388971) .b8 116
(EngineCore_DP0 pid=388971) .b8 95
(EngineCore_DP0 pid=388971) .b8 115
(EngineCore_DP0 pid=388971) .b8 108
(EngineCore_DP0 pid=388971) .b8 105
(EngineCore_DP0 pid=388971) .b8 100
(EngineCore_DP0 pid=388971) .b8 101
(EngineCore_DP0 pid=388971) .b8 95
(EngineCore_DP0 pid=388971) .b8 116
(EngineCore_DP0 pid=388971) .b8 117
(EngineCore_DP0 pid=388971) .b8 110
(EngineCore_DP0 pid=388971) .b8 101
(EngineCore_DP0 pid=388971) .b8 100
(EngineCore_DP0 pid=388971) .b8 95
(EngineCore_DP0 pid=388971) .b8 76
(EngineCore_DP0 pid=388971) .b8 108
(EngineCore_DP0 pid=388971) .b8 97
(EngineCore_DP0 pid=388971) .b8 109
(EngineCore_DP0 pid=388971) .b8 97
(EngineCore_DP0 pid=388971) .b8 51
(EngineCore_DP0 pid=388971) .b8 46
(EngineCore_DP0 pid=388971) .b8 50
(EngineCore_DP0 pid=388971) .b8 45
(EngineCore_DP0 pid=388971) .b8 51
(EngineCore_DP0 pid=388971) .b8 66
(EngineCore_DP0 pid=388971) .b8 46
(EngineCore_DP0 pid=388971) .b8 112
(EngineCore_DP0 pid=388971) .b8 121
(EngineCore_DP0 pid=388971) .b8 0
(EngineCore_DP0 pid=388971) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=388971) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=388971) .b8 114
(EngineCore_DP0 pid=388971) .b8 111
(EngineCore_DP0 pid=388971) .b8 111
(EngineCore_DP0 pid=388971) .b8 116
(EngineCore_DP0 pid=388971) .b8 47
(EngineCore_DP0 pid=388971) .b8 118
(EngineCore_DP0 pid=388971) .b8 108
(EngineCore_DP0 pid=388971) .b8 108
(EngineCore_DP0 pid=388971) .b8 109
(EngineCore_DP0 pid=388971) .b8 98
(EngineCore_DP0 pid=388971) .b8 101
(EngineCore_DP0 pid=388971) .b8 110
(EngineCore_DP0 pid=388971) .b8 99
(EngineCore_DP0 pid=388971) .b8 104
(EngineCore_DP0 pid=388971) .b8 47
(EngineCore_DP0 pid=388971) .b8 115
(EngineCore_DP0 pid=388971) .b8 108
(EngineCore_DP0 pid=388971) .b8 105
(EngineCore_DP0 pid=388971) .b8 100
(EngineCore_DP0 pid=388971) .b8 101
(EngineCore_DP0 pid=388971) .b8 115
(EngineCore_DP0 pid=388971) .b8 112
(EngineCore_DP0 pid=388971) .b8 97
(EngineCore_DP0 pid=388971) .b8 114
(EngineCore_DP0 pid=388971) .b8 115
(EngineCore_DP0 pid=388971) .b8 101
(EngineCore_DP0 pid=388971) .b8 47
(EngineCore_DP0 pid=388971) .b8 99
(EngineCore_DP0 pid=388971) .b8 115
(EngineCore_DP0 pid=388971) .b8 114
(EngineCore_DP0 pid=388971) .b8 99
(EngineCore_DP0 pid=388971) .b8 47
(EngineCore_DP0 pid=388971) .b8 102
(EngineCore_DP0 pid=388971) .b8 117
(EngineCore_DP0 pid=388971) .b8 115
(EngineCore_DP0 pid=388971) .b8 101
(EngineCore_DP0 pid=388971) .b8 100
(EngineCore_DP0 pid=388971) .b8 95
(EngineCore_DP0 pid=388971) .b8 113
(EngineCore_DP0 pid=388971) .b8 117
(EngineCore_DP0 pid=388971) .b8 97
(EngineCore_DP0 pid=388971) .b8 110
(EngineCore_DP0 pid=388971) .b8 116
(EngineCore_DP0 pid=388971) .b8 95
(EngineCore_DP0 pid=388971) .b8 115
(EngineCore_DP0 pid=388971) .b8 108
(EngineCore_DP0 pid=388971) .b8 105
(EngineCore_DP0 pid=388971) .b8 100
(EngineCore_DP0 pid=388971) .b8 101
(EngineCore_DP0 pid=388971) .b8 95
(EngineCore_DP0 pid=388971) .b8 116
(EngineCore_DP0 pid=388971) .b8 114
(EngineCore_DP0 pid=388971) .b8 105
(EngineCore_DP0 pid=388971) .b8 116
(EngineCore_DP0 pid=388971) .b8 111
(EngineCore_DP0 pid=388971) .b8 110
(EngineCore_DP0 pid=388971) .b8 47
(EngineCore_DP0 pid=388971) .b8 98
(EngineCore_DP0 pid=388971) .b8 117
(EngineCore_DP0 pid=388971) .b8 105
(EngineCore_DP0 pid=388971) .b8 108
(EngineCore_DP0 pid=388971) .b8 100
(EngineCore_DP0 pid=388971) .b8 47
(EngineCore_DP0 pid=388971) .b8 71
(EngineCore_DP0 pid=388971) .b8 66
(EngineCore_DP0 pid=388971) .b8 49
(EngineCore_DP0 pid=388971) .b8 48
(EngineCore_DP0 pid=388971) .b8 95
(EngineCore_DP0 pid=388971) .b8 99
(EngineCore_DP0 pid=388971) .b8 99
(EngineCore_DP0 pid=388971) .b8 49
(EngineCore_DP0 pid=388971) .b8 50
(EngineCore_DP0 pid=388971) .b8 49
(EngineCore_DP0 pid=388971) .b8 95
(EngineCore_DP0 pid=388971) .b8 112
(EngineCore_DP0 pid=388971) .b8 121
(EngineCore_DP0 pid=388971) .b8 51
(EngineCore_DP0 pid=388971) .b8 49
(EngineCore_DP0 pid=388971) .b8 50
(EngineCore_DP0 pid=388971) .b8 95
(EngineCore_DP0 pid=388971) .b8 99
(EngineCore_DP0 pid=388971) .b8 117
(EngineCore_DP0 pid=388971) .b8 49
(EngineCore_DP0 pid=388971) .b8 50
(EngineCore_DP0 pid=388971) .b8 57
(EngineCore_DP0 pid=388971) .b8 95
(EngineCore_DP0 pid=388971) .b8 97
(EngineCore_DP0 pid=388971) .b8 97
(EngineCore_DP0 pid=388971) .b8 114
(EngineCore_DP0 pid=388971) .b8 99
(EngineCore_DP0 pid=388971) .b8 104
(EngineCore_DP0 pid=388971) .b8 54
(EngineCore_DP0 pid=388971) .b8 52
(EngineCore_DP0 pid=388971) .b8 0
(EngineCore_DP0 pid=388971) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=388971) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=388971) .b8 113
(EngineCore_DP0 pid=388971) .b8 117
(EngineCore_DP0 pid=388971) .b8 97
(EngineCore_DP0 pid=388971) .b8 110
(EngineCore_DP0 pid=388971) .b8 116
(EngineCore_DP0 pid=388971) .b8 95
(EngineCore_DP0 pid=388971) .b8 115
(EngineCore_DP0 pid=388971) .b8 108
(EngineCore_DP0 pid=388971) .b8 105
(EngineCore_DP0 pid=388971) .b8 100
(EngineCore_DP0 pid=388971) .b8 101
(EngineCore_DP0 pid=388971) .b8 95
(EngineCore_DP0 pid=388971) .b8 102
(EngineCore_DP0 pid=388971) .b8 112
(EngineCore_DP0 pid=388971) .b8 56
(EngineCore_DP0 pid=388971) .b8 95
(EngineCore_DP0 pid=388971) .b8 107
(EngineCore_DP0 pid=388971) .b8 101
(EngineCore_DP0 pid=388971) .b8 114
(EngineCore_DP0 pid=388971) .b8 110
(EngineCore_DP0 pid=388971) .b8 101
(EngineCore_DP0 pid=388971) .b8 108
(EngineCore_DP0 pid=388971) .b8 0
(EngineCore_DP0 pid=388971) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=388971) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=388971) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=388971) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=388971) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=388971) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=388971) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=388971) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=388971) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=388971) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=388971) .b8 205                                 // DW_AT_call_line
(EngineCore_DP0 pid=388971) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=388971) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=388971) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=388971) 	}
(EngineCore_DP0 pid=388971) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=388971) 
(EngineCore_DP0 pid=388971) ================================================================
(EngineCore_DP0 pid=388971) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=388971) 
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpsthh78p_.ptx', '-o', '/tmp/tmpsthh78p_.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866] 
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866] 
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866] 
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpsthh78p_.ptx -o /tmp/tmpsthh78p_.ptx.o
(EngineCore_DP0 pid=388971) ERROR 01-25 20:01:44 [core.py:866] 

STDERR:
[2026-01-25 20:01:23] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:01:23] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:01:23] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:01:23] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:01:23] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:01:23] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:01:23] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:01:23] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:01:23] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:01:23] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:01:23] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:01:23] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:01:23] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:01:23] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:01:26] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:01:26] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:01:26] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:01:26] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:01:26] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:01:26] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:01:26] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:01:26] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:01:26] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:01:26] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:01:26] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:01:26] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:01:26] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:01:26] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=388971) [2026-01-25 20:01:27] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=388971) [2026-01-25 20:01:27] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=388971) [2026-01-25 20:01:27] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=388971) [2026-01-25 20:01:27] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=388971) [2026-01-25 20:01:27] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=388971) [2026-01-25 20:01:27] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=388971) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=388971) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:15<00:00, 15.82s/it]
(EngineCore_DP0 pid=388971) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:15<00:00, 15.82s/it]
(EngineCore_DP0 pid=388971) 
(EngineCore_DP0 pid=388971) [2026-01-25 20:01:44] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 3072] -> 1D uint8
(EngineCore_DP0 pid=388971) [2026-01-25 20:01:44] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9830400 bytes
(EngineCore_DP0 pid=388971) [2026-01-25 20:01:44] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=388971) [2026-01-25 20:01:44] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5898240 bytes
(EngineCore_DP0 pid=388971) [2026-01-25 20:01:44] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=388971) [2026-01-25 20:01:44] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 31457280 bytes
(EngineCore_DP0 pid=388971) [2026-01-25 20:01:44] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 8192] -> 1D uint8
(EngineCore_DP0 pid=388971) [2026-01-25 20:01:44] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15728640 bytes
(EngineCore_DP0 pid=388971) Process EngineCore_DP0:
(EngineCore_DP0 pid=388971) Traceback (most recent call last):
(EngineCore_DP0 pid=388971)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=388971)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=388971)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=388971)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=388971) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpsthh78p_.ptx', '-o', '/tmp/tmpsthh78p_.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=388971) 
(EngineCore_DP0 pid=388971) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=388971) 
(EngineCore_DP0 pid=388971) Traceback (most recent call last):
(EngineCore_DP0 pid=388971)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=388971)     self.run()
(EngineCore_DP0 pid=388971)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=388971)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=388971)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=388971)     raise e
(EngineCore_DP0 pid=388971)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=388971)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=388971)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=388971)     super().__init__(
(EngineCore_DP0 pid=388971)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=388971)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=388971)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=388971)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=388971)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=388971)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=388971)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=388971)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=388971)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=388971)     return func(*args, **kwargs)
(EngineCore_DP0 pid=388971)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=388971)     return func(*args, **kwargs)
(EngineCore_DP0 pid=388971)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=388971)     self.model_runner.profile_run()
(EngineCore_DP0 pid=388971)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=388971)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=388971)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=388971)     return func(*args, **kwargs)
(EngineCore_DP0 pid=388971)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=388971)     outputs = self.model(
(EngineCore_DP0 pid=388971)               ^^^^^^^^^^^
(EngineCore_DP0 pid=388971)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=388971)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=388971)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=388971)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=388971)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=388971)     model_output = self.model(
(EngineCore_DP0 pid=388971)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=388971)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=388971)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=388971)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=388971)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=388971)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=388971)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=388971)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=388971)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=388971)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=388971)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=388971)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=388971)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=388971)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=388971)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=388971)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=388971)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=388971)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=388971)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=388971)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=388971)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=388971)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=388971)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=388971)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=388971)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=388971)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=388971)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=388971)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=388971)     return self._linear_fn(
(EngineCore_DP0 pid=388971)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=388971)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=388971)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=388971)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=388971)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=388971)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=388971)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=388971)     return fn(input, L)
(EngineCore_DP0 pid=388971)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=388971)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=388971)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=388971)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=388971)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=388971)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=388971)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=388971)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=388971)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=388971)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=388971)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=388971)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=388971)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=388971)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=388971)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=388971)     raise PTXASError(error)
(EngineCore_DP0 pid=388971) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=388971) `ptxas` stderr:
(EngineCore_DP0 pid=388971) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=388971) 
(EngineCore_DP0 pid=388971) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpsthh78p_.ptx -o /tmp/tmpsthh78p_.ptx.o
(EngineCore_DP0 pid=388971) 
[rank0]:[W125 20:01:45.448662557 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=4096

========== M=8192 ==========
Time: 2026-01-25 20:01:46
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Llama3.2-3B-FP8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:01:53 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 20:01:53 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=389580) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=389580) 
(EngineCore_DP0 pid=389580) 
(EngineCore_DP0 pid=389580) ================================================================
(EngineCore_DP0 pid=389580) Internal Triton PTX codegen error
(EngineCore_DP0 pid=389580) `ptxas` stderr:
(EngineCore_DP0 pid=389580) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=389580) 
(EngineCore_DP0 pid=389580) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp4pjuuk_f.ptx -o /tmp/tmp4pjuuk_f.ptx.o
(EngineCore_DP0 pid=389580) 
(EngineCore_DP0 pid=389580) 
(EngineCore_DP0 pid=389580) //
(EngineCore_DP0 pid=389580) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=389580) //
(EngineCore_DP0 pid=389580) 
(EngineCore_DP0 pid=389580) .version 8.7
(EngineCore_DP0 pid=389580) .target sm_121a
(EngineCore_DP0 pid=389580) .address_size 64
(EngineCore_DP0 pid=389580) 
(EngineCore_DP0 pid=389580) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=389580) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=389580)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=389580) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=389580) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=389580) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=389580) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=389580) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=389580) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=389580) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=389580) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=389580) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=389580) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=389580) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=389580) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=389580) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=389580) )
(EngineCore_DP0 pid=389580) .reqntid 512
(EngineCore_DP0 pid=389580) {
(EngineCore_DP0 pid=389580) 	.reg .pred 	%p<29>;
(EngineCore_DP0 pid=389580) 	.reg .b16 	%rs<73>;
(EngineCore_DP0 pid=389580) 	.reg .b32 	%r<143>;
(EngineCore_DP0 pid=389580) 	.reg .b64 	%rd<18>;
(EngineCore_DP0 pid=389580) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=389580) $L__func_begin0:
(EngineCore_DP0 pid=389580) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=389580) 
(EngineCore_DP0 pid=389580) // %bb.0:
(EngineCore_DP0 pid=389580) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=389580) 	ld.param.b32 	%r22, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=389580) 	ld.param.b32 	%r21, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=389580) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=389580) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=389580) $L__tmp0:
(EngineCore_DP0 pid=389580) 	.loc	1 191 24                        // quant_slide_tuned_Llama3.2-3B.py:191:24
(EngineCore_DP0 pid=389580) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=389580) 	ld.param.b32 	%r25, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=389580) 	.loc	1 196 26                        // quant_slide_tuned_Llama3.2-3B.py:196:26
(EngineCore_DP0 pid=389580) 	mul.lo.s32 	%r26, %r25, %r1;
(EngineCore_DP0 pid=389580) 	.loc	1 196 20                        // quant_slide_tuned_Llama3.2-3B.py:196:20
(EngineCore_DP0 pid=389580) 	mad.wide.s32 	%rd1, %r26, 2, %rd4;
(EngineCore_DP0 pid=389580) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=389580) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=389580) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=389580) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=389580) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=389580) 	setp.lt.s32 	%p1, %r22, 1;
(EngineCore_DP0 pid=389580) 	mov.b32 	%r140, 0f2B8CBCCC;
(EngineCore_DP0 pid=389580) 	setp.eq.b32 	%p28, %r2, 0;
(EngineCore_DP0 pid=389580) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=389580) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=389580) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=389580) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=389580) 	shr.u32 	%r35, %r2, 3;
(EngineCore_DP0 pid=389580) 	and.b32 	%r36, %r35, 60;
(EngineCore_DP0 pid=389580) 	mov.b32 	%r37, global_smem;
(EngineCore_DP0 pid=389580) 	add.s32 	%r55, %r37, %r36;
(EngineCore_DP0 pid=389580) 	shl.b32 	%r38, %r2, 2;
(EngineCore_DP0 pid=389580) 	add.s32 	%r58, %r37, %r38;
(EngineCore_DP0 pid=389580) 	mov.b32 	%r43, 0;
(EngineCore_DP0 pid=389580) 	mov.b32 	%r138, 0f00000000;
(EngineCore_DP0 pid=389580) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=389580) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=389580) 	mov.b32 	%r139, %r43;
(EngineCore_DP0 pid=389580) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=389580) 	.loc	1 202 19                        // quant_slide_tuned_Llama3.2-3B.py:202:19
(EngineCore_DP0 pid=389580) 	add.s32 	%r61, %r4, %r139;
(EngineCore_DP0 pid=389580) 	.loc	1 203 22                        // quant_slide_tuned_Llama3.2-3B.py:203:22
(EngineCore_DP0 pid=389580) 	add.s32 	%r62, %r61, 4096;
(EngineCore_DP0 pid=389580) 	setp.lt.s32 	%p2, %r61, %r21;
(EngineCore_DP0 pid=389580) 	setp.lt.s32 	%p3, %r62, %r21;
(EngineCore_DP0 pid=389580) 	.loc	1 204 29                        // quant_slide_tuned_Llama3.2-3B.py:204:29
(EngineCore_DP0 pid=389580) 	mad.wide.s32 	%rd6, %r61, 2, %rd1;
(EngineCore_DP0 pid=389580) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=389580) 	.loc	1 204 21                        // quant_slide_tuned_Llama3.2-3B.py:204:21
(EngineCore_DP0 pid=389580) 	// begin inline asm
(EngineCore_DP0 pid=389580) 	mov.u32 %r39, %r43;
(EngineCore_DP0 pid=389580) 	mov.u32 %r40, %r43;
(EngineCore_DP0 pid=389580) 	mov.u32 %r41, %r43;
(EngineCore_DP0 pid=389580) 	mov.u32 %r42, %r43;
(EngineCore_DP0 pid=389580) 	@%p2 ld.global.v4.b32 { %r39, %r40, %r41, %r42 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=389580) 	// end inline asm
(EngineCore_DP0 pid=389580) 	mov.b32 	{%rs1, %rs2}, %r39;
(EngineCore_DP0 pid=389580) 	mov.b32 	{%rs3, %rs4}, %r40;
(EngineCore_DP0 pid=389580) 	mov.b32 	{%rs5, %rs6}, %r41;
(EngineCore_DP0 pid=389580) 	mov.b32 	{%rs7, %rs8}, %r42;
(EngineCore_DP0 pid=389580) 	// begin inline asm
(EngineCore_DP0 pid=389580) 	mov.u32 %r47, %r43;
(EngineCore_DP0 pid=389580) 	mov.u32 %r48, %r43;
(EngineCore_DP0 pid=389580) 	mov.u32 %r49, %r43;
(EngineCore_DP0 pid=389580) 	mov.u32 %r50, %r43;
(EngineCore_DP0 pid=389580) 	@%p3 ld.global.v4.b32 { %r47, %r48, %r49, %r50 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=389580) 	// end inline asm
(EngineCore_DP0 pid=389580) 	mov.b32 	{%rs9, %rs10}, %r47;
(EngineCore_DP0 pid=389580) 	mov.b32 	{%rs11, %rs12}, %r48;
(EngineCore_DP0 pid=389580) 	mov.b32 	{%rs13, %rs14}, %r49;
(EngineCore_DP0 pid=389580) 	mov.b32 	{%rs15, %rs16}, %r50;
(EngineCore_DP0 pid=389580) 	.loc	1 205 50                        // quant_slide_tuned_Llama3.2-3B.py:205:50
(EngineCore_DP0 pid=389580) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=389580) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=389580) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=389580) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=389580) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=389580) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=389580) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=389580) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=389580) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=389580) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=389580) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=389580) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=389580) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=389580) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=389580) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=389580) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=389580) $L__tmp1:
(EngineCore_DP0 pid=389580) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=389580) 	bar.sync 	0;
(EngineCore_DP0 pid=389580) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=389580) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=389580) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=389580) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=389580) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=389580) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=389580) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=389580) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=389580) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=389580) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=389580) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=389580) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=389580) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=389580) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=389580) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=389580) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=389580) 	cvt.f32.bf16 	%r63, %rs47;
(EngineCore_DP0 pid=389580) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=389580) 	shfl.sync.bfly.b32 	%r64, %r63, 16, 31, -1;
(EngineCore_DP0 pid=389580) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=389580) 	max.f32 	%r65, %r63, %r64;
(EngineCore_DP0 pid=389580) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=389580) 	shfl.sync.bfly.b32 	%r66, %r65, 8, 31, -1;
(EngineCore_DP0 pid=389580) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=389580) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=389580) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=389580) 	shfl.sync.bfly.b32 	%r68, %r67, 4, 31, -1;
(EngineCore_DP0 pid=389580) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=389580) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=389580) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=389580) 	shfl.sync.bfly.b32 	%r70, %r69, 2, 31, -1;
(EngineCore_DP0 pid=389580) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=389580) 	max.f32 	%r71, %r69, %r70;
(EngineCore_DP0 pid=389580) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=389580) 	shfl.sync.bfly.b32 	%r72, %r71, 1, 31, -1;
(EngineCore_DP0 pid=389580) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=389580) 	max.f32 	%r56, %r71, %r72;
(EngineCore_DP0 pid=389580) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=389580) 	// begin inline asm
(EngineCore_DP0 pid=389580) 	@%p4 st.shared.b32 [ %r55 + 0 ], %r56;
(EngineCore_DP0 pid=389580) 	// end inline asm
(EngineCore_DP0 pid=389580) 	bar.sync 	0;
(EngineCore_DP0 pid=389580) 	// begin inline asm
(EngineCore_DP0 pid=389580) 	@%p5 ld.shared.b32 %r57, [ %r58 + 0 ];
(EngineCore_DP0 pid=389580) 	// end inline asm
(EngineCore_DP0 pid=389580) 	shfl.sync.bfly.b32 	%r73, %r57, 8, 31, -1;
(EngineCore_DP0 pid=389580) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=389580) 	max.f32 	%r74, %r57, %r73;
(EngineCore_DP0 pid=389580) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=389580) 	shfl.sync.bfly.b32 	%r75, %r74, 4, 31, -1;
(EngineCore_DP0 pid=389580) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=389580) 	max.f32 	%r76, %r74, %r75;
(EngineCore_DP0 pid=389580) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=389580) 	shfl.sync.bfly.b32 	%r77, %r76, 2, 31, -1;
(EngineCore_DP0 pid=389580) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=389580) 	max.f32 	%r78, %r76, %r77;
(EngineCore_DP0 pid=389580) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=389580) 	shfl.sync.bfly.b32 	%r79, %r78, 1, 31, -1;
(EngineCore_DP0 pid=389580) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=389580) 	max.f32 	%r60, %r78, %r79;
(EngineCore_DP0 pid=389580) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=389580) 	// begin inline asm
(EngineCore_DP0 pid=389580) 	@%p28 st.shared.b32 [ %r58 + 0 ], %r60;
(EngineCore_DP0 pid=389580) 	// end inline asm
(EngineCore_DP0 pid=389580) 	bar.sync 	0;
(EngineCore_DP0 pid=389580) 	ld.shared.b32 	%r80, [global_smem];
(EngineCore_DP0 pid=389580) $L__tmp2:
(EngineCore_DP0 pid=389580) 	.loc	1 205 36                        // quant_slide_tuned_Llama3.2-3B.py:205:36
(EngineCore_DP0 pid=389580) 	max.f32 	%r138, %r138, %r80;
(EngineCore_DP0 pid=389580) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=389580) 	add.s32 	%r139, %r139, 8192;
(EngineCore_DP0 pid=389580) 	setp.lt.s32 	%p7, %r139, %r22;
(EngineCore_DP0 pid=389580) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=389580) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=389580) 	.loc	1 207 32                        // quant_slide_tuned_Llama3.2-3B.py:207:32
(EngineCore_DP0 pid=389580) 	max.f32 	%r140, %r138, 0f2B8CBCCC;
(EngineCore_DP0 pid=389580) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=389580) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-3B.py:0:32
(EngineCore_DP0 pid=389580) 	mov.b32 	%r82, 0f43E00000;
(EngineCore_DP0 pid=389580) 	.loc	1 208 32                        // quant_slide_tuned_Llama3.2-3B.py:208:32
(EngineCore_DP0 pid=389580) 	div.full.f32 	%r83, %r140, %r82;
(EngineCore_DP0 pid=389580) 	.loc	1 208 41                        // quant_slide_tuned_Llama3.2-3B.py:208:41
(EngineCore_DP0 pid=389580) 	max.f32 	%r81, %r83, 0f36924925;
(EngineCore_DP0 pid=389580) 	.loc	1 210 25                        // quant_slide_tuned_Llama3.2-3B.py:210:25
(EngineCore_DP0 pid=389580) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=389580) 	.loc	1 210 30                        // quant_slide_tuned_Llama3.2-3B.py:210:30
(EngineCore_DP0 pid=389580) 	// begin inline asm
(EngineCore_DP0 pid=389580) 	@%p28 st.global.b32 [ %rd8 + 0 ], { %r81 };
(EngineCore_DP0 pid=389580) 	// end inline asm
(EngineCore_DP0 pid=389580) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=389580) 	setp.lt.s32 	%p9, %r23, 1;
(EngineCore_DP0 pid=389580) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=389580) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=389580) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-3B.py:0:41
(EngineCore_DP0 pid=389580) 	ld.param.b32 	%r27, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=389580) 	shr.s32 	%r28, %r27, 31;
(EngineCore_DP0 pid=389580) 	shr.u32 	%r29, %r28, 30;
(EngineCore_DP0 pid=389580) 	add.s32 	%r30, %r27, %r29;
(EngineCore_DP0 pid=389580) 	shr.s32 	%r31, %r30, 2;
(EngineCore_DP0 pid=389580) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=389580) 	mul.lo.s32 	%r32, %r31, %r1;
(EngineCore_DP0 pid=389580) 	mad.wide.s32 	%rd2, %r32, 4, %rd5;
(EngineCore_DP0 pid=389580) 	div.full.f32 	%r14, %r82, %r140;
(EngineCore_DP0 pid=389580) 	shl.b32 	%r15, %r3, 1;
(EngineCore_DP0 pid=389580) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=389580) 	add.s32 	%r141, %r4, 7;
(EngineCore_DP0 pid=389580) 	mov.b32 	%r142, 0;
(EngineCore_DP0 pid=389580) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=389580)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=389580) 	.loc	1 217 30                        // quant_slide_tuned_Llama3.2-3B.py:217:30
(EngineCore_DP0 pid=389580) 	add.s32 	%r95, %r15, %r142;
(EngineCore_DP0 pid=389580) 	setp.lt.s32 	%p18, %r95, %r23;
(EngineCore_DP0 pid=389580) 	.loc	1 222 22                        // quant_slide_tuned_Llama3.2-3B.py:222:22
(EngineCore_DP0 pid=389580) 	add.s32 	%r96, %r141, -7;
(EngineCore_DP0 pid=389580) 	.loc	1 225 53                        // quant_slide_tuned_Llama3.2-3B.py:225:53
(EngineCore_DP0 pid=389580) 	add.s32 	%r97, %r141, -3;
(EngineCore_DP0 pid=389580) 	setp.lt.s32 	%p19, %r96, %r21;
(EngineCore_DP0 pid=389580) 	setp.lt.s32 	%p20, %r97, %r21;
(EngineCore_DP0 pid=389580) 	.loc	1 225 37                        // quant_slide_tuned_Llama3.2-3B.py:225:37
(EngineCore_DP0 pid=389580) 	and.pred 	%p10, %p18, %p19;
(EngineCore_DP0 pid=389580) 	and.pred 	%p11, %p18, %p20;
(EngineCore_DP0 pid=389580) 	.loc	1 224 29                        // quant_slide_tuned_Llama3.2-3B.py:224:29
(EngineCore_DP0 pid=389580) 	mad.wide.s32 	%rd9, %r96, 2, %rd1;
(EngineCore_DP0 pid=389580) 	add.s64 	%rd10, %rd9, 8;
(EngineCore_DP0 pid=389580) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=389580) 	.loc	1 224 21                        // quant_slide_tuned_Llama3.2-3B.py:224:21
(EngineCore_DP0 pid=389580) 	// begin inline asm
(EngineCore_DP0 pid=389580) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=389580) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=389580) 	// end inline asm
(EngineCore_DP0 pid=389580) 	// begin inline asm
(EngineCore_DP0 pid=389580) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=389580) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=389580) 	// end inline asm
(EngineCore_DP0 pid=389580) 	.loc	1 225 79                        // quant_slide_tuned_Llama3.2-3B.py:225:79
(EngineCore_DP0 pid=389580) 	cvt.f32.bf16 	%r98, %rs48;
(EngineCore_DP0 pid=389580) 	cvt.f32.bf16 	%r99, %rs50;
(EngineCore_DP0 pid=389580) 	.loc	1 227 48                        // quant_slide_tuned_Llama3.2-3B.py:227:48
(EngineCore_DP0 pid=389580) 	add.s32 	%r100, %r141, -6;
(EngineCore_DP0 pid=389580) 	.loc	1 227 53                        // quant_slide_tuned_Llama3.2-3B.py:227:53
(EngineCore_DP0 pid=389580) 	add.s32 	%r101, %r141, -2;
(EngineCore_DP0 pid=389580) 	setp.lt.s32 	%p21, %r100, %r21;
(EngineCore_DP0 pid=389580) 	setp.lt.s32 	%p22, %r101, %r21;
(EngineCore_DP0 pid=389580) 	.loc	1 227 37                        // quant_slide_tuned_Llama3.2-3B.py:227:37
(EngineCore_DP0 pid=389580) 	and.pred 	%p12, %p18, %p21;
(EngineCore_DP0 pid=389580) 	and.pred 	%p13, %p18, %p22;
(EngineCore_DP0 pid=389580) 	.loc	1 226 39                        // quant_slide_tuned_Llama3.2-3B.py:226:39
(EngineCore_DP0 pid=389580) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=389580) 	add.s64 	%rd12, %rd9, 10;
(EngineCore_DP0 pid=389580) 	.loc	1 226 21                        // quant_slide_tuned_Llama3.2-3B.py:226:21
(EngineCore_DP0 pid=389580) 	// begin inline asm
(EngineCore_DP0 pid=389580) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=389580) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=389580) 	// end inline asm
(EngineCore_DP0 pid=389580) 	// begin inline asm
(EngineCore_DP0 pid=389580) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=389580) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=389580) 	// end inline asm
(EngineCore_DP0 pid=389580) 	.loc	1 227 79                        // quant_slide_tuned_Llama3.2-3B.py:227:79
(EngineCore_DP0 pid=389580) 	cvt.f32.bf16 	%r102, %rs52;
(EngineCore_DP0 pid=389580) 	cvt.f32.bf16 	%r103, %rs54;
(EngineCore_DP0 pid=389580) 	.loc	1 229 48                        // quant_slide_tuned_Llama3.2-3B.py:229:48
(EngineCore_DP0 pid=389580) 	add.s32 	%r104, %r141, -5;
(EngineCore_DP0 pid=389580) 	.loc	1 229 53                        // quant_slide_tuned_Llama3.2-3B.py:229:53
(EngineCore_DP0 pid=389580) 	add.s32 	%r105, %r141, -1;
(EngineCore_DP0 pid=389580) 	setp.lt.s32 	%p23, %r104, %r21;
(EngineCore_DP0 pid=389580) 	setp.lt.s32 	%p24, %r105, %r21;
(EngineCore_DP0 pid=389580) 	.loc	1 229 37                        // quant_slide_tuned_Llama3.2-3B.py:229:37
(EngineCore_DP0 pid=389580) 	and.pred 	%p14, %p18, %p23;
(EngineCore_DP0 pid=389580) 	and.pred 	%p15, %p18, %p24;
(EngineCore_DP0 pid=389580) 	.loc	1 228 39                        // quant_slide_tuned_Llama3.2-3B.py:228:39
(EngineCore_DP0 pid=389580) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=389580) 	add.s64 	%rd14, %rd9, 12;
(EngineCore_DP0 pid=389580) 	.loc	1 228 21                        // quant_slide_tuned_Llama3.2-3B.py:228:21
(EngineCore_DP0 pid=389580) 	// begin inline asm
(EngineCore_DP0 pid=389580) 	mov.u16 %rs56, %rs49;
(EngineCore_DP0 pid=389580) 	@%p14 ld.global.b16 { %rs56 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=389580) 	// end inline asm
(EngineCore_DP0 pid=389580) 	// begin inline asm
(EngineCore_DP0 pid=389580) 	mov.u16 %rs58, %rs49;
(EngineCore_DP0 pid=389580) 	@%p15 ld.global.b16 { %rs58 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=389580) 	// end inline asm
(EngineCore_DP0 pid=389580) 	.loc	1 229 79                        // quant_slide_tuned_Llama3.2-3B.py:229:79
(EngineCore_DP0 pid=389580) 	cvt.f32.bf16 	%r106, %rs56;
(EngineCore_DP0 pid=389580) 	cvt.f32.bf16 	%r107, %rs58;
(EngineCore_DP0 pid=389580) 	.loc	1 231 48                        // quant_slide_tuned_Llama3.2-3B.py:231:48
(EngineCore_DP0 pid=389580) 	add.s32 	%r108, %r141, -4;
(EngineCore_DP0 pid=389580) 	.loc	1 231 53                        // quant_slide_tuned_Llama3.2-3B.py:231:53
(EngineCore_DP0 pid=389580) 	setp.lt.s32 	%p25, %r108, %r21;
(EngineCore_DP0 pid=389580) 	setp.lt.s32 	%p26, %r141, %r21;
(EngineCore_DP0 pid=389580) 	.loc	1 231 37                        // quant_slide_tuned_Llama3.2-3B.py:231:37
(EngineCore_DP0 pid=389580) 	and.pred 	%p16, %p18, %p25;
(EngineCore_DP0 pid=389580) 	and.pred 	%p17, %p18, %p26;
(EngineCore_DP0 pid=389580) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-3B.py:230:39
(EngineCore_DP0 pid=389580) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=389580) 	add.s64 	%rd16, %rd9, 14;
(EngineCore_DP0 pid=389580) 	.loc	1 230 21                        // quant_slide_tuned_Llama3.2-3B.py:230:21
(EngineCore_DP0 pid=389580) 	// begin inline asm
(EngineCore_DP0 pid=389580) 	mov.u16 %rs60, %rs49;
(EngineCore_DP0 pid=389580) 	@%p16 ld.global.b16 { %rs60 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=389580) 	// end inline asm
(EngineCore_DP0 pid=389580) 	// begin inline asm
(EngineCore_DP0 pid=389580) 	mov.u16 %rs62, %rs49;
(EngineCore_DP0 pid=389580) 	@%p17 ld.global.b16 { %rs62 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=389580) 	// end inline asm
(EngineCore_DP0 pid=389580) 	.loc	1 231 79                        // quant_slide_tuned_Llama3.2-3B.py:231:79
(EngineCore_DP0 pid=389580) 	cvt.f32.bf16 	%r109, %rs60;
(EngineCore_DP0 pid=389580) 	cvt.f32.bf16 	%r110, %rs62;
(EngineCore_DP0 pid=389580) 	.loc	1 233 27                        // quant_slide_tuned_Llama3.2-3B.py:233:27
(EngineCore_DP0 pid=389580) 	mul.f32 	%r111, %r14, %r98;
(EngineCore_DP0 pid=389580) 	mul.f32 	%r112, %r14, %r99;
(EngineCore_DP0 pid=389580) 	mov.b32 	%r113, 0f43E00000;
(EngineCore_DP0 pid=389580) 	.loc	1 233 48                        // quant_slide_tuned_Llama3.2-3B.py:233:48
(EngineCore_DP0 pid=389580) 	min.xorsign.abs.f32 	%r85, %r111, %r113;
(EngineCore_DP0 pid=389580) 	min.xorsign.abs.f32 	%r86, %r112, %r113;
(EngineCore_DP0 pid=389580) 	.loc	1 233 60                        // quant_slide_tuned_Llama3.2-3B.py:233:60
(EngineCore_DP0 pid=389580) 	// begin inline asm
(EngineCore_DP0 pid=389580) 	cvt.rn.satfinite.e4m3x2.f32  %rs64, %r86, %r85; 
(EngineCore_DP0 pid=389580) 
(EngineCore_DP0 pid=389580) 	// end inline asm
(EngineCore_DP0 pid=389580) 	shr.u16 	%rs68, %rs64, 8;
(EngineCore_DP0 pid=389580) 	.loc	1 234 27                        // quant_slide_tuned_Llama3.2-3B.py:234:27
(EngineCore_DP0 pid=389580) 	mul.f32 	%r114, %r14, %r102;
(EngineCore_DP0 pid=389580) 	mul.f32 	%r115, %r14, %r103;
(EngineCore_DP0 pid=389580) 	.loc	1 234 48                        // quant_slide_tuned_Llama3.2-3B.py:234:48
(EngineCore_DP0 pid=389580) 	min.xorsign.abs.f32 	%r87, %r114, %r113;
(EngineCore_DP0 pid=389580) 	min.xorsign.abs.f32 	%r88, %r115, %r113;
(EngineCore_DP0 pid=389580) 	.loc	1 234 60                        // quant_slide_tuned_Llama3.2-3B.py:234:60
(EngineCore_DP0 pid=389580) 	// begin inline asm
(EngineCore_DP0 pid=389580) 	cvt.rn.satfinite.e4m3x2.f32  %rs65, %r88, %r87; 
(EngineCore_DP0 pid=389580) 
(EngineCore_DP0 pid=389580) 	// end inline asm
(EngineCore_DP0 pid=389580) 	shr.u16 	%rs69, %rs65, 8;
(EngineCore_DP0 pid=389580) 	.loc	1 235 27                        // quant_slide_tuned_Llama3.2-3B.py:235:27
(EngineCore_DP0 pid=389580) 	mul.f32 	%r116, %r14, %r106;
(EngineCore_DP0 pid=389580) 	mul.f32 	%r117, %r14, %r107;
(EngineCore_DP0 pid=389580) 	.loc	1 235 48                        // quant_slide_tuned_Llama3.2-3B.py:235:48
(EngineCore_DP0 pid=389580) 	min.xorsign.abs.f32 	%r89, %r116, %r113;
(EngineCore_DP0 pid=389580) 	min.xorsign.abs.f32 	%r90, %r117, %r113;
(EngineCore_DP0 pid=389580) 	.loc	1 235 60                        // quant_slide_tuned_Llama3.2-3B.py:235:60
(EngineCore_DP0 pid=389580) 	// begin inline asm
(EngineCore_DP0 pid=389580) 	cvt.rn.satfinite.e4m3x2.f32  %rs66, %r90, %r89; 
(EngineCore_DP0 pid=389580) 
(EngineCore_DP0 pid=389580) 	// end inline asm
(EngineCore_DP0 pid=389580) 	shr.u16 	%rs70, %rs66, 8;
(EngineCore_DP0 pid=389580) 	.loc	1 236 27                        // quant_slide_tuned_Llama3.2-3B.py:236:27
(EngineCore_DP0 pid=389580) 	mul.f32 	%r118, %r14, %r109;
(EngineCore_DP0 pid=389580) 	mul.f32 	%r119, %r14, %r110;
(EngineCore_DP0 pid=389580) 	.loc	1 236 48                        // quant_slide_tuned_Llama3.2-3B.py:236:48
(EngineCore_DP0 pid=389580) 	min.xorsign.abs.f32 	%r91, %r118, %r113;
(EngineCore_DP0 pid=389580) 	min.xorsign.abs.f32 	%r92, %r119, %r113;
(EngineCore_DP0 pid=389580) 	.loc	1 236 60                        // quant_slide_tuned_Llama3.2-3B.py:236:60
(EngineCore_DP0 pid=389580) 	// begin inline asm
(EngineCore_DP0 pid=389580) 	cvt.rn.satfinite.e4m3x2.f32  %rs67, %r92, %r91; 
(EngineCore_DP0 pid=389580) 
(EngineCore_DP0 pid=389580) 	// end inline asm
(EngineCore_DP0 pid=389580) 	shr.u16 	%rs71, %rs67, 8;
(EngineCore_DP0 pid=389580) 	.loc	1 238 45                        // quant_slide_tuned_Llama3.2-3B.py:238:45
(EngineCore_DP0 pid=389580) 	cvt.u32.u16 	%r120, %rs64;
(EngineCore_DP0 pid=389580) 	and.b32 	%r121, %r120, 255;
(EngineCore_DP0 pid=389580) 	cvt.u32.u16 	%r122, %rs68;
(EngineCore_DP0 pid=389580) 	.loc	1 240 45                        // quant_slide_tuned_Llama3.2-3B.py:240:45
(EngineCore_DP0 pid=389580) 	cvt.u32.u16 	%r123, %rs66;
(EngineCore_DP0 pid=389580) 	and.b32 	%r124, %r123, 255;
(EngineCore_DP0 pid=389580) 	cvt.u32.u16 	%r125, %rs70;
(EngineCore_DP0 pid=389580) 	.loc	1 241 45                        // quant_slide_tuned_Llama3.2-3B.py:241:45
(EngineCore_DP0 pid=389580) 	cvt.u32.u16 	%r126, %rs67;
(EngineCore_DP0 pid=389580) 	cvt.u32.u16 	%r127, %rs71;
(EngineCore_DP0 pid=389580) 	.loc	1 243 30                        // quant_slide_tuned_Llama3.2-3B.py:243:30
(EngineCore_DP0 pid=389580) 	and.b16 	%rs72, %rs65, 255;
(EngineCore_DP0 pid=389580) 	mul.wide.u16 	%r128, %rs72, 256;
(EngineCore_DP0 pid=389580) 	mul.wide.u16 	%r129, %rs69, 256;
(EngineCore_DP0 pid=389580) 	.loc	1 243 24                        // quant_slide_tuned_Llama3.2-3B.py:243:24
(EngineCore_DP0 pid=389580) 	or.b32 	%r130, %r128, %r121;
(EngineCore_DP0 pid=389580) 	or.b32 	%r131, %r129, %r122;
(EngineCore_DP0 pid=389580) 	.loc	1 243 42                        // quant_slide_tuned_Llama3.2-3B.py:243:42
(EngineCore_DP0 pid=389580) 	shl.b32 	%r132, %r124, 16;
(EngineCore_DP0 pid=389580) 	shl.b32 	%r133, %r125, 16;
(EngineCore_DP0 pid=389580) 	.loc	1 243 36                        // quant_slide_tuned_Llama3.2-3B.py:243:36
(EngineCore_DP0 pid=389580) 	or.b32 	%r134, %r130, %r132;
(EngineCore_DP0 pid=389580) 	or.b32 	%r135, %r131, %r133;
(EngineCore_DP0 pid=389580) 	.loc	1 243 55                        // quant_slide_tuned_Llama3.2-3B.py:243:55
(EngineCore_DP0 pid=389580) 	shl.b32 	%r136, %r126, 24;
(EngineCore_DP0 pid=389580) 	shl.b32 	%r137, %r127, 24;
(EngineCore_DP0 pid=389580) 	.loc	1 243 49                        // quant_slide_tuned_Llama3.2-3B.py:243:49
(EngineCore_DP0 pid=389580) 	or.b32 	%r93, %r134, %r136;
(EngineCore_DP0 pid=389580) 	or.b32 	%r94, %r135, %r137;
(EngineCore_DP0 pid=389580) 	.loc	1 244 29                        // quant_slide_tuned_Llama3.2-3B.py:244:29
(EngineCore_DP0 pid=389580) 	mad.wide.s32 	%rd17, %r95, 4, %rd2;
(EngineCore_DP0 pid=389580) 	.loc	1 244 39                        // quant_slide_tuned_Llama3.2-3B.py:244:39
(EngineCore_DP0 pid=389580) 	// begin inline asm
(EngineCore_DP0 pid=389580) 	@%p18 st.global.v2.b32 [ %rd17 + 0 ], { %r93, %r94 };
(EngineCore_DP0 pid=389580) 	// end inline asm
(EngineCore_DP0 pid=389580) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=389580) 	add.s32 	%r142, %r142, 1024;
(EngineCore_DP0 pid=389580) 	add.s32 	%r141, %r141, 4096;
(EngineCore_DP0 pid=389580) 	setp.lt.s32 	%p27, %r142, %r23;
(EngineCore_DP0 pid=389580) 	@%p27 bra 	$L__BB0_6;
(EngineCore_DP0 pid=389580) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=389580) 	.loc	1 215 4                         // quant_slide_tuned_Llama3.2-3B.py:215:4
(EngineCore_DP0 pid=389580) 	ret;
(EngineCore_DP0 pid=389580) $L__tmp3:
(EngineCore_DP0 pid=389580) $L__func_end0:
(EngineCore_DP0 pid=389580)                                         // -- End function
(EngineCore_DP0 pid=389580) }
(EngineCore_DP0 pid=389580) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py"
(EngineCore_DP0 pid=389580) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=389580) 	.section	.debug_abbrev
(EngineCore_DP0 pid=389580) 	{
(EngineCore_DP0 pid=389580) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=389580) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=389580) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=389580) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=389580) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=389580) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=389580) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=389580) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=389580) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=389580) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=389580) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=389580) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=389580) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=389580) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=389580) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=389580) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=389580) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=389580) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=389580) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=389580) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=389580) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=389580) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=389580) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=389580) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=389580) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=389580) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=389580) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=389580) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=389580) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=389580) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=389580) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=389580) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=389580) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=389580) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=389580) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=389580) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=389580) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=389580) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=389580) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=389580) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=389580) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=389580) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=389580) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=389580) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=389580) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=389580) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=389580) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=389580) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=389580) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=389580) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=389580) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=389580) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=389580) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=389580) 	}
(EngineCore_DP0 pid=389580) 	.section	.debug_info
(EngineCore_DP0 pid=389580) 	{
(EngineCore_DP0 pid=389580) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=389580) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=389580) .b8 0
(EngineCore_DP0 pid=389580) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=389580) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=389580) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=389580) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=389580) .b8 114
(EngineCore_DP0 pid=389580) .b8 105
(EngineCore_DP0 pid=389580) .b8 116
(EngineCore_DP0 pid=389580) .b8 111
(EngineCore_DP0 pid=389580) .b8 110
(EngineCore_DP0 pid=389580) .b8 0
(EngineCore_DP0 pid=389580) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=389580) .b8 0
(EngineCore_DP0 pid=389580) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=389580) .b8 117
(EngineCore_DP0 pid=389580) .b8 97
(EngineCore_DP0 pid=389580) .b8 110
(EngineCore_DP0 pid=389580) .b8 116
(EngineCore_DP0 pid=389580) .b8 95
(EngineCore_DP0 pid=389580) .b8 115
(EngineCore_DP0 pid=389580) .b8 108
(EngineCore_DP0 pid=389580) .b8 105
(EngineCore_DP0 pid=389580) .b8 100
(EngineCore_DP0 pid=389580) .b8 101
(EngineCore_DP0 pid=389580) .b8 95
(EngineCore_DP0 pid=389580) .b8 116
(EngineCore_DP0 pid=389580) .b8 117
(EngineCore_DP0 pid=389580) .b8 110
(EngineCore_DP0 pid=389580) .b8 101
(EngineCore_DP0 pid=389580) .b8 100
(EngineCore_DP0 pid=389580) .b8 95
(EngineCore_DP0 pid=389580) .b8 76
(EngineCore_DP0 pid=389580) .b8 108
(EngineCore_DP0 pid=389580) .b8 97
(EngineCore_DP0 pid=389580) .b8 109
(EngineCore_DP0 pid=389580) .b8 97
(EngineCore_DP0 pid=389580) .b8 51
(EngineCore_DP0 pid=389580) .b8 46
(EngineCore_DP0 pid=389580) .b8 50
(EngineCore_DP0 pid=389580) .b8 45
(EngineCore_DP0 pid=389580) .b8 51
(EngineCore_DP0 pid=389580) .b8 66
(EngineCore_DP0 pid=389580) .b8 46
(EngineCore_DP0 pid=389580) .b8 112
(EngineCore_DP0 pid=389580) .b8 121
(EngineCore_DP0 pid=389580) .b8 0
(EngineCore_DP0 pid=389580) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=389580) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=389580) .b8 114
(EngineCore_DP0 pid=389580) .b8 111
(EngineCore_DP0 pid=389580) .b8 111
(EngineCore_DP0 pid=389580) .b8 116
(EngineCore_DP0 pid=389580) .b8 47
(EngineCore_DP0 pid=389580) .b8 118
(EngineCore_DP0 pid=389580) .b8 108
(EngineCore_DP0 pid=389580) .b8 108
(EngineCore_DP0 pid=389580) .b8 109
(EngineCore_DP0 pid=389580) .b8 98
(EngineCore_DP0 pid=389580) .b8 101
(EngineCore_DP0 pid=389580) .b8 110
(EngineCore_DP0 pid=389580) .b8 99
(EngineCore_DP0 pid=389580) .b8 104
(EngineCore_DP0 pid=389580) .b8 47
(EngineCore_DP0 pid=389580) .b8 115
(EngineCore_DP0 pid=389580) .b8 108
(EngineCore_DP0 pid=389580) .b8 105
(EngineCore_DP0 pid=389580) .b8 100
(EngineCore_DP0 pid=389580) .b8 101
(EngineCore_DP0 pid=389580) .b8 115
(EngineCore_DP0 pid=389580) .b8 112
(EngineCore_DP0 pid=389580) .b8 97
(EngineCore_DP0 pid=389580) .b8 114
(EngineCore_DP0 pid=389580) .b8 115
(EngineCore_DP0 pid=389580) .b8 101
(EngineCore_DP0 pid=389580) .b8 47
(EngineCore_DP0 pid=389580) .b8 99
(EngineCore_DP0 pid=389580) .b8 115
(EngineCore_DP0 pid=389580) .b8 114
(EngineCore_DP0 pid=389580) .b8 99
(EngineCore_DP0 pid=389580) .b8 47
(EngineCore_DP0 pid=389580) .b8 102
(EngineCore_DP0 pid=389580) .b8 117
(EngineCore_DP0 pid=389580) .b8 115
(EngineCore_DP0 pid=389580) .b8 101
(EngineCore_DP0 pid=389580) .b8 100
(EngineCore_DP0 pid=389580) .b8 95
(EngineCore_DP0 pid=389580) .b8 113
(EngineCore_DP0 pid=389580) .b8 117
(EngineCore_DP0 pid=389580) .b8 97
(EngineCore_DP0 pid=389580) .b8 110
(EngineCore_DP0 pid=389580) .b8 116
(EngineCore_DP0 pid=389580) .b8 95
(EngineCore_DP0 pid=389580) .b8 115
(EngineCore_DP0 pid=389580) .b8 108
(EngineCore_DP0 pid=389580) .b8 105
(EngineCore_DP0 pid=389580) .b8 100
(EngineCore_DP0 pid=389580) .b8 101
(EngineCore_DP0 pid=389580) .b8 95
(EngineCore_DP0 pid=389580) .b8 116
(EngineCore_DP0 pid=389580) .b8 114
(EngineCore_DP0 pid=389580) .b8 105
(EngineCore_DP0 pid=389580) .b8 116
(EngineCore_DP0 pid=389580) .b8 111
(EngineCore_DP0 pid=389580) .b8 110
(EngineCore_DP0 pid=389580) .b8 47
(EngineCore_DP0 pid=389580) .b8 98
(EngineCore_DP0 pid=389580) .b8 117
(EngineCore_DP0 pid=389580) .b8 105
(EngineCore_DP0 pid=389580) .b8 108
(EngineCore_DP0 pid=389580) .b8 100
(EngineCore_DP0 pid=389580) .b8 47
(EngineCore_DP0 pid=389580) .b8 71
(EngineCore_DP0 pid=389580) .b8 66
(EngineCore_DP0 pid=389580) .b8 49
(EngineCore_DP0 pid=389580) .b8 48
(EngineCore_DP0 pid=389580) .b8 95
(EngineCore_DP0 pid=389580) .b8 99
(EngineCore_DP0 pid=389580) .b8 99
(EngineCore_DP0 pid=389580) .b8 49
(EngineCore_DP0 pid=389580) .b8 50
(EngineCore_DP0 pid=389580) .b8 49
(EngineCore_DP0 pid=389580) .b8 95
(EngineCore_DP0 pid=389580) .b8 112
(EngineCore_DP0 pid=389580) .b8 121
(EngineCore_DP0 pid=389580) .b8 51
(EngineCore_DP0 pid=389580) .b8 49
(EngineCore_DP0 pid=389580) .b8 50
(EngineCore_DP0 pid=389580) .b8 95
(EngineCore_DP0 pid=389580) .b8 99
(EngineCore_DP0 pid=389580) .b8 117
(EngineCore_DP0 pid=389580) .b8 49
(EngineCore_DP0 pid=389580) .b8 50
(EngineCore_DP0 pid=389580) .b8 57
(EngineCore_DP0 pid=389580) .b8 95
(EngineCore_DP0 pid=389580) .b8 97
(EngineCore_DP0 pid=389580) .b8 97
(EngineCore_DP0 pid=389580) .b8 114
(EngineCore_DP0 pid=389580) .b8 99
(EngineCore_DP0 pid=389580) .b8 104
(EngineCore_DP0 pid=389580) .b8 54
(EngineCore_DP0 pid=389580) .b8 52
(EngineCore_DP0 pid=389580) .b8 0
(EngineCore_DP0 pid=389580) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=389580) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=389580) .b8 113
(EngineCore_DP0 pid=389580) .b8 117
(EngineCore_DP0 pid=389580) .b8 97
(EngineCore_DP0 pid=389580) .b8 110
(EngineCore_DP0 pid=389580) .b8 116
(EngineCore_DP0 pid=389580) .b8 95
(EngineCore_DP0 pid=389580) .b8 115
(EngineCore_DP0 pid=389580) .b8 108
(EngineCore_DP0 pid=389580) .b8 105
(EngineCore_DP0 pid=389580) .b8 100
(EngineCore_DP0 pid=389580) .b8 101
(EngineCore_DP0 pid=389580) .b8 95
(EngineCore_DP0 pid=389580) .b8 102
(EngineCore_DP0 pid=389580) .b8 112
(EngineCore_DP0 pid=389580) .b8 56
(EngineCore_DP0 pid=389580) .b8 95
(EngineCore_DP0 pid=389580) .b8 107
(EngineCore_DP0 pid=389580) .b8 101
(EngineCore_DP0 pid=389580) .b8 114
(EngineCore_DP0 pid=389580) .b8 110
(EngineCore_DP0 pid=389580) .b8 101
(EngineCore_DP0 pid=389580) .b8 108
(EngineCore_DP0 pid=389580) .b8 0
(EngineCore_DP0 pid=389580) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=389580) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=389580) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=389580) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=389580) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=389580) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=389580) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=389580) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=389580) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=389580) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=389580) .b8 205                                 // DW_AT_call_line
(EngineCore_DP0 pid=389580) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=389580) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=389580) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=389580) 	}
(EngineCore_DP0 pid=389580) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=389580) 
(EngineCore_DP0 pid=389580) ================================================================
(EngineCore_DP0 pid=389580) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=389580) 
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp4pjuuk_f.ptx', '-o', '/tmp/tmp4pjuuk_f.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866] 
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866] 
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866] 
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp4pjuuk_f.ptx -o /tmp/tmp4pjuuk_f.ptx.o
(EngineCore_DP0 pid=389580) ERROR 01-25 20:02:15 [core.py:866] 

STDERR:
[2026-01-25 20:01:53] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:01:53] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:01:53] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:01:53] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:01:53] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:01:53] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:01:53] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:01:53] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:01:53] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:01:53] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:01:53] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:01:53] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:01:53] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:01:53] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:01:56] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:01:56] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:01:56] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:01:56] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:01:56] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:01:56] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:01:56] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:01:56] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:01:56] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:01:56] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:01:56] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:01:56] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:01:56] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:01:56] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=389580) [2026-01-25 20:01:57] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=389580) [2026-01-25 20:01:57] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=389580) [2026-01-25 20:01:57] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=389580) [2026-01-25 20:01:57] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=389580) [2026-01-25 20:01:57] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=389580) [2026-01-25 20:01:57] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=389580) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=389580) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:15<00:00, 15.75s/it]
(EngineCore_DP0 pid=389580) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:15<00:00, 15.75s/it]
(EngineCore_DP0 pid=389580) 
(EngineCore_DP0 pid=389580) [2026-01-25 20:02:14] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 3072] -> 1D uint8
(EngineCore_DP0 pid=389580) [2026-01-25 20:02:14] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9830400 bytes
(EngineCore_DP0 pid=389580) [2026-01-25 20:02:14] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=389580) [2026-01-25 20:02:14] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5898240 bytes
(EngineCore_DP0 pid=389580) [2026-01-25 20:02:14] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=389580) [2026-01-25 20:02:14] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 31457280 bytes
(EngineCore_DP0 pid=389580) [2026-01-25 20:02:14] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 8192] -> 1D uint8
(EngineCore_DP0 pid=389580) [2026-01-25 20:02:14] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15728640 bytes
(EngineCore_DP0 pid=389580) Process EngineCore_DP0:
(EngineCore_DP0 pid=389580) Traceback (most recent call last):
(EngineCore_DP0 pid=389580)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=389580)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=389580)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=389580)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=389580) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp4pjuuk_f.ptx', '-o', '/tmp/tmp4pjuuk_f.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=389580) 
(EngineCore_DP0 pid=389580) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=389580) 
(EngineCore_DP0 pid=389580) Traceback (most recent call last):
(EngineCore_DP0 pid=389580)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=389580)     self.run()
(EngineCore_DP0 pid=389580)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=389580)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=389580)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=389580)     raise e
(EngineCore_DP0 pid=389580)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=389580)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=389580)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=389580)     super().__init__(
(EngineCore_DP0 pid=389580)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=389580)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=389580)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=389580)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=389580)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=389580)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=389580)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=389580)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=389580)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=389580)     return func(*args, **kwargs)
(EngineCore_DP0 pid=389580)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=389580)     return func(*args, **kwargs)
(EngineCore_DP0 pid=389580)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=389580)     self.model_runner.profile_run()
(EngineCore_DP0 pid=389580)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=389580)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=389580)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=389580)     return func(*args, **kwargs)
(EngineCore_DP0 pid=389580)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=389580)     outputs = self.model(
(EngineCore_DP0 pid=389580)               ^^^^^^^^^^^
(EngineCore_DP0 pid=389580)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=389580)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=389580)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=389580)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=389580)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=389580)     model_output = self.model(
(EngineCore_DP0 pid=389580)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=389580)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=389580)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=389580)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=389580)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=389580)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=389580)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=389580)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=389580)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=389580)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=389580)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=389580)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=389580)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=389580)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=389580)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=389580)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=389580)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=389580)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=389580)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=389580)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=389580)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=389580)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=389580)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=389580)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=389580)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=389580)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=389580)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=389580)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=389580)     return self._linear_fn(
(EngineCore_DP0 pid=389580)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=389580)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=389580)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=389580)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=389580)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=389580)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=389580)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=389580)     return fn(input, L)
(EngineCore_DP0 pid=389580)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=389580)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=389580)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=389580)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=389580)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=389580)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=389580)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=389580)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=389580)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=389580)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=389580)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=389580)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=389580)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=389580)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=389580)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=389580)     raise PTXASError(error)
(EngineCore_DP0 pid=389580) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=389580) `ptxas` stderr:
(EngineCore_DP0 pid=389580) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=389580) 
(EngineCore_DP0 pid=389580) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp4pjuuk_f.ptx -o /tmp/tmp4pjuuk_f.ptx.o
(EngineCore_DP0 pid=389580) 
[rank0]:[W125 20:02:15.511496430 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=8192

========== M=16384 ==========
Time: 2026-01-25 20:02:16
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Llama3.2-3B-FP8_M16384.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:02:26 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 20:02:26 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=390230) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=390230) 
(EngineCore_DP0 pid=390230) 
(EngineCore_DP0 pid=390230) ================================================================
(EngineCore_DP0 pid=390230) Internal Triton PTX codegen error
(EngineCore_DP0 pid=390230) `ptxas` stderr:
(EngineCore_DP0 pid=390230) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=390230) 
(EngineCore_DP0 pid=390230) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpetq_0m9g.ptx -o /tmp/tmpetq_0m9g.ptx.o
(EngineCore_DP0 pid=390230) 
(EngineCore_DP0 pid=390230) 
(EngineCore_DP0 pid=390230) //
(EngineCore_DP0 pid=390230) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=390230) //
(EngineCore_DP0 pid=390230) 
(EngineCore_DP0 pid=390230) .version 8.7
(EngineCore_DP0 pid=390230) .target sm_121a
(EngineCore_DP0 pid=390230) .address_size 64
(EngineCore_DP0 pid=390230) 
(EngineCore_DP0 pid=390230) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=390230) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=390230)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=390230) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=390230) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=390230) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=390230) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=390230) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=390230) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=390230) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=390230) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=390230) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=390230) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=390230) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=390230) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=390230) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=390230) )
(EngineCore_DP0 pid=390230) .reqntid 512
(EngineCore_DP0 pid=390230) {
(EngineCore_DP0 pid=390230) 	.reg .pred 	%p<29>;
(EngineCore_DP0 pid=390230) 	.reg .b16 	%rs<73>;
(EngineCore_DP0 pid=390230) 	.reg .b32 	%r<143>;
(EngineCore_DP0 pid=390230) 	.reg .b64 	%rd<18>;
(EngineCore_DP0 pid=390230) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=390230) $L__func_begin0:
(EngineCore_DP0 pid=390230) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=390230) 
(EngineCore_DP0 pid=390230) // %bb.0:
(EngineCore_DP0 pid=390230) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=390230) 	ld.param.b32 	%r22, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=390230) 	ld.param.b32 	%r21, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=390230) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=390230) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=390230) $L__tmp0:
(EngineCore_DP0 pid=390230) 	.loc	1 191 24                        // quant_slide_tuned_Llama3.2-3B.py:191:24
(EngineCore_DP0 pid=390230) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=390230) 	ld.param.b32 	%r25, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=390230) 	.loc	1 196 26                        // quant_slide_tuned_Llama3.2-3B.py:196:26
(EngineCore_DP0 pid=390230) 	mul.lo.s32 	%r26, %r25, %r1;
(EngineCore_DP0 pid=390230) 	.loc	1 196 20                        // quant_slide_tuned_Llama3.2-3B.py:196:20
(EngineCore_DP0 pid=390230) 	mad.wide.s32 	%rd1, %r26, 2, %rd4;
(EngineCore_DP0 pid=390230) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=390230) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=390230) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=390230) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=390230) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=390230) 	setp.lt.s32 	%p1, %r22, 1;
(EngineCore_DP0 pid=390230) 	mov.b32 	%r140, 0f2B8CBCCC;
(EngineCore_DP0 pid=390230) 	setp.eq.b32 	%p28, %r2, 0;
(EngineCore_DP0 pid=390230) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=390230) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=390230) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=390230) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=390230) 	shr.u32 	%r35, %r2, 3;
(EngineCore_DP0 pid=390230) 	and.b32 	%r36, %r35, 60;
(EngineCore_DP0 pid=390230) 	mov.b32 	%r37, global_smem;
(EngineCore_DP0 pid=390230) 	add.s32 	%r55, %r37, %r36;
(EngineCore_DP0 pid=390230) 	shl.b32 	%r38, %r2, 2;
(EngineCore_DP0 pid=390230) 	add.s32 	%r58, %r37, %r38;
(EngineCore_DP0 pid=390230) 	mov.b32 	%r43, 0;
(EngineCore_DP0 pid=390230) 	mov.b32 	%r138, 0f00000000;
(EngineCore_DP0 pid=390230) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=390230) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=390230) 	mov.b32 	%r139, %r43;
(EngineCore_DP0 pid=390230) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=390230) 	.loc	1 202 19                        // quant_slide_tuned_Llama3.2-3B.py:202:19
(EngineCore_DP0 pid=390230) 	add.s32 	%r61, %r4, %r139;
(EngineCore_DP0 pid=390230) 	.loc	1 203 22                        // quant_slide_tuned_Llama3.2-3B.py:203:22
(EngineCore_DP0 pid=390230) 	add.s32 	%r62, %r61, 4096;
(EngineCore_DP0 pid=390230) 	setp.lt.s32 	%p2, %r61, %r21;
(EngineCore_DP0 pid=390230) 	setp.lt.s32 	%p3, %r62, %r21;
(EngineCore_DP0 pid=390230) 	.loc	1 204 29                        // quant_slide_tuned_Llama3.2-3B.py:204:29
(EngineCore_DP0 pid=390230) 	mad.wide.s32 	%rd6, %r61, 2, %rd1;
(EngineCore_DP0 pid=390230) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=390230) 	.loc	1 204 21                        // quant_slide_tuned_Llama3.2-3B.py:204:21
(EngineCore_DP0 pid=390230) 	// begin inline asm
(EngineCore_DP0 pid=390230) 	mov.u32 %r39, %r43;
(EngineCore_DP0 pid=390230) 	mov.u32 %r40, %r43;
(EngineCore_DP0 pid=390230) 	mov.u32 %r41, %r43;
(EngineCore_DP0 pid=390230) 	mov.u32 %r42, %r43;
(EngineCore_DP0 pid=390230) 	@%p2 ld.global.v4.b32 { %r39, %r40, %r41, %r42 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=390230) 	// end inline asm
(EngineCore_DP0 pid=390230) 	mov.b32 	{%rs1, %rs2}, %r39;
(EngineCore_DP0 pid=390230) 	mov.b32 	{%rs3, %rs4}, %r40;
(EngineCore_DP0 pid=390230) 	mov.b32 	{%rs5, %rs6}, %r41;
(EngineCore_DP0 pid=390230) 	mov.b32 	{%rs7, %rs8}, %r42;
(EngineCore_DP0 pid=390230) 	// begin inline asm
(EngineCore_DP0 pid=390230) 	mov.u32 %r47, %r43;
(EngineCore_DP0 pid=390230) 	mov.u32 %r48, %r43;
(EngineCore_DP0 pid=390230) 	mov.u32 %r49, %r43;
(EngineCore_DP0 pid=390230) 	mov.u32 %r50, %r43;
(EngineCore_DP0 pid=390230) 	@%p3 ld.global.v4.b32 { %r47, %r48, %r49, %r50 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=390230) 	// end inline asm
(EngineCore_DP0 pid=390230) 	mov.b32 	{%rs9, %rs10}, %r47;
(EngineCore_DP0 pid=390230) 	mov.b32 	{%rs11, %rs12}, %r48;
(EngineCore_DP0 pid=390230) 	mov.b32 	{%rs13, %rs14}, %r49;
(EngineCore_DP0 pid=390230) 	mov.b32 	{%rs15, %rs16}, %r50;
(EngineCore_DP0 pid=390230) 	.loc	1 205 50                        // quant_slide_tuned_Llama3.2-3B.py:205:50
(EngineCore_DP0 pid=390230) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=390230) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=390230) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=390230) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=390230) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=390230) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=390230) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=390230) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=390230) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=390230) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=390230) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=390230) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=390230) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=390230) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=390230) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=390230) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=390230) $L__tmp1:
(EngineCore_DP0 pid=390230) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=390230) 	bar.sync 	0;
(EngineCore_DP0 pid=390230) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=390230) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=390230) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=390230) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=390230) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=390230) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=390230) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=390230) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=390230) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=390230) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=390230) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=390230) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=390230) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=390230) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=390230) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=390230) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=390230) 	cvt.f32.bf16 	%r63, %rs47;
(EngineCore_DP0 pid=390230) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=390230) 	shfl.sync.bfly.b32 	%r64, %r63, 16, 31, -1;
(EngineCore_DP0 pid=390230) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=390230) 	max.f32 	%r65, %r63, %r64;
(EngineCore_DP0 pid=390230) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=390230) 	shfl.sync.bfly.b32 	%r66, %r65, 8, 31, -1;
(EngineCore_DP0 pid=390230) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=390230) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=390230) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=390230) 	shfl.sync.bfly.b32 	%r68, %r67, 4, 31, -1;
(EngineCore_DP0 pid=390230) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=390230) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=390230) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=390230) 	shfl.sync.bfly.b32 	%r70, %r69, 2, 31, -1;
(EngineCore_DP0 pid=390230) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=390230) 	max.f32 	%r71, %r69, %r70;
(EngineCore_DP0 pid=390230) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=390230) 	shfl.sync.bfly.b32 	%r72, %r71, 1, 31, -1;
(EngineCore_DP0 pid=390230) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=390230) 	max.f32 	%r56, %r71, %r72;
(EngineCore_DP0 pid=390230) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=390230) 	// begin inline asm
(EngineCore_DP0 pid=390230) 	@%p4 st.shared.b32 [ %r55 + 0 ], %r56;
(EngineCore_DP0 pid=390230) 	// end inline asm
(EngineCore_DP0 pid=390230) 	bar.sync 	0;
(EngineCore_DP0 pid=390230) 	// begin inline asm
(EngineCore_DP0 pid=390230) 	@%p5 ld.shared.b32 %r57, [ %r58 + 0 ];
(EngineCore_DP0 pid=390230) 	// end inline asm
(EngineCore_DP0 pid=390230) 	shfl.sync.bfly.b32 	%r73, %r57, 8, 31, -1;
(EngineCore_DP0 pid=390230) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=390230) 	max.f32 	%r74, %r57, %r73;
(EngineCore_DP0 pid=390230) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=390230) 	shfl.sync.bfly.b32 	%r75, %r74, 4, 31, -1;
(EngineCore_DP0 pid=390230) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=390230) 	max.f32 	%r76, %r74, %r75;
(EngineCore_DP0 pid=390230) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=390230) 	shfl.sync.bfly.b32 	%r77, %r76, 2, 31, -1;
(EngineCore_DP0 pid=390230) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=390230) 	max.f32 	%r78, %r76, %r77;
(EngineCore_DP0 pid=390230) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=390230) 	shfl.sync.bfly.b32 	%r79, %r78, 1, 31, -1;
(EngineCore_DP0 pid=390230) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=390230) 	max.f32 	%r60, %r78, %r79;
(EngineCore_DP0 pid=390230) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=390230) 	// begin inline asm
(EngineCore_DP0 pid=390230) 	@%p28 st.shared.b32 [ %r58 + 0 ], %r60;
(EngineCore_DP0 pid=390230) 	// end inline asm
(EngineCore_DP0 pid=390230) 	bar.sync 	0;
(EngineCore_DP0 pid=390230) 	ld.shared.b32 	%r80, [global_smem];
(EngineCore_DP0 pid=390230) $L__tmp2:
(EngineCore_DP0 pid=390230) 	.loc	1 205 36                        // quant_slide_tuned_Llama3.2-3B.py:205:36
(EngineCore_DP0 pid=390230) 	max.f32 	%r138, %r138, %r80;
(EngineCore_DP0 pid=390230) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=390230) 	add.s32 	%r139, %r139, 8192;
(EngineCore_DP0 pid=390230) 	setp.lt.s32 	%p7, %r139, %r22;
(EngineCore_DP0 pid=390230) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=390230) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=390230) 	.loc	1 207 32                        // quant_slide_tuned_Llama3.2-3B.py:207:32
(EngineCore_DP0 pid=390230) 	max.f32 	%r140, %r138, 0f2B8CBCCC;
(EngineCore_DP0 pid=390230) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=390230) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-3B.py:0:32
(EngineCore_DP0 pid=390230) 	mov.b32 	%r82, 0f43E00000;
(EngineCore_DP0 pid=390230) 	.loc	1 208 32                        // quant_slide_tuned_Llama3.2-3B.py:208:32
(EngineCore_DP0 pid=390230) 	div.full.f32 	%r83, %r140, %r82;
(EngineCore_DP0 pid=390230) 	.loc	1 208 41                        // quant_slide_tuned_Llama3.2-3B.py:208:41
(EngineCore_DP0 pid=390230) 	max.f32 	%r81, %r83, 0f36924925;
(EngineCore_DP0 pid=390230) 	.loc	1 210 25                        // quant_slide_tuned_Llama3.2-3B.py:210:25
(EngineCore_DP0 pid=390230) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=390230) 	.loc	1 210 30                        // quant_slide_tuned_Llama3.2-3B.py:210:30
(EngineCore_DP0 pid=390230) 	// begin inline asm
(EngineCore_DP0 pid=390230) 	@%p28 st.global.b32 [ %rd8 + 0 ], { %r81 };
(EngineCore_DP0 pid=390230) 	// end inline asm
(EngineCore_DP0 pid=390230) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=390230) 	setp.lt.s32 	%p9, %r23, 1;
(EngineCore_DP0 pid=390230) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=390230) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=390230) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-3B.py:0:41
(EngineCore_DP0 pid=390230) 	ld.param.b32 	%r27, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=390230) 	shr.s32 	%r28, %r27, 31;
(EngineCore_DP0 pid=390230) 	shr.u32 	%r29, %r28, 30;
(EngineCore_DP0 pid=390230) 	add.s32 	%r30, %r27, %r29;
(EngineCore_DP0 pid=390230) 	shr.s32 	%r31, %r30, 2;
(EngineCore_DP0 pid=390230) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=390230) 	mul.lo.s32 	%r32, %r31, %r1;
(EngineCore_DP0 pid=390230) 	mad.wide.s32 	%rd2, %r32, 4, %rd5;
(EngineCore_DP0 pid=390230) 	div.full.f32 	%r14, %r82, %r140;
(EngineCore_DP0 pid=390230) 	shl.b32 	%r15, %r3, 1;
(EngineCore_DP0 pid=390230) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=390230) 	add.s32 	%r141, %r4, 7;
(EngineCore_DP0 pid=390230) 	mov.b32 	%r142, 0;
(EngineCore_DP0 pid=390230) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=390230)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=390230) 	.loc	1 217 30                        // quant_slide_tuned_Llama3.2-3B.py:217:30
(EngineCore_DP0 pid=390230) 	add.s32 	%r95, %r15, %r142;
(EngineCore_DP0 pid=390230) 	setp.lt.s32 	%p18, %r95, %r23;
(EngineCore_DP0 pid=390230) 	.loc	1 222 22                        // quant_slide_tuned_Llama3.2-3B.py:222:22
(EngineCore_DP0 pid=390230) 	add.s32 	%r96, %r141, -7;
(EngineCore_DP0 pid=390230) 	.loc	1 225 53                        // quant_slide_tuned_Llama3.2-3B.py:225:53
(EngineCore_DP0 pid=390230) 	add.s32 	%r97, %r141, -3;
(EngineCore_DP0 pid=390230) 	setp.lt.s32 	%p19, %r96, %r21;
(EngineCore_DP0 pid=390230) 	setp.lt.s32 	%p20, %r97, %r21;
(EngineCore_DP0 pid=390230) 	.loc	1 225 37                        // quant_slide_tuned_Llama3.2-3B.py:225:37
(EngineCore_DP0 pid=390230) 	and.pred 	%p10, %p18, %p19;
(EngineCore_DP0 pid=390230) 	and.pred 	%p11, %p18, %p20;
(EngineCore_DP0 pid=390230) 	.loc	1 224 29                        // quant_slide_tuned_Llama3.2-3B.py:224:29
(EngineCore_DP0 pid=390230) 	mad.wide.s32 	%rd9, %r96, 2, %rd1;
(EngineCore_DP0 pid=390230) 	add.s64 	%rd10, %rd9, 8;
(EngineCore_DP0 pid=390230) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=390230) 	.loc	1 224 21                        // quant_slide_tuned_Llama3.2-3B.py:224:21
(EngineCore_DP0 pid=390230) 	// begin inline asm
(EngineCore_DP0 pid=390230) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=390230) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=390230) 	// end inline asm
(EngineCore_DP0 pid=390230) 	// begin inline asm
(EngineCore_DP0 pid=390230) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=390230) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=390230) 	// end inline asm
(EngineCore_DP0 pid=390230) 	.loc	1 225 79                        // quant_slide_tuned_Llama3.2-3B.py:225:79
(EngineCore_DP0 pid=390230) 	cvt.f32.bf16 	%r98, %rs48;
(EngineCore_DP0 pid=390230) 	cvt.f32.bf16 	%r99, %rs50;
(EngineCore_DP0 pid=390230) 	.loc	1 227 48                        // quant_slide_tuned_Llama3.2-3B.py:227:48
(EngineCore_DP0 pid=390230) 	add.s32 	%r100, %r141, -6;
(EngineCore_DP0 pid=390230) 	.loc	1 227 53                        // quant_slide_tuned_Llama3.2-3B.py:227:53
(EngineCore_DP0 pid=390230) 	add.s32 	%r101, %r141, -2;
(EngineCore_DP0 pid=390230) 	setp.lt.s32 	%p21, %r100, %r21;
(EngineCore_DP0 pid=390230) 	setp.lt.s32 	%p22, %r101, %r21;
(EngineCore_DP0 pid=390230) 	.loc	1 227 37                        // quant_slide_tuned_Llama3.2-3B.py:227:37
(EngineCore_DP0 pid=390230) 	and.pred 	%p12, %p18, %p21;
(EngineCore_DP0 pid=390230) 	and.pred 	%p13, %p18, %p22;
(EngineCore_DP0 pid=390230) 	.loc	1 226 39                        // quant_slide_tuned_Llama3.2-3B.py:226:39
(EngineCore_DP0 pid=390230) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=390230) 	add.s64 	%rd12, %rd9, 10;
(EngineCore_DP0 pid=390230) 	.loc	1 226 21                        // quant_slide_tuned_Llama3.2-3B.py:226:21
(EngineCore_DP0 pid=390230) 	// begin inline asm
(EngineCore_DP0 pid=390230) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=390230) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=390230) 	// end inline asm
(EngineCore_DP0 pid=390230) 	// begin inline asm
(EngineCore_DP0 pid=390230) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=390230) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=390230) 	// end inline asm
(EngineCore_DP0 pid=390230) 	.loc	1 227 79                        // quant_slide_tuned_Llama3.2-3B.py:227:79
(EngineCore_DP0 pid=390230) 	cvt.f32.bf16 	%r102, %rs52;
(EngineCore_DP0 pid=390230) 	cvt.f32.bf16 	%r103, %rs54;
(EngineCore_DP0 pid=390230) 	.loc	1 229 48                        // quant_slide_tuned_Llama3.2-3B.py:229:48
(EngineCore_DP0 pid=390230) 	add.s32 	%r104, %r141, -5;
(EngineCore_DP0 pid=390230) 	.loc	1 229 53                        // quant_slide_tuned_Llama3.2-3B.py:229:53
(EngineCore_DP0 pid=390230) 	add.s32 	%r105, %r141, -1;
(EngineCore_DP0 pid=390230) 	setp.lt.s32 	%p23, %r104, %r21;
(EngineCore_DP0 pid=390230) 	setp.lt.s32 	%p24, %r105, %r21;
(EngineCore_DP0 pid=390230) 	.loc	1 229 37                        // quant_slide_tuned_Llama3.2-3B.py:229:37
(EngineCore_DP0 pid=390230) 	and.pred 	%p14, %p18, %p23;
(EngineCore_DP0 pid=390230) 	and.pred 	%p15, %p18, %p24;
(EngineCore_DP0 pid=390230) 	.loc	1 228 39                        // quant_slide_tuned_Llama3.2-3B.py:228:39
(EngineCore_DP0 pid=390230) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=390230) 	add.s64 	%rd14, %rd9, 12;
(EngineCore_DP0 pid=390230) 	.loc	1 228 21                        // quant_slide_tuned_Llama3.2-3B.py:228:21
(EngineCore_DP0 pid=390230) 	// begin inline asm
(EngineCore_DP0 pid=390230) 	mov.u16 %rs56, %rs49;
(EngineCore_DP0 pid=390230) 	@%p14 ld.global.b16 { %rs56 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=390230) 	// end inline asm
(EngineCore_DP0 pid=390230) 	// begin inline asm
(EngineCore_DP0 pid=390230) 	mov.u16 %rs58, %rs49;
(EngineCore_DP0 pid=390230) 	@%p15 ld.global.b16 { %rs58 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=390230) 	// end inline asm
(EngineCore_DP0 pid=390230) 	.loc	1 229 79                        // quant_slide_tuned_Llama3.2-3B.py:229:79
(EngineCore_DP0 pid=390230) 	cvt.f32.bf16 	%r106, %rs56;
(EngineCore_DP0 pid=390230) 	cvt.f32.bf16 	%r107, %rs58;
(EngineCore_DP0 pid=390230) 	.loc	1 231 48                        // quant_slide_tuned_Llama3.2-3B.py:231:48
(EngineCore_DP0 pid=390230) 	add.s32 	%r108, %r141, -4;
(EngineCore_DP0 pid=390230) 	.loc	1 231 53                        // quant_slide_tuned_Llama3.2-3B.py:231:53
(EngineCore_DP0 pid=390230) 	setp.lt.s32 	%p25, %r108, %r21;
(EngineCore_DP0 pid=390230) 	setp.lt.s32 	%p26, %r141, %r21;
(EngineCore_DP0 pid=390230) 	.loc	1 231 37                        // quant_slide_tuned_Llama3.2-3B.py:231:37
(EngineCore_DP0 pid=390230) 	and.pred 	%p16, %p18, %p25;
(EngineCore_DP0 pid=390230) 	and.pred 	%p17, %p18, %p26;
(EngineCore_DP0 pid=390230) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-3B.py:230:39
(EngineCore_DP0 pid=390230) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=390230) 	add.s64 	%rd16, %rd9, 14;
(EngineCore_DP0 pid=390230) 	.loc	1 230 21                        // quant_slide_tuned_Llama3.2-3B.py:230:21
(EngineCore_DP0 pid=390230) 	// begin inline asm
(EngineCore_DP0 pid=390230) 	mov.u16 %rs60, %rs49;
(EngineCore_DP0 pid=390230) 	@%p16 ld.global.b16 { %rs60 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=390230) 	// end inline asm
(EngineCore_DP0 pid=390230) 	// begin inline asm
(EngineCore_DP0 pid=390230) 	mov.u16 %rs62, %rs49;
(EngineCore_DP0 pid=390230) 	@%p17 ld.global.b16 { %rs62 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=390230) 	// end inline asm
(EngineCore_DP0 pid=390230) 	.loc	1 231 79                        // quant_slide_tuned_Llama3.2-3B.py:231:79
(EngineCore_DP0 pid=390230) 	cvt.f32.bf16 	%r109, %rs60;
(EngineCore_DP0 pid=390230) 	cvt.f32.bf16 	%r110, %rs62;
(EngineCore_DP0 pid=390230) 	.loc	1 233 27                        // quant_slide_tuned_Llama3.2-3B.py:233:27
(EngineCore_DP0 pid=390230) 	mul.f32 	%r111, %r14, %r98;
(EngineCore_DP0 pid=390230) 	mul.f32 	%r112, %r14, %r99;
(EngineCore_DP0 pid=390230) 	mov.b32 	%r113, 0f43E00000;
(EngineCore_DP0 pid=390230) 	.loc	1 233 48                        // quant_slide_tuned_Llama3.2-3B.py:233:48
(EngineCore_DP0 pid=390230) 	min.xorsign.abs.f32 	%r85, %r111, %r113;
(EngineCore_DP0 pid=390230) 	min.xorsign.abs.f32 	%r86, %r112, %r113;
(EngineCore_DP0 pid=390230) 	.loc	1 233 60                        // quant_slide_tuned_Llama3.2-3B.py:233:60
(EngineCore_DP0 pid=390230) 	// begin inline asm
(EngineCore_DP0 pid=390230) 	cvt.rn.satfinite.e4m3x2.f32  %rs64, %r86, %r85; 
(EngineCore_DP0 pid=390230) 
(EngineCore_DP0 pid=390230) 	// end inline asm
(EngineCore_DP0 pid=390230) 	shr.u16 	%rs68, %rs64, 8;
(EngineCore_DP0 pid=390230) 	.loc	1 234 27                        // quant_slide_tuned_Llama3.2-3B.py:234:27
(EngineCore_DP0 pid=390230) 	mul.f32 	%r114, %r14, %r102;
(EngineCore_DP0 pid=390230) 	mul.f32 	%r115, %r14, %r103;
(EngineCore_DP0 pid=390230) 	.loc	1 234 48                        // quant_slide_tuned_Llama3.2-3B.py:234:48
(EngineCore_DP0 pid=390230) 	min.xorsign.abs.f32 	%r87, %r114, %r113;
(EngineCore_DP0 pid=390230) 	min.xorsign.abs.f32 	%r88, %r115, %r113;
(EngineCore_DP0 pid=390230) 	.loc	1 234 60                        // quant_slide_tuned_Llama3.2-3B.py:234:60
(EngineCore_DP0 pid=390230) 	// begin inline asm
(EngineCore_DP0 pid=390230) 	cvt.rn.satfinite.e4m3x2.f32  %rs65, %r88, %r87; 
(EngineCore_DP0 pid=390230) 
(EngineCore_DP0 pid=390230) 	// end inline asm
(EngineCore_DP0 pid=390230) 	shr.u16 	%rs69, %rs65, 8;
(EngineCore_DP0 pid=390230) 	.loc	1 235 27                        // quant_slide_tuned_Llama3.2-3B.py:235:27
(EngineCore_DP0 pid=390230) 	mul.f32 	%r116, %r14, %r106;
(EngineCore_DP0 pid=390230) 	mul.f32 	%r117, %r14, %r107;
(EngineCore_DP0 pid=390230) 	.loc	1 235 48                        // quant_slide_tuned_Llama3.2-3B.py:235:48
(EngineCore_DP0 pid=390230) 	min.xorsign.abs.f32 	%r89, %r116, %r113;
(EngineCore_DP0 pid=390230) 	min.xorsign.abs.f32 	%r90, %r117, %r113;
(EngineCore_DP0 pid=390230) 	.loc	1 235 60                        // quant_slide_tuned_Llama3.2-3B.py:235:60
(EngineCore_DP0 pid=390230) 	// begin inline asm
(EngineCore_DP0 pid=390230) 	cvt.rn.satfinite.e4m3x2.f32  %rs66, %r90, %r89; 
(EngineCore_DP0 pid=390230) 
(EngineCore_DP0 pid=390230) 	// end inline asm
(EngineCore_DP0 pid=390230) 	shr.u16 	%rs70, %rs66, 8;
(EngineCore_DP0 pid=390230) 	.loc	1 236 27                        // quant_slide_tuned_Llama3.2-3B.py:236:27
(EngineCore_DP0 pid=390230) 	mul.f32 	%r118, %r14, %r109;
(EngineCore_DP0 pid=390230) 	mul.f32 	%r119, %r14, %r110;
(EngineCore_DP0 pid=390230) 	.loc	1 236 48                        // quant_slide_tuned_Llama3.2-3B.py:236:48
(EngineCore_DP0 pid=390230) 	min.xorsign.abs.f32 	%r91, %r118, %r113;
(EngineCore_DP0 pid=390230) 	min.xorsign.abs.f32 	%r92, %r119, %r113;
(EngineCore_DP0 pid=390230) 	.loc	1 236 60                        // quant_slide_tuned_Llama3.2-3B.py:236:60
(EngineCore_DP0 pid=390230) 	// begin inline asm
(EngineCore_DP0 pid=390230) 	cvt.rn.satfinite.e4m3x2.f32  %rs67, %r92, %r91; 
(EngineCore_DP0 pid=390230) 
(EngineCore_DP0 pid=390230) 	// end inline asm
(EngineCore_DP0 pid=390230) 	shr.u16 	%rs71, %rs67, 8;
(EngineCore_DP0 pid=390230) 	.loc	1 238 45                        // quant_slide_tuned_Llama3.2-3B.py:238:45
(EngineCore_DP0 pid=390230) 	cvt.u32.u16 	%r120, %rs64;
(EngineCore_DP0 pid=390230) 	and.b32 	%r121, %r120, 255;
(EngineCore_DP0 pid=390230) 	cvt.u32.u16 	%r122, %rs68;
(EngineCore_DP0 pid=390230) 	.loc	1 240 45                        // quant_slide_tuned_Llama3.2-3B.py:240:45
(EngineCore_DP0 pid=390230) 	cvt.u32.u16 	%r123, %rs66;
(EngineCore_DP0 pid=390230) 	and.b32 	%r124, %r123, 255;
(EngineCore_DP0 pid=390230) 	cvt.u32.u16 	%r125, %rs70;
(EngineCore_DP0 pid=390230) 	.loc	1 241 45                        // quant_slide_tuned_Llama3.2-3B.py:241:45
(EngineCore_DP0 pid=390230) 	cvt.u32.u16 	%r126, %rs67;
(EngineCore_DP0 pid=390230) 	cvt.u32.u16 	%r127, %rs71;
(EngineCore_DP0 pid=390230) 	.loc	1 243 30                        // quant_slide_tuned_Llama3.2-3B.py:243:30
(EngineCore_DP0 pid=390230) 	and.b16 	%rs72, %rs65, 255;
(EngineCore_DP0 pid=390230) 	mul.wide.u16 	%r128, %rs72, 256;
(EngineCore_DP0 pid=390230) 	mul.wide.u16 	%r129, %rs69, 256;
(EngineCore_DP0 pid=390230) 	.loc	1 243 24                        // quant_slide_tuned_Llama3.2-3B.py:243:24
(EngineCore_DP0 pid=390230) 	or.b32 	%r130, %r128, %r121;
(EngineCore_DP0 pid=390230) 	or.b32 	%r131, %r129, %r122;
(EngineCore_DP0 pid=390230) 	.loc	1 243 42                        // quant_slide_tuned_Llama3.2-3B.py:243:42
(EngineCore_DP0 pid=390230) 	shl.b32 	%r132, %r124, 16;
(EngineCore_DP0 pid=390230) 	shl.b32 	%r133, %r125, 16;
(EngineCore_DP0 pid=390230) 	.loc	1 243 36                        // quant_slide_tuned_Llama3.2-3B.py:243:36
(EngineCore_DP0 pid=390230) 	or.b32 	%r134, %r130, %r132;
(EngineCore_DP0 pid=390230) 	or.b32 	%r135, %r131, %r133;
(EngineCore_DP0 pid=390230) 	.loc	1 243 55                        // quant_slide_tuned_Llama3.2-3B.py:243:55
(EngineCore_DP0 pid=390230) 	shl.b32 	%r136, %r126, 24;
(EngineCore_DP0 pid=390230) 	shl.b32 	%r137, %r127, 24;
(EngineCore_DP0 pid=390230) 	.loc	1 243 49                        // quant_slide_tuned_Llama3.2-3B.py:243:49
(EngineCore_DP0 pid=390230) 	or.b32 	%r93, %r134, %r136;
(EngineCore_DP0 pid=390230) 	or.b32 	%r94, %r135, %r137;
(EngineCore_DP0 pid=390230) 	.loc	1 244 29                        // quant_slide_tuned_Llama3.2-3B.py:244:29
(EngineCore_DP0 pid=390230) 	mad.wide.s32 	%rd17, %r95, 4, %rd2;
(EngineCore_DP0 pid=390230) 	.loc	1 244 39                        // quant_slide_tuned_Llama3.2-3B.py:244:39
(EngineCore_DP0 pid=390230) 	// begin inline asm
(EngineCore_DP0 pid=390230) 	@%p18 st.global.v2.b32 [ %rd17 + 0 ], { %r93, %r94 };
(EngineCore_DP0 pid=390230) 	// end inline asm
(EngineCore_DP0 pid=390230) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=390230) 	add.s32 	%r142, %r142, 1024;
(EngineCore_DP0 pid=390230) 	add.s32 	%r141, %r141, 4096;
(EngineCore_DP0 pid=390230) 	setp.lt.s32 	%p27, %r142, %r23;
(EngineCore_DP0 pid=390230) 	@%p27 bra 	$L__BB0_6;
(EngineCore_DP0 pid=390230) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=390230) 	.loc	1 215 4                         // quant_slide_tuned_Llama3.2-3B.py:215:4
(EngineCore_DP0 pid=390230) 	ret;
(EngineCore_DP0 pid=390230) $L__tmp3:
(EngineCore_DP0 pid=390230) $L__func_end0:
(EngineCore_DP0 pid=390230)                                         // -- End function
(EngineCore_DP0 pid=390230) }
(EngineCore_DP0 pid=390230) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py"
(EngineCore_DP0 pid=390230) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=390230) 	.section	.debug_abbrev
(EngineCore_DP0 pid=390230) 	{
(EngineCore_DP0 pid=390230) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=390230) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=390230) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=390230) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=390230) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=390230) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=390230) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=390230) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=390230) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=390230) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=390230) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=390230) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=390230) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=390230) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=390230) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=390230) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=390230) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=390230) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=390230) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=390230) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=390230) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=390230) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=390230) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=390230) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=390230) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=390230) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=390230) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=390230) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=390230) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=390230) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=390230) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=390230) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=390230) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=390230) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=390230) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=390230) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=390230) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=390230) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=390230) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=390230) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=390230) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=390230) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=390230) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=390230) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=390230) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=390230) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=390230) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=390230) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=390230) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=390230) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=390230) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=390230) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=390230) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=390230) 	}
(EngineCore_DP0 pid=390230) 	.section	.debug_info
(EngineCore_DP0 pid=390230) 	{
(EngineCore_DP0 pid=390230) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=390230) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=390230) .b8 0
(EngineCore_DP0 pid=390230) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=390230) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=390230) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=390230) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=390230) .b8 114
(EngineCore_DP0 pid=390230) .b8 105
(EngineCore_DP0 pid=390230) .b8 116
(EngineCore_DP0 pid=390230) .b8 111
(EngineCore_DP0 pid=390230) .b8 110
(EngineCore_DP0 pid=390230) .b8 0
(EngineCore_DP0 pid=390230) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=390230) .b8 0
(EngineCore_DP0 pid=390230) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=390230) .b8 117
(EngineCore_DP0 pid=390230) .b8 97
(EngineCore_DP0 pid=390230) .b8 110
(EngineCore_DP0 pid=390230) .b8 116
(EngineCore_DP0 pid=390230) .b8 95
(EngineCore_DP0 pid=390230) .b8 115
(EngineCore_DP0 pid=390230) .b8 108
(EngineCore_DP0 pid=390230) .b8 105
(EngineCore_DP0 pid=390230) .b8 100
(EngineCore_DP0 pid=390230) .b8 101
(EngineCore_DP0 pid=390230) .b8 95
(EngineCore_DP0 pid=390230) .b8 116
(EngineCore_DP0 pid=390230) .b8 117
(EngineCore_DP0 pid=390230) .b8 110
(EngineCore_DP0 pid=390230) .b8 101
(EngineCore_DP0 pid=390230) .b8 100
(EngineCore_DP0 pid=390230) .b8 95
(EngineCore_DP0 pid=390230) .b8 76
(EngineCore_DP0 pid=390230) .b8 108
(EngineCore_DP0 pid=390230) .b8 97
(EngineCore_DP0 pid=390230) .b8 109
(EngineCore_DP0 pid=390230) .b8 97
(EngineCore_DP0 pid=390230) .b8 51
(EngineCore_DP0 pid=390230) .b8 46
(EngineCore_DP0 pid=390230) .b8 50
(EngineCore_DP0 pid=390230) .b8 45
(EngineCore_DP0 pid=390230) .b8 51
(EngineCore_DP0 pid=390230) .b8 66
(EngineCore_DP0 pid=390230) .b8 46
(EngineCore_DP0 pid=390230) .b8 112
(EngineCore_DP0 pid=390230) .b8 121
(EngineCore_DP0 pid=390230) .b8 0
(EngineCore_DP0 pid=390230) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=390230) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=390230) .b8 114
(EngineCore_DP0 pid=390230) .b8 111
(EngineCore_DP0 pid=390230) .b8 111
(EngineCore_DP0 pid=390230) .b8 116
(EngineCore_DP0 pid=390230) .b8 47
(EngineCore_DP0 pid=390230) .b8 118
(EngineCore_DP0 pid=390230) .b8 108
(EngineCore_DP0 pid=390230) .b8 108
(EngineCore_DP0 pid=390230) .b8 109
(EngineCore_DP0 pid=390230) .b8 98
(EngineCore_DP0 pid=390230) .b8 101
(EngineCore_DP0 pid=390230) .b8 110
(EngineCore_DP0 pid=390230) .b8 99
(EngineCore_DP0 pid=390230) .b8 104
(EngineCore_DP0 pid=390230) .b8 47
(EngineCore_DP0 pid=390230) .b8 115
(EngineCore_DP0 pid=390230) .b8 108
(EngineCore_DP0 pid=390230) .b8 105
(EngineCore_DP0 pid=390230) .b8 100
(EngineCore_DP0 pid=390230) .b8 101
(EngineCore_DP0 pid=390230) .b8 115
(EngineCore_DP0 pid=390230) .b8 112
(EngineCore_DP0 pid=390230) .b8 97
(EngineCore_DP0 pid=390230) .b8 114
(EngineCore_DP0 pid=390230) .b8 115
(EngineCore_DP0 pid=390230) .b8 101
(EngineCore_DP0 pid=390230) .b8 47
(EngineCore_DP0 pid=390230) .b8 99
(EngineCore_DP0 pid=390230) .b8 115
(EngineCore_DP0 pid=390230) .b8 114
(EngineCore_DP0 pid=390230) .b8 99
(EngineCore_DP0 pid=390230) .b8 47
(EngineCore_DP0 pid=390230) .b8 102
(EngineCore_DP0 pid=390230) .b8 117
(EngineCore_DP0 pid=390230) .b8 115
(EngineCore_DP0 pid=390230) .b8 101
(EngineCore_DP0 pid=390230) .b8 100
(EngineCore_DP0 pid=390230) .b8 95
(EngineCore_DP0 pid=390230) .b8 113
(EngineCore_DP0 pid=390230) .b8 117
(EngineCore_DP0 pid=390230) .b8 97
(EngineCore_DP0 pid=390230) .b8 110
(EngineCore_DP0 pid=390230) .b8 116
(EngineCore_DP0 pid=390230) .b8 95
(EngineCore_DP0 pid=390230) .b8 115
(EngineCore_DP0 pid=390230) .b8 108
(EngineCore_DP0 pid=390230) .b8 105
(EngineCore_DP0 pid=390230) .b8 100
(EngineCore_DP0 pid=390230) .b8 101
(EngineCore_DP0 pid=390230) .b8 95
(EngineCore_DP0 pid=390230) .b8 116
(EngineCore_DP0 pid=390230) .b8 114
(EngineCore_DP0 pid=390230) .b8 105
(EngineCore_DP0 pid=390230) .b8 116
(EngineCore_DP0 pid=390230) .b8 111
(EngineCore_DP0 pid=390230) .b8 110
(EngineCore_DP0 pid=390230) .b8 47
(EngineCore_DP0 pid=390230) .b8 98
(EngineCore_DP0 pid=390230) .b8 117
(EngineCore_DP0 pid=390230) .b8 105
(EngineCore_DP0 pid=390230) .b8 108
(EngineCore_DP0 pid=390230) .b8 100
(EngineCore_DP0 pid=390230) .b8 47
(EngineCore_DP0 pid=390230) .b8 71
(EngineCore_DP0 pid=390230) .b8 66
(EngineCore_DP0 pid=390230) .b8 49
(EngineCore_DP0 pid=390230) .b8 48
(EngineCore_DP0 pid=390230) .b8 95
(EngineCore_DP0 pid=390230) .b8 99
(EngineCore_DP0 pid=390230) .b8 99
(EngineCore_DP0 pid=390230) .b8 49
(EngineCore_DP0 pid=390230) .b8 50
(EngineCore_DP0 pid=390230) .b8 49
(EngineCore_DP0 pid=390230) .b8 95
(EngineCore_DP0 pid=390230) .b8 112
(EngineCore_DP0 pid=390230) .b8 121
(EngineCore_DP0 pid=390230) .b8 51
(EngineCore_DP0 pid=390230) .b8 49
(EngineCore_DP0 pid=390230) .b8 50
(EngineCore_DP0 pid=390230) .b8 95
(EngineCore_DP0 pid=390230) .b8 99
(EngineCore_DP0 pid=390230) .b8 117
(EngineCore_DP0 pid=390230) .b8 49
(EngineCore_DP0 pid=390230) .b8 50
(EngineCore_DP0 pid=390230) .b8 57
(EngineCore_DP0 pid=390230) .b8 95
(EngineCore_DP0 pid=390230) .b8 97
(EngineCore_DP0 pid=390230) .b8 97
(EngineCore_DP0 pid=390230) .b8 114
(EngineCore_DP0 pid=390230) .b8 99
(EngineCore_DP0 pid=390230) .b8 104
(EngineCore_DP0 pid=390230) .b8 54
(EngineCore_DP0 pid=390230) .b8 52
(EngineCore_DP0 pid=390230) .b8 0
(EngineCore_DP0 pid=390230) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=390230) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=390230) .b8 113
(EngineCore_DP0 pid=390230) .b8 117
(EngineCore_DP0 pid=390230) .b8 97
(EngineCore_DP0 pid=390230) .b8 110
(EngineCore_DP0 pid=390230) .b8 116
(EngineCore_DP0 pid=390230) .b8 95
(EngineCore_DP0 pid=390230) .b8 115
(EngineCore_DP0 pid=390230) .b8 108
(EngineCore_DP0 pid=390230) .b8 105
(EngineCore_DP0 pid=390230) .b8 100
(EngineCore_DP0 pid=390230) .b8 101
(EngineCore_DP0 pid=390230) .b8 95
(EngineCore_DP0 pid=390230) .b8 102
(EngineCore_DP0 pid=390230) .b8 112
(EngineCore_DP0 pid=390230) .b8 56
(EngineCore_DP0 pid=390230) .b8 95
(EngineCore_DP0 pid=390230) .b8 107
(EngineCore_DP0 pid=390230) .b8 101
(EngineCore_DP0 pid=390230) .b8 114
(EngineCore_DP0 pid=390230) .b8 110
(EngineCore_DP0 pid=390230) .b8 101
(EngineCore_DP0 pid=390230) .b8 108
(EngineCore_DP0 pid=390230) .b8 0
(EngineCore_DP0 pid=390230) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=390230) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=390230) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=390230) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=390230) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=390230) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=390230) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=390230) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=390230) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=390230) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=390230) .b8 205                                 // DW_AT_call_line
(EngineCore_DP0 pid=390230) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=390230) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=390230) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=390230) 	}
(EngineCore_DP0 pid=390230) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=390230) 
(EngineCore_DP0 pid=390230) ================================================================
(EngineCore_DP0 pid=390230) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=390230) 
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpetq_0m9g.ptx', '-o', '/tmp/tmpetq_0m9g.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866] 
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866] 
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866] 
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpetq_0m9g.ptx -o /tmp/tmpetq_0m9g.ptx.o
(EngineCore_DP0 pid=390230) ERROR 01-25 20:02:48 [core.py:866] 

STDERR:
[2026-01-25 20:02:26] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:02:26] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:02:26] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:02:26] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:02:26] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:02:26] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:02:26] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:02:26] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:02:26] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:02:26] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:02:26] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:02:26] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:02:26] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:02:26] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:02:29] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:02:29] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:02:29] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:02:29] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:02:29] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:02:29] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:02:29] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:02:29] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:02:29] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:02:29] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:02:29] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:02:29] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:02:29] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:02:29] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=390230) [2026-01-25 20:02:30] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=390230) [2026-01-25 20:02:30] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=390230) [2026-01-25 20:02:30] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=390230) [2026-01-25 20:02:30] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=390230) [2026-01-25 20:02:30] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=390230) [2026-01-25 20:02:30] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=390230) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=390230) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:15<00:00, 15.80s/it]
(EngineCore_DP0 pid=390230) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:15<00:00, 15.80s/it]
(EngineCore_DP0 pid=390230) 
(EngineCore_DP0 pid=390230) [2026-01-25 20:02:47] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 3072] -> 1D uint8
(EngineCore_DP0 pid=390230) [2026-01-25 20:02:47] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9830400 bytes
(EngineCore_DP0 pid=390230) [2026-01-25 20:02:47] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=390230) [2026-01-25 20:02:47] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5898240 bytes
(EngineCore_DP0 pid=390230) [2026-01-25 20:02:47] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=390230) [2026-01-25 20:02:47] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 31457280 bytes
(EngineCore_DP0 pid=390230) [2026-01-25 20:02:47] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 8192] -> 1D uint8
(EngineCore_DP0 pid=390230) [2026-01-25 20:02:47] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15728640 bytes
(EngineCore_DP0 pid=390230) Process EngineCore_DP0:
(EngineCore_DP0 pid=390230) Traceback (most recent call last):
(EngineCore_DP0 pid=390230)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=390230)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=390230)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=390230)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=390230) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpetq_0m9g.ptx', '-o', '/tmp/tmpetq_0m9g.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=390230) 
(EngineCore_DP0 pid=390230) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=390230) 
(EngineCore_DP0 pid=390230) Traceback (most recent call last):
(EngineCore_DP0 pid=390230)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=390230)     self.run()
(EngineCore_DP0 pid=390230)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=390230)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=390230)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=390230)     raise e
(EngineCore_DP0 pid=390230)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=390230)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=390230)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=390230)     super().__init__(
(EngineCore_DP0 pid=390230)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=390230)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=390230)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=390230)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=390230)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=390230)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=390230)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=390230)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=390230)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=390230)     return func(*args, **kwargs)
(EngineCore_DP0 pid=390230)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=390230)     return func(*args, **kwargs)
(EngineCore_DP0 pid=390230)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=390230)     self.model_runner.profile_run()
(EngineCore_DP0 pid=390230)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=390230)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=390230)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=390230)     return func(*args, **kwargs)
(EngineCore_DP0 pid=390230)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=390230)     outputs = self.model(
(EngineCore_DP0 pid=390230)               ^^^^^^^^^^^
(EngineCore_DP0 pid=390230)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=390230)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=390230)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=390230)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=390230)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=390230)     model_output = self.model(
(EngineCore_DP0 pid=390230)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=390230)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=390230)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=390230)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=390230)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=390230)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=390230)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=390230)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=390230)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=390230)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=390230)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=390230)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=390230)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=390230)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=390230)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=390230)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=390230)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=390230)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=390230)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=390230)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=390230)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=390230)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=390230)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=390230)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=390230)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=390230)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=390230)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=390230)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=390230)     return self._linear_fn(
(EngineCore_DP0 pid=390230)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=390230)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=390230)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=390230)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=390230)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=390230)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=390230)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=390230)     return fn(input, L)
(EngineCore_DP0 pid=390230)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=390230)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=390230)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=390230)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=390230)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=390230)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=390230)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=390230)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=390230)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=390230)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=390230)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=390230)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=390230)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=390230)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390230)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=390230)     raise PTXASError(error)
(EngineCore_DP0 pid=390230) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=390230) `ptxas` stderr:
(EngineCore_DP0 pid=390230) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=390230) 
(EngineCore_DP0 pid=390230) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpetq_0m9g.ptx -o /tmp/tmpetq_0m9g.ptx.o
(EngineCore_DP0 pid=390230) 
[rank0]:[W125 20:02:48.669745555 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=16384

========== M=32768 ==========
Time: 2026-01-25 20:02:50
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Llama3.2-3B-FP8_M32768.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:03:05 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 20:03:05 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=390944) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=390944) 
(EngineCore_DP0 pid=390944) 
(EngineCore_DP0 pid=390944) ================================================================
(EngineCore_DP0 pid=390944) Internal Triton PTX codegen error
(EngineCore_DP0 pid=390944) `ptxas` stderr:
(EngineCore_DP0 pid=390944) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=390944) 
(EngineCore_DP0 pid=390944) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp96f3cru_.ptx -o /tmp/tmp96f3cru_.ptx.o
(EngineCore_DP0 pid=390944) 
(EngineCore_DP0 pid=390944) 
(EngineCore_DP0 pid=390944) //
(EngineCore_DP0 pid=390944) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=390944) //
(EngineCore_DP0 pid=390944) 
(EngineCore_DP0 pid=390944) .version 8.7
(EngineCore_DP0 pid=390944) .target sm_121a
(EngineCore_DP0 pid=390944) .address_size 64
(EngineCore_DP0 pid=390944) 
(EngineCore_DP0 pid=390944) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=390944) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=390944)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=390944) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=390944) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=390944) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=390944) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=390944) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=390944) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=390944) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=390944) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=390944) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=390944) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=390944) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=390944) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=390944) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=390944) )
(EngineCore_DP0 pid=390944) .reqntid 512
(EngineCore_DP0 pid=390944) {
(EngineCore_DP0 pid=390944) 	.reg .pred 	%p<44>;
(EngineCore_DP0 pid=390944) 	.reg .b16 	%rs<74>;
(EngineCore_DP0 pid=390944) 	.reg .b32 	%r<187>;
(EngineCore_DP0 pid=390944) 	.reg .b64 	%rd<25>;
(EngineCore_DP0 pid=390944) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=390944) $L__func_begin0:
(EngineCore_DP0 pid=390944) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=390944) 
(EngineCore_DP0 pid=390944) // %bb.0:
(EngineCore_DP0 pid=390944) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=390944) 	ld.param.b32 	%r22, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=390944) 	ld.param.b32 	%r21, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=390944) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=390944) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=390944) $L__tmp0:
(EngineCore_DP0 pid=390944) 	.loc	1 191 24                        // quant_slide_tuned_Llama3.2-3B.py:191:24
(EngineCore_DP0 pid=390944) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=390944) 	ld.param.b32 	%r25, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=390944) 	.loc	1 196 26                        // quant_slide_tuned_Llama3.2-3B.py:196:26
(EngineCore_DP0 pid=390944) 	mul.lo.s32 	%r26, %r25, %r1;
(EngineCore_DP0 pid=390944) 	.loc	1 196 20                        // quant_slide_tuned_Llama3.2-3B.py:196:20
(EngineCore_DP0 pid=390944) 	mad.wide.s32 	%rd1, %r26, 2, %rd4;
(EngineCore_DP0 pid=390944) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=390944) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=390944) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=390944) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=390944) 	setp.lt.s32 	%p1, %r22, 1;
(EngineCore_DP0 pid=390944) 	mov.b32 	%r184, 0f2B8CBCCC;
(EngineCore_DP0 pid=390944) 	setp.eq.b32 	%p43, %r2, 0;
(EngineCore_DP0 pid=390944) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=390944) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=390944) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=390944) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=390944) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=390944) 	shr.u32 	%r35, %r2, 3;
(EngineCore_DP0 pid=390944) 	and.b32 	%r36, %r35, 60;
(EngineCore_DP0 pid=390944) 	mov.b32 	%r37, global_smem;
(EngineCore_DP0 pid=390944) 	add.s32 	%r47, %r37, %r36;
(EngineCore_DP0 pid=390944) 	shl.b32 	%r38, %r2, 2;
(EngineCore_DP0 pid=390944) 	add.s32 	%r50, %r37, %r38;
(EngineCore_DP0 pid=390944) 	mov.b32 	%r43, 0;
(EngineCore_DP0 pid=390944) 	mov.b32 	%r182, 0f00000000;
(EngineCore_DP0 pid=390944) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=390944) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=390944) 	mov.b32 	%r183, %r43;
(EngineCore_DP0 pid=390944) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=390944) 	.loc	1 203 22                        // quant_slide_tuned_Llama3.2-3B.py:203:22
(EngineCore_DP0 pid=390944) 	add.s32 	%r53, %r4, %r183;
(EngineCore_DP0 pid=390944) 	setp.lt.s32 	%p2, %r53, %r21;
(EngineCore_DP0 pid=390944) 	.loc	1 204 29                        // quant_slide_tuned_Llama3.2-3B.py:204:29
(EngineCore_DP0 pid=390944) 	mad.wide.s32 	%rd6, %r53, 2, %rd1;
(EngineCore_DP0 pid=390944) 	.loc	1 204 21                        // quant_slide_tuned_Llama3.2-3B.py:204:21
(EngineCore_DP0 pid=390944) 	// begin inline asm
(EngineCore_DP0 pid=390944) 	mov.u32 %r39, %r43;
(EngineCore_DP0 pid=390944) 	mov.u32 %r40, %r43;
(EngineCore_DP0 pid=390944) 	mov.u32 %r41, %r43;
(EngineCore_DP0 pid=390944) 	mov.u32 %r42, %r43;
(EngineCore_DP0 pid=390944) 	@%p2 ld.global.v4.b32 { %r39, %r40, %r41, %r42 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=390944) 	// end inline asm
(EngineCore_DP0 pid=390944) 	mov.b32 	{%rs1, %rs2}, %r39;
(EngineCore_DP0 pid=390944) 	mov.b32 	{%rs3, %rs4}, %r40;
(EngineCore_DP0 pid=390944) 	mov.b32 	{%rs5, %rs6}, %r41;
(EngineCore_DP0 pid=390944) 	mov.b32 	{%rs7, %rs8}, %r42;
(EngineCore_DP0 pid=390944) 	.loc	1 205 50                        // quant_slide_tuned_Llama3.2-3B.py:205:50
(EngineCore_DP0 pid=390944) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=390944) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=390944) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=390944) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=390944) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=390944) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=390944) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=390944) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=390944) $L__tmp1:
(EngineCore_DP0 pid=390944) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=390944) 	bar.sync 	0;
(EngineCore_DP0 pid=390944) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=390944) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=390944) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=390944) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=390944) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=390944) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=390944) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=390944) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=390944) 	cvt.f32.bf16 	%r54, %rs23;
(EngineCore_DP0 pid=390944) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=390944) 	shfl.sync.bfly.b32 	%r55, %r54, 16, 31, -1;
(EngineCore_DP0 pid=390944) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=390944) 	max.f32 	%r56, %r54, %r55;
(EngineCore_DP0 pid=390944) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=390944) 	shfl.sync.bfly.b32 	%r57, %r56, 8, 31, -1;
(EngineCore_DP0 pid=390944) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=390944) 	max.f32 	%r58, %r56, %r57;
(EngineCore_DP0 pid=390944) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=390944) 	shfl.sync.bfly.b32 	%r59, %r58, 4, 31, -1;
(EngineCore_DP0 pid=390944) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=390944) 	max.f32 	%r60, %r58, %r59;
(EngineCore_DP0 pid=390944) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=390944) 	shfl.sync.bfly.b32 	%r61, %r60, 2, 31, -1;
(EngineCore_DP0 pid=390944) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=390944) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=390944) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=390944) 	shfl.sync.bfly.b32 	%r63, %r62, 1, 31, -1;
(EngineCore_DP0 pid=390944) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=390944) 	max.f32 	%r48, %r62, %r63;
(EngineCore_DP0 pid=390944) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=390944) 	// begin inline asm
(EngineCore_DP0 pid=390944) 	@%p3 st.shared.b32 [ %r47 + 0 ], %r48;
(EngineCore_DP0 pid=390944) 	// end inline asm
(EngineCore_DP0 pid=390944) 	bar.sync 	0;
(EngineCore_DP0 pid=390944) 	// begin inline asm
(EngineCore_DP0 pid=390944) 	@%p4 ld.shared.b32 %r49, [ %r50 + 0 ];
(EngineCore_DP0 pid=390944) 	// end inline asm
(EngineCore_DP0 pid=390944) 	shfl.sync.bfly.b32 	%r64, %r49, 8, 31, -1;
(EngineCore_DP0 pid=390944) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=390944) 	max.f32 	%r65, %r49, %r64;
(EngineCore_DP0 pid=390944) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=390944) 	shfl.sync.bfly.b32 	%r66, %r65, 4, 31, -1;
(EngineCore_DP0 pid=390944) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=390944) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=390944) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=390944) 	shfl.sync.bfly.b32 	%r68, %r67, 2, 31, -1;
(EngineCore_DP0 pid=390944) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=390944) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=390944) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=390944) 	shfl.sync.bfly.b32 	%r70, %r69, 1, 31, -1;
(EngineCore_DP0 pid=390944) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=390944) 	max.f32 	%r52, %r69, %r70;
(EngineCore_DP0 pid=390944) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=390944) 	// begin inline asm
(EngineCore_DP0 pid=390944) 	@%p43 st.shared.b32 [ %r50 + 0 ], %r52;
(EngineCore_DP0 pid=390944) 	// end inline asm
(EngineCore_DP0 pid=390944) 	bar.sync 	0;
(EngineCore_DP0 pid=390944) 	ld.shared.b32 	%r71, [global_smem];
(EngineCore_DP0 pid=390944) $L__tmp2:
(EngineCore_DP0 pid=390944) 	.loc	1 205 36                        // quant_slide_tuned_Llama3.2-3B.py:205:36
(EngineCore_DP0 pid=390944) 	max.f32 	%r182, %r182, %r71;
(EngineCore_DP0 pid=390944) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=390944) 	add.s32 	%r183, %r183, 4096;
(EngineCore_DP0 pid=390944) 	setp.lt.s32 	%p6, %r183, %r22;
(EngineCore_DP0 pid=390944) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=390944) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=390944) 	.loc	1 207 32                        // quant_slide_tuned_Llama3.2-3B.py:207:32
(EngineCore_DP0 pid=390944) 	max.f32 	%r184, %r182, 0f2B8CBCCC;
(EngineCore_DP0 pid=390944) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=390944) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-3B.py:0:32
(EngineCore_DP0 pid=390944) 	mov.b32 	%r73, 0f43E00000;
(EngineCore_DP0 pid=390944) 	.loc	1 208 32                        // quant_slide_tuned_Llama3.2-3B.py:208:32
(EngineCore_DP0 pid=390944) 	div.full.f32 	%r74, %r184, %r73;
(EngineCore_DP0 pid=390944) 	.loc	1 208 41                        // quant_slide_tuned_Llama3.2-3B.py:208:41
(EngineCore_DP0 pid=390944) 	max.f32 	%r72, %r74, 0f36924925;
(EngineCore_DP0 pid=390944) 	.loc	1 210 25                        // quant_slide_tuned_Llama3.2-3B.py:210:25
(EngineCore_DP0 pid=390944) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=390944) 	.loc	1 210 30                        // quant_slide_tuned_Llama3.2-3B.py:210:30
(EngineCore_DP0 pid=390944) 	// begin inline asm
(EngineCore_DP0 pid=390944) 	@%p43 st.global.b32 [ %rd7 + 0 ], { %r72 };
(EngineCore_DP0 pid=390944) 	// end inline asm
(EngineCore_DP0 pid=390944) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=390944) 	setp.lt.s32 	%p8, %r23, 1;
(EngineCore_DP0 pid=390944) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=390944) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=390944) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-3B.py:0:41
(EngineCore_DP0 pid=390944) 	ld.param.b32 	%r27, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=390944) 	shr.s32 	%r28, %r27, 31;
(EngineCore_DP0 pid=390944) 	shr.u32 	%r29, %r28, 30;
(EngineCore_DP0 pid=390944) 	add.s32 	%r30, %r27, %r29;
(EngineCore_DP0 pid=390944) 	shr.s32 	%r31, %r30, 2;
(EngineCore_DP0 pid=390944) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=390944) 	mul.lo.s32 	%r32, %r31, %r1;
(EngineCore_DP0 pid=390944) 	mad.wide.s32 	%rd2, %r32, 4, %rd5;
(EngineCore_DP0 pid=390944) 	div.full.f32 	%r14, %r73, %r184;
(EngineCore_DP0 pid=390944) 	shl.b32 	%r15, %r3, 2;
(EngineCore_DP0 pid=390944) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=390944) 	shl.b32 	%r76, %r3, 4;
(EngineCore_DP0 pid=390944) 	or.b32 	%r185, %r76, 15;
(EngineCore_DP0 pid=390944) 	mov.b32 	%r186, 0;
(EngineCore_DP0 pid=390944) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=390944)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=390944) 	.loc	1 217 30                        // quant_slide_tuned_Llama3.2-3B.py:217:30
(EngineCore_DP0 pid=390944) 	add.s32 	%r97, %r15, %r186;
(EngineCore_DP0 pid=390944) 	setp.lt.s32 	%p25, %r97, %r23;
(EngineCore_DP0 pid=390944) 	.loc	1 222 22                        // quant_slide_tuned_Llama3.2-3B.py:222:22
(EngineCore_DP0 pid=390944) 	add.s32 	%r98, %r185, -15;
(EngineCore_DP0 pid=390944) 	add.s32 	%r99, %r185, -11;
(EngineCore_DP0 pid=390944) 	add.s32 	%r100, %r185, -7;
(EngineCore_DP0 pid=390944) 	.loc	1 225 53                        // quant_slide_tuned_Llama3.2-3B.py:225:53
(EngineCore_DP0 pid=390944) 	add.s32 	%r101, %r185, -3;
(EngineCore_DP0 pid=390944) 	setp.lt.s32 	%p26, %r98, %r21;
(EngineCore_DP0 pid=390944) 	setp.lt.s32 	%p27, %r99, %r21;
(EngineCore_DP0 pid=390944) 	setp.lt.s32 	%p28, %r100, %r21;
(EngineCore_DP0 pid=390944) 	setp.lt.s32 	%p29, %r101, %r21;
(EngineCore_DP0 pid=390944) 	.loc	1 225 37                        // quant_slide_tuned_Llama3.2-3B.py:225:37
(EngineCore_DP0 pid=390944) 	and.pred 	%p9, %p25, %p26;
(EngineCore_DP0 pid=390944) 	and.pred 	%p10, %p25, %p27;
(EngineCore_DP0 pid=390944) 	and.pred 	%p11, %p25, %p28;
(EngineCore_DP0 pid=390944) 	and.pred 	%p12, %p25, %p29;
(EngineCore_DP0 pid=390944) 	.loc	1 224 29                        // quant_slide_tuned_Llama3.2-3B.py:224:29
(EngineCore_DP0 pid=390944) 	mad.wide.s32 	%rd8, %r98, 2, %rd1;
(EngineCore_DP0 pid=390944) 	add.s64 	%rd9, %rd8, 8;
(EngineCore_DP0 pid=390944) 	add.s64 	%rd10, %rd8, 16;
(EngineCore_DP0 pid=390944) 	add.s64 	%rd11, %rd8, 24;
(EngineCore_DP0 pid=390944) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=390944) 	.loc	1 224 21                        // quant_slide_tuned_Llama3.2-3B.py:224:21
(EngineCore_DP0 pid=390944) 	// begin inline asm
(EngineCore_DP0 pid=390944) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=390944) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=390944) 	// end inline asm
(EngineCore_DP0 pid=390944) 	// begin inline asm
(EngineCore_DP0 pid=390944) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=390944) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=390944) 	// end inline asm
(EngineCore_DP0 pid=390944) 	// begin inline asm
(EngineCore_DP0 pid=390944) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=390944) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=390944) 	// end inline asm
(EngineCore_DP0 pid=390944) 	// begin inline asm
(EngineCore_DP0 pid=390944) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=390944) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=390944) 	// end inline asm
(EngineCore_DP0 pid=390944) 	.loc	1 225 79                        // quant_slide_tuned_Llama3.2-3B.py:225:79
(EngineCore_DP0 pid=390944) 	cvt.f32.bf16 	%r102, %rs24;
(EngineCore_DP0 pid=390944) 	cvt.f32.bf16 	%r103, %rs26;
(EngineCore_DP0 pid=390944) 	cvt.f32.bf16 	%r104, %rs28;
(EngineCore_DP0 pid=390944) 	cvt.f32.bf16 	%r105, %rs30;
(EngineCore_DP0 pid=390944) 	.loc	1 227 48                        // quant_slide_tuned_Llama3.2-3B.py:227:48
(EngineCore_DP0 pid=390944) 	add.s32 	%r106, %r185, -14;
(EngineCore_DP0 pid=390944) 	add.s32 	%r107, %r185, -10;
(EngineCore_DP0 pid=390944) 	add.s32 	%r108, %r185, -6;
(EngineCore_DP0 pid=390944) 	.loc	1 227 53                        // quant_slide_tuned_Llama3.2-3B.py:227:53
(EngineCore_DP0 pid=390944) 	add.s32 	%r109, %r185, -2;
(EngineCore_DP0 pid=390944) 	setp.lt.s32 	%p30, %r106, %r21;
(EngineCore_DP0 pid=390944) 	setp.lt.s32 	%p31, %r107, %r21;
(EngineCore_DP0 pid=390944) 	setp.lt.s32 	%p32, %r108, %r21;
(EngineCore_DP0 pid=390944) 	setp.lt.s32 	%p33, %r109, %r21;
(EngineCore_DP0 pid=390944) 	.loc	1 227 37                        // quant_slide_tuned_Llama3.2-3B.py:227:37
(EngineCore_DP0 pid=390944) 	and.pred 	%p13, %p25, %p30;
(EngineCore_DP0 pid=390944) 	and.pred 	%p14, %p25, %p31;
(EngineCore_DP0 pid=390944) 	and.pred 	%p15, %p25, %p32;
(EngineCore_DP0 pid=390944) 	and.pred 	%p16, %p25, %p33;
(EngineCore_DP0 pid=390944) 	.loc	1 226 39                        // quant_slide_tuned_Llama3.2-3B.py:226:39
(EngineCore_DP0 pid=390944) 	add.s64 	%rd12, %rd8, 2;
(EngineCore_DP0 pid=390944) 	add.s64 	%rd13, %rd8, 10;
(EngineCore_DP0 pid=390944) 	add.s64 	%rd14, %rd8, 18;
(EngineCore_DP0 pid=390944) 	add.s64 	%rd15, %rd8, 26;
(EngineCore_DP0 pid=390944) 	.loc	1 226 21                        // quant_slide_tuned_Llama3.2-3B.py:226:21
(EngineCore_DP0 pid=390944) 	// begin inline asm
(EngineCore_DP0 pid=390944) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=390944) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=390944) 	// end inline asm
(EngineCore_DP0 pid=390944) 	// begin inline asm
(EngineCore_DP0 pid=390944) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=390944) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=390944) 	// end inline asm
(EngineCore_DP0 pid=390944) 	// begin inline asm
(EngineCore_DP0 pid=390944) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=390944) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=390944) 	// end inline asm
(EngineCore_DP0 pid=390944) 	// begin inline asm
(EngineCore_DP0 pid=390944) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=390944) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=390944) 	// end inline asm
(EngineCore_DP0 pid=390944) 	.loc	1 227 79                        // quant_slide_tuned_Llama3.2-3B.py:227:79
(EngineCore_DP0 pid=390944) 	cvt.f32.bf16 	%r110, %rs32;
(EngineCore_DP0 pid=390944) 	cvt.f32.bf16 	%r111, %rs34;
(EngineCore_DP0 pid=390944) 	cvt.f32.bf16 	%r112, %rs36;
(EngineCore_DP0 pid=390944) 	cvt.f32.bf16 	%r113, %rs38;
(EngineCore_DP0 pid=390944) 	.loc	1 229 48                        // quant_slide_tuned_Llama3.2-3B.py:229:48
(EngineCore_DP0 pid=390944) 	add.s32 	%r114, %r185, -13;
(EngineCore_DP0 pid=390944) 	add.s32 	%r115, %r185, -9;
(EngineCore_DP0 pid=390944) 	add.s32 	%r116, %r185, -5;
(EngineCore_DP0 pid=390944) 	.loc	1 229 53                        // quant_slide_tuned_Llama3.2-3B.py:229:53
(EngineCore_DP0 pid=390944) 	add.s32 	%r117, %r185, -1;
(EngineCore_DP0 pid=390944) 	setp.lt.s32 	%p34, %r114, %r21;
(EngineCore_DP0 pid=390944) 	setp.lt.s32 	%p35, %r115, %r21;
(EngineCore_DP0 pid=390944) 	setp.lt.s32 	%p36, %r116, %r21;
(EngineCore_DP0 pid=390944) 	setp.lt.s32 	%p37, %r117, %r21;
(EngineCore_DP0 pid=390944) 	.loc	1 229 37                        // quant_slide_tuned_Llama3.2-3B.py:229:37
(EngineCore_DP0 pid=390944) 	and.pred 	%p17, %p25, %p34;
(EngineCore_DP0 pid=390944) 	and.pred 	%p18, %p25, %p35;
(EngineCore_DP0 pid=390944) 	and.pred 	%p19, %p25, %p36;
(EngineCore_DP0 pid=390944) 	and.pred 	%p20, %p25, %p37;
(EngineCore_DP0 pid=390944) 	.loc	1 228 39                        // quant_slide_tuned_Llama3.2-3B.py:228:39
(EngineCore_DP0 pid=390944) 	add.s64 	%rd16, %rd8, 4;
(EngineCore_DP0 pid=390944) 	add.s64 	%rd17, %rd8, 12;
(EngineCore_DP0 pid=390944) 	add.s64 	%rd18, %rd8, 20;
(EngineCore_DP0 pid=390944) 	add.s64 	%rd19, %rd8, 28;
(EngineCore_DP0 pid=390944) 	.loc	1 228 21                        // quant_slide_tuned_Llama3.2-3B.py:228:21
(EngineCore_DP0 pid=390944) 	// begin inline asm
(EngineCore_DP0 pid=390944) 	mov.u16 %rs40, %rs25;
(EngineCore_DP0 pid=390944) 	@%p17 ld.global.b16 { %rs40 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=390944) 	// end inline asm
(EngineCore_DP0 pid=390944) 	// begin inline asm
(EngineCore_DP0 pid=390944) 	mov.u16 %rs42, %rs25;
(EngineCore_DP0 pid=390944) 	@%p18 ld.global.b16 { %rs42 }, [ %rd17 + 0 ];
(EngineCore_DP0 pid=390944) 	// end inline asm
(EngineCore_DP0 pid=390944) 	// begin inline asm
(EngineCore_DP0 pid=390944) 	mov.u16 %rs44, %rs25;
(EngineCore_DP0 pid=390944) 	@%p19 ld.global.b16 { %rs44 }, [ %rd18 + 0 ];
(EngineCore_DP0 pid=390944) 	// end inline asm
(EngineCore_DP0 pid=390944) 	// begin inline asm
(EngineCore_DP0 pid=390944) 	mov.u16 %rs46, %rs25;
(EngineCore_DP0 pid=390944) 	@%p20 ld.global.b16 { %rs46 }, [ %rd19 + 0 ];
(EngineCore_DP0 pid=390944) 	// end inline asm
(EngineCore_DP0 pid=390944) 	.loc	1 229 79                        // quant_slide_tuned_Llama3.2-3B.py:229:79
(EngineCore_DP0 pid=390944) 	cvt.f32.bf16 	%r118, %rs40;
(EngineCore_DP0 pid=390944) 	cvt.f32.bf16 	%r119, %rs42;
(EngineCore_DP0 pid=390944) 	cvt.f32.bf16 	%r120, %rs44;
(EngineCore_DP0 pid=390944) 	cvt.f32.bf16 	%r121, %rs46;
(EngineCore_DP0 pid=390944) 	.loc	1 231 48                        // quant_slide_tuned_Llama3.2-3B.py:231:48
(EngineCore_DP0 pid=390944) 	add.s32 	%r122, %r185, -12;
(EngineCore_DP0 pid=390944) 	add.s32 	%r123, %r185, -8;
(EngineCore_DP0 pid=390944) 	add.s32 	%r124, %r185, -4;
(EngineCore_DP0 pid=390944) 	.loc	1 231 53                        // quant_slide_tuned_Llama3.2-3B.py:231:53
(EngineCore_DP0 pid=390944) 	setp.lt.s32 	%p38, %r122, %r21;
(EngineCore_DP0 pid=390944) 	setp.lt.s32 	%p39, %r123, %r21;
(EngineCore_DP0 pid=390944) 	setp.lt.s32 	%p40, %r124, %r21;
(EngineCore_DP0 pid=390944) 	setp.lt.s32 	%p41, %r185, %r21;
(EngineCore_DP0 pid=390944) 	.loc	1 231 37                        // quant_slide_tuned_Llama3.2-3B.py:231:37
(EngineCore_DP0 pid=390944) 	and.pred 	%p21, %p25, %p38;
(EngineCore_DP0 pid=390944) 	and.pred 	%p22, %p25, %p39;
(EngineCore_DP0 pid=390944) 	and.pred 	%p23, %p25, %p40;
(EngineCore_DP0 pid=390944) 	and.pred 	%p24, %p25, %p41;
(EngineCore_DP0 pid=390944) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-3B.py:230:39
(EngineCore_DP0 pid=390944) 	add.s64 	%rd20, %rd8, 6;
(EngineCore_DP0 pid=390944) 	add.s64 	%rd21, %rd8, 14;
(EngineCore_DP0 pid=390944) 	add.s64 	%rd22, %rd8, 22;
(EngineCore_DP0 pid=390944) 	add.s64 	%rd23, %rd8, 30;
(EngineCore_DP0 pid=390944) 	.loc	1 230 21                        // quant_slide_tuned_Llama3.2-3B.py:230:21
(EngineCore_DP0 pid=390944) 	// begin inline asm
(EngineCore_DP0 pid=390944) 	mov.u16 %rs48, %rs25;
(EngineCore_DP0 pid=390944) 	@%p21 ld.global.b16 { %rs48 }, [ %rd20 + 0 ];
(EngineCore_DP0 pid=390944) 	// end inline asm
(EngineCore_DP0 pid=390944) 	// begin inline asm
(EngineCore_DP0 pid=390944) 	mov.u16 %rs50, %rs25;
(EngineCore_DP0 pid=390944) 	@%p22 ld.global.b16 { %rs50 }, [ %rd21 + 0 ];
(EngineCore_DP0 pid=390944) 	// end inline asm
(EngineCore_DP0 pid=390944) 	// begin inline asm
(EngineCore_DP0 pid=390944) 	mov.u16 %rs52, %rs25;
(EngineCore_DP0 pid=390944) 	@%p23 ld.global.b16 { %rs52 }, [ %rd22 + 0 ];
(EngineCore_DP0 pid=390944) 	// end inline asm
(EngineCore_DP0 pid=390944) 	// begin inline asm
(EngineCore_DP0 pid=390944) 	mov.u16 %rs54, %rs25;
(EngineCore_DP0 pid=390944) 	@%p24 ld.global.b16 { %rs54 }, [ %rd23 + 0 ];
(EngineCore_DP0 pid=390944) 	// end inline asm
(EngineCore_DP0 pid=390944) 	.loc	1 231 79                        // quant_slide_tuned_Llama3.2-3B.py:231:79
(EngineCore_DP0 pid=390944) 	cvt.f32.bf16 	%r125, %rs48;
(EngineCore_DP0 pid=390944) 	cvt.f32.bf16 	%r126, %rs50;
(EngineCore_DP0 pid=390944) 	cvt.f32.bf16 	%r127, %rs52;
(EngineCore_DP0 pid=390944) 	cvt.f32.bf16 	%r128, %rs54;
(EngineCore_DP0 pid=390944) 	.loc	1 233 27                        // quant_slide_tuned_Llama3.2-3B.py:233:27
(EngineCore_DP0 pid=390944) 	mul.f32 	%r129, %r14, %r102;
(EngineCore_DP0 pid=390944) 	mul.f32 	%r130, %r14, %r103;
(EngineCore_DP0 pid=390944) 	mul.f32 	%r131, %r14, %r104;
(EngineCore_DP0 pid=390944) 	mul.f32 	%r132, %r14, %r105;
(EngineCore_DP0 pid=390944) 	mov.b32 	%r133, 0f43E00000;
(EngineCore_DP0 pid=390944) 	.loc	1 233 48                        // quant_slide_tuned_Llama3.2-3B.py:233:48
(EngineCore_DP0 pid=390944) 	min.xorsign.abs.f32 	%r77, %r129, %r133;
(EngineCore_DP0 pid=390944) 	min.xorsign.abs.f32 	%r78, %r130, %r133;
(EngineCore_DP0 pid=390944) 	min.xorsign.abs.f32 	%r79, %r131, %r133;
(EngineCore_DP0 pid=390944) 	min.xorsign.abs.f32 	%r80, %r132, %r133;
(EngineCore_DP0 pid=390944) 	.loc	1 233 60                        // quant_slide_tuned_Llama3.2-3B.py:233:60
(EngineCore_DP0 pid=390944) 	// begin inline asm
(EngineCore_DP0 pid=390944) 	cvt.rn.satfinite.e4m3x2.f32  %rs56, %r78, %r77; 
(EngineCore_DP0 pid=390944) 
(EngineCore_DP0 pid=390944) 	// end inline asm
(EngineCore_DP0 pid=390944) 	shr.u16 	%rs64, %rs56, 8;
(EngineCore_DP0 pid=390944) 	// begin inline asm
(EngineCore_DP0 pid=390944) 	cvt.rn.satfinite.e4m3x2.f32  %rs57, %r80, %r79; 
(EngineCore_DP0 pid=390944) 
(EngineCore_DP0 pid=390944) 	// end inline asm
(EngineCore_DP0 pid=390944) 	shr.u16 	%rs65, %rs57, 8;
(EngineCore_DP0 pid=390944) 	.loc	1 234 27                        // quant_slide_tuned_Llama3.2-3B.py:234:27
(EngineCore_DP0 pid=390944) 	mul.f32 	%r134, %r14, %r110;
(EngineCore_DP0 pid=390944) 	mul.f32 	%r135, %r14, %r111;
(EngineCore_DP0 pid=390944) 	mul.f32 	%r136, %r14, %r112;
(EngineCore_DP0 pid=390944) 	mul.f32 	%r137, %r14, %r113;
(EngineCore_DP0 pid=390944) 	.loc	1 234 48                        // quant_slide_tuned_Llama3.2-3B.py:234:48
(EngineCore_DP0 pid=390944) 	min.xorsign.abs.f32 	%r81, %r134, %r133;
(EngineCore_DP0 pid=390944) 	min.xorsign.abs.f32 	%r82, %r135, %r133;
(EngineCore_DP0 pid=390944) 	min.xorsign.abs.f32 	%r83, %r136, %r133;
(EngineCore_DP0 pid=390944) 	min.xorsign.abs.f32 	%r84, %r137, %r133;
(EngineCore_DP0 pid=390944) 	.loc	1 234 60                        // quant_slide_tuned_Llama3.2-3B.py:234:60
(EngineCore_DP0 pid=390944) 	// begin inline asm
(EngineCore_DP0 pid=390944) 	cvt.rn.satfinite.e4m3x2.f32  %rs58, %r82, %r81; 
(EngineCore_DP0 pid=390944) 
(EngineCore_DP0 pid=390944) 	// end inline asm
(EngineCore_DP0 pid=390944) 	shr.u16 	%rs66, %rs58, 8;
(EngineCore_DP0 pid=390944) 	// begin inline asm
(EngineCore_DP0 pid=390944) 	cvt.rn.satfinite.e4m3x2.f32  %rs59, %r84, %r83; 
(EngineCore_DP0 pid=390944) 
(EngineCore_DP0 pid=390944) 	// end inline asm
(EngineCore_DP0 pid=390944) 	shr.u16 	%rs67, %rs59, 8;
(EngineCore_DP0 pid=390944) 	.loc	1 235 27                        // quant_slide_tuned_Llama3.2-3B.py:235:27
(EngineCore_DP0 pid=390944) 	mul.f32 	%r138, %r14, %r118;
(EngineCore_DP0 pid=390944) 	mul.f32 	%r139, %r14, %r119;
(EngineCore_DP0 pid=390944) 	mul.f32 	%r140, %r14, %r120;
(EngineCore_DP0 pid=390944) 	mul.f32 	%r141, %r14, %r121;
(EngineCore_DP0 pid=390944) 	.loc	1 235 48                        // quant_slide_tuned_Llama3.2-3B.py:235:48
(EngineCore_DP0 pid=390944) 	min.xorsign.abs.f32 	%r85, %r138, %r133;
(EngineCore_DP0 pid=390944) 	min.xorsign.abs.f32 	%r86, %r139, %r133;
(EngineCore_DP0 pid=390944) 	min.xorsign.abs.f32 	%r87, %r140, %r133;
(EngineCore_DP0 pid=390944) 	min.xorsign.abs.f32 	%r88, %r141, %r133;
(EngineCore_DP0 pid=390944) 	.loc	1 235 60                        // quant_slide_tuned_Llama3.2-3B.py:235:60
(EngineCore_DP0 pid=390944) 	// begin inline asm
(EngineCore_DP0 pid=390944) 	cvt.rn.satfinite.e4m3x2.f32  %rs60, %r86, %r85; 
(EngineCore_DP0 pid=390944) 
(EngineCore_DP0 pid=390944) 	// end inline asm
(EngineCore_DP0 pid=390944) 	shr.u16 	%rs68, %rs60, 8;
(EngineCore_DP0 pid=390944) 	// begin inline asm
(EngineCore_DP0 pid=390944) 	cvt.rn.satfinite.e4m3x2.f32  %rs61, %r88, %r87; 
(EngineCore_DP0 pid=390944) 
(EngineCore_DP0 pid=390944) 	// end inline asm
(EngineCore_DP0 pid=390944) 	shr.u16 	%rs69, %rs61, 8;
(EngineCore_DP0 pid=390944) 	.loc	1 236 27                        // quant_slide_tuned_Llama3.2-3B.py:236:27
(EngineCore_DP0 pid=390944) 	mul.f32 	%r142, %r14, %r125;
(EngineCore_DP0 pid=390944) 	mul.f32 	%r143, %r14, %r126;
(EngineCore_DP0 pid=390944) 	mul.f32 	%r144, %r14, %r127;
(EngineCore_DP0 pid=390944) 	mul.f32 	%r145, %r14, %r128;
(EngineCore_DP0 pid=390944) 	.loc	1 236 48                        // quant_slide_tuned_Llama3.2-3B.py:236:48
(EngineCore_DP0 pid=390944) 	min.xorsign.abs.f32 	%r89, %r142, %r133;
(EngineCore_DP0 pid=390944) 	min.xorsign.abs.f32 	%r90, %r143, %r133;
(EngineCore_DP0 pid=390944) 	min.xorsign.abs.f32 	%r91, %r144, %r133;
(EngineCore_DP0 pid=390944) 	min.xorsign.abs.f32 	%r92, %r145, %r133;
(EngineCore_DP0 pid=390944) 	.loc	1 236 60                        // quant_slide_tuned_Llama3.2-3B.py:236:60
(EngineCore_DP0 pid=390944) 	// begin inline asm
(EngineCore_DP0 pid=390944) 	cvt.rn.satfinite.e4m3x2.f32  %rs62, %r90, %r89; 
(EngineCore_DP0 pid=390944) 
(EngineCore_DP0 pid=390944) 	// end inline asm
(EngineCore_DP0 pid=390944) 	shr.u16 	%rs70, %rs62, 8;
(EngineCore_DP0 pid=390944) 	// begin inline asm
(EngineCore_DP0 pid=390944) 	cvt.rn.satfinite.e4m3x2.f32  %rs63, %r92, %r91; 
(EngineCore_DP0 pid=390944) 
(EngineCore_DP0 pid=390944) 	// end inline asm
(EngineCore_DP0 pid=390944) 	shr.u16 	%rs71, %rs63, 8;
(EngineCore_DP0 pid=390944) 	.loc	1 238 45                        // quant_slide_tuned_Llama3.2-3B.py:238:45
(EngineCore_DP0 pid=390944) 	cvt.u32.u16 	%r146, %rs56;
(EngineCore_DP0 pid=390944) 	and.b32 	%r147, %r146, 255;
(EngineCore_DP0 pid=390944) 	cvt.u32.u16 	%r148, %rs64;
(EngineCore_DP0 pid=390944) 	cvt.u32.u16 	%r149, %rs57;
(EngineCore_DP0 pid=390944) 	and.b32 	%r150, %r149, 255;
(EngineCore_DP0 pid=390944) 	cvt.u32.u16 	%r151, %rs65;
(EngineCore_DP0 pid=390944) 	.loc	1 240 45                        // quant_slide_tuned_Llama3.2-3B.py:240:45
(EngineCore_DP0 pid=390944) 	cvt.u32.u16 	%r152, %rs60;
(EngineCore_DP0 pid=390944) 	and.b32 	%r153, %r152, 255;
(EngineCore_DP0 pid=390944) 	cvt.u32.u16 	%r154, %rs68;
(EngineCore_DP0 pid=390944) 	cvt.u32.u16 	%r155, %rs61;
(EngineCore_DP0 pid=390944) 	and.b32 	%r156, %r155, 255;
(EngineCore_DP0 pid=390944) 	cvt.u32.u16 	%r157, %rs69;
(EngineCore_DP0 pid=390944) 	.loc	1 241 45                        // quant_slide_tuned_Llama3.2-3B.py:241:45
(EngineCore_DP0 pid=390944) 	cvt.u32.u16 	%r158, %rs62;
(EngineCore_DP0 pid=390944) 	cvt.u32.u16 	%r159, %rs70;
(EngineCore_DP0 pid=390944) 	cvt.u32.u16 	%r160, %rs63;
(EngineCore_DP0 pid=390944) 	cvt.u32.u16 	%r161, %rs71;
(EngineCore_DP0 pid=390944) 	.loc	1 243 30                        // quant_slide_tuned_Llama3.2-3B.py:243:30
(EngineCore_DP0 pid=390944) 	and.b16 	%rs72, %rs58, 255;
(EngineCore_DP0 pid=390944) 	mul.wide.u16 	%r162, %rs72, 256;
(EngineCore_DP0 pid=390944) 	mul.wide.u16 	%r163, %rs66, 256;
(EngineCore_DP0 pid=390944) 	and.b16 	%rs73, %rs59, 255;
(EngineCore_DP0 pid=390944) 	mul.wide.u16 	%r164, %rs73, 256;
(EngineCore_DP0 pid=390944) 	mul.wide.u16 	%r165, %rs67, 256;
(EngineCore_DP0 pid=390944) 	.loc	1 243 24                        // quant_slide_tuned_Llama3.2-3B.py:243:24
(EngineCore_DP0 pid=390944) 	or.b32 	%r166, %r162, %r147;
(EngineCore_DP0 pid=390944) 	or.b32 	%r167, %r163, %r148;
(EngineCore_DP0 pid=390944) 	or.b32 	%r168, %r164, %r150;
(EngineCore_DP0 pid=390944) 	or.b32 	%r169, %r165, %r151;
(EngineCore_DP0 pid=390944) 	.loc	1 243 42                        // quant_slide_tuned_Llama3.2-3B.py:243:42
(EngineCore_DP0 pid=390944) 	shl.b32 	%r170, %r153, 16;
(EngineCore_DP0 pid=390944) 	shl.b32 	%r171, %r154, 16;
(EngineCore_DP0 pid=390944) 	shl.b32 	%r172, %r156, 16;
(EngineCore_DP0 pid=390944) 	shl.b32 	%r173, %r157, 16;
(EngineCore_DP0 pid=390944) 	.loc	1 243 36                        // quant_slide_tuned_Llama3.2-3B.py:243:36
(EngineCore_DP0 pid=390944) 	or.b32 	%r174, %r170, %r166;
(EngineCore_DP0 pid=390944) 	or.b32 	%r175, %r171, %r167;
(EngineCore_DP0 pid=390944) 	or.b32 	%r176, %r172, %r168;
(EngineCore_DP0 pid=390944) 	or.b32 	%r177, %r173, %r169;
(EngineCore_DP0 pid=390944) 	.loc	1 243 55                        // quant_slide_tuned_Llama3.2-3B.py:243:55
(EngineCore_DP0 pid=390944) 	shl.b32 	%r178, %r158, 24;
(EngineCore_DP0 pid=390944) 	shl.b32 	%r179, %r159, 24;
(EngineCore_DP0 pid=390944) 	shl.b32 	%r180, %r160, 24;
(EngineCore_DP0 pid=390944) 	shl.b32 	%r181, %r161, 24;
(EngineCore_DP0 pid=390944) 	.loc	1 243 49                        // quant_slide_tuned_Llama3.2-3B.py:243:49
(EngineCore_DP0 pid=390944) 	or.b32 	%r93, %r178, %r174;
(EngineCore_DP0 pid=390944) 	or.b32 	%r94, %r179, %r175;
(EngineCore_DP0 pid=390944) 	or.b32 	%r95, %r180, %r176;
(EngineCore_DP0 pid=390944) 	or.b32 	%r96, %r181, %r177;
(EngineCore_DP0 pid=390944) 	.loc	1 244 29                        // quant_slide_tuned_Llama3.2-3B.py:244:29
(EngineCore_DP0 pid=390944) 	mad.wide.s32 	%rd24, %r97, 4, %rd2;
(EngineCore_DP0 pid=390944) 	.loc	1 244 39                        // quant_slide_tuned_Llama3.2-3B.py:244:39
(EngineCore_DP0 pid=390944) 	// begin inline asm
(EngineCore_DP0 pid=390944) 	@%p25 st.global.v4.b32 [ %rd24 + 0 ], { %r93, %r94, %r95, %r96 };
(EngineCore_DP0 pid=390944) 	// end inline asm
(EngineCore_DP0 pid=390944) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=390944) 	add.s32 	%r186, %r186, 2048;
(EngineCore_DP0 pid=390944) 	add.s32 	%r185, %r185, 8192;
(EngineCore_DP0 pid=390944) 	setp.lt.s32 	%p42, %r186, %r23;
(EngineCore_DP0 pid=390944) 	@%p42 bra 	$L__BB0_6;
(EngineCore_DP0 pid=390944) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=390944) 	.loc	1 215 4                         // quant_slide_tuned_Llama3.2-3B.py:215:4
(EngineCore_DP0 pid=390944) 	ret;
(EngineCore_DP0 pid=390944) $L__tmp3:
(EngineCore_DP0 pid=390944) $L__func_end0:
(EngineCore_DP0 pid=390944)                                         // -- End function
(EngineCore_DP0 pid=390944) }
(EngineCore_DP0 pid=390944) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py"
(EngineCore_DP0 pid=390944) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=390944) 	.section	.debug_abbrev
(EngineCore_DP0 pid=390944) 	{
(EngineCore_DP0 pid=390944) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=390944) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=390944) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=390944) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=390944) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=390944) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=390944) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=390944) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=390944) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=390944) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=390944) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=390944) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=390944) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=390944) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=390944) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=390944) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=390944) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=390944) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=390944) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=390944) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=390944) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=390944) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=390944) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=390944) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=390944) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=390944) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=390944) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=390944) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=390944) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=390944) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=390944) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=390944) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=390944) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=390944) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=390944) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=390944) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=390944) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=390944) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=390944) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=390944) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=390944) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=390944) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=390944) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=390944) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=390944) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=390944) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=390944) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=390944) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=390944) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=390944) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=390944) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=390944) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=390944) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=390944) 	}
(EngineCore_DP0 pid=390944) 	.section	.debug_info
(EngineCore_DP0 pid=390944) 	{
(EngineCore_DP0 pid=390944) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=390944) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=390944) .b8 0
(EngineCore_DP0 pid=390944) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=390944) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=390944) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=390944) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=390944) .b8 114
(EngineCore_DP0 pid=390944) .b8 105
(EngineCore_DP0 pid=390944) .b8 116
(EngineCore_DP0 pid=390944) .b8 111
(EngineCore_DP0 pid=390944) .b8 110
(EngineCore_DP0 pid=390944) .b8 0
(EngineCore_DP0 pid=390944) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=390944) .b8 0
(EngineCore_DP0 pid=390944) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=390944) .b8 117
(EngineCore_DP0 pid=390944) .b8 97
(EngineCore_DP0 pid=390944) .b8 110
(EngineCore_DP0 pid=390944) .b8 116
(EngineCore_DP0 pid=390944) .b8 95
(EngineCore_DP0 pid=390944) .b8 115
(EngineCore_DP0 pid=390944) .b8 108
(EngineCore_DP0 pid=390944) .b8 105
(EngineCore_DP0 pid=390944) .b8 100
(EngineCore_DP0 pid=390944) .b8 101
(EngineCore_DP0 pid=390944) .b8 95
(EngineCore_DP0 pid=390944) .b8 116
(EngineCore_DP0 pid=390944) .b8 117
(EngineCore_DP0 pid=390944) .b8 110
(EngineCore_DP0 pid=390944) .b8 101
(EngineCore_DP0 pid=390944) .b8 100
(EngineCore_DP0 pid=390944) .b8 95
(EngineCore_DP0 pid=390944) .b8 76
(EngineCore_DP0 pid=390944) .b8 108
(EngineCore_DP0 pid=390944) .b8 97
(EngineCore_DP0 pid=390944) .b8 109
(EngineCore_DP0 pid=390944) .b8 97
(EngineCore_DP0 pid=390944) .b8 51
(EngineCore_DP0 pid=390944) .b8 46
(EngineCore_DP0 pid=390944) .b8 50
(EngineCore_DP0 pid=390944) .b8 45
(EngineCore_DP0 pid=390944) .b8 51
(EngineCore_DP0 pid=390944) .b8 66
(EngineCore_DP0 pid=390944) .b8 46
(EngineCore_DP0 pid=390944) .b8 112
(EngineCore_DP0 pid=390944) .b8 121
(EngineCore_DP0 pid=390944) .b8 0
(EngineCore_DP0 pid=390944) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=390944) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=390944) .b8 114
(EngineCore_DP0 pid=390944) .b8 111
(EngineCore_DP0 pid=390944) .b8 111
(EngineCore_DP0 pid=390944) .b8 116
(EngineCore_DP0 pid=390944) .b8 47
(EngineCore_DP0 pid=390944) .b8 118
(EngineCore_DP0 pid=390944) .b8 108
(EngineCore_DP0 pid=390944) .b8 108
(EngineCore_DP0 pid=390944) .b8 109
(EngineCore_DP0 pid=390944) .b8 98
(EngineCore_DP0 pid=390944) .b8 101
(EngineCore_DP0 pid=390944) .b8 110
(EngineCore_DP0 pid=390944) .b8 99
(EngineCore_DP0 pid=390944) .b8 104
(EngineCore_DP0 pid=390944) .b8 47
(EngineCore_DP0 pid=390944) .b8 115
(EngineCore_DP0 pid=390944) .b8 108
(EngineCore_DP0 pid=390944) .b8 105
(EngineCore_DP0 pid=390944) .b8 100
(EngineCore_DP0 pid=390944) .b8 101
(EngineCore_DP0 pid=390944) .b8 115
(EngineCore_DP0 pid=390944) .b8 112
(EngineCore_DP0 pid=390944) .b8 97
(EngineCore_DP0 pid=390944) .b8 114
(EngineCore_DP0 pid=390944) .b8 115
(EngineCore_DP0 pid=390944) .b8 101
(EngineCore_DP0 pid=390944) .b8 47
(EngineCore_DP0 pid=390944) .b8 99
(EngineCore_DP0 pid=390944) .b8 115
(EngineCore_DP0 pid=390944) .b8 114
(EngineCore_DP0 pid=390944) .b8 99
(EngineCore_DP0 pid=390944) .b8 47
(EngineCore_DP0 pid=390944) .b8 102
(EngineCore_DP0 pid=390944) .b8 117
(EngineCore_DP0 pid=390944) .b8 115
(EngineCore_DP0 pid=390944) .b8 101
(EngineCore_DP0 pid=390944) .b8 100
(EngineCore_DP0 pid=390944) .b8 95
(EngineCore_DP0 pid=390944) .b8 113
(EngineCore_DP0 pid=390944) .b8 117
(EngineCore_DP0 pid=390944) .b8 97
(EngineCore_DP0 pid=390944) .b8 110
(EngineCore_DP0 pid=390944) .b8 116
(EngineCore_DP0 pid=390944) .b8 95
(EngineCore_DP0 pid=390944) .b8 115
(EngineCore_DP0 pid=390944) .b8 108
(EngineCore_DP0 pid=390944) .b8 105
(EngineCore_DP0 pid=390944) .b8 100
(EngineCore_DP0 pid=390944) .b8 101
(EngineCore_DP0 pid=390944) .b8 95
(EngineCore_DP0 pid=390944) .b8 116
(EngineCore_DP0 pid=390944) .b8 114
(EngineCore_DP0 pid=390944) .b8 105
(EngineCore_DP0 pid=390944) .b8 116
(EngineCore_DP0 pid=390944) .b8 111
(EngineCore_DP0 pid=390944) .b8 110
(EngineCore_DP0 pid=390944) .b8 47
(EngineCore_DP0 pid=390944) .b8 98
(EngineCore_DP0 pid=390944) .b8 117
(EngineCore_DP0 pid=390944) .b8 105
(EngineCore_DP0 pid=390944) .b8 108
(EngineCore_DP0 pid=390944) .b8 100
(EngineCore_DP0 pid=390944) .b8 47
(EngineCore_DP0 pid=390944) .b8 71
(EngineCore_DP0 pid=390944) .b8 66
(EngineCore_DP0 pid=390944) .b8 49
(EngineCore_DP0 pid=390944) .b8 48
(EngineCore_DP0 pid=390944) .b8 95
(EngineCore_DP0 pid=390944) .b8 99
(EngineCore_DP0 pid=390944) .b8 99
(EngineCore_DP0 pid=390944) .b8 49
(EngineCore_DP0 pid=390944) .b8 50
(EngineCore_DP0 pid=390944) .b8 49
(EngineCore_DP0 pid=390944) .b8 95
(EngineCore_DP0 pid=390944) .b8 112
(EngineCore_DP0 pid=390944) .b8 121
(EngineCore_DP0 pid=390944) .b8 51
(EngineCore_DP0 pid=390944) .b8 49
(EngineCore_DP0 pid=390944) .b8 50
(EngineCore_DP0 pid=390944) .b8 95
(EngineCore_DP0 pid=390944) .b8 99
(EngineCore_DP0 pid=390944) .b8 117
(EngineCore_DP0 pid=390944) .b8 49
(EngineCore_DP0 pid=390944) .b8 50
(EngineCore_DP0 pid=390944) .b8 57
(EngineCore_DP0 pid=390944) .b8 95
(EngineCore_DP0 pid=390944) .b8 97
(EngineCore_DP0 pid=390944) .b8 97
(EngineCore_DP0 pid=390944) .b8 114
(EngineCore_DP0 pid=390944) .b8 99
(EngineCore_DP0 pid=390944) .b8 104
(EngineCore_DP0 pid=390944) .b8 54
(EngineCore_DP0 pid=390944) .b8 52
(EngineCore_DP0 pid=390944) .b8 0
(EngineCore_DP0 pid=390944) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=390944) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=390944) .b8 113
(EngineCore_DP0 pid=390944) .b8 117
(EngineCore_DP0 pid=390944) .b8 97
(EngineCore_DP0 pid=390944) .b8 110
(EngineCore_DP0 pid=390944) .b8 116
(EngineCore_DP0 pid=390944) .b8 95
(EngineCore_DP0 pid=390944) .b8 115
(EngineCore_DP0 pid=390944) .b8 108
(EngineCore_DP0 pid=390944) .b8 105
(EngineCore_DP0 pid=390944) .b8 100
(EngineCore_DP0 pid=390944) .b8 101
(EngineCore_DP0 pid=390944) .b8 95
(EngineCore_DP0 pid=390944) .b8 102
(EngineCore_DP0 pid=390944) .b8 112
(EngineCore_DP0 pid=390944) .b8 56
(EngineCore_DP0 pid=390944) .b8 95
(EngineCore_DP0 pid=390944) .b8 107
(EngineCore_DP0 pid=390944) .b8 101
(EngineCore_DP0 pid=390944) .b8 114
(EngineCore_DP0 pid=390944) .b8 110
(EngineCore_DP0 pid=390944) .b8 101
(EngineCore_DP0 pid=390944) .b8 108
(EngineCore_DP0 pid=390944) .b8 0
(EngineCore_DP0 pid=390944) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=390944) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=390944) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=390944) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=390944) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=390944) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=390944) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=390944) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=390944) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=390944) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=390944) .b8 205                                 // DW_AT_call_line
(EngineCore_DP0 pid=390944) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=390944) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=390944) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=390944) 	}
(EngineCore_DP0 pid=390944) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=390944) 
(EngineCore_DP0 pid=390944) ================================================================
(EngineCore_DP0 pid=390944) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=390944) 
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp96f3cru_.ptx', '-o', '/tmp/tmp96f3cru_.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866] 
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866] 
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866] 
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp96f3cru_.ptx -o /tmp/tmp96f3cru_.ptx.o
(EngineCore_DP0 pid=390944) ERROR 01-25 20:03:26 [core.py:866] 

STDERR:
[2026-01-25 20:03:05] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:03:05] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:03:05] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:03:05] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:03:05] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:03:05] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:03:05] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:03:05] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:03:05] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:03:05] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:03:05] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:03:05] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:03:05] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:03:05] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:03:08] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:03:08] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:03:08] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:03:08] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:03:08] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:03:08] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:03:08] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:03:08] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:03:08] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:03:08] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:03:08] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:03:08] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:03:08] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:03:08] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=390944) [2026-01-25 20:03:09] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=390944) [2026-01-25 20:03:09] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=390944) [2026-01-25 20:03:09] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=390944) [2026-01-25 20:03:09] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=390944) [2026-01-25 20:03:09] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=390944) [2026-01-25 20:03:09] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=390944) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=390944) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:15<00:00, 15.43s/it]
(EngineCore_DP0 pid=390944) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:15<00:00, 15.43s/it]
(EngineCore_DP0 pid=390944) 
(EngineCore_DP0 pid=390944) [2026-01-25 20:03:25] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 3072] -> 1D uint8
(EngineCore_DP0 pid=390944) [2026-01-25 20:03:25] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9830400 bytes
(EngineCore_DP0 pid=390944) [2026-01-25 20:03:25] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=390944) [2026-01-25 20:03:25] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5898240 bytes
(EngineCore_DP0 pid=390944) [2026-01-25 20:03:25] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=390944) [2026-01-25 20:03:25] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 31457280 bytes
(EngineCore_DP0 pid=390944) [2026-01-25 20:03:25] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 8192] -> 1D uint8
(EngineCore_DP0 pid=390944) [2026-01-25 20:03:25] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15728640 bytes
(EngineCore_DP0 pid=390944) Process EngineCore_DP0:
(EngineCore_DP0 pid=390944) Traceback (most recent call last):
(EngineCore_DP0 pid=390944)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=390944)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=390944)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=390944)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=390944) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp96f3cru_.ptx', '-o', '/tmp/tmp96f3cru_.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=390944) 
(EngineCore_DP0 pid=390944) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=390944) 
(EngineCore_DP0 pid=390944) Traceback (most recent call last):
(EngineCore_DP0 pid=390944)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=390944)     self.run()
(EngineCore_DP0 pid=390944)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=390944)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=390944)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=390944)     raise e
(EngineCore_DP0 pid=390944)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=390944)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=390944)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=390944)     super().__init__(
(EngineCore_DP0 pid=390944)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=390944)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=390944)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=390944)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=390944)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=390944)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=390944)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=390944)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=390944)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=390944)     return func(*args, **kwargs)
(EngineCore_DP0 pid=390944)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=390944)     return func(*args, **kwargs)
(EngineCore_DP0 pid=390944)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=390944)     self.model_runner.profile_run()
(EngineCore_DP0 pid=390944)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=390944)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=390944)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=390944)     return func(*args, **kwargs)
(EngineCore_DP0 pid=390944)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=390944)     outputs = self.model(
(EngineCore_DP0 pid=390944)               ^^^^^^^^^^^
(EngineCore_DP0 pid=390944)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=390944)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=390944)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=390944)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=390944)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=390944)     model_output = self.model(
(EngineCore_DP0 pid=390944)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=390944)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=390944)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=390944)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=390944)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=390944)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=390944)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=390944)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=390944)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=390944)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=390944)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=390944)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=390944)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=390944)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=390944)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=390944)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=390944)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=390944)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=390944)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=390944)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=390944)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=390944)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=390944)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=390944)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=390944)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=390944)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=390944)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=390944)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=390944)     return self._linear_fn(
(EngineCore_DP0 pid=390944)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=390944)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=390944)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=390944)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=390944)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=390944)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=390944)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=390944)     return fn(input, L)
(EngineCore_DP0 pid=390944)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=390944)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=390944)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=390944)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=390944)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=390944)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=390944)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=390944)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=390944)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=390944)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=390944)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=390944)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=390944)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=390944)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=390944)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=390944)     raise PTXASError(error)
(EngineCore_DP0 pid=390944) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=390944) `ptxas` stderr:
(EngineCore_DP0 pid=390944) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=390944) 
(EngineCore_DP0 pid=390944) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp96f3cru_.ptx -o /tmp/tmp96f3cru_.ptx.o
(EngineCore_DP0 pid=390944) 
[rank0]:[W125 20:03:26.071615573 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=32768

========== M=65536 ==========
Time: 2026-01-25 20:03:28
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Llama3.2-3B-FP8_M65536.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:03:54 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 20:03:54 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=391823) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=391823) 
(EngineCore_DP0 pid=391823) 
(EngineCore_DP0 pid=391823) ================================================================
(EngineCore_DP0 pid=391823) Internal Triton PTX codegen error
(EngineCore_DP0 pid=391823) `ptxas` stderr:
(EngineCore_DP0 pid=391823) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=391823) 
(EngineCore_DP0 pid=391823) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp_iwn0dp4.ptx -o /tmp/tmp_iwn0dp4.ptx.o
(EngineCore_DP0 pid=391823) 
(EngineCore_DP0 pid=391823) 
(EngineCore_DP0 pid=391823) //
(EngineCore_DP0 pid=391823) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=391823) //
(EngineCore_DP0 pid=391823) 
(EngineCore_DP0 pid=391823) .version 8.7
(EngineCore_DP0 pid=391823) .target sm_121a
(EngineCore_DP0 pid=391823) .address_size 64
(EngineCore_DP0 pid=391823) 
(EngineCore_DP0 pid=391823) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=391823) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=391823)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=391823) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=391823) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=391823) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=391823) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=391823) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=391823) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=391823) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=391823) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=391823) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=391823) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=391823) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=391823) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=391823) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=391823) )
(EngineCore_DP0 pid=391823) .reqntid 512
(EngineCore_DP0 pid=391823) {
(EngineCore_DP0 pid=391823) 	.reg .pred 	%p<28>;
(EngineCore_DP0 pid=391823) 	.reg .b16 	%rs<49>;
(EngineCore_DP0 pid=391823) 	.reg .b32 	%r<134>;
(EngineCore_DP0 pid=391823) 	.reg .b64 	%rd<17>;
(EngineCore_DP0 pid=391823) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=391823) $L__func_begin0:
(EngineCore_DP0 pid=391823) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=391823) 
(EngineCore_DP0 pid=391823) // %bb.0:
(EngineCore_DP0 pid=391823) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=391823) 	ld.param.b32 	%r22, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=391823) 	ld.param.b32 	%r21, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=391823) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=391823) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=391823) $L__tmp0:
(EngineCore_DP0 pid=391823) 	.loc	1 191 24                        // quant_slide_tuned_Llama3.2-3B.py:191:24
(EngineCore_DP0 pid=391823) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=391823) 	ld.param.b32 	%r25, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=391823) 	.loc	1 196 26                        // quant_slide_tuned_Llama3.2-3B.py:196:26
(EngineCore_DP0 pid=391823) 	mul.lo.s32 	%r26, %r25, %r1;
(EngineCore_DP0 pid=391823) 	.loc	1 196 20                        // quant_slide_tuned_Llama3.2-3B.py:196:20
(EngineCore_DP0 pid=391823) 	mad.wide.s32 	%rd1, %r26, 2, %rd4;
(EngineCore_DP0 pid=391823) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=391823) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=391823) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=391823) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=391823) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=391823) 	setp.lt.s32 	%p1, %r22, 1;
(EngineCore_DP0 pid=391823) 	mov.b32 	%r131, 0f2B8CBCCC;
(EngineCore_DP0 pid=391823) 	setp.eq.b32 	%p27, %r2, 0;
(EngineCore_DP0 pid=391823) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=391823) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=391823) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=391823) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=391823) 	shr.u32 	%r35, %r2, 3;
(EngineCore_DP0 pid=391823) 	and.b32 	%r36, %r35, 60;
(EngineCore_DP0 pid=391823) 	mov.b32 	%r37, global_smem;
(EngineCore_DP0 pid=391823) 	add.s32 	%r47, %r37, %r36;
(EngineCore_DP0 pid=391823) 	shl.b32 	%r38, %r2, 2;
(EngineCore_DP0 pid=391823) 	add.s32 	%r50, %r37, %r38;
(EngineCore_DP0 pid=391823) 	mov.b32 	%r43, 0;
(EngineCore_DP0 pid=391823) 	mov.b32 	%r129, 0f00000000;
(EngineCore_DP0 pid=391823) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=391823) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=391823) 	mov.b32 	%r130, %r43;
(EngineCore_DP0 pid=391823) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=391823) 	.loc	1 203 22                        // quant_slide_tuned_Llama3.2-3B.py:203:22
(EngineCore_DP0 pid=391823) 	add.s32 	%r53, %r4, %r130;
(EngineCore_DP0 pid=391823) 	setp.lt.s32 	%p2, %r53, %r21;
(EngineCore_DP0 pid=391823) 	.loc	1 204 29                        // quant_slide_tuned_Llama3.2-3B.py:204:29
(EngineCore_DP0 pid=391823) 	mad.wide.s32 	%rd6, %r53, 2, %rd1;
(EngineCore_DP0 pid=391823) 	.loc	1 204 21                        // quant_slide_tuned_Llama3.2-3B.py:204:21
(EngineCore_DP0 pid=391823) 	// begin inline asm
(EngineCore_DP0 pid=391823) 	mov.u32 %r39, %r43;
(EngineCore_DP0 pid=391823) 	mov.u32 %r40, %r43;
(EngineCore_DP0 pid=391823) 	mov.u32 %r41, %r43;
(EngineCore_DP0 pid=391823) 	mov.u32 %r42, %r43;
(EngineCore_DP0 pid=391823) 	@%p2 ld.global.v4.b32 { %r39, %r40, %r41, %r42 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=391823) 	// end inline asm
(EngineCore_DP0 pid=391823) 	mov.b32 	{%rs1, %rs2}, %r39;
(EngineCore_DP0 pid=391823) 	mov.b32 	{%rs3, %rs4}, %r40;
(EngineCore_DP0 pid=391823) 	mov.b32 	{%rs5, %rs6}, %r41;
(EngineCore_DP0 pid=391823) 	mov.b32 	{%rs7, %rs8}, %r42;
(EngineCore_DP0 pid=391823) 	.loc	1 205 50                        // quant_slide_tuned_Llama3.2-3B.py:205:50
(EngineCore_DP0 pid=391823) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=391823) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=391823) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=391823) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=391823) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=391823) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=391823) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=391823) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=391823) $L__tmp1:
(EngineCore_DP0 pid=391823) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=391823) 	bar.sync 	0;
(EngineCore_DP0 pid=391823) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=391823) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=391823) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=391823) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=391823) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=391823) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=391823) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=391823) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=391823) 	cvt.f32.bf16 	%r54, %rs23;
(EngineCore_DP0 pid=391823) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=391823) 	shfl.sync.bfly.b32 	%r55, %r54, 16, 31, -1;
(EngineCore_DP0 pid=391823) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=391823) 	max.f32 	%r56, %r54, %r55;
(EngineCore_DP0 pid=391823) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=391823) 	shfl.sync.bfly.b32 	%r57, %r56, 8, 31, -1;
(EngineCore_DP0 pid=391823) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=391823) 	max.f32 	%r58, %r56, %r57;
(EngineCore_DP0 pid=391823) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=391823) 	shfl.sync.bfly.b32 	%r59, %r58, 4, 31, -1;
(EngineCore_DP0 pid=391823) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=391823) 	max.f32 	%r60, %r58, %r59;
(EngineCore_DP0 pid=391823) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=391823) 	shfl.sync.bfly.b32 	%r61, %r60, 2, 31, -1;
(EngineCore_DP0 pid=391823) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=391823) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=391823) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=391823) 	shfl.sync.bfly.b32 	%r63, %r62, 1, 31, -1;
(EngineCore_DP0 pid=391823) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=391823) 	max.f32 	%r48, %r62, %r63;
(EngineCore_DP0 pid=391823) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=391823) 	// begin inline asm
(EngineCore_DP0 pid=391823) 	@%p3 st.shared.b32 [ %r47 + 0 ], %r48;
(EngineCore_DP0 pid=391823) 	// end inline asm
(EngineCore_DP0 pid=391823) 	bar.sync 	0;
(EngineCore_DP0 pid=391823) 	// begin inline asm
(EngineCore_DP0 pid=391823) 	@%p4 ld.shared.b32 %r49, [ %r50 + 0 ];
(EngineCore_DP0 pid=391823) 	// end inline asm
(EngineCore_DP0 pid=391823) 	shfl.sync.bfly.b32 	%r64, %r49, 8, 31, -1;
(EngineCore_DP0 pid=391823) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=391823) 	max.f32 	%r65, %r49, %r64;
(EngineCore_DP0 pid=391823) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=391823) 	shfl.sync.bfly.b32 	%r66, %r65, 4, 31, -1;
(EngineCore_DP0 pid=391823) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=391823) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=391823) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=391823) 	shfl.sync.bfly.b32 	%r68, %r67, 2, 31, -1;
(EngineCore_DP0 pid=391823) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=391823) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=391823) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=391823) 	shfl.sync.bfly.b32 	%r70, %r69, 1, 31, -1;
(EngineCore_DP0 pid=391823) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=391823) 	max.f32 	%r52, %r69, %r70;
(EngineCore_DP0 pid=391823) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=391823) 	// begin inline asm
(EngineCore_DP0 pid=391823) 	@%p27 st.shared.b32 [ %r50 + 0 ], %r52;
(EngineCore_DP0 pid=391823) 	// end inline asm
(EngineCore_DP0 pid=391823) 	bar.sync 	0;
(EngineCore_DP0 pid=391823) 	ld.shared.b32 	%r71, [global_smem];
(EngineCore_DP0 pid=391823) $L__tmp2:
(EngineCore_DP0 pid=391823) 	.loc	1 205 36                        // quant_slide_tuned_Llama3.2-3B.py:205:36
(EngineCore_DP0 pid=391823) 	max.f32 	%r129, %r129, %r71;
(EngineCore_DP0 pid=391823) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=391823) 	add.s32 	%r130, %r130, 4096;
(EngineCore_DP0 pid=391823) 	setp.lt.s32 	%p6, %r130, %r22;
(EngineCore_DP0 pid=391823) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=391823) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=391823) 	.loc	1 207 32                        // quant_slide_tuned_Llama3.2-3B.py:207:32
(EngineCore_DP0 pid=391823) 	max.f32 	%r131, %r129, 0f2B8CBCCC;
(EngineCore_DP0 pid=391823) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=391823) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-3B.py:0:32
(EngineCore_DP0 pid=391823) 	mov.b32 	%r73, 0f43E00000;
(EngineCore_DP0 pid=391823) 	.loc	1 208 32                        // quant_slide_tuned_Llama3.2-3B.py:208:32
(EngineCore_DP0 pid=391823) 	div.full.f32 	%r74, %r131, %r73;
(EngineCore_DP0 pid=391823) 	.loc	1 208 41                        // quant_slide_tuned_Llama3.2-3B.py:208:41
(EngineCore_DP0 pid=391823) 	max.f32 	%r72, %r74, 0f36924925;
(EngineCore_DP0 pid=391823) 	.loc	1 210 25                        // quant_slide_tuned_Llama3.2-3B.py:210:25
(EngineCore_DP0 pid=391823) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=391823) 	.loc	1 210 30                        // quant_slide_tuned_Llama3.2-3B.py:210:30
(EngineCore_DP0 pid=391823) 	// begin inline asm
(EngineCore_DP0 pid=391823) 	@%p27 st.global.b32 [ %rd7 + 0 ], { %r72 };
(EngineCore_DP0 pid=391823) 	// end inline asm
(EngineCore_DP0 pid=391823) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=391823) 	setp.lt.s32 	%p8, %r23, 1;
(EngineCore_DP0 pid=391823) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=391823) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=391823) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-3B.py:0:41
(EngineCore_DP0 pid=391823) 	ld.param.b32 	%r27, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=391823) 	shr.s32 	%r28, %r27, 31;
(EngineCore_DP0 pid=391823) 	shr.u32 	%r29, %r28, 30;
(EngineCore_DP0 pid=391823) 	add.s32 	%r30, %r27, %r29;
(EngineCore_DP0 pid=391823) 	shr.s32 	%r31, %r30, 2;
(EngineCore_DP0 pid=391823) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=391823) 	mul.lo.s32 	%r32, %r31, %r1;
(EngineCore_DP0 pid=391823) 	mad.wide.s32 	%rd2, %r32, 4, %rd5;
(EngineCore_DP0 pid=391823) 	div.full.f32 	%r14, %r73, %r131;
(EngineCore_DP0 pid=391823) 	shl.b32 	%r15, %r3, 1;
(EngineCore_DP0 pid=391823) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=391823) 	add.s32 	%r132, %r4, 7;
(EngineCore_DP0 pid=391823) 	mov.b32 	%r133, 0;
(EngineCore_DP0 pid=391823) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=391823)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=391823) 	.loc	1 217 30                        // quant_slide_tuned_Llama3.2-3B.py:217:30
(EngineCore_DP0 pid=391823) 	add.s32 	%r86, %r15, %r133;
(EngineCore_DP0 pid=391823) 	setp.lt.s32 	%p17, %r86, %r23;
(EngineCore_DP0 pid=391823) 	.loc	1 222 22                        // quant_slide_tuned_Llama3.2-3B.py:222:22
(EngineCore_DP0 pid=391823) 	add.s32 	%r87, %r132, -7;
(EngineCore_DP0 pid=391823) 	.loc	1 225 53                        // quant_slide_tuned_Llama3.2-3B.py:225:53
(EngineCore_DP0 pid=391823) 	add.s32 	%r88, %r132, -3;
(EngineCore_DP0 pid=391823) 	setp.lt.s32 	%p18, %r87, %r21;
(EngineCore_DP0 pid=391823) 	setp.lt.s32 	%p19, %r88, %r21;
(EngineCore_DP0 pid=391823) 	.loc	1 225 37                        // quant_slide_tuned_Llama3.2-3B.py:225:37
(EngineCore_DP0 pid=391823) 	and.pred 	%p9, %p17, %p18;
(EngineCore_DP0 pid=391823) 	and.pred 	%p10, %p17, %p19;
(EngineCore_DP0 pid=391823) 	.loc	1 224 29                        // quant_slide_tuned_Llama3.2-3B.py:224:29
(EngineCore_DP0 pid=391823) 	mad.wide.s32 	%rd8, %r87, 2, %rd1;
(EngineCore_DP0 pid=391823) 	add.s64 	%rd9, %rd8, 8;
(EngineCore_DP0 pid=391823) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=391823) 	.loc	1 224 21                        // quant_slide_tuned_Llama3.2-3B.py:224:21
(EngineCore_DP0 pid=391823) 	// begin inline asm
(EngineCore_DP0 pid=391823) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=391823) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=391823) 	// end inline asm
(EngineCore_DP0 pid=391823) 	// begin inline asm
(EngineCore_DP0 pid=391823) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=391823) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=391823) 	// end inline asm
(EngineCore_DP0 pid=391823) 	.loc	1 225 79                        // quant_slide_tuned_Llama3.2-3B.py:225:79
(EngineCore_DP0 pid=391823) 	cvt.f32.bf16 	%r89, %rs24;
(EngineCore_DP0 pid=391823) 	cvt.f32.bf16 	%r90, %rs26;
(EngineCore_DP0 pid=391823) 	.loc	1 227 48                        // quant_slide_tuned_Llama3.2-3B.py:227:48
(EngineCore_DP0 pid=391823) 	add.s32 	%r91, %r132, -6;
(EngineCore_DP0 pid=391823) 	.loc	1 227 53                        // quant_slide_tuned_Llama3.2-3B.py:227:53
(EngineCore_DP0 pid=391823) 	add.s32 	%r92, %r132, -2;
(EngineCore_DP0 pid=391823) 	setp.lt.s32 	%p20, %r91, %r21;
(EngineCore_DP0 pid=391823) 	setp.lt.s32 	%p21, %r92, %r21;
(EngineCore_DP0 pid=391823) 	.loc	1 227 37                        // quant_slide_tuned_Llama3.2-3B.py:227:37
(EngineCore_DP0 pid=391823) 	and.pred 	%p11, %p17, %p20;
(EngineCore_DP0 pid=391823) 	and.pred 	%p12, %p17, %p21;
(EngineCore_DP0 pid=391823) 	.loc	1 226 39                        // quant_slide_tuned_Llama3.2-3B.py:226:39
(EngineCore_DP0 pid=391823) 	add.s64 	%rd10, %rd8, 2;
(EngineCore_DP0 pid=391823) 	add.s64 	%rd11, %rd8, 10;
(EngineCore_DP0 pid=391823) 	.loc	1 226 21                        // quant_slide_tuned_Llama3.2-3B.py:226:21
(EngineCore_DP0 pid=391823) 	// begin inline asm
(EngineCore_DP0 pid=391823) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=391823) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=391823) 	// end inline asm
(EngineCore_DP0 pid=391823) 	// begin inline asm
(EngineCore_DP0 pid=391823) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=391823) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=391823) 	// end inline asm
(EngineCore_DP0 pid=391823) 	.loc	1 227 79                        // quant_slide_tuned_Llama3.2-3B.py:227:79
(EngineCore_DP0 pid=391823) 	cvt.f32.bf16 	%r93, %rs28;
(EngineCore_DP0 pid=391823) 	cvt.f32.bf16 	%r94, %rs30;
(EngineCore_DP0 pid=391823) 	.loc	1 229 48                        // quant_slide_tuned_Llama3.2-3B.py:229:48
(EngineCore_DP0 pid=391823) 	add.s32 	%r95, %r132, -5;
(EngineCore_DP0 pid=391823) 	.loc	1 229 53                        // quant_slide_tuned_Llama3.2-3B.py:229:53
(EngineCore_DP0 pid=391823) 	add.s32 	%r96, %r132, -1;
(EngineCore_DP0 pid=391823) 	setp.lt.s32 	%p22, %r95, %r21;
(EngineCore_DP0 pid=391823) 	setp.lt.s32 	%p23, %r96, %r21;
(EngineCore_DP0 pid=391823) 	.loc	1 229 37                        // quant_slide_tuned_Llama3.2-3B.py:229:37
(EngineCore_DP0 pid=391823) 	and.pred 	%p13, %p17, %p22;
(EngineCore_DP0 pid=391823) 	and.pred 	%p14, %p17, %p23;
(EngineCore_DP0 pid=391823) 	.loc	1 228 39                        // quant_slide_tuned_Llama3.2-3B.py:228:39
(EngineCore_DP0 pid=391823) 	add.s64 	%rd12, %rd8, 4;
(EngineCore_DP0 pid=391823) 	add.s64 	%rd13, %rd8, 12;
(EngineCore_DP0 pid=391823) 	.loc	1 228 21                        // quant_slide_tuned_Llama3.2-3B.py:228:21
(EngineCore_DP0 pid=391823) 	// begin inline asm
(EngineCore_DP0 pid=391823) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=391823) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=391823) 	// end inline asm
(EngineCore_DP0 pid=391823) 	// begin inline asm
(EngineCore_DP0 pid=391823) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=391823) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=391823) 	// end inline asm
(EngineCore_DP0 pid=391823) 	.loc	1 229 79                        // quant_slide_tuned_Llama3.2-3B.py:229:79
(EngineCore_DP0 pid=391823) 	cvt.f32.bf16 	%r97, %rs32;
(EngineCore_DP0 pid=391823) 	cvt.f32.bf16 	%r98, %rs34;
(EngineCore_DP0 pid=391823) 	.loc	1 231 48                        // quant_slide_tuned_Llama3.2-3B.py:231:48
(EngineCore_DP0 pid=391823) 	add.s32 	%r99, %r132, -4;
(EngineCore_DP0 pid=391823) 	.loc	1 231 53                        // quant_slide_tuned_Llama3.2-3B.py:231:53
(EngineCore_DP0 pid=391823) 	setp.lt.s32 	%p24, %r99, %r21;
(EngineCore_DP0 pid=391823) 	setp.lt.s32 	%p25, %r132, %r21;
(EngineCore_DP0 pid=391823) 	.loc	1 231 37                        // quant_slide_tuned_Llama3.2-3B.py:231:37
(EngineCore_DP0 pid=391823) 	and.pred 	%p15, %p17, %p24;
(EngineCore_DP0 pid=391823) 	and.pred 	%p16, %p17, %p25;
(EngineCore_DP0 pid=391823) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-3B.py:230:39
(EngineCore_DP0 pid=391823) 	add.s64 	%rd14, %rd8, 6;
(EngineCore_DP0 pid=391823) 	add.s64 	%rd15, %rd8, 14;
(EngineCore_DP0 pid=391823) 	.loc	1 230 21                        // quant_slide_tuned_Llama3.2-3B.py:230:21
(EngineCore_DP0 pid=391823) 	// begin inline asm
(EngineCore_DP0 pid=391823) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=391823) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=391823) 	// end inline asm
(EngineCore_DP0 pid=391823) 	// begin inline asm
(EngineCore_DP0 pid=391823) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=391823) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=391823) 	// end inline asm
(EngineCore_DP0 pid=391823) 	.loc	1 231 79                        // quant_slide_tuned_Llama3.2-3B.py:231:79
(EngineCore_DP0 pid=391823) 	cvt.f32.bf16 	%r100, %rs36;
(EngineCore_DP0 pid=391823) 	cvt.f32.bf16 	%r101, %rs38;
(EngineCore_DP0 pid=391823) 	.loc	1 233 27                        // quant_slide_tuned_Llama3.2-3B.py:233:27
(EngineCore_DP0 pid=391823) 	mul.f32 	%r102, %r14, %r89;
(EngineCore_DP0 pid=391823) 	mul.f32 	%r103, %r14, %r90;
(EngineCore_DP0 pid=391823) 	mov.b32 	%r104, 0f43E00000;
(EngineCore_DP0 pid=391823) 	.loc	1 233 48                        // quant_slide_tuned_Llama3.2-3B.py:233:48
(EngineCore_DP0 pid=391823) 	min.xorsign.abs.f32 	%r76, %r102, %r104;
(EngineCore_DP0 pid=391823) 	min.xorsign.abs.f32 	%r77, %r103, %r104;
(EngineCore_DP0 pid=391823) 	.loc	1 233 60                        // quant_slide_tuned_Llama3.2-3B.py:233:60
(EngineCore_DP0 pid=391823) 	// begin inline asm
(EngineCore_DP0 pid=391823) 	cvt.rn.satfinite.e4m3x2.f32  %rs40, %r77, %r76; 
(EngineCore_DP0 pid=391823) 
(EngineCore_DP0 pid=391823) 	// end inline asm
(EngineCore_DP0 pid=391823) 	shr.u16 	%rs44, %rs40, 8;
(EngineCore_DP0 pid=391823) 	.loc	1 234 27                        // quant_slide_tuned_Llama3.2-3B.py:234:27
(EngineCore_DP0 pid=391823) 	mul.f32 	%r105, %r14, %r93;
(EngineCore_DP0 pid=391823) 	mul.f32 	%r106, %r14, %r94;
(EngineCore_DP0 pid=391823) 	.loc	1 234 48                        // quant_slide_tuned_Llama3.2-3B.py:234:48
(EngineCore_DP0 pid=391823) 	min.xorsign.abs.f32 	%r78, %r105, %r104;
(EngineCore_DP0 pid=391823) 	min.xorsign.abs.f32 	%r79, %r106, %r104;
(EngineCore_DP0 pid=391823) 	.loc	1 234 60                        // quant_slide_tuned_Llama3.2-3B.py:234:60
(EngineCore_DP0 pid=391823) 	// begin inline asm
(EngineCore_DP0 pid=391823) 	cvt.rn.satfinite.e4m3x2.f32  %rs41, %r79, %r78; 
(EngineCore_DP0 pid=391823) 
(EngineCore_DP0 pid=391823) 	// end inline asm
(EngineCore_DP0 pid=391823) 	shr.u16 	%rs45, %rs41, 8;
(EngineCore_DP0 pid=391823) 	.loc	1 235 27                        // quant_slide_tuned_Llama3.2-3B.py:235:27
(EngineCore_DP0 pid=391823) 	mul.f32 	%r107, %r14, %r97;
(EngineCore_DP0 pid=391823) 	mul.f32 	%r108, %r14, %r98;
(EngineCore_DP0 pid=391823) 	.loc	1 235 48                        // quant_slide_tuned_Llama3.2-3B.py:235:48
(EngineCore_DP0 pid=391823) 	min.xorsign.abs.f32 	%r80, %r107, %r104;
(EngineCore_DP0 pid=391823) 	min.xorsign.abs.f32 	%r81, %r108, %r104;
(EngineCore_DP0 pid=391823) 	.loc	1 235 60                        // quant_slide_tuned_Llama3.2-3B.py:235:60
(EngineCore_DP0 pid=391823) 	// begin inline asm
(EngineCore_DP0 pid=391823) 	cvt.rn.satfinite.e4m3x2.f32  %rs42, %r81, %r80; 
(EngineCore_DP0 pid=391823) 
(EngineCore_DP0 pid=391823) 	// end inline asm
(EngineCore_DP0 pid=391823) 	shr.u16 	%rs46, %rs42, 8;
(EngineCore_DP0 pid=391823) 	.loc	1 236 27                        // quant_slide_tuned_Llama3.2-3B.py:236:27
(EngineCore_DP0 pid=391823) 	mul.f32 	%r109, %r14, %r100;
(EngineCore_DP0 pid=391823) 	mul.f32 	%r110, %r14, %r101;
(EngineCore_DP0 pid=391823) 	.loc	1 236 48                        // quant_slide_tuned_Llama3.2-3B.py:236:48
(EngineCore_DP0 pid=391823) 	min.xorsign.abs.f32 	%r82, %r109, %r104;
(EngineCore_DP0 pid=391823) 	min.xorsign.abs.f32 	%r83, %r110, %r104;
(EngineCore_DP0 pid=391823) 	.loc	1 236 60                        // quant_slide_tuned_Llama3.2-3B.py:236:60
(EngineCore_DP0 pid=391823) 	// begin inline asm
(EngineCore_DP0 pid=391823) 	cvt.rn.satfinite.e4m3x2.f32  %rs43, %r83, %r82; 
(EngineCore_DP0 pid=391823) 
(EngineCore_DP0 pid=391823) 	// end inline asm
(EngineCore_DP0 pid=391823) 	shr.u16 	%rs47, %rs43, 8;
(EngineCore_DP0 pid=391823) 	.loc	1 238 45                        // quant_slide_tuned_Llama3.2-3B.py:238:45
(EngineCore_DP0 pid=391823) 	cvt.u32.u16 	%r111, %rs40;
(EngineCore_DP0 pid=391823) 	and.b32 	%r112, %r111, 255;
(EngineCore_DP0 pid=391823) 	cvt.u32.u16 	%r113, %rs44;
(EngineCore_DP0 pid=391823) 	.loc	1 240 45                        // quant_slide_tuned_Llama3.2-3B.py:240:45
(EngineCore_DP0 pid=391823) 	cvt.u32.u16 	%r114, %rs42;
(EngineCore_DP0 pid=391823) 	and.b32 	%r115, %r114, 255;
(EngineCore_DP0 pid=391823) 	cvt.u32.u16 	%r116, %rs46;
(EngineCore_DP0 pid=391823) 	.loc	1 241 45                        // quant_slide_tuned_Llama3.2-3B.py:241:45
(EngineCore_DP0 pid=391823) 	cvt.u32.u16 	%r117, %rs43;
(EngineCore_DP0 pid=391823) 	cvt.u32.u16 	%r118, %rs47;
(EngineCore_DP0 pid=391823) 	.loc	1 243 30                        // quant_slide_tuned_Llama3.2-3B.py:243:30
(EngineCore_DP0 pid=391823) 	and.b16 	%rs48, %rs41, 255;
(EngineCore_DP0 pid=391823) 	mul.wide.u16 	%r119, %rs48, 256;
(EngineCore_DP0 pid=391823) 	mul.wide.u16 	%r120, %rs45, 256;
(EngineCore_DP0 pid=391823) 	.loc	1 243 24                        // quant_slide_tuned_Llama3.2-3B.py:243:24
(EngineCore_DP0 pid=391823) 	or.b32 	%r121, %r119, %r112;
(EngineCore_DP0 pid=391823) 	or.b32 	%r122, %r120, %r113;
(EngineCore_DP0 pid=391823) 	.loc	1 243 42                        // quant_slide_tuned_Llama3.2-3B.py:243:42
(EngineCore_DP0 pid=391823) 	shl.b32 	%r123, %r115, 16;
(EngineCore_DP0 pid=391823) 	shl.b32 	%r124, %r116, 16;
(EngineCore_DP0 pid=391823) 	.loc	1 243 36                        // quant_slide_tuned_Llama3.2-3B.py:243:36
(EngineCore_DP0 pid=391823) 	or.b32 	%r125, %r121, %r123;
(EngineCore_DP0 pid=391823) 	or.b32 	%r126, %r122, %r124;
(EngineCore_DP0 pid=391823) 	.loc	1 243 55                        // quant_slide_tuned_Llama3.2-3B.py:243:55
(EngineCore_DP0 pid=391823) 	shl.b32 	%r127, %r117, 24;
(EngineCore_DP0 pid=391823) 	shl.b32 	%r128, %r118, 24;
(EngineCore_DP0 pid=391823) 	.loc	1 243 49                        // quant_slide_tuned_Llama3.2-3B.py:243:49
(EngineCore_DP0 pid=391823) 	or.b32 	%r84, %r125, %r127;
(EngineCore_DP0 pid=391823) 	or.b32 	%r85, %r126, %r128;
(EngineCore_DP0 pid=391823) 	.loc	1 244 29                        // quant_slide_tuned_Llama3.2-3B.py:244:29
(EngineCore_DP0 pid=391823) 	mad.wide.s32 	%rd16, %r86, 4, %rd2;
(EngineCore_DP0 pid=391823) 	.loc	1 244 39                        // quant_slide_tuned_Llama3.2-3B.py:244:39
(EngineCore_DP0 pid=391823) 	// begin inline asm
(EngineCore_DP0 pid=391823) 	@%p17 st.global.v2.b32 [ %rd16 + 0 ], { %r84, %r85 };
(EngineCore_DP0 pid=391823) 	// end inline asm
(EngineCore_DP0 pid=391823) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=391823) 	add.s32 	%r133, %r133, 1024;
(EngineCore_DP0 pid=391823) 	add.s32 	%r132, %r132, 4096;
(EngineCore_DP0 pid=391823) 	setp.lt.s32 	%p26, %r133, %r23;
(EngineCore_DP0 pid=391823) 	@%p26 bra 	$L__BB0_6;
(EngineCore_DP0 pid=391823) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=391823) 	.loc	1 215 4                         // quant_slide_tuned_Llama3.2-3B.py:215:4
(EngineCore_DP0 pid=391823) 	ret;
(EngineCore_DP0 pid=391823) $L__tmp3:
(EngineCore_DP0 pid=391823) $L__func_end0:
(EngineCore_DP0 pid=391823)                                         // -- End function
(EngineCore_DP0 pid=391823) }
(EngineCore_DP0 pid=391823) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py"
(EngineCore_DP0 pid=391823) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=391823) 	.section	.debug_abbrev
(EngineCore_DP0 pid=391823) 	{
(EngineCore_DP0 pid=391823) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=391823) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=391823) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=391823) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=391823) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=391823) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=391823) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=391823) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=391823) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=391823) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=391823) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=391823) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=391823) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=391823) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=391823) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=391823) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=391823) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=391823) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=391823) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=391823) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=391823) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=391823) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=391823) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=391823) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=391823) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=391823) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=391823) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=391823) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=391823) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=391823) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=391823) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=391823) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=391823) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=391823) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=391823) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=391823) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=391823) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=391823) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=391823) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=391823) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=391823) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=391823) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=391823) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=391823) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=391823) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=391823) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=391823) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=391823) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=391823) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=391823) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=391823) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=391823) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=391823) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=391823) 	}
(EngineCore_DP0 pid=391823) 	.section	.debug_info
(EngineCore_DP0 pid=391823) 	{
(EngineCore_DP0 pid=391823) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=391823) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=391823) .b8 0
(EngineCore_DP0 pid=391823) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=391823) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=391823) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=391823) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=391823) .b8 114
(EngineCore_DP0 pid=391823) .b8 105
(EngineCore_DP0 pid=391823) .b8 116
(EngineCore_DP0 pid=391823) .b8 111
(EngineCore_DP0 pid=391823) .b8 110
(EngineCore_DP0 pid=391823) .b8 0
(EngineCore_DP0 pid=391823) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=391823) .b8 0
(EngineCore_DP0 pid=391823) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=391823) .b8 117
(EngineCore_DP0 pid=391823) .b8 97
(EngineCore_DP0 pid=391823) .b8 110
(EngineCore_DP0 pid=391823) .b8 116
(EngineCore_DP0 pid=391823) .b8 95
(EngineCore_DP0 pid=391823) .b8 115
(EngineCore_DP0 pid=391823) .b8 108
(EngineCore_DP0 pid=391823) .b8 105
(EngineCore_DP0 pid=391823) .b8 100
(EngineCore_DP0 pid=391823) .b8 101
(EngineCore_DP0 pid=391823) .b8 95
(EngineCore_DP0 pid=391823) .b8 116
(EngineCore_DP0 pid=391823) .b8 117
(EngineCore_DP0 pid=391823) .b8 110
(EngineCore_DP0 pid=391823) .b8 101
(EngineCore_DP0 pid=391823) .b8 100
(EngineCore_DP0 pid=391823) .b8 95
(EngineCore_DP0 pid=391823) .b8 76
(EngineCore_DP0 pid=391823) .b8 108
(EngineCore_DP0 pid=391823) .b8 97
(EngineCore_DP0 pid=391823) .b8 109
(EngineCore_DP0 pid=391823) .b8 97
(EngineCore_DP0 pid=391823) .b8 51
(EngineCore_DP0 pid=391823) .b8 46
(EngineCore_DP0 pid=391823) .b8 50
(EngineCore_DP0 pid=391823) .b8 45
(EngineCore_DP0 pid=391823) .b8 51
(EngineCore_DP0 pid=391823) .b8 66
(EngineCore_DP0 pid=391823) .b8 46
(EngineCore_DP0 pid=391823) .b8 112
(EngineCore_DP0 pid=391823) .b8 121
(EngineCore_DP0 pid=391823) .b8 0
(EngineCore_DP0 pid=391823) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=391823) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=391823) .b8 114
(EngineCore_DP0 pid=391823) .b8 111
(EngineCore_DP0 pid=391823) .b8 111
(EngineCore_DP0 pid=391823) .b8 116
(EngineCore_DP0 pid=391823) .b8 47
(EngineCore_DP0 pid=391823) .b8 118
(EngineCore_DP0 pid=391823) .b8 108
(EngineCore_DP0 pid=391823) .b8 108
(EngineCore_DP0 pid=391823) .b8 109
(EngineCore_DP0 pid=391823) .b8 98
(EngineCore_DP0 pid=391823) .b8 101
(EngineCore_DP0 pid=391823) .b8 110
(EngineCore_DP0 pid=391823) .b8 99
(EngineCore_DP0 pid=391823) .b8 104
(EngineCore_DP0 pid=391823) .b8 47
(EngineCore_DP0 pid=391823) .b8 115
(EngineCore_DP0 pid=391823) .b8 108
(EngineCore_DP0 pid=391823) .b8 105
(EngineCore_DP0 pid=391823) .b8 100
(EngineCore_DP0 pid=391823) .b8 101
(EngineCore_DP0 pid=391823) .b8 115
(EngineCore_DP0 pid=391823) .b8 112
(EngineCore_DP0 pid=391823) .b8 97
(EngineCore_DP0 pid=391823) .b8 114
(EngineCore_DP0 pid=391823) .b8 115
(EngineCore_DP0 pid=391823) .b8 101
(EngineCore_DP0 pid=391823) .b8 47
(EngineCore_DP0 pid=391823) .b8 99
(EngineCore_DP0 pid=391823) .b8 115
(EngineCore_DP0 pid=391823) .b8 114
(EngineCore_DP0 pid=391823) .b8 99
(EngineCore_DP0 pid=391823) .b8 47
(EngineCore_DP0 pid=391823) .b8 102
(EngineCore_DP0 pid=391823) .b8 117
(EngineCore_DP0 pid=391823) .b8 115
(EngineCore_DP0 pid=391823) .b8 101
(EngineCore_DP0 pid=391823) .b8 100
(EngineCore_DP0 pid=391823) .b8 95
(EngineCore_DP0 pid=391823) .b8 113
(EngineCore_DP0 pid=391823) .b8 117
(EngineCore_DP0 pid=391823) .b8 97
(EngineCore_DP0 pid=391823) .b8 110
(EngineCore_DP0 pid=391823) .b8 116
(EngineCore_DP0 pid=391823) .b8 95
(EngineCore_DP0 pid=391823) .b8 115
(EngineCore_DP0 pid=391823) .b8 108
(EngineCore_DP0 pid=391823) .b8 105
(EngineCore_DP0 pid=391823) .b8 100
(EngineCore_DP0 pid=391823) .b8 101
(EngineCore_DP0 pid=391823) .b8 95
(EngineCore_DP0 pid=391823) .b8 116
(EngineCore_DP0 pid=391823) .b8 114
(EngineCore_DP0 pid=391823) .b8 105
(EngineCore_DP0 pid=391823) .b8 116
(EngineCore_DP0 pid=391823) .b8 111
(EngineCore_DP0 pid=391823) .b8 110
(EngineCore_DP0 pid=391823) .b8 47
(EngineCore_DP0 pid=391823) .b8 98
(EngineCore_DP0 pid=391823) .b8 117
(EngineCore_DP0 pid=391823) .b8 105
(EngineCore_DP0 pid=391823) .b8 108
(EngineCore_DP0 pid=391823) .b8 100
(EngineCore_DP0 pid=391823) .b8 47
(EngineCore_DP0 pid=391823) .b8 71
(EngineCore_DP0 pid=391823) .b8 66
(EngineCore_DP0 pid=391823) .b8 49
(EngineCore_DP0 pid=391823) .b8 48
(EngineCore_DP0 pid=391823) .b8 95
(EngineCore_DP0 pid=391823) .b8 99
(EngineCore_DP0 pid=391823) .b8 99
(EngineCore_DP0 pid=391823) .b8 49
(EngineCore_DP0 pid=391823) .b8 50
(EngineCore_DP0 pid=391823) .b8 49
(EngineCore_DP0 pid=391823) .b8 95
(EngineCore_DP0 pid=391823) .b8 112
(EngineCore_DP0 pid=391823) .b8 121
(EngineCore_DP0 pid=391823) .b8 51
(EngineCore_DP0 pid=391823) .b8 49
(EngineCore_DP0 pid=391823) .b8 50
(EngineCore_DP0 pid=391823) .b8 95
(EngineCore_DP0 pid=391823) .b8 99
(EngineCore_DP0 pid=391823) .b8 117
(EngineCore_DP0 pid=391823) .b8 49
(EngineCore_DP0 pid=391823) .b8 50
(EngineCore_DP0 pid=391823) .b8 57
(EngineCore_DP0 pid=391823) .b8 95
(EngineCore_DP0 pid=391823) .b8 97
(EngineCore_DP0 pid=391823) .b8 97
(EngineCore_DP0 pid=391823) .b8 114
(EngineCore_DP0 pid=391823) .b8 99
(EngineCore_DP0 pid=391823) .b8 104
(EngineCore_DP0 pid=391823) .b8 54
(EngineCore_DP0 pid=391823) .b8 52
(EngineCore_DP0 pid=391823) .b8 0
(EngineCore_DP0 pid=391823) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=391823) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=391823) .b8 113
(EngineCore_DP0 pid=391823) .b8 117
(EngineCore_DP0 pid=391823) .b8 97
(EngineCore_DP0 pid=391823) .b8 110
(EngineCore_DP0 pid=391823) .b8 116
(EngineCore_DP0 pid=391823) .b8 95
(EngineCore_DP0 pid=391823) .b8 115
(EngineCore_DP0 pid=391823) .b8 108
(EngineCore_DP0 pid=391823) .b8 105
(EngineCore_DP0 pid=391823) .b8 100
(EngineCore_DP0 pid=391823) .b8 101
(EngineCore_DP0 pid=391823) .b8 95
(EngineCore_DP0 pid=391823) .b8 102
(EngineCore_DP0 pid=391823) .b8 112
(EngineCore_DP0 pid=391823) .b8 56
(EngineCore_DP0 pid=391823) .b8 95
(EngineCore_DP0 pid=391823) .b8 107
(EngineCore_DP0 pid=391823) .b8 101
(EngineCore_DP0 pid=391823) .b8 114
(EngineCore_DP0 pid=391823) .b8 110
(EngineCore_DP0 pid=391823) .b8 101
(EngineCore_DP0 pid=391823) .b8 108
(EngineCore_DP0 pid=391823) .b8 0
(EngineCore_DP0 pid=391823) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=391823) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=391823) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=391823) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=391823) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=391823) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=391823) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=391823) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=391823) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=391823) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=391823) .b8 205                                 // DW_AT_call_line
(EngineCore_DP0 pid=391823) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=391823) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=391823) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=391823) 	}
(EngineCore_DP0 pid=391823) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=391823) 
(EngineCore_DP0 pid=391823) ================================================================
(EngineCore_DP0 pid=391823) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=391823) 
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp_iwn0dp4.ptx', '-o', '/tmp/tmp_iwn0dp4.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866] 
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866] 
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866] 
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp_iwn0dp4.ptx -o /tmp/tmp_iwn0dp4.ptx.o
(EngineCore_DP0 pid=391823) ERROR 01-25 20:04:16 [core.py:866] 

STDERR:
[2026-01-25 20:03:54] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:03:54] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:03:54] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:03:54] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:03:54] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:03:54] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:03:54] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:03:54] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:03:54] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:03:54] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:03:54] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:03:54] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:03:54] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:03:54] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:03:58] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:03:58] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:03:58] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:03:58] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:03:58] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:03:58] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:03:58] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:03:58] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:03:58] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:03:58] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:03:58] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:03:58] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:03:58] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:03:58] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=391823) [2026-01-25 20:03:59] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=391823) [2026-01-25 20:03:59] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=391823) [2026-01-25 20:03:59] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=391823) [2026-01-25 20:03:59] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=391823) [2026-01-25 20:03:59] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=391823) [2026-01-25 20:03:59] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=391823) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=391823) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:15<00:00, 15.63s/it]
(EngineCore_DP0 pid=391823) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:15<00:00, 15.63s/it]
(EngineCore_DP0 pid=391823) 
(EngineCore_DP0 pid=391823) [2026-01-25 20:04:15] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 3072] -> 1D uint8
(EngineCore_DP0 pid=391823) [2026-01-25 20:04:15] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9830400 bytes
(EngineCore_DP0 pid=391823) [2026-01-25 20:04:15] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=391823) [2026-01-25 20:04:15] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5898240 bytes
(EngineCore_DP0 pid=391823) [2026-01-25 20:04:15] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=391823) [2026-01-25 20:04:15] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 31457280 bytes
(EngineCore_DP0 pid=391823) [2026-01-25 20:04:15] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 8192] -> 1D uint8
(EngineCore_DP0 pid=391823) [2026-01-25 20:04:15] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15728640 bytes
(EngineCore_DP0 pid=391823) Process EngineCore_DP0:
(EngineCore_DP0 pid=391823) Traceback (most recent call last):
(EngineCore_DP0 pid=391823)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=391823)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=391823)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=391823)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=391823) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp_iwn0dp4.ptx', '-o', '/tmp/tmp_iwn0dp4.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=391823) 
(EngineCore_DP0 pid=391823) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=391823) 
(EngineCore_DP0 pid=391823) Traceback (most recent call last):
(EngineCore_DP0 pid=391823)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=391823)     self.run()
(EngineCore_DP0 pid=391823)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=391823)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=391823)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=391823)     raise e
(EngineCore_DP0 pid=391823)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=391823)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=391823)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=391823)     super().__init__(
(EngineCore_DP0 pid=391823)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=391823)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=391823)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=391823)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=391823)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=391823)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=391823)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=391823)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=391823)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=391823)     return func(*args, **kwargs)
(EngineCore_DP0 pid=391823)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=391823)     return func(*args, **kwargs)
(EngineCore_DP0 pid=391823)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=391823)     self.model_runner.profile_run()
(EngineCore_DP0 pid=391823)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=391823)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=391823)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=391823)     return func(*args, **kwargs)
(EngineCore_DP0 pid=391823)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=391823)     outputs = self.model(
(EngineCore_DP0 pid=391823)               ^^^^^^^^^^^
(EngineCore_DP0 pid=391823)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=391823)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=391823)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=391823)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=391823)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=391823)     model_output = self.model(
(EngineCore_DP0 pid=391823)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=391823)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=391823)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=391823)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=391823)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=391823)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=391823)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=391823)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=391823)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=391823)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=391823)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=391823)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=391823)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=391823)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=391823)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=391823)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=391823)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=391823)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=391823)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=391823)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=391823)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=391823)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=391823)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=391823)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=391823)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=391823)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=391823)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=391823)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=391823)     return self._linear_fn(
(EngineCore_DP0 pid=391823)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=391823)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=391823)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=391823)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=391823)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=391823)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=391823)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=391823)     return fn(input, L)
(EngineCore_DP0 pid=391823)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=391823)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=391823)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=391823)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=391823)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=391823)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=391823)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=391823)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=391823)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=391823)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=391823)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=391823)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=391823)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=391823)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=391823)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=391823)     raise PTXASError(error)
(EngineCore_DP0 pid=391823) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=391823) `ptxas` stderr:
(EngineCore_DP0 pid=391823) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=391823) 
(EngineCore_DP0 pid=391823) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp_iwn0dp4.ptx -o /tmp/tmp_iwn0dp4.ptx.o
(EngineCore_DP0 pid=391823) 
[rank0]:[W125 20:04:17.187310713 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=65536

========== M=512 ==========
Time: 2026-01-25 21:17:07
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Qwen2.5-7B-FP8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:17:11 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 21:17:11 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=466696) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=466696) 
(EngineCore_DP0 pid=466696) 
(EngineCore_DP0 pid=466696) ================================================================
(EngineCore_DP0 pid=466696) Internal Triton PTX codegen error
(EngineCore_DP0 pid=466696) `ptxas` stderr:
(EngineCore_DP0 pid=466696) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=466696) 
(EngineCore_DP0 pid=466696) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp_hqyeqx5.ptx -o /tmp/tmp_hqyeqx5.ptx.o
(EngineCore_DP0 pid=466696) 
(EngineCore_DP0 pid=466696) 
(EngineCore_DP0 pid=466696) //
(EngineCore_DP0 pid=466696) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=466696) //
(EngineCore_DP0 pid=466696) 
(EngineCore_DP0 pid=466696) .version 8.7
(EngineCore_DP0 pid=466696) .target sm_121a
(EngineCore_DP0 pid=466696) .address_size 64
(EngineCore_DP0 pid=466696) 
(EngineCore_DP0 pid=466696) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=466696) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=466696)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=466696) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=466696) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=466696) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=466696) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=466696) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=466696) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=466696) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=466696) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=466696) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=466696) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=466696) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=466696) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=466696) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=466696) )
(EngineCore_DP0 pid=466696) .reqntid 1024
(EngineCore_DP0 pid=466696) {
(EngineCore_DP0 pid=466696) 	.reg .pred 	%p<20>;
(EngineCore_DP0 pid=466696) 	.reg .b16 	%rs<25>;
(EngineCore_DP0 pid=466696) 	.reg .b32 	%r<108>;
(EngineCore_DP0 pid=466696) 	.reg .b64 	%rd<13>;
(EngineCore_DP0 pid=466696) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=466696) $L__func_begin0:
(EngineCore_DP0 pid=466696) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=466696) 
(EngineCore_DP0 pid=466696) // %bb.0:
(EngineCore_DP0 pid=466696) 	ld.param.b32 	%r20, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=466696) 	ld.param.b32 	%r19, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=466696) 	ld.param.b32 	%r18, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=466696) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=466696) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=466696) $L__tmp0:
(EngineCore_DP0 pid=466696) 	.loc	1 143 24                        // quant_slide_tuned_Qwen2.5-7B.py:143:24
(EngineCore_DP0 pid=466696) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=466696) 	ld.param.b32 	%r22, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=466696) 	.loc	1 148 26                        // quant_slide_tuned_Qwen2.5-7B.py:148:26
(EngineCore_DP0 pid=466696) 	mul.lo.s32 	%r23, %r22, %r1;
(EngineCore_DP0 pid=466696) 	.loc	1 148 20                        // quant_slide_tuned_Qwen2.5-7B.py:148:20
(EngineCore_DP0 pid=466696) 	mad.wide.s32 	%rd1, %r23, 2, %rd4;
(EngineCore_DP0 pid=466696) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=466696) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=466696) 	shl.b32 	%r106, %r2, 2;
(EngineCore_DP0 pid=466696) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=466696) 	setp.lt.s32 	%p1, %r19, 1;
(EngineCore_DP0 pid=466696) 	mov.b32 	%r105, 0f2B8CBCCC;
(EngineCore_DP0 pid=466696) 	setp.eq.b32 	%p19, %r2, 0;
(EngineCore_DP0 pid=466696) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=466696) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=466696) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=466696) 	and.b32 	%r4, %r2, 31;
(EngineCore_DP0 pid=466696) 	shr.u32 	%r32, %r2, 3;
(EngineCore_DP0 pid=466696) 	and.b32 	%r33, %r32, 124;
(EngineCore_DP0 pid=466696) 	mov.b32 	%r34, global_smem;
(EngineCore_DP0 pid=466696) 	add.s32 	%r40, %r34, %r33;
(EngineCore_DP0 pid=466696) 	shl.b32 	%r35, %r2, 2;
(EngineCore_DP0 pid=466696) 	add.s32 	%r43, %r34, %r35;
(EngineCore_DP0 pid=466696) 	mov.b32 	%r38, 0;
(EngineCore_DP0 pid=466696) 	mov.b32 	%r103, 0f00000000;
(EngineCore_DP0 pid=466696) 	setp.lt.u32 	%p4, %r2, 32;
(EngineCore_DP0 pid=466696) 	setp.eq.b32 	%p3, %r4, 0;
(EngineCore_DP0 pid=466696) 	mov.b32 	%r104, %r38;
(EngineCore_DP0 pid=466696) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=466696) 	.loc	1 155 22                        // quant_slide_tuned_Qwen2.5-7B.py:155:22
(EngineCore_DP0 pid=466696) 	add.s32 	%r46, %r106, %r104;
(EngineCore_DP0 pid=466696) 	setp.lt.s32 	%p2, %r46, %r18;
(EngineCore_DP0 pid=466696) 	.loc	1 156 29                        // quant_slide_tuned_Qwen2.5-7B.py:156:29
(EngineCore_DP0 pid=466696) 	mad.wide.s32 	%rd6, %r46, 2, %rd1;
(EngineCore_DP0 pid=466696) 	.loc	1 156 21                        // quant_slide_tuned_Qwen2.5-7B.py:156:21
(EngineCore_DP0 pid=466696) 	// begin inline asm
(EngineCore_DP0 pid=466696) 	mov.u32 %r36, %r38;
(EngineCore_DP0 pid=466696) 	mov.u32 %r37, %r38;
(EngineCore_DP0 pid=466696) 	@%p2 ld.global.v2.b32 { %r36, %r37 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=466696) 	// end inline asm
(EngineCore_DP0 pid=466696) 	mov.b32 	{%rs1, %rs2}, %r36;
(EngineCore_DP0 pid=466696) 	mov.b32 	{%rs3, %rs4}, %r37;
(EngineCore_DP0 pid=466696) 	.loc	1 157 50                        // quant_slide_tuned_Qwen2.5-7B.py:157:50
(EngineCore_DP0 pid=466696) 	abs.bf16 	%rs5, %rs1;
(EngineCore_DP0 pid=466696) 	abs.bf16 	%rs6, %rs2;
(EngineCore_DP0 pid=466696) 	abs.bf16 	%rs7, %rs3;
(EngineCore_DP0 pid=466696) 	abs.bf16 	%rs8, %rs4;
(EngineCore_DP0 pid=466696) $L__tmp1:
(EngineCore_DP0 pid=466696) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=466696) 	bar.sync 	0;
(EngineCore_DP0 pid=466696) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=466696) 	max.bf16 	%rs9, %rs5, %rs6;
(EngineCore_DP0 pid=466696) 	max.bf16 	%rs10, %rs9, %rs7;
(EngineCore_DP0 pid=466696) 	max.bf16 	%rs11, %rs10, %rs8;
(EngineCore_DP0 pid=466696) 	cvt.f32.bf16 	%r47, %rs11;
(EngineCore_DP0 pid=466696) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=466696) 	shfl.sync.bfly.b32 	%r48, %r47, 16, 31, -1;
(EngineCore_DP0 pid=466696) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=466696) 	max.f32 	%r49, %r47, %r48;
(EngineCore_DP0 pid=466696) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=466696) 	shfl.sync.bfly.b32 	%r50, %r49, 8, 31, -1;
(EngineCore_DP0 pid=466696) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=466696) 	max.f32 	%r51, %r49, %r50;
(EngineCore_DP0 pid=466696) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=466696) 	shfl.sync.bfly.b32 	%r52, %r51, 4, 31, -1;
(EngineCore_DP0 pid=466696) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=466696) 	max.f32 	%r53, %r51, %r52;
(EngineCore_DP0 pid=466696) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=466696) 	shfl.sync.bfly.b32 	%r54, %r53, 2, 31, -1;
(EngineCore_DP0 pid=466696) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=466696) 	max.f32 	%r55, %r53, %r54;
(EngineCore_DP0 pid=466696) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=466696) 	shfl.sync.bfly.b32 	%r56, %r55, 1, 31, -1;
(EngineCore_DP0 pid=466696) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=466696) 	max.f32 	%r41, %r55, %r56;
(EngineCore_DP0 pid=466696) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=466696) 	// begin inline asm
(EngineCore_DP0 pid=466696) 	@%p3 st.shared.b32 [ %r40 + 0 ], %r41;
(EngineCore_DP0 pid=466696) 	// end inline asm
(EngineCore_DP0 pid=466696) 	bar.sync 	0;
(EngineCore_DP0 pid=466696) 	// begin inline asm
(EngineCore_DP0 pid=466696) 	@%p4 ld.shared.b32 %r42, [ %r43 + 0 ];
(EngineCore_DP0 pid=466696) 	// end inline asm
(EngineCore_DP0 pid=466696) 	shfl.sync.bfly.b32 	%r57, %r42, 16, 31, -1;
(EngineCore_DP0 pid=466696) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=466696) 	max.f32 	%r58, %r42, %r57;
(EngineCore_DP0 pid=466696) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=466696) 	shfl.sync.bfly.b32 	%r59, %r58, 8, 31, -1;
(EngineCore_DP0 pid=466696) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=466696) 	max.f32 	%r60, %r58, %r59;
(EngineCore_DP0 pid=466696) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=466696) 	shfl.sync.bfly.b32 	%r61, %r60, 4, 31, -1;
(EngineCore_DP0 pid=466696) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=466696) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=466696) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=466696) 	shfl.sync.bfly.b32 	%r63, %r62, 2, 31, -1;
(EngineCore_DP0 pid=466696) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=466696) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=466696) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=466696) 	shfl.sync.bfly.b32 	%r65, %r64, 1, 31, -1;
(EngineCore_DP0 pid=466696) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=466696) 	max.f32 	%r45, %r64, %r65;
(EngineCore_DP0 pid=466696) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=466696) 	// begin inline asm
(EngineCore_DP0 pid=466696) 	@%p19 st.shared.b32 [ %r43 + 0 ], %r45;
(EngineCore_DP0 pid=466696) 	// end inline asm
(EngineCore_DP0 pid=466696) 	bar.sync 	0;
(EngineCore_DP0 pid=466696) 	ld.shared.b32 	%r66, [global_smem];
(EngineCore_DP0 pid=466696) $L__tmp2:
(EngineCore_DP0 pid=466696) 	.loc	1 157 36                        // quant_slide_tuned_Qwen2.5-7B.py:157:36
(EngineCore_DP0 pid=466696) 	max.f32 	%r103, %r103, %r66;
(EngineCore_DP0 pid=466696) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=466696) 	add.s32 	%r104, %r104, 4096;
(EngineCore_DP0 pid=466696) 	setp.lt.s32 	%p6, %r104, %r19;
(EngineCore_DP0 pid=466696) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=466696) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=466696) 	.loc	1 159 32                        // quant_slide_tuned_Qwen2.5-7B.py:159:32
(EngineCore_DP0 pid=466696) 	max.f32 	%r105, %r103, 0f2B8CBCCC;
(EngineCore_DP0 pid=466696) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=466696) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-7B.py:0:32
(EngineCore_DP0 pid=466696) 	mov.b32 	%r68, 0f43E00000;
(EngineCore_DP0 pid=466696) 	.loc	1 160 32                        // quant_slide_tuned_Qwen2.5-7B.py:160:32
(EngineCore_DP0 pid=466696) 	div.full.f32 	%r69, %r105, %r68;
(EngineCore_DP0 pid=466696) 	.loc	1 160 41                        // quant_slide_tuned_Qwen2.5-7B.py:160:41
(EngineCore_DP0 pid=466696) 	max.f32 	%r67, %r69, 0f36924925;
(EngineCore_DP0 pid=466696) 	.loc	1 162 25                        // quant_slide_tuned_Qwen2.5-7B.py:162:25
(EngineCore_DP0 pid=466696) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=466696) 	.loc	1 162 30                        // quant_slide_tuned_Qwen2.5-7B.py:162:30
(EngineCore_DP0 pid=466696) 	// begin inline asm
(EngineCore_DP0 pid=466696) 	@%p19 st.global.b32 [ %rd7 + 0 ], { %r67 };
(EngineCore_DP0 pid=466696) 	// end inline asm
(EngineCore_DP0 pid=466696) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=466696) 	setp.lt.s32 	%p8, %r20, 1;
(EngineCore_DP0 pid=466696) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=466696) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=466696) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-7B.py:0:41
(EngineCore_DP0 pid=466696) 	ld.param.b32 	%r24, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=466696) 	shr.s32 	%r25, %r24, 31;
(EngineCore_DP0 pid=466696) 	shr.u32 	%r26, %r25, 30;
(EngineCore_DP0 pid=466696) 	add.s32 	%r27, %r24, %r26;
(EngineCore_DP0 pid=466696) 	shr.s32 	%r28, %r27, 2;
(EngineCore_DP0 pid=466696) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=466696) 	mul.lo.s32 	%r29, %r28, %r1;
(EngineCore_DP0 pid=466696) 	mad.wide.s32 	%rd2, %r29, 4, %rd5;
(EngineCore_DP0 pid=466696) 	div.full.f32 	%r13, %r68, %r105;
(EngineCore_DP0 pid=466696) 	mov.b32 	%r107, 0;
(EngineCore_DP0 pid=466696) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=466696)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=466696) 	.loc	1 169 30                        // quant_slide_tuned_Qwen2.5-7B.py:169:30
(EngineCore_DP0 pid=466696) 	add.s32 	%r80, %r2, %r107;
(EngineCore_DP0 pid=466696) 	setp.lt.s32 	%p13, %r80, %r20;
(EngineCore_DP0 pid=466696) 	.loc	1 177 53                        // quant_slide_tuned_Qwen2.5-7B.py:177:53
(EngineCore_DP0 pid=466696) 	setp.lt.s32 	%p14, %r106, %r18;
(EngineCore_DP0 pid=466696) 	.loc	1 177 37                        // quant_slide_tuned_Qwen2.5-7B.py:177:37
(EngineCore_DP0 pid=466696) 	and.pred 	%p9, %p13, %p14;
(EngineCore_DP0 pid=466696) 	.loc	1 176 29                        // quant_slide_tuned_Qwen2.5-7B.py:176:29
(EngineCore_DP0 pid=466696) 	mad.wide.s32 	%rd8, %r106, 2, %rd1;
(EngineCore_DP0 pid=466696) 	mov.b16 	%rs13, 0;
(EngineCore_DP0 pid=466696) 	.loc	1 176 21                        // quant_slide_tuned_Qwen2.5-7B.py:176:21
(EngineCore_DP0 pid=466696) 	// begin inline asm
(EngineCore_DP0 pid=466696) 	mov.u16 %rs12, %rs13;
(EngineCore_DP0 pid=466696) 	@%p9 ld.global.b16 { %rs12 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=466696) 	// end inline asm
(EngineCore_DP0 pid=466696) 	.loc	1 177 79                        // quant_slide_tuned_Qwen2.5-7B.py:177:79
(EngineCore_DP0 pid=466696) 	cvt.f32.bf16 	%r81, %rs12;
(EngineCore_DP0 pid=466696) 	.loc	1 179 53                        // quant_slide_tuned_Qwen2.5-7B.py:179:53
(EngineCore_DP0 pid=466696) 	add.s32 	%r82, %r106, 1;
(EngineCore_DP0 pid=466696) 	setp.lt.s32 	%p15, %r82, %r18;
(EngineCore_DP0 pid=466696) 	.loc	1 179 37                        // quant_slide_tuned_Qwen2.5-7B.py:179:37
(EngineCore_DP0 pid=466696) 	and.pred 	%p10, %p13, %p15;
(EngineCore_DP0 pid=466696) 	.loc	1 178 39                        // quant_slide_tuned_Qwen2.5-7B.py:178:39
(EngineCore_DP0 pid=466696) 	add.s64 	%rd9, %rd8, 2;
(EngineCore_DP0 pid=466696) 	.loc	1 178 21                        // quant_slide_tuned_Qwen2.5-7B.py:178:21
(EngineCore_DP0 pid=466696) 	// begin inline asm
(EngineCore_DP0 pid=466696) 	mov.u16 %rs14, %rs13;
(EngineCore_DP0 pid=466696) 	@%p10 ld.global.b16 { %rs14 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=466696) 	// end inline asm
(EngineCore_DP0 pid=466696) 	.loc	1 179 79                        // quant_slide_tuned_Qwen2.5-7B.py:179:79
(EngineCore_DP0 pid=466696) 	cvt.f32.bf16 	%r83, %rs14;
(EngineCore_DP0 pid=466696) 	.loc	1 181 53                        // quant_slide_tuned_Qwen2.5-7B.py:181:53
(EngineCore_DP0 pid=466696) 	add.s32 	%r84, %r106, 2;
(EngineCore_DP0 pid=466696) 	setp.lt.s32 	%p16, %r84, %r18;
(EngineCore_DP0 pid=466696) 	.loc	1 181 37                        // quant_slide_tuned_Qwen2.5-7B.py:181:37
(EngineCore_DP0 pid=466696) 	and.pred 	%p11, %p13, %p16;
(EngineCore_DP0 pid=466696) 	.loc	1 180 39                        // quant_slide_tuned_Qwen2.5-7B.py:180:39
(EngineCore_DP0 pid=466696) 	add.s64 	%rd10, %rd8, 4;
(EngineCore_DP0 pid=466696) 	.loc	1 180 21                        // quant_slide_tuned_Qwen2.5-7B.py:180:21
(EngineCore_DP0 pid=466696) 	// begin inline asm
(EngineCore_DP0 pid=466696) 	mov.u16 %rs16, %rs13;
(EngineCore_DP0 pid=466696) 	@%p11 ld.global.b16 { %rs16 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=466696) 	// end inline asm
(EngineCore_DP0 pid=466696) 	.loc	1 181 79                        // quant_slide_tuned_Qwen2.5-7B.py:181:79
(EngineCore_DP0 pid=466696) 	cvt.f32.bf16 	%r85, %rs16;
(EngineCore_DP0 pid=466696) 	.loc	1 183 53                        // quant_slide_tuned_Qwen2.5-7B.py:183:53
(EngineCore_DP0 pid=466696) 	add.s32 	%r86, %r106, 3;
(EngineCore_DP0 pid=466696) 	setp.lt.s32 	%p17, %r86, %r18;
(EngineCore_DP0 pid=466696) 	.loc	1 183 37                        // quant_slide_tuned_Qwen2.5-7B.py:183:37
(EngineCore_DP0 pid=466696) 	and.pred 	%p12, %p13, %p17;
(EngineCore_DP0 pid=466696) 	.loc	1 182 39                        // quant_slide_tuned_Qwen2.5-7B.py:182:39
(EngineCore_DP0 pid=466696) 	add.s64 	%rd11, %rd8, 6;
(EngineCore_DP0 pid=466696) 	.loc	1 182 21                        // quant_slide_tuned_Qwen2.5-7B.py:182:21
(EngineCore_DP0 pid=466696) 	// begin inline asm
(EngineCore_DP0 pid=466696) 	mov.u16 %rs18, %rs13;
(EngineCore_DP0 pid=466696) 	@%p12 ld.global.b16 { %rs18 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=466696) 	// end inline asm
(EngineCore_DP0 pid=466696) 	.loc	1 183 79                        // quant_slide_tuned_Qwen2.5-7B.py:183:79
(EngineCore_DP0 pid=466696) 	cvt.f32.bf16 	%r87, %rs18;
(EngineCore_DP0 pid=466696) 	.loc	1 185 27                        // quant_slide_tuned_Qwen2.5-7B.py:185:27
(EngineCore_DP0 pid=466696) 	mul.f32 	%r88, %r13, %r81;
(EngineCore_DP0 pid=466696) 	mov.b32 	%r89, 0f43E00000;
(EngineCore_DP0 pid=466696) 	.loc	1 185 48                        // quant_slide_tuned_Qwen2.5-7B.py:185:48
(EngineCore_DP0 pid=466696) 	min.xorsign.abs.f32 	%r71, %r88, %r89;
(EngineCore_DP0 pid=466696) 	.loc	1 185 60                        // quant_slide_tuned_Qwen2.5-7B.py:185:60
(EngineCore_DP0 pid=466696) 	// begin inline asm
(EngineCore_DP0 pid=466696) 	cvt.rn.satfinite.e4m3x2.f32  %rs20, %r72, %r71; 
(EngineCore_DP0 pid=466696) 
(EngineCore_DP0 pid=466696) 	// end inline asm
(EngineCore_DP0 pid=466696) 	.loc	1 186 27                        // quant_slide_tuned_Qwen2.5-7B.py:186:27
(EngineCore_DP0 pid=466696) 	mul.f32 	%r90, %r13, %r83;
(EngineCore_DP0 pid=466696) 	.loc	1 186 48                        // quant_slide_tuned_Qwen2.5-7B.py:186:48
(EngineCore_DP0 pid=466696) 	min.xorsign.abs.f32 	%r73, %r90, %r89;
(EngineCore_DP0 pid=466696) 	.loc	1 186 60                        // quant_slide_tuned_Qwen2.5-7B.py:186:60
(EngineCore_DP0 pid=466696) 	// begin inline asm
(EngineCore_DP0 pid=466696) 	cvt.rn.satfinite.e4m3x2.f32  %rs21, %r74, %r73; 
(EngineCore_DP0 pid=466696) 
(EngineCore_DP0 pid=466696) 	// end inline asm
(EngineCore_DP0 pid=466696) 	.loc	1 187 27                        // quant_slide_tuned_Qwen2.5-7B.py:187:27
(EngineCore_DP0 pid=466696) 	mul.f32 	%r91, %r13, %r85;
(EngineCore_DP0 pid=466696) 	.loc	1 187 48                        // quant_slide_tuned_Qwen2.5-7B.py:187:48
(EngineCore_DP0 pid=466696) 	min.xorsign.abs.f32 	%r75, %r91, %r89;
(EngineCore_DP0 pid=466696) 	.loc	1 187 60                        // quant_slide_tuned_Qwen2.5-7B.py:187:60
(EngineCore_DP0 pid=466696) 	// begin inline asm
(EngineCore_DP0 pid=466696) 	cvt.rn.satfinite.e4m3x2.f32  %rs22, %r76, %r75; 
(EngineCore_DP0 pid=466696) 
(EngineCore_DP0 pid=466696) 	// end inline asm
(EngineCore_DP0 pid=466696) 	.loc	1 188 27                        // quant_slide_tuned_Qwen2.5-7B.py:188:27
(EngineCore_DP0 pid=466696) 	mul.f32 	%r92, %r13, %r87;
(EngineCore_DP0 pid=466696) 	.loc	1 188 48                        // quant_slide_tuned_Qwen2.5-7B.py:188:48
(EngineCore_DP0 pid=466696) 	min.xorsign.abs.f32 	%r77, %r92, %r89;
(EngineCore_DP0 pid=466696) 	.loc	1 188 60                        // quant_slide_tuned_Qwen2.5-7B.py:188:60
(EngineCore_DP0 pid=466696) 	// begin inline asm
(EngineCore_DP0 pid=466696) 	cvt.rn.satfinite.e4m3x2.f32  %rs23, %r78, %r77; 
(EngineCore_DP0 pid=466696) 
(EngineCore_DP0 pid=466696) 	// end inline asm
(EngineCore_DP0 pid=466696) 	.loc	1 190 45                        // quant_slide_tuned_Qwen2.5-7B.py:190:45
(EngineCore_DP0 pid=466696) 	cvt.u32.u16 	%r93, %rs20;
(EngineCore_DP0 pid=466696) 	and.b32 	%r94, %r93, 255;
(EngineCore_DP0 pid=466696) 	.loc	1 192 45                        // quant_slide_tuned_Qwen2.5-7B.py:192:45
(EngineCore_DP0 pid=466696) 	cvt.u32.u16 	%r95, %rs22;
(EngineCore_DP0 pid=466696) 	and.b32 	%r96, %r95, 255;
(EngineCore_DP0 pid=466696) 	.loc	1 193 45                        // quant_slide_tuned_Qwen2.5-7B.py:193:45
(EngineCore_DP0 pid=466696) 	cvt.u32.u16 	%r97, %rs23;
(EngineCore_DP0 pid=466696) 	.loc	1 195 30                        // quant_slide_tuned_Qwen2.5-7B.py:195:30
(EngineCore_DP0 pid=466696) 	and.b16 	%rs24, %rs21, 255;
(EngineCore_DP0 pid=466696) 	mul.wide.u16 	%r98, %rs24, 256;
(EngineCore_DP0 pid=466696) 	.loc	1 195 24                        // quant_slide_tuned_Qwen2.5-7B.py:195:24
(EngineCore_DP0 pid=466696) 	or.b32 	%r99, %r98, %r94;
(EngineCore_DP0 pid=466696) 	.loc	1 195 42                        // quant_slide_tuned_Qwen2.5-7B.py:195:42
(EngineCore_DP0 pid=466696) 	shl.b32 	%r100, %r96, 16;
(EngineCore_DP0 pid=466696) 	.loc	1 195 36                        // quant_slide_tuned_Qwen2.5-7B.py:195:36
(EngineCore_DP0 pid=466696) 	or.b32 	%r101, %r99, %r100;
(EngineCore_DP0 pid=466696) 	.loc	1 195 55                        // quant_slide_tuned_Qwen2.5-7B.py:195:55
(EngineCore_DP0 pid=466696) 	shl.b32 	%r102, %r97, 24;
(EngineCore_DP0 pid=466696) 	.loc	1 195 49                        // quant_slide_tuned_Qwen2.5-7B.py:195:49
(EngineCore_DP0 pid=466696) 	or.b32 	%r79, %r101, %r102;
(EngineCore_DP0 pid=466696) 	.loc	1 196 29                        // quant_slide_tuned_Qwen2.5-7B.py:196:29
(EngineCore_DP0 pid=466696) 	mad.wide.s32 	%rd12, %r80, 4, %rd2;
(EngineCore_DP0 pid=466696) 	.loc	1 196 39                        // quant_slide_tuned_Qwen2.5-7B.py:196:39
(EngineCore_DP0 pid=466696) 	// begin inline asm
(EngineCore_DP0 pid=466696) 	@%p13 st.global.b32 [ %rd12 + 0 ], { %r79 };
(EngineCore_DP0 pid=466696) 	// end inline asm
(EngineCore_DP0 pid=466696) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=466696) 	add.s32 	%r107, %r107, 1024;
(EngineCore_DP0 pid=466696) 	add.s32 	%r106, %r106, 4096;
(EngineCore_DP0 pid=466696) 	setp.lt.s32 	%p18, %r107, %r20;
(EngineCore_DP0 pid=466696) 	@%p18 bra 	$L__BB0_6;
(EngineCore_DP0 pid=466696) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=466696) 	.loc	1 167 4                         // quant_slide_tuned_Qwen2.5-7B.py:167:4
(EngineCore_DP0 pid=466696) 	ret;
(EngineCore_DP0 pid=466696) $L__tmp3:
(EngineCore_DP0 pid=466696) $L__func_end0:
(EngineCore_DP0 pid=466696)                                         // -- End function
(EngineCore_DP0 pid=466696) }
(EngineCore_DP0 pid=466696) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py"
(EngineCore_DP0 pid=466696) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=466696) 	.section	.debug_abbrev
(EngineCore_DP0 pid=466696) 	{
(EngineCore_DP0 pid=466696) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=466696) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=466696) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=466696) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=466696) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=466696) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=466696) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=466696) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=466696) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=466696) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=466696) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=466696) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=466696) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=466696) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=466696) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=466696) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=466696) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=466696) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=466696) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=466696) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=466696) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=466696) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=466696) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=466696) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=466696) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=466696) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=466696) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=466696) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=466696) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=466696) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=466696) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=466696) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=466696) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=466696) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=466696) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=466696) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=466696) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=466696) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=466696) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=466696) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=466696) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=466696) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=466696) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=466696) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=466696) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=466696) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=466696) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=466696) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=466696) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=466696) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=466696) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=466696) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=466696) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=466696) 	}
(EngineCore_DP0 pid=466696) 	.section	.debug_info
(EngineCore_DP0 pid=466696) 	{
(EngineCore_DP0 pid=466696) .b32 221                                // Length of Unit
(EngineCore_DP0 pid=466696) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=466696) .b8 0
(EngineCore_DP0 pid=466696) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=466696) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=466696) .b8 1                                   // Abbrev [1] 0xb:0xd6 DW_TAG_compile_unit
(EngineCore_DP0 pid=466696) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=466696) .b8 114
(EngineCore_DP0 pid=466696) .b8 105
(EngineCore_DP0 pid=466696) .b8 116
(EngineCore_DP0 pid=466696) .b8 111
(EngineCore_DP0 pid=466696) .b8 110
(EngineCore_DP0 pid=466696) .b8 0
(EngineCore_DP0 pid=466696) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=466696) .b8 0
(EngineCore_DP0 pid=466696) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=466696) .b8 117
(EngineCore_DP0 pid=466696) .b8 97
(EngineCore_DP0 pid=466696) .b8 110
(EngineCore_DP0 pid=466696) .b8 116
(EngineCore_DP0 pid=466696) .b8 95
(EngineCore_DP0 pid=466696) .b8 115
(EngineCore_DP0 pid=466696) .b8 108
(EngineCore_DP0 pid=466696) .b8 105
(EngineCore_DP0 pid=466696) .b8 100
(EngineCore_DP0 pid=466696) .b8 101
(EngineCore_DP0 pid=466696) .b8 95
(EngineCore_DP0 pid=466696) .b8 116
(EngineCore_DP0 pid=466696) .b8 117
(EngineCore_DP0 pid=466696) .b8 110
(EngineCore_DP0 pid=466696) .b8 101
(EngineCore_DP0 pid=466696) .b8 100
(EngineCore_DP0 pid=466696) .b8 95
(EngineCore_DP0 pid=466696) .b8 81
(EngineCore_DP0 pid=466696) .b8 119
(EngineCore_DP0 pid=466696) .b8 101
(EngineCore_DP0 pid=466696) .b8 110
(EngineCore_DP0 pid=466696) .b8 50
(EngineCore_DP0 pid=466696) .b8 46
(EngineCore_DP0 pid=466696) .b8 53
(EngineCore_DP0 pid=466696) .b8 45
(EngineCore_DP0 pid=466696) .b8 55
(EngineCore_DP0 pid=466696) .b8 66
(EngineCore_DP0 pid=466696) .b8 46
(EngineCore_DP0 pid=466696) .b8 112
(EngineCore_DP0 pid=466696) .b8 121
(EngineCore_DP0 pid=466696) .b8 0
(EngineCore_DP0 pid=466696) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=466696) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=466696) .b8 114
(EngineCore_DP0 pid=466696) .b8 111
(EngineCore_DP0 pid=466696) .b8 111
(EngineCore_DP0 pid=466696) .b8 116
(EngineCore_DP0 pid=466696) .b8 47
(EngineCore_DP0 pid=466696) .b8 118
(EngineCore_DP0 pid=466696) .b8 108
(EngineCore_DP0 pid=466696) .b8 108
(EngineCore_DP0 pid=466696) .b8 109
(EngineCore_DP0 pid=466696) .b8 98
(EngineCore_DP0 pid=466696) .b8 101
(EngineCore_DP0 pid=466696) .b8 110
(EngineCore_DP0 pid=466696) .b8 99
(EngineCore_DP0 pid=466696) .b8 104
(EngineCore_DP0 pid=466696) .b8 47
(EngineCore_DP0 pid=466696) .b8 115
(EngineCore_DP0 pid=466696) .b8 108
(EngineCore_DP0 pid=466696) .b8 105
(EngineCore_DP0 pid=466696) .b8 100
(EngineCore_DP0 pid=466696) .b8 101
(EngineCore_DP0 pid=466696) .b8 115
(EngineCore_DP0 pid=466696) .b8 112
(EngineCore_DP0 pid=466696) .b8 97
(EngineCore_DP0 pid=466696) .b8 114
(EngineCore_DP0 pid=466696) .b8 115
(EngineCore_DP0 pid=466696) .b8 101
(EngineCore_DP0 pid=466696) .b8 47
(EngineCore_DP0 pid=466696) .b8 99
(EngineCore_DP0 pid=466696) .b8 115
(EngineCore_DP0 pid=466696) .b8 114
(EngineCore_DP0 pid=466696) .b8 99
(EngineCore_DP0 pid=466696) .b8 47
(EngineCore_DP0 pid=466696) .b8 102
(EngineCore_DP0 pid=466696) .b8 117
(EngineCore_DP0 pid=466696) .b8 115
(EngineCore_DP0 pid=466696) .b8 101
(EngineCore_DP0 pid=466696) .b8 100
(EngineCore_DP0 pid=466696) .b8 95
(EngineCore_DP0 pid=466696) .b8 113
(EngineCore_DP0 pid=466696) .b8 117
(EngineCore_DP0 pid=466696) .b8 97
(EngineCore_DP0 pid=466696) .b8 110
(EngineCore_DP0 pid=466696) .b8 116
(EngineCore_DP0 pid=466696) .b8 95
(EngineCore_DP0 pid=466696) .b8 115
(EngineCore_DP0 pid=466696) .b8 108
(EngineCore_DP0 pid=466696) .b8 105
(EngineCore_DP0 pid=466696) .b8 100
(EngineCore_DP0 pid=466696) .b8 101
(EngineCore_DP0 pid=466696) .b8 95
(EngineCore_DP0 pid=466696) .b8 116
(EngineCore_DP0 pid=466696) .b8 114
(EngineCore_DP0 pid=466696) .b8 105
(EngineCore_DP0 pid=466696) .b8 116
(EngineCore_DP0 pid=466696) .b8 111
(EngineCore_DP0 pid=466696) .b8 110
(EngineCore_DP0 pid=466696) .b8 47
(EngineCore_DP0 pid=466696) .b8 98
(EngineCore_DP0 pid=466696) .b8 117
(EngineCore_DP0 pid=466696) .b8 105
(EngineCore_DP0 pid=466696) .b8 108
(EngineCore_DP0 pid=466696) .b8 100
(EngineCore_DP0 pid=466696) .b8 47
(EngineCore_DP0 pid=466696) .b8 71
(EngineCore_DP0 pid=466696) .b8 66
(EngineCore_DP0 pid=466696) .b8 49
(EngineCore_DP0 pid=466696) .b8 48
(EngineCore_DP0 pid=466696) .b8 95
(EngineCore_DP0 pid=466696) .b8 99
(EngineCore_DP0 pid=466696) .b8 99
(EngineCore_DP0 pid=466696) .b8 49
(EngineCore_DP0 pid=466696) .b8 50
(EngineCore_DP0 pid=466696) .b8 49
(EngineCore_DP0 pid=466696) .b8 95
(EngineCore_DP0 pid=466696) .b8 112
(EngineCore_DP0 pid=466696) .b8 121
(EngineCore_DP0 pid=466696) .b8 51
(EngineCore_DP0 pid=466696) .b8 49
(EngineCore_DP0 pid=466696) .b8 50
(EngineCore_DP0 pid=466696) .b8 95
(EngineCore_DP0 pid=466696) .b8 99
(EngineCore_DP0 pid=466696) .b8 117
(EngineCore_DP0 pid=466696) .b8 49
(EngineCore_DP0 pid=466696) .b8 50
(EngineCore_DP0 pid=466696) .b8 57
(EngineCore_DP0 pid=466696) .b8 95
(EngineCore_DP0 pid=466696) .b8 97
(EngineCore_DP0 pid=466696) .b8 97
(EngineCore_DP0 pid=466696) .b8 114
(EngineCore_DP0 pid=466696) .b8 99
(EngineCore_DP0 pid=466696) .b8 104
(EngineCore_DP0 pid=466696) .b8 54
(EngineCore_DP0 pid=466696) .b8 52
(EngineCore_DP0 pid=466696) .b8 0
(EngineCore_DP0 pid=466696) .b8 2                                   // Abbrev [2] 0x98:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=466696) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=466696) .b8 113
(EngineCore_DP0 pid=466696) .b8 117
(EngineCore_DP0 pid=466696) .b8 97
(EngineCore_DP0 pid=466696) .b8 110
(EngineCore_DP0 pid=466696) .b8 116
(EngineCore_DP0 pid=466696) .b8 95
(EngineCore_DP0 pid=466696) .b8 115
(EngineCore_DP0 pid=466696) .b8 108
(EngineCore_DP0 pid=466696) .b8 105
(EngineCore_DP0 pid=466696) .b8 100
(EngineCore_DP0 pid=466696) .b8 101
(EngineCore_DP0 pid=466696) .b8 95
(EngineCore_DP0 pid=466696) .b8 102
(EngineCore_DP0 pid=466696) .b8 112
(EngineCore_DP0 pid=466696) .b8 56
(EngineCore_DP0 pid=466696) .b8 95
(EngineCore_DP0 pid=466696) .b8 107
(EngineCore_DP0 pid=466696) .b8 101
(EngineCore_DP0 pid=466696) .b8 114
(EngineCore_DP0 pid=466696) .b8 110
(EngineCore_DP0 pid=466696) .b8 101
(EngineCore_DP0 pid=466696) .b8 108
(EngineCore_DP0 pid=466696) .b8 0
(EngineCore_DP0 pid=466696) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=466696) .b8 3                                   // Abbrev [3] 0xb2:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=466696) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=466696) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=466696) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=466696) .b8 4                                   // Abbrev [4] 0xc7:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=466696) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=466696) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=466696) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=466696) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=466696) .b8 157                                 // DW_AT_call_line
(EngineCore_DP0 pid=466696) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=466696) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=466696) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=466696) 	}
(EngineCore_DP0 pid=466696) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=466696) 
(EngineCore_DP0 pid=466696) ================================================================
(EngineCore_DP0 pid=466696) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=466696) 
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp_hqyeqx5.ptx', '-o', '/tmp/tmp_hqyeqx5.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866] 
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866] 
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866] 
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp_hqyeqx5.ptx -o /tmp/tmp_hqyeqx5.ptx.o
(EngineCore_DP0 pid=466696) ERROR 01-25 21:17:59 [core.py:866] 

STDERR:
[2026-01-25 21:17:11] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:17:11] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:17:11] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:17:11] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:17:11] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:17:11] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:17:11] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:17:11] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:17:11] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:17:11] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:17:11] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:17:11] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:17:11] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:17:11] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:17:14] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:17:14] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:17:14] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:17:14] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:17:14] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:17:14] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:17:14] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:17:14] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:17:14] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:17:14] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:17:14] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:17:14] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:17:14] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:17:14] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=466696) [2026-01-25 21:17:15] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=466696) [2026-01-25 21:17:15] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=466696) [2026-01-25 21:17:15] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=466696) [2026-01-25 21:17:15] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=466696) [2026-01-25 21:17:15] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=466696) [2026-01-25 21:17:15] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=466696) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=466696) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:20<00:20, 20.74s/it]
(EngineCore_DP0 pid=466696) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:41<00:00, 21.03s/it]
(EngineCore_DP0 pid=466696) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:41<00:00, 20.98s/it]
(EngineCore_DP0 pid=466696) 
(EngineCore_DP0 pid=466696) [2026-01-25 21:17:58] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=466696) [2026-01-25 21:17:58] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10321920 bytes
(EngineCore_DP0 pid=466696) [2026-01-25 21:17:58] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=466696) [2026-01-25 21:17:58] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8028160 bytes
(EngineCore_DP0 pid=466696) [2026-01-25 21:17:58] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=466696) [2026-01-25 21:17:58] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 84869120 bytes
(EngineCore_DP0 pid=466696) [2026-01-25 21:17:58] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=466696) [2026-01-25 21:17:58] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 42434560 bytes
(EngineCore_DP0 pid=466696) Process EngineCore_DP0:
(EngineCore_DP0 pid=466696) Traceback (most recent call last):
(EngineCore_DP0 pid=466696)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=466696)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=466696)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=466696)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=466696) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp_hqyeqx5.ptx', '-o', '/tmp/tmp_hqyeqx5.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=466696) 
(EngineCore_DP0 pid=466696) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=466696) 
(EngineCore_DP0 pid=466696) Traceback (most recent call last):
(EngineCore_DP0 pid=466696)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=466696)     self.run()
(EngineCore_DP0 pid=466696)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=466696)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=466696)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=466696)     raise e
(EngineCore_DP0 pid=466696)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=466696)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=466696)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=466696)     super().__init__(
(EngineCore_DP0 pid=466696)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=466696)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=466696)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=466696)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=466696)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=466696)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=466696)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=466696)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=466696)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=466696)     return func(*args, **kwargs)
(EngineCore_DP0 pid=466696)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=466696)     return func(*args, **kwargs)
(EngineCore_DP0 pid=466696)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=466696)     self.model_runner.profile_run()
(EngineCore_DP0 pid=466696)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=466696)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=466696)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=466696)     return func(*args, **kwargs)
(EngineCore_DP0 pid=466696)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=466696)     outputs = self.model(
(EngineCore_DP0 pid=466696)               ^^^^^^^^^^^
(EngineCore_DP0 pid=466696)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=466696)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=466696)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=466696)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=466696)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=466696)     hidden_states = self.model(
(EngineCore_DP0 pid=466696)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=466696)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=466696)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=466696)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=466696)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=466696)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=466696)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=466696)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=466696)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=466696)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=466696)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=466696)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=466696)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=466696)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=466696)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=466696)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=466696)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=466696)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=466696)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=466696)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=466696)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=466696)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=466696)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=466696)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=466696)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=466696)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=466696)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=466696)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=466696)     return self._linear_fn(
(EngineCore_DP0 pid=466696)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=466696)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=466696)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=466696)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=466696)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=466696)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=466696)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=466696)     return fn(input, L)
(EngineCore_DP0 pid=466696)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=466696)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=466696)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=466696)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=466696)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=466696)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=466696)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=466696)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=466696)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=466696)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=466696)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=466696)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=466696)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=466696)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=466696)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=466696)     raise PTXASError(error)
(EngineCore_DP0 pid=466696) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=466696) `ptxas` stderr:
(EngineCore_DP0 pid=466696) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=466696) 
(EngineCore_DP0 pid=466696) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp_hqyeqx5.ptx -o /tmp/tmp_hqyeqx5.ptx.o
(EngineCore_DP0 pid=466696) 
[rank0]:[W125 21:17:59.115965581 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=512

========== M=1024 ==========
Time: 2026-01-25 21:18:01
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Qwen2.5-7B-FP8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:18:05 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 21:18:05 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=467623) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=467623) 
(EngineCore_DP0 pid=467623) 
(EngineCore_DP0 pid=467623) ================================================================
(EngineCore_DP0 pid=467623) Internal Triton PTX codegen error
(EngineCore_DP0 pid=467623) `ptxas` stderr:
(EngineCore_DP0 pid=467623) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=467623) 
(EngineCore_DP0 pid=467623) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp9d0gonod.ptx -o /tmp/tmp9d0gonod.ptx.o
(EngineCore_DP0 pid=467623) 
(EngineCore_DP0 pid=467623) 
(EngineCore_DP0 pid=467623) //
(EngineCore_DP0 pid=467623) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=467623) //
(EngineCore_DP0 pid=467623) 
(EngineCore_DP0 pid=467623) .version 8.7
(EngineCore_DP0 pid=467623) .target sm_121a
(EngineCore_DP0 pid=467623) .address_size 64
(EngineCore_DP0 pid=467623) 
(EngineCore_DP0 pid=467623) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=467623) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=467623)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=467623) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=467623) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=467623) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=467623) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=467623) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=467623) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=467623) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=467623) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=467623) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=467623) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=467623) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=467623) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=467623) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=467623) )
(EngineCore_DP0 pid=467623) .reqntid 512
(EngineCore_DP0 pid=467623) {
(EngineCore_DP0 pid=467623) 	.reg .pred 	%p<28>;
(EngineCore_DP0 pid=467623) 	.reg .b16 	%rs<49>;
(EngineCore_DP0 pid=467623) 	.reg .b32 	%r<134>;
(EngineCore_DP0 pid=467623) 	.reg .b64 	%rd<17>;
(EngineCore_DP0 pid=467623) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=467623) $L__func_begin0:
(EngineCore_DP0 pid=467623) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=467623) 
(EngineCore_DP0 pid=467623) // %bb.0:
(EngineCore_DP0 pid=467623) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=467623) 	ld.param.b32 	%r22, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=467623) 	ld.param.b32 	%r21, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=467623) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=467623) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=467623) $L__tmp0:
(EngineCore_DP0 pid=467623) 	.loc	1 143 24                        // quant_slide_tuned_Qwen2.5-7B.py:143:24
(EngineCore_DP0 pid=467623) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=467623) 	ld.param.b32 	%r25, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=467623) 	.loc	1 148 26                        // quant_slide_tuned_Qwen2.5-7B.py:148:26
(EngineCore_DP0 pid=467623) 	mul.lo.s32 	%r26, %r25, %r1;
(EngineCore_DP0 pid=467623) 	.loc	1 148 20                        // quant_slide_tuned_Qwen2.5-7B.py:148:20
(EngineCore_DP0 pid=467623) 	mad.wide.s32 	%rd1, %r26, 2, %rd4;
(EngineCore_DP0 pid=467623) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=467623) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=467623) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=467623) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=467623) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=467623) 	setp.lt.s32 	%p1, %r22, 1;
(EngineCore_DP0 pid=467623) 	mov.b32 	%r131, 0f2B8CBCCC;
(EngineCore_DP0 pid=467623) 	setp.eq.b32 	%p27, %r2, 0;
(EngineCore_DP0 pid=467623) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=467623) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=467623) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=467623) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=467623) 	shr.u32 	%r35, %r2, 3;
(EngineCore_DP0 pid=467623) 	and.b32 	%r36, %r35, 60;
(EngineCore_DP0 pid=467623) 	mov.b32 	%r37, global_smem;
(EngineCore_DP0 pid=467623) 	add.s32 	%r47, %r37, %r36;
(EngineCore_DP0 pid=467623) 	shl.b32 	%r38, %r2, 2;
(EngineCore_DP0 pid=467623) 	add.s32 	%r50, %r37, %r38;
(EngineCore_DP0 pid=467623) 	mov.b32 	%r43, 0;
(EngineCore_DP0 pid=467623) 	mov.b32 	%r129, 0f00000000;
(EngineCore_DP0 pid=467623) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=467623) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=467623) 	mov.b32 	%r130, %r43;
(EngineCore_DP0 pid=467623) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=467623) 	.loc	1 155 22                        // quant_slide_tuned_Qwen2.5-7B.py:155:22
(EngineCore_DP0 pid=467623) 	add.s32 	%r53, %r4, %r130;
(EngineCore_DP0 pid=467623) 	setp.lt.s32 	%p2, %r53, %r21;
(EngineCore_DP0 pid=467623) 	.loc	1 156 29                        // quant_slide_tuned_Qwen2.5-7B.py:156:29
(EngineCore_DP0 pid=467623) 	mad.wide.s32 	%rd6, %r53, 2, %rd1;
(EngineCore_DP0 pid=467623) 	.loc	1 156 21                        // quant_slide_tuned_Qwen2.5-7B.py:156:21
(EngineCore_DP0 pid=467623) 	// begin inline asm
(EngineCore_DP0 pid=467623) 	mov.u32 %r39, %r43;
(EngineCore_DP0 pid=467623) 	mov.u32 %r40, %r43;
(EngineCore_DP0 pid=467623) 	mov.u32 %r41, %r43;
(EngineCore_DP0 pid=467623) 	mov.u32 %r42, %r43;
(EngineCore_DP0 pid=467623) 	@%p2 ld.global.v4.b32 { %r39, %r40, %r41, %r42 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=467623) 	// end inline asm
(EngineCore_DP0 pid=467623) 	mov.b32 	{%rs1, %rs2}, %r39;
(EngineCore_DP0 pid=467623) 	mov.b32 	{%rs3, %rs4}, %r40;
(EngineCore_DP0 pid=467623) 	mov.b32 	{%rs5, %rs6}, %r41;
(EngineCore_DP0 pid=467623) 	mov.b32 	{%rs7, %rs8}, %r42;
(EngineCore_DP0 pid=467623) 	.loc	1 157 50                        // quant_slide_tuned_Qwen2.5-7B.py:157:50
(EngineCore_DP0 pid=467623) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=467623) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=467623) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=467623) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=467623) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=467623) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=467623) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=467623) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=467623) $L__tmp1:
(EngineCore_DP0 pid=467623) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=467623) 	bar.sync 	0;
(EngineCore_DP0 pid=467623) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=467623) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=467623) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=467623) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=467623) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=467623) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=467623) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=467623) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=467623) 	cvt.f32.bf16 	%r54, %rs23;
(EngineCore_DP0 pid=467623) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=467623) 	shfl.sync.bfly.b32 	%r55, %r54, 16, 31, -1;
(EngineCore_DP0 pid=467623) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=467623) 	max.f32 	%r56, %r54, %r55;
(EngineCore_DP0 pid=467623) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=467623) 	shfl.sync.bfly.b32 	%r57, %r56, 8, 31, -1;
(EngineCore_DP0 pid=467623) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=467623) 	max.f32 	%r58, %r56, %r57;
(EngineCore_DP0 pid=467623) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=467623) 	shfl.sync.bfly.b32 	%r59, %r58, 4, 31, -1;
(EngineCore_DP0 pid=467623) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=467623) 	max.f32 	%r60, %r58, %r59;
(EngineCore_DP0 pid=467623) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=467623) 	shfl.sync.bfly.b32 	%r61, %r60, 2, 31, -1;
(EngineCore_DP0 pid=467623) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=467623) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=467623) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=467623) 	shfl.sync.bfly.b32 	%r63, %r62, 1, 31, -1;
(EngineCore_DP0 pid=467623) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=467623) 	max.f32 	%r48, %r62, %r63;
(EngineCore_DP0 pid=467623) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=467623) 	// begin inline asm
(EngineCore_DP0 pid=467623) 	@%p3 st.shared.b32 [ %r47 + 0 ], %r48;
(EngineCore_DP0 pid=467623) 	// end inline asm
(EngineCore_DP0 pid=467623) 	bar.sync 	0;
(EngineCore_DP0 pid=467623) 	// begin inline asm
(EngineCore_DP0 pid=467623) 	@%p4 ld.shared.b32 %r49, [ %r50 + 0 ];
(EngineCore_DP0 pid=467623) 	// end inline asm
(EngineCore_DP0 pid=467623) 	shfl.sync.bfly.b32 	%r64, %r49, 8, 31, -1;
(EngineCore_DP0 pid=467623) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=467623) 	max.f32 	%r65, %r49, %r64;
(EngineCore_DP0 pid=467623) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=467623) 	shfl.sync.bfly.b32 	%r66, %r65, 4, 31, -1;
(EngineCore_DP0 pid=467623) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=467623) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=467623) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=467623) 	shfl.sync.bfly.b32 	%r68, %r67, 2, 31, -1;
(EngineCore_DP0 pid=467623) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=467623) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=467623) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=467623) 	shfl.sync.bfly.b32 	%r70, %r69, 1, 31, -1;
(EngineCore_DP0 pid=467623) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=467623) 	max.f32 	%r52, %r69, %r70;
(EngineCore_DP0 pid=467623) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=467623) 	// begin inline asm
(EngineCore_DP0 pid=467623) 	@%p27 st.shared.b32 [ %r50 + 0 ], %r52;
(EngineCore_DP0 pid=467623) 	// end inline asm
(EngineCore_DP0 pid=467623) 	bar.sync 	0;
(EngineCore_DP0 pid=467623) 	ld.shared.b32 	%r71, [global_smem];
(EngineCore_DP0 pid=467623) $L__tmp2:
(EngineCore_DP0 pid=467623) 	.loc	1 157 36                        // quant_slide_tuned_Qwen2.5-7B.py:157:36
(EngineCore_DP0 pid=467623) 	max.f32 	%r129, %r129, %r71;
(EngineCore_DP0 pid=467623) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=467623) 	add.s32 	%r130, %r130, 4096;
(EngineCore_DP0 pid=467623) 	setp.lt.s32 	%p6, %r130, %r22;
(EngineCore_DP0 pid=467623) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=467623) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=467623) 	.loc	1 159 32                        // quant_slide_tuned_Qwen2.5-7B.py:159:32
(EngineCore_DP0 pid=467623) 	max.f32 	%r131, %r129, 0f2B8CBCCC;
(EngineCore_DP0 pid=467623) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=467623) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-7B.py:0:32
(EngineCore_DP0 pid=467623) 	mov.b32 	%r73, 0f43E00000;
(EngineCore_DP0 pid=467623) 	.loc	1 160 32                        // quant_slide_tuned_Qwen2.5-7B.py:160:32
(EngineCore_DP0 pid=467623) 	div.full.f32 	%r74, %r131, %r73;
(EngineCore_DP0 pid=467623) 	.loc	1 160 41                        // quant_slide_tuned_Qwen2.5-7B.py:160:41
(EngineCore_DP0 pid=467623) 	max.f32 	%r72, %r74, 0f36924925;
(EngineCore_DP0 pid=467623) 	.loc	1 162 25                        // quant_slide_tuned_Qwen2.5-7B.py:162:25
(EngineCore_DP0 pid=467623) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=467623) 	.loc	1 162 30                        // quant_slide_tuned_Qwen2.5-7B.py:162:30
(EngineCore_DP0 pid=467623) 	// begin inline asm
(EngineCore_DP0 pid=467623) 	@%p27 st.global.b32 [ %rd7 + 0 ], { %r72 };
(EngineCore_DP0 pid=467623) 	// end inline asm
(EngineCore_DP0 pid=467623) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=467623) 	setp.lt.s32 	%p8, %r23, 1;
(EngineCore_DP0 pid=467623) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=467623) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=467623) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-7B.py:0:41
(EngineCore_DP0 pid=467623) 	ld.param.b32 	%r27, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=467623) 	shr.s32 	%r28, %r27, 31;
(EngineCore_DP0 pid=467623) 	shr.u32 	%r29, %r28, 30;
(EngineCore_DP0 pid=467623) 	add.s32 	%r30, %r27, %r29;
(EngineCore_DP0 pid=467623) 	shr.s32 	%r31, %r30, 2;
(EngineCore_DP0 pid=467623) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=467623) 	mul.lo.s32 	%r32, %r31, %r1;
(EngineCore_DP0 pid=467623) 	mad.wide.s32 	%rd2, %r32, 4, %rd5;
(EngineCore_DP0 pid=467623) 	div.full.f32 	%r14, %r73, %r131;
(EngineCore_DP0 pid=467623) 	shl.b32 	%r15, %r3, 1;
(EngineCore_DP0 pid=467623) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=467623) 	add.s32 	%r132, %r4, 7;
(EngineCore_DP0 pid=467623) 	mov.b32 	%r133, 0;
(EngineCore_DP0 pid=467623) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=467623)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=467623) 	.loc	1 169 30                        // quant_slide_tuned_Qwen2.5-7B.py:169:30
(EngineCore_DP0 pid=467623) 	add.s32 	%r86, %r15, %r133;
(EngineCore_DP0 pid=467623) 	setp.lt.s32 	%p17, %r86, %r23;
(EngineCore_DP0 pid=467623) 	.loc	1 174 22                        // quant_slide_tuned_Qwen2.5-7B.py:174:22
(EngineCore_DP0 pid=467623) 	add.s32 	%r87, %r132, -7;
(EngineCore_DP0 pid=467623) 	.loc	1 177 53                        // quant_slide_tuned_Qwen2.5-7B.py:177:53
(EngineCore_DP0 pid=467623) 	add.s32 	%r88, %r132, -3;
(EngineCore_DP0 pid=467623) 	setp.lt.s32 	%p18, %r87, %r21;
(EngineCore_DP0 pid=467623) 	setp.lt.s32 	%p19, %r88, %r21;
(EngineCore_DP0 pid=467623) 	.loc	1 177 37                        // quant_slide_tuned_Qwen2.5-7B.py:177:37
(EngineCore_DP0 pid=467623) 	and.pred 	%p9, %p17, %p18;
(EngineCore_DP0 pid=467623) 	and.pred 	%p10, %p17, %p19;
(EngineCore_DP0 pid=467623) 	.loc	1 176 29                        // quant_slide_tuned_Qwen2.5-7B.py:176:29
(EngineCore_DP0 pid=467623) 	mad.wide.s32 	%rd8, %r87, 2, %rd1;
(EngineCore_DP0 pid=467623) 	add.s64 	%rd9, %rd8, 8;
(EngineCore_DP0 pid=467623) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=467623) 	.loc	1 176 21                        // quant_slide_tuned_Qwen2.5-7B.py:176:21
(EngineCore_DP0 pid=467623) 	// begin inline asm
(EngineCore_DP0 pid=467623) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=467623) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=467623) 	// end inline asm
(EngineCore_DP0 pid=467623) 	// begin inline asm
(EngineCore_DP0 pid=467623) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=467623) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=467623) 	// end inline asm
(EngineCore_DP0 pid=467623) 	.loc	1 177 79                        // quant_slide_tuned_Qwen2.5-7B.py:177:79
(EngineCore_DP0 pid=467623) 	cvt.f32.bf16 	%r89, %rs24;
(EngineCore_DP0 pid=467623) 	cvt.f32.bf16 	%r90, %rs26;
(EngineCore_DP0 pid=467623) 	.loc	1 179 48                        // quant_slide_tuned_Qwen2.5-7B.py:179:48
(EngineCore_DP0 pid=467623) 	add.s32 	%r91, %r132, -6;
(EngineCore_DP0 pid=467623) 	.loc	1 179 53                        // quant_slide_tuned_Qwen2.5-7B.py:179:53
(EngineCore_DP0 pid=467623) 	add.s32 	%r92, %r132, -2;
(EngineCore_DP0 pid=467623) 	setp.lt.s32 	%p20, %r91, %r21;
(EngineCore_DP0 pid=467623) 	setp.lt.s32 	%p21, %r92, %r21;
(EngineCore_DP0 pid=467623) 	.loc	1 179 37                        // quant_slide_tuned_Qwen2.5-7B.py:179:37
(EngineCore_DP0 pid=467623) 	and.pred 	%p11, %p17, %p20;
(EngineCore_DP0 pid=467623) 	and.pred 	%p12, %p17, %p21;
(EngineCore_DP0 pid=467623) 	.loc	1 178 39                        // quant_slide_tuned_Qwen2.5-7B.py:178:39
(EngineCore_DP0 pid=467623) 	add.s64 	%rd10, %rd8, 2;
(EngineCore_DP0 pid=467623) 	add.s64 	%rd11, %rd8, 10;
(EngineCore_DP0 pid=467623) 	.loc	1 178 21                        // quant_slide_tuned_Qwen2.5-7B.py:178:21
(EngineCore_DP0 pid=467623) 	// begin inline asm
(EngineCore_DP0 pid=467623) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=467623) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=467623) 	// end inline asm
(EngineCore_DP0 pid=467623) 	// begin inline asm
(EngineCore_DP0 pid=467623) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=467623) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=467623) 	// end inline asm
(EngineCore_DP0 pid=467623) 	.loc	1 179 79                        // quant_slide_tuned_Qwen2.5-7B.py:179:79
(EngineCore_DP0 pid=467623) 	cvt.f32.bf16 	%r93, %rs28;
(EngineCore_DP0 pid=467623) 	cvt.f32.bf16 	%r94, %rs30;
(EngineCore_DP0 pid=467623) 	.loc	1 181 48                        // quant_slide_tuned_Qwen2.5-7B.py:181:48
(EngineCore_DP0 pid=467623) 	add.s32 	%r95, %r132, -5;
(EngineCore_DP0 pid=467623) 	.loc	1 181 53                        // quant_slide_tuned_Qwen2.5-7B.py:181:53
(EngineCore_DP0 pid=467623) 	add.s32 	%r96, %r132, -1;
(EngineCore_DP0 pid=467623) 	setp.lt.s32 	%p22, %r95, %r21;
(EngineCore_DP0 pid=467623) 	setp.lt.s32 	%p23, %r96, %r21;
(EngineCore_DP0 pid=467623) 	.loc	1 181 37                        // quant_slide_tuned_Qwen2.5-7B.py:181:37
(EngineCore_DP0 pid=467623) 	and.pred 	%p13, %p17, %p22;
(EngineCore_DP0 pid=467623) 	and.pred 	%p14, %p17, %p23;
(EngineCore_DP0 pid=467623) 	.loc	1 180 39                        // quant_slide_tuned_Qwen2.5-7B.py:180:39
(EngineCore_DP0 pid=467623) 	add.s64 	%rd12, %rd8, 4;
(EngineCore_DP0 pid=467623) 	add.s64 	%rd13, %rd8, 12;
(EngineCore_DP0 pid=467623) 	.loc	1 180 21                        // quant_slide_tuned_Qwen2.5-7B.py:180:21
(EngineCore_DP0 pid=467623) 	// begin inline asm
(EngineCore_DP0 pid=467623) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=467623) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=467623) 	// end inline asm
(EngineCore_DP0 pid=467623) 	// begin inline asm
(EngineCore_DP0 pid=467623) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=467623) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=467623) 	// end inline asm
(EngineCore_DP0 pid=467623) 	.loc	1 181 79                        // quant_slide_tuned_Qwen2.5-7B.py:181:79
(EngineCore_DP0 pid=467623) 	cvt.f32.bf16 	%r97, %rs32;
(EngineCore_DP0 pid=467623) 	cvt.f32.bf16 	%r98, %rs34;
(EngineCore_DP0 pid=467623) 	.loc	1 183 48                        // quant_slide_tuned_Qwen2.5-7B.py:183:48
(EngineCore_DP0 pid=467623) 	add.s32 	%r99, %r132, -4;
(EngineCore_DP0 pid=467623) 	.loc	1 183 53                        // quant_slide_tuned_Qwen2.5-7B.py:183:53
(EngineCore_DP0 pid=467623) 	setp.lt.s32 	%p24, %r99, %r21;
(EngineCore_DP0 pid=467623) 	setp.lt.s32 	%p25, %r132, %r21;
(EngineCore_DP0 pid=467623) 	.loc	1 183 37                        // quant_slide_tuned_Qwen2.5-7B.py:183:37
(EngineCore_DP0 pid=467623) 	and.pred 	%p15, %p17, %p24;
(EngineCore_DP0 pid=467623) 	and.pred 	%p16, %p17, %p25;
(EngineCore_DP0 pid=467623) 	.loc	1 182 39                        // quant_slide_tuned_Qwen2.5-7B.py:182:39
(EngineCore_DP0 pid=467623) 	add.s64 	%rd14, %rd8, 6;
(EngineCore_DP0 pid=467623) 	add.s64 	%rd15, %rd8, 14;
(EngineCore_DP0 pid=467623) 	.loc	1 182 21                        // quant_slide_tuned_Qwen2.5-7B.py:182:21
(EngineCore_DP0 pid=467623) 	// begin inline asm
(EngineCore_DP0 pid=467623) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=467623) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=467623) 	// end inline asm
(EngineCore_DP0 pid=467623) 	// begin inline asm
(EngineCore_DP0 pid=467623) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=467623) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=467623) 	// end inline asm
(EngineCore_DP0 pid=467623) 	.loc	1 183 79                        // quant_slide_tuned_Qwen2.5-7B.py:183:79
(EngineCore_DP0 pid=467623) 	cvt.f32.bf16 	%r100, %rs36;
(EngineCore_DP0 pid=467623) 	cvt.f32.bf16 	%r101, %rs38;
(EngineCore_DP0 pid=467623) 	.loc	1 185 27                        // quant_slide_tuned_Qwen2.5-7B.py:185:27
(EngineCore_DP0 pid=467623) 	mul.f32 	%r102, %r14, %r89;
(EngineCore_DP0 pid=467623) 	mul.f32 	%r103, %r14, %r90;
(EngineCore_DP0 pid=467623) 	mov.b32 	%r104, 0f43E00000;
(EngineCore_DP0 pid=467623) 	.loc	1 185 48                        // quant_slide_tuned_Qwen2.5-7B.py:185:48
(EngineCore_DP0 pid=467623) 	min.xorsign.abs.f32 	%r76, %r102, %r104;
(EngineCore_DP0 pid=467623) 	min.xorsign.abs.f32 	%r77, %r103, %r104;
(EngineCore_DP0 pid=467623) 	.loc	1 185 60                        // quant_slide_tuned_Qwen2.5-7B.py:185:60
(EngineCore_DP0 pid=467623) 	// begin inline asm
(EngineCore_DP0 pid=467623) 	cvt.rn.satfinite.e4m3x2.f32  %rs40, %r77, %r76; 
(EngineCore_DP0 pid=467623) 
(EngineCore_DP0 pid=467623) 	// end inline asm
(EngineCore_DP0 pid=467623) 	shr.u16 	%rs44, %rs40, 8;
(EngineCore_DP0 pid=467623) 	.loc	1 186 27                        // quant_slide_tuned_Qwen2.5-7B.py:186:27
(EngineCore_DP0 pid=467623) 	mul.f32 	%r105, %r14, %r93;
(EngineCore_DP0 pid=467623) 	mul.f32 	%r106, %r14, %r94;
(EngineCore_DP0 pid=467623) 	.loc	1 186 48                        // quant_slide_tuned_Qwen2.5-7B.py:186:48
(EngineCore_DP0 pid=467623) 	min.xorsign.abs.f32 	%r78, %r105, %r104;
(EngineCore_DP0 pid=467623) 	min.xorsign.abs.f32 	%r79, %r106, %r104;
(EngineCore_DP0 pid=467623) 	.loc	1 186 60                        // quant_slide_tuned_Qwen2.5-7B.py:186:60
(EngineCore_DP0 pid=467623) 	// begin inline asm
(EngineCore_DP0 pid=467623) 	cvt.rn.satfinite.e4m3x2.f32  %rs41, %r79, %r78; 
(EngineCore_DP0 pid=467623) 
(EngineCore_DP0 pid=467623) 	// end inline asm
(EngineCore_DP0 pid=467623) 	shr.u16 	%rs45, %rs41, 8;
(EngineCore_DP0 pid=467623) 	.loc	1 187 27                        // quant_slide_tuned_Qwen2.5-7B.py:187:27
(EngineCore_DP0 pid=467623) 	mul.f32 	%r107, %r14, %r97;
(EngineCore_DP0 pid=467623) 	mul.f32 	%r108, %r14, %r98;
(EngineCore_DP0 pid=467623) 	.loc	1 187 48                        // quant_slide_tuned_Qwen2.5-7B.py:187:48
(EngineCore_DP0 pid=467623) 	min.xorsign.abs.f32 	%r80, %r107, %r104;
(EngineCore_DP0 pid=467623) 	min.xorsign.abs.f32 	%r81, %r108, %r104;
(EngineCore_DP0 pid=467623) 	.loc	1 187 60                        // quant_slide_tuned_Qwen2.5-7B.py:187:60
(EngineCore_DP0 pid=467623) 	// begin inline asm
(EngineCore_DP0 pid=467623) 	cvt.rn.satfinite.e4m3x2.f32  %rs42, %r81, %r80; 
(EngineCore_DP0 pid=467623) 
(EngineCore_DP0 pid=467623) 	// end inline asm
(EngineCore_DP0 pid=467623) 	shr.u16 	%rs46, %rs42, 8;
(EngineCore_DP0 pid=467623) 	.loc	1 188 27                        // quant_slide_tuned_Qwen2.5-7B.py:188:27
(EngineCore_DP0 pid=467623) 	mul.f32 	%r109, %r14, %r100;
(EngineCore_DP0 pid=467623) 	mul.f32 	%r110, %r14, %r101;
(EngineCore_DP0 pid=467623) 	.loc	1 188 48                        // quant_slide_tuned_Qwen2.5-7B.py:188:48
(EngineCore_DP0 pid=467623) 	min.xorsign.abs.f32 	%r82, %r109, %r104;
(EngineCore_DP0 pid=467623) 	min.xorsign.abs.f32 	%r83, %r110, %r104;
(EngineCore_DP0 pid=467623) 	.loc	1 188 60                        // quant_slide_tuned_Qwen2.5-7B.py:188:60
(EngineCore_DP0 pid=467623) 	// begin inline asm
(EngineCore_DP0 pid=467623) 	cvt.rn.satfinite.e4m3x2.f32  %rs43, %r83, %r82; 
(EngineCore_DP0 pid=467623) 
(EngineCore_DP0 pid=467623) 	// end inline asm
(EngineCore_DP0 pid=467623) 	shr.u16 	%rs47, %rs43, 8;
(EngineCore_DP0 pid=467623) 	.loc	1 190 45                        // quant_slide_tuned_Qwen2.5-7B.py:190:45
(EngineCore_DP0 pid=467623) 	cvt.u32.u16 	%r111, %rs40;
(EngineCore_DP0 pid=467623) 	and.b32 	%r112, %r111, 255;
(EngineCore_DP0 pid=467623) 	cvt.u32.u16 	%r113, %rs44;
(EngineCore_DP0 pid=467623) 	.loc	1 192 45                        // quant_slide_tuned_Qwen2.5-7B.py:192:45
(EngineCore_DP0 pid=467623) 	cvt.u32.u16 	%r114, %rs42;
(EngineCore_DP0 pid=467623) 	and.b32 	%r115, %r114, 255;
(EngineCore_DP0 pid=467623) 	cvt.u32.u16 	%r116, %rs46;
(EngineCore_DP0 pid=467623) 	.loc	1 193 45                        // quant_slide_tuned_Qwen2.5-7B.py:193:45
(EngineCore_DP0 pid=467623) 	cvt.u32.u16 	%r117, %rs43;
(EngineCore_DP0 pid=467623) 	cvt.u32.u16 	%r118, %rs47;
(EngineCore_DP0 pid=467623) 	.loc	1 195 30                        // quant_slide_tuned_Qwen2.5-7B.py:195:30
(EngineCore_DP0 pid=467623) 	and.b16 	%rs48, %rs41, 255;
(EngineCore_DP0 pid=467623) 	mul.wide.u16 	%r119, %rs48, 256;
(EngineCore_DP0 pid=467623) 	mul.wide.u16 	%r120, %rs45, 256;
(EngineCore_DP0 pid=467623) 	.loc	1 195 24                        // quant_slide_tuned_Qwen2.5-7B.py:195:24
(EngineCore_DP0 pid=467623) 	or.b32 	%r121, %r119, %r112;
(EngineCore_DP0 pid=467623) 	or.b32 	%r122, %r120, %r113;
(EngineCore_DP0 pid=467623) 	.loc	1 195 42                        // quant_slide_tuned_Qwen2.5-7B.py:195:42
(EngineCore_DP0 pid=467623) 	shl.b32 	%r123, %r115, 16;
(EngineCore_DP0 pid=467623) 	shl.b32 	%r124, %r116, 16;
(EngineCore_DP0 pid=467623) 	.loc	1 195 36                        // quant_slide_tuned_Qwen2.5-7B.py:195:36
(EngineCore_DP0 pid=467623) 	or.b32 	%r125, %r121, %r123;
(EngineCore_DP0 pid=467623) 	or.b32 	%r126, %r122, %r124;
(EngineCore_DP0 pid=467623) 	.loc	1 195 55                        // quant_slide_tuned_Qwen2.5-7B.py:195:55
(EngineCore_DP0 pid=467623) 	shl.b32 	%r127, %r117, 24;
(EngineCore_DP0 pid=467623) 	shl.b32 	%r128, %r118, 24;
(EngineCore_DP0 pid=467623) 	.loc	1 195 49                        // quant_slide_tuned_Qwen2.5-7B.py:195:49
(EngineCore_DP0 pid=467623) 	or.b32 	%r84, %r125, %r127;
(EngineCore_DP0 pid=467623) 	or.b32 	%r85, %r126, %r128;
(EngineCore_DP0 pid=467623) 	.loc	1 196 29                        // quant_slide_tuned_Qwen2.5-7B.py:196:29
(EngineCore_DP0 pid=467623) 	mad.wide.s32 	%rd16, %r86, 4, %rd2;
(EngineCore_DP0 pid=467623) 	.loc	1 196 39                        // quant_slide_tuned_Qwen2.5-7B.py:196:39
(EngineCore_DP0 pid=467623) 	// begin inline asm
(EngineCore_DP0 pid=467623) 	@%p17 st.global.v2.b32 [ %rd16 + 0 ], { %r84, %r85 };
(EngineCore_DP0 pid=467623) 	// end inline asm
(EngineCore_DP0 pid=467623) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=467623) 	add.s32 	%r133, %r133, 1024;
(EngineCore_DP0 pid=467623) 	add.s32 	%r132, %r132, 4096;
(EngineCore_DP0 pid=467623) 	setp.lt.s32 	%p26, %r133, %r23;
(EngineCore_DP0 pid=467623) 	@%p26 bra 	$L__BB0_6;
(EngineCore_DP0 pid=467623) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=467623) 	.loc	1 167 4                         // quant_slide_tuned_Qwen2.5-7B.py:167:4
(EngineCore_DP0 pid=467623) 	ret;
(EngineCore_DP0 pid=467623) $L__tmp3:
(EngineCore_DP0 pid=467623) $L__func_end0:
(EngineCore_DP0 pid=467623)                                         // -- End function
(EngineCore_DP0 pid=467623) }
(EngineCore_DP0 pid=467623) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py"
(EngineCore_DP0 pid=467623) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=467623) 	.section	.debug_abbrev
(EngineCore_DP0 pid=467623) 	{
(EngineCore_DP0 pid=467623) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=467623) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=467623) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=467623) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=467623) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=467623) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=467623) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=467623) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=467623) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=467623) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=467623) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=467623) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=467623) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=467623) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=467623) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=467623) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=467623) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=467623) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=467623) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=467623) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=467623) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=467623) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=467623) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=467623) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=467623) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=467623) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=467623) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=467623) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=467623) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=467623) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=467623) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=467623) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=467623) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=467623) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=467623) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=467623) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=467623) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=467623) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=467623) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=467623) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=467623) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=467623) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=467623) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=467623) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=467623) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=467623) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=467623) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=467623) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=467623) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=467623) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=467623) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=467623) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=467623) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=467623) 	}
(EngineCore_DP0 pid=467623) 	.section	.debug_info
(EngineCore_DP0 pid=467623) 	{
(EngineCore_DP0 pid=467623) .b32 221                                // Length of Unit
(EngineCore_DP0 pid=467623) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=467623) .b8 0
(EngineCore_DP0 pid=467623) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=467623) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=467623) .b8 1                                   // Abbrev [1] 0xb:0xd6 DW_TAG_compile_unit
(EngineCore_DP0 pid=467623) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=467623) .b8 114
(EngineCore_DP0 pid=467623) .b8 105
(EngineCore_DP0 pid=467623) .b8 116
(EngineCore_DP0 pid=467623) .b8 111
(EngineCore_DP0 pid=467623) .b8 110
(EngineCore_DP0 pid=467623) .b8 0
(EngineCore_DP0 pid=467623) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=467623) .b8 0
(EngineCore_DP0 pid=467623) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=467623) .b8 117
(EngineCore_DP0 pid=467623) .b8 97
(EngineCore_DP0 pid=467623) .b8 110
(EngineCore_DP0 pid=467623) .b8 116
(EngineCore_DP0 pid=467623) .b8 95
(EngineCore_DP0 pid=467623) .b8 115
(EngineCore_DP0 pid=467623) .b8 108
(EngineCore_DP0 pid=467623) .b8 105
(EngineCore_DP0 pid=467623) .b8 100
(EngineCore_DP0 pid=467623) .b8 101
(EngineCore_DP0 pid=467623) .b8 95
(EngineCore_DP0 pid=467623) .b8 116
(EngineCore_DP0 pid=467623) .b8 117
(EngineCore_DP0 pid=467623) .b8 110
(EngineCore_DP0 pid=467623) .b8 101
(EngineCore_DP0 pid=467623) .b8 100
(EngineCore_DP0 pid=467623) .b8 95
(EngineCore_DP0 pid=467623) .b8 81
(EngineCore_DP0 pid=467623) .b8 119
(EngineCore_DP0 pid=467623) .b8 101
(EngineCore_DP0 pid=467623) .b8 110
(EngineCore_DP0 pid=467623) .b8 50
(EngineCore_DP0 pid=467623) .b8 46
(EngineCore_DP0 pid=467623) .b8 53
(EngineCore_DP0 pid=467623) .b8 45
(EngineCore_DP0 pid=467623) .b8 55
(EngineCore_DP0 pid=467623) .b8 66
(EngineCore_DP0 pid=467623) .b8 46
(EngineCore_DP0 pid=467623) .b8 112
(EngineCore_DP0 pid=467623) .b8 121
(EngineCore_DP0 pid=467623) .b8 0
(EngineCore_DP0 pid=467623) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=467623) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=467623) .b8 114
(EngineCore_DP0 pid=467623) .b8 111
(EngineCore_DP0 pid=467623) .b8 111
(EngineCore_DP0 pid=467623) .b8 116
(EngineCore_DP0 pid=467623) .b8 47
(EngineCore_DP0 pid=467623) .b8 118
(EngineCore_DP0 pid=467623) .b8 108
(EngineCore_DP0 pid=467623) .b8 108
(EngineCore_DP0 pid=467623) .b8 109
(EngineCore_DP0 pid=467623) .b8 98
(EngineCore_DP0 pid=467623) .b8 101
(EngineCore_DP0 pid=467623) .b8 110
(EngineCore_DP0 pid=467623) .b8 99
(EngineCore_DP0 pid=467623) .b8 104
(EngineCore_DP0 pid=467623) .b8 47
(EngineCore_DP0 pid=467623) .b8 115
(EngineCore_DP0 pid=467623) .b8 108
(EngineCore_DP0 pid=467623) .b8 105
(EngineCore_DP0 pid=467623) .b8 100
(EngineCore_DP0 pid=467623) .b8 101
(EngineCore_DP0 pid=467623) .b8 115
(EngineCore_DP0 pid=467623) .b8 112
(EngineCore_DP0 pid=467623) .b8 97
(EngineCore_DP0 pid=467623) .b8 114
(EngineCore_DP0 pid=467623) .b8 115
(EngineCore_DP0 pid=467623) .b8 101
(EngineCore_DP0 pid=467623) .b8 47
(EngineCore_DP0 pid=467623) .b8 99
(EngineCore_DP0 pid=467623) .b8 115
(EngineCore_DP0 pid=467623) .b8 114
(EngineCore_DP0 pid=467623) .b8 99
(EngineCore_DP0 pid=467623) .b8 47
(EngineCore_DP0 pid=467623) .b8 102
(EngineCore_DP0 pid=467623) .b8 117
(EngineCore_DP0 pid=467623) .b8 115
(EngineCore_DP0 pid=467623) .b8 101
(EngineCore_DP0 pid=467623) .b8 100
(EngineCore_DP0 pid=467623) .b8 95
(EngineCore_DP0 pid=467623) .b8 113
(EngineCore_DP0 pid=467623) .b8 117
(EngineCore_DP0 pid=467623) .b8 97
(EngineCore_DP0 pid=467623) .b8 110
(EngineCore_DP0 pid=467623) .b8 116
(EngineCore_DP0 pid=467623) .b8 95
(EngineCore_DP0 pid=467623) .b8 115
(EngineCore_DP0 pid=467623) .b8 108
(EngineCore_DP0 pid=467623) .b8 105
(EngineCore_DP0 pid=467623) .b8 100
(EngineCore_DP0 pid=467623) .b8 101
(EngineCore_DP0 pid=467623) .b8 95
(EngineCore_DP0 pid=467623) .b8 116
(EngineCore_DP0 pid=467623) .b8 114
(EngineCore_DP0 pid=467623) .b8 105
(EngineCore_DP0 pid=467623) .b8 116
(EngineCore_DP0 pid=467623) .b8 111
(EngineCore_DP0 pid=467623) .b8 110
(EngineCore_DP0 pid=467623) .b8 47
(EngineCore_DP0 pid=467623) .b8 98
(EngineCore_DP0 pid=467623) .b8 117
(EngineCore_DP0 pid=467623) .b8 105
(EngineCore_DP0 pid=467623) .b8 108
(EngineCore_DP0 pid=467623) .b8 100
(EngineCore_DP0 pid=467623) .b8 47
(EngineCore_DP0 pid=467623) .b8 71
(EngineCore_DP0 pid=467623) .b8 66
(EngineCore_DP0 pid=467623) .b8 49
(EngineCore_DP0 pid=467623) .b8 48
(EngineCore_DP0 pid=467623) .b8 95
(EngineCore_DP0 pid=467623) .b8 99
(EngineCore_DP0 pid=467623) .b8 99
(EngineCore_DP0 pid=467623) .b8 49
(EngineCore_DP0 pid=467623) .b8 50
(EngineCore_DP0 pid=467623) .b8 49
(EngineCore_DP0 pid=467623) .b8 95
(EngineCore_DP0 pid=467623) .b8 112
(EngineCore_DP0 pid=467623) .b8 121
(EngineCore_DP0 pid=467623) .b8 51
(EngineCore_DP0 pid=467623) .b8 49
(EngineCore_DP0 pid=467623) .b8 50
(EngineCore_DP0 pid=467623) .b8 95
(EngineCore_DP0 pid=467623) .b8 99
(EngineCore_DP0 pid=467623) .b8 117
(EngineCore_DP0 pid=467623) .b8 49
(EngineCore_DP0 pid=467623) .b8 50
(EngineCore_DP0 pid=467623) .b8 57
(EngineCore_DP0 pid=467623) .b8 95
(EngineCore_DP0 pid=467623) .b8 97
(EngineCore_DP0 pid=467623) .b8 97
(EngineCore_DP0 pid=467623) .b8 114
(EngineCore_DP0 pid=467623) .b8 99
(EngineCore_DP0 pid=467623) .b8 104
(EngineCore_DP0 pid=467623) .b8 54
(EngineCore_DP0 pid=467623) .b8 52
(EngineCore_DP0 pid=467623) .b8 0
(EngineCore_DP0 pid=467623) .b8 2                                   // Abbrev [2] 0x98:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=467623) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=467623) .b8 113
(EngineCore_DP0 pid=467623) .b8 117
(EngineCore_DP0 pid=467623) .b8 97
(EngineCore_DP0 pid=467623) .b8 110
(EngineCore_DP0 pid=467623) .b8 116
(EngineCore_DP0 pid=467623) .b8 95
(EngineCore_DP0 pid=467623) .b8 115
(EngineCore_DP0 pid=467623) .b8 108
(EngineCore_DP0 pid=467623) .b8 105
(EngineCore_DP0 pid=467623) .b8 100
(EngineCore_DP0 pid=467623) .b8 101
(EngineCore_DP0 pid=467623) .b8 95
(EngineCore_DP0 pid=467623) .b8 102
(EngineCore_DP0 pid=467623) .b8 112
(EngineCore_DP0 pid=467623) .b8 56
(EngineCore_DP0 pid=467623) .b8 95
(EngineCore_DP0 pid=467623) .b8 107
(EngineCore_DP0 pid=467623) .b8 101
(EngineCore_DP0 pid=467623) .b8 114
(EngineCore_DP0 pid=467623) .b8 110
(EngineCore_DP0 pid=467623) .b8 101
(EngineCore_DP0 pid=467623) .b8 108
(EngineCore_DP0 pid=467623) .b8 0
(EngineCore_DP0 pid=467623) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=467623) .b8 3                                   // Abbrev [3] 0xb2:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=467623) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=467623) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=467623) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=467623) .b8 4                                   // Abbrev [4] 0xc7:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=467623) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=467623) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=467623) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=467623) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=467623) .b8 157                                 // DW_AT_call_line
(EngineCore_DP0 pid=467623) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=467623) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=467623) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=467623) 	}
(EngineCore_DP0 pid=467623) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=467623) 
(EngineCore_DP0 pid=467623) ================================================================
(EngineCore_DP0 pid=467623) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=467623) 
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp9d0gonod.ptx', '-o', '/tmp/tmp9d0gonod.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866] 
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866] 
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866] 
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp9d0gonod.ptx -o /tmp/tmp9d0gonod.ptx.o
(EngineCore_DP0 pid=467623) ERROR 01-25 21:18:52 [core.py:866] 

STDERR:
[2026-01-25 21:18:05] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:18:05] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:18:05] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:18:05] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:18:05] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:18:05] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:18:05] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:18:05] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:18:05] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:18:05] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:18:05] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:18:05] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:18:05] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:18:05] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:18:08] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:18:08] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:18:08] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:18:08] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:18:08] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:18:08] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:18:08] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:18:08] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:18:08] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:18:08] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:18:08] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:18:08] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:18:08] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:18:08] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=467623) [2026-01-25 21:18:09] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=467623) [2026-01-25 21:18:09] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=467623) [2026-01-25 21:18:09] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=467623) [2026-01-25 21:18:09] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=467623) [2026-01-25 21:18:09] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=467623) [2026-01-25 21:18:09] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=467623) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=467623) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:20<00:20, 20.25s/it]
(EngineCore_DP0 pid=467623) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:40<00:00, 20.28s/it]
(EngineCore_DP0 pid=467623) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:40<00:00, 20.27s/it]
(EngineCore_DP0 pid=467623) 
(EngineCore_DP0 pid=467623) [2026-01-25 21:18:51] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=467623) [2026-01-25 21:18:51] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10321920 bytes
(EngineCore_DP0 pid=467623) [2026-01-25 21:18:51] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=467623) [2026-01-25 21:18:51] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8028160 bytes
(EngineCore_DP0 pid=467623) [2026-01-25 21:18:51] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=467623) [2026-01-25 21:18:51] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 84869120 bytes
(EngineCore_DP0 pid=467623) [2026-01-25 21:18:51] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=467623) [2026-01-25 21:18:51] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 42434560 bytes
(EngineCore_DP0 pid=467623) Process EngineCore_DP0:
(EngineCore_DP0 pid=467623) Traceback (most recent call last):
(EngineCore_DP0 pid=467623)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=467623)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=467623)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=467623)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=467623) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp9d0gonod.ptx', '-o', '/tmp/tmp9d0gonod.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=467623) 
(EngineCore_DP0 pid=467623) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=467623) 
(EngineCore_DP0 pid=467623) Traceback (most recent call last):
(EngineCore_DP0 pid=467623)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=467623)     self.run()
(EngineCore_DP0 pid=467623)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=467623)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=467623)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=467623)     raise e
(EngineCore_DP0 pid=467623)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=467623)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=467623)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=467623)     super().__init__(
(EngineCore_DP0 pid=467623)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=467623)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=467623)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=467623)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=467623)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=467623)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=467623)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=467623)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=467623)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=467623)     return func(*args, **kwargs)
(EngineCore_DP0 pid=467623)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=467623)     return func(*args, **kwargs)
(EngineCore_DP0 pid=467623)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=467623)     self.model_runner.profile_run()
(EngineCore_DP0 pid=467623)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=467623)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=467623)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=467623)     return func(*args, **kwargs)
(EngineCore_DP0 pid=467623)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=467623)     outputs = self.model(
(EngineCore_DP0 pid=467623)               ^^^^^^^^^^^
(EngineCore_DP0 pid=467623)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=467623)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=467623)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=467623)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=467623)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=467623)     hidden_states = self.model(
(EngineCore_DP0 pid=467623)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=467623)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=467623)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=467623)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=467623)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=467623)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=467623)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=467623)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=467623)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=467623)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=467623)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=467623)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=467623)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=467623)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=467623)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=467623)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=467623)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=467623)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=467623)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=467623)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=467623)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=467623)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=467623)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=467623)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=467623)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=467623)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=467623)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=467623)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=467623)     return self._linear_fn(
(EngineCore_DP0 pid=467623)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=467623)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=467623)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=467623)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=467623)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=467623)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=467623)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=467623)     return fn(input, L)
(EngineCore_DP0 pid=467623)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=467623)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=467623)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=467623)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=467623)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=467623)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=467623)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=467623)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=467623)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=467623)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=467623)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=467623)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=467623)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=467623)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=467623)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=467623)     raise PTXASError(error)
(EngineCore_DP0 pid=467623) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=467623) `ptxas` stderr:
(EngineCore_DP0 pid=467623) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=467623) 
(EngineCore_DP0 pid=467623) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp9d0gonod.ptx -o /tmp/tmp9d0gonod.ptx.o
(EngineCore_DP0 pid=467623) 
[rank0]:[W125 21:18:52.724934907 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=1024

========== M=2048 ==========
Time: 2026-01-25 21:18:54
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Qwen2.5-7B-FP8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:18:58 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 21:18:58 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=468557) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=468557) 
(EngineCore_DP0 pid=468557) 
(EngineCore_DP0 pid=468557) ================================================================
(EngineCore_DP0 pid=468557) Internal Triton PTX codegen error
(EngineCore_DP0 pid=468557) `ptxas` stderr:
(EngineCore_DP0 pid=468557) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=468557) 
(EngineCore_DP0 pid=468557) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpfk6x1ptn.ptx -o /tmp/tmpfk6x1ptn.ptx.o
(EngineCore_DP0 pid=468557) 
(EngineCore_DP0 pid=468557) 
(EngineCore_DP0 pid=468557) //
(EngineCore_DP0 pid=468557) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=468557) //
(EngineCore_DP0 pid=468557) 
(EngineCore_DP0 pid=468557) .version 8.7
(EngineCore_DP0 pid=468557) .target sm_121a
(EngineCore_DP0 pid=468557) .address_size 64
(EngineCore_DP0 pid=468557) 
(EngineCore_DP0 pid=468557) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=468557) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=468557)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=468557) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=468557) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=468557) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=468557) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=468557) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=468557) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=468557) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=468557) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=468557) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=468557) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=468557) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=468557) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=468557) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=468557) )
(EngineCore_DP0 pid=468557) .reqntid 512
(EngineCore_DP0 pid=468557) {
(EngineCore_DP0 pid=468557) 	.reg .pred 	%p<28>;
(EngineCore_DP0 pid=468557) 	.reg .b16 	%rs<49>;
(EngineCore_DP0 pid=468557) 	.reg .b32 	%r<134>;
(EngineCore_DP0 pid=468557) 	.reg .b64 	%rd<17>;
(EngineCore_DP0 pid=468557) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=468557) $L__func_begin0:
(EngineCore_DP0 pid=468557) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=468557) 
(EngineCore_DP0 pid=468557) // %bb.0:
(EngineCore_DP0 pid=468557) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=468557) 	ld.param.b32 	%r22, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=468557) 	ld.param.b32 	%r21, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=468557) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=468557) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=468557) $L__tmp0:
(EngineCore_DP0 pid=468557) 	.loc	1 143 24                        // quant_slide_tuned_Qwen2.5-7B.py:143:24
(EngineCore_DP0 pid=468557) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=468557) 	ld.param.b32 	%r25, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=468557) 	.loc	1 148 26                        // quant_slide_tuned_Qwen2.5-7B.py:148:26
(EngineCore_DP0 pid=468557) 	mul.lo.s32 	%r26, %r25, %r1;
(EngineCore_DP0 pid=468557) 	.loc	1 148 20                        // quant_slide_tuned_Qwen2.5-7B.py:148:20
(EngineCore_DP0 pid=468557) 	mad.wide.s32 	%rd1, %r26, 2, %rd4;
(EngineCore_DP0 pid=468557) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=468557) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=468557) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=468557) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=468557) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=468557) 	setp.lt.s32 	%p1, %r22, 1;
(EngineCore_DP0 pid=468557) 	mov.b32 	%r131, 0f2B8CBCCC;
(EngineCore_DP0 pid=468557) 	setp.eq.b32 	%p27, %r2, 0;
(EngineCore_DP0 pid=468557) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=468557) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=468557) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=468557) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=468557) 	shr.u32 	%r35, %r2, 3;
(EngineCore_DP0 pid=468557) 	and.b32 	%r36, %r35, 60;
(EngineCore_DP0 pid=468557) 	mov.b32 	%r37, global_smem;
(EngineCore_DP0 pid=468557) 	add.s32 	%r47, %r37, %r36;
(EngineCore_DP0 pid=468557) 	shl.b32 	%r38, %r2, 2;
(EngineCore_DP0 pid=468557) 	add.s32 	%r50, %r37, %r38;
(EngineCore_DP0 pid=468557) 	mov.b32 	%r43, 0;
(EngineCore_DP0 pid=468557) 	mov.b32 	%r129, 0f00000000;
(EngineCore_DP0 pid=468557) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=468557) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=468557) 	mov.b32 	%r130, %r43;
(EngineCore_DP0 pid=468557) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=468557) 	.loc	1 155 22                        // quant_slide_tuned_Qwen2.5-7B.py:155:22
(EngineCore_DP0 pid=468557) 	add.s32 	%r53, %r4, %r130;
(EngineCore_DP0 pid=468557) 	setp.lt.s32 	%p2, %r53, %r21;
(EngineCore_DP0 pid=468557) 	.loc	1 156 29                        // quant_slide_tuned_Qwen2.5-7B.py:156:29
(EngineCore_DP0 pid=468557) 	mad.wide.s32 	%rd6, %r53, 2, %rd1;
(EngineCore_DP0 pid=468557) 	.loc	1 156 21                        // quant_slide_tuned_Qwen2.5-7B.py:156:21
(EngineCore_DP0 pid=468557) 	// begin inline asm
(EngineCore_DP0 pid=468557) 	mov.u32 %r39, %r43;
(EngineCore_DP0 pid=468557) 	mov.u32 %r40, %r43;
(EngineCore_DP0 pid=468557) 	mov.u32 %r41, %r43;
(EngineCore_DP0 pid=468557) 	mov.u32 %r42, %r43;
(EngineCore_DP0 pid=468557) 	@%p2 ld.global.v4.b32 { %r39, %r40, %r41, %r42 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=468557) 	// end inline asm
(EngineCore_DP0 pid=468557) 	mov.b32 	{%rs1, %rs2}, %r39;
(EngineCore_DP0 pid=468557) 	mov.b32 	{%rs3, %rs4}, %r40;
(EngineCore_DP0 pid=468557) 	mov.b32 	{%rs5, %rs6}, %r41;
(EngineCore_DP0 pid=468557) 	mov.b32 	{%rs7, %rs8}, %r42;
(EngineCore_DP0 pid=468557) 	.loc	1 157 50                        // quant_slide_tuned_Qwen2.5-7B.py:157:50
(EngineCore_DP0 pid=468557) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=468557) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=468557) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=468557) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=468557) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=468557) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=468557) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=468557) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=468557) $L__tmp1:
(EngineCore_DP0 pid=468557) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=468557) 	bar.sync 	0;
(EngineCore_DP0 pid=468557) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=468557) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=468557) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=468557) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=468557) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=468557) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=468557) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=468557) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=468557) 	cvt.f32.bf16 	%r54, %rs23;
(EngineCore_DP0 pid=468557) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=468557) 	shfl.sync.bfly.b32 	%r55, %r54, 16, 31, -1;
(EngineCore_DP0 pid=468557) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=468557) 	max.f32 	%r56, %r54, %r55;
(EngineCore_DP0 pid=468557) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=468557) 	shfl.sync.bfly.b32 	%r57, %r56, 8, 31, -1;
(EngineCore_DP0 pid=468557) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=468557) 	max.f32 	%r58, %r56, %r57;
(EngineCore_DP0 pid=468557) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=468557) 	shfl.sync.bfly.b32 	%r59, %r58, 4, 31, -1;
(EngineCore_DP0 pid=468557) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=468557) 	max.f32 	%r60, %r58, %r59;
(EngineCore_DP0 pid=468557) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=468557) 	shfl.sync.bfly.b32 	%r61, %r60, 2, 31, -1;
(EngineCore_DP0 pid=468557) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=468557) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=468557) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=468557) 	shfl.sync.bfly.b32 	%r63, %r62, 1, 31, -1;
(EngineCore_DP0 pid=468557) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=468557) 	max.f32 	%r48, %r62, %r63;
(EngineCore_DP0 pid=468557) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=468557) 	// begin inline asm
(EngineCore_DP0 pid=468557) 	@%p3 st.shared.b32 [ %r47 + 0 ], %r48;
(EngineCore_DP0 pid=468557) 	// end inline asm
(EngineCore_DP0 pid=468557) 	bar.sync 	0;
(EngineCore_DP0 pid=468557) 	// begin inline asm
(EngineCore_DP0 pid=468557) 	@%p4 ld.shared.b32 %r49, [ %r50 + 0 ];
(EngineCore_DP0 pid=468557) 	// end inline asm
(EngineCore_DP0 pid=468557) 	shfl.sync.bfly.b32 	%r64, %r49, 8, 31, -1;
(EngineCore_DP0 pid=468557) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=468557) 	max.f32 	%r65, %r49, %r64;
(EngineCore_DP0 pid=468557) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=468557) 	shfl.sync.bfly.b32 	%r66, %r65, 4, 31, -1;
(EngineCore_DP0 pid=468557) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=468557) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=468557) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=468557) 	shfl.sync.bfly.b32 	%r68, %r67, 2, 31, -1;
(EngineCore_DP0 pid=468557) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=468557) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=468557) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=468557) 	shfl.sync.bfly.b32 	%r70, %r69, 1, 31, -1;
(EngineCore_DP0 pid=468557) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=468557) 	max.f32 	%r52, %r69, %r70;
(EngineCore_DP0 pid=468557) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=468557) 	// begin inline asm
(EngineCore_DP0 pid=468557) 	@%p27 st.shared.b32 [ %r50 + 0 ], %r52;
(EngineCore_DP0 pid=468557) 	// end inline asm
(EngineCore_DP0 pid=468557) 	bar.sync 	0;
(EngineCore_DP0 pid=468557) 	ld.shared.b32 	%r71, [global_smem];
(EngineCore_DP0 pid=468557) $L__tmp2:
(EngineCore_DP0 pid=468557) 	.loc	1 157 36                        // quant_slide_tuned_Qwen2.5-7B.py:157:36
(EngineCore_DP0 pid=468557) 	max.f32 	%r129, %r129, %r71;
(EngineCore_DP0 pid=468557) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=468557) 	add.s32 	%r130, %r130, 4096;
(EngineCore_DP0 pid=468557) 	setp.lt.s32 	%p6, %r130, %r22;
(EngineCore_DP0 pid=468557) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=468557) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=468557) 	.loc	1 159 32                        // quant_slide_tuned_Qwen2.5-7B.py:159:32
(EngineCore_DP0 pid=468557) 	max.f32 	%r131, %r129, 0f2B8CBCCC;
(EngineCore_DP0 pid=468557) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=468557) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-7B.py:0:32
(EngineCore_DP0 pid=468557) 	mov.b32 	%r73, 0f43E00000;
(EngineCore_DP0 pid=468557) 	.loc	1 160 32                        // quant_slide_tuned_Qwen2.5-7B.py:160:32
(EngineCore_DP0 pid=468557) 	div.full.f32 	%r74, %r131, %r73;
(EngineCore_DP0 pid=468557) 	.loc	1 160 41                        // quant_slide_tuned_Qwen2.5-7B.py:160:41
(EngineCore_DP0 pid=468557) 	max.f32 	%r72, %r74, 0f36924925;
(EngineCore_DP0 pid=468557) 	.loc	1 162 25                        // quant_slide_tuned_Qwen2.5-7B.py:162:25
(EngineCore_DP0 pid=468557) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=468557) 	.loc	1 162 30                        // quant_slide_tuned_Qwen2.5-7B.py:162:30
(EngineCore_DP0 pid=468557) 	// begin inline asm
(EngineCore_DP0 pid=468557) 	@%p27 st.global.b32 [ %rd7 + 0 ], { %r72 };
(EngineCore_DP0 pid=468557) 	// end inline asm
(EngineCore_DP0 pid=468557) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=468557) 	setp.lt.s32 	%p8, %r23, 1;
(EngineCore_DP0 pid=468557) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=468557) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=468557) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-7B.py:0:41
(EngineCore_DP0 pid=468557) 	ld.param.b32 	%r27, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=468557) 	shr.s32 	%r28, %r27, 31;
(EngineCore_DP0 pid=468557) 	shr.u32 	%r29, %r28, 30;
(EngineCore_DP0 pid=468557) 	add.s32 	%r30, %r27, %r29;
(EngineCore_DP0 pid=468557) 	shr.s32 	%r31, %r30, 2;
(EngineCore_DP0 pid=468557) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=468557) 	mul.lo.s32 	%r32, %r31, %r1;
(EngineCore_DP0 pid=468557) 	mad.wide.s32 	%rd2, %r32, 4, %rd5;
(EngineCore_DP0 pid=468557) 	div.full.f32 	%r14, %r73, %r131;
(EngineCore_DP0 pid=468557) 	shl.b32 	%r15, %r3, 1;
(EngineCore_DP0 pid=468557) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=468557) 	add.s32 	%r132, %r4, 7;
(EngineCore_DP0 pid=468557) 	mov.b32 	%r133, 0;
(EngineCore_DP0 pid=468557) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=468557)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=468557) 	.loc	1 169 30                        // quant_slide_tuned_Qwen2.5-7B.py:169:30
(EngineCore_DP0 pid=468557) 	add.s32 	%r86, %r15, %r133;
(EngineCore_DP0 pid=468557) 	setp.lt.s32 	%p17, %r86, %r23;
(EngineCore_DP0 pid=468557) 	.loc	1 174 22                        // quant_slide_tuned_Qwen2.5-7B.py:174:22
(EngineCore_DP0 pid=468557) 	add.s32 	%r87, %r132, -7;
(EngineCore_DP0 pid=468557) 	.loc	1 177 53                        // quant_slide_tuned_Qwen2.5-7B.py:177:53
(EngineCore_DP0 pid=468557) 	add.s32 	%r88, %r132, -3;
(EngineCore_DP0 pid=468557) 	setp.lt.s32 	%p18, %r87, %r21;
(EngineCore_DP0 pid=468557) 	setp.lt.s32 	%p19, %r88, %r21;
(EngineCore_DP0 pid=468557) 	.loc	1 177 37                        // quant_slide_tuned_Qwen2.5-7B.py:177:37
(EngineCore_DP0 pid=468557) 	and.pred 	%p9, %p17, %p18;
(EngineCore_DP0 pid=468557) 	and.pred 	%p10, %p17, %p19;
(EngineCore_DP0 pid=468557) 	.loc	1 176 29                        // quant_slide_tuned_Qwen2.5-7B.py:176:29
(EngineCore_DP0 pid=468557) 	mad.wide.s32 	%rd8, %r87, 2, %rd1;
(EngineCore_DP0 pid=468557) 	add.s64 	%rd9, %rd8, 8;
(EngineCore_DP0 pid=468557) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=468557) 	.loc	1 176 21                        // quant_slide_tuned_Qwen2.5-7B.py:176:21
(EngineCore_DP0 pid=468557) 	// begin inline asm
(EngineCore_DP0 pid=468557) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=468557) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=468557) 	// end inline asm
(EngineCore_DP0 pid=468557) 	// begin inline asm
(EngineCore_DP0 pid=468557) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=468557) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=468557) 	// end inline asm
(EngineCore_DP0 pid=468557) 	.loc	1 177 79                        // quant_slide_tuned_Qwen2.5-7B.py:177:79
(EngineCore_DP0 pid=468557) 	cvt.f32.bf16 	%r89, %rs24;
(EngineCore_DP0 pid=468557) 	cvt.f32.bf16 	%r90, %rs26;
(EngineCore_DP0 pid=468557) 	.loc	1 179 48                        // quant_slide_tuned_Qwen2.5-7B.py:179:48
(EngineCore_DP0 pid=468557) 	add.s32 	%r91, %r132, -6;
(EngineCore_DP0 pid=468557) 	.loc	1 179 53                        // quant_slide_tuned_Qwen2.5-7B.py:179:53
(EngineCore_DP0 pid=468557) 	add.s32 	%r92, %r132, -2;
(EngineCore_DP0 pid=468557) 	setp.lt.s32 	%p20, %r91, %r21;
(EngineCore_DP0 pid=468557) 	setp.lt.s32 	%p21, %r92, %r21;
(EngineCore_DP0 pid=468557) 	.loc	1 179 37                        // quant_slide_tuned_Qwen2.5-7B.py:179:37
(EngineCore_DP0 pid=468557) 	and.pred 	%p11, %p17, %p20;
(EngineCore_DP0 pid=468557) 	and.pred 	%p12, %p17, %p21;
(EngineCore_DP0 pid=468557) 	.loc	1 178 39                        // quant_slide_tuned_Qwen2.5-7B.py:178:39
(EngineCore_DP0 pid=468557) 	add.s64 	%rd10, %rd8, 2;
(EngineCore_DP0 pid=468557) 	add.s64 	%rd11, %rd8, 10;
(EngineCore_DP0 pid=468557) 	.loc	1 178 21                        // quant_slide_tuned_Qwen2.5-7B.py:178:21
(EngineCore_DP0 pid=468557) 	// begin inline asm
(EngineCore_DP0 pid=468557) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=468557) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=468557) 	// end inline asm
(EngineCore_DP0 pid=468557) 	// begin inline asm
(EngineCore_DP0 pid=468557) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=468557) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=468557) 	// end inline asm
(EngineCore_DP0 pid=468557) 	.loc	1 179 79                        // quant_slide_tuned_Qwen2.5-7B.py:179:79
(EngineCore_DP0 pid=468557) 	cvt.f32.bf16 	%r93, %rs28;
(EngineCore_DP0 pid=468557) 	cvt.f32.bf16 	%r94, %rs30;
(EngineCore_DP0 pid=468557) 	.loc	1 181 48                        // quant_slide_tuned_Qwen2.5-7B.py:181:48
(EngineCore_DP0 pid=468557) 	add.s32 	%r95, %r132, -5;
(EngineCore_DP0 pid=468557) 	.loc	1 181 53                        // quant_slide_tuned_Qwen2.5-7B.py:181:53
(EngineCore_DP0 pid=468557) 	add.s32 	%r96, %r132, -1;
(EngineCore_DP0 pid=468557) 	setp.lt.s32 	%p22, %r95, %r21;
(EngineCore_DP0 pid=468557) 	setp.lt.s32 	%p23, %r96, %r21;
(EngineCore_DP0 pid=468557) 	.loc	1 181 37                        // quant_slide_tuned_Qwen2.5-7B.py:181:37
(EngineCore_DP0 pid=468557) 	and.pred 	%p13, %p17, %p22;
(EngineCore_DP0 pid=468557) 	and.pred 	%p14, %p17, %p23;
(EngineCore_DP0 pid=468557) 	.loc	1 180 39                        // quant_slide_tuned_Qwen2.5-7B.py:180:39
(EngineCore_DP0 pid=468557) 	add.s64 	%rd12, %rd8, 4;
(EngineCore_DP0 pid=468557) 	add.s64 	%rd13, %rd8, 12;
(EngineCore_DP0 pid=468557) 	.loc	1 180 21                        // quant_slide_tuned_Qwen2.5-7B.py:180:21
(EngineCore_DP0 pid=468557) 	// begin inline asm
(EngineCore_DP0 pid=468557) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=468557) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=468557) 	// end inline asm
(EngineCore_DP0 pid=468557) 	// begin inline asm
(EngineCore_DP0 pid=468557) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=468557) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=468557) 	// end inline asm
(EngineCore_DP0 pid=468557) 	.loc	1 181 79                        // quant_slide_tuned_Qwen2.5-7B.py:181:79
(EngineCore_DP0 pid=468557) 	cvt.f32.bf16 	%r97, %rs32;
(EngineCore_DP0 pid=468557) 	cvt.f32.bf16 	%r98, %rs34;
(EngineCore_DP0 pid=468557) 	.loc	1 183 48                        // quant_slide_tuned_Qwen2.5-7B.py:183:48
(EngineCore_DP0 pid=468557) 	add.s32 	%r99, %r132, -4;
(EngineCore_DP0 pid=468557) 	.loc	1 183 53                        // quant_slide_tuned_Qwen2.5-7B.py:183:53
(EngineCore_DP0 pid=468557) 	setp.lt.s32 	%p24, %r99, %r21;
(EngineCore_DP0 pid=468557) 	setp.lt.s32 	%p25, %r132, %r21;
(EngineCore_DP0 pid=468557) 	.loc	1 183 37                        // quant_slide_tuned_Qwen2.5-7B.py:183:37
(EngineCore_DP0 pid=468557) 	and.pred 	%p15, %p17, %p24;
(EngineCore_DP0 pid=468557) 	and.pred 	%p16, %p17, %p25;
(EngineCore_DP0 pid=468557) 	.loc	1 182 39                        // quant_slide_tuned_Qwen2.5-7B.py:182:39
(EngineCore_DP0 pid=468557) 	add.s64 	%rd14, %rd8, 6;
(EngineCore_DP0 pid=468557) 	add.s64 	%rd15, %rd8, 14;
(EngineCore_DP0 pid=468557) 	.loc	1 182 21                        // quant_slide_tuned_Qwen2.5-7B.py:182:21
(EngineCore_DP0 pid=468557) 	// begin inline asm
(EngineCore_DP0 pid=468557) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=468557) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=468557) 	// end inline asm
(EngineCore_DP0 pid=468557) 	// begin inline asm
(EngineCore_DP0 pid=468557) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=468557) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=468557) 	// end inline asm
(EngineCore_DP0 pid=468557) 	.loc	1 183 79                        // quant_slide_tuned_Qwen2.5-7B.py:183:79
(EngineCore_DP0 pid=468557) 	cvt.f32.bf16 	%r100, %rs36;
(EngineCore_DP0 pid=468557) 	cvt.f32.bf16 	%r101, %rs38;
(EngineCore_DP0 pid=468557) 	.loc	1 185 27                        // quant_slide_tuned_Qwen2.5-7B.py:185:27
(EngineCore_DP0 pid=468557) 	mul.f32 	%r102, %r14, %r89;
(EngineCore_DP0 pid=468557) 	mul.f32 	%r103, %r14, %r90;
(EngineCore_DP0 pid=468557) 	mov.b32 	%r104, 0f43E00000;
(EngineCore_DP0 pid=468557) 	.loc	1 185 48                        // quant_slide_tuned_Qwen2.5-7B.py:185:48
(EngineCore_DP0 pid=468557) 	min.xorsign.abs.f32 	%r76, %r102, %r104;
(EngineCore_DP0 pid=468557) 	min.xorsign.abs.f32 	%r77, %r103, %r104;
(EngineCore_DP0 pid=468557) 	.loc	1 185 60                        // quant_slide_tuned_Qwen2.5-7B.py:185:60
(EngineCore_DP0 pid=468557) 	// begin inline asm
(EngineCore_DP0 pid=468557) 	cvt.rn.satfinite.e4m3x2.f32  %rs40, %r77, %r76; 
(EngineCore_DP0 pid=468557) 
(EngineCore_DP0 pid=468557) 	// end inline asm
(EngineCore_DP0 pid=468557) 	shr.u16 	%rs44, %rs40, 8;
(EngineCore_DP0 pid=468557) 	.loc	1 186 27                        // quant_slide_tuned_Qwen2.5-7B.py:186:27
(EngineCore_DP0 pid=468557) 	mul.f32 	%r105, %r14, %r93;
(EngineCore_DP0 pid=468557) 	mul.f32 	%r106, %r14, %r94;
(EngineCore_DP0 pid=468557) 	.loc	1 186 48                        // quant_slide_tuned_Qwen2.5-7B.py:186:48
(EngineCore_DP0 pid=468557) 	min.xorsign.abs.f32 	%r78, %r105, %r104;
(EngineCore_DP0 pid=468557) 	min.xorsign.abs.f32 	%r79, %r106, %r104;
(EngineCore_DP0 pid=468557) 	.loc	1 186 60                        // quant_slide_tuned_Qwen2.5-7B.py:186:60
(EngineCore_DP0 pid=468557) 	// begin inline asm
(EngineCore_DP0 pid=468557) 	cvt.rn.satfinite.e4m3x2.f32  %rs41, %r79, %r78; 
(EngineCore_DP0 pid=468557) 
(EngineCore_DP0 pid=468557) 	// end inline asm
(EngineCore_DP0 pid=468557) 	shr.u16 	%rs45, %rs41, 8;
(EngineCore_DP0 pid=468557) 	.loc	1 187 27                        // quant_slide_tuned_Qwen2.5-7B.py:187:27
(EngineCore_DP0 pid=468557) 	mul.f32 	%r107, %r14, %r97;
(EngineCore_DP0 pid=468557) 	mul.f32 	%r108, %r14, %r98;
(EngineCore_DP0 pid=468557) 	.loc	1 187 48                        // quant_slide_tuned_Qwen2.5-7B.py:187:48
(EngineCore_DP0 pid=468557) 	min.xorsign.abs.f32 	%r80, %r107, %r104;
(EngineCore_DP0 pid=468557) 	min.xorsign.abs.f32 	%r81, %r108, %r104;
(EngineCore_DP0 pid=468557) 	.loc	1 187 60                        // quant_slide_tuned_Qwen2.5-7B.py:187:60
(EngineCore_DP0 pid=468557) 	// begin inline asm
(EngineCore_DP0 pid=468557) 	cvt.rn.satfinite.e4m3x2.f32  %rs42, %r81, %r80; 
(EngineCore_DP0 pid=468557) 
(EngineCore_DP0 pid=468557) 	// end inline asm
(EngineCore_DP0 pid=468557) 	shr.u16 	%rs46, %rs42, 8;
(EngineCore_DP0 pid=468557) 	.loc	1 188 27                        // quant_slide_tuned_Qwen2.5-7B.py:188:27
(EngineCore_DP0 pid=468557) 	mul.f32 	%r109, %r14, %r100;
(EngineCore_DP0 pid=468557) 	mul.f32 	%r110, %r14, %r101;
(EngineCore_DP0 pid=468557) 	.loc	1 188 48                        // quant_slide_tuned_Qwen2.5-7B.py:188:48
(EngineCore_DP0 pid=468557) 	min.xorsign.abs.f32 	%r82, %r109, %r104;
(EngineCore_DP0 pid=468557) 	min.xorsign.abs.f32 	%r83, %r110, %r104;
(EngineCore_DP0 pid=468557) 	.loc	1 188 60                        // quant_slide_tuned_Qwen2.5-7B.py:188:60
(EngineCore_DP0 pid=468557) 	// begin inline asm
(EngineCore_DP0 pid=468557) 	cvt.rn.satfinite.e4m3x2.f32  %rs43, %r83, %r82; 
(EngineCore_DP0 pid=468557) 
(EngineCore_DP0 pid=468557) 	// end inline asm
(EngineCore_DP0 pid=468557) 	shr.u16 	%rs47, %rs43, 8;
(EngineCore_DP0 pid=468557) 	.loc	1 190 45                        // quant_slide_tuned_Qwen2.5-7B.py:190:45
(EngineCore_DP0 pid=468557) 	cvt.u32.u16 	%r111, %rs40;
(EngineCore_DP0 pid=468557) 	and.b32 	%r112, %r111, 255;
(EngineCore_DP0 pid=468557) 	cvt.u32.u16 	%r113, %rs44;
(EngineCore_DP0 pid=468557) 	.loc	1 192 45                        // quant_slide_tuned_Qwen2.5-7B.py:192:45
(EngineCore_DP0 pid=468557) 	cvt.u32.u16 	%r114, %rs42;
(EngineCore_DP0 pid=468557) 	and.b32 	%r115, %r114, 255;
(EngineCore_DP0 pid=468557) 	cvt.u32.u16 	%r116, %rs46;
(EngineCore_DP0 pid=468557) 	.loc	1 193 45                        // quant_slide_tuned_Qwen2.5-7B.py:193:45
(EngineCore_DP0 pid=468557) 	cvt.u32.u16 	%r117, %rs43;
(EngineCore_DP0 pid=468557) 	cvt.u32.u16 	%r118, %rs47;
(EngineCore_DP0 pid=468557) 	.loc	1 195 30                        // quant_slide_tuned_Qwen2.5-7B.py:195:30
(EngineCore_DP0 pid=468557) 	and.b16 	%rs48, %rs41, 255;
(EngineCore_DP0 pid=468557) 	mul.wide.u16 	%r119, %rs48, 256;
(EngineCore_DP0 pid=468557) 	mul.wide.u16 	%r120, %rs45, 256;
(EngineCore_DP0 pid=468557) 	.loc	1 195 24                        // quant_slide_tuned_Qwen2.5-7B.py:195:24
(EngineCore_DP0 pid=468557) 	or.b32 	%r121, %r119, %r112;
(EngineCore_DP0 pid=468557) 	or.b32 	%r122, %r120, %r113;
(EngineCore_DP0 pid=468557) 	.loc	1 195 42                        // quant_slide_tuned_Qwen2.5-7B.py:195:42
(EngineCore_DP0 pid=468557) 	shl.b32 	%r123, %r115, 16;
(EngineCore_DP0 pid=468557) 	shl.b32 	%r124, %r116, 16;
(EngineCore_DP0 pid=468557) 	.loc	1 195 36                        // quant_slide_tuned_Qwen2.5-7B.py:195:36
(EngineCore_DP0 pid=468557) 	or.b32 	%r125, %r121, %r123;
(EngineCore_DP0 pid=468557) 	or.b32 	%r126, %r122, %r124;
(EngineCore_DP0 pid=468557) 	.loc	1 195 55                        // quant_slide_tuned_Qwen2.5-7B.py:195:55
(EngineCore_DP0 pid=468557) 	shl.b32 	%r127, %r117, 24;
(EngineCore_DP0 pid=468557) 	shl.b32 	%r128, %r118, 24;
(EngineCore_DP0 pid=468557) 	.loc	1 195 49                        // quant_slide_tuned_Qwen2.5-7B.py:195:49
(EngineCore_DP0 pid=468557) 	or.b32 	%r84, %r125, %r127;
(EngineCore_DP0 pid=468557) 	or.b32 	%r85, %r126, %r128;
(EngineCore_DP0 pid=468557) 	.loc	1 196 29                        // quant_slide_tuned_Qwen2.5-7B.py:196:29
(EngineCore_DP0 pid=468557) 	mad.wide.s32 	%rd16, %r86, 4, %rd2;
(EngineCore_DP0 pid=468557) 	.loc	1 196 39                        // quant_slide_tuned_Qwen2.5-7B.py:196:39
(EngineCore_DP0 pid=468557) 	// begin inline asm
(EngineCore_DP0 pid=468557) 	@%p17 st.global.v2.b32 [ %rd16 + 0 ], { %r84, %r85 };
(EngineCore_DP0 pid=468557) 	// end inline asm
(EngineCore_DP0 pid=468557) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=468557) 	add.s32 	%r133, %r133, 1024;
(EngineCore_DP0 pid=468557) 	add.s32 	%r132, %r132, 4096;
(EngineCore_DP0 pid=468557) 	setp.lt.s32 	%p26, %r133, %r23;
(EngineCore_DP0 pid=468557) 	@%p26 bra 	$L__BB0_6;
(EngineCore_DP0 pid=468557) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=468557) 	.loc	1 167 4                         // quant_slide_tuned_Qwen2.5-7B.py:167:4
(EngineCore_DP0 pid=468557) 	ret;
(EngineCore_DP0 pid=468557) $L__tmp3:
(EngineCore_DP0 pid=468557) $L__func_end0:
(EngineCore_DP0 pid=468557)                                         // -- End function
(EngineCore_DP0 pid=468557) }
(EngineCore_DP0 pid=468557) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py"
(EngineCore_DP0 pid=468557) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=468557) 	.section	.debug_abbrev
(EngineCore_DP0 pid=468557) 	{
(EngineCore_DP0 pid=468557) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=468557) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=468557) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=468557) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=468557) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=468557) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=468557) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=468557) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=468557) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=468557) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=468557) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=468557) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=468557) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=468557) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=468557) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=468557) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=468557) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=468557) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=468557) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=468557) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=468557) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=468557) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=468557) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=468557) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=468557) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=468557) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=468557) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=468557) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=468557) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=468557) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=468557) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=468557) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=468557) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=468557) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=468557) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=468557) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=468557) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=468557) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=468557) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=468557) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=468557) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=468557) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=468557) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=468557) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=468557) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=468557) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=468557) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=468557) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=468557) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=468557) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=468557) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=468557) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=468557) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=468557) 	}
(EngineCore_DP0 pid=468557) 	.section	.debug_info
(EngineCore_DP0 pid=468557) 	{
(EngineCore_DP0 pid=468557) .b32 221                                // Length of Unit
(EngineCore_DP0 pid=468557) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=468557) .b8 0
(EngineCore_DP0 pid=468557) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=468557) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=468557) .b8 1                                   // Abbrev [1] 0xb:0xd6 DW_TAG_compile_unit
(EngineCore_DP0 pid=468557) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=468557) .b8 114
(EngineCore_DP0 pid=468557) .b8 105
(EngineCore_DP0 pid=468557) .b8 116
(EngineCore_DP0 pid=468557) .b8 111
(EngineCore_DP0 pid=468557) .b8 110
(EngineCore_DP0 pid=468557) .b8 0
(EngineCore_DP0 pid=468557) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=468557) .b8 0
(EngineCore_DP0 pid=468557) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=468557) .b8 117
(EngineCore_DP0 pid=468557) .b8 97
(EngineCore_DP0 pid=468557) .b8 110
(EngineCore_DP0 pid=468557) .b8 116
(EngineCore_DP0 pid=468557) .b8 95
(EngineCore_DP0 pid=468557) .b8 115
(EngineCore_DP0 pid=468557) .b8 108
(EngineCore_DP0 pid=468557) .b8 105
(EngineCore_DP0 pid=468557) .b8 100
(EngineCore_DP0 pid=468557) .b8 101
(EngineCore_DP0 pid=468557) .b8 95
(EngineCore_DP0 pid=468557) .b8 116
(EngineCore_DP0 pid=468557) .b8 117
(EngineCore_DP0 pid=468557) .b8 110
(EngineCore_DP0 pid=468557) .b8 101
(EngineCore_DP0 pid=468557) .b8 100
(EngineCore_DP0 pid=468557) .b8 95
(EngineCore_DP0 pid=468557) .b8 81
(EngineCore_DP0 pid=468557) .b8 119
(EngineCore_DP0 pid=468557) .b8 101
(EngineCore_DP0 pid=468557) .b8 110
(EngineCore_DP0 pid=468557) .b8 50
(EngineCore_DP0 pid=468557) .b8 46
(EngineCore_DP0 pid=468557) .b8 53
(EngineCore_DP0 pid=468557) .b8 45
(EngineCore_DP0 pid=468557) .b8 55
(EngineCore_DP0 pid=468557) .b8 66
(EngineCore_DP0 pid=468557) .b8 46
(EngineCore_DP0 pid=468557) .b8 112
(EngineCore_DP0 pid=468557) .b8 121
(EngineCore_DP0 pid=468557) .b8 0
(EngineCore_DP0 pid=468557) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=468557) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=468557) .b8 114
(EngineCore_DP0 pid=468557) .b8 111
(EngineCore_DP0 pid=468557) .b8 111
(EngineCore_DP0 pid=468557) .b8 116
(EngineCore_DP0 pid=468557) .b8 47
(EngineCore_DP0 pid=468557) .b8 118
(EngineCore_DP0 pid=468557) .b8 108
(EngineCore_DP0 pid=468557) .b8 108
(EngineCore_DP0 pid=468557) .b8 109
(EngineCore_DP0 pid=468557) .b8 98
(EngineCore_DP0 pid=468557) .b8 101
(EngineCore_DP0 pid=468557) .b8 110
(EngineCore_DP0 pid=468557) .b8 99
(EngineCore_DP0 pid=468557) .b8 104
(EngineCore_DP0 pid=468557) .b8 47
(EngineCore_DP0 pid=468557) .b8 115
(EngineCore_DP0 pid=468557) .b8 108
(EngineCore_DP0 pid=468557) .b8 105
(EngineCore_DP0 pid=468557) .b8 100
(EngineCore_DP0 pid=468557) .b8 101
(EngineCore_DP0 pid=468557) .b8 115
(EngineCore_DP0 pid=468557) .b8 112
(EngineCore_DP0 pid=468557) .b8 97
(EngineCore_DP0 pid=468557) .b8 114
(EngineCore_DP0 pid=468557) .b8 115
(EngineCore_DP0 pid=468557) .b8 101
(EngineCore_DP0 pid=468557) .b8 47
(EngineCore_DP0 pid=468557) .b8 99
(EngineCore_DP0 pid=468557) .b8 115
(EngineCore_DP0 pid=468557) .b8 114
(EngineCore_DP0 pid=468557) .b8 99
(EngineCore_DP0 pid=468557) .b8 47
(EngineCore_DP0 pid=468557) .b8 102
(EngineCore_DP0 pid=468557) .b8 117
(EngineCore_DP0 pid=468557) .b8 115
(EngineCore_DP0 pid=468557) .b8 101
(EngineCore_DP0 pid=468557) .b8 100
(EngineCore_DP0 pid=468557) .b8 95
(EngineCore_DP0 pid=468557) .b8 113
(EngineCore_DP0 pid=468557) .b8 117
(EngineCore_DP0 pid=468557) .b8 97
(EngineCore_DP0 pid=468557) .b8 110
(EngineCore_DP0 pid=468557) .b8 116
(EngineCore_DP0 pid=468557) .b8 95
(EngineCore_DP0 pid=468557) .b8 115
(EngineCore_DP0 pid=468557) .b8 108
(EngineCore_DP0 pid=468557) .b8 105
(EngineCore_DP0 pid=468557) .b8 100
(EngineCore_DP0 pid=468557) .b8 101
(EngineCore_DP0 pid=468557) .b8 95
(EngineCore_DP0 pid=468557) .b8 116
(EngineCore_DP0 pid=468557) .b8 114
(EngineCore_DP0 pid=468557) .b8 105
(EngineCore_DP0 pid=468557) .b8 116
(EngineCore_DP0 pid=468557) .b8 111
(EngineCore_DP0 pid=468557) .b8 110
(EngineCore_DP0 pid=468557) .b8 47
(EngineCore_DP0 pid=468557) .b8 98
(EngineCore_DP0 pid=468557) .b8 117
(EngineCore_DP0 pid=468557) .b8 105
(EngineCore_DP0 pid=468557) .b8 108
(EngineCore_DP0 pid=468557) .b8 100
(EngineCore_DP0 pid=468557) .b8 47
(EngineCore_DP0 pid=468557) .b8 71
(EngineCore_DP0 pid=468557) .b8 66
(EngineCore_DP0 pid=468557) .b8 49
(EngineCore_DP0 pid=468557) .b8 48
(EngineCore_DP0 pid=468557) .b8 95
(EngineCore_DP0 pid=468557) .b8 99
(EngineCore_DP0 pid=468557) .b8 99
(EngineCore_DP0 pid=468557) .b8 49
(EngineCore_DP0 pid=468557) .b8 50
(EngineCore_DP0 pid=468557) .b8 49
(EngineCore_DP0 pid=468557) .b8 95
(EngineCore_DP0 pid=468557) .b8 112
(EngineCore_DP0 pid=468557) .b8 121
(EngineCore_DP0 pid=468557) .b8 51
(EngineCore_DP0 pid=468557) .b8 49
(EngineCore_DP0 pid=468557) .b8 50
(EngineCore_DP0 pid=468557) .b8 95
(EngineCore_DP0 pid=468557) .b8 99
(EngineCore_DP0 pid=468557) .b8 117
(EngineCore_DP0 pid=468557) .b8 49
(EngineCore_DP0 pid=468557) .b8 50
(EngineCore_DP0 pid=468557) .b8 57
(EngineCore_DP0 pid=468557) .b8 95
(EngineCore_DP0 pid=468557) .b8 97
(EngineCore_DP0 pid=468557) .b8 97
(EngineCore_DP0 pid=468557) .b8 114
(EngineCore_DP0 pid=468557) .b8 99
(EngineCore_DP0 pid=468557) .b8 104
(EngineCore_DP0 pid=468557) .b8 54
(EngineCore_DP0 pid=468557) .b8 52
(EngineCore_DP0 pid=468557) .b8 0
(EngineCore_DP0 pid=468557) .b8 2                                   // Abbrev [2] 0x98:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=468557) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=468557) .b8 113
(EngineCore_DP0 pid=468557) .b8 117
(EngineCore_DP0 pid=468557) .b8 97
(EngineCore_DP0 pid=468557) .b8 110
(EngineCore_DP0 pid=468557) .b8 116
(EngineCore_DP0 pid=468557) .b8 95
(EngineCore_DP0 pid=468557) .b8 115
(EngineCore_DP0 pid=468557) .b8 108
(EngineCore_DP0 pid=468557) .b8 105
(EngineCore_DP0 pid=468557) .b8 100
(EngineCore_DP0 pid=468557) .b8 101
(EngineCore_DP0 pid=468557) .b8 95
(EngineCore_DP0 pid=468557) .b8 102
(EngineCore_DP0 pid=468557) .b8 112
(EngineCore_DP0 pid=468557) .b8 56
(EngineCore_DP0 pid=468557) .b8 95
(EngineCore_DP0 pid=468557) .b8 107
(EngineCore_DP0 pid=468557) .b8 101
(EngineCore_DP0 pid=468557) .b8 114
(EngineCore_DP0 pid=468557) .b8 110
(EngineCore_DP0 pid=468557) .b8 101
(EngineCore_DP0 pid=468557) .b8 108
(EngineCore_DP0 pid=468557) .b8 0
(EngineCore_DP0 pid=468557) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=468557) .b8 3                                   // Abbrev [3] 0xb2:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=468557) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=468557) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=468557) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=468557) .b8 4                                   // Abbrev [4] 0xc7:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=468557) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=468557) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=468557) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=468557) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=468557) .b8 157                                 // DW_AT_call_line
(EngineCore_DP0 pid=468557) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=468557) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=468557) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=468557) 	}
(EngineCore_DP0 pid=468557) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=468557) 
(EngineCore_DP0 pid=468557) ================================================================
(EngineCore_DP0 pid=468557) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=468557) 
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpfk6x1ptn.ptx', '-o', '/tmp/tmpfk6x1ptn.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866] 
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866] 
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866] 
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpfk6x1ptn.ptx -o /tmp/tmpfk6x1ptn.ptx.o
(EngineCore_DP0 pid=468557) ERROR 01-25 21:19:45 [core.py:866] 

STDERR:
[2026-01-25 21:18:58] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:18:58] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:18:58] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:18:58] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:18:58] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:18:58] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:18:58] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:18:58] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:18:58] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:18:58] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:18:58] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:18:58] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:18:58] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:18:58] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:19:01] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:19:02] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:19:02] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:19:02] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:19:02] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:19:02] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:19:02] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:19:02] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:19:02] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:19:02] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:19:02] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:19:02] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:19:02] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:19:02] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=468557) [2026-01-25 21:19:02] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=468557) [2026-01-25 21:19:02] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=468557) [2026-01-25 21:19:02] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=468557) [2026-01-25 21:19:02] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=468557) [2026-01-25 21:19:02] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=468557) [2026-01-25 21:19:02] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=468557) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=468557) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:20<00:20, 20.47s/it]
(EngineCore_DP0 pid=468557) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:40<00:00, 20.45s/it]
(EngineCore_DP0 pid=468557) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:40<00:00, 20.45s/it]
(EngineCore_DP0 pid=468557) 
(EngineCore_DP0 pid=468557) [2026-01-25 21:19:44] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=468557) [2026-01-25 21:19:44] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10321920 bytes
(EngineCore_DP0 pid=468557) [2026-01-25 21:19:44] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=468557) [2026-01-25 21:19:44] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8028160 bytes
(EngineCore_DP0 pid=468557) [2026-01-25 21:19:44] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=468557) [2026-01-25 21:19:44] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 84869120 bytes
(EngineCore_DP0 pid=468557) [2026-01-25 21:19:44] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=468557) [2026-01-25 21:19:44] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 42434560 bytes
(EngineCore_DP0 pid=468557) Process EngineCore_DP0:
(EngineCore_DP0 pid=468557) Traceback (most recent call last):
(EngineCore_DP0 pid=468557)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=468557)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=468557)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=468557)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=468557) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpfk6x1ptn.ptx', '-o', '/tmp/tmpfk6x1ptn.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=468557) 
(EngineCore_DP0 pid=468557) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=468557) 
(EngineCore_DP0 pid=468557) Traceback (most recent call last):
(EngineCore_DP0 pid=468557)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=468557)     self.run()
(EngineCore_DP0 pid=468557)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=468557)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=468557)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=468557)     raise e
(EngineCore_DP0 pid=468557)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=468557)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=468557)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=468557)     super().__init__(
(EngineCore_DP0 pid=468557)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=468557)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=468557)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=468557)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=468557)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=468557)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=468557)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=468557)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=468557)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=468557)     return func(*args, **kwargs)
(EngineCore_DP0 pid=468557)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=468557)     return func(*args, **kwargs)
(EngineCore_DP0 pid=468557)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=468557)     self.model_runner.profile_run()
(EngineCore_DP0 pid=468557)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=468557)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=468557)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=468557)     return func(*args, **kwargs)
(EngineCore_DP0 pid=468557)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=468557)     outputs = self.model(
(EngineCore_DP0 pid=468557)               ^^^^^^^^^^^
(EngineCore_DP0 pid=468557)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=468557)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=468557)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=468557)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=468557)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=468557)     hidden_states = self.model(
(EngineCore_DP0 pid=468557)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=468557)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=468557)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=468557)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=468557)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=468557)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=468557)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=468557)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=468557)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=468557)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=468557)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=468557)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=468557)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=468557)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=468557)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=468557)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=468557)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=468557)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=468557)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=468557)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=468557)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=468557)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=468557)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=468557)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=468557)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=468557)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=468557)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=468557)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=468557)     return self._linear_fn(
(EngineCore_DP0 pid=468557)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=468557)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=468557)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=468557)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=468557)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=468557)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=468557)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=468557)     return fn(input, L)
(EngineCore_DP0 pid=468557)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=468557)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=468557)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=468557)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=468557)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=468557)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=468557)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=468557)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=468557)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=468557)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=468557)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=468557)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=468557)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=468557)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=468557)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=468557)     raise PTXASError(error)
(EngineCore_DP0 pid=468557) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=468557) `ptxas` stderr:
(EngineCore_DP0 pid=468557) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=468557) 
(EngineCore_DP0 pid=468557) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpfk6x1ptn.ptx -o /tmp/tmpfk6x1ptn.ptx.o
(EngineCore_DP0 pid=468557) 
[rank0]:[W125 21:19:46.316097000 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=2048

========== M=4096 ==========
Time: 2026-01-25 21:19:47
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Qwen2.5-7B-FP8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:19:53 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 21:19:53 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=469508) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=469508) 
(EngineCore_DP0 pid=469508) 
(EngineCore_DP0 pid=469508) ================================================================
(EngineCore_DP0 pid=469508) Internal Triton PTX codegen error
(EngineCore_DP0 pid=469508) `ptxas` stderr:
(EngineCore_DP0 pid=469508) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=469508) 
(EngineCore_DP0 pid=469508) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpryl353me.ptx -o /tmp/tmpryl353me.ptx.o
(EngineCore_DP0 pid=469508) 
(EngineCore_DP0 pid=469508) 
(EngineCore_DP0 pid=469508) //
(EngineCore_DP0 pid=469508) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=469508) //
(EngineCore_DP0 pid=469508) 
(EngineCore_DP0 pid=469508) .version 8.7
(EngineCore_DP0 pid=469508) .target sm_121a
(EngineCore_DP0 pid=469508) .address_size 64
(EngineCore_DP0 pid=469508) 
(EngineCore_DP0 pid=469508) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=469508) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=469508)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=469508) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=469508) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=469508) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=469508) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=469508) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=469508) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=469508) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=469508) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=469508) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=469508) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=469508) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=469508) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=469508) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=469508) )
(EngineCore_DP0 pid=469508) .reqntid 512
(EngineCore_DP0 pid=469508) {
(EngineCore_DP0 pid=469508) 	.reg .pred 	%p<28>;
(EngineCore_DP0 pid=469508) 	.reg .b16 	%rs<49>;
(EngineCore_DP0 pid=469508) 	.reg .b32 	%r<134>;
(EngineCore_DP0 pid=469508) 	.reg .b64 	%rd<17>;
(EngineCore_DP0 pid=469508) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=469508) $L__func_begin0:
(EngineCore_DP0 pid=469508) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=469508) 
(EngineCore_DP0 pid=469508) // %bb.0:
(EngineCore_DP0 pid=469508) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=469508) 	ld.param.b32 	%r22, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=469508) 	ld.param.b32 	%r21, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=469508) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=469508) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=469508) $L__tmp0:
(EngineCore_DP0 pid=469508) 	.loc	1 143 24                        // quant_slide_tuned_Qwen2.5-7B.py:143:24
(EngineCore_DP0 pid=469508) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=469508) 	ld.param.b32 	%r25, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=469508) 	.loc	1 148 26                        // quant_slide_tuned_Qwen2.5-7B.py:148:26
(EngineCore_DP0 pid=469508) 	mul.lo.s32 	%r26, %r25, %r1;
(EngineCore_DP0 pid=469508) 	.loc	1 148 20                        // quant_slide_tuned_Qwen2.5-7B.py:148:20
(EngineCore_DP0 pid=469508) 	mad.wide.s32 	%rd1, %r26, 2, %rd4;
(EngineCore_DP0 pid=469508) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=469508) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=469508) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=469508) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=469508) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=469508) 	setp.lt.s32 	%p1, %r22, 1;
(EngineCore_DP0 pid=469508) 	mov.b32 	%r131, 0f2B8CBCCC;
(EngineCore_DP0 pid=469508) 	setp.eq.b32 	%p27, %r2, 0;
(EngineCore_DP0 pid=469508) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=469508) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=469508) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=469508) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=469508) 	shr.u32 	%r35, %r2, 3;
(EngineCore_DP0 pid=469508) 	and.b32 	%r36, %r35, 60;
(EngineCore_DP0 pid=469508) 	mov.b32 	%r37, global_smem;
(EngineCore_DP0 pid=469508) 	add.s32 	%r47, %r37, %r36;
(EngineCore_DP0 pid=469508) 	shl.b32 	%r38, %r2, 2;
(EngineCore_DP0 pid=469508) 	add.s32 	%r50, %r37, %r38;
(EngineCore_DP0 pid=469508) 	mov.b32 	%r43, 0;
(EngineCore_DP0 pid=469508) 	mov.b32 	%r129, 0f00000000;
(EngineCore_DP0 pid=469508) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=469508) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=469508) 	mov.b32 	%r130, %r43;
(EngineCore_DP0 pid=469508) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=469508) 	.loc	1 155 22                        // quant_slide_tuned_Qwen2.5-7B.py:155:22
(EngineCore_DP0 pid=469508) 	add.s32 	%r53, %r4, %r130;
(EngineCore_DP0 pid=469508) 	setp.lt.s32 	%p2, %r53, %r21;
(EngineCore_DP0 pid=469508) 	.loc	1 156 29                        // quant_slide_tuned_Qwen2.5-7B.py:156:29
(EngineCore_DP0 pid=469508) 	mad.wide.s32 	%rd6, %r53, 2, %rd1;
(EngineCore_DP0 pid=469508) 	.loc	1 156 21                        // quant_slide_tuned_Qwen2.5-7B.py:156:21
(EngineCore_DP0 pid=469508) 	// begin inline asm
(EngineCore_DP0 pid=469508) 	mov.u32 %r39, %r43;
(EngineCore_DP0 pid=469508) 	mov.u32 %r40, %r43;
(EngineCore_DP0 pid=469508) 	mov.u32 %r41, %r43;
(EngineCore_DP0 pid=469508) 	mov.u32 %r42, %r43;
(EngineCore_DP0 pid=469508) 	@%p2 ld.global.v4.b32 { %r39, %r40, %r41, %r42 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=469508) 	// end inline asm
(EngineCore_DP0 pid=469508) 	mov.b32 	{%rs1, %rs2}, %r39;
(EngineCore_DP0 pid=469508) 	mov.b32 	{%rs3, %rs4}, %r40;
(EngineCore_DP0 pid=469508) 	mov.b32 	{%rs5, %rs6}, %r41;
(EngineCore_DP0 pid=469508) 	mov.b32 	{%rs7, %rs8}, %r42;
(EngineCore_DP0 pid=469508) 	.loc	1 157 50                        // quant_slide_tuned_Qwen2.5-7B.py:157:50
(EngineCore_DP0 pid=469508) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=469508) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=469508) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=469508) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=469508) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=469508) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=469508) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=469508) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=469508) $L__tmp1:
(EngineCore_DP0 pid=469508) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=469508) 	bar.sync 	0;
(EngineCore_DP0 pid=469508) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=469508) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=469508) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=469508) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=469508) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=469508) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=469508) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=469508) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=469508) 	cvt.f32.bf16 	%r54, %rs23;
(EngineCore_DP0 pid=469508) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=469508) 	shfl.sync.bfly.b32 	%r55, %r54, 16, 31, -1;
(EngineCore_DP0 pid=469508) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=469508) 	max.f32 	%r56, %r54, %r55;
(EngineCore_DP0 pid=469508) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=469508) 	shfl.sync.bfly.b32 	%r57, %r56, 8, 31, -1;
(EngineCore_DP0 pid=469508) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=469508) 	max.f32 	%r58, %r56, %r57;
(EngineCore_DP0 pid=469508) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=469508) 	shfl.sync.bfly.b32 	%r59, %r58, 4, 31, -1;
(EngineCore_DP0 pid=469508) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=469508) 	max.f32 	%r60, %r58, %r59;
(EngineCore_DP0 pid=469508) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=469508) 	shfl.sync.bfly.b32 	%r61, %r60, 2, 31, -1;
(EngineCore_DP0 pid=469508) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=469508) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=469508) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=469508) 	shfl.sync.bfly.b32 	%r63, %r62, 1, 31, -1;
(EngineCore_DP0 pid=469508) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=469508) 	max.f32 	%r48, %r62, %r63;
(EngineCore_DP0 pid=469508) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=469508) 	// begin inline asm
(EngineCore_DP0 pid=469508) 	@%p3 st.shared.b32 [ %r47 + 0 ], %r48;
(EngineCore_DP0 pid=469508) 	// end inline asm
(EngineCore_DP0 pid=469508) 	bar.sync 	0;
(EngineCore_DP0 pid=469508) 	// begin inline asm
(EngineCore_DP0 pid=469508) 	@%p4 ld.shared.b32 %r49, [ %r50 + 0 ];
(EngineCore_DP0 pid=469508) 	// end inline asm
(EngineCore_DP0 pid=469508) 	shfl.sync.bfly.b32 	%r64, %r49, 8, 31, -1;
(EngineCore_DP0 pid=469508) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=469508) 	max.f32 	%r65, %r49, %r64;
(EngineCore_DP0 pid=469508) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=469508) 	shfl.sync.bfly.b32 	%r66, %r65, 4, 31, -1;
(EngineCore_DP0 pid=469508) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=469508) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=469508) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=469508) 	shfl.sync.bfly.b32 	%r68, %r67, 2, 31, -1;
(EngineCore_DP0 pid=469508) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=469508) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=469508) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=469508) 	shfl.sync.bfly.b32 	%r70, %r69, 1, 31, -1;
(EngineCore_DP0 pid=469508) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=469508) 	max.f32 	%r52, %r69, %r70;
(EngineCore_DP0 pid=469508) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=469508) 	// begin inline asm
(EngineCore_DP0 pid=469508) 	@%p27 st.shared.b32 [ %r50 + 0 ], %r52;
(EngineCore_DP0 pid=469508) 	// end inline asm
(EngineCore_DP0 pid=469508) 	bar.sync 	0;
(EngineCore_DP0 pid=469508) 	ld.shared.b32 	%r71, [global_smem];
(EngineCore_DP0 pid=469508) $L__tmp2:
(EngineCore_DP0 pid=469508) 	.loc	1 157 36                        // quant_slide_tuned_Qwen2.5-7B.py:157:36
(EngineCore_DP0 pid=469508) 	max.f32 	%r129, %r129, %r71;
(EngineCore_DP0 pid=469508) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=469508) 	add.s32 	%r130, %r130, 4096;
(EngineCore_DP0 pid=469508) 	setp.lt.s32 	%p6, %r130, %r22;
(EngineCore_DP0 pid=469508) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=469508) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=469508) 	.loc	1 159 32                        // quant_slide_tuned_Qwen2.5-7B.py:159:32
(EngineCore_DP0 pid=469508) 	max.f32 	%r131, %r129, 0f2B8CBCCC;
(EngineCore_DP0 pid=469508) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=469508) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-7B.py:0:32
(EngineCore_DP0 pid=469508) 	mov.b32 	%r73, 0f43E00000;
(EngineCore_DP0 pid=469508) 	.loc	1 160 32                        // quant_slide_tuned_Qwen2.5-7B.py:160:32
(EngineCore_DP0 pid=469508) 	div.full.f32 	%r74, %r131, %r73;
(EngineCore_DP0 pid=469508) 	.loc	1 160 41                        // quant_slide_tuned_Qwen2.5-7B.py:160:41
(EngineCore_DP0 pid=469508) 	max.f32 	%r72, %r74, 0f36924925;
(EngineCore_DP0 pid=469508) 	.loc	1 162 25                        // quant_slide_tuned_Qwen2.5-7B.py:162:25
(EngineCore_DP0 pid=469508) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=469508) 	.loc	1 162 30                        // quant_slide_tuned_Qwen2.5-7B.py:162:30
(EngineCore_DP0 pid=469508) 	// begin inline asm
(EngineCore_DP0 pid=469508) 	@%p27 st.global.b32 [ %rd7 + 0 ], { %r72 };
(EngineCore_DP0 pid=469508) 	// end inline asm
(EngineCore_DP0 pid=469508) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=469508) 	setp.lt.s32 	%p8, %r23, 1;
(EngineCore_DP0 pid=469508) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=469508) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=469508) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-7B.py:0:41
(EngineCore_DP0 pid=469508) 	ld.param.b32 	%r27, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=469508) 	shr.s32 	%r28, %r27, 31;
(EngineCore_DP0 pid=469508) 	shr.u32 	%r29, %r28, 30;
(EngineCore_DP0 pid=469508) 	add.s32 	%r30, %r27, %r29;
(EngineCore_DP0 pid=469508) 	shr.s32 	%r31, %r30, 2;
(EngineCore_DP0 pid=469508) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=469508) 	mul.lo.s32 	%r32, %r31, %r1;
(EngineCore_DP0 pid=469508) 	mad.wide.s32 	%rd2, %r32, 4, %rd5;
(EngineCore_DP0 pid=469508) 	div.full.f32 	%r14, %r73, %r131;
(EngineCore_DP0 pid=469508) 	shl.b32 	%r15, %r3, 1;
(EngineCore_DP0 pid=469508) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=469508) 	add.s32 	%r132, %r4, 7;
(EngineCore_DP0 pid=469508) 	mov.b32 	%r133, 0;
(EngineCore_DP0 pid=469508) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=469508)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=469508) 	.loc	1 169 30                        // quant_slide_tuned_Qwen2.5-7B.py:169:30
(EngineCore_DP0 pid=469508) 	add.s32 	%r86, %r15, %r133;
(EngineCore_DP0 pid=469508) 	setp.lt.s32 	%p17, %r86, %r23;
(EngineCore_DP0 pid=469508) 	.loc	1 174 22                        // quant_slide_tuned_Qwen2.5-7B.py:174:22
(EngineCore_DP0 pid=469508) 	add.s32 	%r87, %r132, -7;
(EngineCore_DP0 pid=469508) 	.loc	1 177 53                        // quant_slide_tuned_Qwen2.5-7B.py:177:53
(EngineCore_DP0 pid=469508) 	add.s32 	%r88, %r132, -3;
(EngineCore_DP0 pid=469508) 	setp.lt.s32 	%p18, %r87, %r21;
(EngineCore_DP0 pid=469508) 	setp.lt.s32 	%p19, %r88, %r21;
(EngineCore_DP0 pid=469508) 	.loc	1 177 37                        // quant_slide_tuned_Qwen2.5-7B.py:177:37
(EngineCore_DP0 pid=469508) 	and.pred 	%p9, %p17, %p18;
(EngineCore_DP0 pid=469508) 	and.pred 	%p10, %p17, %p19;
(EngineCore_DP0 pid=469508) 	.loc	1 176 29                        // quant_slide_tuned_Qwen2.5-7B.py:176:29
(EngineCore_DP0 pid=469508) 	mad.wide.s32 	%rd8, %r87, 2, %rd1;
(EngineCore_DP0 pid=469508) 	add.s64 	%rd9, %rd8, 8;
(EngineCore_DP0 pid=469508) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=469508) 	.loc	1 176 21                        // quant_slide_tuned_Qwen2.5-7B.py:176:21
(EngineCore_DP0 pid=469508) 	// begin inline asm
(EngineCore_DP0 pid=469508) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=469508) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=469508) 	// end inline asm
(EngineCore_DP0 pid=469508) 	// begin inline asm
(EngineCore_DP0 pid=469508) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=469508) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=469508) 	// end inline asm
(EngineCore_DP0 pid=469508) 	.loc	1 177 79                        // quant_slide_tuned_Qwen2.5-7B.py:177:79
(EngineCore_DP0 pid=469508) 	cvt.f32.bf16 	%r89, %rs24;
(EngineCore_DP0 pid=469508) 	cvt.f32.bf16 	%r90, %rs26;
(EngineCore_DP0 pid=469508) 	.loc	1 179 48                        // quant_slide_tuned_Qwen2.5-7B.py:179:48
(EngineCore_DP0 pid=469508) 	add.s32 	%r91, %r132, -6;
(EngineCore_DP0 pid=469508) 	.loc	1 179 53                        // quant_slide_tuned_Qwen2.5-7B.py:179:53
(EngineCore_DP0 pid=469508) 	add.s32 	%r92, %r132, -2;
(EngineCore_DP0 pid=469508) 	setp.lt.s32 	%p20, %r91, %r21;
(EngineCore_DP0 pid=469508) 	setp.lt.s32 	%p21, %r92, %r21;
(EngineCore_DP0 pid=469508) 	.loc	1 179 37                        // quant_slide_tuned_Qwen2.5-7B.py:179:37
(EngineCore_DP0 pid=469508) 	and.pred 	%p11, %p17, %p20;
(EngineCore_DP0 pid=469508) 	and.pred 	%p12, %p17, %p21;
(EngineCore_DP0 pid=469508) 	.loc	1 178 39                        // quant_slide_tuned_Qwen2.5-7B.py:178:39
(EngineCore_DP0 pid=469508) 	add.s64 	%rd10, %rd8, 2;
(EngineCore_DP0 pid=469508) 	add.s64 	%rd11, %rd8, 10;
(EngineCore_DP0 pid=469508) 	.loc	1 178 21                        // quant_slide_tuned_Qwen2.5-7B.py:178:21
(EngineCore_DP0 pid=469508) 	// begin inline asm
(EngineCore_DP0 pid=469508) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=469508) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=469508) 	// end inline asm
(EngineCore_DP0 pid=469508) 	// begin inline asm
(EngineCore_DP0 pid=469508) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=469508) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=469508) 	// end inline asm
(EngineCore_DP0 pid=469508) 	.loc	1 179 79                        // quant_slide_tuned_Qwen2.5-7B.py:179:79
(EngineCore_DP0 pid=469508) 	cvt.f32.bf16 	%r93, %rs28;
(EngineCore_DP0 pid=469508) 	cvt.f32.bf16 	%r94, %rs30;
(EngineCore_DP0 pid=469508) 	.loc	1 181 48                        // quant_slide_tuned_Qwen2.5-7B.py:181:48
(EngineCore_DP0 pid=469508) 	add.s32 	%r95, %r132, -5;
(EngineCore_DP0 pid=469508) 	.loc	1 181 53                        // quant_slide_tuned_Qwen2.5-7B.py:181:53
(EngineCore_DP0 pid=469508) 	add.s32 	%r96, %r132, -1;
(EngineCore_DP0 pid=469508) 	setp.lt.s32 	%p22, %r95, %r21;
(EngineCore_DP0 pid=469508) 	setp.lt.s32 	%p23, %r96, %r21;
(EngineCore_DP0 pid=469508) 	.loc	1 181 37                        // quant_slide_tuned_Qwen2.5-7B.py:181:37
(EngineCore_DP0 pid=469508) 	and.pred 	%p13, %p17, %p22;
(EngineCore_DP0 pid=469508) 	and.pred 	%p14, %p17, %p23;
(EngineCore_DP0 pid=469508) 	.loc	1 180 39                        // quant_slide_tuned_Qwen2.5-7B.py:180:39
(EngineCore_DP0 pid=469508) 	add.s64 	%rd12, %rd8, 4;
(EngineCore_DP0 pid=469508) 	add.s64 	%rd13, %rd8, 12;
(EngineCore_DP0 pid=469508) 	.loc	1 180 21                        // quant_slide_tuned_Qwen2.5-7B.py:180:21
(EngineCore_DP0 pid=469508) 	// begin inline asm
(EngineCore_DP0 pid=469508) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=469508) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=469508) 	// end inline asm
(EngineCore_DP0 pid=469508) 	// begin inline asm
(EngineCore_DP0 pid=469508) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=469508) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=469508) 	// end inline asm
(EngineCore_DP0 pid=469508) 	.loc	1 181 79                        // quant_slide_tuned_Qwen2.5-7B.py:181:79
(EngineCore_DP0 pid=469508) 	cvt.f32.bf16 	%r97, %rs32;
(EngineCore_DP0 pid=469508) 	cvt.f32.bf16 	%r98, %rs34;
(EngineCore_DP0 pid=469508) 	.loc	1 183 48                        // quant_slide_tuned_Qwen2.5-7B.py:183:48
(EngineCore_DP0 pid=469508) 	add.s32 	%r99, %r132, -4;
(EngineCore_DP0 pid=469508) 	.loc	1 183 53                        // quant_slide_tuned_Qwen2.5-7B.py:183:53
(EngineCore_DP0 pid=469508) 	setp.lt.s32 	%p24, %r99, %r21;
(EngineCore_DP0 pid=469508) 	setp.lt.s32 	%p25, %r132, %r21;
(EngineCore_DP0 pid=469508) 	.loc	1 183 37                        // quant_slide_tuned_Qwen2.5-7B.py:183:37
(EngineCore_DP0 pid=469508) 	and.pred 	%p15, %p17, %p24;
(EngineCore_DP0 pid=469508) 	and.pred 	%p16, %p17, %p25;
(EngineCore_DP0 pid=469508) 	.loc	1 182 39                        // quant_slide_tuned_Qwen2.5-7B.py:182:39
(EngineCore_DP0 pid=469508) 	add.s64 	%rd14, %rd8, 6;
(EngineCore_DP0 pid=469508) 	add.s64 	%rd15, %rd8, 14;
(EngineCore_DP0 pid=469508) 	.loc	1 182 21                        // quant_slide_tuned_Qwen2.5-7B.py:182:21
(EngineCore_DP0 pid=469508) 	// begin inline asm
(EngineCore_DP0 pid=469508) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=469508) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=469508) 	// end inline asm
(EngineCore_DP0 pid=469508) 	// begin inline asm
(EngineCore_DP0 pid=469508) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=469508) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=469508) 	// end inline asm
(EngineCore_DP0 pid=469508) 	.loc	1 183 79                        // quant_slide_tuned_Qwen2.5-7B.py:183:79
(EngineCore_DP0 pid=469508) 	cvt.f32.bf16 	%r100, %rs36;
(EngineCore_DP0 pid=469508) 	cvt.f32.bf16 	%r101, %rs38;
(EngineCore_DP0 pid=469508) 	.loc	1 185 27                        // quant_slide_tuned_Qwen2.5-7B.py:185:27
(EngineCore_DP0 pid=469508) 	mul.f32 	%r102, %r14, %r89;
(EngineCore_DP0 pid=469508) 	mul.f32 	%r103, %r14, %r90;
(EngineCore_DP0 pid=469508) 	mov.b32 	%r104, 0f43E00000;
(EngineCore_DP0 pid=469508) 	.loc	1 185 48                        // quant_slide_tuned_Qwen2.5-7B.py:185:48
(EngineCore_DP0 pid=469508) 	min.xorsign.abs.f32 	%r76, %r102, %r104;
(EngineCore_DP0 pid=469508) 	min.xorsign.abs.f32 	%r77, %r103, %r104;
(EngineCore_DP0 pid=469508) 	.loc	1 185 60                        // quant_slide_tuned_Qwen2.5-7B.py:185:60
(EngineCore_DP0 pid=469508) 	// begin inline asm
(EngineCore_DP0 pid=469508) 	cvt.rn.satfinite.e4m3x2.f32  %rs40, %r77, %r76; 
(EngineCore_DP0 pid=469508) 
(EngineCore_DP0 pid=469508) 	// end inline asm
(EngineCore_DP0 pid=469508) 	shr.u16 	%rs44, %rs40, 8;
(EngineCore_DP0 pid=469508) 	.loc	1 186 27                        // quant_slide_tuned_Qwen2.5-7B.py:186:27
(EngineCore_DP0 pid=469508) 	mul.f32 	%r105, %r14, %r93;
(EngineCore_DP0 pid=469508) 	mul.f32 	%r106, %r14, %r94;
(EngineCore_DP0 pid=469508) 	.loc	1 186 48                        // quant_slide_tuned_Qwen2.5-7B.py:186:48
(EngineCore_DP0 pid=469508) 	min.xorsign.abs.f32 	%r78, %r105, %r104;
(EngineCore_DP0 pid=469508) 	min.xorsign.abs.f32 	%r79, %r106, %r104;
(EngineCore_DP0 pid=469508) 	.loc	1 186 60                        // quant_slide_tuned_Qwen2.5-7B.py:186:60
(EngineCore_DP0 pid=469508) 	// begin inline asm
(EngineCore_DP0 pid=469508) 	cvt.rn.satfinite.e4m3x2.f32  %rs41, %r79, %r78; 
(EngineCore_DP0 pid=469508) 
(EngineCore_DP0 pid=469508) 	// end inline asm
(EngineCore_DP0 pid=469508) 	shr.u16 	%rs45, %rs41, 8;
(EngineCore_DP0 pid=469508) 	.loc	1 187 27                        // quant_slide_tuned_Qwen2.5-7B.py:187:27
(EngineCore_DP0 pid=469508) 	mul.f32 	%r107, %r14, %r97;
(EngineCore_DP0 pid=469508) 	mul.f32 	%r108, %r14, %r98;
(EngineCore_DP0 pid=469508) 	.loc	1 187 48                        // quant_slide_tuned_Qwen2.5-7B.py:187:48
(EngineCore_DP0 pid=469508) 	min.xorsign.abs.f32 	%r80, %r107, %r104;
(EngineCore_DP0 pid=469508) 	min.xorsign.abs.f32 	%r81, %r108, %r104;
(EngineCore_DP0 pid=469508) 	.loc	1 187 60                        // quant_slide_tuned_Qwen2.5-7B.py:187:60
(EngineCore_DP0 pid=469508) 	// begin inline asm
(EngineCore_DP0 pid=469508) 	cvt.rn.satfinite.e4m3x2.f32  %rs42, %r81, %r80; 
(EngineCore_DP0 pid=469508) 
(EngineCore_DP0 pid=469508) 	// end inline asm
(EngineCore_DP0 pid=469508) 	shr.u16 	%rs46, %rs42, 8;
(EngineCore_DP0 pid=469508) 	.loc	1 188 27                        // quant_slide_tuned_Qwen2.5-7B.py:188:27
(EngineCore_DP0 pid=469508) 	mul.f32 	%r109, %r14, %r100;
(EngineCore_DP0 pid=469508) 	mul.f32 	%r110, %r14, %r101;
(EngineCore_DP0 pid=469508) 	.loc	1 188 48                        // quant_slide_tuned_Qwen2.5-7B.py:188:48
(EngineCore_DP0 pid=469508) 	min.xorsign.abs.f32 	%r82, %r109, %r104;
(EngineCore_DP0 pid=469508) 	min.xorsign.abs.f32 	%r83, %r110, %r104;
(EngineCore_DP0 pid=469508) 	.loc	1 188 60                        // quant_slide_tuned_Qwen2.5-7B.py:188:60
(EngineCore_DP0 pid=469508) 	// begin inline asm
(EngineCore_DP0 pid=469508) 	cvt.rn.satfinite.e4m3x2.f32  %rs43, %r83, %r82; 
(EngineCore_DP0 pid=469508) 
(EngineCore_DP0 pid=469508) 	// end inline asm
(EngineCore_DP0 pid=469508) 	shr.u16 	%rs47, %rs43, 8;
(EngineCore_DP0 pid=469508) 	.loc	1 190 45                        // quant_slide_tuned_Qwen2.5-7B.py:190:45
(EngineCore_DP0 pid=469508) 	cvt.u32.u16 	%r111, %rs40;
(EngineCore_DP0 pid=469508) 	and.b32 	%r112, %r111, 255;
(EngineCore_DP0 pid=469508) 	cvt.u32.u16 	%r113, %rs44;
(EngineCore_DP0 pid=469508) 	.loc	1 192 45                        // quant_slide_tuned_Qwen2.5-7B.py:192:45
(EngineCore_DP0 pid=469508) 	cvt.u32.u16 	%r114, %rs42;
(EngineCore_DP0 pid=469508) 	and.b32 	%r115, %r114, 255;
(EngineCore_DP0 pid=469508) 	cvt.u32.u16 	%r116, %rs46;
(EngineCore_DP0 pid=469508) 	.loc	1 193 45                        // quant_slide_tuned_Qwen2.5-7B.py:193:45
(EngineCore_DP0 pid=469508) 	cvt.u32.u16 	%r117, %rs43;
(EngineCore_DP0 pid=469508) 	cvt.u32.u16 	%r118, %rs47;
(EngineCore_DP0 pid=469508) 	.loc	1 195 30                        // quant_slide_tuned_Qwen2.5-7B.py:195:30
(EngineCore_DP0 pid=469508) 	and.b16 	%rs48, %rs41, 255;
(EngineCore_DP0 pid=469508) 	mul.wide.u16 	%r119, %rs48, 256;
(EngineCore_DP0 pid=469508) 	mul.wide.u16 	%r120, %rs45, 256;
(EngineCore_DP0 pid=469508) 	.loc	1 195 24                        // quant_slide_tuned_Qwen2.5-7B.py:195:24
(EngineCore_DP0 pid=469508) 	or.b32 	%r121, %r119, %r112;
(EngineCore_DP0 pid=469508) 	or.b32 	%r122, %r120, %r113;
(EngineCore_DP0 pid=469508) 	.loc	1 195 42                        // quant_slide_tuned_Qwen2.5-7B.py:195:42
(EngineCore_DP0 pid=469508) 	shl.b32 	%r123, %r115, 16;
(EngineCore_DP0 pid=469508) 	shl.b32 	%r124, %r116, 16;
(EngineCore_DP0 pid=469508) 	.loc	1 195 36                        // quant_slide_tuned_Qwen2.5-7B.py:195:36
(EngineCore_DP0 pid=469508) 	or.b32 	%r125, %r121, %r123;
(EngineCore_DP0 pid=469508) 	or.b32 	%r126, %r122, %r124;
(EngineCore_DP0 pid=469508) 	.loc	1 195 55                        // quant_slide_tuned_Qwen2.5-7B.py:195:55
(EngineCore_DP0 pid=469508) 	shl.b32 	%r127, %r117, 24;
(EngineCore_DP0 pid=469508) 	shl.b32 	%r128, %r118, 24;
(EngineCore_DP0 pid=469508) 	.loc	1 195 49                        // quant_slide_tuned_Qwen2.5-7B.py:195:49
(EngineCore_DP0 pid=469508) 	or.b32 	%r84, %r125, %r127;
(EngineCore_DP0 pid=469508) 	or.b32 	%r85, %r126, %r128;
(EngineCore_DP0 pid=469508) 	.loc	1 196 29                        // quant_slide_tuned_Qwen2.5-7B.py:196:29
(EngineCore_DP0 pid=469508) 	mad.wide.s32 	%rd16, %r86, 4, %rd2;
(EngineCore_DP0 pid=469508) 	.loc	1 196 39                        // quant_slide_tuned_Qwen2.5-7B.py:196:39
(EngineCore_DP0 pid=469508) 	// begin inline asm
(EngineCore_DP0 pid=469508) 	@%p17 st.global.v2.b32 [ %rd16 + 0 ], { %r84, %r85 };
(EngineCore_DP0 pid=469508) 	// end inline asm
(EngineCore_DP0 pid=469508) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=469508) 	add.s32 	%r133, %r133, 1024;
(EngineCore_DP0 pid=469508) 	add.s32 	%r132, %r132, 4096;
(EngineCore_DP0 pid=469508) 	setp.lt.s32 	%p26, %r133, %r23;
(EngineCore_DP0 pid=469508) 	@%p26 bra 	$L__BB0_6;
(EngineCore_DP0 pid=469508) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=469508) 	.loc	1 167 4                         // quant_slide_tuned_Qwen2.5-7B.py:167:4
(EngineCore_DP0 pid=469508) 	ret;
(EngineCore_DP0 pid=469508) $L__tmp3:
(EngineCore_DP0 pid=469508) $L__func_end0:
(EngineCore_DP0 pid=469508)                                         // -- End function
(EngineCore_DP0 pid=469508) }
(EngineCore_DP0 pid=469508) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py"
(EngineCore_DP0 pid=469508) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=469508) 	.section	.debug_abbrev
(EngineCore_DP0 pid=469508) 	{
(EngineCore_DP0 pid=469508) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=469508) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=469508) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=469508) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=469508) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=469508) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=469508) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=469508) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=469508) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=469508) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=469508) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=469508) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=469508) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=469508) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=469508) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=469508) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=469508) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=469508) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=469508) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=469508) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=469508) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=469508) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=469508) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=469508) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=469508) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=469508) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=469508) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=469508) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=469508) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=469508) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=469508) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=469508) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=469508) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=469508) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=469508) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=469508) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=469508) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=469508) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=469508) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=469508) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=469508) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=469508) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=469508) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=469508) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=469508) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=469508) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=469508) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=469508) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=469508) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=469508) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=469508) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=469508) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=469508) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=469508) 	}
(EngineCore_DP0 pid=469508) 	.section	.debug_info
(EngineCore_DP0 pid=469508) 	{
(EngineCore_DP0 pid=469508) .b32 221                                // Length of Unit
(EngineCore_DP0 pid=469508) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=469508) .b8 0
(EngineCore_DP0 pid=469508) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=469508) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=469508) .b8 1                                   // Abbrev [1] 0xb:0xd6 DW_TAG_compile_unit
(EngineCore_DP0 pid=469508) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=469508) .b8 114
(EngineCore_DP0 pid=469508) .b8 105
(EngineCore_DP0 pid=469508) .b8 116
(EngineCore_DP0 pid=469508) .b8 111
(EngineCore_DP0 pid=469508) .b8 110
(EngineCore_DP0 pid=469508) .b8 0
(EngineCore_DP0 pid=469508) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=469508) .b8 0
(EngineCore_DP0 pid=469508) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=469508) .b8 117
(EngineCore_DP0 pid=469508) .b8 97
(EngineCore_DP0 pid=469508) .b8 110
(EngineCore_DP0 pid=469508) .b8 116
(EngineCore_DP0 pid=469508) .b8 95
(EngineCore_DP0 pid=469508) .b8 115
(EngineCore_DP0 pid=469508) .b8 108
(EngineCore_DP0 pid=469508) .b8 105
(EngineCore_DP0 pid=469508) .b8 100
(EngineCore_DP0 pid=469508) .b8 101
(EngineCore_DP0 pid=469508) .b8 95
(EngineCore_DP0 pid=469508) .b8 116
(EngineCore_DP0 pid=469508) .b8 117
(EngineCore_DP0 pid=469508) .b8 110
(EngineCore_DP0 pid=469508) .b8 101
(EngineCore_DP0 pid=469508) .b8 100
(EngineCore_DP0 pid=469508) .b8 95
(EngineCore_DP0 pid=469508) .b8 81
(EngineCore_DP0 pid=469508) .b8 119
(EngineCore_DP0 pid=469508) .b8 101
(EngineCore_DP0 pid=469508) .b8 110
(EngineCore_DP0 pid=469508) .b8 50
(EngineCore_DP0 pid=469508) .b8 46
(EngineCore_DP0 pid=469508) .b8 53
(EngineCore_DP0 pid=469508) .b8 45
(EngineCore_DP0 pid=469508) .b8 55
(EngineCore_DP0 pid=469508) .b8 66
(EngineCore_DP0 pid=469508) .b8 46
(EngineCore_DP0 pid=469508) .b8 112
(EngineCore_DP0 pid=469508) .b8 121
(EngineCore_DP0 pid=469508) .b8 0
(EngineCore_DP0 pid=469508) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=469508) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=469508) .b8 114
(EngineCore_DP0 pid=469508) .b8 111
(EngineCore_DP0 pid=469508) .b8 111
(EngineCore_DP0 pid=469508) .b8 116
(EngineCore_DP0 pid=469508) .b8 47
(EngineCore_DP0 pid=469508) .b8 118
(EngineCore_DP0 pid=469508) .b8 108
(EngineCore_DP0 pid=469508) .b8 108
(EngineCore_DP0 pid=469508) .b8 109
(EngineCore_DP0 pid=469508) .b8 98
(EngineCore_DP0 pid=469508) .b8 101
(EngineCore_DP0 pid=469508) .b8 110
(EngineCore_DP0 pid=469508) .b8 99
(EngineCore_DP0 pid=469508) .b8 104
(EngineCore_DP0 pid=469508) .b8 47
(EngineCore_DP0 pid=469508) .b8 115
(EngineCore_DP0 pid=469508) .b8 108
(EngineCore_DP0 pid=469508) .b8 105
(EngineCore_DP0 pid=469508) .b8 100
(EngineCore_DP0 pid=469508) .b8 101
(EngineCore_DP0 pid=469508) .b8 115
(EngineCore_DP0 pid=469508) .b8 112
(EngineCore_DP0 pid=469508) .b8 97
(EngineCore_DP0 pid=469508) .b8 114
(EngineCore_DP0 pid=469508) .b8 115
(EngineCore_DP0 pid=469508) .b8 101
(EngineCore_DP0 pid=469508) .b8 47
(EngineCore_DP0 pid=469508) .b8 99
(EngineCore_DP0 pid=469508) .b8 115
(EngineCore_DP0 pid=469508) .b8 114
(EngineCore_DP0 pid=469508) .b8 99
(EngineCore_DP0 pid=469508) .b8 47
(EngineCore_DP0 pid=469508) .b8 102
(EngineCore_DP0 pid=469508) .b8 117
(EngineCore_DP0 pid=469508) .b8 115
(EngineCore_DP0 pid=469508) .b8 101
(EngineCore_DP0 pid=469508) .b8 100
(EngineCore_DP0 pid=469508) .b8 95
(EngineCore_DP0 pid=469508) .b8 113
(EngineCore_DP0 pid=469508) .b8 117
(EngineCore_DP0 pid=469508) .b8 97
(EngineCore_DP0 pid=469508) .b8 110
(EngineCore_DP0 pid=469508) .b8 116
(EngineCore_DP0 pid=469508) .b8 95
(EngineCore_DP0 pid=469508) .b8 115
(EngineCore_DP0 pid=469508) .b8 108
(EngineCore_DP0 pid=469508) .b8 105
(EngineCore_DP0 pid=469508) .b8 100
(EngineCore_DP0 pid=469508) .b8 101
(EngineCore_DP0 pid=469508) .b8 95
(EngineCore_DP0 pid=469508) .b8 116
(EngineCore_DP0 pid=469508) .b8 114
(EngineCore_DP0 pid=469508) .b8 105
(EngineCore_DP0 pid=469508) .b8 116
(EngineCore_DP0 pid=469508) .b8 111
(EngineCore_DP0 pid=469508) .b8 110
(EngineCore_DP0 pid=469508) .b8 47
(EngineCore_DP0 pid=469508) .b8 98
(EngineCore_DP0 pid=469508) .b8 117
(EngineCore_DP0 pid=469508) .b8 105
(EngineCore_DP0 pid=469508) .b8 108
(EngineCore_DP0 pid=469508) .b8 100
(EngineCore_DP0 pid=469508) .b8 47
(EngineCore_DP0 pid=469508) .b8 71
(EngineCore_DP0 pid=469508) .b8 66
(EngineCore_DP0 pid=469508) .b8 49
(EngineCore_DP0 pid=469508) .b8 48
(EngineCore_DP0 pid=469508) .b8 95
(EngineCore_DP0 pid=469508) .b8 99
(EngineCore_DP0 pid=469508) .b8 99
(EngineCore_DP0 pid=469508) .b8 49
(EngineCore_DP0 pid=469508) .b8 50
(EngineCore_DP0 pid=469508) .b8 49
(EngineCore_DP0 pid=469508) .b8 95
(EngineCore_DP0 pid=469508) .b8 112
(EngineCore_DP0 pid=469508) .b8 121
(EngineCore_DP0 pid=469508) .b8 51
(EngineCore_DP0 pid=469508) .b8 49
(EngineCore_DP0 pid=469508) .b8 50
(EngineCore_DP0 pid=469508) .b8 95
(EngineCore_DP0 pid=469508) .b8 99
(EngineCore_DP0 pid=469508) .b8 117
(EngineCore_DP0 pid=469508) .b8 49
(EngineCore_DP0 pid=469508) .b8 50
(EngineCore_DP0 pid=469508) .b8 57
(EngineCore_DP0 pid=469508) .b8 95
(EngineCore_DP0 pid=469508) .b8 97
(EngineCore_DP0 pid=469508) .b8 97
(EngineCore_DP0 pid=469508) .b8 114
(EngineCore_DP0 pid=469508) .b8 99
(EngineCore_DP0 pid=469508) .b8 104
(EngineCore_DP0 pid=469508) .b8 54
(EngineCore_DP0 pid=469508) .b8 52
(EngineCore_DP0 pid=469508) .b8 0
(EngineCore_DP0 pid=469508) .b8 2                                   // Abbrev [2] 0x98:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=469508) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=469508) .b8 113
(EngineCore_DP0 pid=469508) .b8 117
(EngineCore_DP0 pid=469508) .b8 97
(EngineCore_DP0 pid=469508) .b8 110
(EngineCore_DP0 pid=469508) .b8 116
(EngineCore_DP0 pid=469508) .b8 95
(EngineCore_DP0 pid=469508) .b8 115
(EngineCore_DP0 pid=469508) .b8 108
(EngineCore_DP0 pid=469508) .b8 105
(EngineCore_DP0 pid=469508) .b8 100
(EngineCore_DP0 pid=469508) .b8 101
(EngineCore_DP0 pid=469508) .b8 95
(EngineCore_DP0 pid=469508) .b8 102
(EngineCore_DP0 pid=469508) .b8 112
(EngineCore_DP0 pid=469508) .b8 56
(EngineCore_DP0 pid=469508) .b8 95
(EngineCore_DP0 pid=469508) .b8 107
(EngineCore_DP0 pid=469508) .b8 101
(EngineCore_DP0 pid=469508) .b8 114
(EngineCore_DP0 pid=469508) .b8 110
(EngineCore_DP0 pid=469508) .b8 101
(EngineCore_DP0 pid=469508) .b8 108
(EngineCore_DP0 pid=469508) .b8 0
(EngineCore_DP0 pid=469508) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=469508) .b8 3                                   // Abbrev [3] 0xb2:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=469508) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=469508) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=469508) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=469508) .b8 4                                   // Abbrev [4] 0xc7:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=469508) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=469508) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=469508) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=469508) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=469508) .b8 157                                 // DW_AT_call_line
(EngineCore_DP0 pid=469508) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=469508) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=469508) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=469508) 	}
(EngineCore_DP0 pid=469508) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=469508) 
(EngineCore_DP0 pid=469508) ================================================================
(EngineCore_DP0 pid=469508) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=469508) 
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpryl353me.ptx', '-o', '/tmp/tmpryl353me.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866] 
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866] 
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866] 
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpryl353me.ptx -o /tmp/tmpryl353me.ptx.o
(EngineCore_DP0 pid=469508) ERROR 01-25 21:20:39 [core.py:866] 

STDERR:
[2026-01-25 21:19:52] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:19:52] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:19:52] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:19:52] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:19:52] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:19:52] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:19:52] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:19:52] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:19:52] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:19:52] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:19:52] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:19:52] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:19:52] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:19:52] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:19:56] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:19:56] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:19:56] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:19:56] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:19:56] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:19:56] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:19:56] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:19:56] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:19:56] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:19:56] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:19:56] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:19:56] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:19:56] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:19:56] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=469508) [2026-01-25 21:19:57] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=469508) [2026-01-25 21:19:57] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=469508) [2026-01-25 21:19:57] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=469508) [2026-01-25 21:19:57] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=469508) [2026-01-25 21:19:57] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=469508) [2026-01-25 21:19:57] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=469508) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=469508) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:20<00:20, 20.29s/it]
(EngineCore_DP0 pid=469508) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:40<00:00, 20.22s/it]
(EngineCore_DP0 pid=469508) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:40<00:00, 20.23s/it]
(EngineCore_DP0 pid=469508) 
(EngineCore_DP0 pid=469508) [2026-01-25 21:20:38] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=469508) [2026-01-25 21:20:38] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10321920 bytes
(EngineCore_DP0 pid=469508) [2026-01-25 21:20:38] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=469508) [2026-01-25 21:20:38] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8028160 bytes
(EngineCore_DP0 pid=469508) [2026-01-25 21:20:38] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=469508) [2026-01-25 21:20:38] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 84869120 bytes
(EngineCore_DP0 pid=469508) [2026-01-25 21:20:38] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=469508) [2026-01-25 21:20:38] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 42434560 bytes
(EngineCore_DP0 pid=469508) Process EngineCore_DP0:
(EngineCore_DP0 pid=469508) Traceback (most recent call last):
(EngineCore_DP0 pid=469508)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=469508)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=469508)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=469508)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=469508) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpryl353me.ptx', '-o', '/tmp/tmpryl353me.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=469508) 
(EngineCore_DP0 pid=469508) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=469508) 
(EngineCore_DP0 pid=469508) Traceback (most recent call last):
(EngineCore_DP0 pid=469508)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=469508)     self.run()
(EngineCore_DP0 pid=469508)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=469508)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=469508)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=469508)     raise e
(EngineCore_DP0 pid=469508)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=469508)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=469508)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=469508)     super().__init__(
(EngineCore_DP0 pid=469508)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=469508)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=469508)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=469508)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=469508)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=469508)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=469508)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=469508)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=469508)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=469508)     return func(*args, **kwargs)
(EngineCore_DP0 pid=469508)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=469508)     return func(*args, **kwargs)
(EngineCore_DP0 pid=469508)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=469508)     self.model_runner.profile_run()
(EngineCore_DP0 pid=469508)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=469508)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=469508)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=469508)     return func(*args, **kwargs)
(EngineCore_DP0 pid=469508)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=469508)     outputs = self.model(
(EngineCore_DP0 pid=469508)               ^^^^^^^^^^^
(EngineCore_DP0 pid=469508)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=469508)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=469508)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=469508)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=469508)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=469508)     hidden_states = self.model(
(EngineCore_DP0 pid=469508)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=469508)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=469508)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=469508)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=469508)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=469508)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=469508)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=469508)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=469508)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=469508)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=469508)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=469508)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=469508)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=469508)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=469508)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=469508)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=469508)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=469508)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=469508)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=469508)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=469508)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=469508)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=469508)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=469508)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=469508)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=469508)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=469508)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=469508)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=469508)     return self._linear_fn(
(EngineCore_DP0 pid=469508)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=469508)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=469508)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=469508)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=469508)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=469508)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=469508)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=469508)     return fn(input, L)
(EngineCore_DP0 pid=469508)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=469508)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=469508)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=469508)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=469508)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=469508)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=469508)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=469508)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=469508)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=469508)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=469508)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=469508)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=469508)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=469508)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=469508)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=469508)     raise PTXASError(error)
(EngineCore_DP0 pid=469508) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=469508) `ptxas` stderr:
(EngineCore_DP0 pid=469508) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=469508) 
(EngineCore_DP0 pid=469508) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpryl353me.ptx -o /tmp/tmpryl353me.ptx.o
(EngineCore_DP0 pid=469508) 
[rank0]:[W125 21:20:40.315249377 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=4096

========== M=8192 ==========
Time: 2026-01-25 21:20:41
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Qwen2.5-7B-FP8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:20:48 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 21:20:48 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=470465) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=470465) 
(EngineCore_DP0 pid=470465) 
(EngineCore_DP0 pid=470465) ================================================================
(EngineCore_DP0 pid=470465) Internal Triton PTX codegen error
(EngineCore_DP0 pid=470465) `ptxas` stderr:
(EngineCore_DP0 pid=470465) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=470465) 
(EngineCore_DP0 pid=470465) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpn74nvl1d.ptx -o /tmp/tmpn74nvl1d.ptx.o
(EngineCore_DP0 pid=470465) 
(EngineCore_DP0 pid=470465) 
(EngineCore_DP0 pid=470465) //
(EngineCore_DP0 pid=470465) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=470465) //
(EngineCore_DP0 pid=470465) 
(EngineCore_DP0 pid=470465) .version 8.7
(EngineCore_DP0 pid=470465) .target sm_121a
(EngineCore_DP0 pid=470465) .address_size 64
(EngineCore_DP0 pid=470465) 
(EngineCore_DP0 pid=470465) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=470465) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=470465)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=470465) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=470465) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=470465) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=470465) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=470465) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=470465) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=470465) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=470465) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=470465) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=470465) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=470465) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=470465) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=470465) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=470465) )
(EngineCore_DP0 pid=470465) .reqntid 512
(EngineCore_DP0 pid=470465) {
(EngineCore_DP0 pid=470465) 	.reg .pred 	%p<29>;
(EngineCore_DP0 pid=470465) 	.reg .b16 	%rs<73>;
(EngineCore_DP0 pid=470465) 	.reg .b32 	%r<143>;
(EngineCore_DP0 pid=470465) 	.reg .b64 	%rd<18>;
(EngineCore_DP0 pid=470465) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=470465) $L__func_begin0:
(EngineCore_DP0 pid=470465) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=470465) 
(EngineCore_DP0 pid=470465) // %bb.0:
(EngineCore_DP0 pid=470465) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=470465) 	ld.param.b32 	%r22, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=470465) 	ld.param.b32 	%r21, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=470465) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=470465) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=470465) $L__tmp0:
(EngineCore_DP0 pid=470465) 	.loc	1 143 24                        // quant_slide_tuned_Qwen2.5-7B.py:143:24
(EngineCore_DP0 pid=470465) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=470465) 	ld.param.b32 	%r25, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=470465) 	.loc	1 148 26                        // quant_slide_tuned_Qwen2.5-7B.py:148:26
(EngineCore_DP0 pid=470465) 	mul.lo.s32 	%r26, %r25, %r1;
(EngineCore_DP0 pid=470465) 	.loc	1 148 20                        // quant_slide_tuned_Qwen2.5-7B.py:148:20
(EngineCore_DP0 pid=470465) 	mad.wide.s32 	%rd1, %r26, 2, %rd4;
(EngineCore_DP0 pid=470465) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=470465) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=470465) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=470465) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=470465) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=470465) 	setp.lt.s32 	%p1, %r22, 1;
(EngineCore_DP0 pid=470465) 	mov.b32 	%r140, 0f2B8CBCCC;
(EngineCore_DP0 pid=470465) 	setp.eq.b32 	%p28, %r2, 0;
(EngineCore_DP0 pid=470465) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=470465) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=470465) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=470465) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=470465) 	shr.u32 	%r35, %r2, 3;
(EngineCore_DP0 pid=470465) 	and.b32 	%r36, %r35, 60;
(EngineCore_DP0 pid=470465) 	mov.b32 	%r37, global_smem;
(EngineCore_DP0 pid=470465) 	add.s32 	%r55, %r37, %r36;
(EngineCore_DP0 pid=470465) 	shl.b32 	%r38, %r2, 2;
(EngineCore_DP0 pid=470465) 	add.s32 	%r58, %r37, %r38;
(EngineCore_DP0 pid=470465) 	mov.b32 	%r43, 0;
(EngineCore_DP0 pid=470465) 	mov.b32 	%r138, 0f00000000;
(EngineCore_DP0 pid=470465) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=470465) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=470465) 	mov.b32 	%r139, %r43;
(EngineCore_DP0 pid=470465) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=470465) 	.loc	1 154 19                        // quant_slide_tuned_Qwen2.5-7B.py:154:19
(EngineCore_DP0 pid=470465) 	add.s32 	%r61, %r4, %r139;
(EngineCore_DP0 pid=470465) 	.loc	1 155 22                        // quant_slide_tuned_Qwen2.5-7B.py:155:22
(EngineCore_DP0 pid=470465) 	add.s32 	%r62, %r61, 4096;
(EngineCore_DP0 pid=470465) 	setp.lt.s32 	%p2, %r61, %r21;
(EngineCore_DP0 pid=470465) 	setp.lt.s32 	%p3, %r62, %r21;
(EngineCore_DP0 pid=470465) 	.loc	1 156 29                        // quant_slide_tuned_Qwen2.5-7B.py:156:29
(EngineCore_DP0 pid=470465) 	mad.wide.s32 	%rd6, %r61, 2, %rd1;
(EngineCore_DP0 pid=470465) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=470465) 	.loc	1 156 21                        // quant_slide_tuned_Qwen2.5-7B.py:156:21
(EngineCore_DP0 pid=470465) 	// begin inline asm
(EngineCore_DP0 pid=470465) 	mov.u32 %r39, %r43;
(EngineCore_DP0 pid=470465) 	mov.u32 %r40, %r43;
(EngineCore_DP0 pid=470465) 	mov.u32 %r41, %r43;
(EngineCore_DP0 pid=470465) 	mov.u32 %r42, %r43;
(EngineCore_DP0 pid=470465) 	@%p2 ld.global.v4.b32 { %r39, %r40, %r41, %r42 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=470465) 	// end inline asm
(EngineCore_DP0 pid=470465) 	mov.b32 	{%rs1, %rs2}, %r39;
(EngineCore_DP0 pid=470465) 	mov.b32 	{%rs3, %rs4}, %r40;
(EngineCore_DP0 pid=470465) 	mov.b32 	{%rs5, %rs6}, %r41;
(EngineCore_DP0 pid=470465) 	mov.b32 	{%rs7, %rs8}, %r42;
(EngineCore_DP0 pid=470465) 	// begin inline asm
(EngineCore_DP0 pid=470465) 	mov.u32 %r47, %r43;
(EngineCore_DP0 pid=470465) 	mov.u32 %r48, %r43;
(EngineCore_DP0 pid=470465) 	mov.u32 %r49, %r43;
(EngineCore_DP0 pid=470465) 	mov.u32 %r50, %r43;
(EngineCore_DP0 pid=470465) 	@%p3 ld.global.v4.b32 { %r47, %r48, %r49, %r50 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=470465) 	// end inline asm
(EngineCore_DP0 pid=470465) 	mov.b32 	{%rs9, %rs10}, %r47;
(EngineCore_DP0 pid=470465) 	mov.b32 	{%rs11, %rs12}, %r48;
(EngineCore_DP0 pid=470465) 	mov.b32 	{%rs13, %rs14}, %r49;
(EngineCore_DP0 pid=470465) 	mov.b32 	{%rs15, %rs16}, %r50;
(EngineCore_DP0 pid=470465) 	.loc	1 157 50                        // quant_slide_tuned_Qwen2.5-7B.py:157:50
(EngineCore_DP0 pid=470465) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=470465) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=470465) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=470465) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=470465) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=470465) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=470465) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=470465) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=470465) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=470465) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=470465) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=470465) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=470465) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=470465) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=470465) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=470465) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=470465) $L__tmp1:
(EngineCore_DP0 pid=470465) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=470465) 	bar.sync 	0;
(EngineCore_DP0 pid=470465) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=470465) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=470465) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=470465) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=470465) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=470465) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=470465) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=470465) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=470465) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=470465) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=470465) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=470465) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=470465) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=470465) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=470465) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=470465) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=470465) 	cvt.f32.bf16 	%r63, %rs47;
(EngineCore_DP0 pid=470465) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=470465) 	shfl.sync.bfly.b32 	%r64, %r63, 16, 31, -1;
(EngineCore_DP0 pid=470465) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=470465) 	max.f32 	%r65, %r63, %r64;
(EngineCore_DP0 pid=470465) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=470465) 	shfl.sync.bfly.b32 	%r66, %r65, 8, 31, -1;
(EngineCore_DP0 pid=470465) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=470465) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=470465) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=470465) 	shfl.sync.bfly.b32 	%r68, %r67, 4, 31, -1;
(EngineCore_DP0 pid=470465) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=470465) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=470465) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=470465) 	shfl.sync.bfly.b32 	%r70, %r69, 2, 31, -1;
(EngineCore_DP0 pid=470465) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=470465) 	max.f32 	%r71, %r69, %r70;
(EngineCore_DP0 pid=470465) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=470465) 	shfl.sync.bfly.b32 	%r72, %r71, 1, 31, -1;
(EngineCore_DP0 pid=470465) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=470465) 	max.f32 	%r56, %r71, %r72;
(EngineCore_DP0 pid=470465) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=470465) 	// begin inline asm
(EngineCore_DP0 pid=470465) 	@%p4 st.shared.b32 [ %r55 + 0 ], %r56;
(EngineCore_DP0 pid=470465) 	// end inline asm
(EngineCore_DP0 pid=470465) 	bar.sync 	0;
(EngineCore_DP0 pid=470465) 	// begin inline asm
(EngineCore_DP0 pid=470465) 	@%p5 ld.shared.b32 %r57, [ %r58 + 0 ];
(EngineCore_DP0 pid=470465) 	// end inline asm
(EngineCore_DP0 pid=470465) 	shfl.sync.bfly.b32 	%r73, %r57, 8, 31, -1;
(EngineCore_DP0 pid=470465) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=470465) 	max.f32 	%r74, %r57, %r73;
(EngineCore_DP0 pid=470465) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=470465) 	shfl.sync.bfly.b32 	%r75, %r74, 4, 31, -1;
(EngineCore_DP0 pid=470465) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=470465) 	max.f32 	%r76, %r74, %r75;
(EngineCore_DP0 pid=470465) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=470465) 	shfl.sync.bfly.b32 	%r77, %r76, 2, 31, -1;
(EngineCore_DP0 pid=470465) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=470465) 	max.f32 	%r78, %r76, %r77;
(EngineCore_DP0 pid=470465) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=470465) 	shfl.sync.bfly.b32 	%r79, %r78, 1, 31, -1;
(EngineCore_DP0 pid=470465) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=470465) 	max.f32 	%r60, %r78, %r79;
(EngineCore_DP0 pid=470465) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=470465) 	// begin inline asm
(EngineCore_DP0 pid=470465) 	@%p28 st.shared.b32 [ %r58 + 0 ], %r60;
(EngineCore_DP0 pid=470465) 	// end inline asm
(EngineCore_DP0 pid=470465) 	bar.sync 	0;
(EngineCore_DP0 pid=470465) 	ld.shared.b32 	%r80, [global_smem];
(EngineCore_DP0 pid=470465) $L__tmp2:
(EngineCore_DP0 pid=470465) 	.loc	1 157 36                        // quant_slide_tuned_Qwen2.5-7B.py:157:36
(EngineCore_DP0 pid=470465) 	max.f32 	%r138, %r138, %r80;
(EngineCore_DP0 pid=470465) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=470465) 	add.s32 	%r139, %r139, 8192;
(EngineCore_DP0 pid=470465) 	setp.lt.s32 	%p7, %r139, %r22;
(EngineCore_DP0 pid=470465) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=470465) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=470465) 	.loc	1 159 32                        // quant_slide_tuned_Qwen2.5-7B.py:159:32
(EngineCore_DP0 pid=470465) 	max.f32 	%r140, %r138, 0f2B8CBCCC;
(EngineCore_DP0 pid=470465) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=470465) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-7B.py:0:32
(EngineCore_DP0 pid=470465) 	mov.b32 	%r82, 0f43E00000;
(EngineCore_DP0 pid=470465) 	.loc	1 160 32                        // quant_slide_tuned_Qwen2.5-7B.py:160:32
(EngineCore_DP0 pid=470465) 	div.full.f32 	%r83, %r140, %r82;
(EngineCore_DP0 pid=470465) 	.loc	1 160 41                        // quant_slide_tuned_Qwen2.5-7B.py:160:41
(EngineCore_DP0 pid=470465) 	max.f32 	%r81, %r83, 0f36924925;
(EngineCore_DP0 pid=470465) 	.loc	1 162 25                        // quant_slide_tuned_Qwen2.5-7B.py:162:25
(EngineCore_DP0 pid=470465) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=470465) 	.loc	1 162 30                        // quant_slide_tuned_Qwen2.5-7B.py:162:30
(EngineCore_DP0 pid=470465) 	// begin inline asm
(EngineCore_DP0 pid=470465) 	@%p28 st.global.b32 [ %rd8 + 0 ], { %r81 };
(EngineCore_DP0 pid=470465) 	// end inline asm
(EngineCore_DP0 pid=470465) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=470465) 	setp.lt.s32 	%p9, %r23, 1;
(EngineCore_DP0 pid=470465) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=470465) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=470465) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-7B.py:0:41
(EngineCore_DP0 pid=470465) 	ld.param.b32 	%r27, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=470465) 	shr.s32 	%r28, %r27, 31;
(EngineCore_DP0 pid=470465) 	shr.u32 	%r29, %r28, 30;
(EngineCore_DP0 pid=470465) 	add.s32 	%r30, %r27, %r29;
(EngineCore_DP0 pid=470465) 	shr.s32 	%r31, %r30, 2;
(EngineCore_DP0 pid=470465) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=470465) 	mul.lo.s32 	%r32, %r31, %r1;
(EngineCore_DP0 pid=470465) 	mad.wide.s32 	%rd2, %r32, 4, %rd5;
(EngineCore_DP0 pid=470465) 	div.full.f32 	%r14, %r82, %r140;
(EngineCore_DP0 pid=470465) 	shl.b32 	%r15, %r3, 1;
(EngineCore_DP0 pid=470465) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=470465) 	add.s32 	%r141, %r4, 7;
(EngineCore_DP0 pid=470465) 	mov.b32 	%r142, 0;
(EngineCore_DP0 pid=470465) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=470465)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=470465) 	.loc	1 169 30                        // quant_slide_tuned_Qwen2.5-7B.py:169:30
(EngineCore_DP0 pid=470465) 	add.s32 	%r95, %r15, %r142;
(EngineCore_DP0 pid=470465) 	setp.lt.s32 	%p18, %r95, %r23;
(EngineCore_DP0 pid=470465) 	.loc	1 174 22                        // quant_slide_tuned_Qwen2.5-7B.py:174:22
(EngineCore_DP0 pid=470465) 	add.s32 	%r96, %r141, -7;
(EngineCore_DP0 pid=470465) 	.loc	1 177 53                        // quant_slide_tuned_Qwen2.5-7B.py:177:53
(EngineCore_DP0 pid=470465) 	add.s32 	%r97, %r141, -3;
(EngineCore_DP0 pid=470465) 	setp.lt.s32 	%p19, %r96, %r21;
(EngineCore_DP0 pid=470465) 	setp.lt.s32 	%p20, %r97, %r21;
(EngineCore_DP0 pid=470465) 	.loc	1 177 37                        // quant_slide_tuned_Qwen2.5-7B.py:177:37
(EngineCore_DP0 pid=470465) 	and.pred 	%p10, %p18, %p19;
(EngineCore_DP0 pid=470465) 	and.pred 	%p11, %p18, %p20;
(EngineCore_DP0 pid=470465) 	.loc	1 176 29                        // quant_slide_tuned_Qwen2.5-7B.py:176:29
(EngineCore_DP0 pid=470465) 	mad.wide.s32 	%rd9, %r96, 2, %rd1;
(EngineCore_DP0 pid=470465) 	add.s64 	%rd10, %rd9, 8;
(EngineCore_DP0 pid=470465) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=470465) 	.loc	1 176 21                        // quant_slide_tuned_Qwen2.5-7B.py:176:21
(EngineCore_DP0 pid=470465) 	// begin inline asm
(EngineCore_DP0 pid=470465) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=470465) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=470465) 	// end inline asm
(EngineCore_DP0 pid=470465) 	// begin inline asm
(EngineCore_DP0 pid=470465) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=470465) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=470465) 	// end inline asm
(EngineCore_DP0 pid=470465) 	.loc	1 177 79                        // quant_slide_tuned_Qwen2.5-7B.py:177:79
(EngineCore_DP0 pid=470465) 	cvt.f32.bf16 	%r98, %rs48;
(EngineCore_DP0 pid=470465) 	cvt.f32.bf16 	%r99, %rs50;
(EngineCore_DP0 pid=470465) 	.loc	1 179 48                        // quant_slide_tuned_Qwen2.5-7B.py:179:48
(EngineCore_DP0 pid=470465) 	add.s32 	%r100, %r141, -6;
(EngineCore_DP0 pid=470465) 	.loc	1 179 53                        // quant_slide_tuned_Qwen2.5-7B.py:179:53
(EngineCore_DP0 pid=470465) 	add.s32 	%r101, %r141, -2;
(EngineCore_DP0 pid=470465) 	setp.lt.s32 	%p21, %r100, %r21;
(EngineCore_DP0 pid=470465) 	setp.lt.s32 	%p22, %r101, %r21;
(EngineCore_DP0 pid=470465) 	.loc	1 179 37                        // quant_slide_tuned_Qwen2.5-7B.py:179:37
(EngineCore_DP0 pid=470465) 	and.pred 	%p12, %p18, %p21;
(EngineCore_DP0 pid=470465) 	and.pred 	%p13, %p18, %p22;
(EngineCore_DP0 pid=470465) 	.loc	1 178 39                        // quant_slide_tuned_Qwen2.5-7B.py:178:39
(EngineCore_DP0 pid=470465) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=470465) 	add.s64 	%rd12, %rd9, 10;
(EngineCore_DP0 pid=470465) 	.loc	1 178 21                        // quant_slide_tuned_Qwen2.5-7B.py:178:21
(EngineCore_DP0 pid=470465) 	// begin inline asm
(EngineCore_DP0 pid=470465) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=470465) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=470465) 	// end inline asm
(EngineCore_DP0 pid=470465) 	// begin inline asm
(EngineCore_DP0 pid=470465) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=470465) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=470465) 	// end inline asm
(EngineCore_DP0 pid=470465) 	.loc	1 179 79                        // quant_slide_tuned_Qwen2.5-7B.py:179:79
(EngineCore_DP0 pid=470465) 	cvt.f32.bf16 	%r102, %rs52;
(EngineCore_DP0 pid=470465) 	cvt.f32.bf16 	%r103, %rs54;
(EngineCore_DP0 pid=470465) 	.loc	1 181 48                        // quant_slide_tuned_Qwen2.5-7B.py:181:48
(EngineCore_DP0 pid=470465) 	add.s32 	%r104, %r141, -5;
(EngineCore_DP0 pid=470465) 	.loc	1 181 53                        // quant_slide_tuned_Qwen2.5-7B.py:181:53
(EngineCore_DP0 pid=470465) 	add.s32 	%r105, %r141, -1;
(EngineCore_DP0 pid=470465) 	setp.lt.s32 	%p23, %r104, %r21;
(EngineCore_DP0 pid=470465) 	setp.lt.s32 	%p24, %r105, %r21;
(EngineCore_DP0 pid=470465) 	.loc	1 181 37                        // quant_slide_tuned_Qwen2.5-7B.py:181:37
(EngineCore_DP0 pid=470465) 	and.pred 	%p14, %p18, %p23;
(EngineCore_DP0 pid=470465) 	and.pred 	%p15, %p18, %p24;
(EngineCore_DP0 pid=470465) 	.loc	1 180 39                        // quant_slide_tuned_Qwen2.5-7B.py:180:39
(EngineCore_DP0 pid=470465) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=470465) 	add.s64 	%rd14, %rd9, 12;
(EngineCore_DP0 pid=470465) 	.loc	1 180 21                        // quant_slide_tuned_Qwen2.5-7B.py:180:21
(EngineCore_DP0 pid=470465) 	// begin inline asm
(EngineCore_DP0 pid=470465) 	mov.u16 %rs56, %rs49;
(EngineCore_DP0 pid=470465) 	@%p14 ld.global.b16 { %rs56 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=470465) 	// end inline asm
(EngineCore_DP0 pid=470465) 	// begin inline asm
(EngineCore_DP0 pid=470465) 	mov.u16 %rs58, %rs49;
(EngineCore_DP0 pid=470465) 	@%p15 ld.global.b16 { %rs58 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=470465) 	// end inline asm
(EngineCore_DP0 pid=470465) 	.loc	1 181 79                        // quant_slide_tuned_Qwen2.5-7B.py:181:79
(EngineCore_DP0 pid=470465) 	cvt.f32.bf16 	%r106, %rs56;
(EngineCore_DP0 pid=470465) 	cvt.f32.bf16 	%r107, %rs58;
(EngineCore_DP0 pid=470465) 	.loc	1 183 48                        // quant_slide_tuned_Qwen2.5-7B.py:183:48
(EngineCore_DP0 pid=470465) 	add.s32 	%r108, %r141, -4;
(EngineCore_DP0 pid=470465) 	.loc	1 183 53                        // quant_slide_tuned_Qwen2.5-7B.py:183:53
(EngineCore_DP0 pid=470465) 	setp.lt.s32 	%p25, %r108, %r21;
(EngineCore_DP0 pid=470465) 	setp.lt.s32 	%p26, %r141, %r21;
(EngineCore_DP0 pid=470465) 	.loc	1 183 37                        // quant_slide_tuned_Qwen2.5-7B.py:183:37
(EngineCore_DP0 pid=470465) 	and.pred 	%p16, %p18, %p25;
(EngineCore_DP0 pid=470465) 	and.pred 	%p17, %p18, %p26;
(EngineCore_DP0 pid=470465) 	.loc	1 182 39                        // quant_slide_tuned_Qwen2.5-7B.py:182:39
(EngineCore_DP0 pid=470465) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=470465) 	add.s64 	%rd16, %rd9, 14;
(EngineCore_DP0 pid=470465) 	.loc	1 182 21                        // quant_slide_tuned_Qwen2.5-7B.py:182:21
(EngineCore_DP0 pid=470465) 	// begin inline asm
(EngineCore_DP0 pid=470465) 	mov.u16 %rs60, %rs49;
(EngineCore_DP0 pid=470465) 	@%p16 ld.global.b16 { %rs60 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=470465) 	// end inline asm
(EngineCore_DP0 pid=470465) 	// begin inline asm
(EngineCore_DP0 pid=470465) 	mov.u16 %rs62, %rs49;
(EngineCore_DP0 pid=470465) 	@%p17 ld.global.b16 { %rs62 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=470465) 	// end inline asm
(EngineCore_DP0 pid=470465) 	.loc	1 183 79                        // quant_slide_tuned_Qwen2.5-7B.py:183:79
(EngineCore_DP0 pid=470465) 	cvt.f32.bf16 	%r109, %rs60;
(EngineCore_DP0 pid=470465) 	cvt.f32.bf16 	%r110, %rs62;
(EngineCore_DP0 pid=470465) 	.loc	1 185 27                        // quant_slide_tuned_Qwen2.5-7B.py:185:27
(EngineCore_DP0 pid=470465) 	mul.f32 	%r111, %r14, %r98;
(EngineCore_DP0 pid=470465) 	mul.f32 	%r112, %r14, %r99;
(EngineCore_DP0 pid=470465) 	mov.b32 	%r113, 0f43E00000;
(EngineCore_DP0 pid=470465) 	.loc	1 185 48                        // quant_slide_tuned_Qwen2.5-7B.py:185:48
(EngineCore_DP0 pid=470465) 	min.xorsign.abs.f32 	%r85, %r111, %r113;
(EngineCore_DP0 pid=470465) 	min.xorsign.abs.f32 	%r86, %r112, %r113;
(EngineCore_DP0 pid=470465) 	.loc	1 185 60                        // quant_slide_tuned_Qwen2.5-7B.py:185:60
(EngineCore_DP0 pid=470465) 	// begin inline asm
(EngineCore_DP0 pid=470465) 	cvt.rn.satfinite.e4m3x2.f32  %rs64, %r86, %r85; 
(EngineCore_DP0 pid=470465) 
(EngineCore_DP0 pid=470465) 	// end inline asm
(EngineCore_DP0 pid=470465) 	shr.u16 	%rs68, %rs64, 8;
(EngineCore_DP0 pid=470465) 	.loc	1 186 27                        // quant_slide_tuned_Qwen2.5-7B.py:186:27
(EngineCore_DP0 pid=470465) 	mul.f32 	%r114, %r14, %r102;
(EngineCore_DP0 pid=470465) 	mul.f32 	%r115, %r14, %r103;
(EngineCore_DP0 pid=470465) 	.loc	1 186 48                        // quant_slide_tuned_Qwen2.5-7B.py:186:48
(EngineCore_DP0 pid=470465) 	min.xorsign.abs.f32 	%r87, %r114, %r113;
(EngineCore_DP0 pid=470465) 	min.xorsign.abs.f32 	%r88, %r115, %r113;
(EngineCore_DP0 pid=470465) 	.loc	1 186 60                        // quant_slide_tuned_Qwen2.5-7B.py:186:60
(EngineCore_DP0 pid=470465) 	// begin inline asm
(EngineCore_DP0 pid=470465) 	cvt.rn.satfinite.e4m3x2.f32  %rs65, %r88, %r87; 
(EngineCore_DP0 pid=470465) 
(EngineCore_DP0 pid=470465) 	// end inline asm
(EngineCore_DP0 pid=470465) 	shr.u16 	%rs69, %rs65, 8;
(EngineCore_DP0 pid=470465) 	.loc	1 187 27                        // quant_slide_tuned_Qwen2.5-7B.py:187:27
(EngineCore_DP0 pid=470465) 	mul.f32 	%r116, %r14, %r106;
(EngineCore_DP0 pid=470465) 	mul.f32 	%r117, %r14, %r107;
(EngineCore_DP0 pid=470465) 	.loc	1 187 48                        // quant_slide_tuned_Qwen2.5-7B.py:187:48
(EngineCore_DP0 pid=470465) 	min.xorsign.abs.f32 	%r89, %r116, %r113;
(EngineCore_DP0 pid=470465) 	min.xorsign.abs.f32 	%r90, %r117, %r113;
(EngineCore_DP0 pid=470465) 	.loc	1 187 60                        // quant_slide_tuned_Qwen2.5-7B.py:187:60
(EngineCore_DP0 pid=470465) 	// begin inline asm
(EngineCore_DP0 pid=470465) 	cvt.rn.satfinite.e4m3x2.f32  %rs66, %r90, %r89; 
(EngineCore_DP0 pid=470465) 
(EngineCore_DP0 pid=470465) 	// end inline asm
(EngineCore_DP0 pid=470465) 	shr.u16 	%rs70, %rs66, 8;
(EngineCore_DP0 pid=470465) 	.loc	1 188 27                        // quant_slide_tuned_Qwen2.5-7B.py:188:27
(EngineCore_DP0 pid=470465) 	mul.f32 	%r118, %r14, %r109;
(EngineCore_DP0 pid=470465) 	mul.f32 	%r119, %r14, %r110;
(EngineCore_DP0 pid=470465) 	.loc	1 188 48                        // quant_slide_tuned_Qwen2.5-7B.py:188:48
(EngineCore_DP0 pid=470465) 	min.xorsign.abs.f32 	%r91, %r118, %r113;
(EngineCore_DP0 pid=470465) 	min.xorsign.abs.f32 	%r92, %r119, %r113;
(EngineCore_DP0 pid=470465) 	.loc	1 188 60                        // quant_slide_tuned_Qwen2.5-7B.py:188:60
(EngineCore_DP0 pid=470465) 	// begin inline asm
(EngineCore_DP0 pid=470465) 	cvt.rn.satfinite.e4m3x2.f32  %rs67, %r92, %r91; 
(EngineCore_DP0 pid=470465) 
(EngineCore_DP0 pid=470465) 	// end inline asm
(EngineCore_DP0 pid=470465) 	shr.u16 	%rs71, %rs67, 8;
(EngineCore_DP0 pid=470465) 	.loc	1 190 45                        // quant_slide_tuned_Qwen2.5-7B.py:190:45
(EngineCore_DP0 pid=470465) 	cvt.u32.u16 	%r120, %rs64;
(EngineCore_DP0 pid=470465) 	and.b32 	%r121, %r120, 255;
(EngineCore_DP0 pid=470465) 	cvt.u32.u16 	%r122, %rs68;
(EngineCore_DP0 pid=470465) 	.loc	1 192 45                        // quant_slide_tuned_Qwen2.5-7B.py:192:45
(EngineCore_DP0 pid=470465) 	cvt.u32.u16 	%r123, %rs66;
(EngineCore_DP0 pid=470465) 	and.b32 	%r124, %r123, 255;
(EngineCore_DP0 pid=470465) 	cvt.u32.u16 	%r125, %rs70;
(EngineCore_DP0 pid=470465) 	.loc	1 193 45                        // quant_slide_tuned_Qwen2.5-7B.py:193:45
(EngineCore_DP0 pid=470465) 	cvt.u32.u16 	%r126, %rs67;
(EngineCore_DP0 pid=470465) 	cvt.u32.u16 	%r127, %rs71;
(EngineCore_DP0 pid=470465) 	.loc	1 195 30                        // quant_slide_tuned_Qwen2.5-7B.py:195:30
(EngineCore_DP0 pid=470465) 	and.b16 	%rs72, %rs65, 255;
(EngineCore_DP0 pid=470465) 	mul.wide.u16 	%r128, %rs72, 256;
(EngineCore_DP0 pid=470465) 	mul.wide.u16 	%r129, %rs69, 256;
(EngineCore_DP0 pid=470465) 	.loc	1 195 24                        // quant_slide_tuned_Qwen2.5-7B.py:195:24
(EngineCore_DP0 pid=470465) 	or.b32 	%r130, %r128, %r121;
(EngineCore_DP0 pid=470465) 	or.b32 	%r131, %r129, %r122;
(EngineCore_DP0 pid=470465) 	.loc	1 195 42                        // quant_slide_tuned_Qwen2.5-7B.py:195:42
(EngineCore_DP0 pid=470465) 	shl.b32 	%r132, %r124, 16;
(EngineCore_DP0 pid=470465) 	shl.b32 	%r133, %r125, 16;
(EngineCore_DP0 pid=470465) 	.loc	1 195 36                        // quant_slide_tuned_Qwen2.5-7B.py:195:36
(EngineCore_DP0 pid=470465) 	or.b32 	%r134, %r130, %r132;
(EngineCore_DP0 pid=470465) 	or.b32 	%r135, %r131, %r133;
(EngineCore_DP0 pid=470465) 	.loc	1 195 55                        // quant_slide_tuned_Qwen2.5-7B.py:195:55
(EngineCore_DP0 pid=470465) 	shl.b32 	%r136, %r126, 24;
(EngineCore_DP0 pid=470465) 	shl.b32 	%r137, %r127, 24;
(EngineCore_DP0 pid=470465) 	.loc	1 195 49                        // quant_slide_tuned_Qwen2.5-7B.py:195:49
(EngineCore_DP0 pid=470465) 	or.b32 	%r93, %r134, %r136;
(EngineCore_DP0 pid=470465) 	or.b32 	%r94, %r135, %r137;
(EngineCore_DP0 pid=470465) 	.loc	1 196 29                        // quant_slide_tuned_Qwen2.5-7B.py:196:29
(EngineCore_DP0 pid=470465) 	mad.wide.s32 	%rd17, %r95, 4, %rd2;
(EngineCore_DP0 pid=470465) 	.loc	1 196 39                        // quant_slide_tuned_Qwen2.5-7B.py:196:39
(EngineCore_DP0 pid=470465) 	// begin inline asm
(EngineCore_DP0 pid=470465) 	@%p18 st.global.v2.b32 [ %rd17 + 0 ], { %r93, %r94 };
(EngineCore_DP0 pid=470465) 	// end inline asm
(EngineCore_DP0 pid=470465) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=470465) 	add.s32 	%r142, %r142, 1024;
(EngineCore_DP0 pid=470465) 	add.s32 	%r141, %r141, 4096;
(EngineCore_DP0 pid=470465) 	setp.lt.s32 	%p27, %r142, %r23;
(EngineCore_DP0 pid=470465) 	@%p27 bra 	$L__BB0_6;
(EngineCore_DP0 pid=470465) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=470465) 	.loc	1 167 4                         // quant_slide_tuned_Qwen2.5-7B.py:167:4
(EngineCore_DP0 pid=470465) 	ret;
(EngineCore_DP0 pid=470465) $L__tmp3:
(EngineCore_DP0 pid=470465) $L__func_end0:
(EngineCore_DP0 pid=470465)                                         // -- End function
(EngineCore_DP0 pid=470465) }
(EngineCore_DP0 pid=470465) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py"
(EngineCore_DP0 pid=470465) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=470465) 	.section	.debug_abbrev
(EngineCore_DP0 pid=470465) 	{
(EngineCore_DP0 pid=470465) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=470465) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=470465) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=470465) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=470465) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=470465) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=470465) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=470465) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=470465) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=470465) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=470465) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=470465) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=470465) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=470465) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=470465) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=470465) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=470465) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=470465) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=470465) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=470465) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=470465) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=470465) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=470465) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=470465) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=470465) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=470465) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=470465) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=470465) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=470465) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=470465) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=470465) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=470465) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=470465) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=470465) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=470465) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=470465) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=470465) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=470465) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=470465) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=470465) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=470465) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=470465) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=470465) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=470465) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=470465) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=470465) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=470465) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=470465) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=470465) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=470465) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=470465) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=470465) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=470465) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=470465) 	}
(EngineCore_DP0 pid=470465) 	.section	.debug_info
(EngineCore_DP0 pid=470465) 	{
(EngineCore_DP0 pid=470465) .b32 221                                // Length of Unit
(EngineCore_DP0 pid=470465) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=470465) .b8 0
(EngineCore_DP0 pid=470465) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=470465) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=470465) .b8 1                                   // Abbrev [1] 0xb:0xd6 DW_TAG_compile_unit
(EngineCore_DP0 pid=470465) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=470465) .b8 114
(EngineCore_DP0 pid=470465) .b8 105
(EngineCore_DP0 pid=470465) .b8 116
(EngineCore_DP0 pid=470465) .b8 111
(EngineCore_DP0 pid=470465) .b8 110
(EngineCore_DP0 pid=470465) .b8 0
(EngineCore_DP0 pid=470465) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=470465) .b8 0
(EngineCore_DP0 pid=470465) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=470465) .b8 117
(EngineCore_DP0 pid=470465) .b8 97
(EngineCore_DP0 pid=470465) .b8 110
(EngineCore_DP0 pid=470465) .b8 116
(EngineCore_DP0 pid=470465) .b8 95
(EngineCore_DP0 pid=470465) .b8 115
(EngineCore_DP0 pid=470465) .b8 108
(EngineCore_DP0 pid=470465) .b8 105
(EngineCore_DP0 pid=470465) .b8 100
(EngineCore_DP0 pid=470465) .b8 101
(EngineCore_DP0 pid=470465) .b8 95
(EngineCore_DP0 pid=470465) .b8 116
(EngineCore_DP0 pid=470465) .b8 117
(EngineCore_DP0 pid=470465) .b8 110
(EngineCore_DP0 pid=470465) .b8 101
(EngineCore_DP0 pid=470465) .b8 100
(EngineCore_DP0 pid=470465) .b8 95
(EngineCore_DP0 pid=470465) .b8 81
(EngineCore_DP0 pid=470465) .b8 119
(EngineCore_DP0 pid=470465) .b8 101
(EngineCore_DP0 pid=470465) .b8 110
(EngineCore_DP0 pid=470465) .b8 50
(EngineCore_DP0 pid=470465) .b8 46
(EngineCore_DP0 pid=470465) .b8 53
(EngineCore_DP0 pid=470465) .b8 45
(EngineCore_DP0 pid=470465) .b8 55
(EngineCore_DP0 pid=470465) .b8 66
(EngineCore_DP0 pid=470465) .b8 46
(EngineCore_DP0 pid=470465) .b8 112
(EngineCore_DP0 pid=470465) .b8 121
(EngineCore_DP0 pid=470465) .b8 0
(EngineCore_DP0 pid=470465) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=470465) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=470465) .b8 114
(EngineCore_DP0 pid=470465) .b8 111
(EngineCore_DP0 pid=470465) .b8 111
(EngineCore_DP0 pid=470465) .b8 116
(EngineCore_DP0 pid=470465) .b8 47
(EngineCore_DP0 pid=470465) .b8 118
(EngineCore_DP0 pid=470465) .b8 108
(EngineCore_DP0 pid=470465) .b8 108
(EngineCore_DP0 pid=470465) .b8 109
(EngineCore_DP0 pid=470465) .b8 98
(EngineCore_DP0 pid=470465) .b8 101
(EngineCore_DP0 pid=470465) .b8 110
(EngineCore_DP0 pid=470465) .b8 99
(EngineCore_DP0 pid=470465) .b8 104
(EngineCore_DP0 pid=470465) .b8 47
(EngineCore_DP0 pid=470465) .b8 115
(EngineCore_DP0 pid=470465) .b8 108
(EngineCore_DP0 pid=470465) .b8 105
(EngineCore_DP0 pid=470465) .b8 100
(EngineCore_DP0 pid=470465) .b8 101
(EngineCore_DP0 pid=470465) .b8 115
(EngineCore_DP0 pid=470465) .b8 112
(EngineCore_DP0 pid=470465) .b8 97
(EngineCore_DP0 pid=470465) .b8 114
(EngineCore_DP0 pid=470465) .b8 115
(EngineCore_DP0 pid=470465) .b8 101
(EngineCore_DP0 pid=470465) .b8 47
(EngineCore_DP0 pid=470465) .b8 99
(EngineCore_DP0 pid=470465) .b8 115
(EngineCore_DP0 pid=470465) .b8 114
(EngineCore_DP0 pid=470465) .b8 99
(EngineCore_DP0 pid=470465) .b8 47
(EngineCore_DP0 pid=470465) .b8 102
(EngineCore_DP0 pid=470465) .b8 117
(EngineCore_DP0 pid=470465) .b8 115
(EngineCore_DP0 pid=470465) .b8 101
(EngineCore_DP0 pid=470465) .b8 100
(EngineCore_DP0 pid=470465) .b8 95
(EngineCore_DP0 pid=470465) .b8 113
(EngineCore_DP0 pid=470465) .b8 117
(EngineCore_DP0 pid=470465) .b8 97
(EngineCore_DP0 pid=470465) .b8 110
(EngineCore_DP0 pid=470465) .b8 116
(EngineCore_DP0 pid=470465) .b8 95
(EngineCore_DP0 pid=470465) .b8 115
(EngineCore_DP0 pid=470465) .b8 108
(EngineCore_DP0 pid=470465) .b8 105
(EngineCore_DP0 pid=470465) .b8 100
(EngineCore_DP0 pid=470465) .b8 101
(EngineCore_DP0 pid=470465) .b8 95
(EngineCore_DP0 pid=470465) .b8 116
(EngineCore_DP0 pid=470465) .b8 114
(EngineCore_DP0 pid=470465) .b8 105
(EngineCore_DP0 pid=470465) .b8 116
(EngineCore_DP0 pid=470465) .b8 111
(EngineCore_DP0 pid=470465) .b8 110
(EngineCore_DP0 pid=470465) .b8 47
(EngineCore_DP0 pid=470465) .b8 98
(EngineCore_DP0 pid=470465) .b8 117
(EngineCore_DP0 pid=470465) .b8 105
(EngineCore_DP0 pid=470465) .b8 108
(EngineCore_DP0 pid=470465) .b8 100
(EngineCore_DP0 pid=470465) .b8 47
(EngineCore_DP0 pid=470465) .b8 71
(EngineCore_DP0 pid=470465) .b8 66
(EngineCore_DP0 pid=470465) .b8 49
(EngineCore_DP0 pid=470465) .b8 48
(EngineCore_DP0 pid=470465) .b8 95
(EngineCore_DP0 pid=470465) .b8 99
(EngineCore_DP0 pid=470465) .b8 99
(EngineCore_DP0 pid=470465) .b8 49
(EngineCore_DP0 pid=470465) .b8 50
(EngineCore_DP0 pid=470465) .b8 49
(EngineCore_DP0 pid=470465) .b8 95
(EngineCore_DP0 pid=470465) .b8 112
(EngineCore_DP0 pid=470465) .b8 121
(EngineCore_DP0 pid=470465) .b8 51
(EngineCore_DP0 pid=470465) .b8 49
(EngineCore_DP0 pid=470465) .b8 50
(EngineCore_DP0 pid=470465) .b8 95
(EngineCore_DP0 pid=470465) .b8 99
(EngineCore_DP0 pid=470465) .b8 117
(EngineCore_DP0 pid=470465) .b8 49
(EngineCore_DP0 pid=470465) .b8 50
(EngineCore_DP0 pid=470465) .b8 57
(EngineCore_DP0 pid=470465) .b8 95
(EngineCore_DP0 pid=470465) .b8 97
(EngineCore_DP0 pid=470465) .b8 97
(EngineCore_DP0 pid=470465) .b8 114
(EngineCore_DP0 pid=470465) .b8 99
(EngineCore_DP0 pid=470465) .b8 104
(EngineCore_DP0 pid=470465) .b8 54
(EngineCore_DP0 pid=470465) .b8 52
(EngineCore_DP0 pid=470465) .b8 0
(EngineCore_DP0 pid=470465) .b8 2                                   // Abbrev [2] 0x98:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=470465) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=470465) .b8 113
(EngineCore_DP0 pid=470465) .b8 117
(EngineCore_DP0 pid=470465) .b8 97
(EngineCore_DP0 pid=470465) .b8 110
(EngineCore_DP0 pid=470465) .b8 116
(EngineCore_DP0 pid=470465) .b8 95
(EngineCore_DP0 pid=470465) .b8 115
(EngineCore_DP0 pid=470465) .b8 108
(EngineCore_DP0 pid=470465) .b8 105
(EngineCore_DP0 pid=470465) .b8 100
(EngineCore_DP0 pid=470465) .b8 101
(EngineCore_DP0 pid=470465) .b8 95
(EngineCore_DP0 pid=470465) .b8 102
(EngineCore_DP0 pid=470465) .b8 112
(EngineCore_DP0 pid=470465) .b8 56
(EngineCore_DP0 pid=470465) .b8 95
(EngineCore_DP0 pid=470465) .b8 107
(EngineCore_DP0 pid=470465) .b8 101
(EngineCore_DP0 pid=470465) .b8 114
(EngineCore_DP0 pid=470465) .b8 110
(EngineCore_DP0 pid=470465) .b8 101
(EngineCore_DP0 pid=470465) .b8 108
(EngineCore_DP0 pid=470465) .b8 0
(EngineCore_DP0 pid=470465) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=470465) .b8 3                                   // Abbrev [3] 0xb2:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=470465) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=470465) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=470465) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=470465) .b8 4                                   // Abbrev [4] 0xc7:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=470465) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=470465) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=470465) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=470465) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=470465) .b8 157                                 // DW_AT_call_line
(EngineCore_DP0 pid=470465) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=470465) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=470465) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=470465) 	}
(EngineCore_DP0 pid=470465) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=470465) 
(EngineCore_DP0 pid=470465) ================================================================
(EngineCore_DP0 pid=470465) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=470465) 
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpn74nvl1d.ptx', '-o', '/tmp/tmpn74nvl1d.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866] 
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866] 
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866] 
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpn74nvl1d.ptx -o /tmp/tmpn74nvl1d.ptx.o
(EngineCore_DP0 pid=470465) ERROR 01-25 21:21:36 [core.py:866] 

STDERR:
[2026-01-25 21:20:48] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:20:48] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:20:48] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:20:48] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:20:48] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:20:48] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:20:48] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:20:48] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:20:48] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:20:48] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:20:48] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:20:48] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:20:48] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:20:48] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:20:52] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:20:52] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:20:52] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:20:52] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:20:52] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:20:52] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:20:52] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:20:52] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:20:52] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:20:52] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:20:52] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:20:52] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:20:52] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:20:52] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=470465) [2026-01-25 21:20:53] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=470465) [2026-01-25 21:20:53] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=470465) [2026-01-25 21:20:53] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=470465) [2026-01-25 21:20:53] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=470465) [2026-01-25 21:20:53] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=470465) [2026-01-25 21:20:53] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=470465) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=470465) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:20<00:20, 20.63s/it]
(EngineCore_DP0 pid=470465) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:41<00:00, 20.52s/it]
(EngineCore_DP0 pid=470465) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:41<00:00, 20.53s/it]
(EngineCore_DP0 pid=470465) 
(EngineCore_DP0 pid=470465) [2026-01-25 21:21:35] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=470465) [2026-01-25 21:21:35] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10321920 bytes
(EngineCore_DP0 pid=470465) [2026-01-25 21:21:35] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=470465) [2026-01-25 21:21:35] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8028160 bytes
(EngineCore_DP0 pid=470465) [2026-01-25 21:21:35] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=470465) [2026-01-25 21:21:35] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 84869120 bytes
(EngineCore_DP0 pid=470465) [2026-01-25 21:21:35] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=470465) [2026-01-25 21:21:35] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 42434560 bytes
(EngineCore_DP0 pid=470465) Process EngineCore_DP0:
(EngineCore_DP0 pid=470465) Traceback (most recent call last):
(EngineCore_DP0 pid=470465)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=470465)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=470465)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=470465)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=470465) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpn74nvl1d.ptx', '-o', '/tmp/tmpn74nvl1d.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=470465) 
(EngineCore_DP0 pid=470465) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=470465) 
(EngineCore_DP0 pid=470465) Traceback (most recent call last):
(EngineCore_DP0 pid=470465)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=470465)     self.run()
(EngineCore_DP0 pid=470465)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=470465)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=470465)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=470465)     raise e
(EngineCore_DP0 pid=470465)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=470465)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=470465)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=470465)     super().__init__(
(EngineCore_DP0 pid=470465)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=470465)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=470465)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=470465)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=470465)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=470465)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=470465)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=470465)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=470465)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=470465)     return func(*args, **kwargs)
(EngineCore_DP0 pid=470465)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=470465)     return func(*args, **kwargs)
(EngineCore_DP0 pid=470465)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=470465)     self.model_runner.profile_run()
(EngineCore_DP0 pid=470465)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=470465)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=470465)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=470465)     return func(*args, **kwargs)
(EngineCore_DP0 pid=470465)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=470465)     outputs = self.model(
(EngineCore_DP0 pid=470465)               ^^^^^^^^^^^
(EngineCore_DP0 pid=470465)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=470465)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=470465)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=470465)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=470465)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=470465)     hidden_states = self.model(
(EngineCore_DP0 pid=470465)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=470465)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=470465)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=470465)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=470465)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=470465)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=470465)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=470465)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=470465)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=470465)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=470465)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=470465)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=470465)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=470465)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=470465)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=470465)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=470465)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=470465)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=470465)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=470465)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=470465)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=470465)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=470465)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=470465)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=470465)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=470465)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=470465)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=470465)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=470465)     return self._linear_fn(
(EngineCore_DP0 pid=470465)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=470465)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=470465)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=470465)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=470465)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=470465)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=470465)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=470465)     return fn(input, L)
(EngineCore_DP0 pid=470465)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=470465)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=470465)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=470465)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=470465)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=470465)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=470465)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=470465)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=470465)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=470465)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=470465)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=470465)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=470465)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=470465)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=470465)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=470465)     raise PTXASError(error)
(EngineCore_DP0 pid=470465) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=470465) `ptxas` stderr:
(EngineCore_DP0 pid=470465) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=470465) 
(EngineCore_DP0 pid=470465) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpn74nvl1d.ptx -o /tmp/tmpn74nvl1d.ptx.o
(EngineCore_DP0 pid=470465) 
[rank0]:[W125 21:21:36.649621598 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=8192

========== M=16384 ==========
Time: 2026-01-25 21:21:38
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Qwen2.5-7B-FP8_M16384.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:21:48 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 21:21:48 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=471486) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=471486) 
(EngineCore_DP0 pid=471486) 
(EngineCore_DP0 pid=471486) ================================================================
(EngineCore_DP0 pid=471486) Internal Triton PTX codegen error
(EngineCore_DP0 pid=471486) `ptxas` stderr:
(EngineCore_DP0 pid=471486) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=471486) 
(EngineCore_DP0 pid=471486) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp0y4k_jbe.ptx -o /tmp/tmp0y4k_jbe.ptx.o
(EngineCore_DP0 pid=471486) 
(EngineCore_DP0 pid=471486) 
(EngineCore_DP0 pid=471486) //
(EngineCore_DP0 pid=471486) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=471486) //
(EngineCore_DP0 pid=471486) 
(EngineCore_DP0 pid=471486) .version 8.7
(EngineCore_DP0 pid=471486) .target sm_121a
(EngineCore_DP0 pid=471486) .address_size 64
(EngineCore_DP0 pid=471486) 
(EngineCore_DP0 pid=471486) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=471486) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=471486)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=471486) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=471486) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=471486) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=471486) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=471486) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=471486) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=471486) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=471486) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=471486) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=471486) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=471486) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=471486) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=471486) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=471486) )
(EngineCore_DP0 pid=471486) .reqntid 512
(EngineCore_DP0 pid=471486) {
(EngineCore_DP0 pid=471486) 	.reg .pred 	%p<29>;
(EngineCore_DP0 pid=471486) 	.reg .b16 	%rs<73>;
(EngineCore_DP0 pid=471486) 	.reg .b32 	%r<143>;
(EngineCore_DP0 pid=471486) 	.reg .b64 	%rd<18>;
(EngineCore_DP0 pid=471486) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=471486) $L__func_begin0:
(EngineCore_DP0 pid=471486) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=471486) 
(EngineCore_DP0 pid=471486) // %bb.0:
(EngineCore_DP0 pid=471486) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=471486) 	ld.param.b32 	%r22, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=471486) 	ld.param.b32 	%r21, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=471486) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=471486) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=471486) $L__tmp0:
(EngineCore_DP0 pid=471486) 	.loc	1 143 24                        // quant_slide_tuned_Qwen2.5-7B.py:143:24
(EngineCore_DP0 pid=471486) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=471486) 	ld.param.b32 	%r25, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=471486) 	.loc	1 148 26                        // quant_slide_tuned_Qwen2.5-7B.py:148:26
(EngineCore_DP0 pid=471486) 	mul.lo.s32 	%r26, %r25, %r1;
(EngineCore_DP0 pid=471486) 	.loc	1 148 20                        // quant_slide_tuned_Qwen2.5-7B.py:148:20
(EngineCore_DP0 pid=471486) 	mad.wide.s32 	%rd1, %r26, 2, %rd4;
(EngineCore_DP0 pid=471486) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=471486) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=471486) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=471486) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=471486) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=471486) 	setp.lt.s32 	%p1, %r22, 1;
(EngineCore_DP0 pid=471486) 	mov.b32 	%r140, 0f2B8CBCCC;
(EngineCore_DP0 pid=471486) 	setp.eq.b32 	%p28, %r2, 0;
(EngineCore_DP0 pid=471486) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=471486) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=471486) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=471486) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=471486) 	shr.u32 	%r35, %r2, 3;
(EngineCore_DP0 pid=471486) 	and.b32 	%r36, %r35, 60;
(EngineCore_DP0 pid=471486) 	mov.b32 	%r37, global_smem;
(EngineCore_DP0 pid=471486) 	add.s32 	%r55, %r37, %r36;
(EngineCore_DP0 pid=471486) 	shl.b32 	%r38, %r2, 2;
(EngineCore_DP0 pid=471486) 	add.s32 	%r58, %r37, %r38;
(EngineCore_DP0 pid=471486) 	mov.b32 	%r43, 0;
(EngineCore_DP0 pid=471486) 	mov.b32 	%r138, 0f00000000;
(EngineCore_DP0 pid=471486) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=471486) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=471486) 	mov.b32 	%r139, %r43;
(EngineCore_DP0 pid=471486) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=471486) 	.loc	1 154 19                        // quant_slide_tuned_Qwen2.5-7B.py:154:19
(EngineCore_DP0 pid=471486) 	add.s32 	%r61, %r4, %r139;
(EngineCore_DP0 pid=471486) 	.loc	1 155 22                        // quant_slide_tuned_Qwen2.5-7B.py:155:22
(EngineCore_DP0 pid=471486) 	add.s32 	%r62, %r61, 4096;
(EngineCore_DP0 pid=471486) 	setp.lt.s32 	%p2, %r61, %r21;
(EngineCore_DP0 pid=471486) 	setp.lt.s32 	%p3, %r62, %r21;
(EngineCore_DP0 pid=471486) 	.loc	1 156 29                        // quant_slide_tuned_Qwen2.5-7B.py:156:29
(EngineCore_DP0 pid=471486) 	mad.wide.s32 	%rd6, %r61, 2, %rd1;
(EngineCore_DP0 pid=471486) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=471486) 	.loc	1 156 21                        // quant_slide_tuned_Qwen2.5-7B.py:156:21
(EngineCore_DP0 pid=471486) 	// begin inline asm
(EngineCore_DP0 pid=471486) 	mov.u32 %r39, %r43;
(EngineCore_DP0 pid=471486) 	mov.u32 %r40, %r43;
(EngineCore_DP0 pid=471486) 	mov.u32 %r41, %r43;
(EngineCore_DP0 pid=471486) 	mov.u32 %r42, %r43;
(EngineCore_DP0 pid=471486) 	@%p2 ld.global.v4.b32 { %r39, %r40, %r41, %r42 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=471486) 	// end inline asm
(EngineCore_DP0 pid=471486) 	mov.b32 	{%rs1, %rs2}, %r39;
(EngineCore_DP0 pid=471486) 	mov.b32 	{%rs3, %rs4}, %r40;
(EngineCore_DP0 pid=471486) 	mov.b32 	{%rs5, %rs6}, %r41;
(EngineCore_DP0 pid=471486) 	mov.b32 	{%rs7, %rs8}, %r42;
(EngineCore_DP0 pid=471486) 	// begin inline asm
(EngineCore_DP0 pid=471486) 	mov.u32 %r47, %r43;
(EngineCore_DP0 pid=471486) 	mov.u32 %r48, %r43;
(EngineCore_DP0 pid=471486) 	mov.u32 %r49, %r43;
(EngineCore_DP0 pid=471486) 	mov.u32 %r50, %r43;
(EngineCore_DP0 pid=471486) 	@%p3 ld.global.v4.b32 { %r47, %r48, %r49, %r50 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=471486) 	// end inline asm
(EngineCore_DP0 pid=471486) 	mov.b32 	{%rs9, %rs10}, %r47;
(EngineCore_DP0 pid=471486) 	mov.b32 	{%rs11, %rs12}, %r48;
(EngineCore_DP0 pid=471486) 	mov.b32 	{%rs13, %rs14}, %r49;
(EngineCore_DP0 pid=471486) 	mov.b32 	{%rs15, %rs16}, %r50;
(EngineCore_DP0 pid=471486) 	.loc	1 157 50                        // quant_slide_tuned_Qwen2.5-7B.py:157:50
(EngineCore_DP0 pid=471486) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=471486) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=471486) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=471486) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=471486) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=471486) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=471486) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=471486) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=471486) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=471486) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=471486) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=471486) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=471486) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=471486) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=471486) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=471486) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=471486) $L__tmp1:
(EngineCore_DP0 pid=471486) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=471486) 	bar.sync 	0;
(EngineCore_DP0 pid=471486) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=471486) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=471486) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=471486) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=471486) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=471486) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=471486) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=471486) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=471486) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=471486) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=471486) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=471486) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=471486) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=471486) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=471486) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=471486) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=471486) 	cvt.f32.bf16 	%r63, %rs47;
(EngineCore_DP0 pid=471486) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=471486) 	shfl.sync.bfly.b32 	%r64, %r63, 16, 31, -1;
(EngineCore_DP0 pid=471486) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=471486) 	max.f32 	%r65, %r63, %r64;
(EngineCore_DP0 pid=471486) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=471486) 	shfl.sync.bfly.b32 	%r66, %r65, 8, 31, -1;
(EngineCore_DP0 pid=471486) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=471486) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=471486) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=471486) 	shfl.sync.bfly.b32 	%r68, %r67, 4, 31, -1;
(EngineCore_DP0 pid=471486) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=471486) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=471486) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=471486) 	shfl.sync.bfly.b32 	%r70, %r69, 2, 31, -1;
(EngineCore_DP0 pid=471486) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=471486) 	max.f32 	%r71, %r69, %r70;
(EngineCore_DP0 pid=471486) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=471486) 	shfl.sync.bfly.b32 	%r72, %r71, 1, 31, -1;
(EngineCore_DP0 pid=471486) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=471486) 	max.f32 	%r56, %r71, %r72;
(EngineCore_DP0 pid=471486) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=471486) 	// begin inline asm
(EngineCore_DP0 pid=471486) 	@%p4 st.shared.b32 [ %r55 + 0 ], %r56;
(EngineCore_DP0 pid=471486) 	// end inline asm
(EngineCore_DP0 pid=471486) 	bar.sync 	0;
(EngineCore_DP0 pid=471486) 	// begin inline asm
(EngineCore_DP0 pid=471486) 	@%p5 ld.shared.b32 %r57, [ %r58 + 0 ];
(EngineCore_DP0 pid=471486) 	// end inline asm
(EngineCore_DP0 pid=471486) 	shfl.sync.bfly.b32 	%r73, %r57, 8, 31, -1;
(EngineCore_DP0 pid=471486) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=471486) 	max.f32 	%r74, %r57, %r73;
(EngineCore_DP0 pid=471486) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=471486) 	shfl.sync.bfly.b32 	%r75, %r74, 4, 31, -1;
(EngineCore_DP0 pid=471486) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=471486) 	max.f32 	%r76, %r74, %r75;
(EngineCore_DP0 pid=471486) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=471486) 	shfl.sync.bfly.b32 	%r77, %r76, 2, 31, -1;
(EngineCore_DP0 pid=471486) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=471486) 	max.f32 	%r78, %r76, %r77;
(EngineCore_DP0 pid=471486) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=471486) 	shfl.sync.bfly.b32 	%r79, %r78, 1, 31, -1;
(EngineCore_DP0 pid=471486) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=471486) 	max.f32 	%r60, %r78, %r79;
(EngineCore_DP0 pid=471486) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=471486) 	// begin inline asm
(EngineCore_DP0 pid=471486) 	@%p28 st.shared.b32 [ %r58 + 0 ], %r60;
(EngineCore_DP0 pid=471486) 	// end inline asm
(EngineCore_DP0 pid=471486) 	bar.sync 	0;
(EngineCore_DP0 pid=471486) 	ld.shared.b32 	%r80, [global_smem];
(EngineCore_DP0 pid=471486) $L__tmp2:
(EngineCore_DP0 pid=471486) 	.loc	1 157 36                        // quant_slide_tuned_Qwen2.5-7B.py:157:36
(EngineCore_DP0 pid=471486) 	max.f32 	%r138, %r138, %r80;
(EngineCore_DP0 pid=471486) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=471486) 	add.s32 	%r139, %r139, 8192;
(EngineCore_DP0 pid=471486) 	setp.lt.s32 	%p7, %r139, %r22;
(EngineCore_DP0 pid=471486) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=471486) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=471486) 	.loc	1 159 32                        // quant_slide_tuned_Qwen2.5-7B.py:159:32
(EngineCore_DP0 pid=471486) 	max.f32 	%r140, %r138, 0f2B8CBCCC;
(EngineCore_DP0 pid=471486) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=471486) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-7B.py:0:32
(EngineCore_DP0 pid=471486) 	mov.b32 	%r82, 0f43E00000;
(EngineCore_DP0 pid=471486) 	.loc	1 160 32                        // quant_slide_tuned_Qwen2.5-7B.py:160:32
(EngineCore_DP0 pid=471486) 	div.full.f32 	%r83, %r140, %r82;
(EngineCore_DP0 pid=471486) 	.loc	1 160 41                        // quant_slide_tuned_Qwen2.5-7B.py:160:41
(EngineCore_DP0 pid=471486) 	max.f32 	%r81, %r83, 0f36924925;
(EngineCore_DP0 pid=471486) 	.loc	1 162 25                        // quant_slide_tuned_Qwen2.5-7B.py:162:25
(EngineCore_DP0 pid=471486) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=471486) 	.loc	1 162 30                        // quant_slide_tuned_Qwen2.5-7B.py:162:30
(EngineCore_DP0 pid=471486) 	// begin inline asm
(EngineCore_DP0 pid=471486) 	@%p28 st.global.b32 [ %rd8 + 0 ], { %r81 };
(EngineCore_DP0 pid=471486) 	// end inline asm
(EngineCore_DP0 pid=471486) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=471486) 	setp.lt.s32 	%p9, %r23, 1;
(EngineCore_DP0 pid=471486) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=471486) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=471486) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-7B.py:0:41
(EngineCore_DP0 pid=471486) 	ld.param.b32 	%r27, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=471486) 	shr.s32 	%r28, %r27, 31;
(EngineCore_DP0 pid=471486) 	shr.u32 	%r29, %r28, 30;
(EngineCore_DP0 pid=471486) 	add.s32 	%r30, %r27, %r29;
(EngineCore_DP0 pid=471486) 	shr.s32 	%r31, %r30, 2;
(EngineCore_DP0 pid=471486) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=471486) 	mul.lo.s32 	%r32, %r31, %r1;
(EngineCore_DP0 pid=471486) 	mad.wide.s32 	%rd2, %r32, 4, %rd5;
(EngineCore_DP0 pid=471486) 	div.full.f32 	%r14, %r82, %r140;
(EngineCore_DP0 pid=471486) 	shl.b32 	%r15, %r3, 1;
(EngineCore_DP0 pid=471486) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=471486) 	add.s32 	%r141, %r4, 7;
(EngineCore_DP0 pid=471486) 	mov.b32 	%r142, 0;
(EngineCore_DP0 pid=471486) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=471486)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=471486) 	.loc	1 169 30                        // quant_slide_tuned_Qwen2.5-7B.py:169:30
(EngineCore_DP0 pid=471486) 	add.s32 	%r95, %r15, %r142;
(EngineCore_DP0 pid=471486) 	setp.lt.s32 	%p18, %r95, %r23;
(EngineCore_DP0 pid=471486) 	.loc	1 174 22                        // quant_slide_tuned_Qwen2.5-7B.py:174:22
(EngineCore_DP0 pid=471486) 	add.s32 	%r96, %r141, -7;
(EngineCore_DP0 pid=471486) 	.loc	1 177 53                        // quant_slide_tuned_Qwen2.5-7B.py:177:53
(EngineCore_DP0 pid=471486) 	add.s32 	%r97, %r141, -3;
(EngineCore_DP0 pid=471486) 	setp.lt.s32 	%p19, %r96, %r21;
(EngineCore_DP0 pid=471486) 	setp.lt.s32 	%p20, %r97, %r21;
(EngineCore_DP0 pid=471486) 	.loc	1 177 37                        // quant_slide_tuned_Qwen2.5-7B.py:177:37
(EngineCore_DP0 pid=471486) 	and.pred 	%p10, %p18, %p19;
(EngineCore_DP0 pid=471486) 	and.pred 	%p11, %p18, %p20;
(EngineCore_DP0 pid=471486) 	.loc	1 176 29                        // quant_slide_tuned_Qwen2.5-7B.py:176:29
(EngineCore_DP0 pid=471486) 	mad.wide.s32 	%rd9, %r96, 2, %rd1;
(EngineCore_DP0 pid=471486) 	add.s64 	%rd10, %rd9, 8;
(EngineCore_DP0 pid=471486) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=471486) 	.loc	1 176 21                        // quant_slide_tuned_Qwen2.5-7B.py:176:21
(EngineCore_DP0 pid=471486) 	// begin inline asm
(EngineCore_DP0 pid=471486) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=471486) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=471486) 	// end inline asm
(EngineCore_DP0 pid=471486) 	// begin inline asm
(EngineCore_DP0 pid=471486) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=471486) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=471486) 	// end inline asm
(EngineCore_DP0 pid=471486) 	.loc	1 177 79                        // quant_slide_tuned_Qwen2.5-7B.py:177:79
(EngineCore_DP0 pid=471486) 	cvt.f32.bf16 	%r98, %rs48;
(EngineCore_DP0 pid=471486) 	cvt.f32.bf16 	%r99, %rs50;
(EngineCore_DP0 pid=471486) 	.loc	1 179 48                        // quant_slide_tuned_Qwen2.5-7B.py:179:48
(EngineCore_DP0 pid=471486) 	add.s32 	%r100, %r141, -6;
(EngineCore_DP0 pid=471486) 	.loc	1 179 53                        // quant_slide_tuned_Qwen2.5-7B.py:179:53
(EngineCore_DP0 pid=471486) 	add.s32 	%r101, %r141, -2;
(EngineCore_DP0 pid=471486) 	setp.lt.s32 	%p21, %r100, %r21;
(EngineCore_DP0 pid=471486) 	setp.lt.s32 	%p22, %r101, %r21;
(EngineCore_DP0 pid=471486) 	.loc	1 179 37                        // quant_slide_tuned_Qwen2.5-7B.py:179:37
(EngineCore_DP0 pid=471486) 	and.pred 	%p12, %p18, %p21;
(EngineCore_DP0 pid=471486) 	and.pred 	%p13, %p18, %p22;
(EngineCore_DP0 pid=471486) 	.loc	1 178 39                        // quant_slide_tuned_Qwen2.5-7B.py:178:39
(EngineCore_DP0 pid=471486) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=471486) 	add.s64 	%rd12, %rd9, 10;
(EngineCore_DP0 pid=471486) 	.loc	1 178 21                        // quant_slide_tuned_Qwen2.5-7B.py:178:21
(EngineCore_DP0 pid=471486) 	// begin inline asm
(EngineCore_DP0 pid=471486) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=471486) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=471486) 	// end inline asm
(EngineCore_DP0 pid=471486) 	// begin inline asm
(EngineCore_DP0 pid=471486) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=471486) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=471486) 	// end inline asm
(EngineCore_DP0 pid=471486) 	.loc	1 179 79                        // quant_slide_tuned_Qwen2.5-7B.py:179:79
(EngineCore_DP0 pid=471486) 	cvt.f32.bf16 	%r102, %rs52;
(EngineCore_DP0 pid=471486) 	cvt.f32.bf16 	%r103, %rs54;
(EngineCore_DP0 pid=471486) 	.loc	1 181 48                        // quant_slide_tuned_Qwen2.5-7B.py:181:48
(EngineCore_DP0 pid=471486) 	add.s32 	%r104, %r141, -5;
(EngineCore_DP0 pid=471486) 	.loc	1 181 53                        // quant_slide_tuned_Qwen2.5-7B.py:181:53
(EngineCore_DP0 pid=471486) 	add.s32 	%r105, %r141, -1;
(EngineCore_DP0 pid=471486) 	setp.lt.s32 	%p23, %r104, %r21;
(EngineCore_DP0 pid=471486) 	setp.lt.s32 	%p24, %r105, %r21;
(EngineCore_DP0 pid=471486) 	.loc	1 181 37                        // quant_slide_tuned_Qwen2.5-7B.py:181:37
(EngineCore_DP0 pid=471486) 	and.pred 	%p14, %p18, %p23;
(EngineCore_DP0 pid=471486) 	and.pred 	%p15, %p18, %p24;
(EngineCore_DP0 pid=471486) 	.loc	1 180 39                        // quant_slide_tuned_Qwen2.5-7B.py:180:39
(EngineCore_DP0 pid=471486) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=471486) 	add.s64 	%rd14, %rd9, 12;
(EngineCore_DP0 pid=471486) 	.loc	1 180 21                        // quant_slide_tuned_Qwen2.5-7B.py:180:21
(EngineCore_DP0 pid=471486) 	// begin inline asm
(EngineCore_DP0 pid=471486) 	mov.u16 %rs56, %rs49;
(EngineCore_DP0 pid=471486) 	@%p14 ld.global.b16 { %rs56 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=471486) 	// end inline asm
(EngineCore_DP0 pid=471486) 	// begin inline asm
(EngineCore_DP0 pid=471486) 	mov.u16 %rs58, %rs49;
(EngineCore_DP0 pid=471486) 	@%p15 ld.global.b16 { %rs58 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=471486) 	// end inline asm
(EngineCore_DP0 pid=471486) 	.loc	1 181 79                        // quant_slide_tuned_Qwen2.5-7B.py:181:79
(EngineCore_DP0 pid=471486) 	cvt.f32.bf16 	%r106, %rs56;
(EngineCore_DP0 pid=471486) 	cvt.f32.bf16 	%r107, %rs58;
(EngineCore_DP0 pid=471486) 	.loc	1 183 48                        // quant_slide_tuned_Qwen2.5-7B.py:183:48
(EngineCore_DP0 pid=471486) 	add.s32 	%r108, %r141, -4;
(EngineCore_DP0 pid=471486) 	.loc	1 183 53                        // quant_slide_tuned_Qwen2.5-7B.py:183:53
(EngineCore_DP0 pid=471486) 	setp.lt.s32 	%p25, %r108, %r21;
(EngineCore_DP0 pid=471486) 	setp.lt.s32 	%p26, %r141, %r21;
(EngineCore_DP0 pid=471486) 	.loc	1 183 37                        // quant_slide_tuned_Qwen2.5-7B.py:183:37
(EngineCore_DP0 pid=471486) 	and.pred 	%p16, %p18, %p25;
(EngineCore_DP0 pid=471486) 	and.pred 	%p17, %p18, %p26;
(EngineCore_DP0 pid=471486) 	.loc	1 182 39                        // quant_slide_tuned_Qwen2.5-7B.py:182:39
(EngineCore_DP0 pid=471486) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=471486) 	add.s64 	%rd16, %rd9, 14;
(EngineCore_DP0 pid=471486) 	.loc	1 182 21                        // quant_slide_tuned_Qwen2.5-7B.py:182:21
(EngineCore_DP0 pid=471486) 	// begin inline asm
(EngineCore_DP0 pid=471486) 	mov.u16 %rs60, %rs49;
(EngineCore_DP0 pid=471486) 	@%p16 ld.global.b16 { %rs60 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=471486) 	// end inline asm
(EngineCore_DP0 pid=471486) 	// begin inline asm
(EngineCore_DP0 pid=471486) 	mov.u16 %rs62, %rs49;
(EngineCore_DP0 pid=471486) 	@%p17 ld.global.b16 { %rs62 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=471486) 	// end inline asm
(EngineCore_DP0 pid=471486) 	.loc	1 183 79                        // quant_slide_tuned_Qwen2.5-7B.py:183:79
(EngineCore_DP0 pid=471486) 	cvt.f32.bf16 	%r109, %rs60;
(EngineCore_DP0 pid=471486) 	cvt.f32.bf16 	%r110, %rs62;
(EngineCore_DP0 pid=471486) 	.loc	1 185 27                        // quant_slide_tuned_Qwen2.5-7B.py:185:27
(EngineCore_DP0 pid=471486) 	mul.f32 	%r111, %r14, %r98;
(EngineCore_DP0 pid=471486) 	mul.f32 	%r112, %r14, %r99;
(EngineCore_DP0 pid=471486) 	mov.b32 	%r113, 0f43E00000;
(EngineCore_DP0 pid=471486) 	.loc	1 185 48                        // quant_slide_tuned_Qwen2.5-7B.py:185:48
(EngineCore_DP0 pid=471486) 	min.xorsign.abs.f32 	%r85, %r111, %r113;
(EngineCore_DP0 pid=471486) 	min.xorsign.abs.f32 	%r86, %r112, %r113;
(EngineCore_DP0 pid=471486) 	.loc	1 185 60                        // quant_slide_tuned_Qwen2.5-7B.py:185:60
(EngineCore_DP0 pid=471486) 	// begin inline asm
(EngineCore_DP0 pid=471486) 	cvt.rn.satfinite.e4m3x2.f32  %rs64, %r86, %r85; 
(EngineCore_DP0 pid=471486) 
(EngineCore_DP0 pid=471486) 	// end inline asm
(EngineCore_DP0 pid=471486) 	shr.u16 	%rs68, %rs64, 8;
(EngineCore_DP0 pid=471486) 	.loc	1 186 27                        // quant_slide_tuned_Qwen2.5-7B.py:186:27
(EngineCore_DP0 pid=471486) 	mul.f32 	%r114, %r14, %r102;
(EngineCore_DP0 pid=471486) 	mul.f32 	%r115, %r14, %r103;
(EngineCore_DP0 pid=471486) 	.loc	1 186 48                        // quant_slide_tuned_Qwen2.5-7B.py:186:48
(EngineCore_DP0 pid=471486) 	min.xorsign.abs.f32 	%r87, %r114, %r113;
(EngineCore_DP0 pid=471486) 	min.xorsign.abs.f32 	%r88, %r115, %r113;
(EngineCore_DP0 pid=471486) 	.loc	1 186 60                        // quant_slide_tuned_Qwen2.5-7B.py:186:60
(EngineCore_DP0 pid=471486) 	// begin inline asm
(EngineCore_DP0 pid=471486) 	cvt.rn.satfinite.e4m3x2.f32  %rs65, %r88, %r87; 
(EngineCore_DP0 pid=471486) 
(EngineCore_DP0 pid=471486) 	// end inline asm
(EngineCore_DP0 pid=471486) 	shr.u16 	%rs69, %rs65, 8;
(EngineCore_DP0 pid=471486) 	.loc	1 187 27                        // quant_slide_tuned_Qwen2.5-7B.py:187:27
(EngineCore_DP0 pid=471486) 	mul.f32 	%r116, %r14, %r106;
(EngineCore_DP0 pid=471486) 	mul.f32 	%r117, %r14, %r107;
(EngineCore_DP0 pid=471486) 	.loc	1 187 48                        // quant_slide_tuned_Qwen2.5-7B.py:187:48
(EngineCore_DP0 pid=471486) 	min.xorsign.abs.f32 	%r89, %r116, %r113;
(EngineCore_DP0 pid=471486) 	min.xorsign.abs.f32 	%r90, %r117, %r113;
(EngineCore_DP0 pid=471486) 	.loc	1 187 60                        // quant_slide_tuned_Qwen2.5-7B.py:187:60
(EngineCore_DP0 pid=471486) 	// begin inline asm
(EngineCore_DP0 pid=471486) 	cvt.rn.satfinite.e4m3x2.f32  %rs66, %r90, %r89; 
(EngineCore_DP0 pid=471486) 
(EngineCore_DP0 pid=471486) 	// end inline asm
(EngineCore_DP0 pid=471486) 	shr.u16 	%rs70, %rs66, 8;
(EngineCore_DP0 pid=471486) 	.loc	1 188 27                        // quant_slide_tuned_Qwen2.5-7B.py:188:27
(EngineCore_DP0 pid=471486) 	mul.f32 	%r118, %r14, %r109;
(EngineCore_DP0 pid=471486) 	mul.f32 	%r119, %r14, %r110;
(EngineCore_DP0 pid=471486) 	.loc	1 188 48                        // quant_slide_tuned_Qwen2.5-7B.py:188:48
(EngineCore_DP0 pid=471486) 	min.xorsign.abs.f32 	%r91, %r118, %r113;
(EngineCore_DP0 pid=471486) 	min.xorsign.abs.f32 	%r92, %r119, %r113;
(EngineCore_DP0 pid=471486) 	.loc	1 188 60                        // quant_slide_tuned_Qwen2.5-7B.py:188:60
(EngineCore_DP0 pid=471486) 	// begin inline asm
(EngineCore_DP0 pid=471486) 	cvt.rn.satfinite.e4m3x2.f32  %rs67, %r92, %r91; 
(EngineCore_DP0 pid=471486) 
(EngineCore_DP0 pid=471486) 	// end inline asm
(EngineCore_DP0 pid=471486) 	shr.u16 	%rs71, %rs67, 8;
(EngineCore_DP0 pid=471486) 	.loc	1 190 45                        // quant_slide_tuned_Qwen2.5-7B.py:190:45
(EngineCore_DP0 pid=471486) 	cvt.u32.u16 	%r120, %rs64;
(EngineCore_DP0 pid=471486) 	and.b32 	%r121, %r120, 255;
(EngineCore_DP0 pid=471486) 	cvt.u32.u16 	%r122, %rs68;
(EngineCore_DP0 pid=471486) 	.loc	1 192 45                        // quant_slide_tuned_Qwen2.5-7B.py:192:45
(EngineCore_DP0 pid=471486) 	cvt.u32.u16 	%r123, %rs66;
(EngineCore_DP0 pid=471486) 	and.b32 	%r124, %r123, 255;
(EngineCore_DP0 pid=471486) 	cvt.u32.u16 	%r125, %rs70;
(EngineCore_DP0 pid=471486) 	.loc	1 193 45                        // quant_slide_tuned_Qwen2.5-7B.py:193:45
(EngineCore_DP0 pid=471486) 	cvt.u32.u16 	%r126, %rs67;
(EngineCore_DP0 pid=471486) 	cvt.u32.u16 	%r127, %rs71;
(EngineCore_DP0 pid=471486) 	.loc	1 195 30                        // quant_slide_tuned_Qwen2.5-7B.py:195:30
(EngineCore_DP0 pid=471486) 	and.b16 	%rs72, %rs65, 255;
(EngineCore_DP0 pid=471486) 	mul.wide.u16 	%r128, %rs72, 256;
(EngineCore_DP0 pid=471486) 	mul.wide.u16 	%r129, %rs69, 256;
(EngineCore_DP0 pid=471486) 	.loc	1 195 24                        // quant_slide_tuned_Qwen2.5-7B.py:195:24
(EngineCore_DP0 pid=471486) 	or.b32 	%r130, %r128, %r121;
(EngineCore_DP0 pid=471486) 	or.b32 	%r131, %r129, %r122;
(EngineCore_DP0 pid=471486) 	.loc	1 195 42                        // quant_slide_tuned_Qwen2.5-7B.py:195:42
(EngineCore_DP0 pid=471486) 	shl.b32 	%r132, %r124, 16;
(EngineCore_DP0 pid=471486) 	shl.b32 	%r133, %r125, 16;
(EngineCore_DP0 pid=471486) 	.loc	1 195 36                        // quant_slide_tuned_Qwen2.5-7B.py:195:36
(EngineCore_DP0 pid=471486) 	or.b32 	%r134, %r130, %r132;
(EngineCore_DP0 pid=471486) 	or.b32 	%r135, %r131, %r133;
(EngineCore_DP0 pid=471486) 	.loc	1 195 55                        // quant_slide_tuned_Qwen2.5-7B.py:195:55
(EngineCore_DP0 pid=471486) 	shl.b32 	%r136, %r126, 24;
(EngineCore_DP0 pid=471486) 	shl.b32 	%r137, %r127, 24;
(EngineCore_DP0 pid=471486) 	.loc	1 195 49                        // quant_slide_tuned_Qwen2.5-7B.py:195:49
(EngineCore_DP0 pid=471486) 	or.b32 	%r93, %r134, %r136;
(EngineCore_DP0 pid=471486) 	or.b32 	%r94, %r135, %r137;
(EngineCore_DP0 pid=471486) 	.loc	1 196 29                        // quant_slide_tuned_Qwen2.5-7B.py:196:29
(EngineCore_DP0 pid=471486) 	mad.wide.s32 	%rd17, %r95, 4, %rd2;
(EngineCore_DP0 pid=471486) 	.loc	1 196 39                        // quant_slide_tuned_Qwen2.5-7B.py:196:39
(EngineCore_DP0 pid=471486) 	// begin inline asm
(EngineCore_DP0 pid=471486) 	@%p18 st.global.v2.b32 [ %rd17 + 0 ], { %r93, %r94 };
(EngineCore_DP0 pid=471486) 	// end inline asm
(EngineCore_DP0 pid=471486) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=471486) 	add.s32 	%r142, %r142, 1024;
(EngineCore_DP0 pid=471486) 	add.s32 	%r141, %r141, 4096;
(EngineCore_DP0 pid=471486) 	setp.lt.s32 	%p27, %r142, %r23;
(EngineCore_DP0 pid=471486) 	@%p27 bra 	$L__BB0_6;
(EngineCore_DP0 pid=471486) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=471486) 	.loc	1 167 4                         // quant_slide_tuned_Qwen2.5-7B.py:167:4
(EngineCore_DP0 pid=471486) 	ret;
(EngineCore_DP0 pid=471486) $L__tmp3:
(EngineCore_DP0 pid=471486) $L__func_end0:
(EngineCore_DP0 pid=471486)                                         // -- End function
(EngineCore_DP0 pid=471486) }
(EngineCore_DP0 pid=471486) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py"
(EngineCore_DP0 pid=471486) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=471486) 	.section	.debug_abbrev
(EngineCore_DP0 pid=471486) 	{
(EngineCore_DP0 pid=471486) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=471486) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=471486) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=471486) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=471486) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=471486) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=471486) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=471486) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=471486) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=471486) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=471486) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=471486) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=471486) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=471486) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=471486) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=471486) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=471486) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=471486) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=471486) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=471486) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=471486) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=471486) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=471486) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=471486) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=471486) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=471486) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=471486) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=471486) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=471486) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=471486) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=471486) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=471486) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=471486) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=471486) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=471486) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=471486) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=471486) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=471486) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=471486) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=471486) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=471486) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=471486) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=471486) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=471486) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=471486) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=471486) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=471486) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=471486) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=471486) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=471486) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=471486) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=471486) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=471486) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=471486) 	}
(EngineCore_DP0 pid=471486) 	.section	.debug_info
(EngineCore_DP0 pid=471486) 	{
(EngineCore_DP0 pid=471486) .b32 221                                // Length of Unit
(EngineCore_DP0 pid=471486) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=471486) .b8 0
(EngineCore_DP0 pid=471486) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=471486) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=471486) .b8 1                                   // Abbrev [1] 0xb:0xd6 DW_TAG_compile_unit
(EngineCore_DP0 pid=471486) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=471486) .b8 114
(EngineCore_DP0 pid=471486) .b8 105
(EngineCore_DP0 pid=471486) .b8 116
(EngineCore_DP0 pid=471486) .b8 111
(EngineCore_DP0 pid=471486) .b8 110
(EngineCore_DP0 pid=471486) .b8 0
(EngineCore_DP0 pid=471486) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=471486) .b8 0
(EngineCore_DP0 pid=471486) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=471486) .b8 117
(EngineCore_DP0 pid=471486) .b8 97
(EngineCore_DP0 pid=471486) .b8 110
(EngineCore_DP0 pid=471486) .b8 116
(EngineCore_DP0 pid=471486) .b8 95
(EngineCore_DP0 pid=471486) .b8 115
(EngineCore_DP0 pid=471486) .b8 108
(EngineCore_DP0 pid=471486) .b8 105
(EngineCore_DP0 pid=471486) .b8 100
(EngineCore_DP0 pid=471486) .b8 101
(EngineCore_DP0 pid=471486) .b8 95
(EngineCore_DP0 pid=471486) .b8 116
(EngineCore_DP0 pid=471486) .b8 117
(EngineCore_DP0 pid=471486) .b8 110
(EngineCore_DP0 pid=471486) .b8 101
(EngineCore_DP0 pid=471486) .b8 100
(EngineCore_DP0 pid=471486) .b8 95
(EngineCore_DP0 pid=471486) .b8 81
(EngineCore_DP0 pid=471486) .b8 119
(EngineCore_DP0 pid=471486) .b8 101
(EngineCore_DP0 pid=471486) .b8 110
(EngineCore_DP0 pid=471486) .b8 50
(EngineCore_DP0 pid=471486) .b8 46
(EngineCore_DP0 pid=471486) .b8 53
(EngineCore_DP0 pid=471486) .b8 45
(EngineCore_DP0 pid=471486) .b8 55
(EngineCore_DP0 pid=471486) .b8 66
(EngineCore_DP0 pid=471486) .b8 46
(EngineCore_DP0 pid=471486) .b8 112
(EngineCore_DP0 pid=471486) .b8 121
(EngineCore_DP0 pid=471486) .b8 0
(EngineCore_DP0 pid=471486) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=471486) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=471486) .b8 114
(EngineCore_DP0 pid=471486) .b8 111
(EngineCore_DP0 pid=471486) .b8 111
(EngineCore_DP0 pid=471486) .b8 116
(EngineCore_DP0 pid=471486) .b8 47
(EngineCore_DP0 pid=471486) .b8 118
(EngineCore_DP0 pid=471486) .b8 108
(EngineCore_DP0 pid=471486) .b8 108
(EngineCore_DP0 pid=471486) .b8 109
(EngineCore_DP0 pid=471486) .b8 98
(EngineCore_DP0 pid=471486) .b8 101
(EngineCore_DP0 pid=471486) .b8 110
(EngineCore_DP0 pid=471486) .b8 99
(EngineCore_DP0 pid=471486) .b8 104
(EngineCore_DP0 pid=471486) .b8 47
(EngineCore_DP0 pid=471486) .b8 115
(EngineCore_DP0 pid=471486) .b8 108
(EngineCore_DP0 pid=471486) .b8 105
(EngineCore_DP0 pid=471486) .b8 100
(EngineCore_DP0 pid=471486) .b8 101
(EngineCore_DP0 pid=471486) .b8 115
(EngineCore_DP0 pid=471486) .b8 112
(EngineCore_DP0 pid=471486) .b8 97
(EngineCore_DP0 pid=471486) .b8 114
(EngineCore_DP0 pid=471486) .b8 115
(EngineCore_DP0 pid=471486) .b8 101
(EngineCore_DP0 pid=471486) .b8 47
(EngineCore_DP0 pid=471486) .b8 99
(EngineCore_DP0 pid=471486) .b8 115
(EngineCore_DP0 pid=471486) .b8 114
(EngineCore_DP0 pid=471486) .b8 99
(EngineCore_DP0 pid=471486) .b8 47
(EngineCore_DP0 pid=471486) .b8 102
(EngineCore_DP0 pid=471486) .b8 117
(EngineCore_DP0 pid=471486) .b8 115
(EngineCore_DP0 pid=471486) .b8 101
(EngineCore_DP0 pid=471486) .b8 100
(EngineCore_DP0 pid=471486) .b8 95
(EngineCore_DP0 pid=471486) .b8 113
(EngineCore_DP0 pid=471486) .b8 117
(EngineCore_DP0 pid=471486) .b8 97
(EngineCore_DP0 pid=471486) .b8 110
(EngineCore_DP0 pid=471486) .b8 116
(EngineCore_DP0 pid=471486) .b8 95
(EngineCore_DP0 pid=471486) .b8 115
(EngineCore_DP0 pid=471486) .b8 108
(EngineCore_DP0 pid=471486) .b8 105
(EngineCore_DP0 pid=471486) .b8 100
(EngineCore_DP0 pid=471486) .b8 101
(EngineCore_DP0 pid=471486) .b8 95
(EngineCore_DP0 pid=471486) .b8 116
(EngineCore_DP0 pid=471486) .b8 114
(EngineCore_DP0 pid=471486) .b8 105
(EngineCore_DP0 pid=471486) .b8 116
(EngineCore_DP0 pid=471486) .b8 111
(EngineCore_DP0 pid=471486) .b8 110
(EngineCore_DP0 pid=471486) .b8 47
(EngineCore_DP0 pid=471486) .b8 98
(EngineCore_DP0 pid=471486) .b8 117
(EngineCore_DP0 pid=471486) .b8 105
(EngineCore_DP0 pid=471486) .b8 108
(EngineCore_DP0 pid=471486) .b8 100
(EngineCore_DP0 pid=471486) .b8 47
(EngineCore_DP0 pid=471486) .b8 71
(EngineCore_DP0 pid=471486) .b8 66
(EngineCore_DP0 pid=471486) .b8 49
(EngineCore_DP0 pid=471486) .b8 48
(EngineCore_DP0 pid=471486) .b8 95
(EngineCore_DP0 pid=471486) .b8 99
(EngineCore_DP0 pid=471486) .b8 99
(EngineCore_DP0 pid=471486) .b8 49
(EngineCore_DP0 pid=471486) .b8 50
(EngineCore_DP0 pid=471486) .b8 49
(EngineCore_DP0 pid=471486) .b8 95
(EngineCore_DP0 pid=471486) .b8 112
(EngineCore_DP0 pid=471486) .b8 121
(EngineCore_DP0 pid=471486) .b8 51
(EngineCore_DP0 pid=471486) .b8 49
(EngineCore_DP0 pid=471486) .b8 50
(EngineCore_DP0 pid=471486) .b8 95
(EngineCore_DP0 pid=471486) .b8 99
(EngineCore_DP0 pid=471486) .b8 117
(EngineCore_DP0 pid=471486) .b8 49
(EngineCore_DP0 pid=471486) .b8 50
(EngineCore_DP0 pid=471486) .b8 57
(EngineCore_DP0 pid=471486) .b8 95
(EngineCore_DP0 pid=471486) .b8 97
(EngineCore_DP0 pid=471486) .b8 97
(EngineCore_DP0 pid=471486) .b8 114
(EngineCore_DP0 pid=471486) .b8 99
(EngineCore_DP0 pid=471486) .b8 104
(EngineCore_DP0 pid=471486) .b8 54
(EngineCore_DP0 pid=471486) .b8 52
(EngineCore_DP0 pid=471486) .b8 0
(EngineCore_DP0 pid=471486) .b8 2                                   // Abbrev [2] 0x98:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=471486) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=471486) .b8 113
(EngineCore_DP0 pid=471486) .b8 117
(EngineCore_DP0 pid=471486) .b8 97
(EngineCore_DP0 pid=471486) .b8 110
(EngineCore_DP0 pid=471486) .b8 116
(EngineCore_DP0 pid=471486) .b8 95
(EngineCore_DP0 pid=471486) .b8 115
(EngineCore_DP0 pid=471486) .b8 108
(EngineCore_DP0 pid=471486) .b8 105
(EngineCore_DP0 pid=471486) .b8 100
(EngineCore_DP0 pid=471486) .b8 101
(EngineCore_DP0 pid=471486) .b8 95
(EngineCore_DP0 pid=471486) .b8 102
(EngineCore_DP0 pid=471486) .b8 112
(EngineCore_DP0 pid=471486) .b8 56
(EngineCore_DP0 pid=471486) .b8 95
(EngineCore_DP0 pid=471486) .b8 107
(EngineCore_DP0 pid=471486) .b8 101
(EngineCore_DP0 pid=471486) .b8 114
(EngineCore_DP0 pid=471486) .b8 110
(EngineCore_DP0 pid=471486) .b8 101
(EngineCore_DP0 pid=471486) .b8 108
(EngineCore_DP0 pid=471486) .b8 0
(EngineCore_DP0 pid=471486) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=471486) .b8 3                                   // Abbrev [3] 0xb2:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=471486) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=471486) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=471486) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=471486) .b8 4                                   // Abbrev [4] 0xc7:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=471486) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=471486) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=471486) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=471486) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=471486) .b8 157                                 // DW_AT_call_line
(EngineCore_DP0 pid=471486) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=471486) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=471486) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=471486) 	}
(EngineCore_DP0 pid=471486) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=471486) 
(EngineCore_DP0 pid=471486) ================================================================
(EngineCore_DP0 pid=471486) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=471486) 
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp0y4k_jbe.ptx', '-o', '/tmp/tmp0y4k_jbe.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866] 
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866] 
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866] 
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp0y4k_jbe.ptx -o /tmp/tmp0y4k_jbe.ptx.o
(EngineCore_DP0 pid=471486) ERROR 01-25 21:22:35 [core.py:866] 

STDERR:
[2026-01-25 21:21:48] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:21:48] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:21:48] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:21:48] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:21:48] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:21:48] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:21:48] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:21:48] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:21:48] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:21:48] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:21:48] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:21:48] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:21:48] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:21:48] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:21:52] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:21:52] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:21:52] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:21:52] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:21:52] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:21:52] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:21:52] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:21:52] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:21:52] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:21:52] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:21:52] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:21:52] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:21:52] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:21:52] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=471486) [2026-01-25 21:21:53] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=471486) [2026-01-25 21:21:53] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=471486) [2026-01-25 21:21:53] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=471486) [2026-01-25 21:21:53] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=471486) [2026-01-25 21:21:53] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=471486) [2026-01-25 21:21:53] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=471486) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=471486) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:20<00:20, 20.37s/it]
(EngineCore_DP0 pid=471486) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:40<00:00, 20.44s/it]
(EngineCore_DP0 pid=471486) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:40<00:00, 20.43s/it]
(EngineCore_DP0 pid=471486) 
(EngineCore_DP0 pid=471486) [2026-01-25 21:22:34] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=471486) [2026-01-25 21:22:34] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10321920 bytes
(EngineCore_DP0 pid=471486) [2026-01-25 21:22:34] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=471486) [2026-01-25 21:22:34] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8028160 bytes
(EngineCore_DP0 pid=471486) [2026-01-25 21:22:34] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=471486) [2026-01-25 21:22:34] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 84869120 bytes
(EngineCore_DP0 pid=471486) [2026-01-25 21:22:34] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=471486) [2026-01-25 21:22:34] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 42434560 bytes
(EngineCore_DP0 pid=471486) Process EngineCore_DP0:
(EngineCore_DP0 pid=471486) Traceback (most recent call last):
(EngineCore_DP0 pid=471486)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=471486)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=471486)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=471486)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=471486) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp0y4k_jbe.ptx', '-o', '/tmp/tmp0y4k_jbe.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=471486) 
(EngineCore_DP0 pid=471486) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=471486) 
(EngineCore_DP0 pid=471486) Traceback (most recent call last):
(EngineCore_DP0 pid=471486)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=471486)     self.run()
(EngineCore_DP0 pid=471486)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=471486)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=471486)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=471486)     raise e
(EngineCore_DP0 pid=471486)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=471486)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=471486)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=471486)     super().__init__(
(EngineCore_DP0 pid=471486)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=471486)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=471486)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=471486)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=471486)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=471486)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=471486)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=471486)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=471486)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=471486)     return func(*args, **kwargs)
(EngineCore_DP0 pid=471486)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=471486)     return func(*args, **kwargs)
(EngineCore_DP0 pid=471486)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=471486)     self.model_runner.profile_run()
(EngineCore_DP0 pid=471486)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=471486)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=471486)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=471486)     return func(*args, **kwargs)
(EngineCore_DP0 pid=471486)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=471486)     outputs = self.model(
(EngineCore_DP0 pid=471486)               ^^^^^^^^^^^
(EngineCore_DP0 pid=471486)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=471486)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=471486)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=471486)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=471486)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=471486)     hidden_states = self.model(
(EngineCore_DP0 pid=471486)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=471486)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=471486)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=471486)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=471486)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=471486)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=471486)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=471486)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=471486)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=471486)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=471486)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=471486)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=471486)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=471486)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=471486)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=471486)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=471486)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=471486)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=471486)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=471486)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=471486)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=471486)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=471486)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=471486)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=471486)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=471486)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=471486)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=471486)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=471486)     return self._linear_fn(
(EngineCore_DP0 pid=471486)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=471486)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=471486)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=471486)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=471486)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=471486)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=471486)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=471486)     return fn(input, L)
(EngineCore_DP0 pid=471486)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=471486)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=471486)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=471486)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=471486)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=471486)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=471486)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=471486)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=471486)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=471486)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=471486)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=471486)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=471486)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=471486)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=471486)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=471486)     raise PTXASError(error)
(EngineCore_DP0 pid=471486) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=471486) `ptxas` stderr:
(EngineCore_DP0 pid=471486) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=471486) 
(EngineCore_DP0 pid=471486) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp0y4k_jbe.ptx -o /tmp/tmp0y4k_jbe.ptx.o
(EngineCore_DP0 pid=471486) 
[rank0]:[W125 21:22:36.365719240 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=16384

========== M=32768 ==========
Time: 2026-01-25 21:22:37
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Qwen2.5-7B-FP8_M32768.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:22:55 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 21:22:55 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=472599) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=472599) 
(EngineCore_DP0 pid=472599) 
(EngineCore_DP0 pid=472599) ================================================================
(EngineCore_DP0 pid=472599) Internal Triton PTX codegen error
(EngineCore_DP0 pid=472599) `ptxas` stderr:
(EngineCore_DP0 pid=472599) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=472599) 
(EngineCore_DP0 pid=472599) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpu0vslzga.ptx -o /tmp/tmpu0vslzga.ptx.o
(EngineCore_DP0 pid=472599) 
(EngineCore_DP0 pid=472599) 
(EngineCore_DP0 pid=472599) //
(EngineCore_DP0 pid=472599) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=472599) //
(EngineCore_DP0 pid=472599) 
(EngineCore_DP0 pid=472599) .version 8.7
(EngineCore_DP0 pid=472599) .target sm_121a
(EngineCore_DP0 pid=472599) .address_size 64
(EngineCore_DP0 pid=472599) 
(EngineCore_DP0 pid=472599) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=472599) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=472599)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=472599) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=472599) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=472599) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=472599) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=472599) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=472599) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=472599) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=472599) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=472599) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=472599) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=472599) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=472599) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=472599) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=472599) )
(EngineCore_DP0 pid=472599) .reqntid 512
(EngineCore_DP0 pid=472599) {
(EngineCore_DP0 pid=472599) 	.reg .pred 	%p<28>;
(EngineCore_DP0 pid=472599) 	.reg .b16 	%rs<49>;
(EngineCore_DP0 pid=472599) 	.reg .b32 	%r<134>;
(EngineCore_DP0 pid=472599) 	.reg .b64 	%rd<17>;
(EngineCore_DP0 pid=472599) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=472599) $L__func_begin0:
(EngineCore_DP0 pid=472599) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=472599) 
(EngineCore_DP0 pid=472599) // %bb.0:
(EngineCore_DP0 pid=472599) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=472599) 	ld.param.b32 	%r22, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=472599) 	ld.param.b32 	%r21, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=472599) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=472599) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=472599) $L__tmp0:
(EngineCore_DP0 pid=472599) 	.loc	1 143 24                        // quant_slide_tuned_Qwen2.5-7B.py:143:24
(EngineCore_DP0 pid=472599) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=472599) 	ld.param.b32 	%r25, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=472599) 	.loc	1 148 26                        // quant_slide_tuned_Qwen2.5-7B.py:148:26
(EngineCore_DP0 pid=472599) 	mul.lo.s32 	%r26, %r25, %r1;
(EngineCore_DP0 pid=472599) 	.loc	1 148 20                        // quant_slide_tuned_Qwen2.5-7B.py:148:20
(EngineCore_DP0 pid=472599) 	mad.wide.s32 	%rd1, %r26, 2, %rd4;
(EngineCore_DP0 pid=472599) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=472599) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=472599) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=472599) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=472599) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=472599) 	setp.lt.s32 	%p1, %r22, 1;
(EngineCore_DP0 pid=472599) 	mov.b32 	%r131, 0f2B8CBCCC;
(EngineCore_DP0 pid=472599) 	setp.eq.b32 	%p27, %r2, 0;
(EngineCore_DP0 pid=472599) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=472599) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=472599) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=472599) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=472599) 	shr.u32 	%r35, %r2, 3;
(EngineCore_DP0 pid=472599) 	and.b32 	%r36, %r35, 60;
(EngineCore_DP0 pid=472599) 	mov.b32 	%r37, global_smem;
(EngineCore_DP0 pid=472599) 	add.s32 	%r47, %r37, %r36;
(EngineCore_DP0 pid=472599) 	shl.b32 	%r38, %r2, 2;
(EngineCore_DP0 pid=472599) 	add.s32 	%r50, %r37, %r38;
(EngineCore_DP0 pid=472599) 	mov.b32 	%r43, 0;
(EngineCore_DP0 pid=472599) 	mov.b32 	%r129, 0f00000000;
(EngineCore_DP0 pid=472599) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=472599) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=472599) 	mov.b32 	%r130, %r43;
(EngineCore_DP0 pid=472599) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=472599) 	.loc	1 155 22                        // quant_slide_tuned_Qwen2.5-7B.py:155:22
(EngineCore_DP0 pid=472599) 	add.s32 	%r53, %r4, %r130;
(EngineCore_DP0 pid=472599) 	setp.lt.s32 	%p2, %r53, %r21;
(EngineCore_DP0 pid=472599) 	.loc	1 156 29                        // quant_slide_tuned_Qwen2.5-7B.py:156:29
(EngineCore_DP0 pid=472599) 	mad.wide.s32 	%rd6, %r53, 2, %rd1;
(EngineCore_DP0 pid=472599) 	.loc	1 156 21                        // quant_slide_tuned_Qwen2.5-7B.py:156:21
(EngineCore_DP0 pid=472599) 	// begin inline asm
(EngineCore_DP0 pid=472599) 	mov.u32 %r39, %r43;
(EngineCore_DP0 pid=472599) 	mov.u32 %r40, %r43;
(EngineCore_DP0 pid=472599) 	mov.u32 %r41, %r43;
(EngineCore_DP0 pid=472599) 	mov.u32 %r42, %r43;
(EngineCore_DP0 pid=472599) 	@%p2 ld.global.v4.b32 { %r39, %r40, %r41, %r42 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=472599) 	// end inline asm
(EngineCore_DP0 pid=472599) 	mov.b32 	{%rs1, %rs2}, %r39;
(EngineCore_DP0 pid=472599) 	mov.b32 	{%rs3, %rs4}, %r40;
(EngineCore_DP0 pid=472599) 	mov.b32 	{%rs5, %rs6}, %r41;
(EngineCore_DP0 pid=472599) 	mov.b32 	{%rs7, %rs8}, %r42;
(EngineCore_DP0 pid=472599) 	.loc	1 157 50                        // quant_slide_tuned_Qwen2.5-7B.py:157:50
(EngineCore_DP0 pid=472599) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=472599) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=472599) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=472599) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=472599) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=472599) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=472599) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=472599) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=472599) $L__tmp1:
(EngineCore_DP0 pid=472599) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=472599) 	bar.sync 	0;
(EngineCore_DP0 pid=472599) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=472599) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=472599) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=472599) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=472599) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=472599) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=472599) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=472599) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=472599) 	cvt.f32.bf16 	%r54, %rs23;
(EngineCore_DP0 pid=472599) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=472599) 	shfl.sync.bfly.b32 	%r55, %r54, 16, 31, -1;
(EngineCore_DP0 pid=472599) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=472599) 	max.f32 	%r56, %r54, %r55;
(EngineCore_DP0 pid=472599) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=472599) 	shfl.sync.bfly.b32 	%r57, %r56, 8, 31, -1;
(EngineCore_DP0 pid=472599) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=472599) 	max.f32 	%r58, %r56, %r57;
(EngineCore_DP0 pid=472599) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=472599) 	shfl.sync.bfly.b32 	%r59, %r58, 4, 31, -1;
(EngineCore_DP0 pid=472599) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=472599) 	max.f32 	%r60, %r58, %r59;
(EngineCore_DP0 pid=472599) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=472599) 	shfl.sync.bfly.b32 	%r61, %r60, 2, 31, -1;
(EngineCore_DP0 pid=472599) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=472599) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=472599) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=472599) 	shfl.sync.bfly.b32 	%r63, %r62, 1, 31, -1;
(EngineCore_DP0 pid=472599) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=472599) 	max.f32 	%r48, %r62, %r63;
(EngineCore_DP0 pid=472599) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=472599) 	// begin inline asm
(EngineCore_DP0 pid=472599) 	@%p3 st.shared.b32 [ %r47 + 0 ], %r48;
(EngineCore_DP0 pid=472599) 	// end inline asm
(EngineCore_DP0 pid=472599) 	bar.sync 	0;
(EngineCore_DP0 pid=472599) 	// begin inline asm
(EngineCore_DP0 pid=472599) 	@%p4 ld.shared.b32 %r49, [ %r50 + 0 ];
(EngineCore_DP0 pid=472599) 	// end inline asm
(EngineCore_DP0 pid=472599) 	shfl.sync.bfly.b32 	%r64, %r49, 8, 31, -1;
(EngineCore_DP0 pid=472599) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=472599) 	max.f32 	%r65, %r49, %r64;
(EngineCore_DP0 pid=472599) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=472599) 	shfl.sync.bfly.b32 	%r66, %r65, 4, 31, -1;
(EngineCore_DP0 pid=472599) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=472599) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=472599) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=472599) 	shfl.sync.bfly.b32 	%r68, %r67, 2, 31, -1;
(EngineCore_DP0 pid=472599) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=472599) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=472599) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=472599) 	shfl.sync.bfly.b32 	%r70, %r69, 1, 31, -1;
(EngineCore_DP0 pid=472599) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=472599) 	max.f32 	%r52, %r69, %r70;
(EngineCore_DP0 pid=472599) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=472599) 	// begin inline asm
(EngineCore_DP0 pid=472599) 	@%p27 st.shared.b32 [ %r50 + 0 ], %r52;
(EngineCore_DP0 pid=472599) 	// end inline asm
(EngineCore_DP0 pid=472599) 	bar.sync 	0;
(EngineCore_DP0 pid=472599) 	ld.shared.b32 	%r71, [global_smem];
(EngineCore_DP0 pid=472599) $L__tmp2:
(EngineCore_DP0 pid=472599) 	.loc	1 157 36                        // quant_slide_tuned_Qwen2.5-7B.py:157:36
(EngineCore_DP0 pid=472599) 	max.f32 	%r129, %r129, %r71;
(EngineCore_DP0 pid=472599) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=472599) 	add.s32 	%r130, %r130, 4096;
(EngineCore_DP0 pid=472599) 	setp.lt.s32 	%p6, %r130, %r22;
(EngineCore_DP0 pid=472599) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=472599) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=472599) 	.loc	1 159 32                        // quant_slide_tuned_Qwen2.5-7B.py:159:32
(EngineCore_DP0 pid=472599) 	max.f32 	%r131, %r129, 0f2B8CBCCC;
(EngineCore_DP0 pid=472599) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=472599) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-7B.py:0:32
(EngineCore_DP0 pid=472599) 	mov.b32 	%r73, 0f43E00000;
(EngineCore_DP0 pid=472599) 	.loc	1 160 32                        // quant_slide_tuned_Qwen2.5-7B.py:160:32
(EngineCore_DP0 pid=472599) 	div.full.f32 	%r74, %r131, %r73;
(EngineCore_DP0 pid=472599) 	.loc	1 160 41                        // quant_slide_tuned_Qwen2.5-7B.py:160:41
(EngineCore_DP0 pid=472599) 	max.f32 	%r72, %r74, 0f36924925;
(EngineCore_DP0 pid=472599) 	.loc	1 162 25                        // quant_slide_tuned_Qwen2.5-7B.py:162:25
(EngineCore_DP0 pid=472599) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=472599) 	.loc	1 162 30                        // quant_slide_tuned_Qwen2.5-7B.py:162:30
(EngineCore_DP0 pid=472599) 	// begin inline asm
(EngineCore_DP0 pid=472599) 	@%p27 st.global.b32 [ %rd7 + 0 ], { %r72 };
(EngineCore_DP0 pid=472599) 	// end inline asm
(EngineCore_DP0 pid=472599) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=472599) 	setp.lt.s32 	%p8, %r23, 1;
(EngineCore_DP0 pid=472599) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=472599) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=472599) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-7B.py:0:41
(EngineCore_DP0 pid=472599) 	ld.param.b32 	%r27, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=472599) 	shr.s32 	%r28, %r27, 31;
(EngineCore_DP0 pid=472599) 	shr.u32 	%r29, %r28, 30;
(EngineCore_DP0 pid=472599) 	add.s32 	%r30, %r27, %r29;
(EngineCore_DP0 pid=472599) 	shr.s32 	%r31, %r30, 2;
(EngineCore_DP0 pid=472599) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=472599) 	mul.lo.s32 	%r32, %r31, %r1;
(EngineCore_DP0 pid=472599) 	mad.wide.s32 	%rd2, %r32, 4, %rd5;
(EngineCore_DP0 pid=472599) 	div.full.f32 	%r14, %r73, %r131;
(EngineCore_DP0 pid=472599) 	shl.b32 	%r15, %r3, 1;
(EngineCore_DP0 pid=472599) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=472599) 	add.s32 	%r132, %r4, 7;
(EngineCore_DP0 pid=472599) 	mov.b32 	%r133, 0;
(EngineCore_DP0 pid=472599) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=472599)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=472599) 	.loc	1 169 30                        // quant_slide_tuned_Qwen2.5-7B.py:169:30
(EngineCore_DP0 pid=472599) 	add.s32 	%r86, %r15, %r133;
(EngineCore_DP0 pid=472599) 	setp.lt.s32 	%p17, %r86, %r23;
(EngineCore_DP0 pid=472599) 	.loc	1 174 22                        // quant_slide_tuned_Qwen2.5-7B.py:174:22
(EngineCore_DP0 pid=472599) 	add.s32 	%r87, %r132, -7;
(EngineCore_DP0 pid=472599) 	.loc	1 177 53                        // quant_slide_tuned_Qwen2.5-7B.py:177:53
(EngineCore_DP0 pid=472599) 	add.s32 	%r88, %r132, -3;
(EngineCore_DP0 pid=472599) 	setp.lt.s32 	%p18, %r87, %r21;
(EngineCore_DP0 pid=472599) 	setp.lt.s32 	%p19, %r88, %r21;
(EngineCore_DP0 pid=472599) 	.loc	1 177 37                        // quant_slide_tuned_Qwen2.5-7B.py:177:37
(EngineCore_DP0 pid=472599) 	and.pred 	%p9, %p17, %p18;
(EngineCore_DP0 pid=472599) 	and.pred 	%p10, %p17, %p19;
(EngineCore_DP0 pid=472599) 	.loc	1 176 29                        // quant_slide_tuned_Qwen2.5-7B.py:176:29
(EngineCore_DP0 pid=472599) 	mad.wide.s32 	%rd8, %r87, 2, %rd1;
(EngineCore_DP0 pid=472599) 	add.s64 	%rd9, %rd8, 8;
(EngineCore_DP0 pid=472599) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=472599) 	.loc	1 176 21                        // quant_slide_tuned_Qwen2.5-7B.py:176:21
(EngineCore_DP0 pid=472599) 	// begin inline asm
(EngineCore_DP0 pid=472599) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=472599) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=472599) 	// end inline asm
(EngineCore_DP0 pid=472599) 	// begin inline asm
(EngineCore_DP0 pid=472599) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=472599) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=472599) 	// end inline asm
(EngineCore_DP0 pid=472599) 	.loc	1 177 79                        // quant_slide_tuned_Qwen2.5-7B.py:177:79
(EngineCore_DP0 pid=472599) 	cvt.f32.bf16 	%r89, %rs24;
(EngineCore_DP0 pid=472599) 	cvt.f32.bf16 	%r90, %rs26;
(EngineCore_DP0 pid=472599) 	.loc	1 179 48                        // quant_slide_tuned_Qwen2.5-7B.py:179:48
(EngineCore_DP0 pid=472599) 	add.s32 	%r91, %r132, -6;
(EngineCore_DP0 pid=472599) 	.loc	1 179 53                        // quant_slide_tuned_Qwen2.5-7B.py:179:53
(EngineCore_DP0 pid=472599) 	add.s32 	%r92, %r132, -2;
(EngineCore_DP0 pid=472599) 	setp.lt.s32 	%p20, %r91, %r21;
(EngineCore_DP0 pid=472599) 	setp.lt.s32 	%p21, %r92, %r21;
(EngineCore_DP0 pid=472599) 	.loc	1 179 37                        // quant_slide_tuned_Qwen2.5-7B.py:179:37
(EngineCore_DP0 pid=472599) 	and.pred 	%p11, %p17, %p20;
(EngineCore_DP0 pid=472599) 	and.pred 	%p12, %p17, %p21;
(EngineCore_DP0 pid=472599) 	.loc	1 178 39                        // quant_slide_tuned_Qwen2.5-7B.py:178:39
(EngineCore_DP0 pid=472599) 	add.s64 	%rd10, %rd8, 2;
(EngineCore_DP0 pid=472599) 	add.s64 	%rd11, %rd8, 10;
(EngineCore_DP0 pid=472599) 	.loc	1 178 21                        // quant_slide_tuned_Qwen2.5-7B.py:178:21
(EngineCore_DP0 pid=472599) 	// begin inline asm
(EngineCore_DP0 pid=472599) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=472599) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=472599) 	// end inline asm
(EngineCore_DP0 pid=472599) 	// begin inline asm
(EngineCore_DP0 pid=472599) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=472599) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=472599) 	// end inline asm
(EngineCore_DP0 pid=472599) 	.loc	1 179 79                        // quant_slide_tuned_Qwen2.5-7B.py:179:79
(EngineCore_DP0 pid=472599) 	cvt.f32.bf16 	%r93, %rs28;
(EngineCore_DP0 pid=472599) 	cvt.f32.bf16 	%r94, %rs30;
(EngineCore_DP0 pid=472599) 	.loc	1 181 48                        // quant_slide_tuned_Qwen2.5-7B.py:181:48
(EngineCore_DP0 pid=472599) 	add.s32 	%r95, %r132, -5;
(EngineCore_DP0 pid=472599) 	.loc	1 181 53                        // quant_slide_tuned_Qwen2.5-7B.py:181:53
(EngineCore_DP0 pid=472599) 	add.s32 	%r96, %r132, -1;
(EngineCore_DP0 pid=472599) 	setp.lt.s32 	%p22, %r95, %r21;
(EngineCore_DP0 pid=472599) 	setp.lt.s32 	%p23, %r96, %r21;
(EngineCore_DP0 pid=472599) 	.loc	1 181 37                        // quant_slide_tuned_Qwen2.5-7B.py:181:37
(EngineCore_DP0 pid=472599) 	and.pred 	%p13, %p17, %p22;
(EngineCore_DP0 pid=472599) 	and.pred 	%p14, %p17, %p23;
(EngineCore_DP0 pid=472599) 	.loc	1 180 39                        // quant_slide_tuned_Qwen2.5-7B.py:180:39
(EngineCore_DP0 pid=472599) 	add.s64 	%rd12, %rd8, 4;
(EngineCore_DP0 pid=472599) 	add.s64 	%rd13, %rd8, 12;
(EngineCore_DP0 pid=472599) 	.loc	1 180 21                        // quant_slide_tuned_Qwen2.5-7B.py:180:21
(EngineCore_DP0 pid=472599) 	// begin inline asm
(EngineCore_DP0 pid=472599) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=472599) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=472599) 	// end inline asm
(EngineCore_DP0 pid=472599) 	// begin inline asm
(EngineCore_DP0 pid=472599) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=472599) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=472599) 	// end inline asm
(EngineCore_DP0 pid=472599) 	.loc	1 181 79                        // quant_slide_tuned_Qwen2.5-7B.py:181:79
(EngineCore_DP0 pid=472599) 	cvt.f32.bf16 	%r97, %rs32;
(EngineCore_DP0 pid=472599) 	cvt.f32.bf16 	%r98, %rs34;
(EngineCore_DP0 pid=472599) 	.loc	1 183 48                        // quant_slide_tuned_Qwen2.5-7B.py:183:48
(EngineCore_DP0 pid=472599) 	add.s32 	%r99, %r132, -4;
(EngineCore_DP0 pid=472599) 	.loc	1 183 53                        // quant_slide_tuned_Qwen2.5-7B.py:183:53
(EngineCore_DP0 pid=472599) 	setp.lt.s32 	%p24, %r99, %r21;
(EngineCore_DP0 pid=472599) 	setp.lt.s32 	%p25, %r132, %r21;
(EngineCore_DP0 pid=472599) 	.loc	1 183 37                        // quant_slide_tuned_Qwen2.5-7B.py:183:37
(EngineCore_DP0 pid=472599) 	and.pred 	%p15, %p17, %p24;
(EngineCore_DP0 pid=472599) 	and.pred 	%p16, %p17, %p25;
(EngineCore_DP0 pid=472599) 	.loc	1 182 39                        // quant_slide_tuned_Qwen2.5-7B.py:182:39
(EngineCore_DP0 pid=472599) 	add.s64 	%rd14, %rd8, 6;
(EngineCore_DP0 pid=472599) 	add.s64 	%rd15, %rd8, 14;
(EngineCore_DP0 pid=472599) 	.loc	1 182 21                        // quant_slide_tuned_Qwen2.5-7B.py:182:21
(EngineCore_DP0 pid=472599) 	// begin inline asm
(EngineCore_DP0 pid=472599) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=472599) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=472599) 	// end inline asm
(EngineCore_DP0 pid=472599) 	// begin inline asm
(EngineCore_DP0 pid=472599) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=472599) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=472599) 	// end inline asm
(EngineCore_DP0 pid=472599) 	.loc	1 183 79                        // quant_slide_tuned_Qwen2.5-7B.py:183:79
(EngineCore_DP0 pid=472599) 	cvt.f32.bf16 	%r100, %rs36;
(EngineCore_DP0 pid=472599) 	cvt.f32.bf16 	%r101, %rs38;
(EngineCore_DP0 pid=472599) 	.loc	1 185 27                        // quant_slide_tuned_Qwen2.5-7B.py:185:27
(EngineCore_DP0 pid=472599) 	mul.f32 	%r102, %r14, %r89;
(EngineCore_DP0 pid=472599) 	mul.f32 	%r103, %r14, %r90;
(EngineCore_DP0 pid=472599) 	mov.b32 	%r104, 0f43E00000;
(EngineCore_DP0 pid=472599) 	.loc	1 185 48                        // quant_slide_tuned_Qwen2.5-7B.py:185:48
(EngineCore_DP0 pid=472599) 	min.xorsign.abs.f32 	%r76, %r102, %r104;
(EngineCore_DP0 pid=472599) 	min.xorsign.abs.f32 	%r77, %r103, %r104;
(EngineCore_DP0 pid=472599) 	.loc	1 185 60                        // quant_slide_tuned_Qwen2.5-7B.py:185:60
(EngineCore_DP0 pid=472599) 	// begin inline asm
(EngineCore_DP0 pid=472599) 	cvt.rn.satfinite.e4m3x2.f32  %rs40, %r77, %r76; 
(EngineCore_DP0 pid=472599) 
(EngineCore_DP0 pid=472599) 	// end inline asm
(EngineCore_DP0 pid=472599) 	shr.u16 	%rs44, %rs40, 8;
(EngineCore_DP0 pid=472599) 	.loc	1 186 27                        // quant_slide_tuned_Qwen2.5-7B.py:186:27
(EngineCore_DP0 pid=472599) 	mul.f32 	%r105, %r14, %r93;
(EngineCore_DP0 pid=472599) 	mul.f32 	%r106, %r14, %r94;
(EngineCore_DP0 pid=472599) 	.loc	1 186 48                        // quant_slide_tuned_Qwen2.5-7B.py:186:48
(EngineCore_DP0 pid=472599) 	min.xorsign.abs.f32 	%r78, %r105, %r104;
(EngineCore_DP0 pid=472599) 	min.xorsign.abs.f32 	%r79, %r106, %r104;
(EngineCore_DP0 pid=472599) 	.loc	1 186 60                        // quant_slide_tuned_Qwen2.5-7B.py:186:60
(EngineCore_DP0 pid=472599) 	// begin inline asm
(EngineCore_DP0 pid=472599) 	cvt.rn.satfinite.e4m3x2.f32  %rs41, %r79, %r78; 
(EngineCore_DP0 pid=472599) 
(EngineCore_DP0 pid=472599) 	// end inline asm
(EngineCore_DP0 pid=472599) 	shr.u16 	%rs45, %rs41, 8;
(EngineCore_DP0 pid=472599) 	.loc	1 187 27                        // quant_slide_tuned_Qwen2.5-7B.py:187:27
(EngineCore_DP0 pid=472599) 	mul.f32 	%r107, %r14, %r97;
(EngineCore_DP0 pid=472599) 	mul.f32 	%r108, %r14, %r98;
(EngineCore_DP0 pid=472599) 	.loc	1 187 48                        // quant_slide_tuned_Qwen2.5-7B.py:187:48
(EngineCore_DP0 pid=472599) 	min.xorsign.abs.f32 	%r80, %r107, %r104;
(EngineCore_DP0 pid=472599) 	min.xorsign.abs.f32 	%r81, %r108, %r104;
(EngineCore_DP0 pid=472599) 	.loc	1 187 60                        // quant_slide_tuned_Qwen2.5-7B.py:187:60
(EngineCore_DP0 pid=472599) 	// begin inline asm
(EngineCore_DP0 pid=472599) 	cvt.rn.satfinite.e4m3x2.f32  %rs42, %r81, %r80; 
(EngineCore_DP0 pid=472599) 
(EngineCore_DP0 pid=472599) 	// end inline asm
(EngineCore_DP0 pid=472599) 	shr.u16 	%rs46, %rs42, 8;
(EngineCore_DP0 pid=472599) 	.loc	1 188 27                        // quant_slide_tuned_Qwen2.5-7B.py:188:27
(EngineCore_DP0 pid=472599) 	mul.f32 	%r109, %r14, %r100;
(EngineCore_DP0 pid=472599) 	mul.f32 	%r110, %r14, %r101;
(EngineCore_DP0 pid=472599) 	.loc	1 188 48                        // quant_slide_tuned_Qwen2.5-7B.py:188:48
(EngineCore_DP0 pid=472599) 	min.xorsign.abs.f32 	%r82, %r109, %r104;
(EngineCore_DP0 pid=472599) 	min.xorsign.abs.f32 	%r83, %r110, %r104;
(EngineCore_DP0 pid=472599) 	.loc	1 188 60                        // quant_slide_tuned_Qwen2.5-7B.py:188:60
(EngineCore_DP0 pid=472599) 	// begin inline asm
(EngineCore_DP0 pid=472599) 	cvt.rn.satfinite.e4m3x2.f32  %rs43, %r83, %r82; 
(EngineCore_DP0 pid=472599) 
(EngineCore_DP0 pid=472599) 	// end inline asm
(EngineCore_DP0 pid=472599) 	shr.u16 	%rs47, %rs43, 8;
(EngineCore_DP0 pid=472599) 	.loc	1 190 45                        // quant_slide_tuned_Qwen2.5-7B.py:190:45
(EngineCore_DP0 pid=472599) 	cvt.u32.u16 	%r111, %rs40;
(EngineCore_DP0 pid=472599) 	and.b32 	%r112, %r111, 255;
(EngineCore_DP0 pid=472599) 	cvt.u32.u16 	%r113, %rs44;
(EngineCore_DP0 pid=472599) 	.loc	1 192 45                        // quant_slide_tuned_Qwen2.5-7B.py:192:45
(EngineCore_DP0 pid=472599) 	cvt.u32.u16 	%r114, %rs42;
(EngineCore_DP0 pid=472599) 	and.b32 	%r115, %r114, 255;
(EngineCore_DP0 pid=472599) 	cvt.u32.u16 	%r116, %rs46;
(EngineCore_DP0 pid=472599) 	.loc	1 193 45                        // quant_slide_tuned_Qwen2.5-7B.py:193:45
(EngineCore_DP0 pid=472599) 	cvt.u32.u16 	%r117, %rs43;
(EngineCore_DP0 pid=472599) 	cvt.u32.u16 	%r118, %rs47;
(EngineCore_DP0 pid=472599) 	.loc	1 195 30                        // quant_slide_tuned_Qwen2.5-7B.py:195:30
(EngineCore_DP0 pid=472599) 	and.b16 	%rs48, %rs41, 255;
(EngineCore_DP0 pid=472599) 	mul.wide.u16 	%r119, %rs48, 256;
(EngineCore_DP0 pid=472599) 	mul.wide.u16 	%r120, %rs45, 256;
(EngineCore_DP0 pid=472599) 	.loc	1 195 24                        // quant_slide_tuned_Qwen2.5-7B.py:195:24
(EngineCore_DP0 pid=472599) 	or.b32 	%r121, %r119, %r112;
(EngineCore_DP0 pid=472599) 	or.b32 	%r122, %r120, %r113;
(EngineCore_DP0 pid=472599) 	.loc	1 195 42                        // quant_slide_tuned_Qwen2.5-7B.py:195:42
(EngineCore_DP0 pid=472599) 	shl.b32 	%r123, %r115, 16;
(EngineCore_DP0 pid=472599) 	shl.b32 	%r124, %r116, 16;
(EngineCore_DP0 pid=472599) 	.loc	1 195 36                        // quant_slide_tuned_Qwen2.5-7B.py:195:36
(EngineCore_DP0 pid=472599) 	or.b32 	%r125, %r121, %r123;
(EngineCore_DP0 pid=472599) 	or.b32 	%r126, %r122, %r124;
(EngineCore_DP0 pid=472599) 	.loc	1 195 55                        // quant_slide_tuned_Qwen2.5-7B.py:195:55
(EngineCore_DP0 pid=472599) 	shl.b32 	%r127, %r117, 24;
(EngineCore_DP0 pid=472599) 	shl.b32 	%r128, %r118, 24;
(EngineCore_DP0 pid=472599) 	.loc	1 195 49                        // quant_slide_tuned_Qwen2.5-7B.py:195:49
(EngineCore_DP0 pid=472599) 	or.b32 	%r84, %r125, %r127;
(EngineCore_DP0 pid=472599) 	or.b32 	%r85, %r126, %r128;
(EngineCore_DP0 pid=472599) 	.loc	1 196 29                        // quant_slide_tuned_Qwen2.5-7B.py:196:29
(EngineCore_DP0 pid=472599) 	mad.wide.s32 	%rd16, %r86, 4, %rd2;
(EngineCore_DP0 pid=472599) 	.loc	1 196 39                        // quant_slide_tuned_Qwen2.5-7B.py:196:39
(EngineCore_DP0 pid=472599) 	// begin inline asm
(EngineCore_DP0 pid=472599) 	@%p17 st.global.v2.b32 [ %rd16 + 0 ], { %r84, %r85 };
(EngineCore_DP0 pid=472599) 	// end inline asm
(EngineCore_DP0 pid=472599) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=472599) 	add.s32 	%r133, %r133, 1024;
(EngineCore_DP0 pid=472599) 	add.s32 	%r132, %r132, 4096;
(EngineCore_DP0 pid=472599) 	setp.lt.s32 	%p26, %r133, %r23;
(EngineCore_DP0 pid=472599) 	@%p26 bra 	$L__BB0_6;
(EngineCore_DP0 pid=472599) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=472599) 	.loc	1 167 4                         // quant_slide_tuned_Qwen2.5-7B.py:167:4
(EngineCore_DP0 pid=472599) 	ret;
(EngineCore_DP0 pid=472599) $L__tmp3:
(EngineCore_DP0 pid=472599) $L__func_end0:
(EngineCore_DP0 pid=472599)                                         // -- End function
(EngineCore_DP0 pid=472599) }
(EngineCore_DP0 pid=472599) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py"
(EngineCore_DP0 pid=472599) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=472599) 	.section	.debug_abbrev
(EngineCore_DP0 pid=472599) 	{
(EngineCore_DP0 pid=472599) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=472599) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=472599) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=472599) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=472599) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=472599) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=472599) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=472599) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=472599) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=472599) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=472599) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=472599) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=472599) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=472599) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=472599) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=472599) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=472599) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=472599) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=472599) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=472599) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=472599) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=472599) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=472599) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=472599) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=472599) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=472599) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=472599) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=472599) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=472599) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=472599) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=472599) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=472599) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=472599) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=472599) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=472599) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=472599) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=472599) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=472599) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=472599) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=472599) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=472599) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=472599) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=472599) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=472599) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=472599) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=472599) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=472599) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=472599) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=472599) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=472599) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=472599) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=472599) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=472599) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=472599) 	}
(EngineCore_DP0 pid=472599) 	.section	.debug_info
(EngineCore_DP0 pid=472599) 	{
(EngineCore_DP0 pid=472599) .b32 221                                // Length of Unit
(EngineCore_DP0 pid=472599) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=472599) .b8 0
(EngineCore_DP0 pid=472599) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=472599) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=472599) .b8 1                                   // Abbrev [1] 0xb:0xd6 DW_TAG_compile_unit
(EngineCore_DP0 pid=472599) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=472599) .b8 114
(EngineCore_DP0 pid=472599) .b8 105
(EngineCore_DP0 pid=472599) .b8 116
(EngineCore_DP0 pid=472599) .b8 111
(EngineCore_DP0 pid=472599) .b8 110
(EngineCore_DP0 pid=472599) .b8 0
(EngineCore_DP0 pid=472599) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=472599) .b8 0
(EngineCore_DP0 pid=472599) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=472599) .b8 117
(EngineCore_DP0 pid=472599) .b8 97
(EngineCore_DP0 pid=472599) .b8 110
(EngineCore_DP0 pid=472599) .b8 116
(EngineCore_DP0 pid=472599) .b8 95
(EngineCore_DP0 pid=472599) .b8 115
(EngineCore_DP0 pid=472599) .b8 108
(EngineCore_DP0 pid=472599) .b8 105
(EngineCore_DP0 pid=472599) .b8 100
(EngineCore_DP0 pid=472599) .b8 101
(EngineCore_DP0 pid=472599) .b8 95
(EngineCore_DP0 pid=472599) .b8 116
(EngineCore_DP0 pid=472599) .b8 117
(EngineCore_DP0 pid=472599) .b8 110
(EngineCore_DP0 pid=472599) .b8 101
(EngineCore_DP0 pid=472599) .b8 100
(EngineCore_DP0 pid=472599) .b8 95
(EngineCore_DP0 pid=472599) .b8 81
(EngineCore_DP0 pid=472599) .b8 119
(EngineCore_DP0 pid=472599) .b8 101
(EngineCore_DP0 pid=472599) .b8 110
(EngineCore_DP0 pid=472599) .b8 50
(EngineCore_DP0 pid=472599) .b8 46
(EngineCore_DP0 pid=472599) .b8 53
(EngineCore_DP0 pid=472599) .b8 45
(EngineCore_DP0 pid=472599) .b8 55
(EngineCore_DP0 pid=472599) .b8 66
(EngineCore_DP0 pid=472599) .b8 46
(EngineCore_DP0 pid=472599) .b8 112
(EngineCore_DP0 pid=472599) .b8 121
(EngineCore_DP0 pid=472599) .b8 0
(EngineCore_DP0 pid=472599) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=472599) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=472599) .b8 114
(EngineCore_DP0 pid=472599) .b8 111
(EngineCore_DP0 pid=472599) .b8 111
(EngineCore_DP0 pid=472599) .b8 116
(EngineCore_DP0 pid=472599) .b8 47
(EngineCore_DP0 pid=472599) .b8 118
(EngineCore_DP0 pid=472599) .b8 108
(EngineCore_DP0 pid=472599) .b8 108
(EngineCore_DP0 pid=472599) .b8 109
(EngineCore_DP0 pid=472599) .b8 98
(EngineCore_DP0 pid=472599) .b8 101
(EngineCore_DP0 pid=472599) .b8 110
(EngineCore_DP0 pid=472599) .b8 99
(EngineCore_DP0 pid=472599) .b8 104
(EngineCore_DP0 pid=472599) .b8 47
(EngineCore_DP0 pid=472599) .b8 115
(EngineCore_DP0 pid=472599) .b8 108
(EngineCore_DP0 pid=472599) .b8 105
(EngineCore_DP0 pid=472599) .b8 100
(EngineCore_DP0 pid=472599) .b8 101
(EngineCore_DP0 pid=472599) .b8 115
(EngineCore_DP0 pid=472599) .b8 112
(EngineCore_DP0 pid=472599) .b8 97
(EngineCore_DP0 pid=472599) .b8 114
(EngineCore_DP0 pid=472599) .b8 115
(EngineCore_DP0 pid=472599) .b8 101
(EngineCore_DP0 pid=472599) .b8 47
(EngineCore_DP0 pid=472599) .b8 99
(EngineCore_DP0 pid=472599) .b8 115
(EngineCore_DP0 pid=472599) .b8 114
(EngineCore_DP0 pid=472599) .b8 99
(EngineCore_DP0 pid=472599) .b8 47
(EngineCore_DP0 pid=472599) .b8 102
(EngineCore_DP0 pid=472599) .b8 117
(EngineCore_DP0 pid=472599) .b8 115
(EngineCore_DP0 pid=472599) .b8 101
(EngineCore_DP0 pid=472599) .b8 100
(EngineCore_DP0 pid=472599) .b8 95
(EngineCore_DP0 pid=472599) .b8 113
(EngineCore_DP0 pid=472599) .b8 117
(EngineCore_DP0 pid=472599) .b8 97
(EngineCore_DP0 pid=472599) .b8 110
(EngineCore_DP0 pid=472599) .b8 116
(EngineCore_DP0 pid=472599) .b8 95
(EngineCore_DP0 pid=472599) .b8 115
(EngineCore_DP0 pid=472599) .b8 108
(EngineCore_DP0 pid=472599) .b8 105
(EngineCore_DP0 pid=472599) .b8 100
(EngineCore_DP0 pid=472599) .b8 101
(EngineCore_DP0 pid=472599) .b8 95
(EngineCore_DP0 pid=472599) .b8 116
(EngineCore_DP0 pid=472599) .b8 114
(EngineCore_DP0 pid=472599) .b8 105
(EngineCore_DP0 pid=472599) .b8 116
(EngineCore_DP0 pid=472599) .b8 111
(EngineCore_DP0 pid=472599) .b8 110
(EngineCore_DP0 pid=472599) .b8 47
(EngineCore_DP0 pid=472599) .b8 98
(EngineCore_DP0 pid=472599) .b8 117
(EngineCore_DP0 pid=472599) .b8 105
(EngineCore_DP0 pid=472599) .b8 108
(EngineCore_DP0 pid=472599) .b8 100
(EngineCore_DP0 pid=472599) .b8 47
(EngineCore_DP0 pid=472599) .b8 71
(EngineCore_DP0 pid=472599) .b8 66
(EngineCore_DP0 pid=472599) .b8 49
(EngineCore_DP0 pid=472599) .b8 48
(EngineCore_DP0 pid=472599) .b8 95
(EngineCore_DP0 pid=472599) .b8 99
(EngineCore_DP0 pid=472599) .b8 99
(EngineCore_DP0 pid=472599) .b8 49
(EngineCore_DP0 pid=472599) .b8 50
(EngineCore_DP0 pid=472599) .b8 49
(EngineCore_DP0 pid=472599) .b8 95
(EngineCore_DP0 pid=472599) .b8 112
(EngineCore_DP0 pid=472599) .b8 121
(EngineCore_DP0 pid=472599) .b8 51
(EngineCore_DP0 pid=472599) .b8 49
(EngineCore_DP0 pid=472599) .b8 50
(EngineCore_DP0 pid=472599) .b8 95
(EngineCore_DP0 pid=472599) .b8 99
(EngineCore_DP0 pid=472599) .b8 117
(EngineCore_DP0 pid=472599) .b8 49
(EngineCore_DP0 pid=472599) .b8 50
(EngineCore_DP0 pid=472599) .b8 57
(EngineCore_DP0 pid=472599) .b8 95
(EngineCore_DP0 pid=472599) .b8 97
(EngineCore_DP0 pid=472599) .b8 97
(EngineCore_DP0 pid=472599) .b8 114
(EngineCore_DP0 pid=472599) .b8 99
(EngineCore_DP0 pid=472599) .b8 104
(EngineCore_DP0 pid=472599) .b8 54
(EngineCore_DP0 pid=472599) .b8 52
(EngineCore_DP0 pid=472599) .b8 0
(EngineCore_DP0 pid=472599) .b8 2                                   // Abbrev [2] 0x98:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=472599) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=472599) .b8 113
(EngineCore_DP0 pid=472599) .b8 117
(EngineCore_DP0 pid=472599) .b8 97
(EngineCore_DP0 pid=472599) .b8 110
(EngineCore_DP0 pid=472599) .b8 116
(EngineCore_DP0 pid=472599) .b8 95
(EngineCore_DP0 pid=472599) .b8 115
(EngineCore_DP0 pid=472599) .b8 108
(EngineCore_DP0 pid=472599) .b8 105
(EngineCore_DP0 pid=472599) .b8 100
(EngineCore_DP0 pid=472599) .b8 101
(EngineCore_DP0 pid=472599) .b8 95
(EngineCore_DP0 pid=472599) .b8 102
(EngineCore_DP0 pid=472599) .b8 112
(EngineCore_DP0 pid=472599) .b8 56
(EngineCore_DP0 pid=472599) .b8 95
(EngineCore_DP0 pid=472599) .b8 107
(EngineCore_DP0 pid=472599) .b8 101
(EngineCore_DP0 pid=472599) .b8 114
(EngineCore_DP0 pid=472599) .b8 110
(EngineCore_DP0 pid=472599) .b8 101
(EngineCore_DP0 pid=472599) .b8 108
(EngineCore_DP0 pid=472599) .b8 0
(EngineCore_DP0 pid=472599) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=472599) .b8 3                                   // Abbrev [3] 0xb2:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=472599) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=472599) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=472599) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=472599) .b8 4                                   // Abbrev [4] 0xc7:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=472599) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=472599) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=472599) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=472599) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=472599) .b8 157                                 // DW_AT_call_line
(EngineCore_DP0 pid=472599) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=472599) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=472599) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=472599) 	}
(EngineCore_DP0 pid=472599) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=472599) 
(EngineCore_DP0 pid=472599) ================================================================
(EngineCore_DP0 pid=472599) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=472599) 
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpu0vslzga.ptx', '-o', '/tmp/tmpu0vslzga.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866] 
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866] 
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866] 
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpu0vslzga.ptx -o /tmp/tmpu0vslzga.ptx.o
(EngineCore_DP0 pid=472599) ERROR 01-25 21:23:42 [core.py:866] 

STDERR:
[2026-01-25 21:22:55] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:22:55] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:22:55] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:22:55] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:22:55] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:22:55] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:22:55] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:22:55] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:22:55] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:22:55] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:22:55] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:22:55] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:22:55] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:22:55] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:22:58] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:22:59] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:22:59] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:22:59] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:22:59] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:22:59] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:22:59] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:22:59] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:22:59] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:22:59] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:22:59] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:22:59] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:22:59] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:22:59] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=472599) [2026-01-25 21:23:00] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=472599) [2026-01-25 21:23:00] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=472599) [2026-01-25 21:23:00] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=472599) [2026-01-25 21:23:00] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=472599) [2026-01-25 21:23:00] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=472599) [2026-01-25 21:23:00] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=472599) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=472599) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:20<00:20, 20.41s/it]
(EngineCore_DP0 pid=472599) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:40<00:00, 20.51s/it]
(EngineCore_DP0 pid=472599) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:40<00:00, 20.49s/it]
(EngineCore_DP0 pid=472599) 
(EngineCore_DP0 pid=472599) [2026-01-25 21:23:41] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=472599) [2026-01-25 21:23:41] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10321920 bytes
(EngineCore_DP0 pid=472599) [2026-01-25 21:23:41] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=472599) [2026-01-25 21:23:41] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8028160 bytes
(EngineCore_DP0 pid=472599) [2026-01-25 21:23:41] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=472599) [2026-01-25 21:23:41] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 84869120 bytes
(EngineCore_DP0 pid=472599) [2026-01-25 21:23:41] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=472599) [2026-01-25 21:23:41] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 42434560 bytes
(EngineCore_DP0 pid=472599) Process EngineCore_DP0:
(EngineCore_DP0 pid=472599) Traceback (most recent call last):
(EngineCore_DP0 pid=472599)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=472599)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=472599)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=472599)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=472599) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpu0vslzga.ptx', '-o', '/tmp/tmpu0vslzga.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=472599) 
(EngineCore_DP0 pid=472599) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=472599) 
(EngineCore_DP0 pid=472599) Traceback (most recent call last):
(EngineCore_DP0 pid=472599)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=472599)     self.run()
(EngineCore_DP0 pid=472599)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=472599)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=472599)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=472599)     raise e
(EngineCore_DP0 pid=472599)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=472599)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=472599)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=472599)     super().__init__(
(EngineCore_DP0 pid=472599)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=472599)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=472599)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=472599)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=472599)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=472599)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=472599)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=472599)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=472599)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=472599)     return func(*args, **kwargs)
(EngineCore_DP0 pid=472599)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=472599)     return func(*args, **kwargs)
(EngineCore_DP0 pid=472599)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=472599)     self.model_runner.profile_run()
(EngineCore_DP0 pid=472599)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=472599)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=472599)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=472599)     return func(*args, **kwargs)
(EngineCore_DP0 pid=472599)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=472599)     outputs = self.model(
(EngineCore_DP0 pid=472599)               ^^^^^^^^^^^
(EngineCore_DP0 pid=472599)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=472599)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=472599)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=472599)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=472599)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=472599)     hidden_states = self.model(
(EngineCore_DP0 pid=472599)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=472599)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=472599)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=472599)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=472599)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=472599)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=472599)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=472599)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=472599)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=472599)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=472599)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=472599)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=472599)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=472599)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=472599)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=472599)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=472599)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=472599)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=472599)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=472599)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=472599)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=472599)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=472599)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=472599)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=472599)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=472599)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=472599)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=472599)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=472599)     return self._linear_fn(
(EngineCore_DP0 pid=472599)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=472599)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=472599)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=472599)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=472599)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=472599)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=472599)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=472599)     return fn(input, L)
(EngineCore_DP0 pid=472599)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=472599)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=472599)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=472599)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=472599)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=472599)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=472599)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=472599)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=472599)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=472599)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=472599)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=472599)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=472599)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=472599)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=472599)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=472599)     raise PTXASError(error)
(EngineCore_DP0 pid=472599) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=472599) `ptxas` stderr:
(EngineCore_DP0 pid=472599) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=472599) 
(EngineCore_DP0 pid=472599) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpu0vslzga.ptx -o /tmp/tmpu0vslzga.ptx.o
(EngineCore_DP0 pid=472599) 
[rank0]:[W125 21:23:43.459169329 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=32768

========== M=65536 ==========
Time: 2026-01-25 21:23:45
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Qwen2.5-7B-FP8_M65536.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:24:17 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 21:24:17 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=473929) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=473929) 
(EngineCore_DP0 pid=473929) 
(EngineCore_DP0 pid=473929) ================================================================
(EngineCore_DP0 pid=473929) Internal Triton PTX codegen error
(EngineCore_DP0 pid=473929) `ptxas` stderr:
(EngineCore_DP0 pid=473929) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=473929) 
(EngineCore_DP0 pid=473929) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpramu2fw_.ptx -o /tmp/tmpramu2fw_.ptx.o
(EngineCore_DP0 pid=473929) 
(EngineCore_DP0 pid=473929) 
(EngineCore_DP0 pid=473929) //
(EngineCore_DP0 pid=473929) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=473929) //
(EngineCore_DP0 pid=473929) 
(EngineCore_DP0 pid=473929) .version 8.7
(EngineCore_DP0 pid=473929) .target sm_121a
(EngineCore_DP0 pid=473929) .address_size 64
(EngineCore_DP0 pid=473929) 
(EngineCore_DP0 pid=473929) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=473929) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=473929)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=473929) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=473929) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=473929) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=473929) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=473929) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=473929) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=473929) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=473929) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=473929) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=473929) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=473929) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=473929) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=473929) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=473929) )
(EngineCore_DP0 pid=473929) .reqntid 512
(EngineCore_DP0 pid=473929) {
(EngineCore_DP0 pid=473929) 	.reg .pred 	%p<21>;
(EngineCore_DP0 pid=473929) 	.reg .b16 	%rs<61>;
(EngineCore_DP0 pid=473929) 	.reg .b32 	%r<121>;
(EngineCore_DP0 pid=473929) 	.reg .b64 	%rd<14>;
(EngineCore_DP0 pid=473929) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=473929) $L__func_begin0:
(EngineCore_DP0 pid=473929) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=473929) 
(EngineCore_DP0 pid=473929) // %bb.0:
(EngineCore_DP0 pid=473929) 	ld.param.b32 	%r22, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=473929) 	ld.param.b32 	%r21, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=473929) 	ld.param.b32 	%r20, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=473929) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=473929) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=473929) $L__tmp0:
(EngineCore_DP0 pid=473929) 	.loc	1 143 24                        // quant_slide_tuned_Qwen2.5-7B.py:143:24
(EngineCore_DP0 pid=473929) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=473929) 	ld.param.b32 	%r24, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=473929) 	.loc	1 148 26                        // quant_slide_tuned_Qwen2.5-7B.py:148:26
(EngineCore_DP0 pid=473929) 	mul.lo.s32 	%r25, %r24, %r1;
(EngineCore_DP0 pid=473929) 	.loc	1 148 20                        // quant_slide_tuned_Qwen2.5-7B.py:148:20
(EngineCore_DP0 pid=473929) 	mad.wide.s32 	%rd1, %r25, 2, %rd4;
(EngineCore_DP0 pid=473929) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=473929) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=473929) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=473929) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=473929) 	setp.lt.s32 	%p1, %r21, 1;
(EngineCore_DP0 pid=473929) 	mov.b32 	%r118, 0f2B8CBCCC;
(EngineCore_DP0 pid=473929) 	setp.eq.b32 	%p20, %r2, 0;
(EngineCore_DP0 pid=473929) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=473929) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=473929) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=473929) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=473929) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=473929) 	shr.u32 	%r34, %r2, 3;
(EngineCore_DP0 pid=473929) 	and.b32 	%r35, %r34, 60;
(EngineCore_DP0 pid=473929) 	mov.b32 	%r36, global_smem;
(EngineCore_DP0 pid=473929) 	add.s32 	%r54, %r36, %r35;
(EngineCore_DP0 pid=473929) 	shl.b32 	%r37, %r2, 2;
(EngineCore_DP0 pid=473929) 	add.s32 	%r57, %r36, %r37;
(EngineCore_DP0 pid=473929) 	mov.b32 	%r42, 0;
(EngineCore_DP0 pid=473929) 	mov.b32 	%r116, 0f00000000;
(EngineCore_DP0 pid=473929) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=473929) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=473929) 	mov.b32 	%r117, %r42;
(EngineCore_DP0 pid=473929) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=473929) 	.loc	1 154 19                        // quant_slide_tuned_Qwen2.5-7B.py:154:19
(EngineCore_DP0 pid=473929) 	add.s32 	%r60, %r4, %r117;
(EngineCore_DP0 pid=473929) 	.loc	1 155 22                        // quant_slide_tuned_Qwen2.5-7B.py:155:22
(EngineCore_DP0 pid=473929) 	add.s32 	%r61, %r60, 4096;
(EngineCore_DP0 pid=473929) 	setp.lt.s32 	%p2, %r60, %r20;
(EngineCore_DP0 pid=473929) 	setp.lt.s32 	%p3, %r61, %r20;
(EngineCore_DP0 pid=473929) 	.loc	1 156 29                        // quant_slide_tuned_Qwen2.5-7B.py:156:29
(EngineCore_DP0 pid=473929) 	mad.wide.s32 	%rd6, %r60, 2, %rd1;
(EngineCore_DP0 pid=473929) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=473929) 	.loc	1 156 21                        // quant_slide_tuned_Qwen2.5-7B.py:156:21
(EngineCore_DP0 pid=473929) 	// begin inline asm
(EngineCore_DP0 pid=473929) 	mov.u32 %r38, %r42;
(EngineCore_DP0 pid=473929) 	mov.u32 %r39, %r42;
(EngineCore_DP0 pid=473929) 	mov.u32 %r40, %r42;
(EngineCore_DP0 pid=473929) 	mov.u32 %r41, %r42;
(EngineCore_DP0 pid=473929) 	@%p2 ld.global.v4.b32 { %r38, %r39, %r40, %r41 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=473929) 	// end inline asm
(EngineCore_DP0 pid=473929) 	mov.b32 	{%rs1, %rs2}, %r38;
(EngineCore_DP0 pid=473929) 	mov.b32 	{%rs3, %rs4}, %r39;
(EngineCore_DP0 pid=473929) 	mov.b32 	{%rs5, %rs6}, %r40;
(EngineCore_DP0 pid=473929) 	mov.b32 	{%rs7, %rs8}, %r41;
(EngineCore_DP0 pid=473929) 	// begin inline asm
(EngineCore_DP0 pid=473929) 	mov.u32 %r46, %r42;
(EngineCore_DP0 pid=473929) 	mov.u32 %r47, %r42;
(EngineCore_DP0 pid=473929) 	mov.u32 %r48, %r42;
(EngineCore_DP0 pid=473929) 	mov.u32 %r49, %r42;
(EngineCore_DP0 pid=473929) 	@%p3 ld.global.v4.b32 { %r46, %r47, %r48, %r49 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=473929) 	// end inline asm
(EngineCore_DP0 pid=473929) 	mov.b32 	{%rs9, %rs10}, %r46;
(EngineCore_DP0 pid=473929) 	mov.b32 	{%rs11, %rs12}, %r47;
(EngineCore_DP0 pid=473929) 	mov.b32 	{%rs13, %rs14}, %r48;
(EngineCore_DP0 pid=473929) 	mov.b32 	{%rs15, %rs16}, %r49;
(EngineCore_DP0 pid=473929) 	.loc	1 157 50                        // quant_slide_tuned_Qwen2.5-7B.py:157:50
(EngineCore_DP0 pid=473929) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=473929) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=473929) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=473929) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=473929) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=473929) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=473929) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=473929) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=473929) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=473929) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=473929) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=473929) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=473929) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=473929) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=473929) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=473929) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=473929) $L__tmp1:
(EngineCore_DP0 pid=473929) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=473929) 	bar.sync 	0;
(EngineCore_DP0 pid=473929) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=473929) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=473929) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=473929) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=473929) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=473929) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=473929) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=473929) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=473929) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=473929) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=473929) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=473929) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=473929) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=473929) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=473929) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=473929) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=473929) 	cvt.f32.bf16 	%r62, %rs47;
(EngineCore_DP0 pid=473929) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=473929) 	shfl.sync.bfly.b32 	%r63, %r62, 16, 31, -1;
(EngineCore_DP0 pid=473929) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=473929) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=473929) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=473929) 	shfl.sync.bfly.b32 	%r65, %r64, 8, 31, -1;
(EngineCore_DP0 pid=473929) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=473929) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=473929) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=473929) 	shfl.sync.bfly.b32 	%r67, %r66, 4, 31, -1;
(EngineCore_DP0 pid=473929) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=473929) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=473929) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=473929) 	shfl.sync.bfly.b32 	%r69, %r68, 2, 31, -1;
(EngineCore_DP0 pid=473929) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=473929) 	max.f32 	%r70, %r68, %r69;
(EngineCore_DP0 pid=473929) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=473929) 	shfl.sync.bfly.b32 	%r71, %r70, 1, 31, -1;
(EngineCore_DP0 pid=473929) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=473929) 	max.f32 	%r55, %r70, %r71;
(EngineCore_DP0 pid=473929) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=473929) 	// begin inline asm
(EngineCore_DP0 pid=473929) 	@%p4 st.shared.b32 [ %r54 + 0 ], %r55;
(EngineCore_DP0 pid=473929) 	// end inline asm
(EngineCore_DP0 pid=473929) 	bar.sync 	0;
(EngineCore_DP0 pid=473929) 	// begin inline asm
(EngineCore_DP0 pid=473929) 	@%p5 ld.shared.b32 %r56, [ %r57 + 0 ];
(EngineCore_DP0 pid=473929) 	// end inline asm
(EngineCore_DP0 pid=473929) 	shfl.sync.bfly.b32 	%r72, %r56, 8, 31, -1;
(EngineCore_DP0 pid=473929) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=473929) 	max.f32 	%r73, %r56, %r72;
(EngineCore_DP0 pid=473929) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=473929) 	shfl.sync.bfly.b32 	%r74, %r73, 4, 31, -1;
(EngineCore_DP0 pid=473929) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=473929) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=473929) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=473929) 	shfl.sync.bfly.b32 	%r76, %r75, 2, 31, -1;
(EngineCore_DP0 pid=473929) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=473929) 	max.f32 	%r77, %r75, %r76;
(EngineCore_DP0 pid=473929) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=473929) 	shfl.sync.bfly.b32 	%r78, %r77, 1, 31, -1;
(EngineCore_DP0 pid=473929) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=473929) 	max.f32 	%r59, %r77, %r78;
(EngineCore_DP0 pid=473929) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=473929) 	// begin inline asm
(EngineCore_DP0 pid=473929) 	@%p20 st.shared.b32 [ %r57 + 0 ], %r59;
(EngineCore_DP0 pid=473929) 	// end inline asm
(EngineCore_DP0 pid=473929) 	bar.sync 	0;
(EngineCore_DP0 pid=473929) 	ld.shared.b32 	%r79, [global_smem];
(EngineCore_DP0 pid=473929) $L__tmp2:
(EngineCore_DP0 pid=473929) 	.loc	1 157 36                        // quant_slide_tuned_Qwen2.5-7B.py:157:36
(EngineCore_DP0 pid=473929) 	max.f32 	%r116, %r116, %r79;
(EngineCore_DP0 pid=473929) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=473929) 	add.s32 	%r117, %r117, 8192;
(EngineCore_DP0 pid=473929) 	setp.lt.s32 	%p7, %r117, %r21;
(EngineCore_DP0 pid=473929) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=473929) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=473929) 	.loc	1 159 32                        // quant_slide_tuned_Qwen2.5-7B.py:159:32
(EngineCore_DP0 pid=473929) 	max.f32 	%r118, %r116, 0f2B8CBCCC;
(EngineCore_DP0 pid=473929) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=473929) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-7B.py:0:32
(EngineCore_DP0 pid=473929) 	mov.b32 	%r81, 0f43E00000;
(EngineCore_DP0 pid=473929) 	.loc	1 160 32                        // quant_slide_tuned_Qwen2.5-7B.py:160:32
(EngineCore_DP0 pid=473929) 	div.full.f32 	%r82, %r118, %r81;
(EngineCore_DP0 pid=473929) 	.loc	1 160 41                        // quant_slide_tuned_Qwen2.5-7B.py:160:41
(EngineCore_DP0 pid=473929) 	max.f32 	%r80, %r82, 0f36924925;
(EngineCore_DP0 pid=473929) 	.loc	1 162 25                        // quant_slide_tuned_Qwen2.5-7B.py:162:25
(EngineCore_DP0 pid=473929) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=473929) 	.loc	1 162 30                        // quant_slide_tuned_Qwen2.5-7B.py:162:30
(EngineCore_DP0 pid=473929) 	// begin inline asm
(EngineCore_DP0 pid=473929) 	@%p20 st.global.b32 [ %rd8 + 0 ], { %r80 };
(EngineCore_DP0 pid=473929) 	// end inline asm
(EngineCore_DP0 pid=473929) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=473929) 	setp.lt.s32 	%p9, %r22, 1;
(EngineCore_DP0 pid=473929) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=473929) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=473929) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-7B.py:0:41
(EngineCore_DP0 pid=473929) 	ld.param.b32 	%r26, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=473929) 	shr.s32 	%r27, %r26, 31;
(EngineCore_DP0 pid=473929) 	shr.u32 	%r28, %r27, 30;
(EngineCore_DP0 pid=473929) 	add.s32 	%r29, %r26, %r28;
(EngineCore_DP0 pid=473929) 	shr.s32 	%r30, %r29, 2;
(EngineCore_DP0 pid=473929) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=473929) 	mul.lo.s32 	%r31, %r30, %r1;
(EngineCore_DP0 pid=473929) 	mad.wide.s32 	%rd2, %r31, 4, %rd5;
(EngineCore_DP0 pid=473929) 	div.full.f32 	%r14, %r81, %r118;
(EngineCore_DP0 pid=473929) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=473929) 	shl.b32 	%r119, %r3, 2;
(EngineCore_DP0 pid=473929) 	mov.b32 	%r120, 0;
(EngineCore_DP0 pid=473929) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=473929)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=473929) 	.loc	1 169 30                        // quant_slide_tuned_Qwen2.5-7B.py:169:30
(EngineCore_DP0 pid=473929) 	add.s32 	%r93, %r3, %r120;
(EngineCore_DP0 pid=473929) 	setp.lt.s32 	%p14, %r93, %r22;
(EngineCore_DP0 pid=473929) 	.loc	1 177 53                        // quant_slide_tuned_Qwen2.5-7B.py:177:53
(EngineCore_DP0 pid=473929) 	setp.lt.s32 	%p15, %r119, %r20;
(EngineCore_DP0 pid=473929) 	.loc	1 177 37                        // quant_slide_tuned_Qwen2.5-7B.py:177:37
(EngineCore_DP0 pid=473929) 	and.pred 	%p10, %p14, %p15;
(EngineCore_DP0 pid=473929) 	.loc	1 176 29                        // quant_slide_tuned_Qwen2.5-7B.py:176:29
(EngineCore_DP0 pid=473929) 	mad.wide.s32 	%rd9, %r119, 2, %rd1;
(EngineCore_DP0 pid=473929) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=473929) 	.loc	1 176 21                        // quant_slide_tuned_Qwen2.5-7B.py:176:21
(EngineCore_DP0 pid=473929) 	// begin inline asm
(EngineCore_DP0 pid=473929) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=473929) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=473929) 	// end inline asm
(EngineCore_DP0 pid=473929) 	.loc	1 177 79                        // quant_slide_tuned_Qwen2.5-7B.py:177:79
(EngineCore_DP0 pid=473929) 	cvt.f32.bf16 	%r94, %rs48;
(EngineCore_DP0 pid=473929) 	.loc	1 179 53                        // quant_slide_tuned_Qwen2.5-7B.py:179:53
(EngineCore_DP0 pid=473929) 	add.s32 	%r95, %r119, 1;
(EngineCore_DP0 pid=473929) 	setp.lt.s32 	%p16, %r95, %r20;
(EngineCore_DP0 pid=473929) 	.loc	1 179 37                        // quant_slide_tuned_Qwen2.5-7B.py:179:37
(EngineCore_DP0 pid=473929) 	and.pred 	%p11, %p14, %p16;
(EngineCore_DP0 pid=473929) 	.loc	1 178 39                        // quant_slide_tuned_Qwen2.5-7B.py:178:39
(EngineCore_DP0 pid=473929) 	add.s64 	%rd10, %rd9, 2;
(EngineCore_DP0 pid=473929) 	.loc	1 178 21                        // quant_slide_tuned_Qwen2.5-7B.py:178:21
(EngineCore_DP0 pid=473929) 	// begin inline asm
(EngineCore_DP0 pid=473929) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=473929) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=473929) 	// end inline asm
(EngineCore_DP0 pid=473929) 	.loc	1 179 79                        // quant_slide_tuned_Qwen2.5-7B.py:179:79
(EngineCore_DP0 pid=473929) 	cvt.f32.bf16 	%r96, %rs50;
(EngineCore_DP0 pid=473929) 	.loc	1 181 53                        // quant_slide_tuned_Qwen2.5-7B.py:181:53
(EngineCore_DP0 pid=473929) 	add.s32 	%r97, %r119, 2;
(EngineCore_DP0 pid=473929) 	setp.lt.s32 	%p17, %r97, %r20;
(EngineCore_DP0 pid=473929) 	.loc	1 181 37                        // quant_slide_tuned_Qwen2.5-7B.py:181:37
(EngineCore_DP0 pid=473929) 	and.pred 	%p12, %p14, %p17;
(EngineCore_DP0 pid=473929) 	.loc	1 180 39                        // quant_slide_tuned_Qwen2.5-7B.py:180:39
(EngineCore_DP0 pid=473929) 	add.s64 	%rd11, %rd9, 4;
(EngineCore_DP0 pid=473929) 	.loc	1 180 21                        // quant_slide_tuned_Qwen2.5-7B.py:180:21
(EngineCore_DP0 pid=473929) 	// begin inline asm
(EngineCore_DP0 pid=473929) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=473929) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=473929) 	// end inline asm
(EngineCore_DP0 pid=473929) 	.loc	1 181 79                        // quant_slide_tuned_Qwen2.5-7B.py:181:79
(EngineCore_DP0 pid=473929) 	cvt.f32.bf16 	%r98, %rs52;
(EngineCore_DP0 pid=473929) 	.loc	1 183 53                        // quant_slide_tuned_Qwen2.5-7B.py:183:53
(EngineCore_DP0 pid=473929) 	add.s32 	%r99, %r119, 3;
(EngineCore_DP0 pid=473929) 	setp.lt.s32 	%p18, %r99, %r20;
(EngineCore_DP0 pid=473929) 	.loc	1 183 37                        // quant_slide_tuned_Qwen2.5-7B.py:183:37
(EngineCore_DP0 pid=473929) 	and.pred 	%p13, %p14, %p18;
(EngineCore_DP0 pid=473929) 	.loc	1 182 39                        // quant_slide_tuned_Qwen2.5-7B.py:182:39
(EngineCore_DP0 pid=473929) 	add.s64 	%rd12, %rd9, 6;
(EngineCore_DP0 pid=473929) 	.loc	1 182 21                        // quant_slide_tuned_Qwen2.5-7B.py:182:21
(EngineCore_DP0 pid=473929) 	// begin inline asm
(EngineCore_DP0 pid=473929) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=473929) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=473929) 	// end inline asm
(EngineCore_DP0 pid=473929) 	.loc	1 183 79                        // quant_slide_tuned_Qwen2.5-7B.py:183:79
(EngineCore_DP0 pid=473929) 	cvt.f32.bf16 	%r100, %rs54;
(EngineCore_DP0 pid=473929) 	.loc	1 185 27                        // quant_slide_tuned_Qwen2.5-7B.py:185:27
(EngineCore_DP0 pid=473929) 	mul.f32 	%r101, %r14, %r94;
(EngineCore_DP0 pid=473929) 	mov.b32 	%r102, 0f43E00000;
(EngineCore_DP0 pid=473929) 	.loc	1 185 48                        // quant_slide_tuned_Qwen2.5-7B.py:185:48
(EngineCore_DP0 pid=473929) 	min.xorsign.abs.f32 	%r84, %r101, %r102;
(EngineCore_DP0 pid=473929) 	.loc	1 185 60                        // quant_slide_tuned_Qwen2.5-7B.py:185:60
(EngineCore_DP0 pid=473929) 	// begin inline asm
(EngineCore_DP0 pid=473929) 	cvt.rn.satfinite.e4m3x2.f32  %rs56, %r85, %r84; 
(EngineCore_DP0 pid=473929) 
(EngineCore_DP0 pid=473929) 	// end inline asm
(EngineCore_DP0 pid=473929) 	.loc	1 186 27                        // quant_slide_tuned_Qwen2.5-7B.py:186:27
(EngineCore_DP0 pid=473929) 	mul.f32 	%r103, %r14, %r96;
(EngineCore_DP0 pid=473929) 	.loc	1 186 48                        // quant_slide_tuned_Qwen2.5-7B.py:186:48
(EngineCore_DP0 pid=473929) 	min.xorsign.abs.f32 	%r86, %r103, %r102;
(EngineCore_DP0 pid=473929) 	.loc	1 186 60                        // quant_slide_tuned_Qwen2.5-7B.py:186:60
(EngineCore_DP0 pid=473929) 	// begin inline asm
(EngineCore_DP0 pid=473929) 	cvt.rn.satfinite.e4m3x2.f32  %rs57, %r87, %r86; 
(EngineCore_DP0 pid=473929) 
(EngineCore_DP0 pid=473929) 	// end inline asm
(EngineCore_DP0 pid=473929) 	.loc	1 187 27                        // quant_slide_tuned_Qwen2.5-7B.py:187:27
(EngineCore_DP0 pid=473929) 	mul.f32 	%r104, %r14, %r98;
(EngineCore_DP0 pid=473929) 	.loc	1 187 48                        // quant_slide_tuned_Qwen2.5-7B.py:187:48
(EngineCore_DP0 pid=473929) 	min.xorsign.abs.f32 	%r88, %r104, %r102;
(EngineCore_DP0 pid=473929) 	.loc	1 187 60                        // quant_slide_tuned_Qwen2.5-7B.py:187:60
(EngineCore_DP0 pid=473929) 	// begin inline asm
(EngineCore_DP0 pid=473929) 	cvt.rn.satfinite.e4m3x2.f32  %rs58, %r89, %r88; 
(EngineCore_DP0 pid=473929) 
(EngineCore_DP0 pid=473929) 	// end inline asm
(EngineCore_DP0 pid=473929) 	.loc	1 188 27                        // quant_slide_tuned_Qwen2.5-7B.py:188:27
(EngineCore_DP0 pid=473929) 	mul.f32 	%r105, %r14, %r100;
(EngineCore_DP0 pid=473929) 	.loc	1 188 48                        // quant_slide_tuned_Qwen2.5-7B.py:188:48
(EngineCore_DP0 pid=473929) 	min.xorsign.abs.f32 	%r90, %r105, %r102;
(EngineCore_DP0 pid=473929) 	.loc	1 188 60                        // quant_slide_tuned_Qwen2.5-7B.py:188:60
(EngineCore_DP0 pid=473929) 	// begin inline asm
(EngineCore_DP0 pid=473929) 	cvt.rn.satfinite.e4m3x2.f32  %rs59, %r91, %r90; 
(EngineCore_DP0 pid=473929) 
(EngineCore_DP0 pid=473929) 	// end inline asm
(EngineCore_DP0 pid=473929) 	.loc	1 190 45                        // quant_slide_tuned_Qwen2.5-7B.py:190:45
(EngineCore_DP0 pid=473929) 	cvt.u32.u16 	%r106, %rs56;
(EngineCore_DP0 pid=473929) 	and.b32 	%r107, %r106, 255;
(EngineCore_DP0 pid=473929) 	.loc	1 192 45                        // quant_slide_tuned_Qwen2.5-7B.py:192:45
(EngineCore_DP0 pid=473929) 	cvt.u32.u16 	%r108, %rs58;
(EngineCore_DP0 pid=473929) 	and.b32 	%r109, %r108, 255;
(EngineCore_DP0 pid=473929) 	.loc	1 193 45                        // quant_slide_tuned_Qwen2.5-7B.py:193:45
(EngineCore_DP0 pid=473929) 	cvt.u32.u16 	%r110, %rs59;
(EngineCore_DP0 pid=473929) 	.loc	1 195 30                        // quant_slide_tuned_Qwen2.5-7B.py:195:30
(EngineCore_DP0 pid=473929) 	and.b16 	%rs60, %rs57, 255;
(EngineCore_DP0 pid=473929) 	mul.wide.u16 	%r111, %rs60, 256;
(EngineCore_DP0 pid=473929) 	.loc	1 195 24                        // quant_slide_tuned_Qwen2.5-7B.py:195:24
(EngineCore_DP0 pid=473929) 	or.b32 	%r112, %r111, %r107;
(EngineCore_DP0 pid=473929) 	.loc	1 195 42                        // quant_slide_tuned_Qwen2.5-7B.py:195:42
(EngineCore_DP0 pid=473929) 	shl.b32 	%r113, %r109, 16;
(EngineCore_DP0 pid=473929) 	.loc	1 195 36                        // quant_slide_tuned_Qwen2.5-7B.py:195:36
(EngineCore_DP0 pid=473929) 	or.b32 	%r114, %r112, %r113;
(EngineCore_DP0 pid=473929) 	.loc	1 195 55                        // quant_slide_tuned_Qwen2.5-7B.py:195:55
(EngineCore_DP0 pid=473929) 	shl.b32 	%r115, %r110, 24;
(EngineCore_DP0 pid=473929) 	.loc	1 195 49                        // quant_slide_tuned_Qwen2.5-7B.py:195:49
(EngineCore_DP0 pid=473929) 	or.b32 	%r92, %r114, %r115;
(EngineCore_DP0 pid=473929) 	.loc	1 196 29                        // quant_slide_tuned_Qwen2.5-7B.py:196:29
(EngineCore_DP0 pid=473929) 	mad.wide.s32 	%rd13, %r93, 4, %rd2;
(EngineCore_DP0 pid=473929) 	.loc	1 196 39                        // quant_slide_tuned_Qwen2.5-7B.py:196:39
(EngineCore_DP0 pid=473929) 	// begin inline asm
(EngineCore_DP0 pid=473929) 	@%p14 st.global.b32 [ %rd13 + 0 ], { %r92 };
(EngineCore_DP0 pid=473929) 	// end inline asm
(EngineCore_DP0 pid=473929) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=473929) 	add.s32 	%r120, %r120, 512;
(EngineCore_DP0 pid=473929) 	add.s32 	%r119, %r119, 2048;
(EngineCore_DP0 pid=473929) 	setp.lt.s32 	%p19, %r120, %r22;
(EngineCore_DP0 pid=473929) 	@%p19 bra 	$L__BB0_6;
(EngineCore_DP0 pid=473929) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=473929) 	.loc	1 167 4                         // quant_slide_tuned_Qwen2.5-7B.py:167:4
(EngineCore_DP0 pid=473929) 	ret;
(EngineCore_DP0 pid=473929) $L__tmp3:
(EngineCore_DP0 pid=473929) $L__func_end0:
(EngineCore_DP0 pid=473929)                                         // -- End function
(EngineCore_DP0 pid=473929) }
(EngineCore_DP0 pid=473929) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py"
(EngineCore_DP0 pid=473929) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=473929) 	.section	.debug_abbrev
(EngineCore_DP0 pid=473929) 	{
(EngineCore_DP0 pid=473929) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=473929) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=473929) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=473929) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=473929) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=473929) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=473929) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=473929) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=473929) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=473929) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=473929) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=473929) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=473929) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=473929) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=473929) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=473929) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=473929) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=473929) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=473929) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=473929) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=473929) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=473929) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=473929) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=473929) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=473929) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=473929) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=473929) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=473929) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=473929) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=473929) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=473929) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=473929) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=473929) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=473929) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=473929) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=473929) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=473929) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=473929) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=473929) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=473929) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=473929) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=473929) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=473929) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=473929) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=473929) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=473929) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=473929) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=473929) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=473929) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=473929) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=473929) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=473929) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=473929) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=473929) 	}
(EngineCore_DP0 pid=473929) 	.section	.debug_info
(EngineCore_DP0 pid=473929) 	{
(EngineCore_DP0 pid=473929) .b32 221                                // Length of Unit
(EngineCore_DP0 pid=473929) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=473929) .b8 0
(EngineCore_DP0 pid=473929) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=473929) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=473929) .b8 1                                   // Abbrev [1] 0xb:0xd6 DW_TAG_compile_unit
(EngineCore_DP0 pid=473929) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=473929) .b8 114
(EngineCore_DP0 pid=473929) .b8 105
(EngineCore_DP0 pid=473929) .b8 116
(EngineCore_DP0 pid=473929) .b8 111
(EngineCore_DP0 pid=473929) .b8 110
(EngineCore_DP0 pid=473929) .b8 0
(EngineCore_DP0 pid=473929) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=473929) .b8 0
(EngineCore_DP0 pid=473929) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=473929) .b8 117
(EngineCore_DP0 pid=473929) .b8 97
(EngineCore_DP0 pid=473929) .b8 110
(EngineCore_DP0 pid=473929) .b8 116
(EngineCore_DP0 pid=473929) .b8 95
(EngineCore_DP0 pid=473929) .b8 115
(EngineCore_DP0 pid=473929) .b8 108
(EngineCore_DP0 pid=473929) .b8 105
(EngineCore_DP0 pid=473929) .b8 100
(EngineCore_DP0 pid=473929) .b8 101
(EngineCore_DP0 pid=473929) .b8 95
(EngineCore_DP0 pid=473929) .b8 116
(EngineCore_DP0 pid=473929) .b8 117
(EngineCore_DP0 pid=473929) .b8 110
(EngineCore_DP0 pid=473929) .b8 101
(EngineCore_DP0 pid=473929) .b8 100
(EngineCore_DP0 pid=473929) .b8 95
(EngineCore_DP0 pid=473929) .b8 81
(EngineCore_DP0 pid=473929) .b8 119
(EngineCore_DP0 pid=473929) .b8 101
(EngineCore_DP0 pid=473929) .b8 110
(EngineCore_DP0 pid=473929) .b8 50
(EngineCore_DP0 pid=473929) .b8 46
(EngineCore_DP0 pid=473929) .b8 53
(EngineCore_DP0 pid=473929) .b8 45
(EngineCore_DP0 pid=473929) .b8 55
(EngineCore_DP0 pid=473929) .b8 66
(EngineCore_DP0 pid=473929) .b8 46
(EngineCore_DP0 pid=473929) .b8 112
(EngineCore_DP0 pid=473929) .b8 121
(EngineCore_DP0 pid=473929) .b8 0
(EngineCore_DP0 pid=473929) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=473929) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=473929) .b8 114
(EngineCore_DP0 pid=473929) .b8 111
(EngineCore_DP0 pid=473929) .b8 111
(EngineCore_DP0 pid=473929) .b8 116
(EngineCore_DP0 pid=473929) .b8 47
(EngineCore_DP0 pid=473929) .b8 118
(EngineCore_DP0 pid=473929) .b8 108
(EngineCore_DP0 pid=473929) .b8 108
(EngineCore_DP0 pid=473929) .b8 109
(EngineCore_DP0 pid=473929) .b8 98
(EngineCore_DP0 pid=473929) .b8 101
(EngineCore_DP0 pid=473929) .b8 110
(EngineCore_DP0 pid=473929) .b8 99
(EngineCore_DP0 pid=473929) .b8 104
(EngineCore_DP0 pid=473929) .b8 47
(EngineCore_DP0 pid=473929) .b8 115
(EngineCore_DP0 pid=473929) .b8 108
(EngineCore_DP0 pid=473929) .b8 105
(EngineCore_DP0 pid=473929) .b8 100
(EngineCore_DP0 pid=473929) .b8 101
(EngineCore_DP0 pid=473929) .b8 115
(EngineCore_DP0 pid=473929) .b8 112
(EngineCore_DP0 pid=473929) .b8 97
(EngineCore_DP0 pid=473929) .b8 114
(EngineCore_DP0 pid=473929) .b8 115
(EngineCore_DP0 pid=473929) .b8 101
(EngineCore_DP0 pid=473929) .b8 47
(EngineCore_DP0 pid=473929) .b8 99
(EngineCore_DP0 pid=473929) .b8 115
(EngineCore_DP0 pid=473929) .b8 114
(EngineCore_DP0 pid=473929) .b8 99
(EngineCore_DP0 pid=473929) .b8 47
(EngineCore_DP0 pid=473929) .b8 102
(EngineCore_DP0 pid=473929) .b8 117
(EngineCore_DP0 pid=473929) .b8 115
(EngineCore_DP0 pid=473929) .b8 101
(EngineCore_DP0 pid=473929) .b8 100
(EngineCore_DP0 pid=473929) .b8 95
(EngineCore_DP0 pid=473929) .b8 113
(EngineCore_DP0 pid=473929) .b8 117
(EngineCore_DP0 pid=473929) .b8 97
(EngineCore_DP0 pid=473929) .b8 110
(EngineCore_DP0 pid=473929) .b8 116
(EngineCore_DP0 pid=473929) .b8 95
(EngineCore_DP0 pid=473929) .b8 115
(EngineCore_DP0 pid=473929) .b8 108
(EngineCore_DP0 pid=473929) .b8 105
(EngineCore_DP0 pid=473929) .b8 100
(EngineCore_DP0 pid=473929) .b8 101
(EngineCore_DP0 pid=473929) .b8 95
(EngineCore_DP0 pid=473929) .b8 116
(EngineCore_DP0 pid=473929) .b8 114
(EngineCore_DP0 pid=473929) .b8 105
(EngineCore_DP0 pid=473929) .b8 116
(EngineCore_DP0 pid=473929) .b8 111
(EngineCore_DP0 pid=473929) .b8 110
(EngineCore_DP0 pid=473929) .b8 47
(EngineCore_DP0 pid=473929) .b8 98
(EngineCore_DP0 pid=473929) .b8 117
(EngineCore_DP0 pid=473929) .b8 105
(EngineCore_DP0 pid=473929) .b8 108
(EngineCore_DP0 pid=473929) .b8 100
(EngineCore_DP0 pid=473929) .b8 47
(EngineCore_DP0 pid=473929) .b8 71
(EngineCore_DP0 pid=473929) .b8 66
(EngineCore_DP0 pid=473929) .b8 49
(EngineCore_DP0 pid=473929) .b8 48
(EngineCore_DP0 pid=473929) .b8 95
(EngineCore_DP0 pid=473929) .b8 99
(EngineCore_DP0 pid=473929) .b8 99
(EngineCore_DP0 pid=473929) .b8 49
(EngineCore_DP0 pid=473929) .b8 50
(EngineCore_DP0 pid=473929) .b8 49
(EngineCore_DP0 pid=473929) .b8 95
(EngineCore_DP0 pid=473929) .b8 112
(EngineCore_DP0 pid=473929) .b8 121
(EngineCore_DP0 pid=473929) .b8 51
(EngineCore_DP0 pid=473929) .b8 49
(EngineCore_DP0 pid=473929) .b8 50
(EngineCore_DP0 pid=473929) .b8 95
(EngineCore_DP0 pid=473929) .b8 99
(EngineCore_DP0 pid=473929) .b8 117
(EngineCore_DP0 pid=473929) .b8 49
(EngineCore_DP0 pid=473929) .b8 50
(EngineCore_DP0 pid=473929) .b8 57
(EngineCore_DP0 pid=473929) .b8 95
(EngineCore_DP0 pid=473929) .b8 97
(EngineCore_DP0 pid=473929) .b8 97
(EngineCore_DP0 pid=473929) .b8 114
(EngineCore_DP0 pid=473929) .b8 99
(EngineCore_DP0 pid=473929) .b8 104
(EngineCore_DP0 pid=473929) .b8 54
(EngineCore_DP0 pid=473929) .b8 52
(EngineCore_DP0 pid=473929) .b8 0
(EngineCore_DP0 pid=473929) .b8 2                                   // Abbrev [2] 0x98:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=473929) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=473929) .b8 113
(EngineCore_DP0 pid=473929) .b8 117
(EngineCore_DP0 pid=473929) .b8 97
(EngineCore_DP0 pid=473929) .b8 110
(EngineCore_DP0 pid=473929) .b8 116
(EngineCore_DP0 pid=473929) .b8 95
(EngineCore_DP0 pid=473929) .b8 115
(EngineCore_DP0 pid=473929) .b8 108
(EngineCore_DP0 pid=473929) .b8 105
(EngineCore_DP0 pid=473929) .b8 100
(EngineCore_DP0 pid=473929) .b8 101
(EngineCore_DP0 pid=473929) .b8 95
(EngineCore_DP0 pid=473929) .b8 102
(EngineCore_DP0 pid=473929) .b8 112
(EngineCore_DP0 pid=473929) .b8 56
(EngineCore_DP0 pid=473929) .b8 95
(EngineCore_DP0 pid=473929) .b8 107
(EngineCore_DP0 pid=473929) .b8 101
(EngineCore_DP0 pid=473929) .b8 114
(EngineCore_DP0 pid=473929) .b8 110
(EngineCore_DP0 pid=473929) .b8 101
(EngineCore_DP0 pid=473929) .b8 108
(EngineCore_DP0 pid=473929) .b8 0
(EngineCore_DP0 pid=473929) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=473929) .b8 3                                   // Abbrev [3] 0xb2:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=473929) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=473929) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=473929) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=473929) .b8 4                                   // Abbrev [4] 0xc7:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=473929) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=473929) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=473929) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=473929) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=473929) .b8 157                                 // DW_AT_call_line
(EngineCore_DP0 pid=473929) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=473929) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=473929) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=473929) 	}
(EngineCore_DP0 pid=473929) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=473929) 
(EngineCore_DP0 pid=473929) ================================================================
(EngineCore_DP0 pid=473929) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=473929) 
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpramu2fw_.ptx', '-o', '/tmp/tmpramu2fw_.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866] 
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866] 
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866] 
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpramu2fw_.ptx -o /tmp/tmpramu2fw_.ptx.o
(EngineCore_DP0 pid=473929) ERROR 01-25 21:25:03 [core.py:866] 

STDERR:
[2026-01-25 21:24:17] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:24:17] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:24:17] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:24:17] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:24:17] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:24:17] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:24:17] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:24:17] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:24:17] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:24:17] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:24:17] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:24:17] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:24:17] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:24:17] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:24:20] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:24:20] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:24:20] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:24:20] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:24:20] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:24:20] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:24:20] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:24:20] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:24:20] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:24:20] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:24:20] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:24:20] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:24:20] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:24:20] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=473929) [2026-01-25 21:24:21] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=473929) [2026-01-25 21:24:21] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=473929) [2026-01-25 21:24:21] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=473929) [2026-01-25 21:24:21] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=473929) [2026-01-25 21:24:21] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=473929) [2026-01-25 21:24:21] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=473929) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=473929) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:20<00:20, 20.32s/it]
(EngineCore_DP0 pid=473929) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:40<00:00, 20.06s/it]
(EngineCore_DP0 pid=473929) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:40<00:00, 20.10s/it]
(EngineCore_DP0 pid=473929) 
(EngineCore_DP0 pid=473929) [2026-01-25 21:25:02] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=473929) [2026-01-25 21:25:02] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10321920 bytes
(EngineCore_DP0 pid=473929) [2026-01-25 21:25:02] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=473929) [2026-01-25 21:25:02] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8028160 bytes
(EngineCore_DP0 pid=473929) [2026-01-25 21:25:02] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=473929) [2026-01-25 21:25:02] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 84869120 bytes
(EngineCore_DP0 pid=473929) [2026-01-25 21:25:02] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=473929) [2026-01-25 21:25:02] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 42434560 bytes
(EngineCore_DP0 pid=473929) Process EngineCore_DP0:
(EngineCore_DP0 pid=473929) Traceback (most recent call last):
(EngineCore_DP0 pid=473929)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=473929)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=473929)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=473929)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=473929) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpramu2fw_.ptx', '-o', '/tmp/tmpramu2fw_.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=473929) 
(EngineCore_DP0 pid=473929) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=473929) 
(EngineCore_DP0 pid=473929) Traceback (most recent call last):
(EngineCore_DP0 pid=473929)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=473929)     self.run()
(EngineCore_DP0 pid=473929)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=473929)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=473929)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=473929)     raise e
(EngineCore_DP0 pid=473929)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=473929)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=473929)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=473929)     super().__init__(
(EngineCore_DP0 pid=473929)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=473929)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=473929)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=473929)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=473929)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=473929)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=473929)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=473929)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=473929)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=473929)     return func(*args, **kwargs)
(EngineCore_DP0 pid=473929)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=473929)     return func(*args, **kwargs)
(EngineCore_DP0 pid=473929)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=473929)     self.model_runner.profile_run()
(EngineCore_DP0 pid=473929)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=473929)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=473929)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=473929)     return func(*args, **kwargs)
(EngineCore_DP0 pid=473929)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=473929)     outputs = self.model(
(EngineCore_DP0 pid=473929)               ^^^^^^^^^^^
(EngineCore_DP0 pid=473929)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=473929)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=473929)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=473929)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=473929)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=473929)     hidden_states = self.model(
(EngineCore_DP0 pid=473929)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=473929)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=473929)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=473929)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=473929)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=473929)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=473929)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=473929)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=473929)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=473929)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=473929)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=473929)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=473929)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=473929)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=473929)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=473929)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=473929)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=473929)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=473929)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=473929)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=473929)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=473929)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=473929)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=473929)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=473929)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=473929)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=473929)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=473929)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=473929)     return self._linear_fn(
(EngineCore_DP0 pid=473929)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=473929)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=473929)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=473929)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=473929)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=473929)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=473929)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=473929)     return fn(input, L)
(EngineCore_DP0 pid=473929)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=473929)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=473929)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=473929)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=473929)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=473929)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=473929)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=473929)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=473929)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=473929)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=473929)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=473929)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=473929)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=473929)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=473929)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=473929)     raise PTXASError(error)
(EngineCore_DP0 pid=473929) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=473929) `ptxas` stderr:
(EngineCore_DP0 pid=473929) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=473929) 
(EngineCore_DP0 pid=473929) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpramu2fw_.ptx -o /tmp/tmpramu2fw_.ptx.o
(EngineCore_DP0 pid=473929) 
[rank0]:[W125 21:25:04.256741402 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=65536

========== M=16 ==========
Time: 2026-01-26 02:35:48
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4
Params: prompt_len=16, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4 --dataset-name random --input-len 16 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 17 --max-num-batched-tokens 17 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Llama3.2-1B-FP8_M16.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 02:35:52 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 02:35:52 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=752053) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=752053) WARNING 01-26 02:36:11 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 96.70 requests/s, 1643.88 total tokens/s, 96.70 output tokens/s
Total num prompt tokens:  2048
Total num output tokens:  128

STDERR:
[2026-01-26 02:35:52] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 02:35:52] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 02:35:52] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 02:35:52] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:35:52] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:35:52] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:35:52] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:35:52] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:35:52] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 02:35:52] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:35:52] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:35:52] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:35:52] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:35:52] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 02:35:55] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 02:35:55] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 02:35:55] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 02:35:55] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:35:55] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:35:55] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:35:55] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:35:55] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:35:55] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 02:35:55] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:35:55] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:35:55] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:35:55] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:35:55] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=752053) [2026-01-26 02:35:56] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=752053) [2026-01-26 02:35:56] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=752053) [2026-01-26 02:35:56] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=752053) [2026-01-26 02:35:56] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=752053) [2026-01-26 02:35:56] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=752053) [2026-01-26 02:35:56] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=752053) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=752053) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.37s/it]
(EngineCore_DP0 pid=752053) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.37s/it]
(EngineCore_DP0 pid=752053) 
(EngineCore_DP0 pid=752053) [2026-01-26 02:36:05] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=752053) [2026-01-26 02:36:05] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=752053) [2026-01-26 02:36:05] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=752053) [2026-01-26 02:36:05] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 2621440 bytes
(EngineCore_DP0 pid=752053) [2026-01-26 02:36:05] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=752053) [2026-01-26 02:36:05] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 20971520 bytes
(EngineCore_DP0 pid=752053) [2026-01-26 02:36:05] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=752053) [2026-01-26 02:36:05] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10485760 bytes
(EngineCore_DP0 pid=752053) 2026-01-26 02:36:10,924 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=752053) 2026-01-26 02:36:10,933 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 13034.96it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:26,  4.82it/s, est. speed input: 77.18 toks/s, output: 4.82 toks/s]
Processed prompts:  10%|         | 13/128 [00:00<00:02, 50.42it/s, est. speed input: 662.27 toks/s, output: 41.39 toks/s]
Processed prompts:  20%|        | 25/128 [00:00<00:01, 74.30it/s, est. speed input: 954.89 toks/s, output: 59.68 toks/s]
Processed prompts:  29%|       | 37/128 [00:00<00:01, 88.73it/s, est. speed input: 1133.83 toks/s, output: 70.86 toks/s]
Processed prompts:  38%|      | 49/128 [00:00<00:00, 98.09it/s, est. speed input: 1255.56 toks/s, output: 78.47 toks/s]
Processed prompts:  48%|     | 61/128 [00:00<00:00, 103.70it/s, est. speed input: 1340.10 toks/s, output: 83.75 toks/s]
Processed prompts:  57%|    | 73/128 [00:00<00:00, 107.41it/s, est. speed input: 1403.45 toks/s, output: 87.71 toks/s]
Processed prompts:  66%|   | 85/128 [00:00<00:00, 109.95it/s, est. speed input: 1452.91 toks/s, output: 90.81 toks/s]
Processed prompts:  76%|  | 97/128 [00:01<00:00, 112.24it/s, est. speed input: 1494.90 toks/s, output: 93.43 toks/s]
Processed prompts:  85%| | 109/128 [00:01<00:00, 111.89it/s, est. speed input: 1521.56 toks/s, output: 95.10 toks/s]
Processed prompts:  95%|| 121/128 [00:01<00:00, 112.07it/s, est. speed input: 1545.25 toks/s, output: 96.58 toks/s]
Processed prompts: 100%|| 128/128 [00:01<00:00, 112.07it/s, est. speed input: 1559.72 toks/s, output: 97.48 toks/s]
Processed prompts: 100%|| 128/128 [00:01<00:00, 97.47it/s, est. speed input: 1559.72 toks/s, output: 97.48 toks/s] 
[rank0]:[W126 02:36:13.391709711 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=128 ==========
Time: 2026-01-26 02:36:15
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4
Params: prompt_len=128, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4 --dataset-name random --input-len 128 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 129 --max-num-batched-tokens 129 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Llama3.2-1B-FP8_M128.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 02:36:19 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 02:36:19 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=752628) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=752628) WARNING 01-26 02:36:38 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 84.31 requests/s, 10876.39 total tokens/s, 84.31 output tokens/s
Total num prompt tokens:  16384
Total num output tokens:  128

STDERR:
[2026-01-26 02:36:19] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 02:36:19] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 02:36:19] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 02:36:19] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:36:19] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:36:19] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:36:19] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:36:19] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:36:19] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 02:36:19] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:36:19] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:36:19] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:36:19] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:36:19] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 02:36:22] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 02:36:22] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 02:36:22] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 02:36:22] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:36:22] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:36:22] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:36:22] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:36:22] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:36:22] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 02:36:22] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:36:22] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:36:22] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:36:22] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:36:22] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=752628) [2026-01-26 02:36:23] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=752628) [2026-01-26 02:36:23] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=752628) [2026-01-26 02:36:23] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=752628) [2026-01-26 02:36:23] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=752628) [2026-01-26 02:36:23] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=752628) [2026-01-26 02:36:23] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=752628) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=752628) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.36s/it]
(EngineCore_DP0 pid=752628) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.36s/it]
(EngineCore_DP0 pid=752628) 
(EngineCore_DP0 pid=752628) [2026-01-26 02:36:32] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=752628) [2026-01-26 02:36:32] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=752628) [2026-01-26 02:36:32] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=752628) [2026-01-26 02:36:32] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 2621440 bytes
(EngineCore_DP0 pid=752628) [2026-01-26 02:36:32] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=752628) [2026-01-26 02:36:32] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 20971520 bytes
(EngineCore_DP0 pid=752628) [2026-01-26 02:36:32] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=752628) [2026-01-26 02:36:32] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10485760 bytes
(EngineCore_DP0 pid=752628) 2026-01-26 02:36:38,106 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=752628) 2026-01-26 02:36:38,113 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 1860.83it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:21,  6.02it/s, est. speed input: 770.89 toks/s, output: 6.02 toks/s]
Processed prompts:   9%|         | 11/128 [00:00<00:02, 47.99it/s, est. speed input: 5161.72 toks/s, output: 40.32 toks/s]
Processed prompts:  16%|        | 21/128 [00:00<00:01, 68.16it/s, est. speed input: 7200.97 toks/s, output: 56.25 toks/s]
Processed prompts:  24%|       | 31/128 [00:00<00:01, 79.20it/s, est. speed input: 8362.17 toks/s, output: 65.33 toks/s]
Processed prompts:  33%|      | 42/128 [00:00<00:00, 86.80it/s, est. speed input: 9204.94 toks/s, output: 71.91 toks/s]
Processed prompts:  41%|      | 52/128 [00:00<00:00, 90.97it/s, est. speed input: 9729.20 toks/s, output: 76.01 toks/s]
Processed prompts:  49%|     | 63/128 [00:00<00:00, 94.19it/s, est. speed input: 10163.93 toks/s, output: 79.40 toks/s]
Processed prompts:  58%|    | 74/128 [00:00<00:00, 96.13it/s, est. speed input: 10487.21 toks/s, output: 81.93 toks/s]
Processed prompts:  66%|   | 85/128 [00:01<00:00, 97.23it/s, est. speed input: 10733.72 toks/s, output: 83.86 toks/s]
Processed prompts:  75%|  | 96/128 [00:01<00:00, 98.36it/s, est. speed input: 10945.63 toks/s, output: 85.51 toks/s]
Processed prompts:  83%| | 106/128 [00:01<00:00, 97.57it/s, est. speed input: 11056.55 toks/s, output: 86.38 toks/s]
Processed prompts:  91%| | 116/128 [00:01<00:00, 97.63it/s, est. speed input: 11168.60 toks/s, output: 87.25 toks/s]
Processed prompts:  99%|| 127/128 [00:01<00:00, 98.58it/s, est. speed input: 11299.37 toks/s, output: 88.28 toks/s]
Processed prompts: 100%|| 128/128 [00:01<00:00, 98.58it/s, est. speed input: 11311.74 toks/s, output: 88.37 toks/s]
Processed prompts: 100%|| 128/128 [00:01<00:00, 88.37it/s, est. speed input: 11311.74 toks/s, output: 88.37 toks/s]
[rank0]:[W126 02:36:40.665456140 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=256 ==========
Time: 2026-01-26 02:36:42
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4
Params: prompt_len=256, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4 --dataset-name random --input-len 256 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 257 --max-num-batched-tokens 257 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Llama3.2-1B-FP8_M256.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 02:36:46 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 02:36:46 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=753182) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=753182) WARNING 01-26 02:37:05 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 76.10 requests/s, 19558.70 total tokens/s, 76.10 output tokens/s
Total num prompt tokens:  32768
Total num output tokens:  128

STDERR:
[2026-01-26 02:36:46] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 02:36:46] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 02:36:46] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 02:36:46] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:36:46] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:36:46] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:36:46] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:36:46] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:36:46] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 02:36:46] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:36:46] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:36:46] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:36:46] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:36:46] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 02:36:49] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 02:36:49] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 02:36:49] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 02:36:49] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:36:49] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:36:49] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:36:49] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:36:49] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:36:49] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 02:36:49] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:36:49] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:36:49] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:36:49] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:36:49] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=753182) [2026-01-26 02:36:50] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=753182) [2026-01-26 02:36:50] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=753182) [2026-01-26 02:36:50] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=753182) [2026-01-26 02:36:50] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=753182) [2026-01-26 02:36:50] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=753182) [2026-01-26 02:36:50] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=753182) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=753182) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.08s/it]
(EngineCore_DP0 pid=753182) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.08s/it]
(EngineCore_DP0 pid=753182) 
(EngineCore_DP0 pid=753182) [2026-01-26 02:36:59] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=753182) [2026-01-26 02:36:59] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=753182) [2026-01-26 02:36:59] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=753182) [2026-01-26 02:36:59] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 2621440 bytes
(EngineCore_DP0 pid=753182) [2026-01-26 02:36:59] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=753182) [2026-01-26 02:36:59] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 20971520 bytes
(EngineCore_DP0 pid=753182) [2026-01-26 02:36:59] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=753182) [2026-01-26 02:36:59] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10485760 bytes
(EngineCore_DP0 pid=753182) 2026-01-26 02:37:04,491 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=753182) 2026-01-26 02:37:04,498 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 2150.29it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:19,  6.50it/s, est. speed input: 1665.44 toks/s, output: 6.51 toks/s]
Processed prompts:   8%|         | 10/128 [00:00<00:02, 45.25it/s, est. speed input: 9828.31 toks/s, output: 38.39 toks/s]
Processed prompts:  15%|        | 19/128 [00:00<00:01, 62.14it/s, est. speed input: 13344.58 toks/s, output: 52.12 toks/s]
Processed prompts:  22%|       | 28/128 [00:00<00:01, 71.14it/s, est. speed input: 15299.19 toks/s, output: 59.76 toks/s]
Processed prompts:  29%|       | 37/128 [00:00<00:01, 76.61it/s, est. speed input: 16561.55 toks/s, output: 64.69 toks/s]
Processed prompts:  36%|      | 46/128 [00:00<00:01, 79.76it/s, est. speed input: 17409.03 toks/s, output: 68.00 toks/s]
Processed prompts:  43%|     | 55/128 [00:00<00:00, 82.04it/s, est. speed input: 18050.61 toks/s, output: 70.51 toks/s]
Processed prompts:  50%|     | 64/128 [00:00<00:00, 83.61it/s, est. speed input: 18546.63 toks/s, output: 72.45 toks/s]
Processed prompts:  57%|    | 73/128 [00:00<00:00, 83.54it/s, est. speed input: 18851.64 toks/s, output: 73.64 toks/s]
Processed prompts:  64%|   | 82/128 [00:01<00:00, 84.72it/s, est. speed input: 19184.29 toks/s, output: 74.94 toks/s]
Processed prompts:  71%|   | 91/128 [00:01<00:00, 85.27it/s, est. speed input: 19441.50 toks/s, output: 75.94 toks/s]
Processed prompts:  78%|  | 100/128 [00:01<00:00, 86.18it/s, est. speed input: 19689.78 toks/s, output: 76.91 toks/s]
Processed prompts:  85%| | 109/128 [00:01<00:00, 86.72it/s, est. speed input: 19896.56 toks/s, output: 77.72 toks/s]
Processed prompts:  92%|| 118/128 [00:01<00:00, 86.92it/s, est. speed input: 20065.49 toks/s, output: 78.38 toks/s]
Processed prompts:  99%|| 127/128 [00:01<00:00, 86.89it/s, est. speed input: 20204.71 toks/s, output: 78.92 toks/s]
Processed prompts: 100%|| 128/128 [00:01<00:00, 86.89it/s, est. speed input: 20215.40 toks/s, output: 78.97 toks/s]
Processed prompts: 100%|| 128/128 [00:01<00:00, 78.96it/s, est. speed input: 20215.40 toks/s, output: 78.97 toks/s]
[rank0]:[W126 02:37:07.208136237 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-26 04:07:47
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Llama3.2-1B-FP8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 04:07:50 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 04:07:50 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=840830) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=840830) WARNING 01-26 04:08:09 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 56.59 requests/s, 29032.12 total tokens/s, 56.59 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-26 04:07:50] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 04:07:50] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 04:07:50] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 04:07:50] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:07:50] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:07:50] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:07:50] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:07:50] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:07:50] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 04:07:50] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 04:07:50] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:07:50] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:07:50] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:07:50] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 04:07:54] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 04:07:54] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 04:07:54] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 04:07:54] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:07:54] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:07:54] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:07:54] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:07:54] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:07:54] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 04:07:54] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 04:07:54] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:07:54] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:07:54] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:07:54] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=840830) [2026-01-26 04:07:55] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=840830) [2026-01-26 04:07:55] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=840830) [2026-01-26 04:07:55] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=840830) [2026-01-26 04:07:55] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=840830) [2026-01-26 04:07:55] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=840830) [2026-01-26 04:07:55] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=840830) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=840830) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.15s/it]
(EngineCore_DP0 pid=840830) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.15s/it]
(EngineCore_DP0 pid=840830) 
(EngineCore_DP0 pid=840830) [2026-01-26 04:08:03] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=840830) [2026-01-26 04:08:03] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=840830) [2026-01-26 04:08:03] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=840830) [2026-01-26 04:08:03] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 2621440 bytes
(EngineCore_DP0 pid=840830) [2026-01-26 04:08:03] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=840830) [2026-01-26 04:08:03] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 20971520 bytes
(EngineCore_DP0 pid=840830) [2026-01-26 04:08:03] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=840830) [2026-01-26 04:08:03] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10485760 bytes
(EngineCore_DP0 pid=840830) 2026-01-26 04:08:08,912 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=840830) 2026-01-26 04:08:08,919 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  92%|| 118/128 [00:00<00:00, 1169.62it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 1165.81it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   4%|         | 5/128 [00:00<00:02, 49.80it/s, est. speed input: 25501.04 toks/s, output: 49.80 toks/s]
Processed prompts:   9%|         | 11/128 [00:00<00:02, 54.45it/s, est. speed input: 27531.42 toks/s, output: 53.77 toks/s]
Processed prompts:  14%|        | 18/128 [00:00<00:01, 57.08it/s, est. speed input: 28657.91 toks/s, output: 55.97 toks/s]
Processed prompts:  20%|        | 25/128 [00:00<00:01, 58.68it/s, est. speed input: 29336.37 toks/s, output: 57.30 toks/s]
Processed prompts:  25%|       | 32/128 [00:00<00:01, 59.28it/s, est. speed input: 29659.28 toks/s, output: 57.93 toks/s]
Processed prompts:  30%|       | 39/128 [00:00<00:01, 59.74it/s, est. speed input: 29896.68 toks/s, output: 58.39 toks/s]
Processed prompts:  35%|      | 45/128 [00:00<00:01, 59.77it/s, est. speed input: 29994.08 toks/s, output: 58.58 toks/s]
Processed prompts:  40%|      | 51/128 [00:00<00:01, 59.83it/s, est. speed input: 30075.70 toks/s, output: 58.74 toks/s]
Processed prompts:  45%|     | 57/128 [00:00<00:01, 59.81it/s, est. speed input: 30130.11 toks/s, output: 58.85 toks/s]
Processed prompts:  50%|     | 64/128 [00:01<00:01, 59.74it/s, est. speed input: 30171.48 toks/s, output: 58.93 toks/s]
Processed prompts:  55%|    | 70/128 [00:01<00:00, 59.41it/s, est. speed input: 30158.56 toks/s, output: 58.90 toks/s]
Processed prompts:  60%|    | 77/128 [00:01<00:00, 59.70it/s, est. speed input: 30221.78 toks/s, output: 59.03 toks/s]
Processed prompts:  65%|   | 83/128 [00:01<00:00, 59.70it/s, est. speed input: 30246.73 toks/s, output: 59.07 toks/s]
Processed prompts:  70%|   | 89/128 [00:01<00:00, 59.73it/s, est. speed input: 30271.72 toks/s, output: 59.12 toks/s]
Processed prompts:  75%|  | 96/128 [00:01<00:00, 60.21it/s, est. speed input: 30348.09 toks/s, output: 59.27 toks/s]
Processed prompts:  80%|  | 103/128 [00:01<00:00, 60.56it/s, est. speed input: 30416.86 toks/s, output: 59.41 toks/s]
Processed prompts:  86%| | 110/128 [00:01<00:00, 61.01it/s, est. speed input: 30498.44 toks/s, output: 59.57 toks/s]
Processed prompts:  91%|| 117/128 [00:01<00:00, 60.45it/s, est. speed input: 30488.28 toks/s, output: 59.55 toks/s]
Processed prompts:  97%|| 124/128 [00:02<00:00, 60.31it/s, est. speed input: 30501.05 toks/s, output: 59.57 toks/s]
Processed prompts: 100%|| 128/128 [00:02<00:00, 60.31it/s, est. speed input: 30467.83 toks/s, output: 59.51 toks/s]
Processed prompts: 100%|| 128/128 [00:02<00:00, 59.50it/s, est. speed input: 30467.83 toks/s, output: 59.51 toks/s]
[rank0]:[W126 04:08:12.252435229 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-26 04:08:14
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Llama3.2-1B-FP8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 04:08:18 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 04:08:18 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=841407) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=841407) WARNING 01-26 04:08:37 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 31.10 requests/s, 31878.31 total tokens/s, 31.10 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-26 04:08:18] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 04:08:18] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 04:08:18] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 04:08:18] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:08:18] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:08:18] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:08:18] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:08:18] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:08:18] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 04:08:18] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 04:08:18] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:08:18] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:08:18] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:08:18] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 04:08:21] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 04:08:21] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 04:08:21] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 04:08:21] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:08:21] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:08:21] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:08:21] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:08:21] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:08:21] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 04:08:21] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 04:08:21] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:08:21] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:08:21] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:08:21] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=841407) [2026-01-26 04:08:22] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=841407) [2026-01-26 04:08:22] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=841407) [2026-01-26 04:08:22] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=841407) [2026-01-26 04:08:22] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=841407) [2026-01-26 04:08:22] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=841407) [2026-01-26 04:08:22] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=841407) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=841407) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.38s/it]
(EngineCore_DP0 pid=841407) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.38s/it]
(EngineCore_DP0 pid=841407) 
(EngineCore_DP0 pid=841407) [2026-01-26 04:08:31] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=841407) [2026-01-26 04:08:31] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=841407) [2026-01-26 04:08:31] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=841407) [2026-01-26 04:08:31] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 2621440 bytes
(EngineCore_DP0 pid=841407) [2026-01-26 04:08:31] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=841407) [2026-01-26 04:08:31] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 20971520 bytes
(EngineCore_DP0 pid=841407) [2026-01-26 04:08:31] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=841407) [2026-01-26 04:08:31] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10485760 bytes
(EngineCore_DP0 pid=841407) 2026-01-26 04:08:36,757 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=841407) 2026-01-26 04:08:36,764 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  45%|     | 58/128 [00:00<00:00, 573.66it/s]
Adding requests:  91%| | 116/128 [00:00<00:00, 552.64it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 555.60it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   7%|         | 9/128 [00:00<00:01, 72.70it/s, est. speed input: 74457.68 toks/s, output: 72.71 toks/s]
Processed prompts:  13%|        | 17/128 [00:00<00:02, 42.11it/s, est. speed input: 46207.58 toks/s, output: 45.12 toks/s]
Processed prompts:  17%|        | 22/128 [00:00<00:02, 38.03it/s, est. speed input: 42216.17 toks/s, output: 41.22 toks/s]
Processed prompts:  21%|        | 27/128 [00:00<00:02, 35.13it/s, est. speed input: 39565.53 toks/s, output: 38.64 toks/s]
Processed prompts:  24%|       | 31/128 [00:00<00:02, 34.18it/s, est. speed input: 38505.95 toks/s, output: 37.60 toks/s]
Processed prompts:  27%|       | 35/128 [00:00<00:02, 33.30it/s, est. speed input: 37626.37 toks/s, output: 36.74 toks/s]
Processed prompts:  30%|       | 39/128 [00:01<00:02, 33.02it/s, est. speed input: 37104.73 toks/s, output: 36.23 toks/s]
Processed prompts:  34%|      | 43/128 [00:01<00:02, 32.71it/s, est. speed input: 36649.79 toks/s, output: 35.79 toks/s]
Processed prompts:  37%|      | 47/128 [00:01<00:02, 32.63it/s, est. speed input: 36329.16 toks/s, output: 35.48 toks/s]
Processed prompts:  40%|      | 51/128 [00:01<00:02, 32.46it/s, est. speed input: 36027.78 toks/s, output: 35.18 toks/s]
Processed prompts:  43%|     | 55/128 [00:01<00:02, 32.33it/s, est. speed input: 35773.12 toks/s, output: 34.93 toks/s]
Processed prompts:  46%|     | 59/128 [00:01<00:02, 31.95it/s, est. speed input: 35474.80 toks/s, output: 34.64 toks/s]
Processed prompts:  49%|     | 63/128 [00:01<00:02, 31.93it/s, est. speed input: 35281.07 toks/s, output: 34.45 toks/s]
Processed prompts:  52%|    | 67/128 [00:01<00:01, 31.93it/s, est. speed input: 35113.74 toks/s, output: 34.29 toks/s]
Processed prompts:  55%|    | 71/128 [00:02<00:01, 31.82it/s, est. speed input: 34943.45 toks/s, output: 34.12 toks/s]
Processed prompts:  59%|    | 75/128 [00:02<00:01, 31.66it/s, est. speed input: 34775.87 toks/s, output: 33.96 toks/s]
Processed prompts:  62%|   | 79/128 [00:02<00:01, 31.67it/s, est. speed input: 34651.49 toks/s, output: 33.84 toks/s]
Processed prompts:  65%|   | 83/128 [00:02<00:01, 31.88it/s, est. speed input: 34575.86 toks/s, output: 33.77 toks/s]
Processed prompts:  68%|   | 87/128 [00:02<00:01, 31.93it/s, est. speed input: 34491.28 toks/s, output: 33.68 toks/s]
Processed prompts:  71%|   | 91/128 [00:02<00:01, 31.61it/s, est. speed input: 34355.19 toks/s, output: 33.55 toks/s]
Processed prompts:  74%|  | 95/128 [00:02<00:01, 31.48it/s, est. speed input: 34245.64 toks/s, output: 33.44 toks/s]
Processed prompts:  77%|  | 99/128 [00:02<00:00, 31.58it/s, est. speed input: 34174.77 toks/s, output: 33.37 toks/s]
Processed prompts:  80%|  | 103/128 [00:03<00:00, 31.62it/s, est. speed input: 34105.83 toks/s, output: 33.31 toks/s]
Processed prompts:  84%| | 107/128 [00:03<00:00, 31.69it/s, est. speed input: 34048.18 toks/s, output: 33.25 toks/s]
Processed prompts:  87%| | 111/128 [00:03<00:00, 31.67it/s, est. speed input: 33984.59 toks/s, output: 33.19 toks/s]
Processed prompts:  90%| | 115/128 [00:03<00:00, 31.85it/s, est. speed input: 33951.71 toks/s, output: 33.16 toks/s]
Processed prompts:  93%|| 119/128 [00:03<00:00, 31.68it/s, est. speed input: 33882.99 toks/s, output: 33.09 toks/s]
Processed prompts:  96%|| 123/128 [00:03<00:00, 31.69it/s, est. speed input: 33835.30 toks/s, output: 33.04 toks/s]
Processed prompts:  99%|| 127/128 [00:03<00:00, 31.34it/s, est. speed input: 33748.96 toks/s, output: 32.96 toks/s]
Processed prompts: 100%|| 128/128 [00:03<00:00, 31.34it/s, est. speed input: 33744.14 toks/s, output: 32.95 toks/s]
Processed prompts: 100%|| 128/128 [00:03<00:00, 32.95it/s, est. speed input: 33744.14 toks/s, output: 32.95 toks/s]
[rank0]:[W126 04:08:41.923383339 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-26 04:08:43
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Llama3.2-1B-FP8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 04:08:48 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 04:08:48 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=842011) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=842011) WARNING 01-26 04:09:07 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 33.42 requests/s, 34252.93 total tokens/s, 33.42 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-26 04:08:48] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 04:08:48] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 04:08:48] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 04:08:48] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:08:48] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:08:48] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:08:48] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:08:48] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:08:48] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 04:08:48] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 04:08:48] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:08:48] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:08:48] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:08:48] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 04:08:51] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 04:08:51] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 04:08:51] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 04:08:51] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:08:51] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:08:51] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:08:51] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:08:51] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:08:51] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 04:08:51] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 04:08:51] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:08:51] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:08:51] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:08:51] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=842011) [2026-01-26 04:08:52] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=842011) [2026-01-26 04:08:52] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=842011) [2026-01-26 04:08:52] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=842011) [2026-01-26 04:08:52] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=842011) [2026-01-26 04:08:52] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=842011) [2026-01-26 04:08:52] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=842011) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=842011) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.17s/it]
(EngineCore_DP0 pid=842011) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.17s/it]
(EngineCore_DP0 pid=842011) 
(EngineCore_DP0 pid=842011) [2026-01-26 04:09:01] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=842011) [2026-01-26 04:09:01] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=842011) [2026-01-26 04:09:01] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=842011) [2026-01-26 04:09:01] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 2621440 bytes
(EngineCore_DP0 pid=842011) [2026-01-26 04:09:01] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=842011) [2026-01-26 04:09:01] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 20971520 bytes
(EngineCore_DP0 pid=842011) [2026-01-26 04:09:01] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=842011) [2026-01-26 04:09:01] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10485760 bytes
(EngineCore_DP0 pid=842011) 2026-01-26 04:09:06,386 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=842011) 2026-01-26 04:09:06,393 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  21%|        | 54/256 [00:00<00:00, 538.27it/s]
Adding requests:  42%|     | 108/256 [00:00<00:00, 511.48it/s]
Adding requests:  62%|   | 160/256 [00:00<00:00, 501.80it/s]
Adding requests:  83%| | 212/256 [00:00<00:00, 506.85it/s]
Adding requests: 100%|| 256/256 [00:00<00:00, 510.88it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|         | 16/256 [00:00<00:01, 125.29it/s, est. speed input: 128327.93 toks/s, output: 125.31 toks/s]
Processed prompts:  11%|        | 29/256 [00:00<00:04, 55.03it/s, est. speed input: 62120.11 toks/s, output: 60.66 toks/s]   
Processed prompts:  14%|        | 37/256 [00:00<00:04, 45.95it/s, est. speed input: 53137.21 toks/s, output: 51.89 toks/s]
Processed prompts:  17%|        | 43/256 [00:00<00:05, 42.31it/s, est. speed input: 49616.18 toks/s, output: 48.45 toks/s]
Processed prompts:  19%|        | 48/256 [00:01<00:05, 37.65it/s, est. speed input: 46009.55 toks/s, output: 44.93 toks/s]
Processed prompts:  21%|        | 53/256 [00:01<00:05, 38.58it/s, est. speed input: 45669.01 toks/s, output: 44.60 toks/s]
Processed prompts:  23%|       | 58/256 [00:01<00:05, 35.30it/s, est. speed input: 43554.05 toks/s, output: 42.53 toks/s]
Processed prompts:  24%|       | 62/256 [00:01<00:05, 35.00it/s, est. speed input: 42865.28 toks/s, output: 41.86 toks/s]
Processed prompts:  26%|       | 66/256 [00:01<00:05, 34.86it/s, est. speed input: 42312.25 toks/s, output: 41.32 toks/s]
Processed prompts:  27%|       | 70/256 [00:01<00:05, 34.74it/s, est. speed input: 41830.92 toks/s, output: 40.85 toks/s]
Processed prompts:  29%|       | 74/256 [00:01<00:05, 34.63it/s, est. speed input: 41406.73 toks/s, output: 40.44 toks/s]
Processed prompts:  30%|       | 78/256 [00:01<00:05, 34.33it/s, est. speed input: 40977.99 toks/s, output: 40.02 toks/s]
Processed prompts:  32%|      | 82/256 [00:02<00:05, 33.98it/s, est. speed input: 40565.76 toks/s, output: 39.61 toks/s]
Processed prompts:  34%|      | 86/256 [00:02<00:05, 33.98it/s, est. speed input: 40256.84 toks/s, output: 39.31 toks/s]
Processed prompts:  35%|      | 90/256 [00:02<00:04, 33.89it/s, est. speed input: 39958.09 toks/s, output: 39.02 toks/s]
Processed prompts:  37%|      | 94/256 [00:02<00:04, 34.06it/s, est. speed input: 39734.56 toks/s, output: 38.80 toks/s]
Processed prompts:  38%|      | 98/256 [00:02<00:04, 33.97it/s, est. speed input: 39494.90 toks/s, output: 38.57 toks/s]
Processed prompts:  40%|      | 102/256 [00:02<00:04, 33.93it/s, est. speed input: 39279.16 toks/s, output: 38.36 toks/s]
Processed prompts:  41%|     | 106/256 [00:02<00:04, 34.08it/s, est. speed input: 39111.59 toks/s, output: 38.19 toks/s]
Processed prompts:  43%|     | 110/256 [00:02<00:04, 34.09it/s, est. speed input: 38941.64 toks/s, output: 38.03 toks/s]
Processed prompts:  45%|     | 114/256 [00:03<00:04, 34.06it/s, est. speed input: 38779.39 toks/s, output: 37.87 toks/s]
Processed prompts:  46%|     | 118/256 [00:03<00:04, 33.65it/s, est. speed input: 38574.00 toks/s, output: 37.67 toks/s]
Processed prompts:  48%|     | 122/256 [00:03<00:03, 33.95it/s, est. speed input: 38465.25 toks/s, output: 37.56 toks/s]
Processed prompts:  49%|     | 126/256 [00:03<00:03, 33.95it/s, est. speed input: 38335.69 toks/s, output: 37.44 toks/s]
Processed prompts:  51%|     | 130/256 [00:03<00:03, 34.11it/s, est. speed input: 38234.48 toks/s, output: 37.34 toks/s]
Processed prompts:  52%|    | 134/256 [00:03<00:03, 34.03it/s, est. speed input: 38117.89 toks/s, output: 37.22 toks/s]
Processed prompts:  54%|    | 138/256 [00:03<00:03, 34.16it/s, est. speed input: 38029.70 toks/s, output: 37.14 toks/s]
Processed prompts:  55%|    | 142/256 [00:03<00:03, 34.15it/s, est. speed input: 37935.60 toks/s, output: 37.05 toks/s]
Processed prompts:  57%|    | 146/256 [00:03<00:03, 33.99it/s, est. speed input: 37829.72 toks/s, output: 36.94 toks/s]
Processed prompts:  59%|    | 150/256 [00:04<00:03, 34.15it/s, est. speed input: 37759.30 toks/s, output: 36.87 toks/s]
Processed prompts:  60%|    | 154/256 [00:04<00:03, 33.76it/s, est. speed input: 37640.52 toks/s, output: 36.76 toks/s]
Processed prompts:  62%|   | 158/256 [00:04<00:02, 33.84it/s, est. speed input: 37564.00 toks/s, output: 36.68 toks/s]
Processed prompts:  63%|   | 162/256 [00:04<00:02, 33.81it/s, est. speed input: 37483.33 toks/s, output: 36.60 toks/s]
Processed prompts:  65%|   | 166/256 [00:04<00:02, 33.95it/s, est. speed input: 37421.78 toks/s, output: 36.54 toks/s]
Processed prompts:  66%|   | 170/256 [00:04<00:02, 34.01it/s, est. speed input: 37360.44 toks/s, output: 36.48 toks/s]
Processed prompts:  68%|   | 174/256 [00:04<00:02, 34.15it/s, est. speed input: 37310.80 toks/s, output: 36.44 toks/s]
Processed prompts:  70%|   | 178/256 [00:04<00:02, 34.32it/s, est. speed input: 37269.48 toks/s, output: 36.40 toks/s]
Processed prompts:  71%|   | 182/256 [00:05<00:02, 34.26it/s, est. speed input: 37215.07 toks/s, output: 36.34 toks/s]
Processed prompts:  73%|  | 186/256 [00:05<00:02, 34.20it/s, est. speed input: 37161.79 toks/s, output: 36.29 toks/s]
Processed prompts:  74%|  | 190/256 [00:05<00:01, 33.81it/s, est. speed input: 37081.84 toks/s, output: 36.21 toks/s]
Processed prompts:  76%|  | 194/256 [00:05<00:01, 33.69it/s, est. speed input: 37018.10 toks/s, output: 36.15 toks/s]
Processed prompts:  77%|  | 198/256 [00:05<00:01, 34.07it/s, est. speed input: 36992.93 toks/s, output: 36.13 toks/s]
Processed prompts:  79%|  | 202/256 [00:05<00:01, 34.18it/s, est. speed input: 36956.88 toks/s, output: 36.09 toks/s]
Processed prompts:  80%|  | 206/256 [00:05<00:01, 34.16it/s, est. speed input: 36915.49 toks/s, output: 36.05 toks/s]
Processed prompts:  82%| | 210/256 [00:05<00:01, 34.23it/s, est. speed input: 36881.98 toks/s, output: 36.02 toks/s]
Processed prompts:  84%| | 214/256 [00:05<00:01, 34.05it/s, est. speed input: 36833.07 toks/s, output: 35.97 toks/s]
Processed prompts:  85%| | 218/256 [00:06<00:01, 34.02it/s, est. speed input: 36793.02 toks/s, output: 35.93 toks/s]
Processed prompts:  87%| | 222/256 [00:06<00:00, 34.12it/s, est. speed input: 36762.78 toks/s, output: 35.90 toks/s]
Processed prompts:  88%| | 226/256 [00:06<00:00, 33.56it/s, est. speed input: 36690.59 toks/s, output: 35.83 toks/s]
Processed prompts:  90%| | 230/256 [00:06<00:00, 33.77it/s, est. speed input: 36661.37 toks/s, output: 35.80 toks/s]
Processed prompts:  91%|| 234/256 [00:06<00:00, 33.97it/s, est. speed input: 36636.59 toks/s, output: 35.78 toks/s]
Processed prompts:  93%|| 238/256 [00:06<00:00, 33.91it/s, est. speed input: 36600.07 toks/s, output: 35.74 toks/s]
Processed prompts:  95%|| 242/256 [00:06<00:00, 34.02it/s, est. speed input: 36574.16 toks/s, output: 35.72 toks/s]
Processed prompts:  96%|| 246/256 [00:06<00:00, 34.24it/s, est. speed input: 36558.06 toks/s, output: 35.70 toks/s]
Processed prompts:  98%|| 250/256 [00:07<00:00, 34.20it/s, est. speed input: 36530.68 toks/s, output: 35.67 toks/s]
Processed prompts:  99%|| 254/256 [00:07<00:00, 33.99it/s, est. speed input: 36493.69 toks/s, output: 35.64 toks/s]
Processed prompts: 100%|| 256/256 [00:07<00:00, 33.99it/s, est. speed input: 36620.20 toks/s, output: 35.76 toks/s]
Processed prompts: 100%|| 256/256 [00:07<00:00, 35.76it/s, est. speed input: 36620.20 toks/s, output: 35.76 toks/s]
[rank0]:[W126 04:09:14.125233728 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-26 04:09:17
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Llama3.2-1B-FP8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 04:09:22 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 04:09:22 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=842666) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=842666) WARNING 01-26 04:09:41 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 33.14 requests/s, 33968.02 total tokens/s, 33.14 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-26 04:09:22] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 04:09:22] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 04:09:22] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 04:09:22] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:09:22] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:09:22] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:09:22] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:09:22] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:09:22] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 04:09:22] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 04:09:22] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:09:22] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:09:22] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:09:22] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 04:09:25] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 04:09:25] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 04:09:25] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 04:09:25] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:09:25] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:09:25] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:09:25] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:09:25] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:09:25] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 04:09:25] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 04:09:25] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:09:25] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:09:25] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:09:25] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=842666) [2026-01-26 04:09:26] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=842666) [2026-01-26 04:09:26] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=842666) [2026-01-26 04:09:26] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=842666) [2026-01-26 04:09:26] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=842666) [2026-01-26 04:09:26] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=842666) [2026-01-26 04:09:26] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=842666) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=842666) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.20s/it]
(EngineCore_DP0 pid=842666) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.20s/it]
(EngineCore_DP0 pid=842666) 
(EngineCore_DP0 pid=842666) [2026-01-26 04:09:35] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=842666) [2026-01-26 04:09:35] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=842666) [2026-01-26 04:09:35] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=842666) [2026-01-26 04:09:35] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 2621440 bytes
(EngineCore_DP0 pid=842666) [2026-01-26 04:09:35] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=842666) [2026-01-26 04:09:35] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 20971520 bytes
(EngineCore_DP0 pid=842666) [2026-01-26 04:09:35] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=842666) [2026-01-26 04:09:35] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10485760 bytes
(EngineCore_DP0 pid=842666) 2026-01-26 04:09:40,393 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=842666) 2026-01-26 04:09:40,412 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:  11%|         | 55/512 [00:00<00:00, 541.20it/s]
Adding requests:  21%|       | 110/512 [00:00<00:00, 516.82it/s]
Adding requests:  32%|      | 162/512 [00:00<00:00, 497.50it/s]
Adding requests:  41%|     | 212/512 [00:00<00:00, 491.09it/s]
Adding requests:  51%|    | 263/512 [00:00<00:00, 495.46it/s]
Adding requests:  61%|    | 313/512 [00:00<00:00, 488.14it/s]
Adding requests:  71%|   | 364/512 [00:00<00:00, 492.99it/s]
Adding requests:  81%|  | 414/512 [00:00<00:00, 481.10it/s]
Adding requests:  90%| | 463/512 [00:00<00:00, 482.66it/s]
Adding requests: 100%|| 512/512 [00:01<00:00, 475.47it/s]
Adding requests: 100%|| 512/512 [00:01<00:00, 487.58it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   7%|         | 34/512 [00:00<00:02, 191.94it/s, est. speed input: 196562.83 toks/s, output: 191.94 toks/s]
Processed prompts:  11%|         | 54/512 [00:00<00:07, 60.90it/s, est. speed input: 71592.53 toks/s, output: 69.91 toks/s]   
Processed prompts:  12%|        | 64/512 [00:01<00:08, 54.89it/s, est. speed input: 64904.15 toks/s, output: 63.38 toks/s]
Processed prompts:  14%|        | 72/512 [00:01<00:09, 47.63it/s, est. speed input: 58665.61 toks/s, output: 57.29 toks/s]
Processed prompts:  15%|        | 78/512 [00:01<00:10, 40.92it/s, est. speed input: 53562.43 toks/s, output: 52.31 toks/s]
Processed prompts:  16%|        | 83/512 [00:01<00:10, 41.14it/s, est. speed input: 52795.84 toks/s, output: 51.56 toks/s]
Processed prompts:  17%|        | 88/512 [00:01<00:10, 41.35it/s, est. speed input: 52134.62 toks/s, output: 50.91 toks/s]
Processed prompts:  18%|        | 93/512 [00:01<00:10, 41.33it/s, est. speed input: 51486.51 toks/s, output: 50.28 toks/s]
Processed prompts:  19%|        | 98/512 [00:02<00:12, 33.41it/s, est. speed input: 48095.96 toks/s, output: 46.97 toks/s]
Processed prompts:  20%|        | 102/512 [00:02<00:12, 33.47it/s, est. speed input: 47359.48 toks/s, output: 46.25 toks/s]
Processed prompts:  21%|        | 106/512 [00:02<00:12, 33.16it/s, est. speed input: 46594.43 toks/s, output: 45.50 toks/s]
Processed prompts:  21%|       | 110/512 [00:02<00:12, 33.27it/s, est. speed input: 45999.84 toks/s, output: 44.92 toks/s]
Processed prompts:  22%|       | 114/512 [00:02<00:11, 33.20it/s, est. speed input: 45426.16 toks/s, output: 44.36 toks/s]
Processed prompts:  23%|       | 118/512 [00:02<00:11, 33.35it/s, est. speed input: 44947.35 toks/s, output: 43.89 toks/s]
Processed prompts:  24%|       | 122/512 [00:02<00:11, 33.44it/s, est. speed input: 44503.22 toks/s, output: 43.46 toks/s]
Processed prompts:  25%|       | 126/512 [00:02<00:11, 33.41it/s, est. speed input: 44078.83 toks/s, output: 43.05 toks/s]
Processed prompts:  25%|       | 130/512 [00:03<00:11, 33.36it/s, est. speed input: 43682.37 toks/s, output: 42.66 toks/s]
Processed prompts:  26%|       | 134/512 [00:03<00:11, 33.53it/s, est. speed input: 43349.82 toks/s, output: 42.33 toks/s]
Processed prompts:  27%|       | 138/512 [00:03<00:11, 33.47it/s, est. speed input: 43012.96 toks/s, output: 42.00 toks/s]
Processed prompts:  28%|       | 142/512 [00:03<00:11, 33.11it/s, est. speed input: 42651.54 toks/s, output: 41.65 toks/s]
Processed prompts:  29%|       | 146/512 [00:03<00:10, 33.46it/s, est. speed input: 42402.78 toks/s, output: 41.41 toks/s]
Processed prompts:  29%|       | 150/512 [00:03<00:10, 33.69it/s, est. speed input: 42167.18 toks/s, output: 41.18 toks/s]
Processed prompts:  30%|       | 154/512 [00:03<00:10, 33.65it/s, est. speed input: 41920.24 toks/s, output: 40.94 toks/s]
Processed prompts:  31%|       | 158/512 [00:03<00:10, 33.72it/s, est. speed input: 41701.11 toks/s, output: 40.72 toks/s]
Processed prompts:  32%|      | 162/512 [00:03<00:10, 33.75it/s, est. speed input: 41491.73 toks/s, output: 40.52 toks/s]
Processed prompts:  32%|      | 166/512 [00:04<00:10, 33.73it/s, est. speed input: 41290.01 toks/s, output: 40.32 toks/s]
Processed prompts:  33%|      | 170/512 [00:04<00:10, 33.74it/s, est. speed input: 41102.24 toks/s, output: 40.14 toks/s]
Processed prompts:  34%|      | 174/512 [00:04<00:10, 33.67it/s, est. speed input: 40916.44 toks/s, output: 39.96 toks/s]
Processed prompts:  35%|      | 178/512 [00:04<00:10, 33.34it/s, est. speed input: 40709.15 toks/s, output: 39.75 toks/s]
Processed prompts:  36%|      | 182/512 [00:04<00:09, 33.25it/s, est. speed input: 40528.65 toks/s, output: 39.58 toks/s]
Processed prompts:  36%|      | 186/512 [00:04<00:09, 33.28it/s, est. speed input: 40366.53 toks/s, output: 39.42 toks/s]
Processed prompts:  37%|      | 190/512 [00:04<00:09, 33.65it/s, est. speed input: 40246.36 toks/s, output: 39.30 toks/s]
Processed prompts:  38%|      | 194/512 [00:04<00:09, 33.54it/s, est. speed input: 40097.43 toks/s, output: 39.16 toks/s]
Processed prompts:  39%|      | 198/512 [00:05<00:09, 33.67it/s, est. speed input: 39974.33 toks/s, output: 39.04 toks/s]
Processed prompts:  39%|      | 202/512 [00:05<00:09, 33.73it/s, est. speed input: 39853.30 toks/s, output: 38.92 toks/s]
Processed prompts:  40%|      | 206/512 [00:05<00:09, 33.67it/s, est. speed input: 39730.11 toks/s, output: 38.80 toks/s]
Processed prompts:  41%|      | 210/512 [00:05<00:09, 33.47it/s, est. speed input: 39597.60 toks/s, output: 38.67 toks/s]
Processed prompts:  42%|     | 214/512 [00:05<00:08, 33.15it/s, est. speed input: 39455.39 toks/s, output: 38.53 toks/s]
Processed prompts:  43%|     | 218/512 [00:05<00:08, 33.41it/s, est. speed input: 39360.36 toks/s, output: 38.44 toks/s]
Processed prompts:  43%|     | 222/512 [00:05<00:08, 33.51it/s, est. speed input: 39261.82 toks/s, output: 38.34 toks/s]
Processed prompts:  44%|     | 226/512 [00:05<00:08, 33.59it/s, est. speed input: 39167.91 toks/s, output: 38.25 toks/s]
Processed prompts:  45%|     | 230/512 [00:06<00:08, 33.61it/s, est. speed input: 39075.07 toks/s, output: 38.16 toks/s]
Processed prompts:  46%|     | 234/512 [00:06<00:08, 33.51it/s, est. speed input: 38977.21 toks/s, output: 38.06 toks/s]
Processed prompts:  46%|     | 238/512 [00:06<00:08, 33.44it/s, est. speed input: 38883.63 toks/s, output: 37.97 toks/s]
Processed prompts:  47%|     | 242/512 [00:06<00:08, 33.42it/s, est. speed input: 38795.43 toks/s, output: 37.89 toks/s]
Processed prompts:  48%|     | 246/512 [00:06<00:08, 33.23it/s, est. speed input: 38697.97 toks/s, output: 37.79 toks/s]
Processed prompts:  49%|     | 250/512 [00:06<00:07, 33.24it/s, est. speed input: 38613.34 toks/s, output: 37.71 toks/s]
Processed prompts:  50%|     | 254/512 [00:06<00:07, 33.18it/s, est. speed input: 38527.48 toks/s, output: 37.62 toks/s]
Processed prompts:  50%|     | 258/512 [00:06<00:07, 33.27it/s, est. speed input: 38453.96 toks/s, output: 37.55 toks/s]
Processed prompts:  51%|     | 262/512 [00:06<00:07, 33.41it/s, est. speed input: 38387.88 toks/s, output: 37.49 toks/s]
Processed prompts:  52%|    | 266/512 [00:07<00:07, 33.44it/s, est. speed input: 38319.26 toks/s, output: 37.42 toks/s]
Processed prompts:  53%|    | 270/512 [00:07<00:07, 33.44it/s, est. speed input: 38252.28 toks/s, output: 37.36 toks/s]
Processed prompts:  54%|    | 274/512 [00:07<00:07, 33.40it/s, est. speed input: 38184.35 toks/s, output: 37.29 toks/s]
Processed prompts:  54%|    | 278/512 [00:07<00:06, 33.57it/s, est. speed input: 38131.04 toks/s, output: 37.24 toks/s]
Processed prompts:  55%|    | 282/512 [00:07<00:06, 33.40it/s, est. speed input: 38061.70 toks/s, output: 37.17 toks/s]
Processed prompts:  56%|    | 286/512 [00:07<00:06, 33.19it/s, est. speed input: 37989.36 toks/s, output: 37.10 toks/s]
Processed prompts:  57%|    | 290/512 [00:07<00:06, 33.32it/s, est. speed input: 37935.41 toks/s, output: 37.05 toks/s]
Processed prompts:  57%|    | 294/512 [00:07<00:06, 33.39it/s, est. speed input: 37881.61 toks/s, output: 36.99 toks/s]
Processed prompts:  58%|    | 298/512 [00:08<00:06, 33.31it/s, est. speed input: 37822.29 toks/s, output: 36.94 toks/s]
Processed prompts:  59%|    | 302/512 [00:08<00:06, 33.50it/s, est. speed input: 37778.30 toks/s, output: 36.89 toks/s]
Processed prompts:  60%|    | 306/512 [00:08<00:06, 33.72it/s, est. speed input: 37740.36 toks/s, output: 36.86 toks/s]
Processed prompts:  61%|    | 310/512 [00:08<00:05, 33.68it/s, est. speed input: 37693.00 toks/s, output: 36.81 toks/s]
Processed prompts:  61%|   | 314/512 [00:08<00:05, 33.75it/s, est. speed input: 37651.98 toks/s, output: 36.77 toks/s]
Processed prompts:  62%|   | 318/512 [00:08<00:05, 33.31it/s, est. speed input: 37587.21 toks/s, output: 36.71 toks/s]
Processed prompts:  63%|   | 322/512 [00:08<00:05, 33.35it/s, est. speed input: 37541.46 toks/s, output: 36.66 toks/s]
Processed prompts:  64%|   | 326/512 [00:08<00:05, 33.48it/s, est. speed input: 37502.55 toks/s, output: 36.62 toks/s]
Processed prompts:  64%|   | 330/512 [00:09<00:05, 33.35it/s, est. speed input: 37453.01 toks/s, output: 36.58 toks/s]
Processed prompts:  65%|   | 334/512 [00:09<00:05, 33.30it/s, est. speed input: 37407.57 toks/s, output: 36.53 toks/s]
Processed prompts:  66%|   | 338/512 [00:09<00:05, 33.20it/s, est. speed input: 37359.61 toks/s, output: 36.48 toks/s]
Processed prompts:  67%|   | 342/512 [00:09<00:05, 33.57it/s, est. speed input: 37334.02 toks/s, output: 36.46 toks/s]
Processed prompts:  68%|   | 346/512 [00:09<00:04, 33.53it/s, est. speed input: 37295.36 toks/s, output: 36.42 toks/s]
Processed prompts:  68%|   | 350/512 [00:09<00:04, 33.45it/s, est. speed input: 37254.64 toks/s, output: 36.38 toks/s]
Processed prompts:  69%|   | 354/512 [00:09<00:04, 33.15it/s, est. speed input: 37204.32 toks/s, output: 36.33 toks/s]
Processed prompts:  70%|   | 358/512 [00:09<00:04, 33.31it/s, est. speed input: 37171.76 toks/s, output: 36.30 toks/s]
Processed prompts:  71%|   | 362/512 [00:09<00:04, 33.31it/s, est. speed input: 37134.90 toks/s, output: 36.26 toks/s]
Processed prompts:  71%|  | 366/512 [00:10<00:04, 33.23it/s, est. speed input: 37095.23 toks/s, output: 36.23 toks/s]
Processed prompts:  72%|  | 370/512 [00:10<00:04, 33.42it/s, est. speed input: 37067.55 toks/s, output: 36.20 toks/s]
Processed prompts:  73%|  | 374/512 [00:10<00:04, 33.63it/s, est. speed input: 37043.49 toks/s, output: 36.18 toks/s]
Processed prompts:  74%|  | 378/512 [00:10<00:03, 33.58it/s, est. speed input: 37011.57 toks/s, output: 36.14 toks/s]
Processed prompts:  75%|  | 382/512 [00:10<00:03, 33.58it/s, est. speed input: 36982.07 toks/s, output: 36.12 toks/s]
Processed prompts:  75%|  | 386/512 [00:10<00:03, 33.37it/s, est. speed input: 36944.58 toks/s, output: 36.08 toks/s]
Processed prompts:  76%|  | 390/512 [00:10<00:03, 33.13it/s, est. speed input: 36903.85 toks/s, output: 36.04 toks/s]
Processed prompts:  77%|  | 394/512 [00:10<00:03, 33.18it/s, est. speed input: 36873.03 toks/s, output: 36.01 toks/s]
Processed prompts:  78%|  | 398/512 [00:11<00:03, 33.32it/s, est. speed input: 36846.98 toks/s, output: 35.98 toks/s]
Processed prompts:  79%|  | 402/512 [00:11<00:03, 33.51it/s, est. speed input: 36825.16 toks/s, output: 35.96 toks/s]
Processed prompts:  79%|  | 406/512 [00:11<00:03, 33.58it/s, est. speed input: 36801.54 toks/s, output: 35.94 toks/s]
Processed prompts:  80%|  | 410/512 [00:11<00:03, 33.62it/s, est. speed input: 36777.87 toks/s, output: 35.92 toks/s]
Processed prompts:  81%|  | 414/512 [00:11<00:02, 33.52it/s, est. speed input: 36750.00 toks/s, output: 35.89 toks/s]
Processed prompts:  82%| | 418/512 [00:11<00:02, 33.52it/s, est. speed input: 36724.92 toks/s, output: 35.86 toks/s]
Processed prompts:  82%| | 422/512 [00:11<00:02, 33.61it/s, est. speed input: 36704.06 toks/s, output: 35.84 toks/s]
Processed prompts:  83%| | 426/512 [00:11<00:02, 33.15it/s, est. speed input: 36664.21 toks/s, output: 35.80 toks/s]
Processed prompts:  84%| | 430/512 [00:12<00:02, 33.12it/s, est. speed input: 36635.61 toks/s, output: 35.78 toks/s]
Processed prompts:  85%| | 434/512 [00:12<00:02, 33.22it/s, est. speed input: 36612.37 toks/s, output: 35.75 toks/s]
Processed prompts:  86%| | 438/512 [00:12<00:02, 33.38it/s, est. speed input: 36592.48 toks/s, output: 35.73 toks/s]
Processed prompts:  86%| | 442/512 [00:12<00:02, 33.59it/s, est. speed input: 36576.50 toks/s, output: 35.72 toks/s]
Processed prompts:  87%| | 446/512 [00:12<00:01, 33.61it/s, est. speed input: 36556.54 toks/s, output: 35.70 toks/s]
Processed prompts:  88%| | 450/512 [00:12<00:01, 34.21it/s, est. speed input: 36556.67 toks/s, output: 35.70 toks/s]
Processed prompts:  89%| | 454/512 [00:12<00:01, 33.96it/s, est. speed input: 36534.13 toks/s, output: 35.68 toks/s]
Processed prompts:  89%| | 458/512 [00:12<00:01, 33.74it/s, est. speed input: 36510.82 toks/s, output: 35.66 toks/s]
Processed prompts:  90%| | 462/512 [00:12<00:01, 33.43it/s, est. speed input: 36482.66 toks/s, output: 35.63 toks/s]
Processed prompts:  91%| | 466/512 [00:13<00:01, 33.25it/s, est. speed input: 36455.83 toks/s, output: 35.60 toks/s]
Processed prompts:  92%|| 470/512 [00:13<00:01, 33.34it/s, est. speed input: 36437.08 toks/s, output: 35.58 toks/s]
Processed prompts:  93%|| 474/512 [00:13<00:01, 33.34it/s, est. speed input: 36416.36 toks/s, output: 35.56 toks/s]
Processed prompts:  93%|| 478/512 [00:13<00:01, 33.58it/s, est. speed input: 36403.64 toks/s, output: 35.55 toks/s]
Processed prompts:  94%|| 482/512 [00:13<00:00, 33.37it/s, est. speed input: 36379.21 toks/s, output: 35.53 toks/s]
Processed prompts:  95%|| 486/512 [00:13<00:00, 33.34it/s, est. speed input: 36359.07 toks/s, output: 35.51 toks/s]
Processed prompts:  96%|| 490/512 [00:13<00:00, 33.28it/s, est. speed input: 36337.94 toks/s, output: 35.49 toks/s]
Processed prompts:  96%|| 494/512 [00:13<00:00, 33.45it/s, est. speed input: 36323.74 toks/s, output: 35.47 toks/s]
Processed prompts:  97%|| 498/512 [00:14<00:00, 32.98it/s, est. speed input: 36291.51 toks/s, output: 35.44 toks/s]
Processed prompts:  98%|| 502/512 [00:14<00:00, 33.15it/s, est. speed input: 36275.02 toks/s, output: 35.42 toks/s]
Processed prompts:  99%|| 506/512 [00:14<00:00, 33.19it/s, est. speed input: 36256.80 toks/s, output: 35.41 toks/s]
Processed prompts: 100%|| 510/512 [00:14<00:00, 34.35it/s, est. speed input: 36271.88 toks/s, output: 35.42 toks/s]
Processed prompts: 100%|| 512/512 [00:14<00:00, 34.35it/s, est. speed input: 36413.76 toks/s, output: 35.56 toks/s]
Processed prompts: 100%|| 512/512 [00:14<00:00, 35.56it/s, est. speed input: 36413.76 toks/s, output: 35.56 toks/s]
[rank0]:[W126 04:09:56.975565346 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-26 04:09:59
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Llama3.2-1B-FP8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 04:10:05 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 04:10:05 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=843467) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=843467) WARNING 01-26 04:10:24 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 32.09 requests/s, 32893.60 total tokens/s, 32.09 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-26 04:10:05] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 04:10:05] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 04:10:05] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 04:10:05] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:10:05] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:10:05] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:10:05] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:10:05] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:10:05] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 04:10:05] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 04:10:05] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:10:05] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:10:05] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:10:05] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 04:10:08] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 04:10:08] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 04:10:08] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 04:10:08] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:10:08] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:10:08] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:10:08] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:10:08] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:10:08] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 04:10:08] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 04:10:08] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:10:08] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:10:08] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:10:08] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=843467) [2026-01-26 04:10:09] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=843467) [2026-01-26 04:10:09] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=843467) [2026-01-26 04:10:09] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=843467) [2026-01-26 04:10:09] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=843467) [2026-01-26 04:10:09] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=843467) [2026-01-26 04:10:09] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=843467) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=843467) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.13s/it]
(EngineCore_DP0 pid=843467) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.13s/it]
(EngineCore_DP0 pid=843467) 
(EngineCore_DP0 pid=843467) [2026-01-26 04:10:18] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=843467) [2026-01-26 04:10:18] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=843467) [2026-01-26 04:10:18] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=843467) [2026-01-26 04:10:18] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 2621440 bytes
(EngineCore_DP0 pid=843467) [2026-01-26 04:10:18] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=843467) [2026-01-26 04:10:18] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 20971520 bytes
(EngineCore_DP0 pid=843467) [2026-01-26 04:10:18] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=843467) [2026-01-26 04:10:18] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10485760 bytes
(EngineCore_DP0 pid=843467) 2026-01-26 04:10:23,729 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=843467) 2026-01-26 04:10:23,780 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   6%|         | 57/1024 [00:00<00:01, 567.36it/s]
Adding requests:  11%|         | 114/1024 [00:00<00:01, 522.60it/s]
Adding requests:  16%|        | 167/1024 [00:00<00:01, 502.45it/s]
Adding requests:  21%|       | 218/1024 [00:00<00:01, 494.23it/s]
Adding requests:  26%|       | 268/1024 [00:00<00:01, 491.73it/s]
Adding requests:  31%|       | 318/1024 [00:00<00:01, 488.55it/s]
Adding requests:  36%|      | 367/1024 [00:00<00:01, 486.29it/s]
Adding requests:  41%|      | 416/1024 [00:00<00:01, 486.65it/s]
Adding requests:  45%|     | 465/1024 [00:00<00:01, 477.90it/s]
Adding requests:  50%|     | 514/1024 [00:01<00:01, 479.96it/s]
Adding requests:  55%|    | 563/1024 [00:01<00:01, 450.78it/s]
Adding requests:  60%|    | 612/1024 [00:01<00:00, 460.57it/s]
Adding requests:  64%|   | 660/1024 [00:01<00:00, 464.44it/s]
Adding requests:  69%|   | 709/1024 [00:01<00:00, 471.75it/s]
Adding requests:  74%|  | 757/1024 [00:01<00:00, 467.76it/s]
Adding requests:  79%|  | 804/1024 [00:01<00:00, 464.88it/s]
Adding requests:  83%| | 851/1024 [00:01<00:00, 452.35it/s]
Adding requests:  88%| | 900/1024 [00:01<00:00, 460.67it/s]
Adding requests:  92%|| 947/1024 [00:02<00:00, 451.33it/s]
Adding requests:  97%|| 998/1024 [00:02<00:00, 465.72it/s]
Adding requests: 100%|| 1024/1024 [00:02<00:00, 474.50it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|         | 66/1024 [00:00<00:03, 285.08it/s, est. speed input: 291952.87 toks/s, output: 285.09 toks/s]
Processed prompts:   9%|         | 95/1024 [00:00<00:11, 83.28it/s, est. speed input: 100043.50 toks/s, output: 97.70 toks/s]  
Processed prompts:  11%|         | 110/1024 [00:01<00:15, 59.62it/s, est. speed input: 76376.23 toks/s, output: 74.59 toks/s]
Processed prompts:  12%|        | 119/1024 [00:01<00:16, 54.10it/s, est. speed input: 70756.75 toks/s, output: 69.10 toks/s]
Processed prompts:  12%|        | 126/1024 [00:01<00:18, 47.71it/s, est. speed input: 65605.16 toks/s, output: 64.07 toks/s]
Processed prompts:  13%|        | 132/1024 [00:02<00:21, 41.26it/s, est. speed input: 60923.51 toks/s, output: 59.50 toks/s]
Processed prompts:  13%|        | 138/1024 [00:02<00:24, 36.58it/s, est. speed input: 57301.39 toks/s, output: 55.96 toks/s]
Processed prompts:  14%|        | 146/1024 [00:02<00:24, 35.39it/s, est. speed input: 55098.44 toks/s, output: 53.81 toks/s]
Processed prompts:  15%|        | 154/1024 [00:02<00:25, 34.44it/s, est. speed input: 53226.78 toks/s, output: 51.98 toks/s]
Processed prompts:  16%|        | 162/1024 [00:03<00:25, 33.69it/s, est. speed input: 51620.96 toks/s, output: 50.41 toks/s]
Processed prompts:  17%|        | 170/1024 [00:03<00:25, 33.30it/s, est. speed input: 50299.14 toks/s, output: 49.12 toks/s]
Processed prompts:  17%|        | 178/1024 [00:03<00:25, 33.00it/s, est. speed input: 49149.35 toks/s, output: 48.00 toks/s]
Processed prompts:  18%|        | 186/1024 [00:03<00:25, 32.90it/s, est. speed input: 48174.43 toks/s, output: 47.04 toks/s]
Processed prompts:  19%|        | 194/1024 [00:04<00:25, 32.72it/s, est. speed input: 47284.23 toks/s, output: 46.18 toks/s]
Processed prompts:  20%|        | 202/1024 [00:04<00:25, 32.48it/s, est. speed input: 46463.46 toks/s, output: 45.37 toks/s]
Processed prompts:  21%|        | 210/1024 [00:04<00:25, 32.39it/s, est. speed input: 45747.77 toks/s, output: 44.68 toks/s]
Processed prompts:  21%|       | 218/1024 [00:04<00:24, 32.30it/s, est. speed input: 45098.13 toks/s, output: 44.04 toks/s]
Processed prompts:  22%|       | 226/1024 [00:05<00:24, 32.27it/s, est. speed input: 44519.61 toks/s, output: 43.48 toks/s]
Processed prompts:  23%|       | 234/1024 [00:05<00:24, 32.10it/s, est. speed input: 43961.85 toks/s, output: 42.93 toks/s]
Processed prompts:  24%|       | 242/1024 [00:05<00:24, 32.21it/s, est. speed input: 43498.20 toks/s, output: 42.48 toks/s]
Processed prompts:  24%|       | 250/1024 [00:05<00:24, 32.16it/s, est. speed input: 43050.54 toks/s, output: 42.04 toks/s]
Processed prompts:  25%|       | 258/1024 [00:06<00:23, 32.21it/s, est. speed input: 42652.95 toks/s, output: 41.65 toks/s]
Processed prompts:  26%|       | 266/1024 [00:06<00:23, 32.03it/s, est. speed input: 42248.81 toks/s, output: 41.26 toks/s]
Processed prompts:  27%|       | 274/1024 [00:06<00:23, 32.12it/s, est. speed input: 41912.02 toks/s, output: 40.93 toks/s]
Processed prompts:  28%|       | 282/1024 [00:06<00:23, 32.14it/s, est. speed input: 41590.61 toks/s, output: 40.62 toks/s]
Processed prompts:  28%|       | 290/1024 [00:07<00:22, 32.11it/s, est. speed input: 41285.78 toks/s, output: 40.32 toks/s]
Processed prompts:  29%|       | 298/1024 [00:07<00:22, 32.07it/s, est. speed input: 40998.44 toks/s, output: 40.04 toks/s]
Processed prompts:  30%|       | 306/1024 [00:07<00:22, 31.91it/s, est. speed input: 40712.19 toks/s, output: 39.76 toks/s]
Processed prompts:  31%|       | 314/1024 [00:07<00:22, 31.98it/s, est. speed input: 40468.05 toks/s, output: 39.52 toks/s]
Processed prompts:  31%|      | 322/1024 [00:08<00:21, 32.11it/s, est. speed input: 40249.46 toks/s, output: 39.31 toks/s]
Processed prompts:  32%|      | 330/1024 [00:08<00:21, 32.15it/s, est. speed input: 40036.78 toks/s, output: 39.10 toks/s]
Processed prompts:  33%|      | 338/1024 [00:08<00:21, 32.13it/s, est. speed input: 39830.45 toks/s, output: 38.90 toks/s]
Processed prompts:  34%|      | 346/1024 [00:08<00:21, 32.17it/s, est. speed input: 39641.76 toks/s, output: 38.71 toks/s]
Processed prompts:  35%|      | 354/1024 [00:09<00:20, 32.19it/s, est. speed input: 39462.92 toks/s, output: 38.54 toks/s]
Processed prompts:  35%|      | 362/1024 [00:09<00:20, 32.22it/s, est. speed input: 39294.29 toks/s, output: 38.37 toks/s]
Processed prompts:  36%|      | 370/1024 [00:09<00:20, 31.99it/s, est. speed input: 39108.69 toks/s, output: 38.19 toks/s]
Processed prompts:  37%|      | 378/1024 [00:09<00:20, 32.00it/s, est. speed input: 38950.56 toks/s, output: 38.04 toks/s]
Processed prompts:  38%|      | 386/1024 [00:10<00:19, 32.12it/s, est. speed input: 38810.29 toks/s, output: 37.90 toks/s]
Processed prompts:  38%|      | 394/1024 [00:10<00:19, 32.19it/s, est. speed input: 38675.88 toks/s, output: 37.77 toks/s]
Processed prompts:  39%|      | 402/1024 [00:10<00:19, 32.10it/s, est. speed input: 38534.37 toks/s, output: 37.63 toks/s]
Processed prompts:  40%|      | 410/1024 [00:10<00:19, 32.03it/s, est. speed input: 38399.02 toks/s, output: 37.50 toks/s]
Processed prompts:  41%|      | 418/1024 [00:11<00:18, 32.13it/s, est. speed input: 38282.87 toks/s, output: 37.39 toks/s]
Processed prompts:  42%|     | 426/1024 [00:11<00:18, 32.17it/s, est. speed input: 38168.69 toks/s, output: 37.27 toks/s]
Processed prompts:  42%|     | 434/1024 [00:11<00:18, 32.24it/s, est. speed input: 38063.14 toks/s, output: 37.17 toks/s]
Processed prompts:  43%|     | 442/1024 [00:11<00:18, 32.17it/s, est. speed input: 37952.88 toks/s, output: 37.06 toks/s]
Processed prompts:  44%|     | 450/1024 [00:12<00:17, 32.48it/s, est. speed input: 37874.99 toks/s, output: 36.99 toks/s]
Processed prompts:  45%|     | 458/1024 [00:12<00:17, 32.48it/s, est. speed input: 37783.18 toks/s, output: 36.90 toks/s]
Processed prompts:  46%|     | 466/1024 [00:12<00:17, 32.49it/s, est. speed input: 37696.34 toks/s, output: 36.81 toks/s]
Processed prompts:  46%|     | 474/1024 [00:12<00:16, 32.39it/s, est. speed input: 37604.38 toks/s, output: 36.72 toks/s]
Processed prompts:  47%|     | 482/1024 [00:13<00:16, 32.27it/s, est. speed input: 37512.33 toks/s, output: 36.63 toks/s]
Processed prompts:  48%|     | 490/1024 [00:13<00:16, 32.34it/s, est. speed input: 37434.32 toks/s, output: 36.56 toks/s]
Processed prompts:  49%|     | 498/1024 [00:13<00:16, 32.42it/s, est. speed input: 37362.19 toks/s, output: 36.49 toks/s]
Processed prompts:  49%|     | 506/1024 [00:13<00:16, 32.36it/s, est. speed input: 37284.18 toks/s, output: 36.41 toks/s]
Processed prompts:  50%|     | 514/1024 [00:14<00:15, 32.18it/s, est. speed input: 37199.70 toks/s, output: 36.33 toks/s]
Processed prompts:  51%|     | 522/1024 [00:14<00:15, 32.21it/s, est. speed input: 37128.07 toks/s, output: 36.26 toks/s]
Processed prompts:  52%|    | 530/1024 [00:14<00:15, 32.30it/s, est. speed input: 37063.49 toks/s, output: 36.19 toks/s]
Processed prompts:  53%|    | 538/1024 [00:14<00:15, 32.34it/s, est. speed input: 36999.59 toks/s, output: 36.13 toks/s]
Processed prompts:  53%|    | 546/1024 [00:15<00:14, 32.17it/s, est. speed input: 36925.98 toks/s, output: 36.06 toks/s]
Processed prompts:  54%|    | 554/1024 [00:15<00:14, 32.36it/s, est. speed input: 36873.02 toks/s, output: 36.01 toks/s]
Processed prompts:  55%|    | 562/1024 [00:15<00:14, 32.39it/s, est. speed input: 36815.72 toks/s, output: 35.95 toks/s]
Processed prompts:  56%|    | 570/1024 [00:15<00:14, 32.33it/s, est. speed input: 36755.33 toks/s, output: 35.89 toks/s]
Processed prompts:  56%|    | 578/1024 [00:16<00:13, 32.12it/s, est. speed input: 36687.41 toks/s, output: 35.83 toks/s]
Processed prompts:  57%|    | 586/1024 [00:16<00:13, 32.20it/s, est. speed input: 36634.32 toks/s, output: 35.78 toks/s]
Processed prompts:  58%|    | 594/1024 [00:16<00:13, 32.20it/s, est. speed input: 36579.39 toks/s, output: 35.72 toks/s]
Processed prompts:  59%|    | 602/1024 [00:16<00:13, 32.26it/s, est. speed input: 36529.47 toks/s, output: 35.67 toks/s]
Processed prompts:  60%|    | 610/1024 [00:17<00:12, 32.26it/s, est. speed input: 36478.75 toks/s, output: 35.62 toks/s]
Processed prompts:  60%|    | 618/1024 [00:17<00:12, 32.19it/s, est. speed input: 36426.12 toks/s, output: 35.57 toks/s]
Processed prompts:  61%|    | 626/1024 [00:17<00:12, 32.23it/s, est. speed input: 36379.46 toks/s, output: 35.53 toks/s]
Processed prompts:  62%|   | 634/1024 [00:17<00:12, 32.22it/s, est. speed input: 36332.03 toks/s, output: 35.48 toks/s]
Processed prompts:  63%|   | 642/1024 [00:18<00:11, 32.12it/s, est. speed input: 36280.97 toks/s, output: 35.43 toks/s]
Processed prompts:  63%|   | 650/1024 [00:18<00:11, 31.99it/s, est. speed input: 36228.20 toks/s, output: 35.38 toks/s]
Processed prompts:  64%|   | 658/1024 [00:18<00:11, 32.07it/s, est. speed input: 36185.88 toks/s, output: 35.34 toks/s]
Processed prompts:  65%|   | 666/1024 [00:18<00:11, 32.18it/s, est. speed input: 36147.16 toks/s, output: 35.30 toks/s]
Processed prompts:  66%|   | 674/1024 [00:19<00:10, 32.19it/s, est. speed input: 36105.96 toks/s, output: 35.26 toks/s]
Processed prompts:  67%|   | 682/1024 [00:19<00:10, 32.08it/s, est. speed input: 36060.27 toks/s, output: 35.22 toks/s]
Processed prompts:  67%|   | 690/1024 [00:19<00:10, 32.18it/s, est. speed input: 36024.23 toks/s, output: 35.18 toks/s]
Processed prompts:  68%|   | 698/1024 [00:19<00:10, 32.13it/s, est. speed input: 35983.39 toks/s, output: 35.14 toks/s]
Processed prompts:  69%|   | 706/1024 [00:20<00:09, 32.21it/s, est. speed input: 35948.87 toks/s, output: 35.11 toks/s]
Processed prompts:  70%|   | 714/1024 [00:20<00:09, 32.33it/s, est. speed input: 35917.93 toks/s, output: 35.08 toks/s]
Processed prompts:  71%|   | 722/1024 [00:20<00:09, 32.19it/s, est. speed input: 35877.96 toks/s, output: 35.04 toks/s]
Processed prompts:  71%|  | 730/1024 [00:20<00:09, 32.25it/s, est. speed input: 35845.75 toks/s, output: 35.01 toks/s]
Processed prompts:  72%|  | 738/1024 [00:21<00:08, 32.29it/s, est. speed input: 35814.62 toks/s, output: 34.98 toks/s]
Processed prompts:  73%|  | 746/1024 [00:21<00:08, 32.32it/s, est. speed input: 35783.82 toks/s, output: 34.95 toks/s]
Processed prompts:  74%|  | 754/1024 [00:21<00:08, 32.05it/s, est. speed input: 35741.44 toks/s, output: 34.90 toks/s]
Processed prompts:  74%|  | 762/1024 [00:21<00:08, 32.10it/s, est. speed input: 35710.40 toks/s, output: 34.87 toks/s]
Processed prompts:  75%|  | 770/1024 [00:22<00:07, 32.05it/s, est. speed input: 35676.00 toks/s, output: 34.84 toks/s]
Processed prompts:  76%|  | 778/1024 [00:22<00:07, 32.13it/s, est. speed input: 35647.38 toks/s, output: 34.81 toks/s]
Processed prompts:  77%|  | 786/1024 [00:22<00:07, 31.98it/s, est. speed input: 35611.18 toks/s, output: 34.78 toks/s]
Processed prompts:  78%|  | 794/1024 [00:22<00:07, 32.07it/s, est. speed input: 35583.38 toks/s, output: 34.75 toks/s]
Processed prompts:  78%|  | 802/1024 [00:23<00:06, 32.13it/s, est. speed input: 35556.27 toks/s, output: 34.72 toks/s]
Processed prompts:  79%|  | 810/1024 [00:23<00:06, 32.23it/s, est. speed input: 35531.60 toks/s, output: 34.70 toks/s]
Processed prompts:  80%|  | 818/1024 [00:23<00:06, 32.16it/s, est. speed input: 35502.36 toks/s, output: 34.67 toks/s]
Processed prompts:  81%|  | 826/1024 [00:23<00:06, 32.12it/s, est. speed input: 35473.87 toks/s, output: 34.64 toks/s]
Processed prompts:  81%| | 834/1024 [00:24<00:05, 32.19it/s, est. speed input: 35450.00 toks/s, output: 34.62 toks/s]
Processed prompts:  82%| | 842/1024 [00:24<00:05, 32.21it/s, est. speed input: 35425.12 toks/s, output: 34.59 toks/s]
Processed prompts:  83%| | 850/1024 [00:24<00:05, 32.18it/s, est. speed input: 35399.66 toks/s, output: 34.57 toks/s]
Processed prompts:  84%| | 858/1024 [00:24<00:05, 32.03it/s, est. speed input: 35369.56 toks/s, output: 34.54 toks/s]
Processed prompts:  85%| | 866/1024 [00:25<00:04, 32.14it/s, est. speed input: 35347.80 toks/s, output: 34.52 toks/s]
Processed prompts:  85%| | 874/1024 [00:25<00:04, 32.14it/s, est. speed input: 35324.13 toks/s, output: 34.50 toks/s]
Processed prompts:  86%| | 882/1024 [00:25<00:04, 32.15it/s, est. speed input: 35300.79 toks/s, output: 34.47 toks/s]
Processed prompts:  87%| | 890/1024 [00:25<00:04, 31.97it/s, est. speed input: 35271.61 toks/s, output: 34.44 toks/s]
Processed prompts:  88%| | 898/1024 [00:26<00:03, 31.97it/s, est. speed input: 35247.39 toks/s, output: 34.42 toks/s]
Processed prompts:  88%| | 906/1024 [00:26<00:03, 32.02it/s, est. speed input: 35225.32 toks/s, output: 34.40 toks/s]
Processed prompts:  89%| | 914/1024 [00:26<00:03, 32.10it/s, est. speed input: 35205.16 toks/s, output: 34.38 toks/s]
Processed prompts:  90%| | 922/1024 [00:26<00:03, 31.99it/s, est. speed input: 35179.66 toks/s, output: 34.36 toks/s]
Processed prompts:  91%| | 930/1024 [00:27<00:02, 32.05it/s, est. speed input: 35159.28 toks/s, output: 34.34 toks/s]
Processed prompts:  92%|| 938/1024 [00:27<00:02, 33.35it/s, est. speed input: 35179.56 toks/s, output: 34.36 toks/s]
Processed prompts:  92%|| 946/1024 [00:27<00:02, 32.91it/s, est. speed input: 35156.98 toks/s, output: 34.33 toks/s]
Processed prompts:  93%|| 954/1024 [00:27<00:02, 32.75it/s, est. speed input: 35139.12 toks/s, output: 34.32 toks/s]
Processed prompts:  94%|| 962/1024 [00:28<00:01, 32.40it/s, est. speed input: 35114.42 toks/s, output: 34.29 toks/s]
Processed prompts:  95%|| 970/1024 [00:28<00:01, 32.38it/s, est. speed input: 35096.92 toks/s, output: 34.27 toks/s]
Processed prompts:  96%|| 978/1024 [00:28<00:01, 32.25it/s, est. speed input: 35075.83 toks/s, output: 34.25 toks/s]
Processed prompts:  96%|| 986/1024 [00:28<00:01, 33.63it/s, est. speed input: 35099.63 toks/s, output: 34.28 toks/s]
Processed prompts:  97%|| 994/1024 [00:29<00:00, 33.04it/s, est. speed input: 35076.99 toks/s, output: 34.25 toks/s]
Processed prompts:  98%|| 1002/1024 [00:29<00:00, 32.75it/s, est. speed input: 35058.00 toks/s, output: 34.24 toks/s]
Processed prompts:  99%|| 1010/1024 [00:29<00:00, 32.56it/s, est. speed input: 35039.96 toks/s, output: 34.22 toks/s]
Processed prompts:  99%|| 1018/1024 [00:29<00:00, 33.06it/s, est. speed input: 35040.54 toks/s, output: 34.22 toks/s]
Processed prompts: 100%|| 1024/1024 [00:29<00:00, 33.06it/s, est. speed input: 35246.93 toks/s, output: 34.42 toks/s]
Processed prompts: 100%|| 1024/1024 [00:29<00:00, 34.42it/s, est. speed input: 35246.93 toks/s, output: 34.42 toks/s]
[rank0]:[W126 04:10:56.900053573 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-26 04:10:58
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Llama3.2-1B-FP8_M16384.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 04:11:08 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 04:11:08 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=844529) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=844529) WARNING 01-26 04:11:28 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 32.72 requests/s, 33538.90 total tokens/s, 32.72 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-26 04:11:08] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 04:11:08] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 04:11:08] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 04:11:08] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:11:08] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:11:08] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:11:08] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:11:08] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:11:08] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 04:11:08] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 04:11:08] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:11:08] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:11:08] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:11:08] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 04:11:11] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 04:11:11] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 04:11:11] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 04:11:11] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:11:11] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:11:11] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:11:11] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:11:11] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:11:11] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 04:11:11] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 04:11:11] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:11:11] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:11:11] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:11:11] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=844529) [2026-01-26 04:11:12] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=844529) [2026-01-26 04:11:12] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=844529) [2026-01-26 04:11:12] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=844529) [2026-01-26 04:11:12] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=844529) [2026-01-26 04:11:12] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=844529) [2026-01-26 04:11:12] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=844529) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=844529) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.21s/it]
(EngineCore_DP0 pid=844529) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.21s/it]
(EngineCore_DP0 pid=844529) 
(EngineCore_DP0 pid=844529) [2026-01-26 04:11:21] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=844529) [2026-01-26 04:11:21] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=844529) [2026-01-26 04:11:21] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=844529) [2026-01-26 04:11:21] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 2621440 bytes
(EngineCore_DP0 pid=844529) [2026-01-26 04:11:21] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=844529) [2026-01-26 04:11:21] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 20971520 bytes
(EngineCore_DP0 pid=844529) [2026-01-26 04:11:21] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=844529) [2026-01-26 04:11:21] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10485760 bytes
(EngineCore_DP0 pid=844529) 2026-01-26 04:11:26,938 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=844529) 2026-01-26 04:11:27,049 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   3%|         | 56/2048 [00:00<00:03, 554.22it/s]
Adding requests:   5%|         | 112/2048 [00:00<00:03, 510.67it/s]
Adding requests:   8%|         | 164/2048 [00:00<00:03, 486.23it/s]
Adding requests:  10%|         | 213/2048 [00:00<00:03, 480.07it/s]
Adding requests:  13%|        | 262/2048 [00:00<00:03, 481.90it/s]
Adding requests:  15%|        | 311/2048 [00:00<00:03, 475.23it/s]
Adding requests:  18%|        | 359/2048 [00:00<00:03, 467.07it/s]
Adding requests:  20%|        | 407/2048 [00:00<00:03, 470.78it/s]
Adding requests:  22%|       | 456/2048 [00:00<00:03, 476.20it/s]
Adding requests:  25%|       | 504/2048 [00:01<00:03, 466.59it/s]
Adding requests:  27%|       | 551/2048 [00:01<00:03, 461.88it/s]
Adding requests:  29%|       | 598/2048 [00:01<00:03, 455.34it/s]
Adding requests:  32%|      | 647/2048 [00:01<00:03, 463.69it/s]
Adding requests:  34%|      | 695/2048 [00:01<00:02, 466.46it/s]
Adding requests:  36%|      | 743/2048 [00:01<00:02, 467.23it/s]
Adding requests:  39%|      | 790/2048 [00:01<00:02, 437.75it/s]
Adding requests:  41%|      | 835/2048 [00:01<00:02, 437.80it/s]
Adding requests:  43%|     | 880/2048 [00:02<00:07, 147.77it/s]
Adding requests:  45%|     | 924/2048 [00:02<00:06, 182.89it/s]
Adding requests:  47%|     | 968/2048 [00:02<00:04, 220.44it/s]
Adding requests:  50%|     | 1017/2048 [00:02<00:03, 266.86it/s]
Adding requests:  52%|    | 1063/2048 [00:02<00:03, 303.92it/s]
Adding requests:  54%|    | 1112/2048 [00:03<00:02, 343.99it/s]
Adding requests:  56%|    | 1157/2048 [00:03<00:02, 362.55it/s]
Adding requests:  59%|    | 1206/2048 [00:03<00:02, 393.39it/s]
Adding requests:  61%|    | 1252/2048 [00:03<00:01, 410.22it/s]
Adding requests:  64%|   | 1302/2048 [00:03<00:01, 433.90it/s]
Adding requests:  66%|   | 1350/2048 [00:03<00:01, 445.53it/s]
Adding requests:  68%|   | 1397/2048 [00:03<00:01, 446.82it/s]
Adding requests:  71%|   | 1444/2048 [00:03<00:01, 449.12it/s]
Adding requests:  73%|  | 1494/2048 [00:03<00:01, 460.86it/s]
Adding requests:  75%|  | 1541/2048 [00:04<00:01, 462.63it/s]
Adding requests:  78%|  | 1590/2048 [00:04<00:00, 469.58it/s]
Adding requests:  80%|  | 1638/2048 [00:04<00:00, 466.68it/s]
Adding requests:  82%| | 1685/2048 [00:04<00:00, 466.74it/s]
Adding requests:  85%| | 1732/2048 [00:04<00:00, 465.28it/s]
Adding requests:  87%| | 1781/2048 [00:04<00:00, 470.82it/s]
Adding requests:  89%| | 1829/2048 [00:04<00:00, 456.15it/s]
Adding requests:  92%|| 1875/2048 [00:04<00:00, 456.45it/s]
Adding requests:  94%|| 1922/2048 [00:04<00:00, 456.79it/s]
Adding requests:  96%|| 1970/2048 [00:04<00:00, 462.83it/s]
Adding requests:  98%|| 2017/2048 [00:05<00:00, 435.72it/s]
Adding requests: 100%|| 2048/2048 [00:05<00:00, 398.33it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   8%|         | 162/2048 [00:00<00:04, 389.93it/s, est. speed input: 399341.74 toks/s, output: 389.95 toks/s]
Processed prompts:  10%|         | 201/2048 [00:01<00:15, 119.99it/s, est. speed input: 147572.76 toks/s, output: 144.11 toks/s]
Processed prompts:  11%|         | 220/2048 [00:01<00:20, 91.00it/s, est. speed input: 119401.46 toks/s, output: 116.60 toks/s] 
Processed prompts:  11%|        | 232/2048 [00:02<00:26, 68.86it/s, est. speed input: 100159.01 toks/s, output: 97.81 toks/s] 
Processed prompts:  12%|        | 242/2048 [00:02<00:34, 52.93it/s, est. speed input: 86445.75 toks/s, output: 84.42 toks/s] 
Processed prompts:  13%|        | 258/2048 [00:03<00:38, 46.58it/s, est. speed input: 78762.19 toks/s, output: 76.92 toks/s]
Processed prompts:  13%|        | 274/2048 [00:03<00:42, 42.16it/s, est. speed input: 72931.00 toks/s, output: 71.22 toks/s]
Processed prompts:  14%|        | 290/2048 [00:04<00:44, 39.30it/s, est. speed input: 68512.07 toks/s, output: 66.91 toks/s]
Processed prompts:  15%|        | 306/2048 [00:04<00:46, 37.23it/s, est. speed input: 64923.90 toks/s, output: 63.40 toks/s]
Processed prompts:  16%|        | 322/2048 [00:05<00:48, 35.86it/s, est. speed input: 62033.95 toks/s, output: 60.58 toks/s]
Processed prompts:  17%|        | 338/2048 [00:05<00:48, 35.13it/s, est. speed input: 59735.80 toks/s, output: 58.34 toks/s]
Processed prompts:  17%|        | 354/2048 [00:06<00:49, 34.30it/s, est. speed input: 57651.87 toks/s, output: 56.30 toks/s]
Processed prompts:  18%|        | 370/2048 [00:06<00:49, 33.87it/s, est. speed input: 55925.62 toks/s, output: 54.61 toks/s]
Processed prompts:  19%|        | 386/2048 [00:07<00:49, 33.40it/s, est. speed input: 54370.47 toks/s, output: 53.10 toks/s]
Processed prompts:  20%|        | 402/2048 [00:07<00:49, 33.25it/s, est. speed input: 53074.02 toks/s, output: 51.83 toks/s]
Processed prompts:  20%|        | 418/2048 [00:08<00:49, 33.00it/s, est. speed input: 51885.89 toks/s, output: 50.67 toks/s]
Processed prompts:  21%|        | 434/2048 [00:08<00:49, 32.92it/s, est. speed input: 50857.47 toks/s, output: 49.67 toks/s]
Processed prompts:  22%|       | 450/2048 [00:09<00:48, 33.05it/s, est. speed input: 49988.54 toks/s, output: 48.82 toks/s]
Processed prompts:  23%|       | 466/2048 [00:09<00:47, 33.02it/s, est. speed input: 49174.74 toks/s, output: 48.02 toks/s]
Processed prompts:  24%|       | 482/2048 [00:10<00:47, 32.86it/s, est. speed input: 48408.82 toks/s, output: 47.27 toks/s]
Processed prompts:  24%|       | 498/2048 [00:10<00:47, 32.88it/s, est. speed input: 47738.65 toks/s, output: 46.62 toks/s]
Processed prompts:  25%|       | 514/2048 [00:11<00:46, 32.84it/s, est. speed input: 47118.96 toks/s, output: 46.01 toks/s]
Processed prompts:  26%|       | 530/2048 [00:11<00:46, 32.70it/s, est. speed input: 46526.18 toks/s, output: 45.44 toks/s]
Processed prompts:  27%|       | 546/2048 [00:12<00:45, 32.73it/s, est. speed input: 46007.14 toks/s, output: 44.93 toks/s]
Processed prompts:  27%|       | 562/2048 [00:12<00:45, 32.68it/s, est. speed input: 45514.53 toks/s, output: 44.45 toks/s]
Processed prompts:  28%|       | 578/2048 [00:13<00:44, 32.68it/s, est. speed input: 45065.99 toks/s, output: 44.01 toks/s]
Processed prompts:  29%|       | 594/2048 [00:13<00:44, 32.61it/s, est. speed input: 44636.97 toks/s, output: 43.59 toks/s]
Processed prompts:  30%|       | 610/2048 [00:14<00:44, 32.63it/s, est. speed input: 44249.32 toks/s, output: 43.21 toks/s]
Processed prompts:  31%|       | 626/2048 [00:14<00:43, 32.64it/s, est. speed input: 43887.63 toks/s, output: 42.86 toks/s]
Processed prompts:  31%|      | 642/2048 [00:15<00:43, 32.68it/s, est. speed input: 43552.92 toks/s, output: 42.53 toks/s]
Processed prompts:  32%|      | 658/2048 [00:15<00:42, 32.66it/s, est. speed input: 43234.12 toks/s, output: 42.22 toks/s]
Processed prompts:  33%|      | 674/2048 [00:16<00:42, 32.64it/s, est. speed input: 42933.26 toks/s, output: 41.93 toks/s]
Processed prompts:  34%|      | 690/2048 [00:16<00:41, 32.72it/s, est. speed input: 42661.58 toks/s, output: 41.66 toks/s]
Processed prompts:  34%|      | 706/2048 [00:17<00:41, 32.68it/s, est. speed input: 42393.71 toks/s, output: 41.40 toks/s]
Processed prompts:  35%|      | 722/2048 [00:17<00:40, 32.73it/s, est. speed input: 42151.12 toks/s, output: 41.16 toks/s]
Processed prompts:  36%|      | 738/2048 [00:18<00:40, 32.63it/s, est. speed input: 41904.78 toks/s, output: 40.92 toks/s]
Processed prompts:  37%|      | 754/2048 [00:18<00:39, 32.75it/s, est. speed input: 41693.54 toks/s, output: 40.72 toks/s]
Processed prompts:  38%|      | 770/2048 [00:19<00:39, 32.61it/s, est. speed input: 41468.33 toks/s, output: 40.50 toks/s]
Processed prompts:  38%|      | 786/2048 [00:19<00:38, 32.71it/s, est. speed input: 41276.46 toks/s, output: 40.31 toks/s]
Processed prompts:  39%|      | 802/2048 [00:19<00:38, 32.59it/s, est. speed input: 41073.33 toks/s, output: 40.11 toks/s]
Processed prompts:  40%|      | 818/2048 [00:20<00:37, 32.65it/s, est. speed input: 40894.43 toks/s, output: 39.94 toks/s]
Processed prompts:  41%|      | 834/2048 [00:20<00:37, 32.59it/s, est. speed input: 40714.73 toks/s, output: 39.76 toks/s]
Processed prompts:  42%|     | 850/2048 [00:21<00:36, 32.64it/s, est. speed input: 40551.15 toks/s, output: 39.60 toks/s]
Processed prompts:  42%|     | 866/2048 [00:21<00:36, 32.72it/s, est. speed input: 40399.07 toks/s, output: 39.45 toks/s]
Processed prompts:  43%|     | 882/2048 [00:22<00:35, 32.66it/s, est. speed input: 40243.70 toks/s, output: 39.30 toks/s]
Processed prompts:  44%|     | 898/2048 [00:22<00:35, 32.71it/s, est. speed input: 40102.60 toks/s, output: 39.16 toks/s]
Processed prompts:  45%|     | 914/2048 [00:23<00:34, 32.61it/s, est. speed input: 39956.04 toks/s, output: 39.02 toks/s]
Processed prompts:  45%|     | 930/2048 [00:23<00:33, 33.29it/s, est. speed input: 39877.25 toks/s, output: 38.94 toks/s]
Processed prompts:  46%|     | 946/2048 [00:24<00:33, 32.99it/s, est. speed input: 39738.94 toks/s, output: 38.81 toks/s]
Processed prompts:  47%|     | 962/2048 [00:24<00:32, 32.97it/s, est. speed input: 39621.16 toks/s, output: 38.69 toks/s]
Processed prompts:  48%|     | 978/2048 [00:25<00:32, 33.35it/s, est. speed input: 39538.19 toks/s, output: 38.61 toks/s]
Processed prompts:  49%|     | 994/2048 [00:25<00:31, 33.12it/s, est. speed input: 39420.87 toks/s, output: 38.50 toks/s]
Processed prompts:  49%|     | 1010/2048 [00:26<00:31, 32.96it/s, est. speed input: 39308.31 toks/s, output: 38.39 toks/s]
Processed prompts:  50%|     | 1026/2048 [00:26<00:31, 32.89it/s, est. speed input: 39202.62 toks/s, output: 38.28 toks/s]
Processed prompts:  51%|     | 1042/2048 [00:27<00:30, 32.88it/s, est. speed input: 39103.11 toks/s, output: 38.19 toks/s]
Processed prompts:  52%|    | 1058/2048 [00:27<00:30, 32.73it/s, est. speed input: 38997.35 toks/s, output: 38.08 toks/s]
Processed prompts:  52%|    | 1074/2048 [00:28<00:29, 32.76it/s, est. speed input: 38904.55 toks/s, output: 37.99 toks/s]
Processed prompts:  53%|    | 1090/2048 [00:28<00:29, 32.60it/s, est. speed input: 38803.22 toks/s, output: 37.89 toks/s]
Processed prompts:  54%|    | 1106/2048 [00:29<00:28, 32.70it/s, est. speed input: 38718.63 toks/s, output: 37.81 toks/s]
Processed prompts:  55%|    | 1122/2048 [00:29<00:28, 32.62it/s, est. speed input: 38627.43 toks/s, output: 37.72 toks/s]
Processed prompts:  56%|    | 1138/2048 [00:30<00:27, 32.65it/s, est. speed input: 38544.60 toks/s, output: 37.64 toks/s]
Processed prompts:  56%|    | 1154/2048 [00:30<00:26, 33.14it/s, est. speed input: 38493.39 toks/s, output: 37.59 toks/s]
Processed prompts:  57%|    | 1170/2048 [00:31<00:26, 33.02it/s, est. speed input: 38415.72 toks/s, output: 37.52 toks/s]
Processed prompts:  58%|    | 1186/2048 [00:31<00:26, 32.90it/s, est. speed input: 38338.20 toks/s, output: 37.44 toks/s]
Processed prompts:  59%|    | 1202/2048 [00:32<00:25, 32.74it/s, est. speed input: 38258.56 toks/s, output: 37.36 toks/s]
Processed prompts:  59%|    | 1218/2048 [00:32<00:25, 32.70it/s, est. speed input: 38185.19 toks/s, output: 37.29 toks/s]
Processed prompts:  60%|    | 1234/2048 [00:33<00:24, 32.63it/s, est. speed input: 38112.07 toks/s, output: 37.22 toks/s]
Processed prompts:  61%|    | 1250/2048 [00:33<00:24, 32.65it/s, est. speed input: 38044.74 toks/s, output: 37.15 toks/s]
Processed prompts:  62%|   | 1266/2048 [00:34<00:23, 33.17it/s, est. speed input: 38006.70 toks/s, output: 37.12 toks/s]
Processed prompts:  63%|   | 1282/2048 [00:34<00:23, 33.04it/s, est. speed input: 37943.53 toks/s, output: 37.05 toks/s]
Processed prompts:  63%|   | 1298/2048 [00:35<00:22, 33.46it/s, est. speed input: 37908.56 toks/s, output: 37.02 toks/s]
Processed prompts:  64%|   | 1314/2048 [00:35<00:22, 33.23it/s, est. speed input: 37847.95 toks/s, output: 36.96 toks/s]
Processed prompts:  65%|   | 1330/2048 [00:36<00:21, 33.02it/s, est. speed input: 37786.21 toks/s, output: 36.90 toks/s]
Processed prompts:  66%|   | 1346/2048 [00:36<00:21, 32.98it/s, est. speed input: 37731.44 toks/s, output: 36.85 toks/s]
Processed prompts:  67%|   | 1362/2048 [00:37<00:20, 32.92it/s, est. speed input: 37676.45 toks/s, output: 36.79 toks/s]
Processed prompts:  67%|   | 1378/2048 [00:37<00:20, 32.76it/s, est. speed input: 37617.05 toks/s, output: 36.74 toks/s]
Processed prompts:  68%|   | 1394/2048 [00:38<00:19, 32.71it/s, est. speed input: 37562.25 toks/s, output: 36.68 toks/s]
Processed prompts:  69%|   | 1410/2048 [00:38<00:19, 32.68it/s, est. speed input: 37509.27 toks/s, output: 36.63 toks/s]
Processed prompts:  70%|   | 1426/2048 [00:38<00:19, 32.67it/s, est. speed input: 37457.78 toks/s, output: 36.58 toks/s]
Processed prompts:  70%|   | 1442/2048 [00:39<00:18, 32.62it/s, est. speed input: 37405.78 toks/s, output: 36.53 toks/s]
Processed prompts:  71%|   | 1458/2048 [00:39<00:18, 32.63it/s, est. speed input: 37357.19 toks/s, output: 36.48 toks/s]
Processed prompts:  72%|  | 1474/2048 [00:40<00:17, 32.54it/s, est. speed input: 37305.18 toks/s, output: 36.43 toks/s]
Processed prompts:  73%|  | 1490/2048 [00:40<00:17, 32.58it/s, est. speed input: 37259.21 toks/s, output: 36.39 toks/s]
Processed prompts:  74%|  | 1506/2048 [00:41<00:16, 32.55it/s, est. speed input: 37211.61 toks/s, output: 36.34 toks/s]
Processed prompts:  74%|  | 1522/2048 [00:41<00:16, 32.61it/s, est. speed input: 37168.70 toks/s, output: 36.30 toks/s]
Processed prompts:  75%|  | 1538/2048 [00:42<00:15, 32.65it/s, est. speed input: 37126.97 toks/s, output: 36.26 toks/s]
Processed prompts:  76%|  | 1554/2048 [00:42<00:15, 32.65it/s, est. speed input: 37084.52 toks/s, output: 36.22 toks/s]
Processed prompts:  77%|  | 1570/2048 [00:43<00:14, 32.67it/s, est. speed input: 37044.27 toks/s, output: 36.18 toks/s]
Processed prompts:  77%|  | 1586/2048 [00:43<00:13, 33.21it/s, est. speed input: 37026.75 toks/s, output: 36.16 toks/s]
Processed prompts:  78%|  | 1602/2048 [00:44<00:13, 33.07it/s, est. speed input: 36988.01 toks/s, output: 36.12 toks/s]
Processed prompts:  79%|  | 1618/2048 [00:44<00:13, 32.82it/s, est. speed input: 36944.46 toks/s, output: 36.08 toks/s]
Processed prompts:  80%|  | 1634/2048 [00:45<00:12, 32.77it/s, est. speed input: 36906.38 toks/s, output: 36.04 toks/s]
Processed prompts:  81%|  | 1650/2048 [00:45<00:11, 33.32it/s, est. speed input: 36892.24 toks/s, output: 36.03 toks/s]
Processed prompts:  81%| | 1666/2048 [00:46<00:11, 33.10it/s, est. speed input: 36854.95 toks/s, output: 35.99 toks/s]
Processed prompts:  82%| | 1682/2048 [00:46<00:11, 33.01it/s, est. speed input: 36820.85 toks/s, output: 35.96 toks/s]
Processed prompts:  83%| | 1698/2048 [00:47<00:10, 32.85it/s, est. speed input: 36784.06 toks/s, output: 35.92 toks/s]
Processed prompts:  84%| | 1714/2048 [00:47<00:10, 32.83it/s, est. speed input: 36751.13 toks/s, output: 35.89 toks/s]
Processed prompts:  84%| | 1730/2048 [00:48<00:09, 32.71it/s, est. speed input: 36714.84 toks/s, output: 35.85 toks/s]
Processed prompts:  85%| | 1746/2048 [00:48<00:09, 32.64it/s, est. speed input: 36680.08 toks/s, output: 35.82 toks/s]
Processed prompts:  86%| | 1762/2048 [00:49<00:08, 32.53it/s, est. speed input: 36643.29 toks/s, output: 35.78 toks/s]
Processed prompts:  87%| | 1778/2048 [00:49<00:08, 32.57it/s, est. speed input: 36612.08 toks/s, output: 35.75 toks/s]
Processed prompts:  88%| | 1794/2048 [00:50<00:07, 32.48it/s, est. speed input: 36576.58 toks/s, output: 35.72 toks/s]
Processed prompts:  88%| | 1810/2048 [00:50<00:07, 32.58it/s, est. speed input: 36548.22 toks/s, output: 35.69 toks/s]
Processed prompts:  89%| | 1826/2048 [00:51<00:06, 32.57it/s, est. speed input: 36517.16 toks/s, output: 35.66 toks/s]
Processed prompts:  90%| | 1842/2048 [00:51<00:06, 32.55it/s, est. speed input: 36486.40 toks/s, output: 35.63 toks/s]
Processed prompts:  91%| | 1858/2048 [00:52<00:05, 32.60it/s, est. speed input: 36458.33 toks/s, output: 35.60 toks/s]
Processed prompts:  92%|| 1874/2048 [00:52<00:05, 33.16it/s, est. speed input: 36449.00 toks/s, output: 35.59 toks/s]
Processed prompts:  92%|| 1890/2048 [00:53<00:04, 33.03it/s, est. speed input: 36421.84 toks/s, output: 35.57 toks/s]
Processed prompts:  93%|| 1906/2048 [00:53<00:04, 32.82it/s, est. speed input: 36391.54 toks/s, output: 35.54 toks/s]
Processed prompts:  94%|| 1922/2048 [00:54<00:03, 32.76it/s, est. speed input: 36364.37 toks/s, output: 35.51 toks/s]
Processed prompts:  95%|| 1938/2048 [00:54<00:03, 32.64it/s, est. speed input: 36335.28 toks/s, output: 35.48 toks/s]
Processed prompts:  95%|| 1954/2048 [00:55<00:02, 33.28it/s, est. speed input: 36330.02 toks/s, output: 35.48 toks/s]
Processed prompts:  96%|| 1970/2048 [00:55<00:02, 32.96it/s, est. speed input: 36300.33 toks/s, output: 35.45 toks/s]
Processed prompts:  97%|| 1986/2048 [00:56<00:01, 33.50it/s, est. speed input: 36295.02 toks/s, output: 35.44 toks/s]
Processed prompts:  98%|| 2002/2048 [00:56<00:01, 34.07it/s, est. speed input: 36295.53 toks/s, output: 35.44 toks/s]
Processed prompts:  99%|| 2018/2048 [00:56<00:00, 33.60it/s, est. speed input: 36269.76 toks/s, output: 35.42 toks/s]
Processed prompts:  99%|| 2034/2048 [00:57<00:00, 33.67it/s, est. speed input: 36256.59 toks/s, output: 35.41 toks/s]
Processed prompts: 100%|| 2048/2048 [00:57<00:00, 33.67it/s, est. speed input: 36506.03 toks/s, output: 35.65 toks/s]
Processed prompts: 100%|| 2048/2048 [00:57<00:00, 35.65it/s, est. speed input: 36506.03 toks/s, output: 35.65 toks/s]
[rank0]:[W126 04:12:30.076042493 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-26 04:12:33
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Llama3.2-1B-FP8_M32768.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 04:12:48 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 04:12:48 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=846098) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=846098) WARNING 01-26 04:13:09 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 32.01 requests/s, 32815.32 total tokens/s, 32.01 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-26 04:12:48] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 04:12:48] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 04:12:48] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 04:12:48] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:12:48] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:12:48] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:12:48] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:12:48] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:12:48] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 04:12:48] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 04:12:48] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:12:48] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:12:48] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:12:48] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 04:12:51] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 04:12:51] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 04:12:51] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 04:12:51] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:12:51] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:12:51] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:12:51] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:12:51] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:12:51] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 04:12:51] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 04:12:51] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:12:51] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:12:51] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:12:51] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=846098) [2026-01-26 04:12:52] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=846098) [2026-01-26 04:12:52] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=846098) [2026-01-26 04:12:52] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=846098) [2026-01-26 04:12:52] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=846098) [2026-01-26 04:12:52] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=846098) [2026-01-26 04:12:52] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=846098) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=846098) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.26s/it]
(EngineCore_DP0 pid=846098) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.26s/it]
(EngineCore_DP0 pid=846098) 
(EngineCore_DP0 pid=846098) [2026-01-26 04:13:01] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=846098) [2026-01-26 04:13:01] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=846098) [2026-01-26 04:13:01] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=846098) [2026-01-26 04:13:01] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 2621440 bytes
(EngineCore_DP0 pid=846098) [2026-01-26 04:13:01] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=846098) [2026-01-26 04:13:01] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 20971520 bytes
(EngineCore_DP0 pid=846098) [2026-01-26 04:13:01] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=846098) [2026-01-26 04:13:01] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10485760 bytes
(EngineCore_DP0 pid=846098) 2026-01-26 04:13:07,320 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=846098) 2026-01-26 04:13:07,481 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|         | 57/4096 [00:00<00:07, 562.66it/s]
Adding requests:   3%|         | 114/4096 [00:00<00:08, 460.96it/s]
Adding requests:   4%|         | 162/4096 [00:00<00:08, 465.54it/s]
Adding requests:   5%|         | 216/4096 [00:00<00:07, 490.27it/s]
Adding requests:   7%|         | 273/4096 [00:00<00:07, 514.41it/s]
Adding requests:   8%|         | 326/4096 [00:00<00:07, 519.30it/s]
Adding requests:   9%|         | 384/4096 [00:00<00:06, 535.16it/s]
Adding requests:  11%|         | 438/4096 [00:00<00:07, 508.34it/s]
Adding requests:  12%|        | 490/4096 [00:00<00:07, 505.34it/s]
Adding requests:  13%|        | 541/4096 [00:01<00:07, 477.71it/s]
Adding requests:  14%|        | 593/4096 [00:01<00:07, 485.22it/s]
Adding requests:  16%|        | 642/4096 [00:01<00:07, 475.77it/s]
Adding requests:  17%|        | 691/4096 [00:01<00:07, 475.84it/s]
Adding requests:  18%|        | 741/4096 [00:01<00:06, 481.06it/s]
Adding requests:  19%|        | 797/4096 [00:01<00:06, 503.41it/s]
Adding requests:  21%|        | 852/4096 [00:01<00:06, 516.13it/s]
Adding requests:  22%|       | 914/4096 [00:01<00:05, 546.69it/s]
Adding requests:  24%|       | 969/4096 [00:01<00:06, 466.12it/s]
Adding requests:  25%|       | 1018/4096 [00:02<00:06, 468.17it/s]
Adding requests:  26%|       | 1067/4096 [00:02<00:06, 468.02it/s]
Adding requests:  27%|       | 1118/4096 [00:02<00:06, 479.63it/s]
Adding requests:  28%|       | 1167/4096 [00:02<00:06, 455.78it/s]
Adding requests:  30%|       | 1227/4096 [00:02<00:05, 495.48it/s]
Adding requests:  31%|       | 1278/4096 [00:02<00:05, 495.53it/s]
Adding requests:  32%|      | 1329/4096 [00:02<00:06, 458.34it/s]
Adding requests:  34%|      | 1376/4096 [00:02<00:06, 438.14it/s]
Adding requests:  35%|      | 1431/4096 [00:02<00:05, 468.35it/s]
Adding requests:  36%|      | 1479/4096 [00:03<00:06, 419.38it/s]
Adding requests:  37%|      | 1529/4096 [00:03<00:05, 440.08it/s]
Adding requests:  38%|      | 1575/4096 [00:03<00:06, 415.16it/s]
Adding requests:  40%|      | 1618/4096 [00:03<00:06, 407.55it/s]
Adding requests:  41%|      | 1676/4096 [00:03<00:05, 452.15it/s]
Adding requests:  42%|     | 1723/4096 [00:03<00:05, 446.11it/s]
Adding requests:  43%|     | 1769/4096 [00:03<00:05, 420.45it/s]
Adding requests:  45%|     | 1831/4096 [00:03<00:04, 474.34it/s]
Adding requests:  46%|     | 1880/4096 [00:03<00:04, 455.29it/s]
Adding requests:  47%|     | 1930/4096 [00:04<00:04, 467.36it/s]
Adding requests:  48%|     | 1978/4096 [00:04<00:04, 457.91it/s]
Adding requests:  50%|     | 2036/4096 [00:04<00:04, 490.78it/s]
Adding requests:  51%|     | 2086/4096 [00:04<00:04, 454.11it/s]
Adding requests:  52%|    | 2135/4096 [00:04<00:04, 461.46it/s]
Adding requests:  53%|    | 2186/4096 [00:04<00:04, 474.25it/s]
Adding requests:  55%|    | 2239/4096 [00:04<00:03, 488.34it/s]
Adding requests:  56%|    | 2289/4096 [00:04<00:03, 488.59it/s]
Adding requests:  57%|    | 2339/4096 [00:04<00:03, 487.20it/s]
Adding requests:  58%|    | 2392/4096 [00:05<00:03, 494.27it/s]
Adding requests:  60%|    | 2442/4096 [00:05<00:03, 450.44it/s]
Adding requests:  61%|    | 2496/4096 [00:05<00:03, 474.13it/s]
Adding requests:  62%|   | 2545/4096 [00:05<00:03, 403.48it/s]
Adding requests:  63%|   | 2593/4096 [00:05<00:03, 421.51it/s]
Adding requests:  64%|   | 2638/4096 [00:05<00:03, 409.08it/s]
Adding requests:  65%|   | 2681/4096 [00:05<00:03, 414.17it/s]
Adding requests:  67%|   | 2729/4096 [00:05<00:03, 432.02it/s]
Adding requests:  68%|   | 2775/4096 [00:05<00:03, 436.46it/s]
Adding requests:  69%|   | 2820/4096 [00:06<00:03, 407.26it/s]
Adding requests:  70%|   | 2862/4096 [00:06<00:03, 391.43it/s]
Adding requests:  71%|   | 2905/4096 [00:06<00:02, 401.65it/s]
Adding requests:  72%|  | 2946/4096 [00:06<00:02, 391.91it/s]
Adding requests:  73%|  | 3007/4096 [00:06<00:02, 446.77it/s]
Adding requests:  75%|  | 3053/4096 [00:06<00:02, 419.84it/s]
Adding requests:  76%|  | 3096/4096 [00:06<00:02, 400.72it/s]
Adding requests:  77%|  | 3137/4096 [00:06<00:02, 382.89it/s]
Adding requests:  78%|  | 3177/4096 [00:06<00:02, 386.70it/s]
Adding requests:  79%|  | 3216/4096 [00:07<00:02, 382.64it/s]
Adding requests:  80%|  | 3258/4096 [00:07<00:02, 391.81it/s]
Adding requests:  81%|  | 3308/4096 [00:07<00:01, 422.05it/s]
Adding requests:  82%| | 3356/4096 [00:07<00:01, 437.31it/s]
Adding requests:  83%| | 3405/4096 [00:07<00:01, 452.48it/s]
Adding requests:  84%| | 3453/4096 [00:07<00:01, 457.62it/s]
Adding requests:  85%| | 3499/4096 [00:07<00:01, 453.49it/s]
Adding requests:  87%| | 3545/4096 [00:07<00:01, 453.19it/s]
Adding requests:  88%| | 3591/4096 [00:07<00:01, 454.90it/s]
Adding requests:  89%| | 3640/4096 [00:08<00:00, 464.88it/s]
Adding requests:  90%| | 3689/4096 [00:08<00:00, 472.17it/s]
Adding requests:  91%|| 3739/4096 [00:08<00:00, 478.87it/s]
Adding requests:  92%|| 3787/4096 [00:08<00:00, 463.22it/s]
Adding requests:  94%|| 3834/4096 [00:08<00:00, 461.00it/s]
Adding requests:  95%|| 3884/4096 [00:08<00:00, 469.73it/s]
Adding requests:  96%|| 3934/4096 [00:08<00:00, 477.58it/s]
Adding requests:  97%|| 3982/4096 [00:08<00:00, 473.58it/s]
Adding requests:  98%|| 4030/4096 [00:08<00:00, 473.63it/s]
Adding requests: 100%|| 4080/4096 [00:08<00:00, 479.27it/s]
Adding requests: 100%|| 4096/4096 [00:08<00:00, 456.86it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   4%|         | 162/4096 [00:00<00:16, 234.03it/s, est. speed input: 239660.89 toks/s, output: 234.04 toks/s]
Processed prompts:   5%|         | 194/4096 [00:01<00:39, 98.80it/s, est. speed input: 118302.60 toks/s, output: 115.52 toks/s] 
Processed prompts:   6%|         | 226/4096 [00:02<00:58, 66.60it/s, est. speed input: 87073.14 toks/s, output: 85.03 toks/s]  
Processed prompts:   6%|         | 258/4096 [00:03<01:12, 52.67it/s, est. speed input: 72637.70 toks/s, output: 70.93 toks/s]
Processed prompts:   7%|         | 290/4096 [00:04<01:24, 45.23it/s, est. speed input: 64288.58 toks/s, output: 62.78 toks/s]
Processed prompts:   8%|         | 322/4096 [00:05<01:32, 40.77it/s, est. speed input: 58802.61 toks/s, output: 57.42 toks/s]
Processed prompts:   9%|         | 354/4096 [00:06<01:38, 38.03it/s, est. speed input: 54985.74 toks/s, output: 53.70 toks/s]
Processed prompts:   9%|         | 386/4096 [00:07<01:42, 36.28it/s, est. speed input: 52178.86 toks/s, output: 50.96 toks/s]
Processed prompts:  10%|         | 418/4096 [00:08<01:44, 35.12it/s, est. speed input: 50022.85 toks/s, output: 48.85 toks/s]
Processed prompts:  11%|         | 450/4096 [00:09<01:45, 34.47it/s, est. speed input: 48372.18 toks/s, output: 47.24 toks/s]
Processed prompts:  12%|        | 482/4096 [00:10<01:46, 33.87it/s, est. speed input: 46960.52 toks/s, output: 45.86 toks/s]
Processed prompts:  13%|        | 514/4096 [00:11<01:47, 33.44it/s, est. speed input: 45785.72 toks/s, output: 44.71 toks/s]
Processed prompts:  13%|        | 546/4096 [00:12<01:46, 33.19it/s, est. speed input: 44809.79 toks/s, output: 43.76 toks/s]
Processed prompts:  14%|        | 578/4096 [00:13<01:46, 33.02it/s, est. speed input: 43978.91 toks/s, output: 42.95 toks/s]
Processed prompts:  15%|        | 610/4096 [00:14<01:45, 32.92it/s, est. speed input: 43265.58 toks/s, output: 42.25 toks/s]
Processed prompts:  16%|        | 642/4096 [00:15<01:45, 32.74it/s, est. speed input: 42615.38 toks/s, output: 41.62 toks/s]
Processed prompts:  16%|        | 674/4096 [00:16<01:44, 32.64it/s, est. speed input: 42047.23 toks/s, output: 41.06 toks/s]
Processed prompts:  17%|        | 706/4096 [00:17<01:44, 32.60it/s, est. speed input: 41550.68 toks/s, output: 40.58 toks/s]
Processed prompts:  18%|        | 738/4096 [00:18<01:42, 32.61it/s, est. speed input: 41117.24 toks/s, output: 40.15 toks/s]
Processed prompts:  19%|        | 770/4096 [00:19<01:42, 32.59it/s, est. speed input: 40722.23 toks/s, output: 39.77 toks/s]
Processed prompts:  20%|        | 802/4096 [00:20<01:41, 32.58it/s, est. speed input: 40364.74 toks/s, output: 39.42 toks/s]
Processed prompts:  20%|        | 834/4096 [00:21<01:40, 32.54it/s, est. speed input: 40035.41 toks/s, output: 39.10 toks/s]
Processed prompts:  21%|        | 866/4096 [00:22<01:39, 32.52it/s, est. speed input: 39735.18 toks/s, output: 38.80 toks/s]
Processed prompts:  22%|       | 898/4096 [00:23<01:38, 32.54it/s, est. speed input: 39467.38 toks/s, output: 38.54 toks/s]
Processed prompts:  23%|       | 930/4096 [00:24<01:36, 32.82it/s, est. speed input: 39263.34 toks/s, output: 38.34 toks/s]
Processed prompts:  23%|       | 962/4096 [00:25<01:34, 33.06it/s, est. speed input: 39081.33 toks/s, output: 38.17 toks/s]
Processed prompts:  24%|       | 994/4096 [00:26<01:34, 32.90it/s, est. speed input: 38865.36 toks/s, output: 37.95 toks/s]
Processed prompts:  25%|       | 1026/4096 [00:27<01:33, 32.78it/s, est. speed input: 38662.24 toks/s, output: 37.76 toks/s]
Processed prompts:  26%|       | 1058/4096 [00:28<01:32, 32.69it/s, est. speed input: 38473.13 toks/s, output: 37.57 toks/s]
Processed prompts:  27%|       | 1090/4096 [00:29<01:32, 32.67it/s, est. speed input: 38302.33 toks/s, output: 37.40 toks/s]
Processed prompts:  27%|       | 1122/4096 [00:30<01:31, 32.57it/s, est. speed input: 38132.50 toks/s, output: 37.24 toks/s]
Processed prompts:  28%|       | 1154/4096 [00:31<01:29, 32.82it/s, est. speed input: 38012.17 toks/s, output: 37.12 toks/s]
Processed prompts:  29%|       | 1186/4096 [00:32<01:28, 32.73it/s, est. speed input: 37866.99 toks/s, output: 36.98 toks/s]
Processed prompts:  30%|       | 1218/4096 [00:33<01:28, 32.66it/s, est. speed input: 37730.68 toks/s, output: 36.85 toks/s]
Processed prompts:  31%|       | 1250/4096 [00:34<01:26, 32.92it/s, est. speed input: 37636.21 toks/s, output: 36.75 toks/s]
Processed prompts:  31%|      | 1282/4096 [00:34<01:24, 33.11it/s, est. speed input: 37547.01 toks/s, output: 36.67 toks/s]
Processed prompts:  32%|      | 1314/4096 [00:35<01:24, 32.94it/s, est. speed input: 37431.53 toks/s, output: 36.55 toks/s]
Processed prompts:  33%|      | 1346/4096 [00:36<01:23, 32.79it/s, est. speed input: 37319.53 toks/s, output: 36.44 toks/s]
Processed prompts:  34%|      | 1378/4096 [00:37<01:23, 32.70it/s, est. speed input: 37213.86 toks/s, output: 36.34 toks/s]
Processed prompts:  34%|      | 1410/4096 [00:38<01:22, 32.64it/s, est. speed input: 37114.33 toks/s, output: 36.24 toks/s]
Processed prompts:  35%|      | 1442/4096 [00:39<01:21, 32.61it/s, est. speed input: 37020.64 toks/s, output: 36.15 toks/s]
Processed prompts:  36%|      | 1474/4096 [00:40<01:20, 32.59it/s, est. speed input: 36931.55 toks/s, output: 36.07 toks/s]
Processed prompts:  37%|      | 1506/4096 [00:41<01:19, 32.54it/s, est. speed input: 36844.11 toks/s, output: 35.98 toks/s]
Processed prompts:  38%|      | 1538/4096 [00:42<01:18, 32.53it/s, est. speed input: 36762.41 toks/s, output: 35.90 toks/s]
Processed prompts:  38%|      | 1570/4096 [00:43<01:17, 32.77it/s, est. speed input: 36704.82 toks/s, output: 35.84 toks/s]
Processed prompts:  39%|      | 1602/4096 [00:44<01:16, 32.69it/s, est. speed input: 36629.52 toks/s, output: 35.77 toks/s]
Processed prompts:  40%|      | 1634/4096 [00:45<01:14, 32.98it/s, est. speed input: 36584.95 toks/s, output: 35.73 toks/s]
Processed prompts:  41%|      | 1666/4096 [00:46<01:14, 32.81it/s, est. speed input: 36513.68 toks/s, output: 35.66 toks/s]
Processed prompts:  41%|     | 1698/4096 [00:47<01:13, 32.73it/s, est. speed input: 36448.14 toks/s, output: 35.59 toks/s]
Processed prompts:  42%|     | 1730/4096 [00:48<01:12, 32.67it/s, est. speed input: 36384.26 toks/s, output: 35.53 toks/s]
Processed prompts:  43%|     | 1762/4096 [00:49<01:11, 32.60it/s, est. speed input: 36321.74 toks/s, output: 35.47 toks/s]
Processed prompts:  44%|     | 1794/4096 [00:50<01:10, 32.56it/s, est. speed input: 36261.39 toks/s, output: 35.41 toks/s]
Processed prompts:  45%|     | 1826/4096 [00:51<01:09, 32.54it/s, est. speed input: 36204.51 toks/s, output: 35.36 toks/s]
Processed prompts:  45%|     | 1858/4096 [00:52<01:08, 32.80it/s, est. speed input: 36168.56 toks/s, output: 35.32 toks/s]
Processed prompts:  46%|     | 1890/4096 [00:53<01:07, 32.72it/s, est. speed input: 36116.12 toks/s, output: 35.27 toks/s]
Processed prompts:  47%|     | 1922/4096 [00:54<01:06, 32.63it/s, est. speed input: 36063.28 toks/s, output: 35.22 toks/s]
Processed prompts:  48%|     | 1954/4096 [00:55<01:05, 32.93it/s, est. speed input: 36036.16 toks/s, output: 35.19 toks/s]
Processed prompts:  48%|     | 1986/4096 [00:56<01:03, 33.46it/s, est. speed input: 36028.92 toks/s, output: 35.18 toks/s]
Processed prompts:  49%|     | 2018/4096 [00:57<01:02, 33.18it/s, est. speed input: 35982.42 toks/s, output: 35.14 toks/s]
Processed prompts:  50%|     | 2050/4096 [00:58<01:01, 33.40it/s, est. speed input: 35962.66 toks/s, output: 35.12 toks/s]
Processed prompts:  51%|     | 2082/4096 [00:59<01:00, 33.41it/s, est. speed input: 35934.65 toks/s, output: 35.09 toks/s]
Processed prompts:  52%|    | 2114/4096 [01:00<00:59, 33.11it/s, est. speed input: 35890.15 toks/s, output: 35.05 toks/s]
Processed prompts:  52%|    | 2146/4096 [01:01<00:59, 32.91it/s, est. speed input: 35847.13 toks/s, output: 35.01 toks/s]
Processed prompts:  53%|    | 2178/4096 [01:02<00:57, 33.40it/s, est. speed input: 35840.81 toks/s, output: 35.00 toks/s]
Processed prompts:  54%|    | 2210/4096 [01:03<00:55, 33.72it/s, est. speed input: 35833.53 toks/s, output: 34.99 toks/s]
Processed prompts:  55%|    | 2242/4096 [01:04<00:55, 33.41it/s, est. speed input: 35797.64 toks/s, output: 34.96 toks/s]
Processed prompts:  56%|    | 2274/4096 [01:05<00:54, 33.38it/s, est. speed input: 35772.93 toks/s, output: 34.93 toks/s]
Processed prompts:  56%|    | 2306/4096 [01:06<00:53, 33.38it/s, est. speed input: 35749.99 toks/s, output: 34.91 toks/s]
Processed prompts:  57%|    | 2338/4096 [01:07<00:52, 33.38it/s, est. speed input: 35727.17 toks/s, output: 34.89 toks/s]
Processed prompts:  58%|    | 2370/4096 [01:07<00:50, 34.01it/s, est. speed input: 35736.45 toks/s, output: 34.90 toks/s]
Processed prompts:  59%|    | 2402/4096 [01:08<00:50, 33.82it/s, est. speed input: 35714.77 toks/s, output: 34.88 toks/s]
Processed prompts:  59%|    | 2434/4096 [01:09<00:49, 33.69it/s, est. speed input: 35694.08 toks/s, output: 34.86 toks/s]
Processed prompts:  60%|    | 2466/4096 [01:10<00:48, 33.59it/s, est. speed input: 35673.08 toks/s, output: 34.84 toks/s]
Processed prompts:  61%|    | 2498/4096 [01:11<00:47, 33.61it/s, est. speed input: 35657.07 toks/s, output: 34.82 toks/s]
Processed prompts:  62%|   | 2530/4096 [01:12<00:47, 33.24it/s, est. speed input: 35623.75 toks/s, output: 34.79 toks/s]
Processed prompts:  63%|   | 2562/4096 [01:13<00:46, 33.27it/s, est. speed input: 35604.38 toks/s, output: 34.77 toks/s]
Processed prompts:  63%|   | 2594/4096 [01:14<00:45, 33.35it/s, est. speed input: 35588.04 toks/s, output: 34.75 toks/s]
Processed prompts:  64%|   | 2626/4096 [01:15<00:44, 33.08it/s, est. speed input: 35557.78 toks/s, output: 34.72 toks/s]
Processed prompts:  65%|   | 2658/4096 [01:16<00:43, 32.87it/s, est. speed input: 35526.90 toks/s, output: 34.69 toks/s]
Processed prompts:  66%|   | 2690/4096 [01:17<00:42, 33.35it/s, est. speed input: 35524.85 toks/s, output: 34.69 toks/s]
Processed prompts:  66%|   | 2722/4096 [01:18<00:41, 33.08it/s, est. speed input: 35496.33 toks/s, output: 34.66 toks/s]
Processed prompts:  67%|   | 2754/4096 [01:19<00:40, 33.17it/s, est. speed input: 35480.58 toks/s, output: 34.65 toks/s]
Processed prompts:  68%|   | 2786/4096 [01:20<00:39, 32.95it/s, est. speed input: 35452.62 toks/s, output: 34.62 toks/s]
Processed prompts:  69%|   | 2818/4096 [01:21<00:38, 33.42it/s, est. speed input: 35452.28 toks/s, output: 34.62 toks/s]
Processed prompts:  70%|   | 2850/4096 [01:22<00:37, 33.42it/s, est. speed input: 35438.07 toks/s, output: 34.61 toks/s]
Processed prompts:  70%|   | 2882/4096 [01:23<00:36, 33.14it/s, est. speed input: 35412.41 toks/s, output: 34.58 toks/s]
Processed prompts:  71%|   | 2914/4096 [01:24<00:35, 32.92it/s, est. speed input: 35386.38 toks/s, output: 34.56 toks/s]
Processed prompts:  72%|  | 2946/4096 [01:25<00:34, 33.07it/s, est. speed input: 35373.45 toks/s, output: 34.54 toks/s]
Processed prompts:  73%|  | 2978/4096 [01:26<00:34, 32.88it/s, est. speed input: 35348.99 toks/s, output: 34.52 toks/s]
Processed prompts:  73%|  | 3010/4096 [01:27<00:32, 33.34it/s, est. speed input: 35348.35 toks/s, output: 34.52 toks/s]
Processed prompts:  74%|  | 3042/4096 [01:28<00:31, 33.40it/s, est. speed input: 35337.37 toks/s, output: 34.51 toks/s]
Processed prompts:  75%|  | 3074/4096 [01:29<00:30, 33.12it/s, est. speed input: 35314.54 toks/s, output: 34.49 toks/s]
Processed prompts:  76%|  | 3106/4096 [01:30<00:29, 33.84it/s, est. speed input: 35326.49 toks/s, output: 34.50 toks/s]
Processed prompts:  77%|  | 3138/4096 [01:30<00:28, 34.04it/s, est. speed input: 35326.53 toks/s, output: 34.50 toks/s]
Processed prompts:  77%|  | 3170/4096 [01:31<00:27, 33.56it/s, est. speed input: 35304.53 toks/s, output: 34.48 toks/s]
Processed prompts:  78%|  | 3202/4096 [01:32<00:26, 33.82it/s, est. speed input: 35304.34 toks/s, output: 34.48 toks/s]
Processed prompts:  79%|  | 3234/4096 [01:33<00:25, 33.67it/s, est. speed input: 35292.21 toks/s, output: 34.47 toks/s]
Processed prompts:  80%|  | 3266/4096 [01:34<00:24, 33.29it/s, est. speed input: 35270.51 toks/s, output: 34.44 toks/s]
Processed prompts:  81%|  | 3298/4096 [01:35<00:23, 33.31it/s, est. speed input: 35259.31 toks/s, output: 34.43 toks/s]
Processed prompts:  81%| | 3330/4096 [01:36<00:22, 33.66it/s, est. speed input: 35260.25 toks/s, output: 34.43 toks/s]
Processed prompts:  82%| | 3362/4096 [01:37<00:22, 33.26it/s, est. speed input: 35238.75 toks/s, output: 34.41 toks/s]
Processed prompts:  83%| | 3394/4096 [01:38<00:21, 33.06it/s, est. speed input: 35220.37 toks/s, output: 34.39 toks/s]
Processed prompts:  84%| | 3426/4096 [01:39<00:20, 33.20it/s, est. speed input: 35211.65 toks/s, output: 34.39 toks/s]
Processed prompts:  84%| | 3458/4096 [01:40<00:19, 33.21it/s, est. speed input: 35200.60 toks/s, output: 34.38 toks/s]
Processed prompts:  85%| | 3490/4096 [01:41<00:18, 33.53it/s, est. speed input: 35199.74 toks/s, output: 34.37 toks/s]
Processed prompts:  86%| | 3522/4096 [01:42<00:17, 33.21it/s, est. speed input: 35181.07 toks/s, output: 34.36 toks/s]
Processed prompts:  87%| | 3554/4096 [01:43<00:16, 32.99it/s, est. speed input: 35162.84 toks/s, output: 34.34 toks/s]
Processed prompts:  88%| | 3586/4096 [01:44<00:15, 32.82it/s, est. speed input: 35144.51 toks/s, output: 34.32 toks/s]
Processed prompts:  88%| | 3618/4096 [01:45<00:14, 32.71it/s, est. speed input: 35126.59 toks/s, output: 34.30 toks/s]
Processed prompts:  89%| | 3650/4096 [01:46<00:13, 32.90it/s, est. speed input: 35117.92 toks/s, output: 34.29 toks/s]
Processed prompts:  90%| | 3682/4096 [01:47<00:12, 33.02it/s, est. speed input: 35108.88 toks/s, output: 34.29 toks/s]
Processed prompts:  91%| | 3714/4096 [01:48<00:11, 33.17it/s, est. speed input: 35101.90 toks/s, output: 34.28 toks/s]
Processed prompts:  91%|| 3746/4096 [01:49<00:10, 32.98it/s, est. speed input: 35085.98 toks/s, output: 34.26 toks/s]
Processed prompts:  92%|| 3778/4096 [01:50<00:09, 32.84it/s, est. speed input: 35070.14 toks/s, output: 34.25 toks/s]
Processed prompts:  93%|| 3810/4096 [01:51<00:08, 32.97it/s, est. speed input: 35061.46 toks/s, output: 34.24 toks/s]
Processed prompts:  94%|| 3842/4096 [01:52<00:07, 33.38it/s, est. speed input: 35062.75 toks/s, output: 34.24 toks/s]
Processed prompts:  95%|| 3874/4096 [01:53<00:06, 33.12it/s, est. speed input: 35047.55 toks/s, output: 34.23 toks/s]
Processed prompts:  95%|| 3906/4096 [01:54<00:05, 32.90it/s, est. speed input: 35031.24 toks/s, output: 34.21 toks/s]
Processed prompts:  96%|| 3938/4096 [01:55<00:04, 33.03it/s, est. speed input: 35023.75 toks/s, output: 34.20 toks/s]
Processed prompts:  97%|| 3970/4096 [01:56<00:03, 32.85it/s, est. speed input: 35008.34 toks/s, output: 34.19 toks/s]
Processed prompts:  98%|| 4002/4096 [01:57<00:02, 32.73it/s, est. speed input: 34993.40 toks/s, output: 34.17 toks/s]
Processed prompts:  98%|| 4034/4096 [01:58<00:01, 33.55it/s, est. speed input: 35004.72 toks/s, output: 34.18 toks/s]
Processed prompts:  99%|| 4066/4096 [01:58<00:00, 33.43it/s, est. speed input: 34996.10 toks/s, output: 34.18 toks/s]
Processed prompts: 100%|| 4096/4096 [01:58<00:00, 33.43it/s, est. speed input: 35254.23 toks/s, output: 34.43 toks/s]
Processed prompts: 100%|| 4096/4096 [01:58<00:00, 34.43it/s, est. speed input: 35254.23 toks/s, output: 34.43 toks/s]
[rank0]:[W126 04:15:17.779190817 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-26 04:15:20
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Llama3.2-1B-FP8_M65536.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 04:15:49 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 04:15:49 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=848799) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=848799) WARNING 01-26 04:16:12 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 33.36 requests/s, 34192.15 total tokens/s, 33.36 output tokens/s
Total num prompt tokens:  8388608
Total num output tokens:  8192

STDERR:
[2026-01-26 04:15:49] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 04:15:49] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 04:15:49] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 04:15:49] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:15:49] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:15:49] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:15:49] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:15:49] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:15:49] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 04:15:49] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 04:15:49] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:15:49] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:15:49] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:15:49] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 04:15:53] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 04:15:53] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 04:15:53] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 04:15:53] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:15:53] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:15:53] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:15:53] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:15:53] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:15:53] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 04:15:53] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 04:15:53] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:15:53] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:15:53] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:15:53] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=848799) [2026-01-26 04:15:54] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=848799) [2026-01-26 04:15:54] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=848799) [2026-01-26 04:15:54] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=848799) [2026-01-26 04:15:54] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=848799) [2026-01-26 04:15:54] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=848799) [2026-01-26 04:15:54] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=848799) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=848799) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.07s/it]
(EngineCore_DP0 pid=848799) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.07s/it]
(EngineCore_DP0 pid=848799) 
(EngineCore_DP0 pid=848799) [2026-01-26 04:16:02] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=848799) [2026-01-26 04:16:02] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=848799) [2026-01-26 04:16:02] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=848799) [2026-01-26 04:16:02] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 2621440 bytes
(EngineCore_DP0 pid=848799) [2026-01-26 04:16:02] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=848799) [2026-01-26 04:16:03] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 20971520 bytes
(EngineCore_DP0 pid=848799) [2026-01-26 04:16:03] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=848799) [2026-01-26 04:16:03] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10485760 bytes
(EngineCore_DP0 pid=848799) 2026-01-26 04:16:10,238 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=848799) 2026-01-26 04:16:10,482 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/8192 [00:00<?, ?it/s]
Adding requests:   1%|          | 59/8192 [00:00<00:14, 580.53it/s]
Adding requests:   1%|         | 118/8192 [00:00<00:14, 542.27it/s]
Adding requests:   2%|         | 173/8192 [00:00<00:16, 495.67it/s]
Adding requests:   3%|         | 223/8192 [00:00<00:16, 470.76it/s]
Adding requests:   3%|         | 271/8192 [00:00<00:16, 470.31it/s]
Adding requests:   4%|         | 319/8192 [00:00<00:17, 460.37it/s]
Adding requests:   4%|         | 366/8192 [00:00<00:16, 461.61it/s]
Adding requests:   5%|         | 413/8192 [00:00<00:16, 461.93it/s]
Adding requests:   6%|         | 462/8192 [00:00<00:16, 469.70it/s]
Adding requests:   6%|         | 510/8192 [00:01<00:16, 462.92it/s]
Adding requests:   7%|         | 557/8192 [00:01<00:16, 459.07it/s]
Adding requests:   7%|         | 603/8192 [00:01<00:16, 448.50it/s]
Adding requests:   8%|         | 653/8192 [00:01<00:16, 462.68it/s]
Adding requests:   9%|         | 700/8192 [00:01<00:17, 438.29it/s]
Adding requests:   9%|         | 745/8192 [00:01<00:17, 436.51it/s]
Adding requests:  10%|         | 792/8192 [00:01<00:16, 443.46it/s]
Adding requests:  10%|         | 838/8192 [00:01<00:16, 447.31it/s]
Adding requests:  11%|         | 886/8192 [00:01<00:16, 456.07it/s]
Adding requests:  11%|        | 934/8192 [00:02<00:15, 462.43it/s]
Adding requests:  12%|        | 981/8192 [00:02<00:15, 458.59it/s]
Adding requests:  13%|        | 1027/8192 [00:02<00:16, 445.67it/s]
Adding requests:  13%|        | 1075/8192 [00:02<00:15, 452.28it/s]
Adding requests:  14%|        | 1123/8192 [00:02<00:15, 459.94it/s]
Adding requests:  14%|        | 1171/8192 [00:02<00:15, 463.16it/s]
Adding requests:  15%|        | 1219/8192 [00:02<00:14, 466.56it/s]
Adding requests:  15%|        | 1266/8192 [00:02<00:14, 463.06it/s]
Adding requests:  16%|        | 1313/8192 [00:02<00:15, 455.82it/s]
Adding requests:  17%|        | 1359/8192 [00:02<00:14, 456.95it/s]
Adding requests:  17%|        | 1407/8192 [00:03<00:14, 461.50it/s]
Adding requests:  18%|        | 1454/8192 [00:03<00:14, 450.05it/s]
Adding requests:  18%|        | 1500/8192 [00:03<00:15, 420.99it/s]
Adding requests:  19%|        | 1547/8192 [00:03<00:15, 432.49it/s]
Adding requests:  19%|        | 1597/8192 [00:03<00:14, 449.79it/s]
Adding requests:  20%|        | 1646/8192 [00:03<00:14, 460.80it/s]
Adding requests:  21%|        | 1693/8192 [00:03<00:14, 459.88it/s]
Adding requests:  21%|        | 1740/8192 [00:03<00:14, 459.12it/s]
Adding requests:  22%|       | 1788/8192 [00:03<00:13, 463.64it/s]
Adding requests:  22%|       | 1837/8192 [00:03<00:13, 468.98it/s]
Adding requests:  23%|       | 1884/8192 [00:04<00:14, 442.95it/s]
Adding requests:  24%|       | 1929/8192 [00:04<00:14, 441.61it/s]
Adding requests:  24%|       | 1974/8192 [00:04<00:14, 443.31it/s]
Adding requests:  25%|       | 2022/8192 [00:04<00:13, 453.81it/s]
Adding requests:  25%|       | 2071/8192 [00:04<00:13, 462.24it/s]
Adding requests:  26%|       | 2118/8192 [00:04<00:13, 460.69it/s]
Adding requests:  26%|       | 2165/8192 [00:04<00:13, 457.44it/s]
Adding requests:  27%|       | 2211/8192 [00:04<00:13, 448.42it/s]
Adding requests:  28%|       | 2259/8192 [00:04<00:13, 456.36it/s]
Adding requests:  28%|       | 2306/8192 [00:05<00:12, 460.11it/s]
Adding requests:  29%|       | 2353/8192 [00:05<00:12, 461.99it/s]
Adding requests:  29%|       | 2401/8192 [00:05<00:12, 463.69it/s]
Adding requests:  30%|       | 2448/8192 [00:05<00:12, 456.22it/s]
Adding requests:  30%|       | 2495/8192 [00:05<00:12, 459.56it/s]
Adding requests:  31%|       | 2541/8192 [00:05<00:12, 459.65it/s]
Adding requests:  32%|      | 2589/8192 [00:05<00:12, 464.29it/s]
Adding requests:  32%|      | 2638/8192 [00:05<00:11, 469.32it/s]
Adding requests:  33%|      | 2685/8192 [00:05<00:11, 468.76it/s]
Adding requests:  33%|      | 2733/8192 [00:05<00:11, 472.02it/s]
Adding requests:  34%|      | 2781/8192 [00:06<00:11, 458.52it/s]
Adding requests:  35%|      | 2827/8192 [00:06<00:11, 453.41it/s]
Adding requests:  35%|      | 2874/8192 [00:06<00:11, 455.61it/s]
Adding requests:  36%|      | 2921/8192 [00:06<00:11, 459.53it/s]
Adding requests:  36%|      | 2969/8192 [00:06<00:11, 464.73it/s]
Adding requests:  37%|      | 3016/8192 [00:06<00:11, 463.25it/s]
Adding requests:  37%|      | 3063/8192 [00:06<00:11, 461.14it/s]
Adding requests:  38%|      | 3110/8192 [00:06<00:11, 459.96it/s]
Adding requests:  39%|      | 3157/8192 [00:06<00:11, 454.95it/s]
Adding requests:  39%|      | 3205/8192 [00:07<00:11, 431.21it/s]
Adding requests:  40%|      | 3249/8192 [00:07<00:11, 427.46it/s]
Adding requests:  40%|      | 3296/8192 [00:07<00:11, 436.71it/s]
Adding requests:  41%|      | 3343/8192 [00:07<00:10, 444.66it/s]
Adding requests:  41%|     | 3392/8192 [00:07<00:10, 455.62it/s]
Adding requests:  42%|     | 3441/8192 [00:07<00:10, 464.79it/s]
Adding requests:  43%|     | 3488/8192 [00:07<00:10, 459.16it/s]
Adding requests:  43%|     | 3536/8192 [00:07<00:10, 463.13it/s]
Adding requests:  44%|     | 3584/8192 [00:07<00:09, 467.48it/s]
Adding requests:  44%|     | 3631/8192 [00:07<00:09, 461.78it/s]
Adding requests:  45%|     | 3678/8192 [00:08<00:09, 453.48it/s]
Adding requests:  45%|     | 3725/8192 [00:08<00:09, 456.54it/s]
Adding requests:  46%|     | 3776/8192 [00:08<00:09, 470.86it/s]
Adding requests:  47%|     | 3824/8192 [00:08<00:09, 466.18it/s]
Adding requests:  47%|     | 3876/8192 [00:08<00:08, 481.66it/s]
Adding requests:  48%|     | 3925/8192 [00:08<00:08, 474.69it/s]
Adding requests:  49%|     | 3977/8192 [00:08<00:08, 486.30it/s]
Adding requests:  49%|     | 4026/8192 [00:08<00:08, 474.75it/s]
Adding requests:  50%|     | 4074/8192 [00:08<00:08, 473.98it/s]
Adding requests:  50%|     | 4122/8192 [00:08<00:08, 468.03it/s]
Adding requests:  51%|     | 4169/8192 [00:09<00:08, 467.78it/s]
Adding requests:  52%|    | 4221/8192 [00:09<00:08, 480.39it/s]
Adding requests:  52%|    | 4270/8192 [00:09<00:08, 472.25it/s]
Adding requests:  53%|    | 4319/8192 [00:09<00:08, 474.39it/s]
Adding requests:  53%|    | 4368/8192 [00:09<00:08, 475.54it/s]
Adding requests:  54%|    | 4417/8192 [00:09<00:07, 479.54it/s]
Adding requests:  55%|    | 4467/8192 [00:09<00:07, 483.99it/s]
Adding requests:  55%|    | 4516/8192 [00:09<00:07, 471.50it/s]
Adding requests:  56%|    | 4564/8192 [00:09<00:07, 465.98it/s]
Adding requests:  56%|    | 4611/8192 [00:10<00:08, 441.04it/s]
Adding requests:  57%|    | 4659/8192 [00:10<00:07, 450.67it/s]
Adding requests:  57%|    | 4705/8192 [00:10<00:07, 450.47it/s]
Adding requests:  58%|    | 4753/8192 [00:10<00:07, 456.70it/s]
Adding requests:  59%|    | 4800/8192 [00:10<00:07, 458.84it/s]
Adding requests:  59%|    | 4847/8192 [00:10<00:07, 459.90it/s]
Adding requests:  60%|    | 4895/8192 [00:10<00:07, 463.87it/s]
Adding requests:  60%|    | 4942/8192 [00:10<00:06, 465.32it/s]
Adding requests:  61%|    | 4990/8192 [00:10<00:06, 468.40it/s]
Adding requests:  61%|   | 5037/8192 [00:10<00:06, 460.47it/s]
Adding requests:  62%|   | 5086/8192 [00:11<00:06, 468.04it/s]
Adding requests:  63%|   | 5137/8192 [00:11<00:06, 478.38it/s]
Adding requests:  63%|   | 5185/8192 [00:11<00:06, 470.44it/s]
Adding requests:  64%|   | 5233/8192 [00:11<00:06, 470.61it/s]
Adding requests:  64%|   | 5281/8192 [00:11<00:06, 461.28it/s]
Adding requests:  65%|   | 5332/8192 [00:11<00:06, 473.64it/s]
Adding requests:  66%|   | 5382/8192 [00:11<00:05, 480.33it/s]
Adding requests:  66%|   | 5431/8192 [00:11<00:05, 477.54it/s]
Adding requests:  67%|   | 5479/8192 [00:11<00:05, 466.97it/s]
Adding requests:  67%|   | 5526/8192 [00:11<00:05, 454.23it/s]
Adding requests:  68%|   | 5574/8192 [00:12<00:05, 460.72it/s]
Adding requests:  69%|   | 5621/8192 [00:12<00:05, 458.50it/s]
Adding requests:  69%|   | 5670/8192 [00:12<00:05, 466.57it/s]
Adding requests:  70%|   | 5718/8192 [00:12<00:05, 469.91it/s]
Adding requests:  70%|   | 5769/8192 [00:12<00:05, 479.99it/s]
Adding requests:  71%|   | 5818/8192 [00:12<00:04, 476.55it/s]
Adding requests:  72%|  | 5866/8192 [00:12<00:04, 476.42it/s]
Adding requests:  72%|  | 5915/8192 [00:12<00:04, 480.09it/s]
Adding requests:  73%|  | 5964/8192 [00:12<00:04, 447.98it/s]
Adding requests:  73%|  | 6012/8192 [00:13<00:04, 455.73it/s]
Adding requests:  74%|  | 6063/8192 [00:13<00:04, 469.36it/s]
Adding requests:  75%|  | 6111/8192 [00:13<00:04, 469.99it/s]
Adding requests:  75%|  | 6159/8192 [00:13<00:04, 470.26it/s]
Adding requests:  76%|  | 6207/8192 [00:13<00:04, 467.52it/s]
Adding requests:  76%|  | 6256/8192 [00:13<00:04, 472.80it/s]
Adding requests:  77%|  | 6304/8192 [00:13<00:04, 470.29it/s]
Adding requests:  78%|  | 6353/8192 [00:13<00:03, 475.21it/s]
Adding requests:  78%|  | 6402/8192 [00:13<00:03, 477.79it/s]
Adding requests:  79%|  | 6450/8192 [00:13<00:03, 466.22it/s]
Adding requests:  79%|  | 6501/8192 [00:14<00:03, 476.23it/s]
Adding requests:  80%|  | 6550/8192 [00:14<00:03, 478.29it/s]
Adding requests:  81%|  | 6601/8192 [00:14<00:03, 486.29it/s]
Adding requests:  81%|  | 6651/8192 [00:14<00:03, 489.46it/s]
Adding requests:  82%| | 6701/8192 [00:14<00:03, 490.88it/s]
Adding requests:  82%| | 6751/8192 [00:14<00:02, 484.58it/s]
Adding requests:  83%| | 6801/8192 [00:14<00:02, 487.40it/s]
Adding requests:  84%| | 6850/8192 [00:14<00:02, 485.71it/s]
Adding requests:  84%| | 6899/8192 [00:14<00:02, 486.54it/s]
Adding requests:  85%| | 6952/8192 [00:14<00:02, 497.21it/s]
Adding requests:  85%| | 7002/8192 [00:15<00:02, 473.42it/s]
Adding requests:  86%| | 7051/8192 [00:15<00:02, 477.24it/s]
Adding requests:  87%| | 7100/8192 [00:15<00:02, 478.72it/s]
Adding requests:  87%| | 7150/8192 [00:15<00:02, 483.98it/s]
Adding requests:  88%| | 7201/8192 [00:15<00:02, 490.03it/s]
Adding requests:  89%| | 7251/8192 [00:15<00:01, 486.00it/s]
Adding requests:  89%| | 7303/8192 [00:15<00:01, 494.36it/s]
Adding requests:  90%| | 7353/8192 [00:15<00:01, 430.92it/s]
Adding requests:  90%| | 7406/8192 [00:15<00:01, 454.14it/s]
Adding requests:  91%| | 7457/8192 [00:16<00:01, 467.53it/s]
Adding requests:  92%|| 7508/8192 [00:16<00:01, 478.99it/s]
Adding requests:  92%|| 7557/8192 [00:16<00:01, 476.10it/s]
Adding requests:  93%|| 7606/8192 [00:16<00:01, 479.61it/s]
Adding requests:  93%|| 7656/8192 [00:16<00:01, 484.30it/s]
Adding requests:  94%|| 7709/8192 [00:16<00:00, 496.33it/s]
Adding requests:  95%|| 7759/8192 [00:16<00:00, 494.97it/s]
Adding requests:  95%|| 7809/8192 [00:16<00:00, 485.74it/s]
Adding requests:  96%|| 7858/8192 [00:16<00:00, 485.20it/s]
Adding requests:  97%|| 7907/8192 [00:16<00:00, 473.80it/s]
Adding requests:  97%|| 7957/8192 [00:17<00:00, 479.75it/s]
Adding requests:  98%|| 8006/8192 [00:17<00:00, 470.50it/s]
Adding requests:  98%|| 8056/8192 [00:17<00:00, 478.10it/s]
Adding requests:  99%|| 8107/8192 [00:17<00:00, 486.13it/s]
Adding requests: 100%|| 8158/8192 [00:17<00:00, 492.99it/s]
Adding requests: 100%|| 8192/8192 [00:17<00:00, 466.59it/s]

Processed prompts:   0%|          | 0/8192 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|         | 514/8192 [00:00<00:02, 3636.60it/s, est. speed input: 3724307.71 toks/s, output: 3636.74 toks/s]
Processed prompts:  11%|         | 878/8192 [00:09<01:39, 73.86it/s, est. speed input: 91355.80 toks/s, output: 89.21 toks/s]      
Processed prompts:  13%|        | 1030/8192 [00:15<02:17, 52.07it/s, est. speed input: 67474.47 toks/s, output: 65.89 toks/s]
Processed prompts:  14%|        | 1114/8192 [00:17<02:20, 50.50it/s, est. speed input: 64925.11 toks/s, output: 63.40 toks/s]
Processed prompts:  14%|        | 1167/8192 [00:19<02:33, 45.87it/s, est. speed input: 61319.85 toks/s, output: 59.88 toks/s]
Processed prompts:  15%|        | 1218/8192 [00:21<02:47, 41.52it/s, est. speed input: 58251.36 toks/s, output: 56.89 toks/s]
Processed prompts:  16%|        | 1282/8192 [00:23<02:54, 39.49it/s, est. speed input: 56244.14 toks/s, output: 54.93 toks/s]
Processed prompts:  16%|        | 1346/8192 [00:25<03:01, 37.79it/s, est. speed input: 54513.62 toks/s, output: 53.24 toks/s]
Processed prompts:  17%|        | 1410/8192 [00:27<03:05, 36.48it/s, est. speed input: 53033.44 toks/s, output: 51.79 toks/s]
Processed prompts:  18%|        | 1474/8192 [00:29<03:09, 35.52it/s, est. speed input: 51754.69 toks/s, output: 50.54 toks/s]
Processed prompts:  19%|        | 1538/8192 [00:31<03:10, 34.84it/s, est. speed input: 50649.17 toks/s, output: 49.46 toks/s]
Processed prompts:  20%|        | 1602/8192 [00:33<03:11, 34.38it/s, est. speed input: 49680.72 toks/s, output: 48.52 toks/s]
Processed prompts:  20%|        | 1666/8192 [00:34<03:12, 33.95it/s, est. speed input: 48790.57 toks/s, output: 47.65 toks/s]
Processed prompts:  21%|        | 1730/8192 [00:36<03:12, 33.63it/s, est. speed input: 47992.37 toks/s, output: 46.87 toks/s]
Processed prompts:  22%|       | 1794/8192 [00:38<03:11, 33.42it/s, est. speed input: 47278.54 toks/s, output: 46.17 toks/s]
Processed prompts:  23%|       | 1858/8192 [00:40<03:10, 33.32it/s, est. speed input: 46643.39 toks/s, output: 45.55 toks/s]
Processed prompts:  23%|       | 1922/8192 [00:42<03:08, 33.31it/s, est. speed input: 46077.42 toks/s, output: 45.00 toks/s]
Processed prompts:  24%|       | 1986/8192 [00:44<03:05, 33.46it/s, est. speed input: 45592.76 toks/s, output: 44.52 toks/s]
Processed prompts:  25%|       | 2050/8192 [00:46<03:02, 33.62it/s, est. speed input: 45156.79 toks/s, output: 44.10 toks/s]
Processed prompts:  26%|       | 2114/8192 [00:48<03:02, 33.29it/s, est. speed input: 44676.27 toks/s, output: 43.63 toks/s]
Processed prompts:  27%|       | 2178/8192 [00:50<02:59, 33.59it/s, est. speed input: 44323.04 toks/s, output: 43.28 toks/s]
Processed prompts:  27%|       | 2242/8192 [00:52<02:58, 33.41it/s, est. speed input: 43931.57 toks/s, output: 42.90 toks/s]
Processed prompts:  28%|       | 2306/8192 [00:54<02:56, 33.44it/s, est. speed input: 43591.95 toks/s, output: 42.57 toks/s]
Processed prompts:  29%|       | 2370/8192 [00:56<02:52, 33.81it/s, est. speed input: 43326.75 toks/s, output: 42.31 toks/s]
Processed prompts:  30%|       | 2434/8192 [00:57<02:50, 33.76it/s, est. speed input: 43035.59 toks/s, output: 42.03 toks/s]
Processed prompts:  30%|       | 2498/8192 [00:59<02:49, 33.61it/s, est. speed input: 42746.64 toks/s, output: 41.74 toks/s]
Processed prompts:  31%|      | 2562/8192 [01:01<02:47, 33.68it/s, est. speed input: 42499.27 toks/s, output: 41.50 toks/s]
Processed prompts:  32%|      | 2626/8192 [01:03<02:46, 33.42it/s, est. speed input: 42227.39 toks/s, output: 41.24 toks/s]
Processed prompts:  33%|      | 2690/8192 [01:05<02:44, 33.51it/s, est. speed input: 42004.15 toks/s, output: 41.02 toks/s]
Processed prompts:  34%|      | 2754/8192 [01:07<02:42, 33.42it/s, est. speed input: 41776.76 toks/s, output: 40.80 toks/s]
Processed prompts:  34%|      | 2818/8192 [01:09<02:39, 33.65it/s, est. speed input: 41594.08 toks/s, output: 40.62 toks/s]
Processed prompts:  35%|      | 2882/8192 [01:11<02:38, 33.45it/s, est. speed input: 41381.84 toks/s, output: 40.41 toks/s]
Processed prompts:  36%|      | 2946/8192 [01:13<02:37, 33.36it/s, est. speed input: 41185.77 toks/s, output: 40.22 toks/s]
Processed prompts:  37%|      | 3010/8192 [01:15<02:34, 33.62it/s, est. speed input: 41033.34 toks/s, output: 40.07 toks/s]
Processed prompts:  38%|      | 3074/8192 [01:16<02:31, 33.80it/s, est. speed input: 40888.31 toks/s, output: 39.93 toks/s]
Processed prompts:  38%|      | 3138/8192 [01:18<02:29, 33.80it/s, est. speed input: 40737.66 toks/s, output: 39.78 toks/s]
Processed prompts:  39%|      | 3202/8192 [01:20<02:27, 33.94it/s, est. speed input: 40607.26 toks/s, output: 39.66 toks/s]
Processed prompts:  40%|      | 3266/8192 [01:22<02:26, 33.70it/s, est. speed input: 40451.37 toks/s, output: 39.50 toks/s]
Processed prompts:  41%|      | 3330/8192 [01:24<02:24, 33.67it/s, est. speed input: 40315.59 toks/s, output: 39.37 toks/s]
Processed prompts:  41%|     | 3394/8192 [01:26<02:23, 33.53it/s, est. speed input: 40175.12 toks/s, output: 39.23 toks/s]
Processed prompts:  42%|     | 3458/8192 [01:28<02:20, 33.75it/s, est. speed input: 40067.57 toks/s, output: 39.13 toks/s]
Processed prompts:  43%|     | 3522/8192 [01:30<02:19, 33.49it/s, est. speed input: 39929.82 toks/s, output: 38.99 toks/s]
Processed prompts:  44%|     | 3586/8192 [01:32<02:18, 33.30it/s, est. speed input: 39797.30 toks/s, output: 38.86 toks/s]
Processed prompts:  45%|     | 3650/8192 [01:34<02:16, 33.38it/s, est. speed input: 39687.65 toks/s, output: 38.76 toks/s]
Processed prompts:  45%|     | 3714/8192 [01:36<02:14, 33.36it/s, est. speed input: 39576.37 toks/s, output: 38.65 toks/s]
Processed prompts:  46%|     | 3778/8192 [01:38<02:12, 33.33it/s, est. speed input: 39468.24 toks/s, output: 38.54 toks/s]
Processed prompts:  47%|     | 3842/8192 [01:39<02:10, 33.41it/s, est. speed input: 39371.40 toks/s, output: 38.45 toks/s]
Processed prompts:  48%|     | 3906/8192 [01:41<02:08, 33.36it/s, est. speed input: 39270.51 toks/s, output: 38.35 toks/s]
Processed prompts:  48%|     | 3970/8192 [01:43<02:07, 33.22it/s, est. speed input: 39166.14 toks/s, output: 38.25 toks/s]
Processed prompts:  49%|     | 4034/8192 [01:45<02:04, 33.52it/s, est. speed input: 39093.66 toks/s, output: 38.18 toks/s]
Processed prompts:  50%|     | 4098/8192 [01:47<02:02, 33.36it/s, est. speed input: 38997.67 toks/s, output: 38.08 toks/s]
Processed prompts:  51%|     | 4162/8192 [01:49<01:59, 33.74it/s, est. speed input: 38938.80 toks/s, output: 38.03 toks/s]
Processed prompts:  52%|    | 4226/8192 [01:51<01:57, 33.77it/s, est. speed input: 38866.20 toks/s, output: 37.96 toks/s]
Processed prompts:  52%|    | 4290/8192 [01:53<01:56, 33.58it/s, est. speed input: 38781.70 toks/s, output: 37.87 toks/s]
Processed prompts:  53%|    | 4354/8192 [01:55<01:55, 33.37it/s, est. speed input: 38695.61 toks/s, output: 37.79 toks/s]
Processed prompts:  54%|    | 4418/8192 [01:57<01:52, 33.46it/s, est. speed input: 38627.37 toks/s, output: 37.72 toks/s]
Processed prompts:  55%|    | 4482/8192 [01:59<01:51, 33.28it/s, est. speed input: 38545.74 toks/s, output: 37.64 toks/s]
Processed prompts:  55%|    | 4546/8192 [02:00<01:48, 33.61it/s, est. speed input: 38495.23 toks/s, output: 37.59 toks/s]
Processed prompts:  56%|    | 4610/8192 [02:02<01:46, 33.50it/s, est. speed input: 38425.26 toks/s, output: 37.52 toks/s]
Processed prompts:  57%|    | 4674/8192 [02:04<01:45, 33.30it/s, est. speed input: 38350.18 toks/s, output: 37.45 toks/s]
Processed prompts:  58%|    | 4738/8192 [02:06<01:43, 33.43it/s, est. speed input: 38293.32 toks/s, output: 37.40 toks/s]
Processed prompts:  59%|    | 4802/8192 [02:08<01:41, 33.38it/s, est. speed input: 38229.99 toks/s, output: 37.33 toks/s]
Processed prompts:  59%|    | 4866/8192 [02:10<01:39, 33.35it/s, est. speed input: 38169.06 toks/s, output: 37.27 toks/s]
Processed prompts:  60%|    | 4930/8192 [02:12<01:37, 33.32it/s, est. speed input: 38108.97 toks/s, output: 37.22 toks/s]
Processed prompts:  61%|    | 4994/8192 [02:14<01:35, 33.45it/s, est. speed input: 38059.28 toks/s, output: 37.17 toks/s]
Processed prompts:  62%|   | 5058/8192 [02:16<01:33, 33.67it/s, est. speed input: 38017.45 toks/s, output: 37.13 toks/s]
Processed prompts:  63%|   | 5122/8192 [02:18<01:31, 33.47it/s, est. speed input: 37958.21 toks/s, output: 37.07 toks/s]
Processed prompts:  63%|   | 5186/8192 [02:20<01:29, 33.70it/s, est. speed input: 37919.92 toks/s, output: 37.03 toks/s]
Processed prompts:  64%|   | 5250/8192 [02:21<01:26, 33.87it/s, est. speed input: 37882.58 toks/s, output: 36.99 toks/s]
Processed prompts:  65%|   | 5314/8192 [02:23<01:24, 34.01it/s, est. speed input: 37847.19 toks/s, output: 36.96 toks/s]
Processed prompts:  66%|   | 5378/8192 [02:25<01:23, 33.76it/s, est. speed input: 37796.27 toks/s, output: 36.91 toks/s]
Processed prompts:  66%|   | 5442/8192 [02:27<01:21, 33.72it/s, est. speed input: 37753.08 toks/s, output: 36.87 toks/s]
Processed prompts:  67%|   | 5506/8192 [02:29<01:20, 33.56it/s, est. speed input: 37704.51 toks/s, output: 36.82 toks/s]
Processed prompts:  68%|   | 5570/8192 [02:31<01:18, 33.38it/s, est. speed input: 37653.65 toks/s, output: 36.77 toks/s]
Processed prompts:  69%|   | 5634/8192 [02:33<01:16, 33.49it/s, est. speed input: 37615.79 toks/s, output: 36.73 toks/s]
Processed prompts:  70%|   | 5698/8192 [02:35<01:14, 33.58it/s, est. speed input: 37578.88 toks/s, output: 36.70 toks/s]
Processed prompts:  70%|   | 5762/8192 [02:37<01:12, 33.45it/s, est. speed input: 37534.18 toks/s, output: 36.65 toks/s]
Processed prompts:  71%|   | 5826/8192 [02:39<01:10, 33.38it/s, est. speed input: 37491.46 toks/s, output: 36.61 toks/s]
Processed prompts:  72%|  | 5890/8192 [02:41<01:08, 33.48it/s, est. speed input: 37456.74 toks/s, output: 36.58 toks/s]
Processed prompts:  73%|  | 5954/8192 [02:42<01:07, 33.32it/s, est. speed input: 37412.49 toks/s, output: 36.54 toks/s]
Processed prompts:  73%|  | 6018/8192 [02:44<01:05, 33.30it/s, est. speed input: 37373.09 toks/s, output: 36.50 toks/s]
Processed prompts:  74%|  | 6082/8192 [02:46<01:03, 33.19it/s, est. speed input: 37330.88 toks/s, output: 36.46 toks/s]
Processed prompts:  75%|  | 6146/8192 [02:48<01:01, 33.52it/s, est. speed input: 37306.62 toks/s, output: 36.43 toks/s]
Processed prompts:  76%|  | 6210/8192 [02:50<00:59, 33.44it/s, est. speed input: 37269.80 toks/s, output: 36.40 toks/s]
Processed prompts:  77%|  | 6274/8192 [02:52<00:57, 33.27it/s, est. speed input: 37229.13 toks/s, output: 36.36 toks/s]
Processed prompts:  77%|  | 6338/8192 [02:54<00:55, 33.40it/s, est. speed input: 37199.70 toks/s, output: 36.33 toks/s]
Processed prompts:  78%|  | 6402/8192 [02:56<00:53, 33.34it/s, est. speed input: 37164.79 toks/s, output: 36.29 toks/s]
Processed prompts:  79%|  | 6466/8192 [02:58<00:51, 33.22it/s, est. speed input: 37127.30 toks/s, output: 36.26 toks/s]
Processed prompts:  80%|  | 6530/8192 [03:00<00:49, 33.37it/s, est. speed input: 37099.89 toks/s, output: 36.23 toks/s]
Processed prompts:  80%|  | 6594/8192 [03:02<00:47, 33.30it/s, est. speed input: 37066.53 toks/s, output: 36.20 toks/s]
Processed prompts:  81%| | 6658/8192 [03:04<00:45, 33.43it/s, est. speed input: 37040.64 toks/s, output: 36.17 toks/s]
Processed prompts:  82%| | 6722/8192 [03:06<00:44, 33.29it/s, est. speed input: 37006.34 toks/s, output: 36.14 toks/s]
Processed prompts:  83%| | 6786/8192 [03:07<00:42, 33.28it/s, est. speed input: 36975.93 toks/s, output: 36.11 toks/s]
Processed prompts:  84%| | 6850/8192 [03:09<00:40, 33.24it/s, est. speed input: 36945.30 toks/s, output: 36.08 toks/s]
Processed prompts:  84%| | 6914/8192 [03:11<00:38, 33.22it/s, est. speed input: 36915.35 toks/s, output: 36.05 toks/s]
Processed prompts:  85%| | 6978/8192 [03:13<00:36, 33.38it/s, est. speed input: 36892.50 toks/s, output: 36.03 toks/s]
Processed prompts:  86%| | 7042/8192 [03:15<00:34, 33.34it/s, est. speed input: 36864.43 toks/s, output: 36.00 toks/s]
Processed prompts:  87%| | 7106/8192 [03:17<00:32, 33.75it/s, est. speed input: 36852.41 toks/s, output: 35.99 toks/s]
Processed prompts:  88%| | 7170/8192 [03:19<00:30, 33.59it/s, est. speed input: 36825.15 toks/s, output: 35.96 toks/s]
Processed prompts:  88%| | 7234/8192 [03:21<00:28, 33.60it/s, est. speed input: 36802.37 toks/s, output: 35.94 toks/s]
Processed prompts:  89%| | 7298/8192 [03:23<00:26, 33.53it/s, est. speed input: 36777.51 toks/s, output: 35.92 toks/s]
Processed prompts:  90%| | 7362/8192 [03:25<00:24, 33.57it/s, est. speed input: 36756.10 toks/s, output: 35.89 toks/s]
Processed prompts:  91%| | 7426/8192 [03:27<00:22, 33.45it/s, est. speed input: 36730.06 toks/s, output: 35.87 toks/s]
Processed prompts:  91%|| 7490/8192 [03:28<00:20, 33.66it/s, est. speed input: 36714.60 toks/s, output: 35.85 toks/s]
Processed prompts:  92%|| 7554/8192 [03:30<00:18, 33.88it/s, est. speed input: 36701.46 toks/s, output: 35.84 toks/s]
Processed prompts:  93%|| 7618/8192 [03:32<00:16, 34.15it/s, est. speed input: 36692.04 toks/s, output: 35.83 toks/s]
Processed prompts:  94%|| 7682/8192 [03:34<00:15, 33.79it/s, est. speed input: 36665.82 toks/s, output: 35.81 toks/s]
Processed prompts:  95%|| 7746/8192 [03:36<00:13, 33.59it/s, est. speed input: 36641.15 toks/s, output: 35.78 toks/s]
Processed prompts:  95%|| 7810/8192 [03:38<00:11, 33.39it/s, est. speed input: 36615.13 toks/s, output: 35.76 toks/s]
Processed prompts:  96%|| 7874/8192 [03:40<00:09, 33.27it/s, est. speed input: 36590.26 toks/s, output: 35.73 toks/s]
Processed prompts:  97%|| 7938/8192 [03:42<00:07, 33.26it/s, est. speed input: 36568.22 toks/s, output: 35.71 toks/s]
Processed prompts:  98%|| 8002/8192 [03:44<00:05, 33.23it/s, est. speed input: 36545.80 toks/s, output: 35.69 toks/s]
Processed prompts:  98%|| 8066/8192 [03:46<00:03, 33.35it/s, est. speed input: 36528.09 toks/s, output: 35.67 toks/s]
Processed prompts:  99%|| 8130/8192 [03:48<00:01, 33.45it/s, est. speed input: 36511.23 toks/s, output: 35.66 toks/s]
Processed prompts: 100%|| 8192/8192 [03:48<00:00, 33.45it/s, est. speed input: 36789.60 toks/s, output: 35.93 toks/s]
Processed prompts: 100%|| 8192/8192 [03:48<00:00, 35.93it/s, est. speed input: 36789.60 toks/s, output: 35.93 toks/s]
[rank0]:[W126 04:20:18.109239792 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-26 08:01:50
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Llama3.2-1B-FP8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:01:54 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 08:01:54 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1049870) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1049870) WARNING 01-26 08:02:13 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 57.65 requests/s, 29575.71 total tokens/s, 57.65 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-26 08:01:54] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:01:54] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:01:54] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:01:54] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:01:54] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:01:54] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:01:54] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:01:54] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:01:54] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:01:54] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:01:54] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:01:54] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:01:54] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:01:54] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:01:57] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:01:57] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:01:57] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:01:57] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:01:57] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:01:57] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:01:57] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:01:57] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:01:57] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:01:57] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:01:57] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:01:57] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:01:57] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:01:57] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1049870) [2026-01-26 08:01:58] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1049870) [2026-01-26 08:01:58] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1049870) [2026-01-26 08:01:58] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1049870) [2026-01-26 08:01:58] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1049870) [2026-01-26 08:01:58] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1049870) [2026-01-26 08:01:58] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1049870) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1049870) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.22s/it]
(EngineCore_DP0 pid=1049870) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.22s/it]
(EngineCore_DP0 pid=1049870) 
(EngineCore_DP0 pid=1049870) [2026-01-26 08:02:07] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=1049870) [2026-01-26 08:02:07] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=1049870) [2026-01-26 08:02:07] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=1049870) [2026-01-26 08:02:07] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 2621440 bytes
(EngineCore_DP0 pid=1049870) [2026-01-26 08:02:07] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=1049870) [2026-01-26 08:02:07] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 20971520 bytes
(EngineCore_DP0 pid=1049870) [2026-01-26 08:02:07] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=1049870) [2026-01-26 08:02:07] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10485760 bytes
(EngineCore_DP0 pid=1049870) 2026-01-26 08:02:12,532 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1049870) 2026-01-26 08:02:12,540 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  90%| | 115/128 [00:00<00:00, 1142.52it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 1123.39it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|         | 8/128 [00:00<00:01, 75.00it/s, est. speed input: 38415.32 toks/s, output: 75.01 toks/s]
Processed prompts:  12%|        | 16/128 [00:00<00:01, 65.75it/s, est. speed input: 34302.59 toks/s, output: 66.99 toks/s]
Processed prompts:  18%|        | 23/128 [00:00<00:01, 63.26it/s, est. speed input: 33153.79 toks/s, output: 64.75 toks/s]
Processed prompts:  23%|       | 30/128 [00:00<00:01, 61.99it/s, est. speed input: 32553.99 toks/s, output: 63.58 toks/s]
Processed prompts:  29%|       | 37/128 [00:00<00:01, 61.09it/s, est. speed input: 32134.63 toks/s, output: 62.76 toks/s]
Processed prompts:  34%|      | 44/128 [00:00<00:01, 60.72it/s, est. speed input: 31900.37 toks/s, output: 62.30 toks/s]
Processed prompts:  40%|      | 51/128 [00:00<00:01, 60.50it/s, est. speed input: 31736.40 toks/s, output: 61.98 toks/s]
Processed prompts:  45%|     | 58/128 [00:00<00:01, 60.53it/s, est. speed input: 31649.88 toks/s, output: 61.81 toks/s]
Processed prompts:  51%|     | 65/128 [00:01<00:01, 60.25it/s, est. speed input: 31525.25 toks/s, output: 61.57 toks/s]
Processed prompts:  56%|    | 72/128 [00:01<00:00, 59.48it/s, est. speed input: 31326.41 toks/s, output: 61.18 toks/s]
Processed prompts:  62%|   | 79/128 [00:01<00:00, 59.94it/s, est. speed input: 31319.26 toks/s, output: 61.17 toks/s]
Processed prompts:  67%|   | 86/128 [00:01<00:00, 60.09it/s, est. speed input: 31288.65 toks/s, output: 61.11 toks/s]
Processed prompts:  73%|  | 93/128 [00:01<00:00, 60.11it/s, est. speed input: 31250.46 toks/s, output: 61.04 toks/s]
Processed prompts:  78%|  | 100/128 [00:01<00:00, 59.96it/s, est. speed input: 31199.58 toks/s, output: 60.94 toks/s]
Processed prompts:  84%| | 107/128 [00:01<00:00, 60.29it/s, est. speed input: 31203.52 toks/s, output: 60.94 toks/s]
Processed prompts:  89%| | 114/128 [00:01<00:00, 60.13it/s, est. speed input: 31165.83 toks/s, output: 60.87 toks/s]
Processed prompts:  95%|| 121/128 [00:01<00:00, 60.08it/s, est. speed input: 31138.94 toks/s, output: 60.82 toks/s]
Processed prompts: 100%|| 128/128 [00:02<00:00, 60.18it/s, est. speed input: 31127.23 toks/s, output: 60.80 toks/s]
Processed prompts: 100%|| 128/128 [00:02<00:00, 60.18it/s, est. speed input: 31127.23 toks/s, output: 60.80 toks/s]
Processed prompts: 100%|| 128/128 [00:02<00:00, 60.79it/s, est. speed input: 31127.23 toks/s, output: 60.80 toks/s]
[rank0]:[W126 08:02:15.794629103 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-26 08:02:17
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Llama3.2-1B-FP8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:02:21 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 08:02:21 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1050426) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1050426) WARNING 01-26 08:02:40 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 31.14 requests/s, 31915.83 total tokens/s, 31.14 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-26 08:02:21] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:02:21] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:02:21] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:02:21] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:02:21] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:02:21] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:02:21] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:02:21] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:02:21] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:02:21] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:02:21] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:02:21] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:02:21] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:02:21] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:02:25] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:02:25] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:02:25] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:02:25] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:02:25] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:02:25] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:02:25] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:02:25] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:02:25] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:02:25] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:02:25] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:02:25] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:02:25] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:02:25] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1050426) [2026-01-26 08:02:26] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1050426) [2026-01-26 08:02:26] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1050426) [2026-01-26 08:02:26] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1050426) [2026-01-26 08:02:26] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1050426) [2026-01-26 08:02:26] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1050426) [2026-01-26 08:02:26] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1050426) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1050426) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.33s/it]
(EngineCore_DP0 pid=1050426) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.33s/it]
(EngineCore_DP0 pid=1050426) 
(EngineCore_DP0 pid=1050426) [2026-01-26 08:02:35] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=1050426) [2026-01-26 08:02:35] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=1050426) [2026-01-26 08:02:35] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=1050426) [2026-01-26 08:02:35] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 2621440 bytes
(EngineCore_DP0 pid=1050426) [2026-01-26 08:02:35] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=1050426) [2026-01-26 08:02:35] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 20971520 bytes
(EngineCore_DP0 pid=1050426) [2026-01-26 08:02:35] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=1050426) [2026-01-26 08:02:35] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10485760 bytes
(EngineCore_DP0 pid=1050426) 2026-01-26 08:02:40,155 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1050426) 2026-01-26 08:02:40,162 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  46%|     | 59/128 [00:00<00:00, 577.90it/s]
Adding requests:  91%|| 117/128 [00:00<00:00, 564.59it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 562.18it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|         | 8/128 [00:00<00:01, 77.85it/s, est. speed input: 79754.46 toks/s, output: 77.86 toks/s]
Processed prompts:  12%|        | 16/128 [00:00<00:02, 42.11it/s, est. speed input: 46310.73 toks/s, output: 45.22 toks/s]
Processed prompts:  17%|        | 22/128 [00:00<00:02, 37.63it/s, est. speed input: 41708.61 toks/s, output: 40.73 toks/s]
Processed prompts:  21%|        | 27/128 [00:00<00:02, 35.74it/s, est. speed input: 39765.56 toks/s, output: 38.83 toks/s]
Processed prompts:  24%|       | 31/128 [00:00<00:02, 34.64it/s, est. speed input: 38681.83 toks/s, output: 37.77 toks/s]
Processed prompts:  27%|       | 35/128 [00:00<00:02, 33.50it/s, est. speed input: 37709.00 toks/s, output: 36.82 toks/s]
Processed prompts:  30%|       | 39/128 [00:01<00:02, 32.48it/s, est. speed input: 36870.33 toks/s, output: 36.01 toks/s]
Processed prompts:  34%|      | 43/128 [00:01<00:02, 32.26it/s, est. speed input: 36411.15 toks/s, output: 35.56 toks/s]
Processed prompts:  37%|      | 47/128 [00:01<00:02, 32.02it/s, est. speed input: 36013.01 toks/s, output: 35.17 toks/s]
Processed prompts:  40%|      | 51/128 [00:01<00:02, 32.14it/s, est. speed input: 35775.57 toks/s, output: 34.94 toks/s]
Processed prompts:  43%|     | 55/128 [00:01<00:02, 32.13it/s, est. speed input: 35547.37 toks/s, output: 34.71 toks/s]
Processed prompts:  46%|     | 59/128 [00:01<00:02, 32.14it/s, est. speed input: 35356.60 toks/s, output: 34.53 toks/s]
Processed prompts:  49%|     | 63/128 [00:01<00:02, 32.04it/s, est. speed input: 35165.33 toks/s, output: 34.34 toks/s]
Processed prompts:  52%|    | 67/128 [00:01<00:01, 31.94it/s, est. speed input: 34991.63 toks/s, output: 34.17 toks/s]
Processed prompts:  55%|    | 71/128 [00:02<00:01, 31.66it/s, est. speed input: 34792.19 toks/s, output: 33.98 toks/s]
Processed prompts:  59%|    | 75/128 [00:02<00:01, 31.66it/s, est. speed input: 34657.02 toks/s, output: 33.84 toks/s]
Processed prompts:  62%|   | 79/128 [00:02<00:01, 31.66it/s, est. speed input: 34537.38 toks/s, output: 33.73 toks/s]
Processed prompts:  65%|   | 83/128 [00:02<00:01, 31.79it/s, est. speed input: 34452.08 toks/s, output: 33.64 toks/s]
Processed prompts:  68%|   | 87/128 [00:02<00:01, 31.74it/s, est. speed input: 34351.71 toks/s, output: 33.55 toks/s]
Processed prompts:  71%|   | 91/128 [00:02<00:01, 31.86it/s, est. speed input: 34286.62 toks/s, output: 33.48 toks/s]
Processed prompts:  74%|  | 95/128 [00:02<00:01, 31.94it/s, est. speed input: 34225.30 toks/s, output: 33.42 toks/s]
Processed prompts:  77%|  | 99/128 [00:02<00:00, 32.02it/s, est. speed input: 34173.07 toks/s, output: 33.37 toks/s]
Processed prompts:  80%|  | 103/128 [00:03<00:00, 32.07it/s, est. speed input: 34123.91 toks/s, output: 33.32 toks/s]
Processed prompts:  84%| | 107/128 [00:03<00:00, 31.61it/s, est. speed input: 34010.17 toks/s, output: 33.21 toks/s]
Processed prompts:  87%| | 111/128 [00:03<00:00, 31.49it/s, est. speed input: 33931.76 toks/s, output: 33.14 toks/s]
Processed prompts:  90%| | 115/128 [00:03<00:00, 31.58it/s, est. speed input: 33882.02 toks/s, output: 33.09 toks/s]
Processed prompts:  93%|| 119/128 [00:03<00:00, 31.69it/s, est. speed input: 33841.55 toks/s, output: 33.05 toks/s]
Processed prompts:  96%|| 123/128 [00:03<00:00, 31.90it/s, est. speed input: 33819.11 toks/s, output: 33.03 toks/s]
Processed prompts:  99%|| 127/128 [00:03<00:00, 31.87it/s, est. speed input: 33778.62 toks/s, output: 32.99 toks/s]
Processed prompts: 100%|| 128/128 [00:03<00:00, 31.87it/s, est. speed input: 33761.69 toks/s, output: 32.97 toks/s]
Processed prompts: 100%|| 128/128 [00:03<00:00, 32.97it/s, est. speed input: 33761.69 toks/s, output: 32.97 toks/s]
[rank0]:[W126 08:02:45.310106017 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-26 08:02:47
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Llama3.2-1B-FP8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:02:51 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 08:02:51 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1051029) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1051029) WARNING 01-26 08:03:10 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 33.36 requests/s, 34193.97 total tokens/s, 33.36 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-26 08:02:51] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:02:51] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:02:51] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:02:51] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:02:51] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:02:51] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:02:51] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:02:51] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:02:51] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:02:51] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:02:51] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:02:51] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:02:51] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:02:51] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:02:55] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:02:55] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:02:55] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:02:55] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:02:55] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:02:55] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:02:55] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:02:55] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:02:55] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:02:55] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:02:55] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:02:55] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:02:55] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:02:55] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1051029) [2026-01-26 08:02:56] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1051029) [2026-01-26 08:02:56] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1051029) [2026-01-26 08:02:56] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1051029) [2026-01-26 08:02:56] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1051029) [2026-01-26 08:02:56] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1051029) [2026-01-26 08:02:56] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1051029) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1051029) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.21s/it]
(EngineCore_DP0 pid=1051029) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.21s/it]
(EngineCore_DP0 pid=1051029) 
(EngineCore_DP0 pid=1051029) [2026-01-26 08:03:04] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=1051029) [2026-01-26 08:03:04] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=1051029) [2026-01-26 08:03:04] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=1051029) [2026-01-26 08:03:04] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 2621440 bytes
(EngineCore_DP0 pid=1051029) [2026-01-26 08:03:04] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=1051029) [2026-01-26 08:03:04] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 20971520 bytes
(EngineCore_DP0 pid=1051029) [2026-01-26 08:03:04] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=1051029) [2026-01-26 08:03:04] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10485760 bytes
(EngineCore_DP0 pid=1051029) 2026-01-26 08:03:09,833 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1051029) 2026-01-26 08:03:09,839 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  23%|       | 58/256 [00:00<00:00, 571.77it/s]
Adding requests:  45%|     | 116/256 [00:00<00:00, 533.04it/s]
Adding requests:  66%|   | 170/256 [00:00<00:00, 513.88it/s]
Adding requests:  87%| | 222/256 [00:00<00:00, 507.70it/s]
Adding requests: 100%|| 256/256 [00:00<00:00, 516.26it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|         | 16/256 [00:00<00:01, 126.30it/s, est. speed input: 129358.94 toks/s, output: 126.32 toks/s]
Processed prompts:  11%|        | 29/256 [00:00<00:04, 54.74it/s, est. speed input: 61850.97 toks/s, output: 60.40 toks/s]   
Processed prompts:  14%|        | 37/256 [00:00<00:04, 45.61it/s, est. speed input: 52808.49 toks/s, output: 51.57 toks/s]
Processed prompts:  17%|        | 43/256 [00:00<00:05, 41.91it/s, est. speed input: 49229.54 toks/s, output: 48.08 toks/s]
Processed prompts:  19%|        | 48/256 [00:01<00:05, 37.74it/s, est. speed input: 45929.43 toks/s, output: 44.85 toks/s]
Processed prompts:  21%|        | 53/256 [00:01<00:05, 38.81it/s, est. speed input: 45681.30 toks/s, output: 44.61 toks/s]
Processed prompts:  23%|       | 58/256 [00:01<00:05, 35.51it/s, est. speed input: 43594.61 toks/s, output: 42.57 toks/s]
Processed prompts:  24%|       | 62/256 [00:01<00:05, 35.01it/s, est. speed input: 42838.89 toks/s, output: 41.83 toks/s]
Processed prompts:  26%|       | 66/256 [00:01<00:05, 34.40it/s, est. speed input: 42125.73 toks/s, output: 41.14 toks/s]
Processed prompts:  27%|       | 70/256 [00:01<00:05, 34.36it/s, est. speed input: 41647.34 toks/s, output: 40.67 toks/s]
Processed prompts:  29%|       | 74/256 [00:01<00:05, 34.34it/s, est. speed input: 41232.18 toks/s, output: 40.27 toks/s]
Processed prompts:  30%|       | 78/256 [00:01<00:05, 34.41it/s, est. speed input: 40889.23 toks/s, output: 39.93 toks/s]
Processed prompts:  32%|      | 82/256 [00:02<00:05, 34.32it/s, est. speed input: 40549.30 toks/s, output: 39.60 toks/s]
Processed prompts:  34%|      | 86/256 [00:02<00:04, 34.31it/s, est. speed input: 40260.08 toks/s, output: 39.32 toks/s]
Processed prompts:  35%|      | 90/256 [00:02<00:04, 34.28it/s, est. speed input: 39993.93 toks/s, output: 39.06 toks/s]
Processed prompts:  37%|      | 94/256 [00:02<00:04, 34.14it/s, est. speed input: 39730.24 toks/s, output: 38.80 toks/s]
Processed prompts:  38%|      | 98/256 [00:02<00:04, 34.06it/s, est. speed input: 39496.95 toks/s, output: 38.57 toks/s]
Processed prompts:  40%|      | 102/256 [00:02<00:04, 33.64it/s, est. speed input: 39219.33 toks/s, output: 38.30 toks/s]
Processed prompts:  41%|     | 106/256 [00:02<00:04, 33.70it/s, est. speed input: 39026.02 toks/s, output: 38.11 toks/s]
Processed prompts:  43%|     | 110/256 [00:02<00:04, 33.87it/s, est. speed input: 38867.61 toks/s, output: 37.96 toks/s]
Processed prompts:  45%|     | 114/256 [00:03<00:04, 33.84it/s, est. speed input: 38700.06 toks/s, output: 37.79 toks/s]
Processed prompts:  46%|     | 118/256 [00:03<00:04, 33.95it/s, est. speed input: 38563.34 toks/s, output: 37.66 toks/s]
Processed prompts:  48%|     | 122/256 [00:03<00:03, 33.93it/s, est. speed input: 38423.25 toks/s, output: 37.52 toks/s]
Processed prompts:  49%|     | 126/256 [00:03<00:03, 33.94it/s, est. speed input: 38294.83 toks/s, output: 37.40 toks/s]
Processed prompts:  51%|     | 130/256 [00:03<00:03, 34.07it/s, est. speed input: 38191.30 toks/s, output: 37.30 toks/s]
Processed prompts:  52%|    | 134/256 [00:03<00:03, 33.95it/s, est. speed input: 38069.47 toks/s, output: 37.18 toks/s]
Processed prompts:  54%|    | 138/256 [00:03<00:03, 33.61it/s, est. speed input: 37923.67 toks/s, output: 37.03 toks/s]
Processed prompts:  55%|    | 142/256 [00:03<00:03, 33.71it/s, est. speed input: 37826.92 toks/s, output: 36.94 toks/s]
Processed prompts:  57%|    | 146/256 [00:03<00:03, 33.63it/s, est. speed input: 37719.27 toks/s, output: 36.83 toks/s]
Processed prompts:  59%|    | 150/256 [00:04<00:03, 33.75it/s, est. speed input: 37636.44 toks/s, output: 36.75 toks/s]
Processed prompts:  60%|    | 154/256 [00:04<00:03, 33.93it/s, est. speed input: 37568.18 toks/s, output: 36.69 toks/s]
Processed prompts:  62%|   | 158/256 [00:04<00:02, 34.09it/s, est. speed input: 37506.68 toks/s, output: 36.63 toks/s]
Processed prompts:  63%|   | 162/256 [00:04<00:02, 34.14it/s, est. speed input: 37442.91 toks/s, output: 36.57 toks/s]
Processed prompts:  65%|   | 166/256 [00:04<00:02, 34.11it/s, est. speed input: 37376.58 toks/s, output: 36.50 toks/s]
Processed prompts:  66%|   | 170/256 [00:04<00:02, 34.19it/s, est. speed input: 37322.29 toks/s, output: 36.45 toks/s]
Processed prompts:  68%|   | 174/256 [00:04<00:02, 33.54it/s, est. speed input: 37207.07 toks/s, output: 36.33 toks/s]
Processed prompts:  70%|   | 178/256 [00:04<00:02, 33.60it/s, est. speed input: 37143.10 toks/s, output: 36.27 toks/s]
Processed prompts:  71%|   | 182/256 [00:05<00:02, 33.79it/s, est. speed input: 37094.40 toks/s, output: 36.22 toks/s]
Processed prompts:  73%|  | 186/256 [00:05<00:02, 33.90it/s, est. speed input: 37046.18 toks/s, output: 36.18 toks/s]
Processed prompts:  74%|  | 190/256 [00:05<00:01, 33.81it/s, est. speed input: 36986.48 toks/s, output: 36.12 toks/s]
Processed prompts:  76%|  | 194/256 [00:05<00:01, 33.89it/s, est. speed input: 36941.24 toks/s, output: 36.08 toks/s]
Processed prompts:  77%|  | 198/256 [00:05<00:01, 33.93it/s, est. speed input: 36895.78 toks/s, output: 36.03 toks/s]
Processed prompts:  79%|  | 202/256 [00:05<00:01, 33.82it/s, est. speed input: 36842.12 toks/s, output: 35.98 toks/s]
Processed prompts:  80%|  | 206/256 [00:05<00:01, 33.90it/s, est. speed input: 36802.83 toks/s, output: 35.94 toks/s]
Processed prompts:  82%| | 210/256 [00:05<00:01, 33.72it/s, est. speed input: 36747.74 toks/s, output: 35.89 toks/s]
Processed prompts:  84%| | 214/256 [00:05<00:01, 33.87it/s, est. speed input: 36714.44 toks/s, output: 35.85 toks/s]
Processed prompts:  85%| | 218/256 [00:06<00:01, 34.05it/s, est. speed input: 36687.54 toks/s, output: 35.83 toks/s]
Processed prompts:  87%| | 222/256 [00:06<00:00, 34.25it/s, est. speed input: 36666.64 toks/s, output: 35.81 toks/s]
Processed prompts:  88%| | 226/256 [00:06<00:00, 34.28it/s, est. speed input: 36639.01 toks/s, output: 35.78 toks/s]
Processed prompts:  90%| | 230/256 [00:06<00:00, 34.03it/s, est. speed input: 36594.77 toks/s, output: 35.74 toks/s]
Processed prompts:  91%|| 234/256 [00:06<00:00, 34.07it/s, est. speed input: 36566.04 toks/s, output: 35.71 toks/s]
Processed prompts:  93%|| 238/256 [00:06<00:00, 34.00it/s, est. speed input: 36532.19 toks/s, output: 35.68 toks/s]
Processed prompts:  95%|| 242/256 [00:06<00:00, 33.98it/s, est. speed input: 36501.53 toks/s, output: 35.65 toks/s]
Processed prompts:  96%|| 246/256 [00:06<00:00, 33.61it/s, est. speed input: 36449.79 toks/s, output: 35.60 toks/s]
Processed prompts:  98%|| 250/256 [00:07<00:00, 33.69it/s, est. speed input: 36419.62 toks/s, output: 35.57 toks/s]
Processed prompts:  99%|| 254/256 [00:07<00:00, 33.83it/s, est. speed input: 36396.55 toks/s, output: 35.54 toks/s]
Processed prompts: 100%|| 256/256 [00:07<00:00, 33.83it/s, est. speed input: 36525.47 toks/s, output: 35.67 toks/s]
Processed prompts: 100%|| 256/256 [00:07<00:00, 35.67it/s, est. speed input: 36525.47 toks/s, output: 35.67 toks/s]
[rank0]:[W126 08:03:18.580453740 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-26 08:03:20
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Llama3.2-1B-FP8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:03:25 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 08:03:25 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1051694) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1051694) WARNING 01-26 08:03:44 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 33.05 requests/s, 33881.11 total tokens/s, 33.05 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-26 08:03:25] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:03:25] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:03:25] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:03:25] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:03:25] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:03:25] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:03:25] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:03:25] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:03:25] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:03:25] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:03:25] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:03:25] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:03:25] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:03:25] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:03:29] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:03:29] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:03:29] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:03:29] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:03:29] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:03:29] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:03:29] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:03:29] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:03:29] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:03:29] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:03:29] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:03:29] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:03:29] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:03:29] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1051694) [2026-01-26 08:03:29] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1051694) [2026-01-26 08:03:29] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1051694) [2026-01-26 08:03:29] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1051694) [2026-01-26 08:03:29] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1051694) [2026-01-26 08:03:29] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1051694) [2026-01-26 08:03:29] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1051694) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1051694) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.36s/it]
(EngineCore_DP0 pid=1051694) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.36s/it]
(EngineCore_DP0 pid=1051694) 
(EngineCore_DP0 pid=1051694) [2026-01-26 08:03:38] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=1051694) [2026-01-26 08:03:38] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=1051694) [2026-01-26 08:03:38] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=1051694) [2026-01-26 08:03:38] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 2621440 bytes
(EngineCore_DP0 pid=1051694) [2026-01-26 08:03:38] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=1051694) [2026-01-26 08:03:38] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 20971520 bytes
(EngineCore_DP0 pid=1051694) [2026-01-26 08:03:38] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=1051694) [2026-01-26 08:03:38] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10485760 bytes
(EngineCore_DP0 pid=1051694) 2026-01-26 08:03:43,965 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1051694) 2026-01-26 08:03:43,983 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:  12%|        | 60/512 [00:00<00:00, 595.63it/s]
Adding requests:  23%|       | 120/512 [00:00<00:00, 553.85it/s]
Adding requests:  34%|      | 176/512 [00:00<00:00, 529.77it/s]
Adding requests:  45%|     | 230/512 [00:00<00:00, 520.18it/s]
Adding requests:  55%|    | 283/512 [00:00<00:00, 509.87it/s]
Adding requests:  65%|   | 335/512 [00:00<00:00, 504.57it/s]
Adding requests:  76%|  | 387/512 [00:00<00:00, 506.95it/s]
Adding requests:  86%| | 439/512 [00:00<00:00, 508.32it/s]
Adding requests:  96%|| 490/512 [00:00<00:00, 497.88it/s]
Adding requests: 100%|| 512/512 [00:01<00:00, 511.91it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|         | 30/512 [00:00<00:01, 258.41it/s, est. speed input: 264667.80 toks/s, output: 258.43 toks/s]
Processed prompts:  11%|         | 56/512 [00:00<00:07, 58.37it/s, est. speed input: 68259.14 toks/s, output: 66.66 toks/s]   
Processed prompts:  13%|        | 69/512 [00:01<00:08, 49.72it/s, est. speed input: 58903.60 toks/s, output: 57.52 toks/s]
Processed prompts:  15%|        | 78/512 [00:01<00:10, 40.70it/s, est. speed input: 51072.16 toks/s, output: 49.87 toks/s]
Processed prompts:  17%|        | 85/512 [00:01<00:09, 43.31it/s, est. speed input: 51717.59 toks/s, output: 50.51 toks/s]
Processed prompts:  18%|        | 92/512 [00:01<00:10, 39.24it/s, est. speed input: 49034.80 toks/s, output: 47.89 toks/s]
Processed prompts:  19%|        | 98/512 [00:02<00:11, 35.19it/s, est. speed input: 46509.84 toks/s, output: 45.42 toks/s]
Processed prompts:  20%|        | 103/512 [00:02<00:11, 36.35it/s, est. speed input: 46319.11 toks/s, output: 45.23 toks/s]
Processed prompts:  21%|        | 108/512 [00:02<00:10, 37.52it/s, est. speed input: 46169.66 toks/s, output: 45.09 toks/s]
Processed prompts:  22%|       | 113/512 [00:02<00:10, 38.42it/s, est. speed input: 45995.88 toks/s, output: 44.92 toks/s]
Processed prompts:  23%|       | 118/512 [00:02<00:12, 31.32it/s, est. speed input: 43765.51 toks/s, output: 42.74 toks/s]
Processed prompts:  24%|       | 122/512 [00:02<00:12, 31.87it/s, est. speed input: 43395.11 toks/s, output: 42.38 toks/s]
Processed prompts:  25%|       | 126/512 [00:02<00:11, 32.25it/s, est. speed input: 43032.86 toks/s, output: 42.02 toks/s]
Processed prompts:  25%|       | 130/512 [00:03<00:11, 32.59it/s, est. speed input: 42703.59 toks/s, output: 41.70 toks/s]
Processed prompts:  26%|       | 134/512 [00:03<00:11, 32.80it/s, est. speed input: 42387.46 toks/s, output: 41.39 toks/s]
Processed prompts:  27%|       | 138/512 [00:03<00:11, 33.04it/s, est. speed input: 42108.05 toks/s, output: 41.12 toks/s]
Processed prompts:  28%|       | 142/512 [00:03<00:11, 33.39it/s, est. speed input: 41873.26 toks/s, output: 40.89 toks/s]
Processed prompts:  29%|       | 146/512 [00:03<00:10, 33.46it/s, est. speed input: 41626.77 toks/s, output: 40.65 toks/s]
Processed prompts:  29%|       | 150/512 [00:03<00:10, 33.10it/s, est. speed input: 41340.15 toks/s, output: 40.37 toks/s]
Processed prompts:  30%|       | 154/512 [00:03<00:10, 33.17it/s, est. speed input: 41115.15 toks/s, output: 40.15 toks/s]
Processed prompts:  31%|       | 158/512 [00:03<00:10, 33.14it/s, est. speed input: 40892.72 toks/s, output: 39.93 toks/s]
Processed prompts:  32%|      | 162/512 [00:04<00:10, 33.14it/s, est. speed input: 40687.53 toks/s, output: 39.73 toks/s]
Processed prompts:  32%|      | 166/512 [00:04<00:10, 33.30it/s, est. speed input: 40512.25 toks/s, output: 39.56 toks/s]
Processed prompts:  33%|      | 170/512 [00:04<00:10, 33.27it/s, est. speed input: 40329.96 toks/s, output: 39.38 toks/s]
Processed prompts:  34%|      | 174/512 [00:04<00:10, 33.35it/s, est. speed input: 40168.98 toks/s, output: 39.23 toks/s]
Processed prompts:  35%|      | 178/512 [00:04<00:09, 33.50it/s, est. speed input: 40026.90 toks/s, output: 39.09 toks/s]
Processed prompts:  36%|      | 182/512 [00:04<00:09, 33.43it/s, est. speed input: 39873.10 toks/s, output: 38.94 toks/s]
Processed prompts:  36%|      | 186/512 [00:04<00:09, 33.18it/s, est. speed input: 39707.06 toks/s, output: 38.78 toks/s]
Processed prompts:  37%|      | 190/512 [00:04<00:09, 33.29it/s, est. speed input: 39577.22 toks/s, output: 38.65 toks/s]
Processed prompts:  38%|      | 194/512 [00:05<00:09, 33.30it/s, est. speed input: 39447.27 toks/s, output: 38.52 toks/s]
Processed prompts:  39%|      | 198/512 [00:05<00:09, 33.44it/s, est. speed input: 39335.78 toks/s, output: 38.41 toks/s]
Processed prompts:  39%|      | 202/512 [00:05<00:09, 33.47it/s, est. speed input: 39222.64 toks/s, output: 38.30 toks/s]
Processed prompts:  40%|      | 206/512 [00:05<00:09, 33.70it/s, est. speed input: 39132.82 toks/s, output: 38.22 toks/s]
Processed prompts:  41%|      | 210/512 [00:05<00:08, 33.74it/s, est. speed input: 39036.60 toks/s, output: 38.12 toks/s]
Processed prompts:  42%|     | 214/512 [00:05<00:08, 33.79it/s, est. speed input: 38946.06 toks/s, output: 38.03 toks/s]
Processed prompts:  43%|     | 218/512 [00:05<00:08, 33.49it/s, est. speed input: 38832.18 toks/s, output: 37.92 toks/s]
Processed prompts:  43%|     | 222/512 [00:05<00:08, 33.30it/s, est. speed input: 38724.98 toks/s, output: 37.82 toks/s]
Processed prompts:  44%|     | 226/512 [00:05<00:08, 33.42it/s, est. speed input: 38641.67 toks/s, output: 37.74 toks/s]
Processed prompts:  45%|     | 230/512 [00:06<00:08, 33.40it/s, est. speed input: 38553.09 toks/s, output: 37.65 toks/s]
Processed prompts:  46%|     | 234/512 [00:06<00:08, 33.36it/s, est. speed input: 38466.77 toks/s, output: 37.57 toks/s]
Processed prompts:  46%|     | 238/512 [00:06<00:08, 33.43it/s, est. speed input: 38390.69 toks/s, output: 37.49 toks/s]
Processed prompts:  47%|     | 242/512 [00:06<00:08, 33.21it/s, est. speed input: 38297.60 toks/s, output: 37.40 toks/s]
Processed prompts:  48%|     | 246/512 [00:06<00:08, 33.19it/s, est. speed input: 38217.84 toks/s, output: 37.32 toks/s]
Processed prompts:  49%|     | 250/512 [00:06<00:07, 33.32it/s, est. speed input: 38151.12 toks/s, output: 37.26 toks/s]
Processed prompts:  50%|     | 254/512 [00:06<00:07, 32.99it/s, est. speed input: 38057.75 toks/s, output: 37.17 toks/s]
Processed prompts:  50%|     | 258/512 [00:06<00:07, 33.06it/s, est. speed input: 37987.64 toks/s, output: 37.10 toks/s]
Processed prompts:  51%|     | 262/512 [00:07<00:07, 33.05it/s, est. speed input: 37916.73 toks/s, output: 37.03 toks/s]
Processed prompts:  52%|    | 266/512 [00:07<00:07, 33.03it/s, est. speed input: 37847.08 toks/s, output: 36.96 toks/s]
Processed prompts:  53%|    | 270/512 [00:07<00:07, 33.27it/s, est. speed input: 37795.47 toks/s, output: 36.91 toks/s]
Processed prompts:  54%|    | 274/512 [00:07<00:07, 33.35it/s, est. speed input: 37740.07 toks/s, output: 36.86 toks/s]
Processed prompts:  54%|    | 278/512 [00:07<00:06, 33.55it/s, est. speed input: 37694.72 toks/s, output: 36.81 toks/s]
Processed prompts:  55%|    | 282/512 [00:07<00:06, 33.50it/s, est. speed input: 37640.27 toks/s, output: 36.76 toks/s]
Processed prompts:  56%|    | 286/512 [00:07<00:06, 33.51it/s, est. speed input: 37589.45 toks/s, output: 36.71 toks/s]
Processed prompts:  57%|    | 290/512 [00:07<00:06, 33.18it/s, est. speed input: 37521.40 toks/s, output: 36.64 toks/s]
Processed prompts:  57%|    | 294/512 [00:08<00:06, 33.06it/s, est. speed input: 37461.43 toks/s, output: 36.58 toks/s]
Processed prompts:  58%|    | 298/512 [00:08<00:06, 33.34it/s, est. speed input: 37423.59 toks/s, output: 36.55 toks/s]
Processed prompts:  59%|    | 302/512 [00:08<00:06, 33.57it/s, est. speed input: 37388.24 toks/s, output: 36.51 toks/s]
Processed prompts:  60%|    | 306/512 [00:08<00:06, 33.76it/s, est. speed input: 37355.58 toks/s, output: 36.48 toks/s]
Processed prompts:  61%|    | 310/512 [00:08<00:06, 33.57it/s, est. speed input: 37306.84 toks/s, output: 36.43 toks/s]
Processed prompts:  61%|   | 314/512 [00:08<00:05, 33.50it/s, est. speed input: 37262.66 toks/s, output: 36.39 toks/s]
Processed prompts:  62%|   | 318/512 [00:08<00:05, 33.51it/s, est. speed input: 37222.77 toks/s, output: 36.35 toks/s]
Processed prompts:  63%|   | 322/512 [00:08<00:05, 33.53it/s, est. speed input: 37184.54 toks/s, output: 36.31 toks/s]
Processed prompts:  64%|   | 326/512 [00:08<00:05, 32.96it/s, est. speed input: 37118.92 toks/s, output: 36.25 toks/s]
Processed prompts:  64%|   | 330/512 [00:09<00:05, 33.12it/s, est. speed input: 37081.61 toks/s, output: 36.21 toks/s]
Processed prompts:  65%|   | 334/512 [00:09<00:05, 33.20it/s, est. speed input: 37044.01 toks/s, output: 36.18 toks/s]
Processed prompts:  66%|   | 338/512 [00:09<00:05, 33.20it/s, est. speed input: 37004.94 toks/s, output: 36.14 toks/s]
Processed prompts:  67%|   | 342/512 [00:09<00:05, 33.65it/s, est. speed input: 36987.43 toks/s, output: 36.12 toks/s]
Processed prompts:  68%|   | 346/512 [00:09<00:04, 33.66it/s, est. speed input: 36956.51 toks/s, output: 36.09 toks/s]
Processed prompts:  68%|   | 350/512 [00:09<00:04, 33.67it/s, est. speed input: 36926.70 toks/s, output: 36.06 toks/s]
Processed prompts:  69%|   | 354/512 [00:09<00:04, 33.61it/s, est. speed input: 36894.30 toks/s, output: 36.03 toks/s]
Processed prompts:  70%|   | 358/512 [00:09<00:04, 33.53it/s, est. speed input: 36861.30 toks/s, output: 36.00 toks/s]
Processed prompts:  71%|   | 362/512 [00:10<00:04, 32.96it/s, est. speed input: 36806.23 toks/s, output: 35.94 toks/s]
Processed prompts:  71%|  | 366/512 [00:10<00:04, 33.22it/s, est. speed input: 36781.13 toks/s, output: 35.92 toks/s]
Processed prompts:  72%|  | 370/512 [00:10<00:04, 33.46it/s, est. speed input: 36759.17 toks/s, output: 35.90 toks/s]
Processed prompts:  73%|  | 374/512 [00:10<00:04, 33.72it/s, est. speed input: 36741.20 toks/s, output: 35.88 toks/s]
Processed prompts:  74%|  | 378/512 [00:10<00:03, 33.55it/s, est. speed input: 36709.38 toks/s, output: 35.85 toks/s]
Processed prompts:  75%|  | 382/512 [00:10<00:03, 33.50it/s, est. speed input: 36680.96 toks/s, output: 35.82 toks/s]
Processed prompts:  75%|  | 386/512 [00:10<00:03, 33.34it/s, est. speed input: 36648.25 toks/s, output: 35.79 toks/s]
Processed prompts:  76%|  | 390/512 [00:10<00:03, 33.57it/s, est. speed input: 36629.94 toks/s, output: 35.77 toks/s]
Processed prompts:  77%|  | 394/512 [00:11<00:03, 33.48it/s, est. speed input: 36601.88 toks/s, output: 35.74 toks/s]
Processed prompts:  78%|  | 398/512 [00:11<00:03, 33.00it/s, est. speed input: 36557.93 toks/s, output: 35.70 toks/s]
Processed prompts:  79%|  | 402/512 [00:11<00:03, 33.02it/s, est. speed input: 36528.84 toks/s, output: 35.67 toks/s]
Processed prompts:  79%|  | 406/512 [00:11<00:03, 33.23it/s, est. speed input: 36508.09 toks/s, output: 35.65 toks/s]
Processed prompts:  80%|  | 410/512 [00:11<00:03, 33.32it/s, est. speed input: 36485.84 toks/s, output: 35.63 toks/s]
Processed prompts:  81%|  | 414/512 [00:11<00:02, 33.42it/s, est. speed input: 36464.98 toks/s, output: 35.61 toks/s]
Processed prompts:  82%| | 418/512 [00:11<00:02, 33.28it/s, est. speed input: 36436.91 toks/s, output: 35.58 toks/s]
Processed prompts:  82%| | 422/512 [00:11<00:02, 33.36it/s, est. speed input: 36416.02 toks/s, output: 35.56 toks/s]
Processed prompts:  83%| | 426/512 [00:11<00:02, 33.35it/s, est. speed input: 36393.22 toks/s, output: 35.54 toks/s]
Processed prompts:  84%| | 430/512 [00:12<00:02, 33.33it/s, est. speed input: 36370.02 toks/s, output: 35.52 toks/s]
Processed prompts:  85%| | 434/512 [00:12<00:02, 32.97it/s, est. speed input: 36335.05 toks/s, output: 35.48 toks/s]
Processed prompts:  86%| | 438/512 [00:12<00:02, 33.18it/s, est. speed input: 36317.24 toks/s, output: 35.47 toks/s]
Processed prompts:  86%| | 442/512 [00:12<00:02, 33.38it/s, est. speed input: 36301.88 toks/s, output: 35.45 toks/s]
Processed prompts:  87%| | 446/512 [00:12<00:01, 33.60it/s, est. speed input: 36289.06 toks/s, output: 35.44 toks/s]
Processed prompts:  88%| | 450/512 [00:12<00:01, 34.17it/s, est. speed input: 36290.45 toks/s, output: 35.44 toks/s]
Processed prompts:  89%| | 454/512 [00:12<00:01, 33.87it/s, est. speed input: 36268.59 toks/s, output: 35.42 toks/s]
Processed prompts:  89%| | 458/512 [00:12<00:01, 33.75it/s, est. speed input: 36250.21 toks/s, output: 35.40 toks/s]
Processed prompts:  90%| | 462/512 [00:13<00:01, 33.70it/s, est. speed input: 36233.40 toks/s, output: 35.38 toks/s]
Processed prompts:  91%| | 466/512 [00:13<00:01, 33.79it/s, est. speed input: 36220.51 toks/s, output: 35.37 toks/s]
Processed prompts:  92%|| 470/512 [00:13<00:01, 33.27it/s, est. speed input: 36189.57 toks/s, output: 35.34 toks/s]
Processed prompts:  93%|| 474/512 [00:13<00:01, 33.42it/s, est. speed input: 36175.43 toks/s, output: 35.33 toks/s]
Processed prompts:  93%|| 478/512 [00:13<00:01, 33.50it/s, est. speed input: 36160.52 toks/s, output: 35.31 toks/s]
Processed prompts:  94%|| 482/512 [00:13<00:00, 33.47it/s, est. speed input: 36143.54 toks/s, output: 35.30 toks/s]
Processed prompts:  95%|| 486/512 [00:13<00:00, 33.49it/s, est. speed input: 36127.87 toks/s, output: 35.28 toks/s]
Processed prompts:  96%|| 490/512 [00:13<00:00, 33.55it/s, est. speed input: 36113.94 toks/s, output: 35.27 toks/s]
Processed prompts:  96%|| 494/512 [00:14<00:00, 33.60it/s, est. speed input: 36100.46 toks/s, output: 35.25 toks/s]
Processed prompts:  97%|| 498/512 [00:14<00:00, 33.59it/s, est. speed input: 36085.98 toks/s, output: 35.24 toks/s]
Processed prompts:  98%|| 502/512 [00:14<00:00, 33.41it/s, est. speed input: 36066.21 toks/s, output: 35.22 toks/s]
Processed prompts:  99%|| 506/512 [00:14<00:00, 33.04it/s, est. speed input: 36039.77 toks/s, output: 35.20 toks/s]
Processed prompts: 100%|| 510/512 [00:14<00:00, 33.91it/s, est. speed input: 36047.11 toks/s, output: 35.20 toks/s]
Processed prompts: 100%|| 512/512 [00:14<00:00, 33.91it/s, est. speed input: 36188.23 toks/s, output: 35.34 toks/s]
Processed prompts: 100%|| 512/512 [00:14<00:00, 35.34it/s, est. speed input: 36188.23 toks/s, output: 35.34 toks/s]
[rank0]:[W126 08:04:00.600082981 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-26 08:04:02
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Llama3.2-1B-FP8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:04:09 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 08:04:09 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1052484) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1052484) WARNING 01-26 08:04:28 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 32.00 requests/s, 32798.49 total tokens/s, 32.00 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-26 08:04:09] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:04:09] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:04:09] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:04:09] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:04:09] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:04:09] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:04:09] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:04:09] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:04:09] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:04:09] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:04:09] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:04:09] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:04:09] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:04:09] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:04:12] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:04:12] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:04:12] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:04:12] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:04:12] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:04:12] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:04:12] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:04:12] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:04:12] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:04:12] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:04:12] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:04:12] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:04:12] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:04:12] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1052484) [2026-01-26 08:04:13] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1052484) [2026-01-26 08:04:13] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1052484) [2026-01-26 08:04:13] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1052484) [2026-01-26 08:04:13] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1052484) [2026-01-26 08:04:13] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1052484) [2026-01-26 08:04:13] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1052484) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1052484) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.17s/it]
(EngineCore_DP0 pid=1052484) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.17s/it]
(EngineCore_DP0 pid=1052484) 
(EngineCore_DP0 pid=1052484) [2026-01-26 08:04:22] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=1052484) [2026-01-26 08:04:22] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=1052484) [2026-01-26 08:04:22] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=1052484) [2026-01-26 08:04:22] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 2621440 bytes
(EngineCore_DP0 pid=1052484) [2026-01-26 08:04:22] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=1052484) [2026-01-26 08:04:22] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 20971520 bytes
(EngineCore_DP0 pid=1052484) [2026-01-26 08:04:22] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=1052484) [2026-01-26 08:04:22] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10485760 bytes
(EngineCore_DP0 pid=1052484) 2026-01-26 08:04:27,432 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1052484) 2026-01-26 08:04:27,486 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   6%|         | 57/1024 [00:00<00:01, 566.64it/s]
Adding requests:  11%|         | 114/1024 [00:00<00:01, 516.27it/s]
Adding requests:  16%|        | 166/1024 [00:00<00:01, 485.97it/s]
Adding requests:  21%|        | 215/1024 [00:00<00:01, 474.29it/s]
Adding requests:  26%|       | 263/1024 [00:00<00:01, 472.64it/s]
Adding requests:  30%|       | 311/1024 [00:00<00:01, 473.38it/s]
Adding requests:  35%|      | 359/1024 [00:00<00:01, 464.44it/s]
Adding requests:  40%|      | 406/1024 [00:00<00:01, 465.64it/s]
Adding requests:  44%|     | 453/1024 [00:00<00:01, 456.42it/s]
Adding requests:  49%|     | 499/1024 [00:01<00:01, 456.46it/s]
Adding requests:  53%|    | 545/1024 [00:01<00:01, 442.79it/s]
Adding requests:  58%|    | 590/1024 [00:01<00:00, 442.10it/s]
Adding requests:  62%|   | 636/1024 [00:01<00:00, 446.25it/s]
Adding requests:  67%|   | 682/1024 [00:01<00:00, 449.33it/s]
Adding requests:  71%|   | 729/1024 [00:01<00:00, 453.61it/s]
Adding requests:  76%|  | 775/1024 [00:01<00:00, 447.09it/s]
Adding requests:  80%|  | 820/1024 [00:01<00:00, 442.65it/s]
Adding requests:  84%| | 865/1024 [00:01<00:00, 435.68it/s]
Adding requests:  89%| | 912/1024 [00:01<00:00, 443.60it/s]
Adding requests:  93%|| 957/1024 [00:02<00:00, 445.31it/s]
Adding requests:  98%|| 1005/1024 [00:02<00:00, 454.08it/s]
Adding requests: 100%|| 1024/1024 [00:02<00:00, 457.27it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|         | 66/1024 [00:00<00:02, 407.41it/s, est. speed input: 417227.71 toks/s, output: 407.42 toks/s]
Processed prompts:  10%|         | 107/1024 [00:01<00:14, 63.96it/s, est. speed input: 77606.44 toks/s, output: 75.79 toks/s]  
Processed prompts:  12%|        | 126/1024 [00:01<00:16, 55.20it/s, est. speed input: 67633.96 toks/s, output: 66.05 toks/s]
Processed prompts:  13%|        | 138/1024 [00:02<00:19, 44.93it/s, est. speed input: 58716.06 toks/s, output: 57.34 toks/s]
Processed prompts:  14%|        | 147/1024 [00:02<00:20, 43.37it/s, est. speed input: 56755.38 toks/s, output: 55.43 toks/s]
Processed prompts:  15%|        | 154/1024 [00:02<00:21, 40.19it/s, est. speed input: 54399.84 toks/s, output: 53.12 toks/s]
Processed prompts:  16%|        | 162/1024 [00:03<00:22, 38.15it/s, est. speed input: 52631.49 toks/s, output: 51.40 toks/s]
Processed prompts:  17%|        | 170/1024 [00:03<00:23, 36.70it/s, est. speed input: 51207.93 toks/s, output: 50.01 toks/s]
Processed prompts:  17%|        | 178/1024 [00:03<00:23, 35.50it/s, est. speed input: 49961.30 toks/s, output: 48.79 toks/s]
Processed prompts:  18%|        | 186/1024 [00:03<00:24, 34.59it/s, est. speed input: 48875.83 toks/s, output: 47.73 toks/s]
Processed prompts:  19%|        | 194/1024 [00:04<00:24, 33.97it/s, est. speed input: 47936.73 toks/s, output: 46.81 toks/s]
Processed prompts:  20%|        | 202/1024 [00:04<00:24, 33.31it/s, est. speed input: 47048.94 toks/s, output: 45.95 toks/s]
Processed prompts:  21%|        | 210/1024 [00:04<00:24, 33.05it/s, est. speed input: 46311.63 toks/s, output: 45.23 toks/s]
Processed prompts:  21%|       | 218/1024 [00:04<00:24, 32.80it/s, est. speed input: 45633.37 toks/s, output: 44.56 toks/s]
Processed prompts:  22%|       | 226/1024 [00:05<00:24, 32.61it/s, est. speed input: 45017.82 toks/s, output: 43.96 toks/s]
Processed prompts:  23%|       | 234/1024 [00:05<00:24, 32.33it/s, est. speed input: 44428.48 toks/s, output: 43.39 toks/s]
Processed prompts:  24%|       | 242/1024 [00:05<00:24, 32.37it/s, est. speed input: 43939.85 toks/s, output: 42.91 toks/s]
Processed prompts:  24%|       | 250/1024 [00:05<00:23, 32.43it/s, est. speed input: 43497.60 toks/s, output: 42.48 toks/s]
Processed prompts:  25%|       | 258/1024 [00:06<00:23, 32.37it/s, est. speed input: 43074.26 toks/s, output: 42.06 toks/s]
Processed prompts:  26%|       | 266/1024 [00:06<00:23, 32.16it/s, est. speed input: 42653.44 toks/s, output: 41.65 toks/s]
Processed prompts:  27%|       | 274/1024 [00:06<00:23, 32.10it/s, est. speed input: 42278.90 toks/s, output: 41.29 toks/s]
Processed prompts:  28%|       | 282/1024 [00:06<00:23, 32.13it/s, est. speed input: 41942.98 toks/s, output: 40.96 toks/s]
Processed prompts:  28%|       | 290/1024 [00:07<00:22, 32.17it/s, est. speed input: 41632.72 toks/s, output: 40.66 toks/s]
Processed prompts:  29%|       | 298/1024 [00:07<00:22, 32.25it/s, est. speed input: 41352.61 toks/s, output: 40.38 toks/s]
Processed prompts:  30%|       | 306/1024 [00:07<00:22, 32.01it/s, est. speed input: 41047.67 toks/s, output: 40.09 toks/s]
Processed prompts:  31%|       | 314/1024 [00:07<00:22, 32.05it/s, est. speed input: 40791.31 toks/s, output: 39.84 toks/s]
Processed prompts:  31%|      | 322/1024 [00:08<00:21, 32.06it/s, est. speed input: 40547.71 toks/s, output: 39.60 toks/s]
Processed prompts:  32%|      | 330/1024 [00:08<00:21, 32.08it/s, est. speed input: 40320.93 toks/s, output: 39.38 toks/s]
Processed prompts:  33%|      | 338/1024 [00:08<00:21, 32.29it/s, est. speed input: 40129.39 toks/s, output: 39.19 toks/s]
Processed prompts:  34%|      | 346/1024 [00:08<00:21, 32.27it/s, est. speed input: 39930.03 toks/s, output: 38.99 toks/s]
Processed prompts:  35%|      | 354/1024 [00:09<00:20, 32.27it/s, est. speed input: 39742.86 toks/s, output: 38.81 toks/s]
Processed prompts:  35%|      | 362/1024 [00:09<00:20, 32.27it/s, est. speed input: 39565.94 toks/s, output: 38.64 toks/s]
Processed prompts:  36%|      | 370/1024 [00:09<00:20, 32.14it/s, est. speed input: 39384.47 toks/s, output: 38.46 toks/s]
Processed prompts:  37%|      | 378/1024 [00:09<00:20, 32.23it/s, est. speed input: 39230.02 toks/s, output: 38.31 toks/s]
Processed prompts:  38%|      | 386/1024 [00:10<00:19, 32.18it/s, est. speed input: 39072.51 toks/s, output: 38.16 toks/s]
Processed prompts:  38%|      | 394/1024 [00:10<00:19, 32.23it/s, est. speed input: 38930.83 toks/s, output: 38.02 toks/s]
Processed prompts:  39%|      | 402/1024 [00:10<00:19, 32.12it/s, est. speed input: 38781.52 toks/s, output: 37.87 toks/s]
Processed prompts:  40%|      | 410/1024 [00:10<00:19, 31.96it/s, est. speed input: 38631.34 toks/s, output: 37.73 toks/s]
Processed prompts:  41%|      | 418/1024 [00:11<00:18, 32.17it/s, est. speed input: 38517.12 toks/s, output: 37.61 toks/s]
Processed prompts:  42%|     | 426/1024 [00:11<00:18, 32.20it/s, est. speed input: 38398.13 toks/s, output: 37.50 toks/s]
Processed prompts:  42%|     | 434/1024 [00:11<00:18, 32.07it/s, est. speed input: 38270.77 toks/s, output: 37.37 toks/s]
Processed prompts:  43%|     | 442/1024 [00:11<00:18, 31.96it/s, est. speed input: 38147.18 toks/s, output: 37.25 toks/s]
Processed prompts:  44%|     | 450/1024 [00:12<00:17, 32.71it/s, est. speed input: 38095.32 toks/s, output: 37.20 toks/s]
Processed prompts:  45%|     | 458/1024 [00:12<00:17, 32.60it/s, est. speed input: 37995.90 toks/s, output: 37.11 toks/s]
Processed prompts:  46%|     | 466/1024 [00:12<00:17, 32.36it/s, est. speed input: 37887.75 toks/s, output: 37.00 toks/s]
Processed prompts:  46%|     | 474/1024 [00:12<00:17, 32.15it/s, est. speed input: 37780.63 toks/s, output: 36.90 toks/s]
Processed prompts:  47%|     | 482/1024 [00:13<00:16, 32.07it/s, est. speed input: 37682.27 toks/s, output: 36.80 toks/s]
Processed prompts:  48%|     | 490/1024 [00:13<00:16, 32.17it/s, est. speed input: 37599.14 toks/s, output: 36.72 toks/s]
Processed prompts:  49%|     | 498/1024 [00:13<00:16, 32.13it/s, est. speed input: 37511.31 toks/s, output: 36.63 toks/s]
Processed prompts:  49%|     | 506/1024 [00:13<00:16, 31.99it/s, est. speed input: 37418.66 toks/s, output: 36.54 toks/s]
Processed prompts:  50%|     | 514/1024 [00:14<00:15, 31.94it/s, est. speed input: 37332.59 toks/s, output: 36.46 toks/s]
Processed prompts:  51%|     | 522/1024 [00:14<00:15, 31.98it/s, est. speed input: 37254.03 toks/s, output: 36.38 toks/s]
Processed prompts:  52%|    | 530/1024 [00:14<00:15, 32.04it/s, est. speed input: 37181.35 toks/s, output: 36.31 toks/s]
Processed prompts:  53%|    | 538/1024 [00:14<00:15, 32.07it/s, est. speed input: 37109.54 toks/s, output: 36.24 toks/s]
Processed prompts:  53%|    | 546/1024 [00:15<00:15, 31.86it/s, est. speed input: 37025.55 toks/s, output: 36.16 toks/s]
Processed prompts:  54%|    | 554/1024 [00:15<00:14, 31.87it/s, est. speed input: 36954.41 toks/s, output: 36.09 toks/s]
Processed prompts:  55%|    | 562/1024 [00:15<00:14, 31.99it/s, est. speed input: 36891.97 toks/s, output: 36.03 toks/s]
Processed prompts:  56%|    | 570/1024 [00:15<00:14, 31.93it/s, est. speed input: 36823.64 toks/s, output: 35.96 toks/s]
Processed prompts:  56%|    | 578/1024 [00:16<00:13, 31.87it/s, est. speed input: 36755.57 toks/s, output: 35.89 toks/s]
Processed prompts:  57%|    | 586/1024 [00:16<00:13, 32.08it/s, est. speed input: 36704.56 toks/s, output: 35.84 toks/s]
Processed prompts:  58%|    | 594/1024 [00:16<00:13, 32.09it/s, est. speed input: 36647.50 toks/s, output: 35.79 toks/s]
Processed prompts:  59%|    | 602/1024 [00:16<00:13, 32.21it/s, est. speed input: 36598.06 toks/s, output: 35.74 toks/s]
Processed prompts:  60%|    | 610/1024 [00:17<00:12, 31.96it/s, est. speed input: 36531.47 toks/s, output: 35.68 toks/s]
Processed prompts:  60%|    | 618/1024 [00:17<00:12, 31.98it/s, est. speed input: 36477.67 toks/s, output: 35.62 toks/s]
Processed prompts:  61%|    | 626/1024 [00:17<00:12, 31.98it/s, est. speed input: 36424.94 toks/s, output: 35.57 toks/s]
Processed prompts:  62%|   | 634/1024 [00:17<00:12, 32.04it/s, est. speed input: 36376.19 toks/s, output: 35.52 toks/s]
Processed prompts:  63%|   | 642/1024 [00:18<00:11, 32.01it/s, est. speed input: 36325.84 toks/s, output: 35.47 toks/s]
Processed prompts:  63%|   | 650/1024 [00:18<00:11, 31.87it/s, est. speed input: 36270.08 toks/s, output: 35.42 toks/s]
Processed prompts:  64%|   | 658/1024 [00:18<00:11, 31.94it/s, est. speed input: 36224.44 toks/s, output: 35.38 toks/s]
Processed prompts:  65%|   | 666/1024 [00:18<00:11, 32.00it/s, est. speed input: 36180.54 toks/s, output: 35.33 toks/s]
Processed prompts:  66%|   | 674/1024 [00:19<00:10, 32.03it/s, est. speed input: 36137.67 toks/s, output: 35.29 toks/s]
Processed prompts:  67%|   | 682/1024 [00:19<00:10, 31.94it/s, est. speed input: 36090.00 toks/s, output: 35.24 toks/s]
Processed prompts:  67%|   | 690/1024 [00:19<00:10, 32.03it/s, est. speed input: 36051.20 toks/s, output: 35.21 toks/s]
Processed prompts:  68%|   | 698/1024 [00:19<00:10, 32.11it/s, est. speed input: 36013.88 toks/s, output: 35.17 toks/s]
Processed prompts:  69%|   | 706/1024 [00:20<00:09, 32.06it/s, est. speed input: 35972.68 toks/s, output: 35.13 toks/s]
Processed prompts:  70%|   | 714/1024 [00:20<00:09, 31.90it/s, est. speed input: 35926.95 toks/s, output: 35.08 toks/s]
Processed prompts:  71%|   | 722/1024 [00:20<00:09, 31.95it/s, est. speed input: 35889.58 toks/s, output: 35.05 toks/s]
Processed prompts:  71%|  | 730/1024 [00:20<00:09, 31.99it/s, est. speed input: 35853.13 toks/s, output: 35.01 toks/s]
Processed prompts:  72%|  | 738/1024 [00:21<00:08, 32.03it/s, est. speed input: 35818.44 toks/s, output: 34.98 toks/s]
Processed prompts:  73%|  | 746/1024 [00:21<00:08, 31.96it/s, est. speed input: 35780.08 toks/s, output: 34.94 toks/s]
Processed prompts:  74%|  | 754/1024 [00:21<00:08, 31.87it/s, est. speed input: 35740.57 toks/s, output: 34.90 toks/s]
Processed prompts:  74%|  | 762/1024 [00:21<00:08, 31.98it/s, est. speed input: 35709.78 toks/s, output: 34.87 toks/s]
Processed prompts:  75%|  | 770/1024 [00:22<00:07, 31.99it/s, est. speed input: 35676.67 toks/s, output: 34.84 toks/s]
Processed prompts:  76%|  | 778/1024 [00:22<00:07, 32.01it/s, est. speed input: 35644.65 toks/s, output: 34.81 toks/s]
Processed prompts:  77%|  | 786/1024 [00:22<00:07, 31.85it/s, est. speed input: 35606.32 toks/s, output: 34.77 toks/s]
Processed prompts:  78%|  | 794/1024 [00:22<00:07, 31.88it/s, est. speed input: 35574.61 toks/s, output: 34.74 toks/s]
Processed prompts:  78%|  | 802/1024 [00:23<00:06, 32.04it/s, est. speed input: 35549.25 toks/s, output: 34.72 toks/s]
Processed prompts:  79%|  | 810/1024 [00:23<00:06, 31.99it/s, est. speed input: 35517.93 toks/s, output: 34.69 toks/s]
Processed prompts:  80%|  | 818/1024 [00:23<00:06, 31.87it/s, est. speed input: 35484.07 toks/s, output: 34.65 toks/s]
Processed prompts:  81%|  | 826/1024 [00:23<00:06, 31.93it/s, est. speed input: 35456.25 toks/s, output: 34.63 toks/s]
Processed prompts:  81%| | 834/1024 [00:24<00:05, 31.90it/s, est. speed input: 35426.57 toks/s, output: 34.60 toks/s]
Processed prompts:  82%| | 842/1024 [00:24<00:05, 32.04it/s, est. speed input: 35403.34 toks/s, output: 34.57 toks/s]
Processed prompts:  83%| | 850/1024 [00:24<00:05, 31.93it/s, est. speed input: 35372.81 toks/s, output: 34.54 toks/s]
Processed prompts:  84%| | 858/1024 [00:24<00:05, 31.90it/s, est. speed input: 35344.63 toks/s, output: 34.52 toks/s]
Processed prompts:  85%| | 866/1024 [00:25<00:04, 31.94it/s, est. speed input: 35319.47 toks/s, output: 34.49 toks/s]
Processed prompts:  85%| | 874/1024 [00:25<00:04, 32.07it/s, est. speed input: 35298.27 toks/s, output: 34.47 toks/s]
Processed prompts:  86%| | 882/1024 [00:25<00:04, 32.13it/s, est. speed input: 35276.44 toks/s, output: 34.45 toks/s]
Processed prompts:  87%| | 890/1024 [00:25<00:04, 31.98it/s, est. speed input: 35248.50 toks/s, output: 34.42 toks/s]
Processed prompts:  88%| | 898/1024 [00:26<00:03, 32.07it/s, est. speed input: 35227.43 toks/s, output: 34.40 toks/s]
Processed prompts:  88%| | 906/1024 [00:26<00:03, 32.02it/s, est. speed input: 35203.20 toks/s, output: 34.38 toks/s]
Processed prompts:  89%| | 914/1024 [00:26<00:03, 32.19it/s, est. speed input: 35186.25 toks/s, output: 34.36 toks/s]
Processed prompts:  90%| | 922/1024 [00:26<00:03, 31.96it/s, est. speed input: 35157.96 toks/s, output: 34.33 toks/s]
Processed prompts:  91%| | 930/1024 [00:27<00:02, 32.04it/s, est. speed input: 35138.27 toks/s, output: 34.31 toks/s]
Processed prompts:  92%|| 938/1024 [00:27<00:02, 33.42it/s, est. speed input: 35161.24 toks/s, output: 34.34 toks/s]
Processed prompts:  92%|| 946/1024 [00:27<00:02, 32.99it/s, est. speed input: 35139.79 toks/s, output: 34.32 toks/s]
Processed prompts:  93%|| 954/1024 [00:27<00:02, 32.59it/s, est. speed input: 35115.46 toks/s, output: 34.29 toks/s]
Processed prompts:  94%|| 962/1024 [00:28<00:01, 32.45it/s, est. speed input: 35095.64 toks/s, output: 34.27 toks/s]
Processed prompts:  95%|| 970/1024 [00:28<00:01, 32.36it/s, est. speed input: 35076.55 toks/s, output: 34.25 toks/s]
Processed prompts:  96%|| 978/1024 [00:28<00:01, 32.36it/s, est. speed input: 35059.67 toks/s, output: 34.24 toks/s]
Processed prompts:  96%|| 986/1024 [00:28<00:01, 33.68it/s, est. speed input: 35082.73 toks/s, output: 34.26 toks/s]
Processed prompts:  97%|| 994/1024 [00:29<00:00, 33.05it/s, est. speed input: 35059.41 toks/s, output: 34.24 toks/s]
Processed prompts:  98%|| 1002/1024 [00:29<00:00, 32.76it/s, est. speed input: 35040.89 toks/s, output: 34.22 toks/s]
Processed prompts:  99%|| 1010/1024 [00:29<00:00, 32.49it/s, est. speed input: 35020.61 toks/s, output: 34.20 toks/s]
Processed prompts:  99%|| 1018/1024 [00:29<00:00, 33.21it/s, est. speed input: 35027.09 toks/s, output: 34.21 toks/s]
Processed prompts: 100%|| 1024/1024 [00:29<00:00, 33.21it/s, est. speed input: 35233.38 toks/s, output: 34.41 toks/s]
Processed prompts: 100%|| 1024/1024 [00:29<00:00, 34.41it/s, est. speed input: 35233.38 toks/s, output: 34.41 toks/s]
[rank0]:[W126 08:05:00.701046849 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-26 08:05:02
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Llama3.2-1B-FP8_M16384.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:05:11 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 08:05:12 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1053534) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1053534) WARNING 01-26 08:05:31 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 32.22 requests/s, 33022.43 total tokens/s, 32.22 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-26 08:05:11] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:05:11] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:05:11] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:05:11] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:05:11] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:05:11] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:05:11] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:05:11] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:05:11] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:05:11] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:05:11] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:05:11] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:05:11] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:05:11] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:05:15] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:05:15] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:05:15] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:05:15] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:05:15] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:05:15] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:05:15] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:05:15] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:05:15] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:05:15] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:05:15] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:05:15] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:05:15] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:05:15] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1053534) [2026-01-26 08:05:16] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1053534) [2026-01-26 08:05:16] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1053534) [2026-01-26 08:05:16] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1053534) [2026-01-26 08:05:16] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1053534) [2026-01-26 08:05:16] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1053534) [2026-01-26 08:05:16] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1053534) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1053534) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.24s/it]
(EngineCore_DP0 pid=1053534) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.24s/it]
(EngineCore_DP0 pid=1053534) 
(EngineCore_DP0 pid=1053534) [2026-01-26 08:05:25] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=1053534) [2026-01-26 08:05:25] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=1053534) [2026-01-26 08:05:25] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=1053534) [2026-01-26 08:05:25] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 2621440 bytes
(EngineCore_DP0 pid=1053534) [2026-01-26 08:05:25] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=1053534) [2026-01-26 08:05:25] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 20971520 bytes
(EngineCore_DP0 pid=1053534) [2026-01-26 08:05:25] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=1053534) [2026-01-26 08:05:25] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10485760 bytes
(EngineCore_DP0 pid=1053534) 2026-01-26 08:05:30,606 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1053534) 2026-01-26 08:05:30,716 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   3%|         | 59/2048 [00:00<00:03, 586.96it/s]
Adding requests:   6%|         | 118/2048 [00:00<00:03, 536.56it/s]
Adding requests:   8%|         | 172/2048 [00:00<00:03, 500.24it/s]
Adding requests:  11%|         | 223/2048 [00:00<00:03, 496.37it/s]
Adding requests:  13%|        | 273/2048 [00:00<00:03, 495.29it/s]
Adding requests:  16%|        | 323/2048 [00:00<00:03, 486.95it/s]
Adding requests:  18%|        | 372/2048 [00:00<00:03, 485.18it/s]
Adding requests:  21%|        | 421/2048 [00:00<00:03, 483.47it/s]
Adding requests:  23%|       | 470/2048 [00:00<00:03, 471.65it/s]
Adding requests:  25%|       | 518/2048 [00:01<00:03, 468.62it/s]
Adding requests:  28%|       | 566/2048 [00:01<00:03, 470.37it/s]
Adding requests:  30%|       | 614/2048 [00:01<00:03, 461.87it/s]
Adding requests:  32%|      | 661/2048 [00:01<00:03, 460.14it/s]
Adding requests:  35%|      | 710/2048 [00:01<00:02, 467.44it/s]
Adding requests:  37%|      | 757/2048 [00:01<00:02, 444.06it/s]
Adding requests:  39%|      | 802/2048 [00:01<00:02, 437.48it/s]
Adding requests:  41%|     | 846/2048 [00:02<00:08, 143.65it/s]
Adding requests:  43%|     | 879/2048 [00:02<00:07, 164.96it/s]
Adding requests:  45%|     | 923/2048 [00:02<00:05, 204.45it/s]
Adding requests:  47%|     | 967/2048 [00:02<00:04, 243.98it/s]
Adding requests:  50%|     | 1015/2048 [00:02<00:03, 289.51it/s]
Adding requests:  52%|    | 1062/2048 [00:03<00:03, 327.75it/s]
Adding requests:  54%|    | 1109/2048 [00:03<00:02, 360.88it/s]
Adding requests:  56%|    | 1153/2048 [00:03<00:02, 377.34it/s]
Adding requests:  59%|    | 1203/2048 [00:03<00:02, 409.52it/s]
Adding requests:  61%|    | 1249/2048 [00:03<00:01, 418.58it/s]
Adding requests:  63%|   | 1294/2048 [00:03<00:01, 425.22it/s]
Adding requests:  65%|   | 1340/2048 [00:03<00:01, 434.57it/s]
Adding requests:  68%|   | 1386/2048 [00:03<00:01, 437.96it/s]
Adding requests:  70%|   | 1432/2048 [00:03<00:01, 443.60it/s]
Adding requests:  72%|  | 1480/2048 [00:03<00:01, 453.82it/s]
Adding requests:  75%|  | 1527/2048 [00:04<00:01, 456.96it/s]
Adding requests:  77%|  | 1574/2048 [00:04<00:01, 459.07it/s]
Adding requests:  79%|  | 1621/2048 [00:04<00:00, 454.54it/s]
Adding requests:  81%| | 1667/2048 [00:04<00:00, 449.07it/s]
Adding requests:  84%| | 1713/2048 [00:04<00:00, 442.04it/s]
Adding requests:  86%| | 1758/2048 [00:04<00:00, 443.26it/s]
Adding requests:  88%| | 1804/2048 [00:04<00:00, 447.96it/s]
Adding requests:  90%| | 1849/2048 [00:04<00:00, 444.93it/s]
Adding requests:  93%|| 1897/2048 [00:04<00:00, 454.38it/s]
Adding requests:  95%|| 1943/2048 [00:04<00:00, 455.60it/s]
Adding requests:  97%|| 1991/2048 [00:05<00:00, 460.35it/s]
Adding requests: 100%|| 2038/2048 [00:05<00:00, 419.17it/s]
Adding requests: 100%|| 2048/2048 [00:05<00:00, 391.61it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   8%|         | 162/2048 [00:00<00:04, 387.97it/s, est. speed input: 397315.63 toks/s, output: 387.98 toks/s]
Processed prompts:  10%|         | 201/2048 [00:01<00:15, 118.96it/s, est. speed input: 146349.47 toks/s, output: 142.92 toks/s]
Processed prompts:  11%|         | 220/2048 [00:01<00:20, 90.30it/s, est. speed input: 118477.28 toks/s, output: 115.70 toks/s] 
Processed prompts:  11%|        | 232/2048 [00:02<00:26, 68.14it/s, est. speed input: 99222.10 toks/s, output: 96.90 toks/s]  
Processed prompts:  12%|        | 242/2048 [00:02<00:34, 52.54it/s, est. speed input: 85761.61 toks/s, output: 83.75 toks/s]
Processed prompts:  13%|        | 258/2048 [00:03<00:38, 46.18it/s, est. speed input: 78098.22 toks/s, output: 76.27 toks/s]
Processed prompts:  13%|        | 274/2048 [00:03<00:42, 41.83it/s, est. speed input: 72336.60 toks/s, output: 70.64 toks/s]
Processed prompts:  14%|        | 290/2048 [00:04<00:45, 38.90it/s, est. speed input: 67896.69 toks/s, output: 66.30 toks/s]
Processed prompts:  15%|        | 306/2048 [00:04<00:47, 36.86it/s, est. speed input: 64338.16 toks/s, output: 62.83 toks/s]
Processed prompts:  16%|        | 322/2048 [00:05<00:48, 35.51it/s, est. speed input: 61470.09 toks/s, output: 60.03 toks/s]
Processed prompts:  17%|        | 338/2048 [00:05<00:49, 34.70it/s, est. speed input: 59150.59 toks/s, output: 57.76 toks/s]
Processed prompts:  17%|        | 354/2048 [00:06<00:49, 34.00it/s, est. speed input: 57124.35 toks/s, output: 55.79 toks/s]
Processed prompts:  18%|        | 370/2048 [00:06<00:50, 33.44it/s, est. speed input: 55366.96 toks/s, output: 54.07 toks/s]
Processed prompts:  19%|        | 386/2048 [00:07<00:50, 33.02it/s, est. speed input: 53831.90 toks/s, output: 52.57 toks/s]
Processed prompts:  20%|        | 402/2048 [00:07<00:50, 32.79it/s, est. speed input: 52516.96 toks/s, output: 51.29 toks/s]
Processed prompts:  20%|        | 418/2048 [00:08<00:49, 32.64it/s, est. speed input: 51359.55 toks/s, output: 50.16 toks/s]
Processed prompts:  21%|        | 434/2048 [00:08<00:49, 32.59it/s, est. speed input: 50350.63 toks/s, output: 49.17 toks/s]
Processed prompts:  22%|       | 450/2048 [00:09<00:49, 32.56it/s, est. speed input: 49446.79 toks/s, output: 48.29 toks/s]
Processed prompts:  23%|       | 466/2048 [00:09<00:48, 32.50it/s, est. speed input: 48624.40 toks/s, output: 47.48 toks/s]
Processed prompts:  24%|       | 482/2048 [00:10<00:48, 32.32it/s, est. speed input: 47849.83 toks/s, output: 46.73 toks/s]
Processed prompts:  24%|       | 498/2048 [00:10<00:47, 32.35it/s, est. speed input: 47180.60 toks/s, output: 46.07 toks/s]
Processed prompts:  25%|       | 514/2048 [00:11<00:47, 32.31it/s, est. speed input: 46557.23 toks/s, output: 45.47 toks/s]
Processed prompts:  26%|       | 530/2048 [00:11<00:46, 32.35it/s, est. speed input: 46000.50 toks/s, output: 44.92 toks/s]
Processed prompts:  27%|       | 546/2048 [00:12<00:46, 32.21it/s, est. speed input: 45456.18 toks/s, output: 44.39 toks/s]
Processed prompts:  27%|       | 562/2048 [00:12<00:45, 32.30it/s, est. speed input: 44988.60 toks/s, output: 43.93 toks/s]
Processed prompts:  28%|       | 578/2048 [00:13<00:45, 32.31it/s, est. speed input: 44545.71 toks/s, output: 43.50 toks/s]
Processed prompts:  29%|       | 594/2048 [00:13<00:45, 32.28it/s, est. speed input: 44129.51 toks/s, output: 43.10 toks/s]
Processed prompts:  30%|       | 610/2048 [00:14<00:44, 32.26it/s, est. speed input: 43741.93 toks/s, output: 42.72 toks/s]
Processed prompts:  31%|       | 626/2048 [00:14<00:44, 32.25it/s, est. speed input: 43380.81 toks/s, output: 42.36 toks/s]
Processed prompts:  31%|      | 642/2048 [00:15<00:43, 32.36it/s, est. speed input: 43059.93 toks/s, output: 42.05 toks/s]
Processed prompts:  32%|      | 658/2048 [00:15<00:43, 32.28it/s, est. speed input: 42738.23 toks/s, output: 41.74 toks/s]
Processed prompts:  33%|      | 674/2048 [00:16<00:42, 32.32it/s, est. speed input: 42447.55 toks/s, output: 41.45 toks/s]
Processed prompts:  34%|      | 690/2048 [00:16<00:42, 32.24it/s, est. speed input: 42161.07 toks/s, output: 41.17 toks/s]
Processed prompts:  34%|      | 706/2048 [00:17<00:41, 32.29it/s, est. speed input: 41903.97 toks/s, output: 40.92 toks/s]
Processed prompts:  35%|      | 722/2048 [00:17<00:41, 32.25it/s, est. speed input: 41652.53 toks/s, output: 40.68 toks/s]
Processed prompts:  36%|      | 738/2048 [00:18<00:40, 32.25it/s, est. speed input: 41417.92 toks/s, output: 40.45 toks/s]
Processed prompts:  37%|      | 754/2048 [00:18<00:40, 32.21it/s, est. speed input: 41191.53 toks/s, output: 40.23 toks/s]
Processed prompts:  38%|      | 770/2048 [00:19<00:39, 32.26it/s, est. speed input: 40984.85 toks/s, output: 40.02 toks/s]
Processed prompts:  38%|      | 786/2048 [00:19<00:39, 32.23it/s, est. speed input: 40782.30 toks/s, output: 39.83 toks/s]
Processed prompts:  39%|      | 802/2048 [00:20<00:38, 32.23it/s, est. speed input: 40591.52 toks/s, output: 39.64 toks/s]
Processed prompts:  40%|      | 818/2048 [00:20<00:38, 32.23it/s, est. speed input: 40409.74 toks/s, output: 39.46 toks/s]
Processed prompts:  41%|      | 834/2048 [00:21<00:37, 32.29it/s, est. speed input: 40242.56 toks/s, output: 39.30 toks/s]
Processed prompts:  42%|     | 850/2048 [00:21<00:37, 32.29it/s, est. speed input: 40078.59 toks/s, output: 39.14 toks/s]
Processed prompts:  42%|     | 866/2048 [00:22<00:36, 32.28it/s, est. speed input: 39921.12 toks/s, output: 38.99 toks/s]
Processed prompts:  43%|     | 882/2048 [00:22<00:36, 32.33it/s, est. speed input: 39775.76 toks/s, output: 38.84 toks/s]
Processed prompts:  44%|     | 898/2048 [00:23<00:35, 32.23it/s, est. speed input: 39625.16 toks/s, output: 38.70 toks/s]
Processed prompts:  45%|     | 914/2048 [00:23<00:35, 32.29it/s, est. speed input: 39490.99 toks/s, output: 38.57 toks/s]
Processed prompts:  45%|     | 930/2048 [00:24<00:34, 32.85it/s, est. speed input: 39405.80 toks/s, output: 38.48 toks/s]
Processed prompts:  46%|     | 946/2048 [00:24<00:33, 32.75it/s, est. speed input: 39283.60 toks/s, output: 38.36 toks/s]
Processed prompts:  47%|     | 962/2048 [00:25<00:33, 32.59it/s, est. speed input: 39159.55 toks/s, output: 38.24 toks/s]
Processed prompts:  48%|     | 978/2048 [00:25<00:32, 33.20it/s, est. speed input: 39094.69 toks/s, output: 38.18 toks/s]
Processed prompts:  49%|     | 994/2048 [00:26<00:32, 32.87it/s, est. speed input: 38976.18 toks/s, output: 38.06 toks/s]
Processed prompts:  49%|     | 1010/2048 [00:26<00:31, 32.72it/s, est. speed input: 38868.41 toks/s, output: 37.96 toks/s]
Processed prompts:  50%|     | 1026/2048 [00:27<00:31, 32.59it/s, est. speed input: 38762.37 toks/s, output: 37.85 toks/s]
Processed prompts:  51%|     | 1042/2048 [00:27<00:31, 32.01it/s, est. speed input: 38625.17 toks/s, output: 37.72 toks/s]
Processed prompts:  52%|    | 1058/2048 [00:28<00:35, 27.79it/s, est. speed input: 38177.38 toks/s, output: 37.28 toks/s]
Processed prompts:  52%|    | 1074/2048 [00:28<00:33, 29.00it/s, est. speed input: 38089.86 toks/s, output: 37.20 toks/s]
Processed prompts:  53%|    | 1090/2048 [00:29<00:32, 29.86it/s, est. speed input: 38001.04 toks/s, output: 37.11 toks/s]
Processed prompts:  54%|    | 1106/2048 [00:29<00:30, 30.58it/s, est. speed input: 37921.11 toks/s, output: 37.03 toks/s]
Processed prompts:  55%|    | 1122/2048 [00:30<00:29, 31.00it/s, est. speed input: 37837.00 toks/s, output: 36.95 toks/s]
Processed prompts:  56%|    | 1138/2048 [00:30<00:28, 31.40it/s, est. speed input: 37761.90 toks/s, output: 36.88 toks/s]
Processed prompts:  56%|    | 1154/2048 [00:31<00:27, 32.28it/s, est. speed input: 37726.49 toks/s, output: 36.84 toks/s]
Processed prompts:  57%|    | 1170/2048 [00:31<00:27, 32.25it/s, est. speed input: 37652.02 toks/s, output: 36.77 toks/s]
Processed prompts:  58%|    | 1186/2048 [00:32<00:26, 32.29it/s, est. speed input: 37582.94 toks/s, output: 36.70 toks/s]
Processed prompts:  59%|    | 1202/2048 [00:32<00:26, 32.28it/s, est. speed input: 37514.19 toks/s, output: 36.63 toks/s]
Processed prompts:  59%|    | 1218/2048 [00:33<00:25, 32.30it/s, est. speed input: 37449.34 toks/s, output: 36.57 toks/s]
Processed prompts:  60%|    | 1234/2048 [00:33<00:25, 32.22it/s, est. speed input: 37380.65 toks/s, output: 36.50 toks/s]
Processed prompts:  61%|    | 1250/2048 [00:34<00:24, 32.28it/s, est. speed input: 37320.21 toks/s, output: 36.45 toks/s]
Processed prompts:  62%|   | 1266/2048 [00:34<00:23, 32.81it/s, est. speed input: 37288.00 toks/s, output: 36.41 toks/s]
Processed prompts:  63%|   | 1282/2048 [00:35<00:23, 32.72it/s, est. speed input: 37232.12 toks/s, output: 36.36 toks/s]
Processed prompts:  63%|   | 1298/2048 [00:35<00:22, 33.13it/s, est. speed input: 37202.19 toks/s, output: 36.33 toks/s]
Processed prompts:  64%|   | 1314/2048 [00:36<00:22, 32.91it/s, est. speed input: 37147.58 toks/s, output: 36.28 toks/s]
Processed prompts:  65%|   | 1330/2048 [00:36<00:21, 32.84it/s, est. speed input: 37098.49 toks/s, output: 36.23 toks/s]
Processed prompts:  66%|   | 1346/2048 [00:37<00:21, 32.58it/s, est. speed input: 37040.26 toks/s, output: 36.17 toks/s]
Processed prompts:  67%|   | 1362/2048 [00:37<00:21, 32.51it/s, est. speed input: 36988.62 toks/s, output: 36.12 toks/s]
Processed prompts:  67%|   | 1378/2048 [00:38<00:20, 32.42it/s, est. speed input: 36936.70 toks/s, output: 36.07 toks/s]
Processed prompts:  68%|   | 1394/2048 [00:38<00:20, 32.39it/s, est. speed input: 36887.59 toks/s, output: 36.02 toks/s]
Processed prompts:  69%|   | 1410/2048 [00:39<00:19, 32.25it/s, est. speed input: 36833.79 toks/s, output: 35.97 toks/s]
Processed prompts:  70%|   | 1426/2048 [00:39<00:19, 32.32it/s, est. speed input: 36789.70 toks/s, output: 35.93 toks/s]
Processed prompts:  70%|   | 1442/2048 [00:40<00:18, 32.23it/s, est. speed input: 36740.03 toks/s, output: 35.88 toks/s]
Processed prompts:  71%|   | 1458/2048 [00:40<00:18, 32.27it/s, est. speed input: 36696.34 toks/s, output: 35.84 toks/s]
Processed prompts:  72%|  | 1474/2048 [00:41<00:17, 32.22it/s, est. speed input: 36650.22 toks/s, output: 35.79 toks/s]
Processed prompts:  73%|  | 1490/2048 [00:41<00:17, 32.29it/s, est. speed input: 36609.85 toks/s, output: 35.75 toks/s]
Processed prompts:  74%|  | 1506/2048 [00:42<00:16, 32.30it/s, est. speed input: 36568.66 toks/s, output: 35.71 toks/s]
Processed prompts:  74%|  | 1522/2048 [00:42<00:16, 32.35it/s, est. speed input: 36530.15 toks/s, output: 35.67 toks/s]
Processed prompts:  75%|  | 1538/2048 [00:43<00:15, 32.40it/s, est. speed input: 36493.46 toks/s, output: 35.64 toks/s]
Processed prompts:  76%|  | 1554/2048 [00:43<00:15, 32.33it/s, est. speed input: 36452.81 toks/s, output: 35.60 toks/s]
Processed prompts:  77%|  | 1570/2048 [00:44<00:14, 32.34it/s, est. speed input: 36415.59 toks/s, output: 35.56 toks/s]
Processed prompts:  77%|  | 1586/2048 [00:44<00:14, 32.89it/s, est. speed input: 36401.47 toks/s, output: 35.55 toks/s]
Processed prompts:  78%|  | 1602/2048 [00:45<00:13, 32.71it/s, est. speed input: 36364.92 toks/s, output: 35.51 toks/s]
Processed prompts:  79%|  | 1618/2048 [00:45<00:13, 32.52it/s, est. speed input: 36326.65 toks/s, output: 35.48 toks/s]
Processed prompts:  80%|  | 1634/2048 [00:46<00:12, 32.43it/s, est. speed input: 36290.93 toks/s, output: 35.44 toks/s]
Processed prompts:  81%|  | 1650/2048 [00:46<00:12, 32.97it/s, est. speed input: 36279.05 toks/s, output: 35.43 toks/s]
Processed prompts:  81%| | 1666/2048 [00:47<00:11, 32.79it/s, est. speed input: 36246.36 toks/s, output: 35.40 toks/s]
Processed prompts:  82%| | 1682/2048 [00:47<00:11, 32.59it/s, est. speed input: 36211.49 toks/s, output: 35.36 toks/s]
Processed prompts:  83%| | 1698/2048 [00:48<00:10, 32.52it/s, est. speed input: 36179.53 toks/s, output: 35.33 toks/s]
Processed prompts:  84%| | 1714/2048 [00:48<00:10, 32.46it/s, est. speed input: 36148.26 toks/s, output: 35.30 toks/s]
Processed prompts:  84%| | 1730/2048 [00:49<00:09, 32.36it/s, est. speed input: 36115.37 toks/s, output: 35.27 toks/s]
Processed prompts:  85%| | 1746/2048 [00:49<00:09, 32.34it/s, est. speed input: 36084.94 toks/s, output: 35.24 toks/s]
Processed prompts:  86%| | 1762/2048 [00:50<00:08, 32.28it/s, est. speed input: 36053.19 toks/s, output: 35.21 toks/s]
Processed prompts:  87%| | 1778/2048 [00:50<00:08, 32.31it/s, est. speed input: 36024.85 toks/s, output: 35.18 toks/s]
Processed prompts:  88%| | 1794/2048 [00:51<00:07, 32.25it/s, est. speed input: 35994.38 toks/s, output: 35.15 toks/s]
Processed prompts:  88%| | 1810/2048 [00:51<00:07, 32.29it/s, est. speed input: 35967.02 toks/s, output: 35.12 toks/s]
Processed prompts:  89%| | 1826/2048 [00:52<00:06, 32.16it/s, est. speed input: 35934.74 toks/s, output: 35.09 toks/s]
Processed prompts:  90%| | 1842/2048 [00:52<00:06, 32.24it/s, est. speed input: 35909.19 toks/s, output: 35.07 toks/s]
Processed prompts:  91%| | 1858/2048 [00:53<00:05, 32.14it/s, est. speed input: 35878.58 toks/s, output: 35.04 toks/s]
Processed prompts:  92%|| 1874/2048 [00:53<00:05, 32.86it/s, est. speed input: 35875.44 toks/s, output: 35.03 toks/s]
Processed prompts:  92%|| 1890/2048 [00:53<00:04, 32.68it/s, est. speed input: 35849.43 toks/s, output: 35.01 toks/s]
Processed prompts:  93%|| 1906/2048 [00:54<00:04, 32.53it/s, est. speed input: 35822.91 toks/s, output: 34.98 toks/s]
Processed prompts:  94%|| 1922/2048 [00:54<00:03, 32.47it/s, est. speed input: 35798.56 toks/s, output: 34.96 toks/s]
Processed prompts:  95%|| 1938/2048 [00:55<00:03, 32.32it/s, est. speed input: 35771.02 toks/s, output: 34.93 toks/s]
Processed prompts:  95%|| 1954/2048 [00:55<00:02, 32.98it/s, est. speed input: 35768.40 toks/s, output: 34.93 toks/s]
Processed prompts:  96%|| 1970/2048 [00:56<00:02, 32.71it/s, est. speed input: 35742.82 toks/s, output: 34.91 toks/s]
Processed prompts:  97%|| 1986/2048 [00:56<00:01, 33.24it/s, est. speed input: 35739.83 toks/s, output: 34.90 toks/s]
Processed prompts:  98%|| 2002/2048 [00:57<00:01, 33.76it/s, est. speed input: 35740.94 toks/s, output: 34.90 toks/s]
Processed prompts:  99%|| 2018/2048 [00:57<00:00, 33.30it/s, est. speed input: 35718.02 toks/s, output: 34.88 toks/s]
Processed prompts:  99%|| 2034/2048 [00:58<00:00, 33.24it/s, est. speed input: 35702.87 toks/s, output: 34.87 toks/s]
Processed prompts: 100%|| 2048/2048 [00:58<00:00, 33.24it/s, est. speed input: 35948.50 toks/s, output: 35.11 toks/s]
Processed prompts: 100%|| 2048/2048 [00:58<00:00, 35.11it/s, est. speed input: 35948.50 toks/s, output: 35.11 toks/s]
[rank0]:[W126 08:06:35.794318955 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-26 08:06:37
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Llama3.2-1B-FP8_M32768.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:06:52 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 08:06:52 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1055100) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1055100) WARNING 01-26 08:07:14 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 33.13 requests/s, 33954.58 total tokens/s, 33.13 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-26 08:06:52] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:06:52] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:06:52] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:06:52] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:06:52] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:06:52] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:06:52] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:06:52] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:06:52] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:06:52] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:06:52] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:06:52] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:06:52] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:06:52] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:06:56] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:06:56] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:06:56] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:06:56] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:06:56] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:06:56] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:06:56] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:06:56] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:06:56] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:06:56] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:06:56] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:06:56] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:06:56] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:06:56] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1055100) [2026-01-26 08:06:57] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1055100) [2026-01-26 08:06:57] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1055100) [2026-01-26 08:06:57] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1055100) [2026-01-26 08:06:57] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1055100) [2026-01-26 08:06:57] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1055100) [2026-01-26 08:06:57] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1055100) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1055100) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.27s/it]
(EngineCore_DP0 pid=1055100) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.27s/it]
(EngineCore_DP0 pid=1055100) 
(EngineCore_DP0 pid=1055100) [2026-01-26 08:07:06] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=1055100) [2026-01-26 08:07:06] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=1055100) [2026-01-26 08:07:06] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=1055100) [2026-01-26 08:07:06] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 2621440 bytes
(EngineCore_DP0 pid=1055100) [2026-01-26 08:07:06] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=1055100) [2026-01-26 08:07:06] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 20971520 bytes
(EngineCore_DP0 pid=1055100) [2026-01-26 08:07:06] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=1055100) [2026-01-26 08:07:06] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10485760 bytes
(EngineCore_DP0 pid=1055100) 2026-01-26 08:07:12,206 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1055100) 2026-01-26 08:07:12,357 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|         | 55/4096 [00:00<00:07, 545.50it/s]
Adding requests:   3%|         | 110/4096 [00:00<00:10, 373.08it/s]
Adding requests:   4%|         | 151/4096 [00:00<00:10, 384.99it/s]
Adding requests:   5%|         | 200/4096 [00:00<00:09, 417.90it/s]
Adding requests:   6%|         | 249/4096 [00:00<00:08, 438.99it/s]
Adding requests:   7%|         | 298/4096 [00:00<00:08, 451.69it/s]
Adding requests:   9%|         | 349/4096 [00:00<00:07, 468.40it/s]
Adding requests:  10%|         | 406/4096 [00:00<00:07, 499.48it/s]
Adding requests:  11%|        | 465/4096 [00:00<00:06, 526.29it/s]
Adding requests:  13%|        | 519/4096 [00:01<00:07, 493.01it/s]
Adding requests:  14%|        | 570/4096 [00:01<00:07, 481.94it/s]
Adding requests:  15%|        | 619/4096 [00:01<00:07, 470.24it/s]
Adding requests:  16%|        | 667/4096 [00:01<00:07, 469.90it/s]
Adding requests:  17%|        | 715/4096 [00:01<00:07, 470.70it/s]
Adding requests:  19%|        | 763/4096 [00:01<00:07, 472.20it/s]
Adding requests:  20%|        | 811/4096 [00:01<00:07, 459.25it/s]
Adding requests:  21%|        | 858/4096 [00:01<00:07, 454.51it/s]
Adding requests:  22%|       | 907/4096 [00:01<00:06, 461.43it/s]
Adding requests:  23%|       | 954/4096 [00:02<00:06, 462.53it/s]
Adding requests:  24%|       | 1001/4096 [00:02<00:06, 461.05it/s]
Adding requests:  26%|       | 1048/4096 [00:02<00:06, 456.98it/s]
Adding requests:  27%|       | 1094/4096 [00:02<00:06, 449.45it/s]
Adding requests:  28%|       | 1139/4096 [00:02<00:06, 447.93it/s]
Adding requests:  29%|       | 1184/4096 [00:02<00:06, 421.88it/s]
Adding requests:  30%|       | 1229/4096 [00:02<00:06, 429.59it/s]
Adding requests:  31%|       | 1273/4096 [00:02<00:06, 427.45it/s]
Adding requests:  32%|      | 1319/4096 [00:02<00:06, 435.94it/s]
Adding requests:  33%|      | 1366/4096 [00:03<00:06, 444.83it/s]
Adding requests:  34%|      | 1413/4096 [00:03<00:05, 452.08it/s]
Adding requests:  36%|      | 1461/4096 [00:03<00:05, 460.21it/s]
Adding requests:  37%|      | 1508/4096 [00:03<00:05, 444.41it/s]
Adding requests:  38%|      | 1557/4096 [00:03<00:05, 455.19it/s]
Adding requests:  39%|      | 1606/4096 [00:03<00:05, 463.21it/s]
Adding requests:  40%|      | 1653/4096 [00:03<00:05, 465.14it/s]
Adding requests:  42%|     | 1700/4096 [00:03<00:05, 461.95it/s]
Adding requests:  43%|     | 1750/4096 [00:03<00:04, 471.07it/s]
Adding requests:  44%|     | 1798/4096 [00:03<00:04, 469.18it/s]
Adding requests:  45%|     | 1847/4096 [00:04<00:04, 474.70it/s]
Adding requests:  46%|     | 1895/4096 [00:04<00:04, 459.35it/s]
Adding requests:  47%|     | 1942/4096 [00:04<00:04, 450.84it/s]
Adding requests:  49%|     | 1988/4096 [00:04<00:04, 447.49it/s]
Adding requests:  50%|     | 2037/4096 [00:04<00:04, 458.99it/s]
Adding requests:  51%|     | 2083/4096 [00:04<00:04, 454.86it/s]
Adding requests:  52%|    | 2129/4096 [00:04<00:04, 454.33it/s]
Adding requests:  53%|    | 2176/4096 [00:04<00:04, 453.56it/s]
Adding requests:  54%|    | 2222/4096 [00:04<00:04, 450.47it/s]
Adding requests:  55%|    | 2269/4096 [00:04<00:04, 454.53it/s]
Adding requests:  57%|    | 2316/4096 [00:05<00:03, 456.92it/s]
Adding requests:  58%|    | 2365/4096 [00:05<00:03, 462.99it/s]
Adding requests:  59%|    | 2412/4096 [00:05<00:04, 417.64it/s]
Adding requests:  60%|    | 2458/4096 [00:05<00:03, 428.35it/s]
Adding requests:  61%|    | 2505/4096 [00:05<00:03, 438.57it/s]
Adding requests:  62%|   | 2552/4096 [00:05<00:03, 446.73it/s]
Adding requests:  63%|   | 2599/4096 [00:05<00:03, 451.07it/s]
Adding requests:  65%|   | 2647/4096 [00:05<00:03, 459.02it/s]
Adding requests:  66%|   | 2696/4096 [00:05<00:02, 467.99it/s]
Adding requests:  67%|   | 2744/4096 [00:06<00:02, 469.24it/s]
Adding requests:  68%|   | 2792/4096 [00:06<00:02, 458.49it/s]
Adding requests:  69%|   | 2838/4096 [00:06<00:02, 443.36it/s]
Adding requests:  70%|   | 2884/4096 [00:06<00:02, 445.92it/s]
Adding requests:  72%|  | 2930/4096 [00:06<00:02, 449.07it/s]
Adding requests:  73%|  | 2977/4096 [00:06<00:02, 454.61it/s]
Adding requests:  74%|  | 3023/4096 [00:06<00:02, 454.78it/s]
Adding requests:  75%|  | 3069/4096 [00:06<00:02, 454.37it/s]
Adding requests:  76%|  | 3115/4096 [00:06<00:02, 453.16it/s]
Adding requests:  77%|  | 3161/4096 [00:06<00:02, 454.74it/s]
Adding requests:  78%|  | 3208/4096 [00:07<00:01, 458.01it/s]
Adding requests:  79%|  | 3254/4096 [00:07<00:01, 458.09it/s]
Adding requests:  81%|  | 3300/4096 [00:07<00:01, 455.57it/s]
Adding requests:  82%| | 3347/4096 [00:07<00:01, 458.01it/s]
Adding requests:  83%| | 3396/4096 [00:07<00:01, 465.54it/s]
Adding requests:  84%| | 3443/4096 [00:07<00:01, 464.87it/s]
Adding requests:  85%| | 3490/4096 [00:07<00:01, 458.56it/s]
Adding requests:  86%| | 3538/4096 [00:07<00:01, 459.95it/s]
Adding requests:  88%| | 3585/4096 [00:07<00:01, 453.78it/s]
Adding requests:  89%| | 3632/4096 [00:07<00:01, 457.18it/s]
Adding requests:  90%| | 3680/4096 [00:08<00:00, 460.41it/s]
Adding requests:  91%| | 3727/4096 [00:08<00:00, 458.83it/s]
Adding requests:  92%|| 3773/4096 [00:08<00:00, 422.01it/s]
Adding requests:  93%|| 3821/4096 [00:08<00:00, 436.25it/s]
Adding requests:  95%|| 3871/4096 [00:08<00:00, 452.70it/s]
Adding requests:  96%|| 3918/4096 [00:08<00:00, 456.04it/s]
Adding requests:  97%|| 3968/4096 [00:08<00:00, 466.56it/s]
Adding requests:  98%|| 4015/4096 [00:08<00:00, 465.00it/s]
Adding requests:  99%|| 4062/4096 [00:08<00:00, 466.29it/s]
Adding requests: 100%|| 4096/4096 [00:08<00:00, 455.62it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   7%|         | 290/4096 [00:01<00:14, 270.04it/s, est. speed input: 276527.40 toks/s, output: 270.04 toks/s]
Processed prompts:   8%|         | 322/4096 [00:02<00:27, 136.50it/s, est. speed input: 161330.81 toks/s, output: 157.55 toks/s]
Processed prompts:   9%|         | 354/4096 [00:03<00:41, 90.08it/s, est. speed input: 120034.44 toks/s, output: 117.22 toks/s] 
Processed prompts:   9%|         | 386/4096 [00:03<00:54, 67.73it/s, est. speed input: 98905.55 toks/s, output: 96.59 toks/s]  
Processed prompts:  10%|         | 418/4096 [00:04<01:06, 55.14it/s, est. speed input: 86008.23 toks/s, output: 83.99 toks/s]
Processed prompts:  11%|         | 450/4096 [00:05<01:16, 47.78it/s, est. speed input: 77556.95 toks/s, output: 75.74 toks/s]
Processed prompts:  12%|        | 482/4096 [00:06<01:24, 42.96it/s, est. speed input: 71406.61 toks/s, output: 69.73 toks/s]
Processed prompts:  13%|        | 514/4096 [00:07<01:30, 39.75it/s, est. speed input: 66744.44 toks/s, output: 65.18 toks/s]
Processed prompts:  13%|        | 546/4096 [00:08<01:34, 37.50it/s, est. speed input: 63048.59 toks/s, output: 61.57 toks/s]
Processed prompts:  14%|        | 578/4096 [00:09<01:37, 36.01it/s, est. speed input: 60105.21 toks/s, output: 58.70 toks/s]
Processed prompts:  15%|        | 610/4096 [00:10<01:39, 35.03it/s, est. speed input: 57714.03 toks/s, output: 56.36 toks/s]
Processed prompts:  16%|        | 642/4096 [00:11<01:40, 34.33it/s, est. speed input: 55709.82 toks/s, output: 54.40 toks/s]
Processed prompts:  16%|        | 674/4096 [00:12<01:41, 33.86it/s, est. speed input: 54019.74 toks/s, output: 52.75 toks/s]
Processed prompts:  17%|        | 706/4096 [00:13<01:41, 33.53it/s, est. speed input: 52564.61 toks/s, output: 51.33 toks/s]
Processed prompts:  18%|        | 738/4096 [00:14<01:40, 33.27it/s, est. speed input: 51294.13 toks/s, output: 50.09 toks/s]
Processed prompts:  19%|        | 770/4096 [00:15<01:40, 33.09it/s, est. speed input: 50181.86 toks/s, output: 49.01 toks/s]
Processed prompts:  20%|        | 802/4096 [00:16<01:39, 32.97it/s, est. speed input: 49203.14 toks/s, output: 48.05 toks/s]
Processed prompts:  20%|        | 834/4096 [00:17<01:39, 32.94it/s, est. speed input: 48344.92 toks/s, output: 47.21 toks/s]
Processed prompts:  21%|        | 866/4096 [00:18<01:38, 32.86it/s, est. speed input: 47564.99 toks/s, output: 46.45 toks/s]
Processed prompts:  22%|       | 898/4096 [00:19<01:37, 32.85it/s, est. speed input: 46869.93 toks/s, output: 45.77 toks/s]
Processed prompts:  23%|       | 930/4096 [00:20<01:35, 33.11it/s, est. speed input: 46301.69 toks/s, output: 45.22 toks/s]
Processed prompts:  23%|       | 962/4096 [00:21<01:34, 33.25it/s, est. speed input: 45774.41 toks/s, output: 44.70 toks/s]
Processed prompts:  24%|       | 994/4096 [00:22<01:33, 33.10it/s, est. speed input: 45242.34 toks/s, output: 44.18 toks/s]
Processed prompts:  25%|       | 1026/4096 [00:23<01:33, 32.98it/s, est. speed input: 44752.29 toks/s, output: 43.70 toks/s]
Processed prompts:  26%|       | 1058/4096 [00:24<01:32, 32.89it/s, est. speed input: 44300.78 toks/s, output: 43.26 toks/s]
Processed prompts:  27%|       | 1090/4096 [00:25<01:31, 32.82it/s, est. speed input: 43882.37 toks/s, output: 42.85 toks/s]
Processed prompts:  27%|       | 1122/4096 [00:26<01:30, 32.77it/s, est. speed input: 43495.66 toks/s, output: 42.48 toks/s]
Processed prompts:  28%|       | 1154/4096 [00:27<01:28, 33.10it/s, est. speed input: 43192.10 toks/s, output: 42.18 toks/s]
Processed prompts:  29%|       | 1186/4096 [00:28<01:28, 32.96it/s, est. speed input: 42853.55 toks/s, output: 41.85 toks/s]
Processed prompts:  30%|       | 1218/4096 [00:29<01:27, 32.88it/s, est. speed input: 42540.86 toks/s, output: 41.54 toks/s]
Processed prompts:  31%|       | 1250/4096 [00:30<01:25, 33.13it/s, est. speed input: 42290.41 toks/s, output: 41.30 toks/s]
Processed prompts:  31%|      | 1282/4096 [00:31<01:24, 33.30it/s, est. speed input: 42053.14 toks/s, output: 41.07 toks/s]
Processed prompts:  32%|      | 1314/4096 [00:32<01:24, 33.11it/s, est. speed input: 41792.44 toks/s, output: 40.81 toks/s]
Processed prompts:  33%|      | 1346/4096 [00:33<01:23, 32.99it/s, est. speed input: 41547.67 toks/s, output: 40.57 toks/s]
Processed prompts:  34%|      | 1378/4096 [00:34<01:22, 32.90it/s, est. speed input: 41315.99 toks/s, output: 40.35 toks/s]
Processed prompts:  34%|      | 1410/4096 [00:35<01:21, 32.83it/s, est. speed input: 41097.16 toks/s, output: 40.13 toks/s]
Processed prompts:  35%|      | 1442/4096 [00:36<01:20, 32.78it/s, est. speed input: 40888.98 toks/s, output: 39.93 toks/s]
Processed prompts:  36%|      | 1474/4096 [00:37<01:19, 32.78it/s, est. speed input: 40696.12 toks/s, output: 39.74 toks/s]
Processed prompts:  37%|      | 1506/4096 [00:38<01:19, 32.73it/s, est. speed input: 40508.02 toks/s, output: 39.56 toks/s]
Processed prompts:  38%|      | 1538/4096 [00:39<01:18, 32.72it/s, est. speed input: 40332.12 toks/s, output: 39.39 toks/s]
Processed prompts:  38%|      | 1570/4096 [00:39<01:16, 33.04it/s, est. speed input: 40196.63 toks/s, output: 39.25 toks/s]
Processed prompts:  39%|      | 1602/4096 [00:40<01:15, 32.95it/s, est. speed input: 40038.14 toks/s, output: 39.10 toks/s]
Processed prompts:  40%|      | 1634/4096 [00:41<01:14, 33.15it/s, est. speed input: 39910.46 toks/s, output: 38.98 toks/s]
Processed prompts:  41%|      | 1666/4096 [00:42<01:13, 33.05it/s, est. speed input: 39767.24 toks/s, output: 38.84 toks/s]
Processed prompts:  41%|     | 1698/4096 [00:43<01:12, 32.94it/s, est. speed input: 39626.96 toks/s, output: 38.70 toks/s]
Processed prompts:  42%|     | 1730/4096 [00:44<01:11, 32.86it/s, est. speed input: 39492.48 toks/s, output: 38.57 toks/s]
Processed prompts:  43%|     | 1762/4096 [00:45<01:11, 32.79it/s, est. speed input: 39362.07 toks/s, output: 38.44 toks/s]
Processed prompts:  44%|     | 1794/4096 [00:46<01:10, 32.80it/s, est. speed input: 39242.38 toks/s, output: 38.32 toks/s]
Processed prompts:  45%|     | 1826/4096 [00:47<01:09, 32.79it/s, est. speed input: 39126.34 toks/s, output: 38.21 toks/s]
Processed prompts:  45%|     | 1858/4096 [00:48<01:07, 33.04it/s, est. speed input: 39034.99 toks/s, output: 38.12 toks/s]
Processed prompts:  46%|     | 1890/4096 [00:49<01:06, 32.94it/s, est. speed input: 38925.46 toks/s, output: 38.01 toks/s]
Processed prompts:  47%|     | 1922/4096 [00:50<01:06, 32.87it/s, est. speed input: 38821.10 toks/s, output: 37.91 toks/s]
Processed prompts:  48%|     | 1954/4096 [00:51<01:04, 33.12it/s, est. speed input: 38741.89 toks/s, output: 37.83 toks/s]
Processed prompts:  48%|     | 1986/4096 [00:52<01:02, 33.78it/s, est. speed input: 38699.53 toks/s, output: 37.79 toks/s]
Processed prompts:  49%|     | 2018/4096 [00:53<01:02, 33.44it/s, est. speed input: 38603.87 toks/s, output: 37.70 toks/s]
Processed prompts:  50%|     | 2050/4096 [00:54<01:00, 33.64it/s, est. speed input: 38540.38 toks/s, output: 37.64 toks/s]
Processed prompts:  51%|     | 2082/4096 [00:55<00:59, 33.73it/s, est. speed input: 38476.39 toks/s, output: 37.57 toks/s]
Processed prompts:  52%|    | 2114/4096 [00:56<00:59, 33.37it/s, est. speed input: 38386.95 toks/s, output: 37.49 toks/s]
Processed prompts:  52%|    | 2146/4096 [00:57<00:58, 33.15it/s, est. speed input: 38302.23 toks/s, output: 37.40 toks/s]
Processed prompts:  53%|    | 2178/4096 [00:58<00:57, 33.60it/s, est. speed input: 38258.24 toks/s, output: 37.36 toks/s]
Processed prompts:  54%|    | 2210/4096 [00:59<00:55, 33.91it/s, est. speed input: 38214.95 toks/s, output: 37.32 toks/s]
Processed prompts:  55%|    | 2242/4096 [01:00<00:55, 33.52it/s, est. speed input: 38137.02 toks/s, output: 37.24 toks/s]
Processed prompts:  56%|    | 2274/4096 [01:01<00:54, 33.60it/s, est. speed input: 38082.04 toks/s, output: 37.19 toks/s]
Processed prompts:  56%|    | 2306/4096 [01:02<00:53, 33.57it/s, est. speed input: 38024.37 toks/s, output: 37.13 toks/s]
Processed prompts:  57%|    | 2338/4096 [01:03<00:52, 33.59it/s, est. speed input: 37970.11 toks/s, output: 37.08 toks/s]
Processed prompts:  58%|    | 2370/4096 [01:03<00:50, 34.28it/s, est. speed input: 37954.97 toks/s, output: 37.07 toks/s]
Processed prompts:  59%|    | 2402/4096 [01:04<00:49, 34.13it/s, est. speed input: 37905.73 toks/s, output: 37.02 toks/s]
Processed prompts:  59%|    | 2434/4096 [01:05<00:48, 33.99it/s, est. speed input: 37856.20 toks/s, output: 36.97 toks/s]
Processed prompts:  60%|    | 2466/4096 [01:06<00:48, 33.85it/s, est. speed input: 37806.01 toks/s, output: 36.92 toks/s]
Processed prompts:  61%|    | 2498/4096 [01:07<00:47, 33.79it/s, est. speed input: 37758.79 toks/s, output: 36.87 toks/s]
Processed prompts:  62%|   | 2530/4096 [01:08<00:46, 33.42it/s, est. speed input: 37696.18 toks/s, output: 36.81 toks/s]
Processed prompts:  63%|   | 2562/4096 [01:09<00:45, 33.54it/s, est. speed input: 37654.81 toks/s, output: 36.77 toks/s]
Processed prompts:  63%|   | 2594/4096 [01:10<00:44, 33.60it/s, est. speed input: 37613.03 toks/s, output: 36.73 toks/s]
Processed prompts:  64%|   | 2626/4096 [01:11<00:44, 33.34it/s, est. speed input: 37557.24 toks/s, output: 36.68 toks/s]
Processed prompts:  65%|   | 2658/4096 [01:12<00:43, 33.18it/s, est. speed input: 37504.19 toks/s, output: 36.63 toks/s]
Processed prompts:  66%|   | 2690/4096 [01:13<00:41, 33.61it/s, est. speed input: 37479.00 toks/s, output: 36.60 toks/s]
Processed prompts:  66%|   | 2722/4096 [01:14<00:41, 33.33it/s, est. speed input: 37426.20 toks/s, output: 36.55 toks/s]
Processed prompts:  67%|   | 2754/4096 [01:15<00:40, 33.39it/s, est. speed input: 37387.33 toks/s, output: 36.51 toks/s]
Processed prompts:  68%|   | 2786/4096 [01:16<00:39, 33.21it/s, est. speed input: 37338.51 toks/s, output: 36.46 toks/s]
Processed prompts:  69%|   | 2818/4096 [01:17<00:38, 33.60it/s, est. speed input: 37314.98 toks/s, output: 36.44 toks/s]
Processed prompts:  70%|   | 2850/4096 [01:18<00:37, 33.59it/s, est. speed input: 37279.25 toks/s, output: 36.41 toks/s]
Processed prompts:  70%|   | 2882/4096 [01:19<00:36, 33.33it/s, est. speed input: 37232.93 toks/s, output: 36.36 toks/s]
Processed prompts:  71%|   | 2914/4096 [01:20<00:35, 33.17it/s, est. speed input: 37188.43 toks/s, output: 36.32 toks/s]
Processed prompts:  72%|  | 2946/4096 [01:21<00:34, 33.35it/s, est. speed input: 37158.35 toks/s, output: 36.29 toks/s]
Processed prompts:  73%|  | 2978/4096 [01:22<00:33, 33.14it/s, est. speed input: 37113.87 toks/s, output: 36.24 toks/s]
Processed prompts:  73%|  | 3010/4096 [01:23<00:32, 33.59it/s, est. speed input: 37096.25 toks/s, output: 36.23 toks/s]
Processed prompts:  74%|  | 3042/4096 [01:24<00:31, 33.62it/s, est. speed input: 37066.74 toks/s, output: 36.20 toks/s]
Processed prompts:  75%|  | 3074/4096 [01:25<00:30, 33.33it/s, est. speed input: 37025.09 toks/s, output: 36.16 toks/s]
Processed prompts:  76%|  | 3106/4096 [01:25<00:29, 34.06it/s, est. speed input: 37022.61 toks/s, output: 36.15 toks/s]
Processed prompts:  77%|  | 3138/4096 [01:26<00:27, 34.23it/s, est. speed input: 37005.86 toks/s, output: 36.14 toks/s]
Processed prompts:  77%|  | 3170/4096 [01:27<00:27, 33.73it/s, est. speed input: 36965.68 toks/s, output: 36.10 toks/s]
Processed prompts:  78%|  | 3202/4096 [01:28<00:26, 34.00it/s, est. speed input: 36950.16 toks/s, output: 36.08 toks/s]
Processed prompts:  79%|  | 3234/4096 [01:29<00:25, 33.88it/s, est. speed input: 36923.21 toks/s, output: 36.06 toks/s]
Processed prompts:  80%|  | 3266/4096 [01:30<00:24, 33.52it/s, est. speed input: 36886.03 toks/s, output: 36.02 toks/s]
Processed prompts:  81%|  | 3298/4096 [01:31<00:23, 33.53it/s, est. speed input: 36859.82 toks/s, output: 36.00 toks/s]
Processed prompts:  81%| | 3330/4096 [01:32<00:22, 33.85it/s, est. speed input: 36845.73 toks/s, output: 35.98 toks/s]
Processed prompts:  82%| | 3362/4096 [01:33<00:21, 33.50it/s, est. speed input: 36810.67 toks/s, output: 35.95 toks/s]
Processed prompts:  83%| | 3394/4096 [01:34<00:21, 33.24it/s, est. speed input: 36775.74 toks/s, output: 35.91 toks/s]
Processed prompts:  84%| | 3426/4096 [01:35<00:20, 33.35it/s, est. speed input: 36751.98 toks/s, output: 35.89 toks/s]
Processed prompts:  84%| | 3458/4096 [01:36<00:19, 33.46it/s, est. speed input: 36730.26 toks/s, output: 35.87 toks/s]
Processed prompts:  85%| | 3490/4096 [01:37<00:17, 33.89it/s, est. speed input: 36721.26 toks/s, output: 35.86 toks/s]
Processed prompts:  86%| | 3522/4096 [01:38<00:17, 33.54it/s, est. speed input: 36689.53 toks/s, output: 35.83 toks/s]
Processed prompts:  87%| | 3554/4096 [01:39<00:16, 33.26it/s, est. speed input: 36657.08 toks/s, output: 35.80 toks/s]
Processed prompts:  88%| | 3586/4096 [01:40<00:15, 33.07it/s, est. speed input: 36625.62 toks/s, output: 35.77 toks/s]
Processed prompts:  88%| | 3618/4096 [01:41<00:14, 32.92it/s, est. speed input: 36593.73 toks/s, output: 35.74 toks/s]
Processed prompts:  89%| | 3650/4096 [01:42<00:13, 33.15it/s, est. speed input: 36574.39 toks/s, output: 35.72 toks/s]
Processed prompts:  90%| | 3682/4096 [01:43<00:12, 33.27it/s, est. speed input: 36553.94 toks/s, output: 35.70 toks/s]
Processed prompts:  91%| | 3714/4096 [01:44<00:11, 33.38it/s, est. speed input: 36534.65 toks/s, output: 35.68 toks/s]
Processed prompts:  91%|| 3746/4096 [01:45<00:10, 33.15it/s, est. speed input: 36505.42 toks/s, output: 35.65 toks/s]
Processed prompts:  92%|| 3778/4096 [01:46<00:09, 33.06it/s, est. speed input: 36479.26 toks/s, output: 35.62 toks/s]
Processed prompts:  93%|| 3810/4096 [01:47<00:08, 33.23it/s, est. speed input: 36460.98 toks/s, output: 35.61 toks/s]
Processed prompts:  94%|| 3842/4096 [01:47<00:07, 33.63it/s, est. speed input: 36452.23 toks/s, output: 35.60 toks/s]
Processed prompts:  95%|| 3874/4096 [01:48<00:06, 33.30it/s, est. speed input: 36424.15 toks/s, output: 35.57 toks/s]
Processed prompts:  95%|| 3906/4096 [01:49<00:05, 33.10it/s, est. speed input: 36397.34 toks/s, output: 35.54 toks/s]
Processed prompts:  96%|| 3938/4096 [01:50<00:04, 33.27it/s, est. speed input: 36380.94 toks/s, output: 35.53 toks/s]
Processed prompts:  97%|| 3970/4096 [01:51<00:03, 33.10it/s, est. speed input: 36355.58 toks/s, output: 35.50 toks/s]
Processed prompts:  98%|| 4002/4096 [01:52<00:02, 32.93it/s, est. speed input: 36329.24 toks/s, output: 35.48 toks/s]
Processed prompts:  98%|| 4034/4096 [01:53<00:01, 33.76it/s, est. speed input: 36332.22 toks/s, output: 35.48 toks/s]
Processed prompts:  99%|| 4066/4096 [01:54<00:00, 33.65it/s, est. speed input: 36314.33 toks/s, output: 35.46 toks/s]
Processed prompts: 100%|| 4096/4096 [01:54<00:00, 33.65it/s, est. speed input: 36582.11 toks/s, output: 35.72 toks/s]
Processed prompts: 100%|| 4096/4096 [01:54<00:00, 35.72it/s, est. speed input: 36582.11 toks/s, output: 35.72 toks/s]
[rank0]:[W126 08:09:18.545569167 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-26 08:09:20
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Llama3.2-1B-FP8_M65536.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:09:47 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 08:09:47 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1057695) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1057695) WARNING 01-26 08:10:09 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 33.48 requests/s, 34319.78 total tokens/s, 33.48 output tokens/s
Total num prompt tokens:  8388608
Total num output tokens:  8192

STDERR:
[2026-01-26 08:09:47] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:09:47] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:09:47] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:09:47] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:09:47] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:09:47] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:09:47] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:09:47] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:09:47] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:09:47] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:09:47] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:09:47] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:09:47] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:09:47] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:09:50] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:09:50] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:09:50] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:09:50] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:09:50] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:09:50] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:09:50] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:09:50] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:09:50] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:09:50] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:09:50] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:09:50] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:09:50] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:09:50] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1057695) [2026-01-26 08:09:51] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1057695) [2026-01-26 08:09:51] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1057695) [2026-01-26 08:09:51] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1057695) [2026-01-26 08:09:51] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1057695) [2026-01-26 08:09:51] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1057695) [2026-01-26 08:09:51] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1057695) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1057695) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.19s/it]
(EngineCore_DP0 pid=1057695) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:08<00:00,  8.19s/it]
(EngineCore_DP0 pid=1057695) 
(EngineCore_DP0 pid=1057695) [2026-01-26 08:10:00] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=1057695) [2026-01-26 08:10:00] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=1057695) [2026-01-26 08:10:00] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=1057695) [2026-01-26 08:10:00] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 2621440 bytes
(EngineCore_DP0 pid=1057695) [2026-01-26 08:10:00] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=1057695) [2026-01-26 08:10:00] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 20971520 bytes
(EngineCore_DP0 pid=1057695) [2026-01-26 08:10:00] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=1057695) [2026-01-26 08:10:00] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10485760 bytes
(EngineCore_DP0 pid=1057695) 2026-01-26 08:10:07,271 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1057695) 2026-01-26 08:10:07,515 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/8192 [00:00<?, ?it/s]
Adding requests:   1%|          | 59/8192 [00:00<00:13, 581.20it/s]
Adding requests:   1%|         | 118/8192 [00:00<00:14, 541.97it/s]
Adding requests:   2%|         | 173/8192 [00:00<00:16, 487.08it/s]
Adding requests:   3%|         | 223/8192 [00:00<00:17, 458.62it/s]
Adding requests:   3%|         | 270/8192 [00:00<00:17, 460.49it/s]
Adding requests:   4%|         | 317/8192 [00:00<00:17, 450.09it/s]
Adding requests:   4%|         | 363/8192 [00:00<00:17, 453.02it/s]
Adding requests:   5%|         | 409/8192 [00:00<00:17, 446.15it/s]
Adding requests:   6%|         | 455/8192 [00:00<00:17, 447.87it/s]
Adding requests:   6%|         | 500/8192 [00:01<00:17, 447.34it/s]
Adding requests:   7%|         | 545/8192 [00:01<00:17, 440.62it/s]
Adding requests:   7%|         | 592/8192 [00:01<00:16, 448.15it/s]
Adding requests:   8%|         | 637/8192 [00:01<00:16, 448.54it/s]
Adding requests:   8%|         | 685/8192 [00:01<00:16, 455.53it/s]
Adding requests:   9%|         | 733/8192 [00:01<00:16, 461.92it/s]
Adding requests:  10%|         | 780/8192 [00:01<00:16, 452.44it/s]
Adding requests:  10%|         | 826/8192 [00:01<00:17, 417.59it/s]
Adding requests:  11%|         | 874/8192 [00:01<00:16, 432.92it/s]
Adding requests:  11%|        | 923/8192 [00:02<00:16, 446.24it/s]
Adding requests:  12%|        | 969/8192 [00:02<00:16, 439.62it/s]
Adding requests:  12%|        | 1014/8192 [00:02<00:16, 432.78it/s]
Adding requests:  13%|        | 1060/8192 [00:02<00:16, 439.25it/s]
Adding requests:  13%|        | 1105/8192 [00:02<00:16, 439.29it/s]
Adding requests:  14%|        | 1151/8192 [00:02<00:15, 443.68it/s]
Adding requests:  15%|        | 1199/8192 [00:02<00:15, 451.72it/s]
Adding requests:  15%|        | 1246/8192 [00:02<00:15, 455.75it/s]
Adding requests:  16%|        | 1292/8192 [00:02<00:15, 448.07it/s]
Adding requests:  16%|        | 1341/8192 [00:02<00:14, 459.27it/s]
Adding requests:  17%|        | 1387/8192 [00:03<00:15, 453.58it/s]
Adding requests:  18%|        | 1434/8192 [00:03<00:14, 456.62it/s]
Adding requests:  18%|        | 1480/8192 [00:03<00:15, 433.60it/s]
Adding requests:  19%|        | 1525/8192 [00:03<00:15, 436.09it/s]
Adding requests:  19%|        | 1572/8192 [00:03<00:14, 444.87it/s]
Adding requests:  20%|        | 1617/8192 [00:03<00:14, 445.68it/s]
Adding requests:  20%|        | 1663/8192 [00:03<00:14, 448.71it/s]
Adding requests:  21%|        | 1709/8192 [00:03<00:14, 450.77it/s]
Adding requests:  21%|       | 1758/8192 [00:03<00:14, 458.75it/s]
Adding requests:  22%|       | 1804/8192 [00:04<00:14, 452.96it/s]
Adding requests:  23%|       | 1850/8192 [00:04<00:14, 450.64it/s]
Adding requests:  23%|       | 1896/8192 [00:04<00:14, 448.51it/s]
Adding requests:  24%|       | 1943/8192 [00:04<00:13, 452.33it/s]
Adding requests:  24%|       | 1989/8192 [00:04<00:15, 397.11it/s]
Adding requests:  25%|       | 2036/8192 [00:04<00:14, 415.61it/s]
Adding requests:  25%|       | 2082/8192 [00:04<00:14, 426.46it/s]
Adding requests:  26%|       | 2127/8192 [00:04<00:14, 431.63it/s]
Adding requests:  27%|       | 2172/8192 [00:04<00:13, 435.75it/s]
Adding requests:  27%|       | 2218/8192 [00:04<00:13, 439.94it/s]
Adding requests:  28%|       | 2267/8192 [00:05<00:13, 454.01it/s]
Adding requests:  28%|       | 2313/8192 [00:05<00:13, 451.15it/s]
Adding requests:  29%|       | 2359/8192 [00:05<00:13, 444.61it/s]
Adding requests:  29%|       | 2404/8192 [00:05<00:13, 438.98it/s]
Adding requests:  30%|       | 2449/8192 [00:05<00:13, 434.83it/s]
Adding requests:  30%|       | 2493/8192 [00:05<00:13, 428.33it/s]
Adding requests:  31%|       | 2536/8192 [00:05<00:13, 424.42it/s]
Adding requests:  32%|      | 2581/8192 [00:05<00:13, 427.95it/s]
Adding requests:  32%|      | 2627/8192 [00:05<00:12, 433.88it/s]
Adding requests:  33%|      | 2671/8192 [00:06<00:12, 430.69it/s]
Adding requests:  33%|      | 2715/8192 [00:06<00:12, 423.95it/s]
Adding requests:  34%|      | 2758/8192 [00:06<00:12, 419.93it/s]
Adding requests:  34%|      | 2801/8192 [00:06<00:12, 421.23it/s]
Adding requests:  35%|      | 2846/8192 [00:06<00:12, 427.03it/s]
Adding requests:  35%|      | 2889/8192 [00:06<00:12, 421.93it/s]
Adding requests:  36%|      | 2932/8192 [00:06<00:12, 407.99it/s]
Adding requests:  36%|      | 2973/8192 [00:06<00:12, 406.87it/s]
Adding requests:  37%|      | 3014/8192 [00:06<00:12, 403.97it/s]
Adding requests:  37%|      | 3057/8192 [00:06<00:12, 408.80it/s]
Adding requests:  38%|      | 3098/8192 [00:07<00:12, 405.76it/s]
Adding requests:  38%|      | 3142/8192 [00:07<00:12, 414.18it/s]
Adding requests:  39%|      | 3188/8192 [00:07<00:11, 425.22it/s]
Adding requests:  39%|      | 3232/8192 [00:07<00:11, 427.50it/s]
Adding requests:  40%|      | 3275/8192 [00:07<00:11, 425.09it/s]
Adding requests:  41%|      | 3318/8192 [00:07<00:12, 400.97it/s]
Adding requests:  41%|      | 3362/8192 [00:07<00:11, 410.11it/s]
Adding requests:  42%|     | 3407/8192 [00:07<00:11, 421.45it/s]
Adding requests:  42%|     | 3452/8192 [00:07<00:11, 426.96it/s]
Adding requests:  43%|     | 3496/8192 [00:07<00:10, 429.03it/s]
Adding requests:  43%|     | 3541/8192 [00:08<00:10, 433.46it/s]
Adding requests:  44%|     | 3585/8192 [00:08<00:10, 430.35it/s]
Adding requests:  44%|     | 3630/8192 [00:08<00:10, 435.44it/s]
Adding requests:  45%|     | 3678/8192 [00:08<00:10, 448.05it/s]
Adding requests:  45%|     | 3724/8192 [00:08<00:09, 450.81it/s]
Adding requests:  46%|     | 3773/8192 [00:08<00:09, 460.09it/s]
Adding requests:  47%|     | 3820/8192 [00:08<00:09, 458.69it/s]
Adding requests:  47%|     | 3866/8192 [00:08<00:09, 457.83it/s]
Adding requests:  48%|     | 3912/8192 [00:08<00:09, 453.13it/s]
Adding requests:  48%|     | 3960/8192 [00:09<00:09, 458.15it/s]
Adding requests:  49%|     | 4006/8192 [00:09<00:09, 457.56it/s]
Adding requests:  49%|     | 4053/8192 [00:09<00:09, 458.51it/s]
Adding requests:  50%|     | 4103/8192 [00:09<00:08, 467.62it/s]
Adding requests:  51%|     | 4150/8192 [00:09<00:08, 463.42it/s]
Adding requests:  51%|     | 4197/8192 [00:09<00:08, 464.64it/s]
Adding requests:  52%|    | 4244/8192 [00:09<00:08, 457.18it/s]
Adding requests:  52%|    | 4291/8192 [00:09<00:08, 459.68it/s]
Adding requests:  53%|    | 4340/8192 [00:09<00:08, 468.44it/s]
Adding requests:  54%|    | 4388/8192 [00:09<00:08, 469.29it/s]
Adding requests:  54%|    | 4435/8192 [00:10<00:08, 460.45it/s]
Adding requests:  55%|    | 4482/8192 [00:10<00:08, 447.07it/s]
Adding requests:  55%|    | 4528/8192 [00:10<00:08, 448.69it/s]
Adding requests:  56%|    | 4574/8192 [00:10<00:08, 449.89it/s]
Adding requests:  56%|    | 4621/8192 [00:10<00:07, 455.07it/s]
Adding requests:  57%|    | 4667/8192 [00:10<00:08, 430.67it/s]
Adding requests:  58%|    | 4711/8192 [00:10<00:08, 426.67it/s]
Adding requests:  58%|    | 4759/8192 [00:10<00:07, 441.05it/s]
Adding requests:  59%|    | 4804/8192 [00:10<00:07, 438.58it/s]
Adding requests:  59%|    | 4851/8192 [00:10<00:07, 446.18it/s]
Adding requests:  60%|    | 4897/8192 [00:11<00:07, 449.60it/s]
Adding requests:  60%|    | 4943/8192 [00:11<00:07, 452.48it/s]
Adding requests:  61%|    | 4989/8192 [00:11<00:07, 452.84it/s]
Adding requests:  61%|   | 5035/8192 [00:11<00:06, 453.44it/s]
Adding requests:  62%|   | 5087/8192 [00:11<00:06, 470.15it/s]
Adding requests:  63%|   | 5135/8192 [00:11<00:06, 469.00it/s]
Adding requests:  63%|   | 5183/8192 [00:11<00:06, 469.95it/s]
Adding requests:  64%|   | 5231/8192 [00:11<00:06, 471.10it/s]
Adding requests:  64%|   | 5279/8192 [00:11<00:06, 448.84it/s]
Adding requests:  65%|   | 5328/8192 [00:12<00:06, 460.17it/s]
Adding requests:  66%|   | 5376/8192 [00:12<00:06, 462.13it/s]
Adding requests:  66%|   | 5427/8192 [00:12<00:05, 474.63it/s]
Adding requests:  67%|   | 5475/8192 [00:12<00:05, 467.53it/s]
Adding requests:  67%|   | 5522/8192 [00:12<00:05, 461.17it/s]
Adding requests:  68%|   | 5569/8192 [00:12<00:05, 458.79it/s]
Adding requests:  69%|   | 5615/8192 [00:12<00:05, 456.68it/s]
Adding requests:  69%|   | 5661/8192 [00:12<00:05, 455.65it/s]
Adding requests:  70%|   | 5708/8192 [00:12<00:05, 459.25it/s]
Adding requests:  70%|   | 5755/8192 [00:12<00:05, 461.75it/s]
Adding requests:  71%|   | 5802/8192 [00:13<00:05, 457.26it/s]
Adding requests:  71%|  | 5848/8192 [00:13<00:05, 454.91it/s]
Adding requests:  72%|  | 5897/8192 [00:13<00:04, 465.13it/s]
Adding requests:  73%|  | 5944/8192 [00:13<00:04, 461.26it/s]
Adding requests:  73%|  | 5994/8192 [00:13<00:04, 470.74it/s]
Adding requests:  74%|  | 6042/8192 [00:13<00:05, 420.87it/s]
Adding requests:  74%|  | 6086/8192 [00:13<00:05, 410.20it/s]
Adding requests:  75%|  | 6136/8192 [00:13<00:04, 433.84it/s]
Adding requests:  75%|  | 6181/8192 [00:13<00:04, 436.91it/s]
Adding requests:  76%|  | 6232/8192 [00:14<00:04, 457.01it/s]
Adding requests:  77%|  | 6279/8192 [00:14<00:04, 449.56it/s]
Adding requests:  77%|  | 6329/8192 [00:14<00:04, 462.76it/s]
Adding requests:  78%|  | 6376/8192 [00:14<00:03, 458.05it/s]
Adding requests:  78%|  | 6427/8192 [00:14<00:03, 471.82it/s]
Adding requests:  79%|  | 6477/8192 [00:14<00:03, 480.02it/s]
Adding requests:  80%|  | 6526/8192 [00:14<00:03, 476.95it/s]
Adding requests:  80%|  | 6575/8192 [00:14<00:03, 479.34it/s]
Adding requests:  81%|  | 6624/8192 [00:14<00:03, 469.28it/s]
Adding requests:  81%| | 6674/8192 [00:14<00:03, 476.63it/s]
Adding requests:  82%| | 6722/8192 [00:15<00:03, 467.81it/s]
Adding requests:  83%| | 6771/8192 [00:15<00:03, 471.57it/s]
Adding requests:  83%| | 6821/8192 [00:15<00:02, 476.87it/s]
Adding requests:  84%| | 6870/8192 [00:15<00:02, 479.75it/s]
Adding requests:  84%| | 6919/8192 [00:15<00:02, 478.83it/s]
Adding requests:  85%| | 6967/8192 [00:15<00:02, 478.66it/s]
Adding requests:  86%| | 7015/8192 [00:15<00:02, 474.28it/s]
Adding requests:  86%| | 7063/8192 [00:15<00:02, 453.16it/s]
Adding requests:  87%| | 7112/8192 [00:15<00:02, 462.98it/s]
Adding requests:  87%| | 7162/8192 [00:15<00:02, 470.56it/s]
Adding requests:  88%| | 7210/8192 [00:16<00:02, 471.04it/s]
Adding requests:  89%| | 7260/8192 [00:16<00:01, 477.76it/s]
Adding requests:  89%| | 7308/8192 [00:16<00:01, 469.07it/s]
Adding requests:  90%| | 7358/8192 [00:16<00:01, 476.07it/s]
Adding requests:  90%| | 7406/8192 [00:16<00:01, 428.46it/s]
Adding requests:  91%| | 7457/8192 [00:16<00:01, 448.97it/s]
Adding requests:  92%|| 7506/8192 [00:16<00:01, 459.51it/s]
Adding requests:  92%|| 7553/8192 [00:16<00:01, 452.97it/s]
Adding requests:  93%|| 7601/8192 [00:16<00:01, 459.83it/s]
Adding requests:  93%|| 7648/8192 [00:17<00:01, 459.32it/s]
Adding requests:  94%|| 7698/8192 [00:17<00:01, 470.90it/s]
Adding requests:  95%|| 7746/8192 [00:17<00:00, 466.22it/s]
Adding requests:  95%|| 7793/8192 [00:17<00:00, 466.84it/s]
Adding requests:  96%|| 7840/8192 [00:17<00:00, 466.77it/s]
Adding requests:  96%|| 7887/8192 [00:17<00:00, 463.91it/s]
Adding requests:  97%|| 7934/8192 [00:17<00:00, 463.18it/s]
Adding requests:  97%|| 7981/8192 [00:17<00:00, 454.25it/s]
Adding requests:  98%|| 8027/8192 [00:17<00:00, 455.55it/s]
Adding requests:  99%|| 8076/8192 [00:17<00:00, 462.70it/s]
Adding requests:  99%|| 8126/8192 [00:18<00:00, 472.70it/s]
Adding requests: 100%|| 8177/8192 [00:18<00:00, 480.84it/s]
Adding requests: 100%|| 8192/8192 [00:18<00:00, 450.18it/s]

Processed prompts:   0%|          | 0/8192 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   7%|         | 578/8192 [00:01<00:17, 426.16it/s, est. speed input: 436407.52 toks/s, output: 426.17 toks/s]
Processed prompts:   8%|         | 642/8192 [00:03<00:46, 162.53it/s, est. speed input: 199826.12 toks/s, output: 195.14 toks/s]
Processed prompts:   9%|         | 706/8192 [00:05<01:15, 99.29it/s, est. speed input: 138498.19 toks/s, output: 135.25 toks/s] 
Processed prompts:   9%|         | 770/8192 [00:07<01:43, 72.00it/s, est. speed input: 110182.50 toks/s, output: 107.60 toks/s]
Processed prompts:  10%|         | 834/8192 [00:09<02:07, 57.53it/s, est. speed input: 93888.90 toks/s, output: 91.69 toks/s]  
Processed prompts:  11%|         | 898/8192 [00:11<02:28, 49.20it/s, est. speed input: 83465.88 toks/s, output: 81.51 toks/s]
Processed prompts:  12%|        | 962/8192 [00:12<02:44, 44.00it/s, est. speed input: 76170.17 toks/s, output: 74.38 toks/s]
Processed prompts:  13%|        | 1026/8192 [00:14<02:56, 40.50it/s, est. speed input: 70676.51 toks/s, output: 69.02 toks/s]
Processed prompts:  13%|        | 1090/8192 [00:16<03:06, 38.09it/s, est. speed input: 66391.85 toks/s, output: 64.84 toks/s]
Processed prompts:  14%|        | 1154/8192 [00:18<03:11, 36.66it/s, est. speed input: 63104.52 toks/s, output: 61.63 toks/s]
Processed prompts:  15%|        | 1218/8192 [00:20<03:15, 35.67it/s, est. speed input: 60424.00 toks/s, output: 59.01 toks/s]
Processed prompts:  16%|        | 1282/8192 [00:22<03:17, 35.00it/s, est. speed input: 58205.65 toks/s, output: 56.84 toks/s]
Processed prompts:  16%|        | 1346/8192 [00:24<03:19, 34.40it/s, est. speed input: 56276.45 toks/s, output: 54.96 toks/s]
Processed prompts:  17%|        | 1410/8192 [00:26<03:19, 33.96it/s, est. speed input: 54623.34 toks/s, output: 53.34 toks/s]
Processed prompts:  18%|        | 1474/8192 [00:28<03:19, 33.66it/s, est. speed input: 53194.09 toks/s, output: 51.95 toks/s]
Processed prompts:  19%|        | 1538/8192 [00:30<03:18, 33.57it/s, est. speed input: 51989.81 toks/s, output: 50.77 toks/s]
Processed prompts:  20%|        | 1602/8192 [00:32<03:16, 33.52it/s, est. speed input: 50932.23 toks/s, output: 49.74 toks/s]
Processed prompts:  20%|        | 1666/8192 [00:34<03:15, 33.34it/s, est. speed input: 49952.47 toks/s, output: 48.78 toks/s]
Processed prompts:  21%|        | 1730/8192 [00:36<03:14, 33.22it/s, est. speed input: 49079.92 toks/s, output: 47.93 toks/s]
Processed prompts:  22%|       | 1794/8192 [00:38<03:13, 33.13it/s, est. speed input: 48294.29 toks/s, output: 47.16 toks/s]
Processed prompts:  23%|       | 1858/8192 [00:39<03:10, 33.25it/s, est. speed input: 47627.90 toks/s, output: 46.51 toks/s]
Processed prompts:  23%|       | 1922/8192 [00:41<03:08, 33.30it/s, est. speed input: 47013.27 toks/s, output: 45.91 toks/s]
Processed prompts:  24%|       | 1986/8192 [00:43<03:04, 33.56it/s, est. speed input: 46498.98 toks/s, output: 45.41 toks/s]
Processed prompts:  25%|       | 2050/8192 [00:45<03:01, 33.76it/s, est. speed input: 46029.97 toks/s, output: 44.95 toks/s]
Processed prompts:  26%|       | 2114/8192 [00:47<03:01, 33.54it/s, est. speed input: 45533.31 toks/s, output: 44.47 toks/s]
Processed prompts:  27%|       | 2178/8192 [00:49<02:57, 33.86it/s, est. speed input: 45156.55 toks/s, output: 44.10 toks/s]
Processed prompts:  27%|       | 2242/8192 [00:51<02:56, 33.71it/s, est. speed input: 44746.06 toks/s, output: 43.70 toks/s]
Processed prompts:  28%|       | 2306/8192 [00:53<02:54, 33.66it/s, est. speed input: 44372.63 toks/s, output: 43.33 toks/s]
Processed prompts:  29%|       | 2370/8192 [00:55<02:50, 34.06it/s, est. speed input: 44090.81 toks/s, output: 43.06 toks/s]
Processed prompts:  30%|       | 2434/8192 [00:56<02:49, 33.98it/s, est. speed input: 43774.97 toks/s, output: 42.75 toks/s]
Processed prompts:  30%|       | 2498/8192 [00:58<02:48, 33.79it/s, est. speed input: 43461.82 toks/s, output: 42.44 toks/s]
Processed prompts:  31%|      | 2562/8192 [01:00<02:46, 33.81it/s, est. speed input: 43187.78 toks/s, output: 42.18 toks/s]
Processed prompts:  32%|      | 2626/8192 [01:02<02:45, 33.59it/s, est. speed input: 42901.37 toks/s, output: 41.90 toks/s]
Processed prompts:  33%|      | 2690/8192 [01:04<02:43, 33.68it/s, est. speed input: 42661.36 toks/s, output: 41.66 toks/s]
Processed prompts:  34%|      | 2754/8192 [01:06<02:41, 33.57it/s, est. speed input: 42414.20 toks/s, output: 41.42 toks/s]
Processed prompts:  34%|      | 2818/8192 [01:08<02:38, 33.80it/s, est. speed input: 42216.94 toks/s, output: 41.23 toks/s]
Processed prompts:  35%|      | 2882/8192 [01:10<02:38, 33.53it/s, est. speed input: 41981.17 toks/s, output: 41.00 toks/s]
Processed prompts:  36%|      | 2946/8192 [01:12<02:36, 33.49it/s, est. speed input: 41774.96 toks/s, output: 40.80 toks/s]
Processed prompts:  37%|      | 3010/8192 [01:14<02:33, 33.71it/s, est. speed input: 41605.12 toks/s, output: 40.63 toks/s]
Processed prompts:  38%|      | 3074/8192 [01:15<02:31, 33.87it/s, est. speed input: 41444.43 toks/s, output: 40.47 toks/s]
Processed prompts:  38%|      | 3138/8192 [01:17<02:29, 33.86it/s, est. speed input: 41279.52 toks/s, output: 40.31 toks/s]
Processed prompts:  39%|      | 3202/8192 [01:19<02:26, 33.98it/s, est. speed input: 41134.69 toks/s, output: 40.17 toks/s]
Processed prompts:  40%|      | 3266/8192 [01:21<02:25, 33.77it/s, est. speed input: 40968.34 toks/s, output: 40.01 toks/s]
Processed prompts:  41%|      | 3330/8192 [01:23<02:23, 33.79it/s, est. speed input: 40824.97 toks/s, output: 39.87 toks/s]
Processed prompts:  41%|     | 3394/8192 [01:25<02:22, 33.66it/s, est. speed input: 40675.20 toks/s, output: 39.72 toks/s]
Processed prompts:  42%|     | 3458/8192 [01:27<02:19, 33.87it/s, est. speed input: 40558.48 toks/s, output: 39.61 toks/s]
Processed prompts:  43%|     | 3522/8192 [01:29<02:18, 33.60it/s, est. speed input: 40410.88 toks/s, output: 39.46 toks/s]
Processed prompts:  44%|     | 3586/8192 [01:31<02:17, 33.39it/s, est. speed input: 40268.31 toks/s, output: 39.32 toks/s]
Processed prompts:  45%|     | 3650/8192 [01:33<02:15, 33.50it/s, est. speed input: 40152.17 toks/s, output: 39.21 toks/s]
Processed prompts:  45%|     | 3714/8192 [01:35<02:13, 33.47it/s, est. speed input: 40031.99 toks/s, output: 39.09 toks/s]
Processed prompts:  46%|     | 3778/8192 [01:36<02:11, 33.44it/s, est. speed input: 39916.31 toks/s, output: 38.98 toks/s]
Processed prompts:  47%|     | 3842/8192 [01:38<02:09, 33.55it/s, est. speed input: 39814.61 toks/s, output: 38.88 toks/s]
Processed prompts:  48%|     | 3906/8192 [01:40<02:08, 33.47it/s, est. speed input: 39705.46 toks/s, output: 38.77 toks/s]
Processed prompts:  48%|     | 3970/8192 [01:42<02:06, 33.31it/s, est. speed input: 39592.06 toks/s, output: 38.66 toks/s]
Processed prompts:  49%|     | 4034/8192 [01:44<02:03, 33.60it/s, est. speed input: 39512.16 toks/s, output: 38.59 toks/s]
Processed prompts:  50%|     | 4098/8192 [01:46<02:02, 33.44it/s, est. speed input: 39409.80 toks/s, output: 38.49 toks/s]
Processed prompts:  51%|     | 4162/8192 [01:48<01:59, 33.85it/s, est. speed input: 39346.26 toks/s, output: 38.42 toks/s]
Processed prompts:  52%|    | 4226/8192 [01:50<01:57, 33.87it/s, est. speed input: 39267.15 toks/s, output: 38.35 toks/s]
Processed prompts:  52%|    | 4290/8192 [01:52<01:55, 33.72it/s, est. speed input: 39180.28 toks/s, output: 38.26 toks/s]
Processed prompts:  53%|    | 4354/8192 [01:54<01:54, 33.47it/s, est. speed input: 39086.59 toks/s, output: 38.17 toks/s]
Processed prompts:  54%|    | 4418/8192 [01:55<01:52, 33.58it/s, est. speed input: 39014.38 toks/s, output: 38.10 toks/s]
Processed prompts:  55%|    | 4482/8192 [01:57<01:51, 33.37it/s, est. speed input: 38926.45 toks/s, output: 38.01 toks/s]
Processed prompts:  55%|    | 4546/8192 [01:59<01:48, 33.70it/s, est. speed input: 38870.43 toks/s, output: 37.96 toks/s]
Processed prompts:  56%|    | 4610/8192 [02:01<01:46, 33.55it/s, est. speed input: 38793.48 toks/s, output: 37.88 toks/s]
Processed prompts:  57%|    | 4674/8192 [02:03<01:45, 33.38it/s, est. speed input: 38714.46 toks/s, output: 37.81 toks/s]
Processed prompts:  58%|    | 4738/8192 [02:05<01:43, 33.51it/s, est. speed input: 38652.94 toks/s, output: 37.75 toks/s]
Processed prompts:  59%|    | 4802/8192 [02:07<01:41, 33.46it/s, est. speed input: 38585.15 toks/s, output: 37.68 toks/s]
Processed prompts:  59%|    | 4866/8192 [02:09<01:39, 33.46it/s, est. speed input: 38521.01 toks/s, output: 37.62 toks/s]
Processed prompts:  60%|    | 4930/8192 [02:11<01:37, 33.41it/s, est. speed input: 38456.42 toks/s, output: 37.56 toks/s]
Processed prompts:  61%|    | 4994/8192 [02:13<01:35, 33.55it/s, est. speed input: 38402.94 toks/s, output: 37.50 toks/s]
Processed prompts:  62%|   | 5058/8192 [02:15<01:32, 33.79it/s, est. speed input: 38358.52 toks/s, output: 37.46 toks/s]
Processed prompts:  63%|   | 5122/8192 [02:16<01:31, 33.60it/s, est. speed input: 38296.40 toks/s, output: 37.40 toks/s]
Processed prompts:  63%|   | 5186/8192 [02:18<01:28, 33.79it/s, est. speed input: 38252.93 toks/s, output: 37.36 toks/s]
Processed prompts:  64%|   | 5250/8192 [02:20<01:26, 33.94it/s, est. speed input: 38211.63 toks/s, output: 37.32 toks/s]
Processed prompts:  65%|   | 5314/8192 [02:22<01:24, 34.05it/s, est. speed input: 38171.31 toks/s, output: 37.28 toks/s]
Processed prompts:  66%|   | 5378/8192 [02:24<01:23, 33.86it/s, est. speed input: 38118.75 toks/s, output: 37.23 toks/s]
Processed prompts:  66%|   | 5442/8192 [02:26<01:21, 33.83it/s, est. speed input: 38072.93 toks/s, output: 37.18 toks/s]
Processed prompts:  67%|   | 5506/8192 [02:28<01:19, 33.68it/s, est. speed input: 38021.99 toks/s, output: 37.13 toks/s]
Processed prompts:  68%|   | 5570/8192 [02:30<01:18, 33.46it/s, est. speed input: 37966.97 toks/s, output: 37.08 toks/s]
Processed prompts:  69%|   | 5634/8192 [02:32<01:16, 33.59it/s, est. speed input: 37926.28 toks/s, output: 37.04 toks/s]
Processed prompts:  70%|   | 5698/8192 [02:34<01:14, 33.66it/s, est. speed input: 37885.86 toks/s, output: 37.00 toks/s]
Processed prompts:  70%|   | 5762/8192 [02:35<01:12, 33.56it/s, est. speed input: 37839.62 toks/s, output: 36.95 toks/s]
Processed prompts:  71%|   | 5826/8192 [02:37<01:10, 33.48it/s, est. speed input: 37793.99 toks/s, output: 36.91 toks/s]
Processed prompts:  72%|  | 5890/8192 [02:39<01:08, 33.58it/s, est. speed input: 37756.39 toks/s, output: 36.87 toks/s]
Processed prompts:  73%|  | 5954/8192 [02:41<01:06, 33.41it/s, est. speed input: 37709.34 toks/s, output: 36.83 toks/s]
Processed prompts:  73%|  | 6018/8192 [02:43<01:05, 33.41it/s, est. speed input: 37668.42 toks/s, output: 36.79 toks/s]
Processed prompts:  74%|  | 6082/8192 [02:45<01:03, 33.28it/s, est. speed input: 37622.49 toks/s, output: 36.74 toks/s]
Processed prompts:  75%|  | 6146/8192 [02:47<01:00, 33.58it/s, est. speed input: 37594.95 toks/s, output: 36.71 toks/s]
Processed prompts:  76%|  | 6210/8192 [02:49<00:59, 33.53it/s, est. speed input: 37556.56 toks/s, output: 36.68 toks/s]
Processed prompts:  77%|  | 6274/8192 [02:51<00:57, 33.40it/s, est. speed input: 37515.18 toks/s, output: 36.64 toks/s]
Processed prompts:  77%|  | 6338/8192 [02:53<00:55, 33.52it/s, est. speed input: 37483.63 toks/s, output: 36.61 toks/s]
Processed prompts:  78%|  | 6402/8192 [02:55<00:53, 33.48it/s, est. speed input: 37447.54 toks/s, output: 36.57 toks/s]
Processed prompts:  79%|  | 6466/8192 [02:57<00:51, 33.33it/s, est. speed input: 37407.33 toks/s, output: 36.53 toks/s]
Processed prompts:  80%|  | 6530/8192 [02:58<00:49, 33.51it/s, est. speed input: 37379.09 toks/s, output: 36.50 toks/s]
Processed prompts:  80%|  | 6594/8192 [03:00<00:47, 33.45it/s, est. speed input: 37344.32 toks/s, output: 36.47 toks/s]
Processed prompts:  81%| | 6658/8192 [03:02<00:45, 33.57it/s, est. speed input: 37316.74 toks/s, output: 36.44 toks/s]
Processed prompts:  82%| | 6722/8192 [03:04<00:43, 33.41it/s, est. speed input: 37280.29 toks/s, output: 36.41 toks/s]
Processed prompts:  83%| | 6786/8192 [03:06<00:42, 33.40it/s, est. speed input: 37248.34 toks/s, output: 36.38 toks/s]
Processed prompts:  84%| | 6850/8192 [03:08<00:40, 33.41it/s, est. speed input: 37217.63 toks/s, output: 36.35 toks/s]
Processed prompts:  84%| | 6914/8192 [03:10<00:38, 33.39it/s, est. speed input: 37186.67 toks/s, output: 36.32 toks/s]
Processed prompts:  85%| | 6978/8192 [03:12<00:36, 33.51it/s, est. speed input: 37161.19 toks/s, output: 36.29 toks/s]
Processed prompts:  86%| | 7042/8192 [03:14<00:34, 33.44it/s, est. speed input: 37130.61 toks/s, output: 36.26 toks/s]
Processed prompts:  87%| | 7106/8192 [03:16<00:32, 33.89it/s, est. speed input: 37118.41 toks/s, output: 36.25 toks/s]
Processed prompts:  88%| | 7170/8192 [03:17<00:30, 33.74it/s, est. speed input: 37090.16 toks/s, output: 36.22 toks/s]
Processed prompts:  88%| | 7234/8192 [03:19<00:28, 33.81it/s, est. speed input: 37068.60 toks/s, output: 36.20 toks/s]
Processed prompts:  89%| | 7298/8192 [03:21<00:26, 33.66it/s, est. speed input: 37040.53 toks/s, output: 36.17 toks/s]
Processed prompts:  90%| | 7362/8192 [03:23<00:24, 33.74it/s, est. speed input: 37019.07 toks/s, output: 36.15 toks/s]
Processed prompts:  91%| | 7426/8192 [03:25<00:22, 33.62it/s, est. speed input: 36992.40 toks/s, output: 36.13 toks/s]
Processed prompts:  91%|| 7490/8192 [03:27<00:20, 33.82it/s, est. speed input: 36975.60 toks/s, output: 36.11 toks/s]
Processed prompts:  92%|| 7554/8192 [03:29<00:18, 33.97it/s, est. speed input: 36959.18 toks/s, output: 36.09 toks/s]
Processed prompts:  93%|| 7618/8192 [03:31<00:16, 34.26it/s, est. speed input: 36949.02 toks/s, output: 36.08 toks/s]
Processed prompts:  94%|| 7682/8192 [03:33<00:15, 33.96it/s, est. speed input: 36923.18 toks/s, output: 36.06 toks/s]
Processed prompts:  95%|| 7746/8192 [03:34<00:13, 33.81it/s, est. speed input: 36899.40 toks/s, output: 36.03 toks/s]
Processed prompts:  95%|| 7810/8192 [03:36<00:11, 33.55it/s, est. speed input: 36871.32 toks/s, output: 36.01 toks/s]
Processed prompts:  96%|| 7874/8192 [03:38<00:09, 33.40it/s, est. speed input: 36844.66 toks/s, output: 35.98 toks/s]
Processed prompts:  97%|| 7938/8192 [03:40<00:07, 33.39it/s, est. speed input: 36821.33 toks/s, output: 35.96 toks/s]
Processed prompts:  98%|| 8002/8192 [03:42<00:05, 33.36it/s, est. speed input: 36797.79 toks/s, output: 35.94 toks/s]
Processed prompts:  98%|| 8066/8192 [03:44<00:03, 33.50it/s, est. speed input: 36779.72 toks/s, output: 35.92 toks/s]
Processed prompts:  99%|| 8130/8192 [03:46<00:01, 33.59it/s, est. speed input: 36761.57 toks/s, output: 35.90 toks/s]
Processed prompts: 100%|| 8192/8192 [03:46<00:00, 33.59it/s, est. speed input: 37041.84 toks/s, output: 36.17 toks/s]
Processed prompts: 100%|| 8192/8192 [03:46<00:00, 36.17it/s, est. speed input: 37041.84 toks/s, output: 36.17 toks/s]
[rank0]:[W126 08:14:15.217853496 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-26 11:59:17
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_4
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_4 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Llama3.2-3B-FP8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:59:21 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 11:59:21 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1261595) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1261595) WARNING 01-26 11:59:49 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 27.17 requests/s, 13937.20 total tokens/s, 27.17 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-26 11:59:21] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 11:59:21] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 11:59:21] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 11:59:21] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 11:59:21] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 11:59:21] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 11:59:21] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 11:59:21] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 11:59:21] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 11:59:21] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:59:21] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:59:21] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:59:21] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:59:21] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:59:25] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 11:59:25] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 11:59:25] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 11:59:25] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 11:59:25] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 11:59:25] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 11:59:25] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 11:59:25] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 11:59:25] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 11:59:25] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:59:25] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:59:25] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:59:25] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:59:25] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1261595) [2026-01-26 11:59:26] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1261595) [2026-01-26 11:59:26] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1261595) [2026-01-26 11:59:26] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1261595) [2026-01-26 11:59:26] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1261595) [2026-01-26 11:59:26] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1261595) [2026-01-26 11:59:26] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1261595) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1261595) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:16<00:00, 16.38s/it]
(EngineCore_DP0 pid=1261595) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:16<00:00, 16.38s/it]
(EngineCore_DP0 pid=1261595) 
(EngineCore_DP0 pid=1261595) [2026-01-26 11:59:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 3072] -> 1D uint8
(EngineCore_DP0 pid=1261595) [2026-01-26 11:59:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9830400 bytes
(EngineCore_DP0 pid=1261595) [2026-01-26 11:59:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=1261595) [2026-01-26 11:59:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5898240 bytes
(EngineCore_DP0 pid=1261595) [2026-01-26 11:59:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=1261595) [2026-01-26 11:59:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 31457280 bytes
(EngineCore_DP0 pid=1261595) [2026-01-26 11:59:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 8192] -> 1D uint8
(EngineCore_DP0 pid=1261595) [2026-01-26 11:59:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15728640 bytes
(EngineCore_DP0 pid=1261595) 2026-01-26 11:59:48,901 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1261595) 2026-01-26 11:59:48,912 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  96%|| 123/128 [00:00<00:00, 1226.42it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 1226.30it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 2/128 [00:00<00:06, 18.65it/s, est. speed input: 9549.95 toks/s, output: 18.65 toks/s]
Processed prompts:   4%|         | 5/128 [00:00<00:05, 20.80it/s, est. speed input: 10504.55 toks/s, output: 20.52 toks/s]
Processed prompts:   6%|         | 8/128 [00:00<00:05, 21.77it/s, est. speed input: 10926.80 toks/s, output: 21.34 toks/s]
Processed prompts:   9%|         | 11/128 [00:00<00:05, 23.31it/s, est. speed input: 11477.01 toks/s, output: 22.41 toks/s]
Processed prompts:  11%|         | 14/128 [00:00<00:04, 24.98it/s, est. speed input: 12022.60 toks/s, output: 23.48 toks/s]
Processed prompts:  13%|        | 17/128 [00:00<00:04, 26.20it/s, est. speed input: 12432.07 toks/s, output: 24.28 toks/s]
Processed prompts:  16%|        | 20/128 [00:00<00:04, 26.85it/s, est. speed input: 12699.42 toks/s, output: 24.80 toks/s]
Processed prompts:  18%|        | 23/128 [00:00<00:03, 27.45it/s, est. speed input: 12933.92 toks/s, output: 25.26 toks/s]
Processed prompts:  20%|        | 26/128 [00:01<00:03, 27.83it/s, est. speed input: 13115.33 toks/s, output: 25.62 toks/s]
Processed prompts:  23%|       | 29/128 [00:01<00:03, 27.95it/s, est. speed input: 13241.48 toks/s, output: 25.86 toks/s]
Processed prompts:  25%|       | 32/128 [00:01<00:03, 28.17it/s, est. speed input: 13365.33 toks/s, output: 26.10 toks/s]
Processed prompts:  27%|       | 35/128 [00:01<00:03, 28.24it/s, est. speed input: 13458.16 toks/s, output: 26.28 toks/s]
Processed prompts:  30%|       | 38/128 [00:01<00:03, 28.32it/s, est. speed input: 13540.77 toks/s, output: 26.45 toks/s]
Processed prompts:  32%|      | 41/128 [00:01<00:03, 27.85it/s, est. speed input: 13554.53 toks/s, output: 26.47 toks/s]
Processed prompts:  34%|      | 44/128 [00:01<00:03, 27.95it/s, est. speed input: 13610.95 toks/s, output: 26.58 toks/s]
Processed prompts:  37%|      | 47/128 [00:01<00:02, 28.17it/s, est. speed input: 13674.92 toks/s, output: 26.71 toks/s]
Processed prompts:  39%|      | 50/128 [00:01<00:02, 28.31it/s, est. speed input: 13731.06 toks/s, output: 26.82 toks/s]
Processed prompts:  41%|     | 53/128 [00:01<00:02, 28.22it/s, est. speed input: 13764.28 toks/s, output: 26.88 toks/s]
Processed prompts:  44%|     | 56/128 [00:02<00:02, 28.26it/s, est. speed input: 13802.25 toks/s, output: 26.96 toks/s]
Processed prompts:  46%|     | 59/128 [00:02<00:02, 28.41it/s, est. speed input: 13846.77 toks/s, output: 27.04 toks/s]
Processed prompts:  48%|     | 62/128 [00:02<00:02, 28.38it/s, est. speed input: 13877.02 toks/s, output: 27.10 toks/s]
Processed prompts:  51%|     | 65/128 [00:02<00:02, 28.51it/s, est. speed input: 13914.85 toks/s, output: 27.18 toks/s]
Processed prompts:  53%|    | 68/128 [00:02<00:02, 28.50it/s, est. speed input: 13942.84 toks/s, output: 27.23 toks/s]
Processed prompts:  55%|    | 71/128 [00:02<00:02, 28.10it/s, est. speed input: 13942.83 toks/s, output: 27.23 toks/s]
Processed prompts:  58%|    | 74/128 [00:02<00:01, 28.21it/s, est. speed input: 13966.93 toks/s, output: 27.28 toks/s]
Processed prompts:  60%|    | 77/128 [00:02<00:01, 28.36it/s, est. speed input: 13994.30 toks/s, output: 27.33 toks/s]
Processed prompts:  62%|   | 80/128 [00:02<00:01, 28.48it/s, est. speed input: 14020.24 toks/s, output: 27.38 toks/s]
Processed prompts:  65%|   | 83/128 [00:03<00:01, 28.50it/s, est. speed input: 14041.34 toks/s, output: 27.42 toks/s]
Processed prompts:  67%|   | 86/128 [00:03<00:01, 28.56it/s, est. speed input: 14062.87 toks/s, output: 27.47 toks/s]
Processed prompts:  70%|   | 89/128 [00:03<00:01, 28.58it/s, est. speed input: 14082.10 toks/s, output: 27.50 toks/s]
Processed prompts:  72%|  | 92/128 [00:03<00:01, 28.54it/s, est. speed input: 14097.46 toks/s, output: 27.53 toks/s]
Processed prompts:  74%|  | 95/128 [00:03<00:01, 28.55it/s, est. speed input: 14113.48 toks/s, output: 27.57 toks/s]
Processed prompts:  77%|  | 98/128 [00:03<00:01, 28.44it/s, est. speed input: 14123.36 toks/s, output: 27.58 toks/s]
Processed prompts:  79%|  | 101/128 [00:03<00:00, 28.17it/s, est. speed input: 14122.65 toks/s, output: 27.58 toks/s]
Processed prompts:  81%| | 104/128 [00:03<00:00, 28.24it/s, est. speed input: 14134.47 toks/s, output: 27.61 toks/s]
Processed prompts:  84%| | 107/128 [00:03<00:00, 28.42it/s, est. speed input: 14151.43 toks/s, output: 27.64 toks/s]
Processed prompts:  86%| | 110/128 [00:03<00:00, 28.27it/s, est. speed input: 14155.67 toks/s, output: 27.65 toks/s]
Processed prompts:  88%| | 113/128 [00:04<00:00, 28.50it/s, est. speed input: 14173.74 toks/s, output: 27.68 toks/s]
Processed prompts:  91%| | 116/128 [00:04<00:00, 28.44it/s, est. speed input: 14181.93 toks/s, output: 27.70 toks/s]
Processed prompts:  93%|| 119/128 [00:04<00:00, 28.54it/s, est. speed input: 14195.23 toks/s, output: 27.72 toks/s]
Processed prompts:  95%|| 122/128 [00:04<00:00, 28.57it/s, est. speed input: 14206.37 toks/s, output: 27.75 toks/s]
Processed prompts:  98%|| 125/128 [00:04<00:00, 28.59it/s, est. speed input: 14216.96 toks/s, output: 27.77 toks/s]
Processed prompts: 100%|| 128/128 [00:04<00:00, 28.63it/s, est. speed input: 14228.23 toks/s, output: 27.79 toks/s]
Processed prompts: 100%|| 128/128 [00:04<00:00, 28.63it/s, est. speed input: 14228.23 toks/s, output: 27.79 toks/s]
Processed prompts: 100%|| 128/128 [00:04<00:00, 27.79it/s, est. speed input: 14228.23 toks/s, output: 27.79 toks/s]
[rank0]:[W126 11:59:54.824124265 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-26 11:59:56
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Llama3.2-3B-FP8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 12:00:00 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 12:00:00 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1262337) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1262337) WARNING 01-26 12:00:27 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 14.91 requests/s, 15284.74 total tokens/s, 14.91 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-26 12:00:00] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 12:00:00] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 12:00:00] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 12:00:00] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:00:00] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:00:00] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:00:00] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:00:00] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:00:00] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 12:00:00] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:00:00] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:00:00] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:00:00] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:00:00] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 12:00:04] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 12:00:04] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 12:00:04] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 12:00:04] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:00:04] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:00:04] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:00:04] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:00:04] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:00:04] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 12:00:04] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:00:04] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:00:04] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:00:04] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:00:04] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1262337) [2026-01-26 12:00:05] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1262337) [2026-01-26 12:00:05] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1262337) [2026-01-26 12:00:05] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1262337) [2026-01-26 12:00:05] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1262337) [2026-01-26 12:00:05] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1262337) [2026-01-26 12:00:05] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1262337) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1262337) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:15<00:00, 15.57s/it]
(EngineCore_DP0 pid=1262337) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:15<00:00, 15.57s/it]
(EngineCore_DP0 pid=1262337) 
(EngineCore_DP0 pid=1262337) [2026-01-26 12:00:21] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 3072] -> 1D uint8
(EngineCore_DP0 pid=1262337) [2026-01-26 12:00:21] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9830400 bytes
(EngineCore_DP0 pid=1262337) [2026-01-26 12:00:21] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=1262337) [2026-01-26 12:00:21] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5898240 bytes
(EngineCore_DP0 pid=1262337) [2026-01-26 12:00:21] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=1262337) [2026-01-26 12:00:21] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 31457280 bytes
(EngineCore_DP0 pid=1262337) [2026-01-26 12:00:21] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 8192] -> 1D uint8
(EngineCore_DP0 pid=1262337) [2026-01-26 12:00:21] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15728640 bytes
(EngineCore_DP0 pid=1262337) 2026-01-26 12:00:26,782 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1262337) 2026-01-26 12:00:26,793 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  45%|     | 57/128 [00:00<00:00, 561.62it/s]
Adding requests:  89%| | 114/128 [00:00<00:00, 532.19it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 528.22it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   4%|         | 5/128 [00:00<00:03, 32.43it/s, est. speed input: 33220.67 toks/s, output: 32.44 toks/s]
Processed prompts:   7%|         | 9/128 [00:00<00:05, 20.25it/s, est. speed input: 22123.04 toks/s, output: 21.60 toks/s]
Processed prompts:   9%|         | 12/128 [00:00<00:06, 17.80it/s, est. speed input: 19790.52 toks/s, output: 19.33 toks/s]
Processed prompts:  11%|         | 14/128 [00:00<00:06, 17.00it/s, est. speed input: 19019.90 toks/s, output: 18.57 toks/s]
Processed prompts:  12%|        | 16/128 [00:00<00:06, 16.47it/s, est. speed input: 18505.65 toks/s, output: 18.07 toks/s]
Processed prompts:  14%|        | 18/128 [00:01<00:06, 16.04it/s, est. speed input: 18094.55 toks/s, output: 17.67 toks/s]
Processed prompts:  16%|        | 20/128 [00:01<00:06, 15.76it/s, est. speed input: 17789.65 toks/s, output: 17.37 toks/s]
Processed prompts:  17%|        | 22/128 [00:01<00:06, 15.53it/s, est. speed input: 17536.16 toks/s, output: 17.12 toks/s]
Processed prompts:  19%|        | 24/128 [00:01<00:06, 15.32it/s, est. speed input: 17314.53 toks/s, output: 16.91 toks/s]
Processed prompts:  20%|        | 26/128 [00:01<00:06, 15.23it/s, est. speed input: 17148.75 toks/s, output: 16.75 toks/s]
Processed prompts:  22%|       | 28/128 [00:01<00:06, 15.06it/s, est. speed input: 16977.27 toks/s, output: 16.58 toks/s]
Processed prompts:  23%|       | 30/128 [00:01<00:06, 15.12it/s, est. speed input: 16880.05 toks/s, output: 16.48 toks/s]
Processed prompts:  25%|       | 32/128 [00:01<00:06, 15.13it/s, est. speed input: 16787.95 toks/s, output: 16.39 toks/s]
Processed prompts:  27%|       | 34/128 [00:02<00:06, 15.08it/s, est. speed input: 16694.60 toks/s, output: 16.30 toks/s]
Processed prompts:  28%|       | 36/128 [00:02<00:06, 15.10it/s, est. speed input: 16622.80 toks/s, output: 16.23 toks/s]
Processed prompts:  30%|       | 38/128 [00:02<00:05, 15.05it/s, est. speed input: 16547.33 toks/s, output: 16.16 toks/s]
Processed prompts:  31%|      | 40/128 [00:02<00:05, 15.01it/s, est. speed input: 16478.49 toks/s, output: 16.09 toks/s]
Processed prompts:  33%|      | 42/128 [00:02<00:05, 15.02it/s, est. speed input: 16424.57 toks/s, output: 16.04 toks/s]
Processed prompts:  34%|      | 44/128 [00:02<00:05, 14.88it/s, est. speed input: 16349.69 toks/s, output: 15.97 toks/s]
Processed prompts:  36%|      | 46/128 [00:02<00:05, 14.99it/s, est. speed input: 16316.04 toks/s, output: 15.93 toks/s]
Processed prompts:  38%|      | 48/128 [00:03<00:05, 14.94it/s, est. speed input: 16264.63 toks/s, output: 15.88 toks/s]
Processed prompts:  39%|      | 50/128 [00:03<00:05, 14.98it/s, est. speed input: 16230.34 toks/s, output: 15.85 toks/s]
Processed prompts:  41%|      | 52/128 [00:03<00:05, 15.01it/s, est. speed input: 16198.95 toks/s, output: 15.82 toks/s]
Processed prompts:  42%|     | 54/128 [00:03<00:04, 15.04it/s, est. speed input: 16170.17 toks/s, output: 15.79 toks/s]
Processed prompts:  44%|     | 56/128 [00:03<00:04, 14.98it/s, est. speed input: 16132.98 toks/s, output: 15.75 toks/s]
Processed prompts:  45%|     | 58/128 [00:03<00:04, 15.03it/s, est. speed input: 16111.04 toks/s, output: 15.73 toks/s]
Processed prompts:  47%|     | 60/128 [00:03<00:04, 14.99it/s, est. speed input: 16081.46 toks/s, output: 15.70 toks/s]
Processed prompts:  48%|     | 62/128 [00:03<00:04, 15.02it/s, est. speed input: 16059.46 toks/s, output: 15.68 toks/s]
Processed prompts:  50%|     | 64/128 [00:04<00:04, 15.07it/s, est. speed input: 16043.57 toks/s, output: 15.67 toks/s]
Processed prompts:  52%|    | 66/128 [00:04<00:04, 15.19it/s, est. speed input: 16037.96 toks/s, output: 15.66 toks/s]
Processed prompts:  53%|    | 68/128 [00:04<00:03, 15.11it/s, est. speed input: 16014.85 toks/s, output: 15.64 toks/s]
Processed prompts:  55%|    | 70/128 [00:04<00:03, 15.20it/s, est. speed input: 16008.19 toks/s, output: 15.63 toks/s]
Processed prompts:  56%|    | 72/128 [00:04<00:03, 15.13it/s, est. speed input: 15988.45 toks/s, output: 15.61 toks/s]
Processed prompts:  58%|    | 74/128 [00:04<00:03, 15.16it/s, est. speed input: 15977.66 toks/s, output: 15.60 toks/s]
Processed prompts:  59%|    | 76/128 [00:04<00:03, 14.98it/s, est. speed input: 15948.27 toks/s, output: 15.57 toks/s]
Processed prompts:  61%|    | 78/128 [00:05<00:03, 15.01it/s, est. speed input: 15934.25 toks/s, output: 15.56 toks/s]
Processed prompts:  62%|   | 80/128 [00:05<00:03, 15.07it/s, est. speed input: 15925.50 toks/s, output: 15.55 toks/s]
Processed prompts:  64%|   | 82/128 [00:05<00:03, 15.19it/s, est. speed input: 15923.28 toks/s, output: 15.55 toks/s]
Processed prompts:  66%|   | 84/128 [00:05<00:02, 15.11it/s, est. speed input: 15907.20 toks/s, output: 15.53 toks/s]
Processed prompts:  67%|   | 86/128 [00:05<00:02, 15.10it/s, est. speed input: 15895.99 toks/s, output: 15.52 toks/s]
Processed prompts:  69%|   | 88/128 [00:05<00:02, 15.08it/s, est. speed input: 15884.50 toks/s, output: 15.51 toks/s]
Processed prompts:  70%|   | 90/128 [00:05<00:02, 15.13it/s, est. speed input: 15878.53 toks/s, output: 15.51 toks/s]
Processed prompts:  72%|  | 92/128 [00:05<00:02, 14.92it/s, est. speed input: 15853.11 toks/s, output: 15.48 toks/s]
Processed prompts:  73%|  | 94/128 [00:06<00:02, 14.92it/s, est. speed input: 15840.63 toks/s, output: 15.47 toks/s]
Processed prompts:  75%|  | 96/128 [00:06<00:02, 15.07it/s, est. speed input: 15839.67 toks/s, output: 15.47 toks/s]
Processed prompts:  77%|  | 98/128 [00:06<00:01, 15.00it/s, est. speed input: 15826.10 toks/s, output: 15.46 toks/s]
Processed prompts:  78%|  | 100/128 [00:06<00:01, 15.05it/s, est. speed input: 15820.12 toks/s, output: 15.45 toks/s]
Processed prompts:  80%|  | 102/128 [00:06<00:01, 15.16it/s, est. speed input: 15819.27 toks/s, output: 15.45 toks/s]
Processed prompts:  81%| | 104/128 [00:06<00:01, 15.09it/s, est. speed input: 15808.73 toks/s, output: 15.44 toks/s]
Processed prompts:  83%| | 106/128 [00:06<00:01, 15.07it/s, est. speed input: 15800.75 toks/s, output: 15.43 toks/s]
Processed prompts:  84%| | 108/128 [00:07<00:01, 14.86it/s, est. speed input: 15779.93 toks/s, output: 15.41 toks/s]
Processed prompts:  86%| | 110/128 [00:07<00:01, 14.90it/s, est. speed input: 15771.89 toks/s, output: 15.40 toks/s]
Processed prompts:  88%| | 112/128 [00:07<00:01, 14.91it/s, est. speed input: 15762.76 toks/s, output: 15.39 toks/s]
Processed prompts:  89%| | 114/128 [00:07<00:00, 14.97it/s, est. speed input: 15757.79 toks/s, output: 15.39 toks/s]
Processed prompts:  91%| | 116/128 [00:07<00:00, 15.12it/s, est. speed input: 15759.27 toks/s, output: 15.39 toks/s]
Processed prompts:  92%|| 118/128 [00:07<00:00, 15.01it/s, est. speed input: 15748.28 toks/s, output: 15.38 toks/s]
Processed prompts:  94%|| 120/128 [00:07<00:00, 15.07it/s, est. speed input: 15745.00 toks/s, output: 15.38 toks/s]
Processed prompts:  95%|| 122/128 [00:07<00:00, 15.05it/s, est. speed input: 15738.87 toks/s, output: 15.37 toks/s]
Processed prompts:  97%|| 124/128 [00:08<00:00, 14.85it/s, est. speed input: 15721.79 toks/s, output: 15.35 toks/s]
Processed prompts:  98%|| 126/128 [00:08<00:00, 14.87it/s, est. speed input: 15714.56 toks/s, output: 15.35 toks/s]
Processed prompts: 100%|| 128/128 [00:08<00:00, 15.02it/s, est. speed input: 15715.12 toks/s, output: 15.35 toks/s]
Processed prompts: 100%|| 128/128 [00:08<00:00, 15.02it/s, est. speed input: 15715.12 toks/s, output: 15.35 toks/s]
Processed prompts: 100%|| 128/128 [00:08<00:00, 15.35it/s, est. speed input: 15715.12 toks/s, output: 15.35 toks/s]
[rank0]:[W126 12:00:36.468151875 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-26 12:00:38
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Llama3.2-3B-FP8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 12:00:42 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 12:00:42 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1263103) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1263103) WARNING 01-26 12:01:09 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 14.70 requests/s, 15065.39 total tokens/s, 14.70 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-26 12:00:42] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 12:00:42] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 12:00:42] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 12:00:42] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:00:42] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:00:42] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:00:42] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:00:42] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:00:42] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 12:00:42] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:00:42] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:00:42] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:00:42] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:00:42] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 12:00:46] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 12:00:46] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 12:00:46] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 12:00:46] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:00:46] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:00:46] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:00:46] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:00:46] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:00:46] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 12:00:46] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:00:46] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:00:46] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:00:46] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:00:46] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1263103) [2026-01-26 12:00:47] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1263103) [2026-01-26 12:00:47] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1263103) [2026-01-26 12:00:47] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1263103) [2026-01-26 12:00:47] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1263103) [2026-01-26 12:00:47] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1263103) [2026-01-26 12:00:47] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1263103) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1263103) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:15<00:00, 15.83s/it]
(EngineCore_DP0 pid=1263103) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:15<00:00, 15.83s/it]
(EngineCore_DP0 pid=1263103) 
(EngineCore_DP0 pid=1263103) [2026-01-26 12:01:03] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 3072] -> 1D uint8
(EngineCore_DP0 pid=1263103) [2026-01-26 12:01:03] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9830400 bytes
(EngineCore_DP0 pid=1263103) [2026-01-26 12:01:03] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=1263103) [2026-01-26 12:01:03] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5898240 bytes
(EngineCore_DP0 pid=1263103) [2026-01-26 12:01:03] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=1263103) [2026-01-26 12:01:03] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 31457280 bytes
(EngineCore_DP0 pid=1263103) [2026-01-26 12:01:03] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 8192] -> 1D uint8
(EngineCore_DP0 pid=1263103) [2026-01-26 12:01:03] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15728640 bytes
(EngineCore_DP0 pid=1263103) 2026-01-26 12:01:08,986 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1263103) 2026-01-26 12:01:08,996 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  21%|        | 54/256 [00:00<00:00, 529.88it/s]
Adding requests:  42%|     | 107/256 [00:00<00:00, 496.07it/s]
Adding requests:  61%|   | 157/256 [00:00<00:00, 497.39it/s]
Adding requests:  81%|  | 207/256 [00:00<00:00, 478.21it/s]
Adding requests: 100%|| 256/256 [00:00<00:00, 490.64it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   3%|         | 8/256 [00:00<00:05, 42.79it/s, est. speed input: 43821.50 toks/s, output: 42.79 toks/s]
Processed prompts:   5%|         | 13/256 [00:00<00:09, 26.47it/s, est. speed input: 29161.89 toks/s, output: 28.48 toks/s]
Processed prompts:   6%|         | 16/256 [00:00<00:12, 18.90it/s, est. speed input: 22518.70 toks/s, output: 21.99 toks/s]
Processed prompts:   7%|         | 19/256 [00:00<00:11, 19.81it/s, est. speed input: 22592.89 toks/s, output: 22.06 toks/s]
Processed prompts:   9%|         | 22/256 [00:01<00:14, 16.09it/s, est. speed input: 19902.61 toks/s, output: 19.44 toks/s]
Processed prompts:   9%|         | 24/256 [00:01<00:14, 15.73it/s, est. speed input: 19366.14 toks/s, output: 18.91 toks/s]
Processed prompts:  10%|         | 26/256 [00:01<00:14, 15.51it/s, est. speed input: 18965.89 toks/s, output: 18.52 toks/s]
Processed prompts:  11%|         | 28/256 [00:01<00:14, 15.34it/s, est. speed input: 18636.75 toks/s, output: 18.20 toks/s]
Processed prompts:  12%|        | 30/256 [00:01<00:14, 15.17it/s, est. speed input: 18349.54 toks/s, output: 17.92 toks/s]
Processed prompts:  12%|        | 32/256 [00:01<00:14, 15.12it/s, est. speed input: 18128.86 toks/s, output: 17.70 toks/s]
Processed prompts:  13%|        | 34/256 [00:01<00:14, 15.02it/s, est. speed input: 17919.48 toks/s, output: 17.50 toks/s]
Processed prompts:  14%|        | 36/256 [00:02<00:14, 14.93it/s, est. speed input: 17732.45 toks/s, output: 17.32 toks/s]
Processed prompts:  15%|        | 38/256 [00:02<00:14, 14.82it/s, est. speed input: 17557.92 toks/s, output: 17.15 toks/s]
Processed prompts:  16%|        | 40/256 [00:02<00:14, 14.71it/s, est. speed input: 17395.84 toks/s, output: 16.99 toks/s]
Processed prompts:  16%|        | 42/256 [00:02<00:14, 14.70it/s, est. speed input: 17264.98 toks/s, output: 16.86 toks/s]
Processed prompts:  17%|        | 44/256 [00:02<00:14, 14.75it/s, est. speed input: 17161.97 toks/s, output: 16.76 toks/s]
Processed prompts:  18%|        | 46/256 [00:02<00:14, 14.76it/s, est. speed input: 17062.80 toks/s, output: 16.66 toks/s]
Processed prompts:  19%|        | 48/256 [00:02<00:14, 14.80it/s, est. speed input: 16978.03 toks/s, output: 16.58 toks/s]
Processed prompts:  20%|        | 50/256 [00:03<00:13, 14.78it/s, est. speed input: 16893.62 toks/s, output: 16.50 toks/s]
Processed prompts:  20%|        | 52/256 [00:03<00:13, 14.77it/s, est. speed input: 16816.40 toks/s, output: 16.42 toks/s]
Processed prompts:  21%|        | 54/256 [00:03<00:13, 14.73it/s, est. speed input: 16740.72 toks/s, output: 16.35 toks/s]
Processed prompts:  22%|       | 56/256 [00:03<00:13, 14.70it/s, est. speed input: 16671.78 toks/s, output: 16.28 toks/s]
Processed prompts:  23%|       | 58/256 [00:03<00:13, 14.75it/s, est. speed input: 16616.25 toks/s, output: 16.23 toks/s]
Processed prompts:  23%|       | 60/256 [00:03<00:13, 14.76it/s, est. speed input: 16562.23 toks/s, output: 16.17 toks/s]
Processed prompts:  24%|       | 62/256 [00:03<00:13, 14.76it/s, est. speed input: 16511.22 toks/s, output: 16.12 toks/s]
Processed prompts:  25%|       | 64/256 [00:03<00:12, 14.81it/s, est. speed input: 16470.39 toks/s, output: 16.08 toks/s]
Processed prompts:  26%|       | 66/256 [00:04<00:12, 14.86it/s, est. speed input: 16432.90 toks/s, output: 16.05 toks/s]
Processed prompts:  27%|       | 68/256 [00:04<00:12, 14.85it/s, est. speed input: 16393.55 toks/s, output: 16.01 toks/s]
Processed prompts:  27%|       | 70/256 [00:04<00:12, 14.71it/s, est. speed input: 16340.71 toks/s, output: 15.96 toks/s]
Processed prompts:  28%|       | 72/256 [00:04<00:12, 14.67it/s, est. speed input: 16297.91 toks/s, output: 15.92 toks/s]
Processed prompts:  29%|       | 74/256 [00:04<00:12, 14.83it/s, est. speed input: 16278.14 toks/s, output: 15.90 toks/s]
Processed prompts:  30%|       | 76/256 [00:04<00:12, 14.93it/s, est. speed input: 16257.59 toks/s, output: 15.88 toks/s]
Processed prompts:  30%|       | 78/256 [00:04<00:11, 14.96it/s, est. speed input: 16233.86 toks/s, output: 15.85 toks/s]
Processed prompts:  31%|      | 80/256 [00:05<00:11, 14.91it/s, est. speed input: 16205.14 toks/s, output: 15.83 toks/s]
Processed prompts:  32%|      | 82/256 [00:05<00:11, 14.85it/s, est. speed input: 16175.53 toks/s, output: 15.80 toks/s]
Processed prompts:  33%|      | 84/256 [00:05<00:11, 14.91it/s, est. speed input: 16156.27 toks/s, output: 15.78 toks/s]
Processed prompts:  34%|      | 86/256 [00:05<00:11, 14.72it/s, est. speed input: 16117.34 toks/s, output: 15.74 toks/s]
Processed prompts:  34%|      | 88/256 [00:05<00:11, 14.74it/s, est. speed input: 16093.72 toks/s, output: 15.72 toks/s]
Processed prompts:  35%|      | 90/256 [00:05<00:11, 14.72it/s, est. speed input: 16068.06 toks/s, output: 15.69 toks/s]
Processed prompts:  36%|      | 92/256 [00:05<00:11, 14.79it/s, est. speed input: 16051.22 toks/s, output: 15.67 toks/s]
Processed prompts:  37%|      | 94/256 [00:06<00:10, 14.74it/s, est. speed input: 16027.02 toks/s, output: 15.65 toks/s]
Processed prompts:  38%|      | 96/256 [00:06<00:10, 14.83it/s, est. speed input: 16013.27 toks/s, output: 15.64 toks/s]
Processed prompts:  38%|      | 98/256 [00:06<00:10, 14.82it/s, est. speed input: 15994.75 toks/s, output: 15.62 toks/s]
Processed prompts:  39%|      | 100/256 [00:06<00:10, 14.85it/s, est. speed input: 15979.97 toks/s, output: 15.61 toks/s]
Processed prompts:  40%|      | 102/256 [00:06<00:10, 14.71it/s, est. speed input: 15953.28 toks/s, output: 15.58 toks/s]
Processed prompts:  41%|      | 104/256 [00:06<00:10, 14.74it/s, est. speed input: 15937.63 toks/s, output: 15.56 toks/s]
Processed prompts:  41%|     | 106/256 [00:06<00:10, 14.84it/s, est. speed input: 15928.22 toks/s, output: 15.55 toks/s]
Processed prompts:  42%|     | 108/256 [00:06<00:09, 14.83it/s, est. speed input: 15912.74 toks/s, output: 15.54 toks/s]
Processed prompts:  43%|     | 110/256 [00:07<00:09, 14.88it/s, est. speed input: 15902.82 toks/s, output: 15.53 toks/s]
Processed prompts:  44%|     | 112/256 [00:07<00:09, 14.87it/s, est. speed input: 15889.28 toks/s, output: 15.52 toks/s]
Processed prompts:  45%|     | 114/256 [00:07<00:09, 14.93it/s, est. speed input: 15881.41 toks/s, output: 15.51 toks/s]
Processed prompts:  45%|     | 116/256 [00:07<00:09, 14.89it/s, est. speed input: 15868.44 toks/s, output: 15.50 toks/s]
Processed prompts:  46%|     | 118/256 [00:07<00:09, 14.68it/s, est. speed input: 15844.27 toks/s, output: 15.47 toks/s]
Processed prompts:  47%|     | 120/256 [00:07<00:09, 14.78it/s, est. speed input: 15835.89 toks/s, output: 15.46 toks/s]
Processed prompts:  48%|     | 122/256 [00:07<00:09, 14.79it/s, est. speed input: 15824.32 toks/s, output: 15.45 toks/s]
Processed prompts:  48%|     | 124/256 [00:08<00:08, 14.78it/s, est. speed input: 15812.67 toks/s, output: 15.44 toks/s]
Processed prompts:  49%|     | 126/256 [00:08<00:08, 14.84it/s, est. speed input: 15805.08 toks/s, output: 15.43 toks/s]
Processed prompts:  50%|     | 128/256 [00:08<00:08, 14.81it/s, est. speed input: 15793.49 toks/s, output: 15.42 toks/s]
Processed prompts:  51%|     | 130/256 [00:08<00:08, 14.93it/s, est. speed input: 15789.99 toks/s, output: 15.42 toks/s]
Processed prompts:  52%|    | 132/256 [00:08<00:08, 14.90it/s, est. speed input: 15780.30 toks/s, output: 15.41 toks/s]
Processed prompts:  52%|    | 134/256 [00:08<00:08, 14.70it/s, est. speed input: 15761.59 toks/s, output: 15.39 toks/s]
Processed prompts:  53%|    | 136/256 [00:08<00:08, 14.84it/s, est. speed input: 15758.36 toks/s, output: 15.39 toks/s]
Processed prompts:  54%|    | 138/256 [00:08<00:07, 14.90it/s, est. speed input: 15752.71 toks/s, output: 15.38 toks/s]
Processed prompts:  55%|    | 140/256 [00:09<00:07, 14.84it/s, est. speed input: 15742.67 toks/s, output: 15.37 toks/s]
Processed prompts:  55%|    | 142/256 [00:09<00:07, 14.79it/s, est. speed input: 15731.75 toks/s, output: 15.36 toks/s]
Processed prompts:  56%|    | 144/256 [00:09<00:07, 14.80it/s, est. speed input: 15723.97 toks/s, output: 15.36 toks/s]
Processed prompts:  57%|    | 146/256 [00:09<00:07, 14.80it/s, est. speed input: 15716.09 toks/s, output: 15.35 toks/s]
Processed prompts:  58%|    | 148/256 [00:09<00:07, 14.72it/s, est. speed input: 15703.96 toks/s, output: 15.34 toks/s]
Processed prompts:  59%|    | 150/256 [00:09<00:07, 14.72it/s, est. speed input: 15695.53 toks/s, output: 15.33 toks/s]
Processed prompts:  59%|    | 152/256 [00:09<00:07, 14.74it/s, est. speed input: 15687.73 toks/s, output: 15.32 toks/s]
Processed prompts:  60%|    | 154/256 [00:10<00:06, 14.78it/s, est. speed input: 15681.68 toks/s, output: 15.31 toks/s]
Processed prompts:  61%|    | 156/256 [00:10<00:06, 14.85it/s, est. speed input: 15677.82 toks/s, output: 15.31 toks/s]
Processed prompts:  62%|   | 158/256 [00:10<00:06, 14.84it/s, est. speed input: 15671.11 toks/s, output: 15.30 toks/s]
Processed prompts:  62%|   | 160/256 [00:10<00:06, 14.81it/s, est. speed input: 15663.83 toks/s, output: 15.30 toks/s]
Processed prompts:  63%|   | 162/256 [00:10<00:06, 14.91it/s, est. speed input: 15661.83 toks/s, output: 15.29 toks/s]
Processed prompts:  64%|   | 164/256 [00:10<00:06, 14.69it/s, est. speed input: 15647.28 toks/s, output: 15.28 toks/s]
Processed prompts:  65%|   | 166/256 [00:10<00:06, 14.72it/s, est. speed input: 15640.94 toks/s, output: 15.27 toks/s]
Processed prompts:  66%|   | 168/256 [00:11<00:05, 14.71it/s, est. speed input: 15633.33 toks/s, output: 15.27 toks/s]
Processed prompts:  66%|   | 170/256 [00:11<00:05, 14.69it/s, est. speed input: 15625.53 toks/s, output: 15.26 toks/s]
Processed prompts:  67%|   | 172/256 [00:11<00:05, 14.69it/s, est. speed input: 15618.37 toks/s, output: 15.25 toks/s]
Processed prompts:  68%|   | 174/256 [00:11<00:05, 14.79it/s, est. speed input: 15615.70 toks/s, output: 15.25 toks/s]
Processed prompts:  69%|   | 176/256 [00:11<00:05, 14.72it/s, est. speed input: 15607.45 toks/s, output: 15.24 toks/s]
Processed prompts:  70%|   | 178/256 [00:11<00:05, 14.80it/s, est. speed input: 15604.35 toks/s, output: 15.24 toks/s]
Processed prompts:  70%|   | 180/256 [00:11<00:05, 14.64it/s, est. speed input: 15592.85 toks/s, output: 15.23 toks/s]
Processed prompts:  71%|   | 182/256 [00:11<00:05, 14.72it/s, est. speed input: 15589.01 toks/s, output: 15.22 toks/s]
Processed prompts:  72%|  | 184/256 [00:12<00:04, 14.75it/s, est. speed input: 15584.60 toks/s, output: 15.22 toks/s]
Processed prompts:  73%|  | 186/256 [00:12<00:04, 14.74it/s, est. speed input: 15578.99 toks/s, output: 15.21 toks/s]
Processed prompts:  73%|  | 188/256 [00:12<00:04, 14.86it/s, est. speed input: 15578.15 toks/s, output: 15.21 toks/s]
Processed prompts:  74%|  | 190/256 [00:12<00:04, 14.86it/s, est. speed input: 15574.38 toks/s, output: 15.21 toks/s]
Processed prompts:  75%|  | 192/256 [00:12<00:04, 14.85it/s, est. speed input: 15570.13 toks/s, output: 15.21 toks/s]
Processed prompts:  76%|  | 194/256 [00:12<00:04, 14.89it/s, est. speed input: 15567.67 toks/s, output: 15.20 toks/s]
Processed prompts:  77%|  | 196/256 [00:12<00:04, 14.65it/s, est. speed input: 15555.36 toks/s, output: 15.19 toks/s]
Processed prompts:  77%|  | 198/256 [00:13<00:03, 14.67it/s, est. speed input: 15550.32 toks/s, output: 15.19 toks/s]
Processed prompts:  78%|  | 200/256 [00:13<00:03, 14.78it/s, est. speed input: 15548.94 toks/s, output: 15.18 toks/s]
Processed prompts:  79%|  | 202/256 [00:13<00:03, 14.84it/s, est. speed input: 15546.74 toks/s, output: 15.18 toks/s]
Processed prompts:  80%|  | 204/256 [00:13<00:03, 14.84it/s, est. speed input: 15543.34 toks/s, output: 15.18 toks/s]
Processed prompts:  80%|  | 206/256 [00:13<00:03, 14.81it/s, est. speed input: 15538.88 toks/s, output: 15.17 toks/s]
Processed prompts:  81%| | 208/256 [00:13<00:03, 14.84it/s, est. speed input: 15536.11 toks/s, output: 15.17 toks/s]
Processed prompts:  82%| | 210/256 [00:13<00:03, 14.84it/s, est. speed input: 15532.78 toks/s, output: 15.17 toks/s]
Processed prompts:  83%| | 212/256 [00:13<00:03, 14.64it/s, est. speed input: 15522.84 toks/s, output: 15.16 toks/s]
Processed prompts:  84%| | 214/256 [00:14<00:02, 14.64it/s, est. speed input: 15517.70 toks/s, output: 15.15 toks/s]
Processed prompts:  84%| | 216/256 [00:14<00:02, 14.73it/s, est. speed input: 15515.75 toks/s, output: 15.15 toks/s]
Processed prompts:  85%| | 218/256 [00:14<00:02, 14.78it/s, est. speed input: 15513.16 toks/s, output: 15.15 toks/s]
Processed prompts:  86%| | 220/256 [00:14<00:02, 14.81it/s, est. speed input: 15510.79 toks/s, output: 15.15 toks/s]
Processed prompts:  87%| | 222/256 [00:14<00:02, 14.77it/s, est. speed input: 15506.16 toks/s, output: 15.14 toks/s]
Processed prompts:  88%| | 224/256 [00:14<00:02, 14.81it/s, est. speed input: 15504.13 toks/s, output: 15.14 toks/s]
Processed prompts:  88%| | 226/256 [00:14<00:02, 14.80it/s, est. speed input: 15500.60 toks/s, output: 15.14 toks/s]
Processed prompts:  89%| | 228/256 [00:15<00:01, 14.61it/s, est. speed input: 15491.62 toks/s, output: 15.13 toks/s]
Processed prompts:  90%| | 230/256 [00:15<00:01, 14.72it/s, est. speed input: 15490.28 toks/s, output: 15.13 toks/s]
Processed prompts:  91%| | 232/256 [00:15<00:01, 14.81it/s, est. speed input: 15489.29 toks/s, output: 15.13 toks/s]
Processed prompts:  91%|| 234/256 [00:15<00:01, 14.79it/s, est. speed input: 15485.96 toks/s, output: 15.12 toks/s]
Processed prompts:  92%|| 236/256 [00:15<00:01, 14.72it/s, est. speed input: 15480.70 toks/s, output: 15.12 toks/s]
Processed prompts:  93%|| 238/256 [00:15<00:01, 14.76it/s, est. speed input: 15478.50 toks/s, output: 15.12 toks/s]
Processed prompts:  94%|| 240/256 [00:15<00:01, 14.83it/s, est. speed input: 15477.52 toks/s, output: 15.11 toks/s]
Processed prompts:  95%|| 242/256 [00:16<00:00, 14.75it/s, est. speed input: 15472.77 toks/s, output: 15.11 toks/s]
Processed prompts:  95%|| 244/256 [00:16<00:00, 14.68it/s, est. speed input: 15467.48 toks/s, output: 15.10 toks/s]
Processed prompts:  96%|| 246/256 [00:16<00:00, 14.76it/s, est. speed input: 15466.12 toks/s, output: 15.10 toks/s]
Processed prompts:  97%|| 248/256 [00:16<00:00, 14.74it/s, est. speed input: 15462.84 toks/s, output: 15.10 toks/s]
Processed prompts:  98%|| 250/256 [00:16<00:00, 14.70it/s, est. speed input: 15458.69 toks/s, output: 15.10 toks/s]
Processed prompts:  98%|| 252/256 [00:16<00:00, 14.82it/s, est. speed input: 15458.75 toks/s, output: 15.10 toks/s]
Processed prompts:  99%|| 254/256 [00:16<00:00, 14.81it/s, est. speed input: 15456.18 toks/s, output: 15.09 toks/s]
Processed prompts: 100%|| 256/256 [00:16<00:00, 14.81it/s, est. speed input: 15516.61 toks/s, output: 15.15 toks/s]
Processed prompts: 100%|| 256/256 [00:16<00:00, 15.15it/s, est. speed input: 15516.61 toks/s, output: 15.15 toks/s]
[rank0]:[W126 12:01:27.578834375 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-26 12:01:29
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Llama3.2-3B-FP8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 12:01:34 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 12:01:34 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1264021) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1264021) WARNING 01-26 12:02:01 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 14.04 requests/s, 14387.31 total tokens/s, 14.04 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-26 12:01:34] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 12:01:34] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 12:01:34] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 12:01:34] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:01:34] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:01:34] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:01:34] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:01:34] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:01:34] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 12:01:34] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:01:34] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:01:34] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:01:34] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:01:34] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 12:01:38] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 12:01:38] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 12:01:38] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 12:01:38] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:01:38] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:01:38] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:01:38] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:01:38] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:01:38] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 12:01:38] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:01:38] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:01:38] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:01:38] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:01:38] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1264021) [2026-01-26 12:01:39] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1264021) [2026-01-26 12:01:39] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1264021) [2026-01-26 12:01:39] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1264021) [2026-01-26 12:01:39] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1264021) [2026-01-26 12:01:39] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1264021) [2026-01-26 12:01:39] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1264021) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1264021) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:15<00:00, 15.87s/it]
(EngineCore_DP0 pid=1264021) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:15<00:00, 15.87s/it]
(EngineCore_DP0 pid=1264021) 
(EngineCore_DP0 pid=1264021) [2026-01-26 12:01:55] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 3072] -> 1D uint8
(EngineCore_DP0 pid=1264021) [2026-01-26 12:01:55] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9830400 bytes
(EngineCore_DP0 pid=1264021) [2026-01-26 12:01:55] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=1264021) [2026-01-26 12:01:55] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5898240 bytes
(EngineCore_DP0 pid=1264021) [2026-01-26 12:01:55] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=1264021) [2026-01-26 12:01:55] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 31457280 bytes
(EngineCore_DP0 pid=1264021) [2026-01-26 12:01:55] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 8192] -> 1D uint8
(EngineCore_DP0 pid=1264021) [2026-01-26 12:01:55] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15728640 bytes
(EngineCore_DP0 pid=1264021) 2026-01-26 12:02:01,040 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1264021) 2026-01-26 12:02:01,050 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:  10%|         | 52/512 [00:00<00:00, 517.87it/s]
Adding requests:  20%|        | 104/512 [00:00<00:00, 495.20it/s]
Adding requests:  31%|       | 157/512 [00:00<00:00, 508.23it/s]
Adding requests:  41%|      | 208/512 [00:00<00:00, 506.50it/s]
Adding requests:  51%|     | 262/512 [00:00<00:00, 513.27it/s]
Adding requests:  61%|   | 314/512 [00:00<00:00, 506.11it/s]
Adding requests:  72%|  | 368/512 [00:00<00:00, 514.65it/s]
Adding requests:  82%| | 420/512 [00:00<00:00, 497.76it/s]
Adding requests:  92%|| 473/512 [00:00<00:00, 506.51it/s]
Adding requests: 100%|| 512/512 [00:01<00:00, 505.92it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   3%|         | 14/512 [00:00<00:10, 49.17it/s, est. speed input: 50355.49 toks/s, output: 49.17 toks/s]
Processed prompts:   4%|         | 19/512 [00:00<00:16, 30.47it/s, est. speed input: 34069.47 toks/s, output: 33.27 toks/s]
Processed prompts:   4%|         | 23/512 [00:00<00:21, 23.11it/s, est. speed input: 27627.21 toks/s, output: 26.98 toks/s]
Processed prompts:   5%|         | 26/512 [00:01<00:26, 18.22it/s, est. speed input: 23482.72 toks/s, output: 22.93 toks/s]
Processed prompts:   6%|         | 30/512 [00:01<00:28, 16.67it/s, est. speed input: 21624.76 toks/s, output: 21.12 toks/s]
Processed prompts:   7%|         | 34/512 [00:01<00:30, 15.74it/s, est. speed input: 20395.00 toks/s, output: 19.92 toks/s]
Processed prompts:   7%|         | 38/512 [00:01<00:31, 15.23it/s, est. speed input: 19560.10 toks/s, output: 19.10 toks/s]
Processed prompts:   8%|         | 42/512 [00:02<00:31, 14.89it/s, est. speed input: 18928.81 toks/s, output: 18.48 toks/s]
Processed prompts:   9%|         | 46/512 [00:02<00:31, 14.59it/s, est. speed input: 18407.79 toks/s, output: 17.98 toks/s]
Processed prompts:  10%|         | 50/512 [00:02<00:31, 14.45it/s, est. speed input: 18016.62 toks/s, output: 17.59 toks/s]
Processed prompts:  11%|         | 54/512 [00:03<00:31, 14.37it/s, est. speed input: 17702.57 toks/s, output: 17.29 toks/s]
Processed prompts:  11%|        | 58/512 [00:03<00:31, 14.31it/s, est. speed input: 17436.78 toks/s, output: 17.03 toks/s]
Processed prompts:  12%|        | 62/512 [00:03<00:31, 14.21it/s, est. speed input: 17195.49 toks/s, output: 16.79 toks/s]
Processed prompts:  13%|        | 66/512 [00:03<00:31, 14.15it/s, est. speed input: 16992.54 toks/s, output: 16.59 toks/s]
Processed prompts:  14%|        | 70/512 [00:04<00:31, 14.19it/s, est. speed input: 16835.86 toks/s, output: 16.44 toks/s]
Processed prompts:  14%|        | 74/512 [00:04<00:30, 14.16it/s, est. speed input: 16686.32 toks/s, output: 16.30 toks/s]
Processed prompts:  15%|        | 78/512 [00:04<00:30, 14.08it/s, est. speed input: 16539.25 toks/s, output: 16.15 toks/s]
Processed prompts:  16%|        | 82/512 [00:05<00:30, 14.07it/s, est. speed input: 16420.09 toks/s, output: 16.04 toks/s]
Processed prompts:  17%|        | 86/512 [00:05<00:30, 14.13it/s, est. speed input: 16325.93 toks/s, output: 15.94 toks/s]
Processed prompts:  18%|        | 90/512 [00:05<00:30, 14.00it/s, est. speed input: 16208.83 toks/s, output: 15.83 toks/s]
Processed prompts:  18%|        | 94/512 [00:05<00:29, 14.02it/s, est. speed input: 16122.10 toks/s, output: 15.74 toks/s]
Processed prompts:  19%|        | 98/512 [00:06<00:29, 14.06it/s, est. speed input: 16048.19 toks/s, output: 15.67 toks/s]
Processed prompts:  20%|        | 102/512 [00:06<00:29, 14.08it/s, est. speed input: 15980.27 toks/s, output: 15.61 toks/s]
Processed prompts:  21%|        | 106/512 [00:06<00:28, 14.03it/s, est. speed input: 15906.43 toks/s, output: 15.53 toks/s]
Processed prompts:  21%|       | 110/512 [00:07<00:28, 14.04it/s, est. speed input: 15846.66 toks/s, output: 15.48 toks/s]
Processed prompts:  22%|       | 114/512 [00:07<00:28, 14.04it/s, est. speed input: 15789.70 toks/s, output: 15.42 toks/s]
Processed prompts:  23%|       | 118/512 [00:07<00:28, 14.06it/s, est. speed input: 15740.34 toks/s, output: 15.37 toks/s]
Processed prompts:  24%|       | 122/512 [00:07<00:27, 14.01it/s, est. speed input: 15684.98 toks/s, output: 15.32 toks/s]
Processed prompts:  25%|       | 126/512 [00:08<00:27, 14.01it/s, est. speed input: 15639.57 toks/s, output: 15.27 toks/s]
Processed prompts:  25%|       | 130/512 [00:08<00:27, 14.04it/s, est. speed input: 15599.46 toks/s, output: 15.23 toks/s]
Processed prompts:  26%|       | 134/512 [00:08<00:27, 13.99it/s, est. speed input: 15553.99 toks/s, output: 15.19 toks/s]
Processed prompts:  27%|       | 138/512 [00:09<00:26, 14.05it/s, est. speed input: 15522.31 toks/s, output: 15.16 toks/s]
Processed prompts:  28%|       | 142/512 [00:09<00:26, 14.07it/s, est. speed input: 15489.77 toks/s, output: 15.13 toks/s]
Processed prompts:  29%|       | 146/512 [00:09<00:25, 14.08it/s, est. speed input: 15459.49 toks/s, output: 15.10 toks/s]
Processed prompts:  29%|       | 150/512 [00:09<00:25, 14.03it/s, est. speed input: 15424.00 toks/s, output: 15.06 toks/s]
Processed prompts:  30%|       | 154/512 [00:10<00:25, 14.06it/s, est. speed input: 15398.41 toks/s, output: 15.04 toks/s]
Processed prompts:  31%|       | 158/512 [00:10<00:25, 14.08it/s, est. speed input: 15372.82 toks/s, output: 15.01 toks/s]
Processed prompts:  32%|      | 162/512 [00:10<00:24, 14.09it/s, est. speed input: 15349.21 toks/s, output: 14.99 toks/s]
Processed prompts:  32%|      | 166/512 [00:11<00:24, 14.04it/s, est. speed input: 15320.35 toks/s, output: 14.96 toks/s]
Processed prompts:  33%|      | 170/512 [00:11<00:24, 14.09it/s, est. speed input: 15301.30 toks/s, output: 14.94 toks/s]
Processed prompts:  34%|      | 174/512 [00:11<00:23, 14.09it/s, est. speed input: 15280.44 toks/s, output: 14.92 toks/s]
Processed prompts:  35%|      | 178/512 [00:11<00:23, 14.12it/s, est. speed input: 15262.85 toks/s, output: 14.91 toks/s]
Processed prompts:  36%|      | 182/512 [00:12<00:23, 14.06it/s, est. speed input: 15238.62 toks/s, output: 14.88 toks/s]
Processed prompts:  36%|      | 186/512 [00:12<00:23, 14.05it/s, est. speed input: 15219.26 toks/s, output: 14.86 toks/s]
Processed prompts:  37%|      | 190/512 [00:12<00:22, 14.10it/s, est. speed input: 15204.25 toks/s, output: 14.85 toks/s]
Processed prompts:  38%|      | 194/512 [00:13<00:22, 14.06it/s, est. speed input: 15184.60 toks/s, output: 14.83 toks/s]
Processed prompts:  39%|      | 198/512 [00:13<00:22, 14.05it/s, est. speed input: 15167.24 toks/s, output: 14.81 toks/s]
Processed prompts:  39%|      | 202/512 [00:13<00:22, 14.04it/s, est. speed input: 15150.52 toks/s, output: 14.80 toks/s]
Processed prompts:  40%|      | 206/512 [00:13<00:21, 14.04it/s, est. speed input: 15134.59 toks/s, output: 14.78 toks/s]
Processed prompts:  41%|      | 210/512 [00:14<00:21, 14.03it/s, est. speed input: 15118.36 toks/s, output: 14.76 toks/s]
Processed prompts:  42%|     | 214/512 [00:14<00:21, 14.06it/s, est. speed input: 15105.90 toks/s, output: 14.75 toks/s]
Processed prompts:  43%|     | 218/512 [00:14<00:20, 14.08it/s, est. speed input: 15093.86 toks/s, output: 14.74 toks/s]
Processed prompts:  43%|     | 222/512 [00:15<00:20, 14.09it/s, est. speed input: 15081.86 toks/s, output: 14.73 toks/s]
Processed prompts:  44%|     | 226/512 [00:15<00:20, 14.01it/s, est. speed input: 15064.05 toks/s, output: 14.71 toks/s]
Processed prompts:  45%|     | 230/512 [00:15<00:20, 14.02it/s, est. speed input: 15051.63 toks/s, output: 14.70 toks/s]
Processed prompts:  46%|     | 234/512 [00:15<00:19, 14.08it/s, est. speed input: 15043.40 toks/s, output: 14.69 toks/s]
Processed prompts:  46%|     | 238/512 [00:16<00:19, 14.10it/s, est. speed input: 15033.33 toks/s, output: 14.68 toks/s]
Processed prompts:  47%|     | 242/512 [00:16<00:19, 14.00it/s, est. speed input: 15017.30 toks/s, output: 14.67 toks/s]
Processed prompts:  48%|     | 246/512 [00:16<00:18, 14.06it/s, est. speed input: 15008.89 toks/s, output: 14.66 toks/s]
Processed prompts:  49%|     | 250/512 [00:17<00:18, 14.07it/s, est. speed input: 14999.67 toks/s, output: 14.65 toks/s]
Processed prompts:  50%|     | 254/512 [00:17<00:18, 14.03it/s, est. speed input: 14987.59 toks/s, output: 14.64 toks/s]
Processed prompts:  50%|     | 258/512 [00:17<00:18, 14.04it/s, est. speed input: 14978.24 toks/s, output: 14.63 toks/s]
Processed prompts:  51%|     | 262/512 [00:17<00:17, 14.09it/s, est. speed input: 14971.09 toks/s, output: 14.62 toks/s]
Processed prompts:  52%|    | 266/512 [00:18<00:17, 14.07it/s, est. speed input: 14961.55 toks/s, output: 14.61 toks/s]
Processed prompts:  53%|    | 270/512 [00:18<00:17, 14.00it/s, est. speed input: 14949.35 toks/s, output: 14.60 toks/s]
Processed prompts:  54%|    | 274/512 [00:18<00:16, 14.04it/s, est. speed input: 14942.36 toks/s, output: 14.59 toks/s]
Processed prompts:  54%|    | 278/512 [00:19<00:16, 14.06it/s, est. speed input: 14934.66 toks/s, output: 14.58 toks/s]
Processed prompts:  55%|    | 282/512 [00:19<00:16, 14.09it/s, est. speed input: 14928.64 toks/s, output: 14.58 toks/s]
Processed prompts:  56%|    | 286/512 [00:19<00:16, 14.02it/s, est. speed input: 14917.76 toks/s, output: 14.57 toks/s]
Processed prompts:  57%|    | 290/512 [00:19<00:15, 14.06it/s, est. speed input: 14911.50 toks/s, output: 14.56 toks/s]
Processed prompts:  57%|    | 294/512 [00:20<00:15, 14.05it/s, est. speed input: 14904.08 toks/s, output: 14.55 toks/s]
Processed prompts:  58%|    | 298/512 [00:20<00:15, 14.03it/s, est. speed input: 14895.86 toks/s, output: 14.55 toks/s]
Processed prompts:  59%|    | 302/512 [00:20<00:15, 13.98it/s, est. speed input: 14886.01 toks/s, output: 14.54 toks/s]
Processed prompts:  60%|    | 306/512 [00:21<00:14, 14.01it/s, est. speed input: 14879.94 toks/s, output: 14.53 toks/s]
Processed prompts:  61%|    | 310/512 [00:21<00:14, 14.04it/s, est. speed input: 14874.21 toks/s, output: 14.53 toks/s]
Processed prompts:  61%|   | 314/512 [00:21<00:14, 14.01it/s, est. speed input: 14866.14 toks/s, output: 14.52 toks/s]
Processed prompts:  62%|   | 318/512 [00:21<00:13, 14.08it/s, est. speed input: 14862.46 toks/s, output: 14.51 toks/s]
Processed prompts:  63%|   | 322/512 [00:22<00:13, 14.05it/s, est. speed input: 14855.34 toks/s, output: 14.51 toks/s]
Processed prompts:  64%|   | 326/512 [00:22<00:13, 14.04it/s, est. speed input: 14849.20 toks/s, output: 14.50 toks/s]
Processed prompts:  64%|   | 330/512 [00:22<00:13, 13.98it/s, est. speed input: 14840.57 toks/s, output: 14.49 toks/s]
Processed prompts:  65%|   | 334/512 [00:23<00:12, 14.03it/s, est. speed input: 14836.17 toks/s, output: 14.49 toks/s]
Processed prompts:  66%|   | 338/512 [00:23<00:12, 14.05it/s, est. speed input: 14831.27 toks/s, output: 14.48 toks/s]
Processed prompts:  67%|   | 342/512 [00:23<00:11, 14.68it/s, est. speed input: 14851.74 toks/s, output: 14.50 toks/s]
Processed prompts:  68%|   | 346/512 [00:23<00:11, 14.41it/s, est. speed input: 14842.92 toks/s, output: 14.50 toks/s]
Processed prompts:  68%|   | 350/512 [00:24<00:11, 14.33it/s, est. speed input: 14838.93 toks/s, output: 14.49 toks/s]
Processed prompts:  69%|   | 354/512 [00:24<00:11, 14.23it/s, est. speed input: 14833.02 toks/s, output: 14.49 toks/s]
Processed prompts:  70%|   | 358/512 [00:24<00:10, 14.20it/s, est. speed input: 14828.77 toks/s, output: 14.48 toks/s]
Processed prompts:  71%|   | 362/512 [00:25<00:10, 14.10it/s, est. speed input: 14821.61 toks/s, output: 14.47 toks/s]
Processed prompts:  71%|  | 366/512 [00:25<00:10, 14.11it/s, est. speed input: 14817.53 toks/s, output: 14.47 toks/s]
Processed prompts:  72%|  | 370/512 [00:25<00:10, 14.08it/s, est. speed input: 14812.45 toks/s, output: 14.47 toks/s]
Processed prompts:  73%|  | 374/512 [00:25<00:09, 14.05it/s, est. speed input: 14807.12 toks/s, output: 14.46 toks/s]
Processed prompts:  74%|  | 378/512 [00:26<00:09, 14.03it/s, est. speed input: 14801.47 toks/s, output: 14.45 toks/s]
Processed prompts:  75%|  | 382/512 [00:26<00:09, 14.03it/s, est. speed input: 14796.92 toks/s, output: 14.45 toks/s]
Processed prompts:  75%|  | 386/512 [00:26<00:08, 14.02it/s, est. speed input: 14791.97 toks/s, output: 14.45 toks/s]
Processed prompts:  76%|  | 390/512 [00:27<00:08, 13.96it/s, est. speed input: 14784.99 toks/s, output: 14.44 toks/s]
Processed prompts:  77%|  | 394/512 [00:27<00:08, 14.01it/s, est. speed input: 14781.81 toks/s, output: 14.44 toks/s]
Processed prompts:  78%|  | 398/512 [00:27<00:08, 14.07it/s, est. speed input: 14779.39 toks/s, output: 14.43 toks/s]
Processed prompts:  79%|  | 402/512 [00:27<00:07, 14.08it/s, est. speed input: 14775.96 toks/s, output: 14.43 toks/s]
Processed prompts:  79%|  | 406/512 [00:28<00:07, 14.02it/s, est. speed input: 14770.18 toks/s, output: 14.42 toks/s]
Processed prompts:  80%|  | 410/512 [00:28<00:07, 14.03it/s, est. speed input: 14766.33 toks/s, output: 14.42 toks/s]
Processed prompts:  81%|  | 414/512 [00:28<00:06, 14.06it/s, est. speed input: 14763.50 toks/s, output: 14.42 toks/s]
Processed prompts:  82%| | 418/512 [00:29<00:06, 14.05it/s, est. speed input: 14759.59 toks/s, output: 14.41 toks/s]
Processed prompts:  82%| | 422/512 [00:29<00:06, 13.97it/s, est. speed input: 14753.23 toks/s, output: 14.41 toks/s]
Processed prompts:  83%| | 426/512 [00:29<00:06, 14.02it/s, est. speed input: 14750.51 toks/s, output: 14.40 toks/s]
Processed prompts:  84%| | 430/512 [00:29<00:05, 14.03it/s, est. speed input: 14747.04 toks/s, output: 14.40 toks/s]
Processed prompts:  85%| | 434/512 [00:30<00:05, 14.00it/s, est. speed input: 14742.47 toks/s, output: 14.40 toks/s]
Processed prompts:  86%| | 438/512 [00:30<00:05, 14.03it/s, est. speed input: 14739.59 toks/s, output: 14.39 toks/s]
Processed prompts:  86%| | 442/512 [00:30<00:04, 14.03it/s, est. speed input: 14736.17 toks/s, output: 14.39 toks/s]
Processed prompts:  87%| | 446/512 [00:30<00:04, 14.05it/s, est. speed input: 14733.25 toks/s, output: 14.39 toks/s]
Processed prompts:  88%| | 450/512 [00:31<00:04, 14.73it/s, est. speed input: 14750.74 toks/s, output: 14.41 toks/s]
Processed prompts:  89%| | 454/512 [00:31<00:03, 14.54it/s, est. speed input: 14748.11 toks/s, output: 14.40 toks/s]
Processed prompts:  89%| | 458/512 [00:31<00:03, 14.38it/s, est. speed input: 14744.50 toks/s, output: 14.40 toks/s]
Processed prompts:  90%| | 462/512 [00:32<00:03, 14.30it/s, est. speed input: 14742.02 toks/s, output: 14.40 toks/s]
Processed prompts:  91%| | 466/512 [00:32<00:03, 14.19it/s, est. speed input: 14737.87 toks/s, output: 14.39 toks/s]
Processed prompts:  92%|| 470/512 [00:32<00:02, 14.15it/s, est. speed input: 14734.98 toks/s, output: 14.39 toks/s]
Processed prompts:  93%|| 474/512 [00:32<00:02, 14.12it/s, est. speed input: 14731.92 toks/s, output: 14.39 toks/s]
Processed prompts:  93%|| 478/512 [00:33<00:02, 14.11it/s, est. speed input: 14729.24 toks/s, output: 14.38 toks/s]
Processed prompts:  94%|| 482/512 [00:33<00:02, 14.05it/s, est. speed input: 14725.01 toks/s, output: 14.38 toks/s]
Processed prompts:  95%|| 486/512 [00:33<00:01, 14.08it/s, est. speed input: 14723.12 toks/s, output: 14.38 toks/s]
Processed prompts:  96%|| 490/512 [00:34<00:01, 14.07it/s, est. speed input: 14720.19 toks/s, output: 14.38 toks/s]
Processed prompts:  96%|| 494/512 [00:34<00:01, 14.08it/s, est. speed input: 14717.88 toks/s, output: 14.37 toks/s]
Processed prompts:  97%|| 498/512 [00:34<00:00, 14.00it/s, est. speed input: 14713.29 toks/s, output: 14.37 toks/s]
Processed prompts:  98%|| 502/512 [00:34<00:00, 14.05it/s, est. speed input: 14711.68 toks/s, output: 14.37 toks/s]
Processed prompts:  99%|| 506/512 [00:35<00:00, 14.04it/s, est. speed input: 14708.70 toks/s, output: 14.36 toks/s]
Processed prompts: 100%|| 510/512 [00:35<00:00, 14.80it/s, est. speed input: 14726.30 toks/s, output: 14.38 toks/s]
Processed prompts: 100%|| 512/512 [00:35<00:00, 14.80it/s, est. speed input: 14784.01 toks/s, output: 14.44 toks/s]
Processed prompts: 100%|| 512/512 [00:35<00:00, 14.44it/s, est. speed input: 14784.01 toks/s, output: 14.44 toks/s]
[rank0]:[W126 12:02:38.751192717 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-26 12:02:40
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Llama3.2-3B-FP8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 12:02:47 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 12:02:47 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1265209) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1265209) WARNING 01-26 12:03:14 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 14.15 requests/s, 14507.39 total tokens/s, 14.15 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-26 12:02:47] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 12:02:47] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 12:02:47] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 12:02:47] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:02:47] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:02:47] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:02:47] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:02:47] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:02:47] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 12:02:47] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:02:47] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:02:47] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:02:47] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:02:47] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 12:02:50] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 12:02:50] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 12:02:50] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 12:02:50] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:02:50] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:02:50] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:02:50] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:02:50] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:02:50] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 12:02:50] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:02:50] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:02:50] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:02:50] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:02:50] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1265209) [2026-01-26 12:02:51] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1265209) [2026-01-26 12:02:51] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1265209) [2026-01-26 12:02:51] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1265209) [2026-01-26 12:02:51] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1265209) [2026-01-26 12:02:51] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1265209) [2026-01-26 12:02:51] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1265209) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1265209) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:15<00:00, 15.53s/it]
(EngineCore_DP0 pid=1265209) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:15<00:00, 15.53s/it]
(EngineCore_DP0 pid=1265209) 
(EngineCore_DP0 pid=1265209) [2026-01-26 12:03:07] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 3072] -> 1D uint8
(EngineCore_DP0 pid=1265209) [2026-01-26 12:03:07] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9830400 bytes
(EngineCore_DP0 pid=1265209) [2026-01-26 12:03:07] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=1265209) [2026-01-26 12:03:07] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5898240 bytes
(EngineCore_DP0 pid=1265209) [2026-01-26 12:03:07] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=1265209) [2026-01-26 12:03:07] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 31457280 bytes
(EngineCore_DP0 pid=1265209) [2026-01-26 12:03:07] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 8192] -> 1D uint8
(EngineCore_DP0 pid=1265209) [2026-01-26 12:03:07] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15728640 bytes
(EngineCore_DP0 pid=1265209) 2026-01-26 12:03:13,504 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1265209) 2026-01-26 12:03:13,567 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   5%|         | 55/1024 [00:00<00:01, 541.55it/s]
Adding requests:  11%|         | 110/1024 [00:00<00:01, 497.08it/s]
Adding requests:  16%|        | 160/1024 [00:00<00:01, 493.47it/s]
Adding requests:  21%|        | 210/1024 [00:00<00:01, 495.24it/s]
Adding requests:  25%|       | 261/1024 [00:00<00:01, 497.84it/s]
Adding requests:  30%|       | 311/1024 [00:00<00:01, 494.99it/s]
Adding requests:  35%|      | 361/1024 [00:00<00:01, 495.01it/s]
Adding requests:  40%|      | 411/1024 [00:00<00:01, 492.09it/s]
Adding requests:  45%|     | 461/1024 [00:00<00:01, 484.52it/s]
Adding requests:  50%|     | 510/1024 [00:01<00:01, 483.61it/s]
Adding requests:  55%|    | 559/1024 [00:01<00:01, 461.85it/s]
Adding requests:  59%|    | 606/1024 [00:01<00:00, 462.03it/s]
Adding requests:  64%|   | 653/1024 [00:01<00:00, 463.37it/s]
Adding requests:  69%|   | 704/1024 [00:01<00:00, 476.00it/s]
Adding requests:  74%|  | 753/1024 [00:01<00:00, 478.07it/s]
Adding requests:  78%|  | 802/1024 [00:01<00:00, 479.19it/s]
Adding requests:  83%| | 850/1024 [00:01<00:00, 472.92it/s]
Adding requests:  88%| | 902/1024 [00:01<00:00, 484.59it/s]
Adding requests:  93%|| 951/1024 [00:01<00:00, 473.09it/s]
Adding requests:  98%|| 1001/1024 [00:02<00:00, 479.69it/s]
Adding requests: 100%|| 1024/1024 [00:02<00:00, 482.38it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   3%|         | 26/1024 [00:00<00:11, 86.14it/s, est. speed input: 88221.75 toks/s, output: 86.14 toks/s]
Processed prompts:   3%|         | 35/1024 [00:00<00:28, 34.98it/s, est. speed input: 41285.56 toks/s, output: 40.32 toks/s]
Processed prompts:   4%|         | 42/1024 [00:01<00:41, 23.58it/s, est. speed input: 30115.40 toks/s, output: 29.41 toks/s]
Processed prompts:   5%|         | 50/1024 [00:01<00:49, 19.53it/s, est. speed input: 25622.32 toks/s, output: 25.02 toks/s]
Processed prompts:   6%|         | 58/1024 [00:02<00:55, 17.55it/s, est. speed input: 23196.28 toks/s, output: 22.65 toks/s]
Processed prompts:   6%|         | 66/1024 [00:03<00:58, 16.38it/s, est. speed input: 21634.38 toks/s, output: 21.13 toks/s]
Processed prompts:   7%|         | 74/1024 [00:03<01:00, 15.62it/s, est. speed input: 20531.21 toks/s, output: 20.05 toks/s]
Processed prompts:   8%|         | 82/1024 [00:04<01:02, 15.18it/s, est. speed input: 19746.63 toks/s, output: 19.28 toks/s]
Processed prompts:   9%|         | 90/1024 [00:04<01:02, 14.84it/s, est. speed input: 19120.62 toks/s, output: 18.67 toks/s]
Processed prompts:  10%|         | 98/1024 [00:05<01:03, 14.66it/s, est. speed input: 18649.62 toks/s, output: 18.21 toks/s]
Processed prompts:  10%|         | 106/1024 [00:05<01:03, 14.50it/s, est. speed input: 18252.38 toks/s, output: 17.82 toks/s]
Processed prompts:  11%|         | 114/1024 [00:06<01:03, 14.43it/s, est. speed input: 17940.90 toks/s, output: 17.52 toks/s]
Processed prompts:  12%|        | 122/1024 [00:07<01:02, 14.33it/s, est. speed input: 17658.59 toks/s, output: 17.24 toks/s]
Processed prompts:  13%|        | 130/1024 [00:07<01:02, 14.28it/s, est. speed input: 17425.11 toks/s, output: 17.02 toks/s]
Processed prompts:  13%|        | 138/1024 [00:08<01:02, 14.22it/s, est. speed input: 17218.89 toks/s, output: 16.82 toks/s]
Processed prompts:  14%|        | 146/1024 [00:08<01:01, 14.25it/s, est. speed input: 17055.27 toks/s, output: 16.66 toks/s]
Processed prompts:  15%|        | 154/1024 [00:09<01:01, 14.19it/s, est. speed input: 16891.75 toks/s, output: 16.50 toks/s]
Processed prompts:  16%|        | 162/1024 [00:09<01:00, 14.18it/s, est. speed input: 16756.31 toks/s, output: 16.36 toks/s]
Processed prompts:  17%|        | 170/1024 [00:10<01:00, 14.18it/s, est. speed input: 16635.52 toks/s, output: 16.25 toks/s]
Processed prompts:  17%|        | 178/1024 [00:11<00:59, 14.18it/s, est. speed input: 16527.80 toks/s, output: 16.14 toks/s]
Processed prompts:  18%|        | 186/1024 [00:11<00:59, 14.17it/s, est. speed input: 16427.96 toks/s, output: 16.04 toks/s]
Processed prompts:  19%|        | 194/1024 [00:12<00:58, 14.15it/s, est. speed input: 16334.83 toks/s, output: 15.95 toks/s]
Processed prompts:  20%|        | 202/1024 [00:12<00:58, 14.17it/s, est. speed input: 16255.86 toks/s, output: 15.87 toks/s]
Processed prompts:  21%|        | 210/1024 [00:13<00:57, 14.16it/s, est. speed input: 16180.29 toks/s, output: 15.80 toks/s]
Processed prompts:  21%|       | 218/1024 [00:13<00:56, 14.18it/s, est. speed input: 16115.35 toks/s, output: 15.74 toks/s]
Processed prompts:  22%|       | 226/1024 [00:14<00:56, 14.15it/s, est. speed input: 16048.32 toks/s, output: 15.67 toks/s]
Processed prompts:  23%|       | 234/1024 [00:14<00:55, 14.18it/s, est. speed input: 15993.28 toks/s, output: 15.62 toks/s]
Processed prompts:  24%|       | 242/1024 [00:15<00:55, 14.16it/s, est. speed input: 15937.14 toks/s, output: 15.56 toks/s]
Processed prompts:  24%|       | 250/1024 [00:16<00:54, 14.17it/s, est. speed input: 15888.13 toks/s, output: 15.52 toks/s]
Processed prompts:  25%|       | 258/1024 [00:16<00:54, 14.15it/s, est. speed input: 15839.27 toks/s, output: 15.47 toks/s]
Processed prompts:  26%|       | 266/1024 [00:17<00:53, 14.16it/s, est. speed input: 15796.25 toks/s, output: 15.43 toks/s]
Processed prompts:  27%|       | 274/1024 [00:17<00:53, 14.13it/s, est. speed input: 15751.13 toks/s, output: 15.38 toks/s]
Processed prompts:  28%|       | 282/1024 [00:18<00:52, 14.16it/s, est. speed input: 15715.46 toks/s, output: 15.35 toks/s]
Processed prompts:  28%|       | 290/1024 [00:18<00:51, 14.15it/s, est. speed input: 15677.87 toks/s, output: 15.31 toks/s]
Processed prompts:  29%|       | 298/1024 [00:19<00:51, 14.17it/s, est. speed input: 15645.23 toks/s, output: 15.28 toks/s]
Processed prompts:  30%|       | 306/1024 [00:20<00:50, 14.15it/s, est. speed input: 15611.62 toks/s, output: 15.25 toks/s]
Processed prompts:  31%|       | 314/1024 [00:20<00:50, 14.16it/s, est. speed input: 15581.98 toks/s, output: 15.22 toks/s]
Processed prompts:  31%|      | 322/1024 [00:21<00:49, 14.14it/s, est. speed input: 15550.83 toks/s, output: 15.19 toks/s]
Processed prompts:  32%|      | 330/1024 [00:21<00:49, 14.11it/s, est. speed input: 15520.59 toks/s, output: 15.16 toks/s]
Processed prompts:  33%|      | 338/1024 [00:22<00:47, 14.38it/s, est. speed input: 15517.69 toks/s, output: 15.15 toks/s]
Processed prompts:  34%|      | 346/1024 [00:22<00:47, 14.29it/s, est. speed input: 15490.69 toks/s, output: 15.13 toks/s]
Processed prompts:  35%|      | 354/1024 [00:23<00:47, 14.24it/s, est. speed input: 15465.90 toks/s, output: 15.10 toks/s]
Processed prompts:  35%|      | 362/1024 [00:24<00:46, 14.18it/s, est. speed input: 15440.09 toks/s, output: 15.08 toks/s]
Processed prompts:  36%|      | 370/1024 [00:24<00:46, 14.20it/s, est. speed input: 15420.54 toks/s, output: 15.06 toks/s]
Processed prompts:  37%|      | 378/1024 [00:25<00:45, 14.16it/s, est. speed input: 15397.42 toks/s, output: 15.04 toks/s]
Processed prompts:  38%|      | 386/1024 [00:25<00:44, 14.18it/s, est. speed input: 15379.25 toks/s, output: 15.02 toks/s]
Processed prompts:  38%|      | 394/1024 [00:26<00:44, 14.15it/s, est. speed input: 15358.25 toks/s, output: 15.00 toks/s]
Processed prompts:  39%|      | 402/1024 [00:26<00:43, 14.15it/s, est. speed input: 15339.92 toks/s, output: 14.98 toks/s]
Processed prompts:  40%|      | 410/1024 [00:27<00:43, 14.14it/s, est. speed input: 15321.56 toks/s, output: 14.96 toks/s]
Processed prompts:  41%|      | 418/1024 [00:27<00:42, 14.15it/s, est. speed input: 15305.78 toks/s, output: 14.95 toks/s]
Processed prompts:  42%|     | 426/1024 [00:28<00:42, 14.10it/s, est. speed input: 15286.11 toks/s, output: 14.93 toks/s]
Processed prompts:  42%|     | 434/1024 [00:29<00:41, 14.15it/s, est. speed input: 15272.97 toks/s, output: 14.91 toks/s]
Processed prompts:  43%|     | 442/1024 [00:29<00:41, 14.11it/s, est. speed input: 15254.99 toks/s, output: 14.90 toks/s]
Processed prompts:  44%|     | 450/1024 [00:30<00:39, 14.47it/s, est. speed input: 15263.73 toks/s, output: 14.91 toks/s]
Processed prompts:  45%|     | 458/1024 [00:30<00:39, 14.39it/s, est. speed input: 15250.86 toks/s, output: 14.89 toks/s]
Processed prompts:  46%|     | 466/1024 [00:31<00:38, 14.35it/s, est. speed input: 15238.87 toks/s, output: 14.88 toks/s]
Processed prompts:  46%|     | 474/1024 [00:31<00:38, 14.25it/s, est. speed input: 15223.41 toks/s, output: 14.87 toks/s]
Processed prompts:  47%|     | 482/1024 [00:32<00:38, 14.21it/s, est. speed input: 15210.01 toks/s, output: 14.85 toks/s]
Processed prompts:  48%|     | 490/1024 [00:33<00:37, 14.21it/s, est. speed input: 15198.46 toks/s, output: 14.84 toks/s]
Processed prompts:  49%|     | 498/1024 [00:33<00:37, 14.16it/s, est. speed input: 15184.76 toks/s, output: 14.83 toks/s]
Processed prompts:  49%|     | 506/1024 [00:34<00:36, 14.17it/s, est. speed input: 15174.05 toks/s, output: 14.82 toks/s]
Processed prompts:  50%|     | 514/1024 [00:34<00:36, 14.14it/s, est. speed input: 15161.32 toks/s, output: 14.81 toks/s]
Processed prompts:  51%|     | 522/1024 [00:35<00:35, 14.17it/s, est. speed input: 15152.27 toks/s, output: 14.80 toks/s]
Processed prompts:  52%|    | 530/1024 [00:35<00:34, 14.13it/s, est. speed input: 15139.73 toks/s, output: 14.78 toks/s]
Processed prompts:  53%|    | 538/1024 [00:36<00:34, 14.15it/s, est. speed input: 15130.67 toks/s, output: 14.78 toks/s]
Processed prompts:  53%|    | 546/1024 [00:36<00:33, 14.11it/s, est. speed input: 15118.57 toks/s, output: 14.76 toks/s]
Processed prompts:  54%|    | 554/1024 [00:37<00:33, 14.15it/s, est. speed input: 15110.47 toks/s, output: 14.76 toks/s]
Processed prompts:  55%|    | 562/1024 [00:38<00:32, 14.13it/s, est. speed input: 15100.20 toks/s, output: 14.75 toks/s]
Processed prompts:  56%|    | 570/1024 [00:38<00:32, 14.15it/s, est. speed input: 15092.10 toks/s, output: 14.74 toks/s]
Processed prompts:  56%|    | 578/1024 [00:39<00:31, 14.13it/s, est. speed input: 15082.49 toks/s, output: 14.73 toks/s]
Processed prompts:  57%|    | 586/1024 [00:39<00:30, 14.16it/s, est. speed input: 15075.02 toks/s, output: 14.72 toks/s]
Processed prompts:  58%|    | 594/1024 [00:40<00:30, 14.13it/s, est. speed input: 15065.68 toks/s, output: 14.71 toks/s]
Processed prompts:  59%|    | 602/1024 [00:40<00:29, 14.11it/s, est. speed input: 15056.46 toks/s, output: 14.70 toks/s]
Processed prompts:  60%|    | 610/1024 [00:41<00:29, 14.09it/s, est. speed input: 15047.09 toks/s, output: 14.69 toks/s]
Processed prompts:  60%|    | 618/1024 [00:42<00:28, 14.08it/s, est. speed input: 15038.20 toks/s, output: 14.69 toks/s]
Processed prompts:  61%|    | 626/1024 [00:42<00:28, 14.11it/s, est. speed input: 15031.60 toks/s, output: 14.68 toks/s]
Processed prompts:  62%|   | 634/1024 [00:43<00:27, 14.09it/s, est. speed input: 15022.88 toks/s, output: 14.67 toks/s]
Processed prompts:  63%|   | 642/1024 [00:43<00:26, 14.15it/s, est. speed input: 15018.00 toks/s, output: 14.67 toks/s]
Processed prompts:  63%|   | 650/1024 [00:44<00:26, 14.11it/s, est. speed input: 15009.55 toks/s, output: 14.66 toks/s]
Processed prompts:  64%|   | 658/1024 [00:44<00:25, 14.14it/s, est. speed input: 15003.61 toks/s, output: 14.65 toks/s]
Processed prompts:  65%|   | 666/1024 [00:45<00:25, 14.11it/s, est. speed input: 14995.76 toks/s, output: 14.64 toks/s]
Processed prompts:  66%|   | 674/1024 [00:46<00:24, 14.15it/s, est. speed input: 14990.82 toks/s, output: 14.64 toks/s]
Processed prompts:  67%|   | 682/1024 [00:46<00:24, 14.13it/s, est. speed input: 14983.81 toks/s, output: 14.63 toks/s]
Processed prompts:  67%|   | 690/1024 [00:47<00:23, 14.15it/s, est. speed input: 14978.35 toks/s, output: 14.63 toks/s]
Processed prompts:  68%|   | 698/1024 [00:47<00:23, 14.12it/s, est. speed input: 14971.61 toks/s, output: 14.62 toks/s]
Processed prompts:  69%|   | 706/1024 [00:48<00:22, 14.15it/s, est. speed input: 14966.85 toks/s, output: 14.62 toks/s]
Processed prompts:  70%|   | 714/1024 [00:48<00:21, 14.12it/s, est. speed input: 14959.81 toks/s, output: 14.61 toks/s]
Processed prompts:  71%|   | 722/1024 [00:49<00:21, 14.14it/s, est. speed input: 14955.08 toks/s, output: 14.60 toks/s]
Processed prompts:  71%|  | 730/1024 [00:50<00:20, 14.10it/s, est. speed input: 14948.20 toks/s, output: 14.60 toks/s]
Processed prompts:  72%|  | 738/1024 [00:50<00:20, 14.09it/s, est. speed input: 14942.16 toks/s, output: 14.59 toks/s]
Processed prompts:  73%|  | 746/1024 [00:51<00:19, 14.13it/s, est. speed input: 14937.75 toks/s, output: 14.59 toks/s]
Processed prompts:  74%|  | 754/1024 [00:51<00:19, 14.12it/s, est. speed input: 14932.29 toks/s, output: 14.58 toks/s]
Processed prompts:  74%|  | 762/1024 [00:52<00:18, 14.14it/s, est. speed input: 14927.98 toks/s, output: 14.58 toks/s]
Processed prompts:  75%|  | 770/1024 [00:52<00:17, 14.11it/s, est. speed input: 14922.15 toks/s, output: 14.57 toks/s]
Processed prompts:  76%|  | 778/1024 [00:53<00:17, 14.13it/s, est. speed input: 14917.88 toks/s, output: 14.57 toks/s]
Processed prompts:  77%|  | 786/1024 [00:53<00:16, 14.12it/s, est. speed input: 14912.82 toks/s, output: 14.56 toks/s]
Processed prompts:  78%|  | 794/1024 [00:54<00:16, 14.13it/s, est. speed input: 14908.56 toks/s, output: 14.56 toks/s]
Processed prompts:  78%|  | 802/1024 [00:55<00:15, 14.15it/s, est. speed input: 14904.60 toks/s, output: 14.56 toks/s]
Processed prompts:  79%|  | 810/1024 [00:55<00:15, 14.15it/s, est. speed input: 14900.35 toks/s, output: 14.55 toks/s]
Processed prompts:  80%|  | 818/1024 [00:56<00:14, 14.10it/s, est. speed input: 14894.42 toks/s, output: 14.55 toks/s]
Processed prompts:  81%|  | 826/1024 [00:56<00:14, 14.11it/s, est. speed input: 14890.33 toks/s, output: 14.54 toks/s]
Processed prompts:  81%| | 834/1024 [00:57<00:13, 14.10it/s, est. speed input: 14885.49 toks/s, output: 14.54 toks/s]
Processed prompts:  82%| | 842/1024 [00:57<00:12, 14.11it/s, est. speed input: 14881.66 toks/s, output: 14.53 toks/s]
Processed prompts:  83%| | 850/1024 [00:58<00:12, 14.11it/s, est. speed input: 14877.28 toks/s, output: 14.53 toks/s]
Processed prompts:  84%| | 858/1024 [00:59<00:11, 14.11it/s, est. speed input: 14873.32 toks/s, output: 14.52 toks/s]
Processed prompts:  85%| | 866/1024 [00:59<00:11, 14.10it/s, est. speed input: 14868.95 toks/s, output: 14.52 toks/s]
Processed prompts:  85%| | 874/1024 [01:00<00:10, 14.11it/s, est. speed input: 14865.14 toks/s, output: 14.52 toks/s]
Processed prompts:  86%| | 882/1024 [01:00<00:10, 14.11it/s, est. speed input: 14861.31 toks/s, output: 14.51 toks/s]
Processed prompts:  87%| | 890/1024 [01:01<00:09, 14.10it/s, est. speed input: 14857.18 toks/s, output: 14.51 toks/s]
Processed prompts:  88%| | 898/1024 [01:01<00:08, 14.12it/s, est. speed input: 14853.96 toks/s, output: 14.51 toks/s]
Processed prompts:  88%| | 906/1024 [01:02<00:08, 14.12it/s, est. speed input: 14850.49 toks/s, output: 14.50 toks/s]
Processed prompts:  89%| | 914/1024 [01:03<00:07, 14.13it/s, est. speed input: 14847.36 toks/s, output: 14.50 toks/s]
Processed prompts:  90%| | 922/1024 [01:03<00:07, 14.09it/s, est. speed input: 14842.53 toks/s, output: 14.49 toks/s]
Processed prompts:  91%| | 930/1024 [01:04<00:06, 14.13it/s, est. speed input: 14840.09 toks/s, output: 14.49 toks/s]
Processed prompts:  92%|| 938/1024 [01:04<00:05, 14.60it/s, est. speed input: 14850.82 toks/s, output: 14.50 toks/s]
Processed prompts:  92%|| 946/1024 [01:05<00:05, 14.50it/s, est. speed input: 14848.82 toks/s, output: 14.50 toks/s]
Processed prompts:  93%|| 954/1024 [01:05<00:04, 14.36it/s, est. speed input: 14844.67 toks/s, output: 14.50 toks/s]
Processed prompts:  94%|| 962/1024 [01:06<00:04, 14.30it/s, est. speed input: 14841.83 toks/s, output: 14.49 toks/s]
Processed prompts:  95%|| 970/1024 [01:06<00:03, 14.24it/s, est. speed input: 14838.40 toks/s, output: 14.49 toks/s]
Processed prompts:  96%|| 978/1024 [01:07<00:03, 14.23it/s, est. speed input: 14835.88 toks/s, output: 14.49 toks/s]
Processed prompts:  96%|| 986/1024 [01:08<00:02, 14.67it/s, est. speed input: 14845.95 toks/s, output: 14.50 toks/s]
Processed prompts:  97%|| 994/1024 [01:08<00:02, 14.50it/s, est. speed input: 14842.78 toks/s, output: 14.49 toks/s]
Processed prompts:  98%|| 1002/1024 [01:09<00:01, 14.38it/s, est. speed input: 14839.53 toks/s, output: 14.49 toks/s]
Processed prompts:  99%|| 1010/1024 [01:09<00:00, 14.32it/s, est. speed input: 14837.04 toks/s, output: 14.49 toks/s]
Processed prompts:  99%|| 1018/1024 [01:10<00:00, 14.64it/s, est. speed input: 14844.31 toks/s, output: 14.50 toks/s]
Processed prompts: 100%|| 1024/1024 [01:10<00:00, 14.64it/s, est. speed input: 14931.77 toks/s, output: 14.58 toks/s]
Processed prompts: 100%|| 1024/1024 [01:10<00:00, 14.58it/s, est. speed input: 14931.77 toks/s, output: 14.58 toks/s]
[rank0]:[W126 12:04:27.373391529 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-26 12:04:29
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Llama3.2-3B-FP8_M16384.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 12:04:38 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 12:04:38 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1266930) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1266930) WARNING 01-26 12:05:07 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 14.32 requests/s, 14674.08 total tokens/s, 14.32 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-26 12:04:38] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 12:04:38] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 12:04:38] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 12:04:38] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:04:38] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:04:38] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:04:38] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:04:38] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:04:38] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 12:04:38] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:04:38] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:04:38] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:04:38] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:04:38] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 12:04:42] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 12:04:42] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 12:04:42] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 12:04:42] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:04:42] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:04:42] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:04:42] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:04:42] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:04:42] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 12:04:42] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:04:42] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:04:42] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:04:42] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:04:42] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1266930) [2026-01-26 12:04:43] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1266930) [2026-01-26 12:04:43] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1266930) [2026-01-26 12:04:43] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1266930) [2026-01-26 12:04:43] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1266930) [2026-01-26 12:04:43] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1266930) [2026-01-26 12:04:43] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1266930) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1266930) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:15<00:00, 15.68s/it]
(EngineCore_DP0 pid=1266930) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:15<00:00, 15.68s/it]
(EngineCore_DP0 pid=1266930) 
(EngineCore_DP0 pid=1266930) [2026-01-26 12:04:59] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 3072] -> 1D uint8
(EngineCore_DP0 pid=1266930) [2026-01-26 12:04:59] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9830400 bytes
(EngineCore_DP0 pid=1266930) [2026-01-26 12:04:59] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=1266930) [2026-01-26 12:04:59] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5898240 bytes
(EngineCore_DP0 pid=1266930) [2026-01-26 12:04:59] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=1266930) [2026-01-26 12:04:59] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 31457280 bytes
(EngineCore_DP0 pid=1266930) [2026-01-26 12:04:59] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 8192] -> 1D uint8
(EngineCore_DP0 pid=1266930) [2026-01-26 12:04:59] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15728640 bytes
(EngineCore_DP0 pid=1266930) 2026-01-26 12:05:05,772 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1266930) 2026-01-26 12:05:05,901 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   3%|         | 54/2048 [00:00<00:03, 530.63it/s]
Adding requests:   5%|         | 108/2048 [00:00<00:03, 487.15it/s]
Adding requests:   8%|         | 157/2048 [00:00<00:03, 480.74it/s]
Adding requests:  10%|         | 206/2048 [00:00<00:03, 479.95it/s]
Adding requests:  12%|        | 256/2048 [00:00<00:03, 486.03it/s]
Adding requests:  15%|        | 305/2048 [00:00<00:03, 476.72it/s]
Adding requests:  17%|        | 358/2048 [00:00<00:03, 491.67it/s]
Adding requests:  20%|        | 408/2048 [00:00<00:03, 492.22it/s]
Adding requests:  22%|       | 459/2048 [00:00<00:03, 497.54it/s]
Adding requests:  25%|       | 509/2048 [00:01<00:03, 486.63it/s]
Adding requests:  27%|       | 558/2048 [00:01<00:03, 487.17it/s]
Adding requests:  30%|       | 607/2048 [00:01<00:02, 484.76it/s]
Adding requests:  32%|      | 656/2048 [00:01<00:02, 482.11it/s]
Adding requests:  34%|      | 705/2048 [00:01<00:02, 482.51it/s]
Adding requests:  37%|      | 754/2048 [00:01<00:02, 470.80it/s]
Adding requests:  39%|      | 802/2048 [00:01<00:02, 458.60it/s]
Adding requests:  42%|     | 850/2048 [00:01<00:02, 462.09it/s]
Adding requests:  44%|     | 897/2048 [00:02<00:07, 161.71it/s]
Adding requests:  46%|     | 947/2048 [00:02<00:05, 204.05it/s]
Adding requests:  49%|     | 995/2048 [00:02<00:04, 245.80it/s]
Adding requests:  51%|     | 1045/2048 [00:02<00:03, 290.84it/s]
Adding requests:  53%|    | 1094/2048 [00:02<00:02, 330.35it/s]
Adding requests:  56%|    | 1142/2048 [00:03<00:02, 363.30it/s]
Adding requests:  58%|    | 1194/2048 [00:03<00:02, 400.13it/s]
Adding requests:  61%|    | 1242/2048 [00:03<00:01, 419.78it/s]
Adding requests:  63%|   | 1290/2048 [00:03<00:01, 432.47it/s]
Adding requests:  65%|   | 1340/2048 [00:03<00:01, 450.58it/s]
Adding requests:  68%|   | 1391/2048 [00:03<00:01, 464.79it/s]
Adding requests:  70%|   | 1440/2048 [00:03<00:01, 464.71it/s]
Adding requests:  73%|  | 1491/2048 [00:03<00:01, 477.56it/s]
Adding requests:  75%|  | 1541/2048 [00:03<00:01, 481.34it/s]
Adding requests:  78%|  | 1590/2048 [00:03<00:00, 481.98it/s]
Adding requests:  80%|  | 1640/2048 [00:04<00:00, 486.11it/s]
Adding requests:  83%| | 1690/2048 [00:04<00:00, 486.07it/s]
Adding requests:  85%| | 1739/2048 [00:04<00:00, 486.20it/s]
Adding requests:  87%| | 1788/2048 [00:04<00:00, 483.01it/s]
Adding requests:  90%| | 1837/2048 [00:04<00:00, 480.79it/s]
Adding requests:  92%|| 1886/2048 [00:04<00:00, 482.83it/s]
Adding requests:  95%|| 1936/2048 [00:04<00:00, 484.11it/s]
Adding requests:  97%|| 1985/2048 [00:04<00:00, 477.73it/s]
Adding requests:  99%|| 2033/2048 [00:04<00:00, 451.04it/s]
Adding requests: 100%|| 2048/2048 [00:04<00:00, 417.10it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   3%|         | 66/2048 [00:00<00:25, 76.52it/s, est. speed input: 78358.33 toks/s, output: 76.52 toks/s]
Processed prompts:   4%|         | 82/2048 [00:01<00:54, 36.15it/s, est. speed input: 42422.13 toks/s, output: 41.43 toks/s]
Processed prompts:   5%|         | 98/2048 [00:03<01:16, 25.59it/s, est. speed input: 32351.71 toks/s, output: 31.59 toks/s]
Processed prompts:   6%|         | 114/2048 [00:04<01:32, 20.99it/s, est. speed input: 27652.64 toks/s, output: 27.00 toks/s]
Processed prompts:   6%|         | 130/2048 [00:05<01:43, 18.53it/s, est. speed input: 24928.63 toks/s, output: 24.34 toks/s]
Processed prompts:   7%|         | 146/2048 [00:06<01:51, 17.04it/s, est. speed input: 23127.85 toks/s, output: 22.59 toks/s]
Processed prompts:   8%|         | 162/2048 [00:07<01:56, 16.14it/s, est. speed input: 21873.05 toks/s, output: 21.36 toks/s]
Processed prompts:   9%|         | 178/2048 [00:08<02:00, 15.56it/s, est. speed input: 20948.21 toks/s, output: 20.46 toks/s]
Processed prompts:   9%|         | 194/2048 [00:09<02:02, 15.15it/s, est. speed input: 20225.92 toks/s, output: 19.75 toks/s]
Processed prompts:  10%|         | 210/2048 [00:10<02:03, 14.88it/s, est. speed input: 19652.63 toks/s, output: 19.19 toks/s]
Processed prompts:  11%|         | 226/2048 [00:12<02:03, 14.71it/s, est. speed input: 19191.67 toks/s, output: 18.74 toks/s]
Processed prompts:  12%|        | 242/2048 [00:13<02:03, 14.57it/s, est. speed input: 18797.71 toks/s, output: 18.36 toks/s]
Processed prompts:  13%|        | 258/2048 [00:14<02:03, 14.49it/s, est. speed input: 18474.63 toks/s, output: 18.04 toks/s]
Processed prompts:  13%|        | 274/2048 [00:15<02:02, 14.44it/s, est. speed input: 18197.16 toks/s, output: 17.77 toks/s]
Processed prompts:  14%|        | 290/2048 [00:16<02:02, 14.39it/s, est. speed input: 17955.85 toks/s, output: 17.53 toks/s]
Processed prompts:  15%|        | 306/2048 [00:17<02:01, 14.35it/s, est. speed input: 17742.46 toks/s, output: 17.33 toks/s]
Processed prompts:  16%|        | 322/2048 [00:18<02:00, 14.33it/s, est. speed input: 17556.25 toks/s, output: 17.14 toks/s]
Processed prompts:  17%|        | 338/2048 [00:19<01:57, 14.52it/s, est. speed input: 17436.98 toks/s, output: 17.03 toks/s]
Processed prompts:  17%|        | 354/2048 [00:20<01:57, 14.46it/s, est. speed input: 17289.83 toks/s, output: 16.88 toks/s]
Processed prompts:  18%|        | 370/2048 [00:22<01:56, 14.42it/s, est. speed input: 17157.28 toks/s, output: 16.76 toks/s]
Processed prompts:  19%|        | 386/2048 [00:23<01:55, 14.39it/s, est. speed input: 17037.53 toks/s, output: 16.64 toks/s]
Processed prompts:  20%|        | 402/2048 [00:24<01:54, 14.35it/s, est. speed input: 16925.59 toks/s, output: 16.53 toks/s]
Processed prompts:  20%|        | 418/2048 [00:25<01:53, 14.34it/s, est. speed input: 16824.78 toks/s, output: 16.43 toks/s]
Processed prompts:  21%|        | 434/2048 [00:26<01:52, 14.33it/s, est. speed input: 16733.94 toks/s, output: 16.34 toks/s]
Processed prompts:  22%|       | 450/2048 [00:27<01:49, 14.53it/s, est. speed input: 16681.65 toks/s, output: 16.29 toks/s]
Processed prompts:  23%|       | 466/2048 [00:28<01:49, 14.45it/s, est. speed input: 16601.08 toks/s, output: 16.21 toks/s]
Processed prompts:  24%|       | 482/2048 [00:29<01:48, 14.42it/s, est. speed input: 16529.16 toks/s, output: 16.14 toks/s]
Processed prompts:  24%|       | 498/2048 [00:30<01:47, 14.38it/s, est. speed input: 16460.45 toks/s, output: 16.07 toks/s]
Processed prompts:  25%|       | 514/2048 [00:32<01:46, 14.34it/s, est. speed input: 16394.92 toks/s, output: 16.01 toks/s]
Processed prompts:  26%|       | 530/2048 [00:33<01:46, 14.32it/s, est. speed input: 16335.11 toks/s, output: 15.95 toks/s]
Processed prompts:  27%|       | 546/2048 [00:34<01:44, 14.31it/s, est. speed input: 16279.72 toks/s, output: 15.90 toks/s]
Processed prompts:  27%|       | 562/2048 [00:35<01:43, 14.30it/s, est. speed input: 16226.77 toks/s, output: 15.85 toks/s]
Processed prompts:  28%|       | 578/2048 [00:36<01:42, 14.30it/s, est. speed input: 16178.55 toks/s, output: 15.80 toks/s]
Processed prompts:  29%|       | 594/2048 [00:37<01:41, 14.29it/s, est. speed input: 16131.77 toks/s, output: 15.75 toks/s]
Processed prompts:  30%|       | 610/2048 [00:38<01:40, 14.30it/s, est. speed input: 16089.51 toks/s, output: 15.71 toks/s]
Processed prompts:  31%|       | 626/2048 [00:39<01:39, 14.29it/s, est. speed input: 16047.93 toks/s, output: 15.67 toks/s]
Processed prompts:  31%|      | 642/2048 [00:41<01:38, 14.29it/s, est. speed input: 16009.43 toks/s, output: 15.63 toks/s]
Processed prompts:  32%|      | 658/2048 [00:42<01:37, 14.28it/s, est. speed input: 15972.11 toks/s, output: 15.60 toks/s]
Processed prompts:  33%|      | 674/2048 [00:43<01:36, 14.28it/s, est. speed input: 15937.03 toks/s, output: 15.56 toks/s]
Processed prompts:  34%|      | 690/2048 [00:44<01:35, 14.29it/s, est. speed input: 15904.80 toks/s, output: 15.53 toks/s]
Processed prompts:  34%|      | 706/2048 [00:45<01:33, 14.29it/s, est. speed input: 15873.97 toks/s, output: 15.50 toks/s]
Processed prompts:  35%|      | 722/2048 [00:46<01:32, 14.29it/s, est. speed input: 15844.26 toks/s, output: 15.47 toks/s]
Processed prompts:  36%|      | 738/2048 [00:47<01:31, 14.29it/s, est. speed input: 15815.44 toks/s, output: 15.44 toks/s]
Processed prompts:  37%|      | 754/2048 [00:48<01:30, 14.29it/s, est. speed input: 15788.29 toks/s, output: 15.42 toks/s]
Processed prompts:  38%|      | 770/2048 [00:50<01:29, 14.31it/s, est. speed input: 15763.88 toks/s, output: 15.39 toks/s]
Processed prompts:  38%|      | 786/2048 [00:51<01:28, 14.29it/s, est. speed input: 15738.29 toks/s, output: 15.37 toks/s]
Processed prompts:  39%|      | 802/2048 [00:52<01:27, 14.29it/s, est. speed input: 15714.87 toks/s, output: 15.35 toks/s]
Processed prompts:  40%|      | 818/2048 [00:53<01:26, 14.28it/s, est. speed input: 15691.36 toks/s, output: 15.32 toks/s]
Processed prompts:  41%|      | 834/2048 [00:54<01:25, 14.27it/s, est. speed input: 15668.44 toks/s, output: 15.30 toks/s]
Processed prompts:  42%|     | 850/2048 [00:55<01:23, 14.27it/s, est. speed input: 15647.14 toks/s, output: 15.28 toks/s]
Processed prompts:  42%|     | 866/2048 [00:56<01:22, 14.27it/s, est. speed input: 15626.73 toks/s, output: 15.26 toks/s]
Processed prompts:  43%|     | 882/2048 [00:57<01:21, 14.27it/s, est. speed input: 15607.29 toks/s, output: 15.24 toks/s]
Processed prompts:  44%|     | 898/2048 [00:58<01:20, 14.29it/s, est. speed input: 15589.34 toks/s, output: 15.22 toks/s]
Processed prompts:  45%|     | 914/2048 [01:00<01:19, 14.29it/s, est. speed input: 15571.84 toks/s, output: 15.21 toks/s]
Processed prompts:  45%|     | 930/2048 [01:01<01:16, 14.58it/s, est. speed input: 15573.43 toks/s, output: 15.21 toks/s]
Processed prompts:  46%|     | 946/2048 [01:02<01:16, 14.48it/s, est. speed input: 15555.50 toks/s, output: 15.19 toks/s]
Processed prompts:  47%|     | 962/2048 [01:03<01:15, 14.42it/s, est. speed input: 15539.38 toks/s, output: 15.18 toks/s]
Processed prompts:  48%|     | 978/2048 [01:04<01:13, 14.65it/s, est. speed input: 15539.96 toks/s, output: 15.18 toks/s]
Processed prompts:  49%|     | 994/2048 [01:05<01:12, 14.54it/s, est. speed input: 15524.75 toks/s, output: 15.16 toks/s]
Processed prompts:  49%|     | 1010/2048 [01:06<01:11, 14.46it/s, est. speed input: 15509.34 toks/s, output: 15.15 toks/s]
Processed prompts:  50%|     | 1026/2048 [01:07<01:10, 14.41it/s, est. speed input: 15494.82 toks/s, output: 15.13 toks/s]
Processed prompts:  51%|     | 1042/2048 [01:08<01:10, 14.36it/s, est. speed input: 15480.30 toks/s, output: 15.12 toks/s]
Processed prompts:  52%|    | 1058/2048 [01:10<01:09, 14.34it/s, est. speed input: 15466.83 toks/s, output: 15.10 toks/s]
Processed prompts:  52%|    | 1074/2048 [01:11<01:08, 14.32it/s, est. speed input: 15453.15 toks/s, output: 15.09 toks/s]
Processed prompts:  53%|    | 1090/2048 [01:12<01:06, 14.30it/s, est. speed input: 15440.00 toks/s, output: 15.08 toks/s]
Processed prompts:  54%|    | 1106/2048 [01:13<01:06, 14.27it/s, est. speed input: 15426.07 toks/s, output: 15.06 toks/s]
Processed prompts:  55%|    | 1122/2048 [01:14<01:04, 14.26it/s, est. speed input: 15413.13 toks/s, output: 15.05 toks/s]
Processed prompts:  56%|    | 1138/2048 [01:15<01:03, 14.26it/s, est. speed input: 15401.31 toks/s, output: 15.04 toks/s]
Processed prompts:  56%|    | 1154/2048 [01:16<01:01, 14.52it/s, est. speed input: 15403.02 toks/s, output: 15.04 toks/s]
Processed prompts:  57%|    | 1170/2048 [01:17<01:00, 14.44it/s, est. speed input: 15391.24 toks/s, output: 15.03 toks/s]
Processed prompts:  58%|    | 1186/2048 [01:18<00:59, 14.39it/s, est. speed input: 15380.51 toks/s, output: 15.02 toks/s]
Processed prompts:  59%|    | 1202/2048 [01:20<00:58, 14.35it/s, est. speed input: 15369.34 toks/s, output: 15.01 toks/s]
Processed prompts:  59%|    | 1218/2048 [01:21<00:57, 14.33it/s, est. speed input: 15359.15 toks/s, output: 15.00 toks/s]
Processed prompts:  60%|    | 1234/2048 [01:22<00:56, 14.31it/s, est. speed input: 15348.75 toks/s, output: 14.99 toks/s]
Processed prompts:  61%|    | 1250/2048 [01:23<00:55, 14.30it/s, est. speed input: 15339.03 toks/s, output: 14.98 toks/s]
Processed prompts:  62%|   | 1266/2048 [01:24<00:53, 14.55it/s, est. speed input: 15341.36 toks/s, output: 14.98 toks/s]
Processed prompts:  63%|   | 1282/2048 [01:25<00:52, 14.46it/s, est. speed input: 15331.51 toks/s, output: 14.97 toks/s]
Processed prompts:  63%|   | 1298/2048 [01:26<00:52, 14.39it/s, est. speed input: 15321.81 toks/s, output: 14.96 toks/s]
Processed prompts:  64%|   | 1314/2048 [01:27<00:51, 14.35it/s, est. speed input: 15312.41 toks/s, output: 14.95 toks/s]
Processed prompts:  65%|   | 1330/2048 [01:28<00:50, 14.31it/s, est. speed input: 15303.04 toks/s, output: 14.94 toks/s]
Processed prompts:  66%|   | 1346/2048 [01:30<00:49, 14.28it/s, est. speed input: 15293.83 toks/s, output: 14.94 toks/s]
Processed prompts:  67%|   | 1362/2048 [01:31<00:48, 14.27it/s, est. speed input: 15285.04 toks/s, output: 14.93 toks/s]
Processed prompts:  67%|   | 1378/2048 [01:32<00:46, 14.28it/s, est. speed input: 15277.13 toks/s, output: 14.92 toks/s]
Processed prompts:  68%|   | 1394/2048 [01:33<00:45, 14.27it/s, est. speed input: 15269.16 toks/s, output: 14.91 toks/s]
Processed prompts:  69%|   | 1410/2048 [01:34<00:44, 14.27it/s, est. speed input: 15261.05 toks/s, output: 14.90 toks/s]
Processed prompts:  70%|   | 1426/2048 [01:35<00:43, 14.25it/s, est. speed input: 15252.89 toks/s, output: 14.90 toks/s]
Processed prompts:  70%|   | 1442/2048 [01:36<00:42, 14.25it/s, est. speed input: 15245.25 toks/s, output: 14.89 toks/s]
Processed prompts:  71%|   | 1458/2048 [01:37<00:41, 14.25it/s, est. speed input: 15237.53 toks/s, output: 14.88 toks/s]
Processed prompts:  72%|  | 1474/2048 [01:39<00:40, 14.25it/s, est. speed input: 15230.20 toks/s, output: 14.87 toks/s]
Processed prompts:  73%|  | 1490/2048 [01:40<00:39, 14.25it/s, est. speed input: 15222.95 toks/s, output: 14.87 toks/s]
Processed prompts:  74%|  | 1506/2048 [01:41<00:38, 14.25it/s, est. speed input: 15216.07 toks/s, output: 14.86 toks/s]
Processed prompts:  74%|  | 1522/2048 [01:42<00:36, 14.24it/s, est. speed input: 15208.86 toks/s, output: 14.85 toks/s]
Processed prompts:  75%|  | 1538/2048 [01:43<00:35, 14.25it/s, est. speed input: 15202.51 toks/s, output: 14.85 toks/s]
Processed prompts:  76%|  | 1554/2048 [01:44<00:34, 14.26it/s, est. speed input: 15196.36 toks/s, output: 14.84 toks/s]
Processed prompts:  77%|  | 1570/2048 [01:45<00:33, 14.24it/s, est. speed input: 15189.38 toks/s, output: 14.83 toks/s]
Processed prompts:  77%|  | 1586/2048 [01:46<00:31, 14.54it/s, est. speed input: 15193.74 toks/s, output: 14.84 toks/s]
Processed prompts:  78%|  | 1602/2048 [01:48<00:30, 14.43it/s, est. speed input: 15186.96 toks/s, output: 14.83 toks/s]
Processed prompts:  79%|  | 1618/2048 [01:49<00:29, 14.38it/s, est. speed input: 15180.81 toks/s, output: 14.83 toks/s]
Processed prompts:  80%|  | 1634/2048 [01:50<00:28, 14.34it/s, est. speed input: 15174.71 toks/s, output: 14.82 toks/s]
Processed prompts:  81%|  | 1650/2048 [01:51<00:27, 14.31it/s, est. speed input: 15168.89 toks/s, output: 14.81 toks/s]
Processed prompts:  81%| | 1666/2048 [01:52<00:26, 14.30it/s, est. speed input: 15163.20 toks/s, output: 14.81 toks/s]
Processed prompts:  82%| | 1682/2048 [01:53<00:25, 14.28it/s, est. speed input: 15157.44 toks/s, output: 14.80 toks/s]
Processed prompts:  83%| | 1698/2048 [01:54<00:24, 14.25it/s, est. speed input: 15151.40 toks/s, output: 14.80 toks/s]
Processed prompts:  84%| | 1714/2048 [01:55<00:23, 14.25it/s, est. speed input: 15145.76 toks/s, output: 14.79 toks/s]
Processed prompts:  84%| | 1730/2048 [01:57<00:22, 14.25it/s, est. speed input: 15140.48 toks/s, output: 14.79 toks/s]
Processed prompts:  85%| | 1746/2048 [01:58<00:21, 14.26it/s, est. speed input: 15135.52 toks/s, output: 14.78 toks/s]
Processed prompts:  86%| | 1762/2048 [01:59<00:20, 14.25it/s, est. speed input: 15130.36 toks/s, output: 14.78 toks/s]
Processed prompts:  87%| | 1778/2048 [02:00<00:18, 14.26it/s, est. speed input: 15125.60 toks/s, output: 14.77 toks/s]
Processed prompts:  88%| | 1794/2048 [02:01<00:17, 14.25it/s, est. speed input: 15120.39 toks/s, output: 14.77 toks/s]
Processed prompts:  88%| | 1810/2048 [02:02<00:16, 14.24it/s, est. speed input: 15115.25 toks/s, output: 14.76 toks/s]
Processed prompts:  89%| | 1826/2048 [02:03<00:15, 14.24it/s, est. speed input: 15110.44 toks/s, output: 14.76 toks/s]
Processed prompts:  90%| | 1842/2048 [02:04<00:14, 14.26it/s, est. speed input: 15106.38 toks/s, output: 14.75 toks/s]
Processed prompts:  91%| | 1858/2048 [02:05<00:13, 14.27it/s, est. speed input: 15102.00 toks/s, output: 14.75 toks/s]
Processed prompts:  92%|| 1874/2048 [02:07<00:11, 14.53it/s, est. speed input: 15105.59 toks/s, output: 14.75 toks/s]
Processed prompts:  92%|| 1890/2048 [02:08<00:10, 14.44it/s, est. speed input: 15100.94 toks/s, output: 14.75 toks/s]
Processed prompts:  93%|| 1906/2048 [02:09<00:09, 14.37it/s, est. speed input: 15096.33 toks/s, output: 14.74 toks/s]
Processed prompts:  94%|| 1922/2048 [02:10<00:08, 14.33it/s, est. speed input: 15091.71 toks/s, output: 14.74 toks/s]
Processed prompts:  95%|| 1938/2048 [02:11<00:07, 14.30it/s, est. speed input: 15087.38 toks/s, output: 14.73 toks/s]
Processed prompts:  95%|| 1954/2048 [02:12<00:06, 14.56it/s, est. speed input: 15091.13 toks/s, output: 14.74 toks/s]
Processed prompts:  96%|| 1970/2048 [02:13<00:05, 14.46it/s, est. speed input: 15086.82 toks/s, output: 14.73 toks/s]
Processed prompts:  97%|| 1986/2048 [02:14<00:04, 14.41it/s, est. speed input: 15083.19 toks/s, output: 14.73 toks/s]
Processed prompts:  98%|| 2002/2048 [02:15<00:03, 14.35it/s, est. speed input: 15078.85 toks/s, output: 14.73 toks/s]
Processed prompts:  99%|| 2018/2048 [02:17<00:02, 14.32it/s, est. speed input: 15074.88 toks/s, output: 14.72 toks/s]
Processed prompts:  99%|| 2034/2048 [02:18<00:00, 14.52it/s, est. speed input: 15077.19 toks/s, output: 14.72 toks/s]
Processed prompts: 100%|| 2048/2048 [02:18<00:00, 14.52it/s, est. speed input: 15180.95 toks/s, output: 14.83 toks/s]
Processed prompts: 100%|| 2048/2048 [02:18<00:00, 14.83it/s, est. speed input: 15180.95 toks/s, output: 14.83 toks/s]
[rank0]:[W126 12:07:31.311525401 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-26 12:07:33
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Llama3.2-3B-FP8_M32768.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 12:07:48 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 12:07:48 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1269728) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1269728) WARNING 01-26 12:08:19 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 14.28 requests/s, 14637.37 total tokens/s, 14.28 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-26 12:07:48] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 12:07:48] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 12:07:48] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 12:07:48] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:07:48] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:07:48] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:07:48] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:07:48] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:07:48] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 12:07:48] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:07:48] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:07:48] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:07:48] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:07:48] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 12:07:51] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 12:07:52] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 12:07:52] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 12:07:52] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:07:52] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:07:52] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:07:52] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:07:52] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:07:52] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 12:07:52] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:07:52] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:07:52] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:07:52] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:07:52] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1269728) [2026-01-26 12:07:52] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1269728) [2026-01-26 12:07:52] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1269728) [2026-01-26 12:07:52] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1269728) [2026-01-26 12:07:52] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1269728) [2026-01-26 12:07:52] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1269728) [2026-01-26 12:07:52] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1269728) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1269728) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:15<00:00, 15.66s/it]
(EngineCore_DP0 pid=1269728) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:15<00:00, 15.66s/it]
(EngineCore_DP0 pid=1269728) 
(EngineCore_DP0 pid=1269728) [2026-01-26 12:08:09] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 3072] -> 1D uint8
(EngineCore_DP0 pid=1269728) [2026-01-26 12:08:09] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9830400 bytes
(EngineCore_DP0 pid=1269728) [2026-01-26 12:08:09] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=1269728) [2026-01-26 12:08:09] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5898240 bytes
(EngineCore_DP0 pid=1269728) [2026-01-26 12:08:09] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=1269728) [2026-01-26 12:08:09] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 31457280 bytes
(EngineCore_DP0 pid=1269728) [2026-01-26 12:08:09] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 8192] -> 1D uint8
(EngineCore_DP0 pid=1269728) [2026-01-26 12:08:09] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15728640 bytes
(EngineCore_DP0 pid=1269728) 2026-01-26 12:08:16,621 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1269728) 2026-01-26 12:08:16,773 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|         | 57/4096 [00:00<00:07, 562.99it/s]
Adding requests:   3%|         | 114/4096 [00:00<00:09, 409.89it/s]
Adding requests:   4%|         | 158/4096 [00:00<00:09, 399.05it/s]
Adding requests:   5%|         | 204/4096 [00:00<00:09, 417.04it/s]
Adding requests:   6%|         | 252/4096 [00:00<00:08, 435.08it/s]
Adding requests:   7%|         | 299/4096 [00:00<00:08, 443.34it/s]
Adding requests:   8%|         | 344/4096 [00:00<00:08, 439.98it/s]
Adding requests:   9%|         | 389/4096 [00:00<00:08, 442.69it/s]
Adding requests:  11%|         | 434/4096 [00:00<00:08, 439.38it/s]
Adding requests:  12%|        | 479/4096 [00:01<00:08, 441.14it/s]
Adding requests:  13%|        | 524/4096 [00:01<00:08, 433.81it/s]
Adding requests:  14%|        | 573/4096 [00:01<00:07, 447.85it/s]
Adding requests:  15%|        | 620/4096 [00:01<00:07, 453.07it/s]
Adding requests:  16%|        | 669/4096 [00:01<00:07, 462.61it/s]
Adding requests:  17%|        | 716/4096 [00:01<00:07, 459.30it/s]
Adding requests:  19%|        | 762/4096 [00:01<00:07, 455.92it/s]
Adding requests:  20%|        | 808/4096 [00:01<00:07, 449.35it/s]
Adding requests:  21%|        | 853/4096 [00:01<00:07, 449.08it/s]
Adding requests:  22%|       | 898/4096 [00:02<00:07, 447.91it/s]
Adding requests:  23%|       | 943/4096 [00:02<00:07, 442.22it/s]
Adding requests:  24%|       | 990/4096 [00:02<00:06, 448.91it/s]
Adding requests:  25%|       | 1035/4096 [00:02<00:06, 443.16it/s]
Adding requests:  26%|       | 1084/4096 [00:02<00:06, 455.68it/s]
Adding requests:  28%|       | 1130/4096 [00:02<00:06, 445.57it/s]
Adding requests:  29%|       | 1179/4096 [00:02<00:06, 457.91it/s]
Adding requests:  30%|       | 1225/4096 [00:02<00:06, 419.68it/s]
Adding requests:  31%|       | 1272/4096 [00:02<00:06, 431.35it/s]
Adding requests:  32%|      | 1317/4096 [00:02<00:06, 434.82it/s]
Adding requests:  33%|      | 1364/4096 [00:03<00:06, 443.70it/s]
Adding requests:  34%|      | 1412/4096 [00:03<00:05, 453.06it/s]
Adding requests:  36%|      | 1461/4096 [00:03<00:05, 461.71it/s]
Adding requests:  37%|      | 1508/4096 [00:03<00:05, 460.24it/s]
Adding requests:  38%|      | 1556/4096 [00:03<00:05, 463.92it/s]
Adding requests:  39%|      | 1603/4096 [00:03<00:05, 461.62it/s]
Adding requests:  40%|      | 1651/4096 [00:03<00:05, 466.97it/s]
Adding requests:  41%|     | 1698/4096 [00:03<00:05, 462.71it/s]
Adding requests:  43%|     | 1747/4096 [00:03<00:05, 469.30it/s]
Adding requests:  44%|     | 1795/4096 [00:03<00:04, 472.13it/s]
Adding requests:  45%|     | 1843/4096 [00:04<00:04, 459.19it/s]
Adding requests:  46%|     | 1890/4096 [00:04<00:04, 455.80it/s]
Adding requests:  47%|     | 1936/4096 [00:04<00:04, 452.09it/s]
Adding requests:  48%|     | 1982/4096 [00:04<00:04, 447.85it/s]
Adding requests:  50%|     | 2032/4096 [00:04<00:04, 459.89it/s]
Adding requests:  51%|     | 2080/4096 [00:04<00:04, 463.44it/s]
Adding requests:  52%|    | 2127/4096 [00:04<00:04, 457.56it/s]
Adding requests:  53%|    | 2173/4096 [00:04<00:04, 453.45it/s]
Adding requests:  54%|    | 2219/4096 [00:04<00:04, 452.32it/s]
Adding requests:  55%|    | 2265/4096 [00:05<00:04, 453.06it/s]
Adding requests:  56%|    | 2313/4096 [00:05<00:03, 458.09it/s]
Adding requests:  58%|    | 2359/4096 [00:05<00:03, 455.89it/s]
Adding requests:  59%|    | 2406/4096 [00:05<00:03, 458.93it/s]
Adding requests:  60%|    | 2452/4096 [00:05<00:03, 421.28it/s]
Adding requests:  61%|    | 2500/4096 [00:05<00:03, 437.02it/s]
Adding requests:  62%|   | 2545/4096 [00:05<00:03, 439.24it/s]
Adding requests:  63%|   | 2594/4096 [00:05<00:03, 451.01it/s]
Adding requests:  65%|   | 2643/4096 [00:05<00:03, 460.79it/s]
Adding requests:  66%|   | 2690/4096 [00:05<00:03, 458.99it/s]
Adding requests:  67%|   | 2737/4096 [00:06<00:02, 458.62it/s]
Adding requests:  68%|   | 2783/4096 [00:06<00:02, 446.28it/s]
Adding requests:  69%|   | 2829/4096 [00:06<00:02, 448.62it/s]
Adding requests:  70%|   | 2877/4096 [00:06<00:02, 455.43it/s]
Adding requests:  71%|  | 2923/4096 [00:06<00:02, 455.09it/s]
Adding requests:  73%|  | 2970/4096 [00:06<00:02, 458.48it/s]
Adding requests:  74%|  | 3017/4096 [00:06<00:02, 459.21it/s]
Adding requests:  75%|  | 3065/4096 [00:06<00:02, 463.56it/s]
Adding requests:  76%|  | 3113/4096 [00:06<00:02, 468.13it/s]
Adding requests:  77%|  | 3160/4096 [00:07<00:02, 462.76it/s]
Adding requests:  78%|  | 3208/4096 [00:07<00:01, 466.07it/s]
Adding requests:  79%|  | 3255/4096 [00:07<00:01, 465.31it/s]
Adding requests:  81%|  | 3304/4096 [00:07<00:01, 469.21it/s]
Adding requests:  82%| | 3352/4096 [00:07<00:01, 467.84it/s]
Adding requests:  83%| | 3400/4096 [00:07<00:01, 469.02it/s]
Adding requests:  84%| | 3447/4096 [00:07<00:01, 468.15it/s]
Adding requests:  85%| | 3494/4096 [00:07<00:01, 446.16it/s]
Adding requests:  86%| | 3542/4096 [00:07<00:01, 454.39it/s]
Adding requests:  88%| | 3588/4096 [00:07<00:01, 454.68it/s]
Adding requests:  89%| | 3636/4096 [00:08<00:00, 460.55it/s]
Adding requests:  90%| | 3685/4096 [00:08<00:00, 466.68it/s]
Adding requests:  91%| | 3732/4096 [00:08<00:00, 464.41it/s]
Adding requests:  92%|| 3779/4096 [00:08<00:00, 464.16it/s]
Adding requests:  93%|| 3826/4096 [00:08<00:00, 425.56it/s]
Adding requests:  95%|| 3876/4096 [00:08<00:00, 446.17it/s]
Adding requests:  96%|| 3922/4096 [00:08<00:00, 444.66it/s]
Adding requests:  97%|| 3971/4096 [00:08<00:00, 457.24it/s]
Adding requests:  98%|| 4020/4096 [00:08<00:00, 464.87it/s]
Adding requests:  99%|| 4067/4096 [00:08<00:00, 460.07it/s]
Adding requests: 100%|| 4096/4096 [00:09<00:00, 452.97it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 98/4096 [00:00<00:05, 704.26it/s, est. speed input: 721232.22 toks/s, output: 704.28 toks/s]
Processed prompts:   4%|         | 169/4096 [00:04<02:08, 30.44it/s, est. speed input: 37399.50 toks/s, output: 36.52 toks/s]  
Processed prompts:   5%|         | 199/4096 [00:06<02:46, 23.42it/s, est. speed input: 29657.01 toks/s, output: 28.96 toks/s]
Processed prompts:   6%|         | 226/4096 [00:09<03:21, 19.21it/s, est. speed input: 25392.51 toks/s, output: 24.80 toks/s]
Processed prompts:   6%|         | 258/4096 [00:11<03:39, 17.50it/s, est. speed input: 23265.67 toks/s, output: 22.72 toks/s]
Processed prompts:   7%|         | 290/4096 [00:13<03:51, 16.42it/s, est. speed input: 21829.01 toks/s, output: 21.32 toks/s]
Processed prompts:   8%|         | 322/4096 [00:15<03:58, 15.83it/s, est. speed input: 20867.88 toks/s, output: 20.38 toks/s]
Processed prompts:   9%|         | 354/4096 [00:18<04:04, 15.33it/s, est. speed input: 20086.69 toks/s, output: 19.62 toks/s]
Processed prompts:   9%|         | 386/4096 [00:20<04:07, 15.00it/s, est. speed input: 19480.02 toks/s, output: 19.02 toks/s]
Processed prompts:  10%|         | 418/4096 [00:22<04:09, 14.76it/s, est. speed input: 18988.99 toks/s, output: 18.54 toks/s]
Processed prompts:  11%|         | 450/4096 [00:24<04:07, 14.70it/s, est. speed input: 18628.63 toks/s, output: 18.19 toks/s]
Processed prompts:  12%|        | 482/4096 [00:26<04:08, 14.57it/s, est. speed input: 18293.59 toks/s, output: 17.86 toks/s]
Processed prompts:  13%|        | 514/4096 [00:29<04:07, 14.47it/s, est. speed input: 18008.94 toks/s, output: 17.59 toks/s]
Processed prompts:  13%|        | 546/4096 [00:31<04:06, 14.40it/s, est. speed input: 17763.76 toks/s, output: 17.35 toks/s]
Processed prompts:  14%|        | 578/4096 [00:33<04:05, 14.36it/s, est. speed input: 17553.45 toks/s, output: 17.14 toks/s]
Processed prompts:  15%|        | 610/4096 [00:35<04:03, 14.32it/s, est. speed input: 17367.10 toks/s, output: 16.96 toks/s]
Processed prompts:  16%|        | 642/4096 [00:38<04:01, 14.29it/s, est. speed input: 17202.52 toks/s, output: 16.80 toks/s]
Processed prompts:  16%|        | 674/4096 [00:40<03:59, 14.29it/s, est. speed input: 17059.26 toks/s, output: 16.66 toks/s]
Processed prompts:  17%|        | 706/4096 [00:42<03:57, 14.26it/s, est. speed input: 16926.03 toks/s, output: 16.53 toks/s]
Processed prompts:  18%|        | 738/4096 [00:44<03:55, 14.26it/s, est. speed input: 16810.23 toks/s, output: 16.42 toks/s]
Processed prompts:  19%|        | 770/4096 [00:47<03:53, 14.24it/s, est. speed input: 16700.87 toks/s, output: 16.31 toks/s]
Processed prompts:  20%|        | 802/4096 [00:49<03:51, 14.23it/s, est. speed input: 16604.04 toks/s, output: 16.21 toks/s]
Processed prompts:  20%|        | 834/4096 [00:51<03:49, 14.24it/s, est. speed input: 16516.08 toks/s, output: 16.13 toks/s]
Processed prompts:  21%|        | 866/4096 [00:53<03:46, 14.23it/s, est. speed input: 16435.09 toks/s, output: 16.05 toks/s]
Processed prompts:  22%|       | 898/4096 [00:56<03:44, 14.24it/s, est. speed input: 16360.98 toks/s, output: 15.98 toks/s]
Processed prompts:  23%|       | 930/4096 [00:58<03:40, 14.35it/s, est. speed input: 16308.87 toks/s, output: 15.93 toks/s]
Processed prompts:  23%|       | 962/4096 [01:00<03:37, 14.43it/s, est. speed input: 16260.51 toks/s, output: 15.88 toks/s]
Processed prompts:  24%|       | 994/4096 [01:02<03:35, 14.37it/s, est. speed input: 16199.90 toks/s, output: 15.82 toks/s]
Processed prompts:  25%|       | 1026/4096 [01:05<03:34, 14.33it/s, est. speed input: 16144.25 toks/s, output: 15.77 toks/s]
Processed prompts:  26%|       | 1058/4096 [01:07<03:32, 14.29it/s, est. speed input: 16090.62 toks/s, output: 15.71 toks/s]
Processed prompts:  27%|       | 1090/4096 [01:09<03:30, 14.28it/s, est. speed input: 16042.48 toks/s, output: 15.67 toks/s]
Processed prompts:  27%|       | 1122/4096 [01:11<03:28, 14.25it/s, est. speed input: 15995.08 toks/s, output: 15.62 toks/s]
Processed prompts:  28%|       | 1154/4096 [01:14<03:24, 14.36it/s, est. speed input: 15964.39 toks/s, output: 15.59 toks/s]
Processed prompts:  29%|       | 1186/4096 [01:16<03:23, 14.31it/s, est. speed input: 15922.45 toks/s, output: 15.55 toks/s]
Processed prompts:  30%|       | 1218/4096 [01:18<03:21, 14.29it/s, est. speed input: 15883.81 toks/s, output: 15.51 toks/s]
Processed prompts:  31%|       | 1250/4096 [01:20<03:17, 14.39it/s, est. speed input: 15859.93 toks/s, output: 15.49 toks/s]
Processed prompts:  31%|      | 1282/4096 [01:22<03:16, 14.34it/s, est. speed input: 15824.09 toks/s, output: 15.45 toks/s]
Processed prompts:  32%|      | 1314/4096 [01:25<03:14, 14.30it/s, est. speed input: 15790.94 toks/s, output: 15.42 toks/s]
Processed prompts:  33%|      | 1346/4096 [01:27<03:12, 14.28it/s, est. speed input: 15759.33 toks/s, output: 15.39 toks/s]
Processed prompts:  34%|      | 1378/4096 [01:29<03:10, 14.26it/s, est. speed input: 15729.31 toks/s, output: 15.36 toks/s]
Processed prompts:  34%|      | 1410/4096 [01:31<03:08, 14.25it/s, est. speed input: 15701.26 toks/s, output: 15.33 toks/s]
Processed prompts:  35%|      | 1442/4096 [01:34<03:06, 14.24it/s, est. speed input: 15673.95 toks/s, output: 15.31 toks/s]
Processed prompts:  36%|      | 1474/4096 [01:36<03:04, 14.23it/s, est. speed input: 15647.39 toks/s, output: 15.28 toks/s]
Processed prompts:  37%|      | 1506/4096 [01:38<03:02, 14.22it/s, est. speed input: 15622.33 toks/s, output: 15.26 toks/s]
Processed prompts:  38%|      | 1538/4096 [01:40<02:59, 14.23it/s, est. speed input: 15599.59 toks/s, output: 15.23 toks/s]
Processed prompts:  38%|      | 1570/4096 [01:43<02:55, 14.35it/s, est. speed input: 15586.68 toks/s, output: 15.22 toks/s]
Processed prompts:  39%|      | 1602/4096 [01:45<02:54, 14.31it/s, est. speed input: 15564.70 toks/s, output: 15.20 toks/s]
Processed prompts:  40%|      | 1634/4096 [01:47<02:52, 14.29it/s, est. speed input: 15544.45 toks/s, output: 15.18 toks/s]
Processed prompts:  41%|      | 1666/4096 [01:49<02:50, 14.27it/s, est. speed input: 15523.89 toks/s, output: 15.16 toks/s]
Processed prompts:  41%|     | 1698/4096 [01:52<02:48, 14.26it/s, est. speed input: 15505.21 toks/s, output: 15.14 toks/s]
Processed prompts:  42%|     | 1730/4096 [01:54<02:46, 14.25it/s, est. speed input: 15486.68 toks/s, output: 15.12 toks/s]
Processed prompts:  43%|     | 1762/4096 [01:56<02:43, 14.24it/s, est. speed input: 15468.98 toks/s, output: 15.11 toks/s]
Processed prompts:  44%|     | 1794/4096 [01:58<02:41, 14.23it/s, est. speed input: 15451.63 toks/s, output: 15.09 toks/s]
Processed prompts:  45%|     | 1826/4096 [02:01<02:39, 14.23it/s, est. speed input: 15434.83 toks/s, output: 15.07 toks/s]
Processed prompts:  45%|     | 1858/4096 [02:03<02:36, 14.34it/s, est. speed input: 15426.76 toks/s, output: 15.07 toks/s]
Processed prompts:  46%|     | 1890/4096 [02:05<02:34, 14.31it/s, est. speed input: 15411.27 toks/s, output: 15.05 toks/s]
Processed prompts:  47%|     | 1922/4096 [02:07<02:32, 14.28it/s, est. speed input: 15396.46 toks/s, output: 15.04 toks/s]
Processed prompts:  48%|     | 1954/4096 [02:10<02:28, 14.39it/s, est. speed input: 15389.79 toks/s, output: 15.03 toks/s]
Processed prompts:  48%|     | 1986/4096 [02:12<02:27, 14.35it/s, est. speed input: 15376.21 toks/s, output: 15.02 toks/s]
Processed prompts:  49%|     | 2018/4096 [02:14<02:25, 14.31it/s, est. speed input: 15362.51 toks/s, output: 15.00 toks/s]
Processed prompts:  50%|     | 2050/4096 [02:16<02:23, 14.29it/s, est. speed input: 15349.68 toks/s, output: 14.99 toks/s]
Processed prompts:  51%|     | 2082/4096 [02:19<02:21, 14.26it/s, est. speed input: 15336.63 toks/s, output: 14.98 toks/s]
Processed prompts:  52%|    | 2114/4096 [02:21<02:19, 14.26it/s, est. speed input: 15324.68 toks/s, output: 14.97 toks/s]
Processed prompts:  52%|    | 2146/4096 [02:23<02:16, 14.24it/s, est. speed input: 15312.40 toks/s, output: 14.95 toks/s]
Processed prompts:  53%|    | 2178/4096 [02:25<02:14, 14.23it/s, est. speed input: 15300.83 toks/s, output: 14.94 toks/s]
Processed prompts:  54%|    | 2210/4096 [02:27<02:10, 14.49it/s, est. speed input: 15303.47 toks/s, output: 14.94 toks/s]
Processed prompts:  55%|    | 2242/4096 [02:30<02:08, 14.40it/s, est. speed input: 15291.74 toks/s, output: 14.93 toks/s]
Processed prompts:  56%|    | 2274/4096 [02:32<02:05, 14.47it/s, est. speed input: 15287.63 toks/s, output: 14.93 toks/s]
Processed prompts:  56%|    | 2306/4096 [02:34<02:04, 14.41it/s, est. speed input: 15277.70 toks/s, output: 14.92 toks/s]
Processed prompts:  57%|    | 2338/4096 [02:36<02:01, 14.46it/s, est. speed input: 15273.05 toks/s, output: 14.92 toks/s]
Processed prompts:  58%|    | 2370/4096 [02:38<01:57, 14.68it/s, est. speed input: 15276.95 toks/s, output: 14.92 toks/s]
Processed prompts:  59%|    | 2402/4096 [02:41<01:56, 14.54it/s, est. speed input: 15267.19 toks/s, output: 14.91 toks/s]
Processed prompts:  59%|    | 2434/4096 [02:43<01:55, 14.45it/s, est. speed input: 15257.82 toks/s, output: 14.90 toks/s]
Processed prompts:  60%|    | 2466/4096 [02:45<01:53, 14.39it/s, est. speed input: 15248.73 toks/s, output: 14.89 toks/s]
Processed prompts:  61%|    | 2498/4096 [02:47<01:50, 14.47it/s, est. speed input: 15245.90 toks/s, output: 14.89 toks/s]
Processed prompts:  62%|   | 2530/4096 [02:50<01:48, 14.40it/s, est. speed input: 15236.89 toks/s, output: 14.88 toks/s]
Processed prompts:  63%|   | 2562/4096 [02:52<01:46, 14.47it/s, est. speed input: 15233.74 toks/s, output: 14.88 toks/s]
Processed prompts:  63%|   | 2594/4096 [02:54<01:44, 14.40it/s, est. speed input: 15225.36 toks/s, output: 14.87 toks/s]
Processed prompts:  64%|   | 2626/4096 [02:56<01:42, 14.36it/s, est. speed input: 15217.46 toks/s, output: 14.86 toks/s]
Processed prompts:  65%|   | 2658/4096 [02:58<01:40, 14.32it/s, est. speed input: 15209.32 toks/s, output: 14.85 toks/s]
Processed prompts:  66%|   | 2690/4096 [03:01<01:38, 14.29it/s, est. speed input: 15201.13 toks/s, output: 14.84 toks/s]
Processed prompts:  66%|   | 2722/4096 [03:03<01:36, 14.26it/s, est. speed input: 15193.15 toks/s, output: 14.84 toks/s]
Processed prompts:  67%|   | 2754/4096 [03:05<01:34, 14.24it/s, est. speed input: 15185.20 toks/s, output: 14.83 toks/s]
Processed prompts:  68%|   | 2786/4096 [03:07<01:31, 14.25it/s, est. speed input: 15178.11 toks/s, output: 14.82 toks/s]
Processed prompts:  69%|   | 2818/4096 [03:10<01:29, 14.24it/s, est. speed input: 15171.03 toks/s, output: 14.82 toks/s]
Processed prompts:  70%|   | 2850/4096 [03:12<01:27, 14.24it/s, est. speed input: 15164.08 toks/s, output: 14.81 toks/s]
Processed prompts:  70%|   | 2882/4096 [03:14<01:25, 14.24it/s, est. speed input: 15157.32 toks/s, output: 14.80 toks/s]
Processed prompts:  71%|   | 2914/4096 [03:16<01:23, 14.24it/s, est. speed input: 15150.68 toks/s, output: 14.80 toks/s]
Processed prompts:  72%|  | 2946/4096 [03:19<01:20, 14.23it/s, est. speed input: 15144.08 toks/s, output: 14.79 toks/s]
Processed prompts:  73%|  | 2978/4096 [03:21<01:18, 14.23it/s, est. speed input: 15137.70 toks/s, output: 14.78 toks/s]
Processed prompts:  73%|  | 3010/4096 [03:23<01:16, 14.24it/s, est. speed input: 15131.62 toks/s, output: 14.78 toks/s]
Processed prompts:  74%|  | 3042/4096 [03:25<01:14, 14.22it/s, est. speed input: 15124.80 toks/s, output: 14.77 toks/s]
Processed prompts:  75%|  | 3074/4096 [03:28<01:11, 14.22it/s, est. speed input: 15118.62 toks/s, output: 14.76 toks/s]
Processed prompts:  76%|  | 3106/4096 [03:30<01:09, 14.22it/s, est. speed input: 15112.92 toks/s, output: 14.76 toks/s]
Processed prompts:  77%|  | 3138/4096 [03:32<01:06, 14.34it/s, est. speed input: 15111.41 toks/s, output: 14.76 toks/s]
Processed prompts:  77%|  | 3170/4096 [03:34<01:04, 14.31it/s, est. speed input: 15105.73 toks/s, output: 14.75 toks/s]
Processed prompts:  78%|  | 3202/4096 [03:37<01:02, 14.28it/s, est. speed input: 15100.20 toks/s, output: 14.75 toks/s]
Processed prompts:  79%|  | 3234/4096 [03:39<01:00, 14.26it/s, est. speed input: 15094.53 toks/s, output: 14.74 toks/s]
Processed prompts:  80%|  | 3266/4096 [03:41<00:58, 14.09it/s, est. speed input: 15083.37 toks/s, output: 14.73 toks/s]
Processed prompts:  81%|  | 3298/4096 [03:44<00:57, 13.80it/s, est. speed input: 15065.93 toks/s, output: 14.71 toks/s]
Processed prompts:  81%| | 3330/4096 [03:46<00:55, 13.90it/s, est. speed input: 15060.04 toks/s, output: 14.71 toks/s]
Processed prompts:  82%| | 3362/4096 [03:48<00:52, 13.98it/s, est. speed input: 15054.85 toks/s, output: 14.70 toks/s]
Processed prompts:  83%| | 3394/4096 [03:50<00:49, 14.06it/s, est. speed input: 15050.19 toks/s, output: 14.70 toks/s]
Processed prompts:  84%| | 3426/4096 [03:53<00:47, 14.11it/s, est. speed input: 15045.42 toks/s, output: 14.69 toks/s]
Processed prompts:  84%| | 3458/4096 [03:55<00:45, 14.16it/s, est. speed input: 15041.36 toks/s, output: 14.69 toks/s]
Processed prompts:  85%| | 3490/4096 [03:57<00:41, 14.45it/s, est. speed input: 15045.91 toks/s, output: 14.69 toks/s]
Processed prompts:  86%| | 3522/4096 [03:59<00:39, 14.38it/s, est. speed input: 15041.26 toks/s, output: 14.69 toks/s]
Processed prompts:  87%| | 3554/4096 [04:02<00:37, 14.32it/s, est. speed input: 15036.51 toks/s, output: 14.68 toks/s]
Processed prompts:  88%| | 3586/4096 [04:04<00:35, 14.30it/s, est. speed input: 15032.56 toks/s, output: 14.68 toks/s]
Processed prompts:  88%| | 3618/4096 [04:06<00:33, 14.28it/s, est. speed input: 15028.39 toks/s, output: 14.68 toks/s]
Processed prompts:  89%| | 3650/4096 [04:08<00:31, 14.26it/s, est. speed input: 15024.01 toks/s, output: 14.67 toks/s]
Processed prompts:  90%| | 3682/4096 [04:11<00:29, 14.25it/s, est. speed input: 15020.02 toks/s, output: 14.67 toks/s]
Processed prompts:  91%| | 3714/4096 [04:13<00:26, 14.37it/s, est. speed input: 15019.91 toks/s, output: 14.67 toks/s]
Processed prompts:  91%|| 3746/4096 [04:15<00:24, 14.32it/s, est. speed input: 15015.85 toks/s, output: 14.66 toks/s]
Processed prompts:  92%|| 3778/4096 [04:17<00:22, 14.31it/s, est. speed input: 15012.30 toks/s, output: 14.66 toks/s]
Processed prompts:  93%|| 3810/4096 [04:19<00:20, 14.28it/s, est. speed input: 15008.26 toks/s, output: 14.66 toks/s]
Processed prompts:  94%|| 3842/4096 [04:22<00:17, 14.38it/s, est. speed input: 15007.98 toks/s, output: 14.66 toks/s]
Processed prompts:  95%|| 3874/4096 [04:24<00:15, 14.33it/s, est. speed input: 15004.03 toks/s, output: 14.65 toks/s]
Processed prompts:  95%|| 3906/4096 [04:26<00:13, 14.30it/s, est. speed input: 15000.59 toks/s, output: 14.65 toks/s]
Processed prompts:  96%|| 3938/4096 [04:28<00:11, 14.28it/s, est. speed input: 14996.96 toks/s, output: 14.65 toks/s]
Processed prompts:  97%|| 3970/4096 [04:31<00:08, 14.26it/s, est. speed input: 14993.34 toks/s, output: 14.64 toks/s]
Processed prompts:  98%|| 4002/4096 [04:33<00:06, 14.24it/s, est. speed input: 14989.66 toks/s, output: 14.64 toks/s]
Processed prompts:  98%|| 4034/4096 [04:35<00:04, 14.36it/s, est. speed input: 14989.68 toks/s, output: 14.64 toks/s]
Processed prompts:  99%|| 4066/4096 [04:37<00:02, 14.41it/s, est. speed input: 14988.63 toks/s, output: 14.64 toks/s]
Processed prompts: 100%|| 4096/4096 [04:37<00:00, 14.41it/s, est. speed input: 15099.20 toks/s, output: 14.75 toks/s]
Processed prompts: 100%|| 4096/4096 [04:37<00:00, 14.75it/s, est. speed input: 15099.20 toks/s, output: 14.75 toks/s]
[rank0]:[W126 12:13:06.820985268 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-26 12:13:08
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Llama3.2-3B-FP8_M65536.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 12:13:35 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 12:13:35 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1274691) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1274691) WARNING 01-26 12:14:10 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 14.45 requests/s, 14811.75 total tokens/s, 14.45 output tokens/s
Total num prompt tokens:  8388608
Total num output tokens:  8192

STDERR:
[2026-01-26 12:13:35] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 12:13:35] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 12:13:35] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 12:13:35] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:13:35] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:13:35] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:13:35] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:13:35] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:13:35] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 12:13:35] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:13:35] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:13:35] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:13:35] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:13:35] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 12:13:39] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 12:13:39] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 12:13:39] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 12:13:39] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:13:39] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:13:39] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:13:39] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:13:39] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:13:39] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 12:13:39] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:13:39] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:13:39] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:13:39] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:13:39] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1274691) [2026-01-26 12:13:40] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1274691) [2026-01-26 12:13:40] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1274691) [2026-01-26 12:13:40] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1274691) [2026-01-26 12:13:40] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1274691) [2026-01-26 12:13:40] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1274691) [2026-01-26 12:13:40] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1274691) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1274691) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:15<00:00, 15.52s/it]
(EngineCore_DP0 pid=1274691) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:15<00:00, 15.52s/it]
(EngineCore_DP0 pid=1274691) 
(EngineCore_DP0 pid=1274691) [2026-01-26 12:13:56] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 3072] -> 1D uint8
(EngineCore_DP0 pid=1274691) [2026-01-26 12:13:56] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9830400 bytes
(EngineCore_DP0 pid=1274691) [2026-01-26 12:13:56] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=1274691) [2026-01-26 12:13:56] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5898240 bytes
(EngineCore_DP0 pid=1274691) [2026-01-26 12:13:56] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=1274691) [2026-01-26 12:13:56] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 31457280 bytes
(EngineCore_DP0 pid=1274691) [2026-01-26 12:13:56] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 8192] -> 1D uint8
(EngineCore_DP0 pid=1274691) [2026-01-26 12:13:56] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15728640 bytes
(EngineCore_DP0 pid=1274691) 2026-01-26 12:14:05,630 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1274691) 2026-01-26 12:14:05,915 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/8192 [00:00<?, ?it/s]
Adding requests:   1%|          | 53/8192 [00:00<00:15, 524.35it/s]
Adding requests:   1%|         | 106/8192 [00:00<00:17, 460.80it/s]
Adding requests:   2%|         | 153/8192 [00:00<00:17, 447.24it/s]
Adding requests:   2%|         | 198/8192 [00:00<00:18, 439.55it/s]
Adding requests:   3%|         | 243/8192 [00:00<00:18, 437.02it/s]
Adding requests:   4%|         | 288/8192 [00:00<00:17, 439.16it/s]
Adding requests:   4%|         | 333/8192 [00:00<00:17, 442.02it/s]
Adding requests:   5%|         | 378/8192 [00:00<00:18, 432.81it/s]
Adding requests:   5%|         | 424/8192 [00:00<00:17, 438.65it/s]
Adding requests:   6%|         | 471/8192 [00:01<00:17, 445.86it/s]
Adding requests:   6%|         | 516/8192 [00:01<00:17, 431.12it/s]
Adding requests:   7%|         | 561/8192 [00:01<00:17, 433.51it/s]
Adding requests:   7%|         | 608/8192 [00:01<00:17, 442.12it/s]
Adding requests:   8%|         | 655/8192 [00:01<00:16, 450.27it/s]
Adding requests:   9%|         | 701/8192 [00:01<00:17, 432.76it/s]
Adding requests:   9%|         | 745/8192 [00:01<00:17, 431.75it/s]
Adding requests:  10%|         | 789/8192 [00:01<00:17, 428.06it/s]
Adding requests:  10%|         | 833/8192 [00:01<00:17, 430.05it/s]
Adding requests:  11%|         | 879/8192 [00:02<00:16, 435.82it/s]
Adding requests:  11%|        | 923/8192 [00:02<00:16, 430.07it/s]
Adding requests:  12%|        | 968/8192 [00:02<00:16, 434.24it/s]
Adding requests:  12%|        | 1014/8192 [00:02<00:16, 440.69it/s]
Adding requests:  13%|        | 1059/8192 [00:02<00:16, 440.45it/s]
Adding requests:  13%|        | 1104/8192 [00:02<00:16, 432.06it/s]
Adding requests:  14%|        | 1149/8192 [00:02<00:16, 437.21it/s]
Adding requests:  15%|        | 1193/8192 [00:02<00:16, 431.25it/s]
Adding requests:  15%|        | 1237/8192 [00:02<00:16, 428.93it/s]
Adding requests:  16%|        | 1284/8192 [00:02<00:15, 438.89it/s]
Adding requests:  16%|        | 1328/8192 [00:03<00:15, 432.75it/s]
Adding requests:  17%|        | 1374/8192 [00:03<00:15, 437.42it/s]
Adding requests:  17%|        | 1420/8192 [00:03<00:15, 443.60it/s]
Adding requests:  18%|        | 1466/8192 [00:03<00:15, 445.34it/s]
Adding requests:  18%|        | 1511/8192 [00:03<00:15, 438.77it/s]
Adding requests:  19%|        | 1557/8192 [00:03<00:14, 444.01it/s]
Adding requests:  20%|        | 1602/8192 [00:03<00:15, 433.17it/s]
Adding requests:  20%|        | 1646/8192 [00:03<00:15, 432.51it/s]
Adding requests:  21%|        | 1691/8192 [00:03<00:14, 436.35it/s]
Adding requests:  21%|        | 1739/8192 [00:03<00:14, 447.85it/s]
Adding requests:  22%|       | 1784/8192 [00:04<00:14, 444.08it/s]
Adding requests:  22%|       | 1829/8192 [00:04<00:14, 444.49it/s]
Adding requests:  23%|       | 1874/8192 [00:04<00:15, 420.43it/s]
Adding requests:  23%|       | 1917/8192 [00:04<00:15, 416.53it/s]
Adding requests:  24%|       | 1962/8192 [00:04<00:14, 424.64it/s]
Adding requests:  24%|       | 2007/8192 [00:04<00:14, 430.65it/s]
Adding requests:  25%|       | 2051/8192 [00:04<00:14, 427.05it/s]
Adding requests:  26%|       | 2095/8192 [00:04<00:14, 429.26it/s]
Adding requests:  26%|       | 2138/8192 [00:04<00:14, 428.19it/s]
Adding requests:  27%|       | 2184/8192 [00:05<00:13, 437.05it/s]
Adding requests:  27%|       | 2231/8192 [00:05<00:13, 444.46it/s]
Adding requests:  28%|       | 2276/8192 [00:05<00:13, 440.80it/s]
Adding requests:  28%|       | 2322/8192 [00:05<00:13, 446.05it/s]
Adding requests:  29%|       | 2368/8192 [00:05<00:12, 449.67it/s]
Adding requests:  29%|       | 2413/8192 [00:05<00:13, 433.51it/s]
Adding requests:  30%|       | 2457/8192 [00:05<00:13, 435.16it/s]
Adding requests:  31%|       | 2502/8192 [00:05<00:12, 438.54it/s]
Adding requests:  31%|       | 2547/8192 [00:05<00:12, 441.11it/s]
Adding requests:  32%|      | 2594/8192 [00:05<00:12, 446.53it/s]
Adding requests:  32%|      | 2641/8192 [00:06<00:12, 452.98it/s]
Adding requests:  33%|      | 2688/8192 [00:06<00:12, 456.86it/s]
Adding requests:  33%|      | 2734/8192 [00:06<00:12, 447.88it/s]
Adding requests:  34%|      | 2779/8192 [00:06<00:12, 443.40it/s]
Adding requests:  34%|      | 2826/8192 [00:06<00:11, 449.67it/s]
Adding requests:  35%|      | 2872/8192 [00:06<00:12, 438.41it/s]
Adding requests:  36%|      | 2916/8192 [00:06<00:12, 433.41it/s]
Adding requests:  36%|      | 2962/8192 [00:06<00:11, 439.99it/s]
Adding requests:  37%|      | 3007/8192 [00:06<00:11, 434.06it/s]
Adding requests:  37%|      | 3051/8192 [00:06<00:11, 435.51it/s]
Adding requests:  38%|      | 3098/8192 [00:07<00:11, 443.94it/s]
Adding requests:  38%|      | 3143/8192 [00:07<00:11, 435.39it/s]
Adding requests:  39%|      | 3189/8192 [00:07<00:11, 439.87it/s]
Adding requests:  39%|      | 3234/8192 [00:07<00:12, 409.38it/s]
Adding requests:  40%|      | 3277/8192 [00:07<00:11, 412.93it/s]
Adding requests:  41%|      | 3322/8192 [00:07<00:11, 423.36it/s]
Adding requests:  41%|      | 3369/8192 [00:07<00:11, 433.66it/s]
Adding requests:  42%|     | 3415/8192 [00:07<00:10, 439.46it/s]
Adding requests:  42%|     | 3460/8192 [00:07<00:10, 433.83it/s]
Adding requests:  43%|     | 3507/8192 [00:08<00:10, 442.20it/s]
Adding requests:  43%|     | 3552/8192 [00:08<00:10, 442.09it/s]
Adding requests:  44%|     | 3597/8192 [00:08<00:10, 438.02it/s]
Adding requests:  44%|     | 3644/8192 [00:08<00:10, 447.31it/s]
Adding requests:  45%|     | 3689/8192 [00:08<00:10, 437.49it/s]
Adding requests:  46%|     | 3733/8192 [00:08<00:10, 436.89it/s]
Adding requests:  46%|     | 3783/8192 [00:08<00:09, 454.41it/s]
Adding requests:  47%|     | 3829/8192 [00:08<00:09, 447.83it/s]
Adding requests:  47%|     | 3875/8192 [00:08<00:09, 447.74it/s]
Adding requests:  48%|     | 3920/8192 [00:08<00:09, 441.63it/s]
Adding requests:  48%|     | 3966/8192 [00:09<00:09, 444.94it/s]
Adding requests:  49%|     | 4011/8192 [00:09<00:09, 425.89it/s]
Adding requests:  49%|     | 4054/8192 [00:09<00:09, 425.09it/s]
Adding requests:  50%|     | 4101/8192 [00:09<00:09, 434.17it/s]
Adding requests:  51%|     | 4146/8192 [00:09<00:09, 436.42it/s]
Adding requests:  51%|     | 4193/8192 [00:09<00:08, 444.42it/s]
Adding requests:  52%|    | 4239/8192 [00:09<00:08, 448.87it/s]
Adding requests:  52%|    | 4285/8192 [00:09<00:08, 450.98it/s]
Adding requests:  53%|    | 4331/8192 [00:09<00:08, 452.03it/s]
Adding requests:  53%|    | 4377/8192 [00:09<00:08, 453.05it/s]
Adding requests:  54%|    | 4425/8192 [00:10<00:08, 460.48it/s]
Adding requests:  55%|    | 4472/8192 [00:10<00:08, 452.79it/s]
Adding requests:  55%|    | 4518/8192 [00:10<00:08, 436.10it/s]
Adding requests:  56%|    | 4568/8192 [00:10<00:07, 453.34it/s]
Adding requests:  56%|    | 4614/8192 [00:10<00:08, 414.02it/s]
Adding requests:  57%|    | 4660/8192 [00:10<00:08, 425.22it/s]
Adding requests:  57%|    | 4706/8192 [00:10<00:08, 434.74it/s]
Adding requests:  58%|    | 4751/8192 [00:10<00:07, 438.63it/s]
Adding requests:  59%|    | 4798/8192 [00:10<00:07, 444.97it/s]
Adding requests:  59%|    | 4845/8192 [00:11<00:07, 450.82it/s]
Adding requests:  60%|    | 4891/8192 [00:11<00:07, 443.82it/s]
Adding requests:  60%|    | 4937/8192 [00:11<00:07, 446.51it/s]
Adding requests:  61%|    | 4982/8192 [00:11<00:07, 443.69it/s]
Adding requests:  61%|   | 5027/8192 [00:11<00:07, 445.16it/s]
Adding requests:  62%|   | 5072/8192 [00:11<00:07, 444.22it/s]
Adding requests:  63%|   | 5121/8192 [00:11<00:06, 457.70it/s]
Adding requests:  63%|   | 5167/8192 [00:11<00:06, 455.31it/s]
Adding requests:  64%|   | 5213/8192 [00:11<00:06, 454.37it/s]
Adding requests:  64%|   | 5259/8192 [00:11<00:06, 450.00it/s]
Adding requests:  65%|   | 5305/8192 [00:12<00:06, 448.71it/s]
Adding requests:  65%|   | 5353/8192 [00:12<00:06, 456.59it/s]
Adding requests:  66%|   | 5399/8192 [00:12<00:06, 447.55it/s]
Adding requests:  66%|   | 5446/8192 [00:12<00:06, 452.69it/s]
Adding requests:  67%|   | 5492/8192 [00:12<00:06, 446.75it/s]
Adding requests:  68%|   | 5538/8192 [00:12<00:05, 446.91it/s]
Adding requests:  68%|   | 5586/8192 [00:12<00:05, 454.99it/s]
Adding requests:  69%|   | 5632/8192 [00:12<00:05, 453.07it/s]
Adding requests:  69%|   | 5678/8192 [00:12<00:05, 448.74it/s]
Adding requests:  70%|   | 5724/8192 [00:12<00:05, 451.22it/s]
Adding requests:  70%|   | 5770/8192 [00:13<00:05, 452.44it/s]
Adding requests:  71%|   | 5816/8192 [00:13<00:05, 443.20it/s]
Adding requests:  72%|  | 5861/8192 [00:13<00:05, 442.17it/s]
Adding requests:  72%|  | 5912/8192 [00:13<00:04, 459.80it/s]
Adding requests:  73%|  | 5959/8192 [00:13<00:05, 426.44it/s]
Adding requests:  73%|  | 6003/8192 [00:13<00:05, 421.54it/s]
Adding requests:  74%|  | 6054/8192 [00:13<00:04, 445.64it/s]
Adding requests:  74%|  | 6099/8192 [00:13<00:04, 440.49it/s]
Adding requests:  75%|  | 6145/8192 [00:13<00:04, 445.89it/s]
Adding requests:  76%|  | 6190/8192 [00:14<00:04, 445.71it/s]
Adding requests:  76%|  | 6239/8192 [00:14<00:04, 457.10it/s]
Adding requests:  77%|  | 6286/8192 [00:14<00:04, 459.39it/s]
Adding requests:  77%|  | 6334/8192 [00:14<00:04, 460.65it/s]
Adding requests:  78%|  | 6383/8192 [00:14<00:03, 468.06it/s]
Adding requests:  79%|  | 6432/8192 [00:14<00:03, 474.03it/s]
Adding requests:  79%|  | 6481/8192 [00:14<00:03, 476.64it/s]
Adding requests:  80%|  | 6531/8192 [00:14<00:03, 482.03it/s]
Adding requests:  80%|  | 6581/8192 [00:14<00:03, 484.46it/s]
Adding requests:  81%|  | 6630/8192 [00:14<00:03, 484.84it/s]
Adding requests:  82%| | 6679/8192 [00:15<00:03, 477.63it/s]
Adding requests:  82%| | 6730/8192 [00:15<00:03, 486.38it/s]
Adding requests:  83%| | 6779/8192 [00:15<00:02, 477.94it/s]
Adding requests:  83%| | 6827/8192 [00:15<00:02, 478.04it/s]
Adding requests:  84%| | 6880/8192 [00:15<00:02, 490.60it/s]
Adding requests:  85%| | 6930/8192 [00:15<00:02, 492.55it/s]
Adding requests:  85%| | 6980/8192 [00:15<00:02, 487.06it/s]
Adding requests:  86%| | 7029/8192 [00:15<00:02, 487.34it/s]
Adding requests:  86%| | 7078/8192 [00:15<00:02, 487.76it/s]
Adding requests:  87%| | 7127/8192 [00:15<00:02, 488.11it/s]
Adding requests:  88%| | 7176/8192 [00:16<00:02, 476.66it/s]
Adding requests:  88%| | 7224/8192 [00:16<00:02, 476.59it/s]
Adding requests:  89%| | 7274/8192 [00:16<00:01, 483.17it/s]
Adding requests:  89%| | 7325/8192 [00:16<00:01, 488.44it/s]
Adding requests:  90%| | 7374/8192 [00:16<00:01, 452.37it/s]
Adding requests:  91%| | 7426/8192 [00:16<00:01, 469.59it/s]
Adding requests:  91%|| 7476/8192 [00:16<00:01, 473.85it/s]
Adding requests:  92%|| 7527/8192 [00:16<00:01, 483.12it/s]
Adding requests:  92%|| 7577/8192 [00:16<00:01, 485.57it/s]
Adding requests:  93%|| 7626/8192 [00:17<00:01, 480.70it/s]
Adding requests:  94%|| 7677/8192 [00:17<00:01, 486.35it/s]
Adding requests:  94%|| 7726/8192 [00:17<00:00, 482.89it/s]
Adding requests:  95%|| 7775/8192 [00:17<00:00, 479.56it/s]
Adding requests:  96%|| 7824/8192 [00:17<00:00, 479.06it/s]
Adding requests:  96%|| 7875/8192 [00:17<00:00, 487.56it/s]
Adding requests:  97%|| 7924/8192 [00:17<00:00, 482.33it/s]
Adding requests:  97%|| 7973/8192 [00:17<00:00, 478.70it/s]
Adding requests:  98%|| 8025/8192 [00:17<00:00, 489.23it/s]
Adding requests:  99%|| 8075/8192 [00:17<00:00, 491.92it/s]
Adding requests:  99%|| 8125/8192 [00:18<00:00, 473.01it/s]
Adding requests: 100%|| 8173/8192 [00:18<00:00, 472.00it/s]
Adding requests: 100%|| 8192/8192 [00:18<00:00, 449.89it/s]

Processed prompts:   0%|          | 0/8192 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   3%|         | 258/8192 [00:04<02:08, 61.57it/s, est. speed input: 63052.94 toks/s, output: 61.57 toks/s]
Processed prompts:   4%|         | 322/8192 [00:08<03:56, 33.34it/s, est. speed input: 38371.84 toks/s, output: 37.47 toks/s]
Processed prompts:   5%|         | 386/8192 [00:13<05:17, 24.55it/s, est. speed input: 30317.17 toks/s, output: 29.61 toks/s]
Processed prompts:   5%|         | 450/8192 [00:17<06:15, 20.60it/s, est. speed input: 26438.40 toks/s, output: 25.82 toks/s]
Processed prompts:   6%|         | 514/8192 [00:21<06:58, 18.34it/s, est. speed input: 24055.40 toks/s, output: 23.49 toks/s]
Processed prompts:   7%|         | 578/8192 [00:26<07:28, 16.98it/s, est. speed input: 22478.16 toks/s, output: 21.95 toks/s]
Processed prompts:   8%|         | 642/8192 [00:30<07:48, 16.13it/s, est. speed input: 21356.38 toks/s, output: 20.86 toks/s]
Processed prompts:   9%|         | 706/8192 [00:35<08:01, 15.56it/s, est. speed input: 20515.71 toks/s, output: 20.03 toks/s]
Processed prompts:   9%|         | 770/8192 [00:39<08:08, 15.19it/s, est. speed input: 19866.21 toks/s, output: 19.40 toks/s]
Processed prompts:  10%|         | 834/8192 [00:44<08:12, 14.93it/s, est. speed input: 19344.83 toks/s, output: 18.89 toks/s]
Processed prompts:  11%|         | 898/8192 [00:48<08:11, 14.83it/s, est. speed input: 18947.31 toks/s, output: 18.50 toks/s]
Processed prompts:  12%|        | 962/8192 [00:52<08:09, 14.77it/s, est. speed input: 18619.04 toks/s, output: 18.18 toks/s]
Processed prompts:  13%|        | 1026/8192 [00:57<08:09, 14.65it/s, est. speed input: 18316.69 toks/s, output: 17.89 toks/s]
Processed prompts:  13%|        | 1090/8192 [01:01<08:07, 14.56it/s, est. speed input: 18055.12 toks/s, output: 17.63 toks/s]
Processed prompts:  14%|        | 1154/8192 [01:06<08:03, 14.57it/s, est. speed input: 17849.13 toks/s, output: 17.43 toks/s]
Processed prompts:  15%|        | 1218/8192 [01:10<07:58, 14.58it/s, est. speed input: 17668.72 toks/s, output: 17.25 toks/s]
Processed prompts:  16%|        | 1282/8192 [01:15<07:56, 14.51it/s, est. speed input: 17492.72 toks/s, output: 17.08 toks/s]
Processed prompts:  16%|        | 1346/8192 [01:19<07:53, 14.47it/s, est. speed input: 17336.65 toks/s, output: 16.93 toks/s]
Processed prompts:  17%|        | 1410/8192 [01:23<07:49, 14.43it/s, est. speed input: 17196.73 toks/s, output: 16.79 toks/s]
Processed prompts:  18%|        | 1474/8192 [01:28<07:46, 14.41it/s, est. speed input: 17071.64 toks/s, output: 16.67 toks/s]
Processed prompts:  19%|        | 1538/8192 [01:32<07:39, 14.47it/s, est. speed input: 16972.06 toks/s, output: 16.57 toks/s]
Processed prompts:  20%|        | 1602/8192 [01:37<07:36, 14.43it/s, est. speed input: 16867.36 toks/s, output: 16.47 toks/s]
Processed prompts:  20%|        | 1666/8192 [01:41<07:32, 14.41it/s, est. speed input: 16773.10 toks/s, output: 16.38 toks/s]
Processed prompts:  21%|        | 1730/8192 [01:46<07:28, 14.41it/s, est. speed input: 16687.83 toks/s, output: 16.30 toks/s]
Processed prompts:  22%|       | 1794/8192 [01:50<07:24, 14.40it/s, est. speed input: 16608.69 toks/s, output: 16.22 toks/s]
Processed prompts:  23%|       | 1858/8192 [01:54<07:18, 14.46it/s, est. speed input: 16545.29 toks/s, output: 16.16 toks/s]
Processed prompts:  23%|       | 1922/8192 [01:59<07:12, 14.50it/s, est. speed input: 16487.02 toks/s, output: 16.10 toks/s]
Processed prompts:  24%|       | 1986/8192 [02:03<07:09, 14.47it/s, est. speed input: 16423.74 toks/s, output: 16.04 toks/s]
Processed prompts:  25%|       | 2050/8192 [02:08<07:05, 14.43it/s, est. speed input: 16364.15 toks/s, output: 15.98 toks/s]
Processed prompts:  26%|       | 2114/8192 [02:12<07:01, 14.41it/s, est. speed input: 16308.72 toks/s, output: 15.93 toks/s]
Processed prompts:  27%|       | 2178/8192 [02:17<06:54, 14.52it/s, est. speed input: 16271.33 toks/s, output: 15.89 toks/s]
Processed prompts:  27%|       | 2242/8192 [02:21<06:49, 14.53it/s, est. speed input: 16229.31 toks/s, output: 15.85 toks/s]
Processed prompts:  28%|       | 2306/8192 [02:25<06:44, 14.55it/s, est. speed input: 16190.50 toks/s, output: 15.81 toks/s]
Processed prompts:  29%|       | 2370/8192 [02:30<06:37, 14.63it/s, est. speed input: 16161.42 toks/s, output: 15.78 toks/s]
Processed prompts:  30%|       | 2434/8192 [02:34<06:35, 14.55it/s, est. speed input: 16119.68 toks/s, output: 15.74 toks/s]
Processed prompts:  30%|       | 2498/8192 [02:39<06:30, 14.56it/s, est. speed input: 16087.35 toks/s, output: 15.71 toks/s]
Processed prompts:  31%|      | 2562/8192 [02:43<06:26, 14.58it/s, est. speed input: 16056.81 toks/s, output: 15.68 toks/s]
Processed prompts:  32%|      | 2626/8192 [02:47<06:23, 14.52it/s, est. speed input: 16021.71 toks/s, output: 15.65 toks/s]
Processed prompts:  33%|      | 2690/8192 [02:52<06:20, 14.46it/s, est. speed input: 15986.73 toks/s, output: 15.61 toks/s]
Processed prompts:  34%|      | 2754/8192 [02:56<06:16, 14.43it/s, est. speed input: 15954.51 toks/s, output: 15.58 toks/s]
Processed prompts:  34%|      | 2818/8192 [03:01<06:12, 14.41it/s, est. speed input: 15924.02 toks/s, output: 15.55 toks/s]
Processed prompts:  35%|      | 2882/8192 [03:05<06:08, 14.40it/s, est. speed input: 15895.25 toks/s, output: 15.52 toks/s]
Processed prompts:  36%|      | 2946/8192 [03:10<06:04, 14.39it/s, est. speed input: 15867.44 toks/s, output: 15.50 toks/s]
Processed prompts:  37%|      | 3010/8192 [03:14<06:00, 14.39it/s, est. speed input: 15841.14 toks/s, output: 15.47 toks/s]
Processed prompts:  38%|      | 3074/8192 [03:19<05:55, 14.38it/s, est. speed input: 15816.05 toks/s, output: 15.45 toks/s]
Processed prompts:  38%|      | 3138/8192 [03:23<05:49, 14.45it/s, est. speed input: 15797.36 toks/s, output: 15.43 toks/s]
Processed prompts:  39%|      | 3202/8192 [03:27<05:46, 14.42it/s, est. speed input: 15773.89 toks/s, output: 15.40 toks/s]
Processed prompts:  40%|      | 3266/8192 [03:32<05:41, 14.40it/s, est. speed input: 15751.57 toks/s, output: 15.38 toks/s]
Processed prompts:  41%|      | 3330/8192 [03:36<05:37, 14.40it/s, est. speed input: 15730.52 toks/s, output: 15.36 toks/s]
Processed prompts:  41%|     | 3394/8192 [03:41<05:33, 14.40it/s, est. speed input: 15710.64 toks/s, output: 15.34 toks/s]
Processed prompts:  42%|     | 3458/8192 [03:45<05:26, 14.52it/s, est. speed input: 15699.98 toks/s, output: 15.33 toks/s]
Processed prompts:  43%|     | 3522/8192 [03:49<05:22, 14.47it/s, est. speed input: 15680.79 toks/s, output: 15.31 toks/s]
Processed prompts:  44%|     | 3586/8192 [03:54<05:18, 14.45it/s, est. speed input: 15662.88 toks/s, output: 15.30 toks/s]
Processed prompts:  45%|     | 3650/8192 [03:58<05:14, 14.43it/s, est. speed input: 15645.42 toks/s, output: 15.28 toks/s]
Processed prompts:  45%|     | 3714/8192 [04:03<05:09, 14.48it/s, est. speed input: 15632.92 toks/s, output: 15.27 toks/s]
Processed prompts:  46%|     | 3778/8192 [04:07<05:05, 14.45it/s, est. speed input: 15616.64 toks/s, output: 15.25 toks/s]
Processed prompts:  47%|     | 3842/8192 [04:12<05:00, 14.50it/s, est. speed input: 15605.33 toks/s, output: 15.24 toks/s]
Processed prompts:  48%|     | 3906/8192 [04:16<04:56, 14.46it/s, est. speed input: 15590.16 toks/s, output: 15.22 toks/s]
Processed prompts:  48%|     | 3970/8192 [04:21<04:52, 14.43it/s, est. speed input: 15575.02 toks/s, output: 15.21 toks/s]
Processed prompts:  49%|     | 4034/8192 [04:25<04:47, 14.49it/s, est. speed input: 15564.93 toks/s, output: 15.20 toks/s]
Processed prompts:  50%|     | 4098/8192 [04:29<04:43, 14.45it/s, est. speed input: 15550.69 toks/s, output: 15.19 toks/s]
Processed prompts:  51%|     | 4162/8192 [04:34<04:38, 14.49it/s, est. speed input: 15540.69 toks/s, output: 15.18 toks/s]
Processed prompts:  52%|    | 4226/8192 [04:38<04:31, 14.58it/s, est. speed input: 15534.95 toks/s, output: 15.17 toks/s]
Processed prompts:  52%|    | 4290/8192 [04:42<04:27, 14.59it/s, est. speed input: 15525.83 toks/s, output: 15.16 toks/s]
Processed prompts:  53%|    | 4354/8192 [04:47<04:24, 14.52it/s, est. speed input: 15513.33 toks/s, output: 15.15 toks/s]
Processed prompts:  54%|    | 4418/8192 [04:51<04:20, 14.48it/s, est. speed input: 15501.56 toks/s, output: 15.14 toks/s]
Processed prompts:  55%|    | 4482/8192 [04:56<04:16, 14.45it/s, est. speed input: 15489.78 toks/s, output: 15.13 toks/s]
Processed prompts:  55%|    | 4546/8192 [05:00<04:12, 14.42it/s, est. speed input: 15478.16 toks/s, output: 15.12 toks/s]
Processed prompts:  56%|    | 4610/8192 [05:05<04:08, 14.41it/s, est. speed input: 15466.98 toks/s, output: 15.10 toks/s]
Processed prompts:  57%|    | 4674/8192 [05:09<04:04, 14.40it/s, est. speed input: 15456.16 toks/s, output: 15.09 toks/s]
Processed prompts:  58%|    | 4738/8192 [05:14<03:58, 14.46it/s, est. speed input: 15449.07 toks/s, output: 15.09 toks/s]
Processed prompts:  59%|    | 4802/8192 [05:18<03:53, 14.50it/s, est. speed input: 15442.32 toks/s, output: 15.08 toks/s]
Processed prompts:  59%|    | 4866/8192 [05:22<03:49, 14.46it/s, est. speed input: 15432.33 toks/s, output: 15.07 toks/s]
Processed prompts:  60%|    | 4930/8192 [05:27<03:45, 14.43it/s, est. speed input: 15422.59 toks/s, output: 15.06 toks/s]
Processed prompts:  61%|    | 4994/8192 [05:31<03:39, 14.55it/s, est. speed input: 15419.66 toks/s, output: 15.06 toks/s]
Processed prompts:  62%|   | 5058/8192 [05:36<03:36, 14.49it/s, est. speed input: 15410.13 toks/s, output: 15.05 toks/s]
Processed prompts:  63%|   | 5122/8192 [05:40<03:32, 14.45it/s, est. speed input: 15400.87 toks/s, output: 15.04 toks/s]
Processed prompts:  63%|   | 5186/8192 [05:44<03:27, 14.50it/s, est. speed input: 15395.17 toks/s, output: 15.03 toks/s]
Processed prompts:  64%|   | 5250/8192 [05:49<03:23, 14.46it/s, est. speed input: 15386.35 toks/s, output: 15.03 toks/s]
Processed prompts:  65%|   | 5314/8192 [05:53<03:18, 14.50it/s, est. speed input: 15381.12 toks/s, output: 15.02 toks/s]
Processed prompts:  66%|   | 5378/8192 [05:58<03:13, 14.53it/s, est. speed input: 15375.74 toks/s, output: 15.02 toks/s]
Processed prompts:  66%|   | 5442/8192 [06:02<03:09, 14.48it/s, est. speed input: 15367.43 toks/s, output: 15.01 toks/s]
Processed prompts:  67%|   | 5506/8192 [06:07<03:05, 14.52it/s, est. speed input: 15362.65 toks/s, output: 15.00 toks/s]
Processed prompts:  68%|   | 5570/8192 [06:11<03:01, 14.47it/s, est. speed input: 15354.86 toks/s, output: 14.99 toks/s]
Processed prompts:  69%|   | 5634/8192 [06:15<02:56, 14.51it/s, est. speed input: 15350.15 toks/s, output: 14.99 toks/s]
Processed prompts:  70%|   | 5698/8192 [06:20<02:52, 14.47it/s, est. speed input: 15342.60 toks/s, output: 14.98 toks/s]
Processed prompts:  70%|   | 5762/8192 [06:24<02:48, 14.44it/s, est. speed input: 15335.26 toks/s, output: 14.98 toks/s]
Processed prompts:  71%|   | 5826/8192 [06:29<02:44, 14.42it/s, est. speed input: 15328.17 toks/s, output: 14.97 toks/s]
Processed prompts:  72%|  | 5890/8192 [06:33<02:39, 14.40it/s, est. speed input: 15321.34 toks/s, output: 14.96 toks/s]
Processed prompts:  73%|  | 5954/8192 [06:38<02:35, 14.40it/s, est. speed input: 15314.81 toks/s, output: 14.96 toks/s]
Processed prompts:  73%|  | 6018/8192 [06:42<02:31, 14.39it/s, est. speed input: 15308.10 toks/s, output: 14.95 toks/s]
Processed prompts:  74%|  | 6082/8192 [06:47<02:26, 14.38it/s, est. speed input: 15301.47 toks/s, output: 14.94 toks/s]
Processed prompts:  75%|  | 6146/8192 [06:51<02:22, 14.38it/s, est. speed input: 15295.09 toks/s, output: 14.94 toks/s]
Processed prompts:  76%|  | 6210/8192 [06:55<02:17, 14.38it/s, est. speed input: 15289.11 toks/s, output: 14.93 toks/s]
Processed prompts:  77%|  | 6274/8192 [07:00<02:13, 14.38it/s, est. speed input: 15282.96 toks/s, output: 14.92 toks/s]
Processed prompts:  77%|  | 6338/8192 [07:04<02:08, 14.37it/s, est. speed input: 15276.99 toks/s, output: 14.92 toks/s]
Processed prompts:  78%|  | 6402/8192 [07:09<02:04, 14.36it/s, est. speed input: 15270.79 toks/s, output: 14.91 toks/s]
Processed prompts:  79%|  | 6466/8192 [07:13<02:00, 14.36it/s, est. speed input: 15265.08 toks/s, output: 14.91 toks/s]
Processed prompts:  80%|  | 6530/8192 [07:18<01:55, 14.36it/s, est. speed input: 15259.36 toks/s, output: 14.90 toks/s]
Processed prompts:  80%|  | 6594/8192 [07:22<01:50, 14.43it/s, est. speed input: 15256.34 toks/s, output: 14.90 toks/s]
Processed prompts:  81%| | 6658/8192 [07:26<01:45, 14.49it/s, est. speed input: 15253.42 toks/s, output: 14.90 toks/s]
Processed prompts:  82%| | 6722/8192 [07:31<01:41, 14.46it/s, est. speed input: 15248.28 toks/s, output: 14.89 toks/s]
Processed prompts:  83%| | 6786/8192 [07:35<01:37, 14.43it/s, est. speed input: 15243.19 toks/s, output: 14.89 toks/s]
Processed prompts:  84%| | 6850/8192 [07:40<01:33, 14.41it/s, est. speed input: 15237.96 toks/s, output: 14.88 toks/s]
Processed prompts:  84%| | 6914/8192 [07:44<01:28, 14.40it/s, est. speed input: 15233.06 toks/s, output: 14.88 toks/s]
Processed prompts:  85%| | 6978/8192 [07:49<01:24, 14.39it/s, est. speed input: 15228.18 toks/s, output: 14.87 toks/s]
Processed prompts:  86%| | 7042/8192 [07:53<01:19, 14.39it/s, est. speed input: 15223.38 toks/s, output: 14.87 toks/s]
Processed prompts:  87%| | 7106/8192 [07:58<01:15, 14.45it/s, est. speed input: 15220.90 toks/s, output: 14.86 toks/s]
Processed prompts:  88%| | 7170/8192 [08:02<01:10, 14.43it/s, est. speed input: 15216.35 toks/s, output: 14.86 toks/s]
Processed prompts:  88%| | 7234/8192 [08:06<01:06, 14.48it/s, est. speed input: 15213.97 toks/s, output: 14.86 toks/s]
Processed prompts:  89%| | 7298/8192 [08:11<01:01, 14.44it/s, est. speed input: 15209.35 toks/s, output: 14.85 toks/s]
Processed prompts:  90%| | 7362/8192 [08:15<00:57, 14.42it/s, est. speed input: 15204.90 toks/s, output: 14.85 toks/s]
Processed prompts:  91%| | 7426/8192 [08:20<00:52, 14.48it/s, est. speed input: 15202.71 toks/s, output: 14.85 toks/s]
Processed prompts:  91%|| 7490/8192 [08:24<00:48, 14.44it/s, est. speed input: 15198.34 toks/s, output: 14.84 toks/s]
Processed prompts:  92%|| 7554/8192 [08:28<00:43, 14.56it/s, est. speed input: 15198.20 toks/s, output: 14.84 toks/s]
Processed prompts:  93%|| 7618/8192 [08:33<00:39, 14.50it/s, est. speed input: 15194.05 toks/s, output: 14.84 toks/s]
Processed prompts:  94%|| 7682/8192 [08:37<00:35, 14.53it/s, est. speed input: 15192.09 toks/s, output: 14.84 toks/s]
Processed prompts:  95%|| 7746/8192 [08:42<00:30, 14.49it/s, est. speed input: 15188.17 toks/s, output: 14.83 toks/s]
Processed prompts:  95%|| 7810/8192 [08:46<00:26, 14.45it/s, est. speed input: 15184.03 toks/s, output: 14.83 toks/s]
Processed prompts:  96%|| 7874/8192 [08:51<00:22, 14.43it/s, est. speed input: 15180.28 toks/s, output: 14.82 toks/s]
Processed prompts:  97%|| 7938/8192 [08:55<00:17, 14.48it/s, est. speed input: 15178.30 toks/s, output: 14.82 toks/s]
Processed prompts:  98%|| 8002/8192 [08:59<00:13, 14.45it/s, est. speed input: 15174.51 toks/s, output: 14.82 toks/s]
Processed prompts:  98%|| 8066/8192 [09:04<00:08, 14.50it/s, est. speed input: 15172.79 toks/s, output: 14.82 toks/s]
Processed prompts:  99%|| 8130/8192 [09:08<00:04, 14.59it/s, est. speed input: 15172.79 toks/s, output: 14.82 toks/s]
Processed prompts: 100%|| 8192/8192 [09:08<00:00, 14.59it/s, est. speed input: 15288.48 toks/s, output: 14.93 toks/s]
Processed prompts: 100%|| 8192/8192 [09:08<00:00, 14.93it/s, est. speed input: 15288.48 toks/s, output: 14.93 toks/s]
[rank0]:[W126 12:23:38.282936041 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-26 18:14:38
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Qwen2.5-7B-FP8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 18:14:42 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 18:14:42 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1587141) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1587141) WARNING 01-26 18:15:39 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 12.38 requests/s, 6348.77 total tokens/s, 12.38 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-26 18:14:41] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 18:14:42] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 18:14:42] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 18:14:42] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:14:42] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:14:42] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:14:42] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:14:42] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:14:42] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 18:14:42] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 18:14:42] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 18:14:42] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 18:14:42] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 18:14:42] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 18:14:45] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 18:14:45] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 18:14:45] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 18:14:45] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:14:45] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:14:45] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:14:45] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:14:45] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:14:45] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 18:14:45] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 18:14:45] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 18:14:45] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 18:14:45] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 18:14:45] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1587141) [2026-01-26 18:14:46] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1587141) [2026-01-26 18:14:46] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1587141) [2026-01-26 18:14:46] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1587141) [2026-01-26 18:14:46] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1587141) [2026-01-26 18:14:46] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1587141) [2026-01-26 18:14:46] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1587141) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1587141) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:20<00:20, 20.91s/it]
(EngineCore_DP0 pid=1587141) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:41<00:00, 20.94s/it]
(EngineCore_DP0 pid=1587141) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:41<00:00, 20.93s/it]
(EngineCore_DP0 pid=1587141) 
(EngineCore_DP0 pid=1587141) [2026-01-26 18:15:29] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=1587141) [2026-01-26 18:15:29] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10321920 bytes
(EngineCore_DP0 pid=1587141) [2026-01-26 18:15:29] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=1587141) [2026-01-26 18:15:29] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8028160 bytes
(EngineCore_DP0 pid=1587141) [2026-01-26 18:15:29] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=1587141) [2026-01-26 18:15:29] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 84869120 bytes
(EngineCore_DP0 pid=1587141) [2026-01-26 18:15:29] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=1587141) [2026-01-26 18:15:29] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 42434560 bytes
(EngineCore_DP0 pid=1587141) 2026-01-26 18:15:36,528 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1587141) 2026-01-26 18:15:36,643 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:   1%|          | 1/128 [00:00<01:50,  1.15it/s]
Adding requests:   2%|         | 2/128 [00:01<01:03,  1.97it/s]
Adding requests:   2%|         | 3/128 [00:01<00:42,  2.93it/s]
Adding requests:   3%|         | 4/128 [00:01<00:30,  4.01it/s]
Adding requests:   4%|         | 5/128 [00:01<00:24,  5.04it/s]
Adding requests:   5%|         | 7/128 [00:01<00:17,  7.07it/s]
Adding requests:   7%|         | 9/128 [00:01<00:13,  8.63it/s]
Adding requests:   9%|         | 12/128 [00:01<00:09, 12.40it/s]
Adding requests:  12%|        | 15/128 [00:02<00:06, 16.16it/s]
Adding requests:  15%|        | 19/128 [00:02<00:05, 21.20it/s]
Adding requests:  20%|        | 25/128 [00:02<00:03, 29.42it/s]
Adding requests:  26%|       | 33/128 [00:02<00:02, 41.61it/s]
Adding requests:  41%|      | 52/128 [00:02<00:00, 80.01it/s]
Adding requests:  62%|   | 80/128 [00:02<00:00, 133.57it/s]
Adding requests:  88%| | 112/128 [00:02<00:00, 185.27it/s]
Adding requests: 100%|| 128/128 [00:02<00:00, 46.85it/s] 

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  18%|        | 23/128 [00:00<00:00, 168.40it/s, est. speed input: 86240.41 toks/s, output: 168.41 toks/s]
Processed prompts:  31%|      | 40/128 [00:01<00:03, 26.00it/s, est. speed input: 15585.33 toks/s, output: 30.44 toks/s]  
Processed prompts:  38%|      | 48/128 [00:01<00:03, 21.52it/s, est. speed input: 13131.60 toks/s, output: 25.65 toks/s]
Processed prompts:  41%|     | 53/128 [00:02<00:03, 19.71it/s, est. speed input: 12234.87 toks/s, output: 23.90 toks/s]
Processed prompts:  45%|     | 57/128 [00:02<00:03, 18.51it/s, est. speed input: 11693.72 toks/s, output: 22.84 toks/s]
Processed prompts:  47%|     | 60/128 [00:02<00:03, 17.69it/s, est. speed input: 11354.11 toks/s, output: 22.18 toks/s]
Processed prompts:  49%|     | 63/128 [00:02<00:03, 16.93it/s, est. speed input: 11061.64 toks/s, output: 21.60 toks/s]
Processed prompts:  52%|    | 66/128 [00:03<00:03, 16.32it/s, est. speed input: 10813.43 toks/s, output: 21.12 toks/s]
Processed prompts:  53%|    | 68/128 [00:03<00:03, 15.90it/s, est. speed input: 10656.76 toks/s, output: 20.81 toks/s]
Processed prompts:  55%|    | 70/128 [00:03<00:03, 15.65it/s, est. speed input: 10531.19 toks/s, output: 20.57 toks/s]
Processed prompts:  56%|    | 72/128 [00:03<00:03, 15.37it/s, est. speed input: 10408.07 toks/s, output: 20.33 toks/s]
Processed prompts:  58%|    | 74/128 [00:03<00:03, 15.11it/s, est. speed input: 10291.20 toks/s, output: 20.10 toks/s]
Processed prompts:  59%|    | 76/128 [00:03<00:03, 14.87it/s, est. speed input: 10179.94 toks/s, output: 19.88 toks/s]
Processed prompts:  61%|    | 78/128 [00:03<00:03, 14.60it/s, est. speed input: 10068.26 toks/s, output: 19.66 toks/s]
Processed prompts:  62%|   | 80/128 [00:04<00:03, 14.51it/s, est. speed input: 9974.38 toks/s, output: 19.48 toks/s] 
Processed prompts:  64%|   | 82/128 [00:04<00:03, 14.48it/s, est. speed input: 9888.98 toks/s, output: 19.31 toks/s]
Processed prompts:  66%|   | 84/128 [00:04<00:03, 14.47it/s, est. speed input: 9810.74 toks/s, output: 19.16 toks/s]
Processed prompts:  67%|   | 86/128 [00:04<00:02, 14.41it/s, est. speed input: 9732.62 toks/s, output: 19.01 toks/s]
Processed prompts:  69%|   | 88/128 [00:04<00:02, 14.42it/s, est. speed input: 9663.19 toks/s, output: 18.87 toks/s]
Processed prompts:  70%|   | 90/128 [00:04<00:02, 14.41it/s, est. speed input: 9597.09 toks/s, output: 18.74 toks/s]
Processed prompts:  72%|  | 92/128 [00:04<00:02, 14.33it/s, est. speed input: 9529.80 toks/s, output: 18.61 toks/s]
Processed prompts:  73%|  | 94/128 [00:05<00:02, 14.19it/s, est. speed input: 9460.63 toks/s, output: 18.48 toks/s]
Processed prompts:  75%|  | 96/128 [00:05<00:02, 14.30it/s, est. speed input: 9408.31 toks/s, output: 18.38 toks/s]
Processed prompts:  77%|  | 98/128 [00:05<00:02, 14.26it/s, est. speed input: 9351.37 toks/s, output: 18.26 toks/s]
Processed prompts:  78%|  | 100/128 [00:05<00:01, 14.36it/s, est. speed input: 9304.91 toks/s, output: 18.17 toks/s]
Processed prompts:  80%|  | 102/128 [00:05<00:01, 14.31it/s, est. speed input: 9253.85 toks/s, output: 18.07 toks/s]
Processed prompts:  81%| | 104/128 [00:05<00:01, 14.26it/s, est. speed input: 9204.96 toks/s, output: 17.98 toks/s]
Processed prompts:  83%| | 106/128 [00:05<00:01, 14.30it/s, est. speed input: 9161.76 toks/s, output: 17.89 toks/s]
Processed prompts:  84%| | 108/128 [00:06<00:01, 14.19it/s, est. speed input: 9113.72 toks/s, output: 17.80 toks/s]
Processed prompts:  86%| | 110/128 [00:06<00:01, 14.18it/s, est. speed input: 9071.16 toks/s, output: 17.72 toks/s]
Processed prompts:  88%| | 112/128 [00:06<00:01, 14.24it/s, est. speed input: 9034.11 toks/s, output: 17.64 toks/s]
Processed prompts:  89%| | 114/128 [00:06<00:00, 14.31it/s, est. speed input: 8999.56 toks/s, output: 17.58 toks/s]
Processed prompts:  91%| | 116/128 [00:06<00:00, 14.34it/s, est. speed input: 8965.63 toks/s, output: 17.51 toks/s]
Processed prompts:  92%|| 118/128 [00:06<00:00, 14.34it/s, est. speed input: 8932.13 toks/s, output: 17.45 toks/s]
Processed prompts:  94%|| 120/128 [00:06<00:00, 14.41it/s, est. speed input: 8902.67 toks/s, output: 17.39 toks/s]
Processed prompts:  95%|| 122/128 [00:07<00:00, 14.33it/s, est. speed input: 8869.29 toks/s, output: 17.32 toks/s]
Processed prompts:  97%|| 124/128 [00:07<00:00, 14.16it/s, est. speed input: 8832.75 toks/s, output: 17.25 toks/s]
Processed prompts:  98%|| 126/128 [00:07<00:00, 14.18it/s, est. speed input: 8803.23 toks/s, output: 17.19 toks/s]
Processed prompts: 100%|| 128/128 [00:07<00:00, 13.93it/s, est. speed input: 8763.93 toks/s, output: 17.12 toks/s]
Processed prompts: 100%|| 128/128 [00:07<00:00, 13.93it/s, est. speed input: 8763.93 toks/s, output: 17.12 toks/s]
Processed prompts: 100%|| 128/128 [00:07<00:00, 17.12it/s, est. speed input: 8763.93 toks/s, output: 17.12 toks/s]
[rank0]:[W126 18:15:51.409725887 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-26 18:16:07
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Qwen2.5-7B-FP8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 18:16:11 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 18:16:11 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1588568) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1588568) WARNING 01-26 18:17:05 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 7.43 requests/s, 7611.07 total tokens/s, 7.43 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-26 18:16:11] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 18:16:11] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 18:16:11] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 18:16:11] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:16:11] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:16:11] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:16:11] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:16:11] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:16:11] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 18:16:11] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 18:16:11] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 18:16:11] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 18:16:11] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 18:16:11] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 18:16:14] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 18:16:14] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 18:16:14] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 18:16:14] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:16:14] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:16:14] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:16:14] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:16:14] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:16:14] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 18:16:14] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 18:16:14] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 18:16:14] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 18:16:14] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 18:16:14] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1588568) [2026-01-26 18:16:15] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1588568) [2026-01-26 18:16:15] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1588568) [2026-01-26 18:16:15] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1588568) [2026-01-26 18:16:15] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1588568) [2026-01-26 18:16:15] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1588568) [2026-01-26 18:16:15] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1588568) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1588568) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:21<00:21, 21.28s/it]
(EngineCore_DP0 pid=1588568) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:42<00:00, 21.06s/it]
(EngineCore_DP0 pid=1588568) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:42<00:00, 21.10s/it]
(EngineCore_DP0 pid=1588568) 
(EngineCore_DP0 pid=1588568) [2026-01-26 18:16:58] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=1588568) [2026-01-26 18:16:58] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10321920 bytes
(EngineCore_DP0 pid=1588568) [2026-01-26 18:16:58] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=1588568) [2026-01-26 18:16:58] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8028160 bytes
(EngineCore_DP0 pid=1588568) [2026-01-26 18:16:58] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=1588568) [2026-01-26 18:16:58] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 84869120 bytes
(EngineCore_DP0 pid=1588568) [2026-01-26 18:16:58] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=1588568) [2026-01-26 18:16:58] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 42434560 bytes
(EngineCore_DP0 pid=1588568) 2026-01-26 18:17:04,959 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1588568) 2026-01-26 18:17:05,020 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  25%|       | 32/128 [00:00<00:00, 312.11it/s]
Adding requests:  55%|    | 71/128 [00:00<00:00, 353.90it/s]
Adding requests:  86%| | 110/128 [00:00<00:00, 365.91it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 361.61it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 3/128 [00:00<00:05, 22.13it/s, est. speed input: 22664.85 toks/s, output: 22.13 toks/s]
Processed prompts:   5%|         | 6/128 [00:00<00:11, 10.33it/s, est. speed input: 11497.10 toks/s, output: 11.23 toks/s]
Processed prompts:   6%|         | 8/128 [00:00<00:13,  9.08it/s, est. speed input: 10215.17 toks/s, output: 9.98 toks/s] 
Processed prompts:   8%|         | 10/128 [00:01<00:13,  8.46it/s, est. speed input: 9568.61 toks/s, output: 9.34 toks/s]
Processed prompts:   9%|         | 11/128 [00:01<00:14,  8.28it/s, est. speed input: 9373.47 toks/s, output: 9.15 toks/s]
Processed prompts:   9%|         | 12/128 [00:01<00:14,  8.10it/s, est. speed input: 9205.08 toks/s, output: 8.99 toks/s]
Processed prompts:  10%|         | 13/128 [00:01<00:14,  7.94it/s, est. speed input: 9064.37 toks/s, output: 8.85 toks/s]
Processed prompts:  11%|         | 14/128 [00:01<00:14,  7.81it/s, est. speed input: 8945.20 toks/s, output: 8.74 toks/s]
Processed prompts:  12%|        | 15/128 [00:01<00:14,  7.77it/s, est. speed input: 8861.48 toks/s, output: 8.65 toks/s]
Processed prompts:  12%|        | 16/128 [00:01<00:14,  7.66it/s, est. speed input: 8768.19 toks/s, output: 8.56 toks/s]
Processed prompts:  13%|        | 17/128 [00:02<00:14,  7.52it/s, est. speed input: 8671.02 toks/s, output: 8.47 toks/s]
Processed prompts:  14%|        | 18/128 [00:02<00:14,  7.58it/s, est. speed input: 8624.60 toks/s, output: 8.42 toks/s]
Processed prompts:  15%|        | 19/128 [00:02<00:14,  7.53it/s, est. speed input: 8564.32 toks/s, output: 8.36 toks/s]
Processed prompts:  16%|        | 20/128 [00:02<00:14,  7.56it/s, est. speed input: 8522.92 toks/s, output: 8.32 toks/s]
Processed prompts:  16%|        | 21/128 [00:02<00:14,  7.54it/s, est. speed input: 8477.71 toks/s, output: 8.28 toks/s]
Processed prompts:  17%|        | 22/128 [00:02<00:14,  7.54it/s, est. speed input: 8441.24 toks/s, output: 8.24 toks/s]
Processed prompts:  18%|        | 23/128 [00:02<00:13,  7.53it/s, est. speed input: 8405.15 toks/s, output: 8.21 toks/s]
Processed prompts:  19%|        | 24/128 [00:02<00:13,  7.55it/s, est. speed input: 8376.48 toks/s, output: 8.18 toks/s]
Processed prompts:  20%|        | 25/128 [00:03<00:13,  7.47it/s, est. speed input: 8336.08 toks/s, output: 8.14 toks/s]
Processed prompts:  20%|        | 26/128 [00:03<00:13,  7.48it/s, est. speed input: 8308.90 toks/s, output: 8.11 toks/s]
Processed prompts:  21%|        | 27/128 [00:03<00:13,  7.46it/s, est. speed input: 8279.32 toks/s, output: 8.09 toks/s]
Processed prompts:  22%|       | 28/128 [00:03<00:13,  7.48it/s, est. speed input: 8257.21 toks/s, output: 8.06 toks/s]
Processed prompts:  23%|       | 29/128 [00:03<00:13,  7.48it/s, est. speed input: 8234.88 toks/s, output: 8.04 toks/s]
Processed prompts:  23%|       | 30/128 [00:03<00:13,  7.49it/s, est. speed input: 8215.75 toks/s, output: 8.02 toks/s]
Processed prompts:  24%|       | 31/128 [00:03<00:13,  7.45it/s, est. speed input: 8192.05 toks/s, output: 8.00 toks/s]
Processed prompts:  25%|       | 32/128 [00:04<00:12,  7.49it/s, est. speed input: 8177.65 toks/s, output: 7.99 toks/s]
Processed prompts:  26%|       | 33/128 [00:04<00:12,  7.43it/s, est. speed input: 8154.16 toks/s, output: 7.96 toks/s]
Processed prompts:  27%|       | 34/128 [00:04<00:12,  7.45it/s, est. speed input: 8139.20 toks/s, output: 7.95 toks/s]
Processed prompts:  27%|       | 35/128 [00:04<00:12,  7.52it/s, est. speed input: 8131.22 toks/s, output: 7.94 toks/s]
Processed prompts:  28%|       | 36/128 [00:04<00:12,  7.55it/s, est. speed input: 8121.61 toks/s, output: 7.93 toks/s]
Processed prompts:  29%|       | 37/128 [00:04<00:12,  7.55it/s, est. speed input: 8110.61 toks/s, output: 7.92 toks/s]
Processed prompts:  30%|       | 38/128 [00:04<00:11,  7.53it/s, est. speed input: 8097.90 toks/s, output: 7.91 toks/s]
Processed prompts:  30%|       | 39/128 [00:04<00:11,  7.52it/s, est. speed input: 8086.30 toks/s, output: 7.90 toks/s]
Processed prompts:  31%|      | 40/128 [00:05<00:11,  7.52it/s, est. speed input: 8076.21 toks/s, output: 7.89 toks/s]
Processed prompts:  32%|      | 41/128 [00:05<00:11,  7.48it/s, est. speed input: 8063.00 toks/s, output: 7.87 toks/s]
Processed prompts:  33%|      | 42/128 [00:05<00:11,  7.51it/s, est. speed input: 8055.87 toks/s, output: 7.87 toks/s]
Processed prompts:  34%|      | 43/128 [00:05<00:11,  7.53it/s, est. speed input: 8048.17 toks/s, output: 7.86 toks/s]
Processed prompts:  34%|      | 44/128 [00:05<00:11,  7.52it/s, est. speed input: 8039.82 toks/s, output: 7.85 toks/s]
Processed prompts:  35%|      | 45/128 [00:05<00:11,  7.48it/s, est. speed input: 8028.68 toks/s, output: 7.84 toks/s]
Processed prompts:  36%|      | 46/128 [00:05<00:10,  7.50it/s, est. speed input: 8021.90 toks/s, output: 7.83 toks/s]
Processed prompts:  37%|      | 47/128 [00:06<00:10,  7.50it/s, est. speed input: 8014.51 toks/s, output: 7.83 toks/s]
Processed prompts:  38%|      | 48/128 [00:06<00:10,  7.47it/s, est. speed input: 8004.65 toks/s, output: 7.82 toks/s]
Processed prompts:  38%|      | 49/128 [00:06<00:10,  7.37it/s, est. speed input: 7989.27 toks/s, output: 7.80 toks/s]
Processed prompts:  39%|      | 50/128 [00:06<00:10,  7.46it/s, est. speed input: 7986.89 toks/s, output: 7.80 toks/s]
Processed prompts:  40%|      | 51/128 [00:06<00:10,  7.47it/s, est. speed input: 7980.35 toks/s, output: 7.79 toks/s]
Processed prompts:  41%|      | 52/128 [00:06<00:10,  7.47it/s, est. speed input: 7973.76 toks/s, output: 7.79 toks/s]
Processed prompts:  41%|     | 53/128 [00:06<00:10,  7.47it/s, est. speed input: 7967.15 toks/s, output: 7.78 toks/s]
Processed prompts:  42%|     | 54/128 [00:06<00:09,  7.47it/s, est. speed input: 7960.88 toks/s, output: 7.77 toks/s]
Processed prompts:  43%|     | 55/128 [00:07<00:09,  7.51it/s, est. speed input: 7957.58 toks/s, output: 7.77 toks/s]
Processed prompts:  44%|     | 56/128 [00:07<00:09,  7.49it/s, est. speed input: 7951.45 toks/s, output: 7.77 toks/s]
Processed prompts:  45%|     | 57/128 [00:07<00:09,  7.41it/s, est. speed input: 7940.99 toks/s, output: 7.75 toks/s]
Processed prompts:  45%|     | 58/128 [00:07<00:09,  7.44it/s, est. speed input: 7936.44 toks/s, output: 7.75 toks/s]
Processed prompts:  46%|     | 59/128 [00:07<00:09,  7.49it/s, est. speed input: 7934.04 toks/s, output: 7.75 toks/s]
Processed prompts:  47%|     | 60/128 [00:07<00:09,  7.44it/s, est. speed input: 7926.72 toks/s, output: 7.74 toks/s]
Processed prompts:  48%|     | 61/128 [00:07<00:08,  7.47it/s, est. speed input: 7922.99 toks/s, output: 7.74 toks/s]
Processed prompts:  48%|     | 62/128 [00:08<00:08,  7.52it/s, est. speed input: 7921.66 toks/s, output: 7.74 toks/s]
Processed prompts:  49%|     | 63/128 [00:08<00:08,  7.51it/s, est. speed input: 7917.19 toks/s, output: 7.73 toks/s]
Processed prompts:  50%|     | 64/128 [00:08<00:08,  7.54it/s, est. speed input: 7915.53 toks/s, output: 7.73 toks/s]
Processed prompts:  51%|     | 65/128 [00:08<00:08,  7.46it/s, est. speed input: 7907.85 toks/s, output: 7.72 toks/s]
Processed prompts:  52%|    | 66/128 [00:08<00:08,  7.44it/s, est. speed input: 7902.32 toks/s, output: 7.72 toks/s]
Processed prompts:  52%|    | 67/128 [00:08<00:08,  7.45it/s, est. speed input: 7898.76 toks/s, output: 7.71 toks/s]
Processed prompts:  53%|    | 68/128 [00:08<00:08,  7.48it/s, est. speed input: 7896.07 toks/s, output: 7.71 toks/s]
Processed prompts:  54%|    | 69/128 [00:08<00:07,  7.48it/s, est. speed input: 7892.68 toks/s, output: 7.71 toks/s]
Processed prompts:  55%|    | 70/128 [00:09<00:07,  7.49it/s, est. speed input: 7889.50 toks/s, output: 7.70 toks/s]
Processed prompts:  55%|    | 71/128 [00:09<00:07,  7.50it/s, est. speed input: 7886.81 toks/s, output: 7.70 toks/s]
Processed prompts:  56%|    | 72/128 [00:09<00:07,  7.47it/s, est. speed input: 7882.48 toks/s, output: 7.70 toks/s]
Processed prompts:  57%|    | 73/128 [00:09<00:07,  7.39it/s, est. speed input: 7875.18 toks/s, output: 7.69 toks/s]
Processed prompts:  58%|    | 74/128 [00:09<00:07,  7.44it/s, est. speed input: 7873.55 toks/s, output: 7.69 toks/s]
Processed prompts:  59%|    | 75/128 [00:09<00:07,  7.49it/s, est. speed input: 7872.10 toks/s, output: 7.69 toks/s]
Processed prompts:  59%|    | 76/128 [00:09<00:06,  7.48it/s, est. speed input: 7869.07 toks/s, output: 7.68 toks/s]
Processed prompts:  60%|    | 77/128 [00:10<00:06,  7.49it/s, est. speed input: 7866.82 toks/s, output: 7.68 toks/s]
Processed prompts:  61%|    | 78/128 [00:10<00:06,  7.50it/s, est. speed input: 7864.84 toks/s, output: 7.68 toks/s]
Processed prompts:  62%|   | 79/128 [00:10<00:06,  7.46it/s, est. speed input: 7860.34 toks/s, output: 7.68 toks/s]
Processed prompts:  62%|   | 80/128 [00:10<00:06,  7.43it/s, est. speed input: 7856.23 toks/s, output: 7.67 toks/s]
Processed prompts:  63%|   | 81/128 [00:10<00:06,  7.39it/s, est. speed input: 7851.38 toks/s, output: 7.67 toks/s]
Processed prompts:  64%|   | 82/128 [00:10<00:06,  7.43it/s, est. speed input: 7849.55 toks/s, output: 7.67 toks/s]
Processed prompts:  65%|   | 83/128 [00:10<00:06,  7.40it/s, est. speed input: 7845.38 toks/s, output: 7.66 toks/s]
Processed prompts:  66%|   | 84/128 [00:10<00:05,  7.43it/s, est. speed input: 7843.16 toks/s, output: 7.66 toks/s]
Processed prompts:  66%|   | 85/128 [00:11<00:05,  7.45it/s, est. speed input: 7841.15 toks/s, output: 7.66 toks/s]
Processed prompts:  67%|   | 86/128 [00:11<00:05,  7.49it/s, est. speed input: 7840.39 toks/s, output: 7.66 toks/s]
Processed prompts:  68%|   | 87/128 [00:11<00:05,  7.44it/s, est. speed input: 7836.29 toks/s, output: 7.65 toks/s]
Processed prompts:  69%|   | 88/128 [00:11<00:05,  7.41it/s, est. speed input: 7832.43 toks/s, output: 7.65 toks/s]
Processed prompts:  70%|   | 89/128 [00:11<00:05,  7.42it/s, est. speed input: 7830.12 toks/s, output: 7.65 toks/s]
Processed prompts:  70%|   | 90/128 [00:11<00:05,  7.43it/s, est. speed input: 7827.81 toks/s, output: 7.64 toks/s]
Processed prompts:  71%|   | 91/128 [00:11<00:04,  7.42it/s, est. speed input: 7825.09 toks/s, output: 7.64 toks/s]
Processed prompts:  72%|  | 92/128 [00:12<00:04,  7.50it/s, est. speed input: 7825.47 toks/s, output: 7.64 toks/s]
Processed prompts:  73%|  | 93/128 [00:12<00:04,  7.51it/s, est. speed input: 7824.33 toks/s, output: 7.64 toks/s]
Processed prompts:  73%|  | 94/128 [00:12<00:04,  7.50it/s, est. speed input: 7822.33 toks/s, output: 7.64 toks/s]
Processed prompts:  74%|  | 95/128 [00:12<00:04,  7.54it/s, est. speed input: 7822.34 toks/s, output: 7.64 toks/s]
Processed prompts:  75%|  | 96/128 [00:12<00:04,  7.43it/s, est. speed input: 7817.09 toks/s, output: 7.63 toks/s]
Processed prompts:  76%|  | 97/128 [00:12<00:04,  7.41it/s, est. speed input: 7814.24 toks/s, output: 7.63 toks/s]
Processed prompts:  77%|  | 98/128 [00:12<00:04,  7.45it/s, est. speed input: 7813.50 toks/s, output: 7.63 toks/s]
Processed prompts:  77%|  | 99/128 [00:12<00:03,  7.45it/s, est. speed input: 7811.64 toks/s, output: 7.63 toks/s]
Processed prompts:  78%|  | 100/128 [00:13<00:03,  7.48it/s, est. speed input: 7810.65 toks/s, output: 7.63 toks/s]
Processed prompts:  79%|  | 101/128 [00:13<00:03,  7.49it/s, est. speed input: 7809.67 toks/s, output: 7.63 toks/s]
Processed prompts:  80%|  | 102/128 [00:13<00:03,  7.48it/s, est. speed input: 7807.75 toks/s, output: 7.62 toks/s]
Processed prompts:  80%|  | 103/128 [00:13<00:03,  7.44it/s, est. speed input: 7805.12 toks/s, output: 7.62 toks/s]
Processed prompts:  81%| | 104/128 [00:13<00:03,  7.38it/s, est. speed input: 7800.92 toks/s, output: 7.62 toks/s]
Processed prompts:  82%| | 105/128 [00:13<00:03,  7.36it/s, est. speed input: 7798.08 toks/s, output: 7.62 toks/s]
Processed prompts:  83%| | 106/128 [00:13<00:02,  7.44it/s, est. speed input: 7797.99 toks/s, output: 7.62 toks/s]
Processed prompts:  84%| | 107/128 [00:14<00:02,  7.44it/s, est. speed input: 7796.40 toks/s, output: 7.61 toks/s]
Processed prompts:  84%| | 108/128 [00:14<00:02,  7.43it/s, est. speed input: 7794.53 toks/s, output: 7.61 toks/s]
Processed prompts:  85%| | 109/128 [00:14<00:02,  7.46it/s, est. speed input: 7793.53 toks/s, output: 7.61 toks/s]
Processed prompts:  86%| | 110/128 [00:14<00:02,  7.48it/s, est. speed input: 7792.78 toks/s, output: 7.61 toks/s]
Processed prompts:  87%| | 111/128 [00:14<00:02,  7.51it/s, est. speed input: 7792.43 toks/s, output: 7.61 toks/s]
Processed prompts:  88%| | 112/128 [00:14<00:02,  7.40it/s, est. speed input: 7788.25 toks/s, output: 7.61 toks/s]
Processed prompts:  88%| | 113/128 [00:14<00:02,  7.42it/s, est. speed input: 7786.96 toks/s, output: 7.60 toks/s]
Processed prompts:  89%| | 114/128 [00:14<00:01,  7.43it/s, est. speed input: 7785.40 toks/s, output: 7.60 toks/s]
Processed prompts:  90%| | 115/128 [00:15<00:01,  7.41it/s, est. speed input: 7783.26 toks/s, output: 7.60 toks/s]
Processed prompts:  91%| | 116/128 [00:15<00:01,  7.39it/s, est. speed input: 7780.97 toks/s, output: 7.60 toks/s]
Processed prompts:  91%|| 117/128 [00:15<00:01,  7.39it/s, est. speed input: 7779.06 toks/s, output: 7.60 toks/s]
Processed prompts:  92%|| 118/128 [00:15<00:01,  7.46it/s, est. speed input: 7779.22 toks/s, output: 7.60 toks/s]
Processed prompts:  93%|| 119/128 [00:15<00:01,  7.45it/s, est. speed input: 7777.73 toks/s, output: 7.60 toks/s]
Processed prompts:  94%|| 120/128 [00:15<00:01,  7.35it/s, est. speed input: 7773.43 toks/s, output: 7.59 toks/s]
Processed prompts:  95%|| 121/128 [00:15<00:00,  7.37it/s, est. speed input: 7772.08 toks/s, output: 7.59 toks/s]
Processed prompts:  95%|| 122/128 [00:16<00:00,  7.39it/s, est. speed input: 7770.86 toks/s, output: 7.59 toks/s]
Processed prompts:  96%|| 123/128 [00:16<00:00,  7.40it/s, est. speed input: 7769.24 toks/s, output: 7.59 toks/s]
Processed prompts:  97%|| 124/128 [00:16<00:00,  7.42it/s, est. speed input: 7768.40 toks/s, output: 7.59 toks/s]
Processed prompts:  98%|| 125/128 [00:16<00:00,  7.44it/s, est. speed input: 7767.52 toks/s, output: 7.59 toks/s]
Processed prompts:  98%|| 126/128 [00:16<00:00,  7.46it/s, est. speed input: 7766.98 toks/s, output: 7.58 toks/s]
Processed prompts:  99%|| 127/128 [00:16<00:00,  7.52it/s, est. speed input: 7767.43 toks/s, output: 7.59 toks/s]
Processed prompts: 100%|| 128/128 [00:16<00:00,  7.40it/s, est. speed input: 7763.62 toks/s, output: 7.58 toks/s]
Processed prompts: 100%|| 128/128 [00:16<00:00,  7.40it/s, est. speed input: 7763.62 toks/s, output: 7.58 toks/s]
Processed prompts: 100%|| 128/128 [00:16<00:00,  7.58it/s, est. speed input: 7763.62 toks/s, output: 7.58 toks/s]
[rank0]:[W126 18:17:23.399393628 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-26 18:17:25
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Qwen2.5-7B-FP8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 18:17:31 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 18:17:31 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1589875) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1589875) WARNING 01-26 18:18:20 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 7.40 requests/s, 7590.03 total tokens/s, 7.40 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-26 18:17:31] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 18:17:31] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 18:17:31] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 18:17:31] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:17:31] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:17:31] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:17:31] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:17:31] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:17:31] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 18:17:31] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 18:17:31] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 18:17:31] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 18:17:31] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 18:17:31] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 18:17:35] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 18:17:35] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 18:17:35] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 18:17:35] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:17:35] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:17:35] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:17:35] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:17:35] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:17:35] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 18:17:35] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 18:17:35] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 18:17:35] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 18:17:35] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 18:17:35] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1589875) [2026-01-26 18:17:36] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1589875) [2026-01-26 18:17:36] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1589875) [2026-01-26 18:17:36] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1589875) [2026-01-26 18:17:36] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1589875) [2026-01-26 18:17:36] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1589875) [2026-01-26 18:17:36] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1589875) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1589875) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:15<00:15, 15.29s/it]
(EngineCore_DP0 pid=1589875) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:36<00:00, 18.61s/it]
(EngineCore_DP0 pid=1589875) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:36<00:00, 18.11s/it]
(EngineCore_DP0 pid=1589875) 
(EngineCore_DP0 pid=1589875) [2026-01-26 18:18:13] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=1589875) [2026-01-26 18:18:13] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10321920 bytes
(EngineCore_DP0 pid=1589875) [2026-01-26 18:18:13] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=1589875) [2026-01-26 18:18:13] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8028160 bytes
(EngineCore_DP0 pid=1589875) [2026-01-26 18:18:13] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=1589875) [2026-01-26 18:18:13] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 84869120 bytes
(EngineCore_DP0 pid=1589875) [2026-01-26 18:18:13] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=1589875) [2026-01-26 18:18:13] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 42434560 bytes
(EngineCore_DP0 pid=1589875) 2026-01-26 18:18:19,352 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1589875) 2026-01-26 18:18:19,445 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  11%|         | 28/256 [00:00<00:00, 278.24it/s]
Adding requests:  25%|       | 63/256 [00:00<00:00, 319.34it/s]
Adding requests:  39%|      | 100/256 [00:00<00:00, 341.57it/s]
Adding requests:  54%|    | 139/256 [00:00<00:00, 359.08it/s]
Adding requests:  71%|   | 181/256 [00:00<00:00, 380.06it/s]
Adding requests:  88%| | 225/256 [00:00<00:00, 396.90it/s]
Adding requests: 100%|| 256/256 [00:00<00:00, 375.44it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 6/256 [00:00<00:15, 16.10it/s, est. speed input: 16485.99 toks/s, output: 16.10 toks/s]
Processed prompts:   3%|         | 8/256 [00:00<00:21, 11.69it/s, est. speed input: 12753.45 toks/s, output: 12.45 toks/s]
Processed prompts:   4%|         | 10/256 [00:00<00:24,  9.91it/s, est. speed input: 11242.81 toks/s, output: 10.98 toks/s]
Processed prompts:   5%|         | 12/256 [00:01<00:27,  9.02it/s, est. speed input: 10446.15 toks/s, output: 10.20 toks/s]
Processed prompts:   5%|         | 14/256 [00:01<00:28,  8.44it/s, est. speed input: 9898.99 toks/s, output: 9.67 toks/s]  
Processed prompts:   6%|         | 16/256 [00:01<00:29,  8.13it/s, est. speed input: 9554.46 toks/s, output: 9.33 toks/s]
Processed prompts:   7%|         | 18/256 [00:02<00:30,  7.73it/s, est. speed input: 9202.64 toks/s, output: 8.99 toks/s]
Processed prompts:   8%|         | 20/256 [00:02<00:30,  7.64it/s, est. speed input: 9015.80 toks/s, output: 8.80 toks/s]
Processed prompts:   9%|         | 22/256 [00:02<00:31,  7.55it/s, est. speed input: 8854.99 toks/s, output: 8.65 toks/s]
Processed prompts:   9%|         | 24/256 [00:02<00:30,  7.52it/s, est. speed input: 8739.78 toks/s, output: 8.53 toks/s]
Processed prompts:  10%|         | 26/256 [00:03<00:30,  7.49it/s, est. speed input: 8640.89 toks/s, output: 8.44 toks/s]
Processed prompts:  11%|         | 28/256 [00:03<00:30,  7.47it/s, est. speed input: 8557.93 toks/s, output: 8.36 toks/s]
Processed prompts:  12%|        | 30/256 [00:03<00:30,  7.43it/s, est. speed input: 8478.67 toks/s, output: 8.28 toks/s]
Processed prompts:  12%|        | 32/256 [00:03<00:30,  7.43it/s, est. speed input: 8417.82 toks/s, output: 8.22 toks/s]
Processed prompts:  13%|        | 34/256 [00:04<00:29,  7.44it/s, est. speed input: 8367.22 toks/s, output: 8.17 toks/s]
Processed prompts:  14%|        | 36/256 [00:04<00:29,  7.46it/s, est. speed input: 8327.86 toks/s, output: 8.13 toks/s]
Processed prompts:  15%|        | 38/256 [00:04<00:29,  7.43it/s, est. speed input: 8280.53 toks/s, output: 8.09 toks/s]
Processed prompts:  16%|        | 40/256 [00:04<00:29,  7.44it/s, est. speed input: 8246.42 toks/s, output: 8.05 toks/s]
Processed prompts:  16%|        | 42/256 [00:05<00:28,  7.44it/s, est. speed input: 8214.93 toks/s, output: 8.02 toks/s]
Processed prompts:  17%|        | 44/256 [00:05<00:28,  7.44it/s, est. speed input: 8184.82 toks/s, output: 7.99 toks/s]
Processed prompts:  18%|        | 46/256 [00:05<00:28,  7.41it/s, est. speed input: 8153.54 toks/s, output: 7.96 toks/s]
Processed prompts:  19%|        | 48/256 [00:06<00:28,  7.43it/s, est. speed input: 8130.92 toks/s, output: 7.94 toks/s]
Processed prompts:  20%|        | 50/256 [00:06<00:27,  7.44it/s, est. speed input: 8109.95 toks/s, output: 7.92 toks/s]
Processed prompts:  20%|        | 52/256 [00:06<00:27,  7.43it/s, est. speed input: 8089.40 toks/s, output: 7.90 toks/s]
Processed prompts:  21%|        | 54/256 [00:06<00:27,  7.40it/s, est. speed input: 8066.18 toks/s, output: 7.88 toks/s]
Processed prompts:  22%|       | 56/256 [00:07<00:26,  7.42it/s, est. speed input: 8050.05 toks/s, output: 7.86 toks/s]
Processed prompts:  23%|       | 58/256 [00:07<00:26,  7.42it/s, est. speed input: 8034.20 toks/s, output: 7.85 toks/s]
Processed prompts:  23%|       | 60/256 [00:07<00:26,  7.42it/s, est. speed input: 8019.07 toks/s, output: 7.83 toks/s]
Processed prompts:  24%|       | 62/256 [00:07<00:26,  7.38it/s, est. speed input: 7999.49 toks/s, output: 7.81 toks/s]
Processed prompts:  25%|       | 64/256 [00:08<00:25,  7.39it/s, est. speed input: 7986.61 toks/s, output: 7.80 toks/s]
Processed prompts:  26%|       | 66/256 [00:08<00:25,  7.41it/s, est. speed input: 7975.04 toks/s, output: 7.79 toks/s]
Processed prompts:  27%|       | 68/256 [00:08<00:25,  7.42it/s, est. speed input: 7963.81 toks/s, output: 7.78 toks/s]
Processed prompts:  27%|       | 70/256 [00:09<00:25,  7.38it/s, est. speed input: 7948.61 toks/s, output: 7.76 toks/s]
Processed prompts:  28%|       | 72/256 [00:09<00:24,  7.39it/s, est. speed input: 7938.77 toks/s, output: 7.75 toks/s]
Processed prompts:  29%|       | 74/256 [00:09<00:24,  7.41it/s, est. speed input: 7930.49 toks/s, output: 7.74 toks/s]
Processed prompts:  30%|       | 76/256 [00:09<00:24,  7.42it/s, est. speed input: 7921.63 toks/s, output: 7.74 toks/s]
Processed prompts:  30%|       | 78/256 [00:10<00:24,  7.40it/s, est. speed input: 7911.08 toks/s, output: 7.73 toks/s]
Processed prompts:  31%|      | 80/256 [00:10<00:23,  7.43it/s, est. speed input: 7905.00 toks/s, output: 7.72 toks/s]
Processed prompts:  32%|      | 82/256 [00:10<00:23,  7.42it/s, est. speed input: 7896.43 toks/s, output: 7.71 toks/s]
Processed prompts:  33%|      | 84/256 [00:10<00:23,  7.42it/s, est. speed input: 7889.23 toks/s, output: 7.70 toks/s]
Processed prompts:  34%|      | 86/256 [00:11<00:22,  7.40it/s, est. speed input: 7880.84 toks/s, output: 7.70 toks/s]
Processed prompts:  34%|      | 88/256 [00:11<00:22,  7.42it/s, est. speed input: 7874.97 toks/s, output: 7.69 toks/s]
Processed prompts:  35%|      | 90/256 [00:11<00:22,  7.44it/s, est. speed input: 7870.10 toks/s, output: 7.69 toks/s]
Processed prompts:  36%|      | 92/256 [00:11<00:22,  7.44it/s, est. speed input: 7864.39 toks/s, output: 7.68 toks/s]
Processed prompts:  37%|      | 94/256 [00:12<00:21,  7.40it/s, est. speed input: 7855.76 toks/s, output: 7.67 toks/s]
Processed prompts:  38%|      | 96/256 [00:12<00:21,  7.41it/s, est. speed input: 7850.43 toks/s, output: 7.67 toks/s]
Processed prompts:  38%|      | 98/256 [00:12<00:21,  7.42it/s, est. speed input: 7846.11 toks/s, output: 7.66 toks/s]
Processed prompts:  39%|      | 100/256 [00:13<00:21,  7.43it/s, est. speed input: 7841.30 toks/s, output: 7.66 toks/s]
Processed prompts:  40%|      | 102/256 [00:13<00:20,  7.40it/s, est. speed input: 7834.91 toks/s, output: 7.65 toks/s]
Processed prompts:  41%|      | 104/256 [00:13<00:20,  7.42it/s, est. speed input: 7831.15 toks/s, output: 7.65 toks/s]
Processed prompts:  41%|     | 106/256 [00:13<00:20,  7.44it/s, est. speed input: 7827.86 toks/s, output: 7.64 toks/s]
Processed prompts:  42%|     | 108/256 [00:14<00:19,  7.43it/s, est. speed input: 7823.00 toks/s, output: 7.64 toks/s]
Processed prompts:  43%|     | 110/256 [00:14<00:19,  7.41it/s, est. speed input: 7817.55 toks/s, output: 7.63 toks/s]
Processed prompts:  44%|     | 112/256 [00:14<00:19,  7.43it/s, est. speed input: 7814.93 toks/s, output: 7.63 toks/s]
Processed prompts:  45%|     | 114/256 [00:14<00:19,  7.43it/s, est. speed input: 7811.00 toks/s, output: 7.63 toks/s]
Processed prompts:  45%|     | 116/256 [00:15<00:18,  7.40it/s, est. speed input: 7805.36 toks/s, output: 7.62 toks/s]
Processed prompts:  46%|     | 118/256 [00:15<00:18,  7.41it/s, est. speed input: 7802.40 toks/s, output: 7.62 toks/s]
Processed prompts:  47%|     | 120/256 [00:15<00:18,  7.43it/s, est. speed input: 7799.82 toks/s, output: 7.62 toks/s]
Processed prompts:  48%|     | 122/256 [00:16<00:18,  7.44it/s, est. speed input: 7796.99 toks/s, output: 7.61 toks/s]
Processed prompts:  48%|     | 124/256 [00:16<00:17,  7.41it/s, est. speed input: 7792.26 toks/s, output: 7.61 toks/s]
Processed prompts:  49%|     | 126/256 [00:16<00:17,  7.42it/s, est. speed input: 7789.40 toks/s, output: 7.61 toks/s]
Processed prompts:  50%|     | 128/256 [00:16<00:17,  7.42it/s, est. speed input: 7786.60 toks/s, output: 7.60 toks/s]
Processed prompts:  51%|     | 130/256 [00:17<00:16,  7.43it/s, est. speed input: 7784.22 toks/s, output: 7.60 toks/s]
Processed prompts:  52%|    | 132/256 [00:17<00:16,  7.39it/s, est. speed input: 7779.42 toks/s, output: 7.60 toks/s]
Processed prompts:  52%|    | 134/256 [00:17<00:16,  7.41it/s, est. speed input: 7777.22 toks/s, output: 7.59 toks/s]
Processed prompts:  53%|    | 136/256 [00:17<00:16,  7.41it/s, est. speed input: 7774.27 toks/s, output: 7.59 toks/s]
Processed prompts:  54%|    | 138/256 [00:18<00:15,  7.42it/s, est. speed input: 7771.98 toks/s, output: 7.59 toks/s]
Processed prompts:  55%|    | 140/256 [00:18<00:15,  7.39it/s, est. speed input: 7767.90 toks/s, output: 7.59 toks/s]
Processed prompts:  55%|    | 142/256 [00:18<00:15,  7.42it/s, est. speed input: 7766.72 toks/s, output: 7.58 toks/s]
Processed prompts:  56%|    | 144/256 [00:18<00:15,  7.41it/s, est. speed input: 7763.74 toks/s, output: 7.58 toks/s]
Processed prompts:  57%|    | 146/256 [00:19<00:14,  7.44it/s, est. speed input: 7762.54 toks/s, output: 7.58 toks/s]
Processed prompts:  58%|    | 148/256 [00:19<00:14,  7.41it/s, est. speed input: 7759.46 toks/s, output: 7.58 toks/s]
Processed prompts:  59%|    | 150/256 [00:19<00:14,  7.41it/s, est. speed input: 7757.20 toks/s, output: 7.58 toks/s]
Processed prompts:  59%|    | 152/256 [00:20<00:14,  7.42it/s, est. speed input: 7755.25 toks/s, output: 7.57 toks/s]
Processed prompts:  60%|    | 154/256 [00:20<00:13,  7.42it/s, est. speed input: 7753.20 toks/s, output: 7.57 toks/s]
Processed prompts:  61%|    | 156/256 [00:20<00:13,  7.39it/s, est. speed input: 7749.96 toks/s, output: 7.57 toks/s]
Processed prompts:  62%|   | 158/256 [00:20<00:13,  7.40it/s, est. speed input: 7747.98 toks/s, output: 7.57 toks/s]
Processed prompts:  62%|   | 160/256 [00:21<00:12,  7.40it/s, est. speed input: 7745.87 toks/s, output: 7.56 toks/s]
Processed prompts:  63%|   | 162/256 [00:21<00:12,  7.41it/s, est. speed input: 7744.33 toks/s, output: 7.56 toks/s]
Processed prompts:  64%|   | 164/256 [00:21<00:12,  7.41it/s, est. speed input: 7742.02 toks/s, output: 7.56 toks/s]
Processed prompts:  65%|   | 166/256 [00:21<00:12,  7.40it/s, est. speed input: 7740.00 toks/s, output: 7.56 toks/s]
Processed prompts:  66%|   | 168/256 [00:22<00:11,  7.43it/s, est. speed input: 7739.03 toks/s, output: 7.56 toks/s]
Processed prompts:  66%|   | 170/256 [00:22<00:11,  7.42it/s, est. speed input: 7737.22 toks/s, output: 7.56 toks/s]
Processed prompts:  67%|   | 172/256 [00:22<00:11,  7.39it/s, est. speed input: 7734.15 toks/s, output: 7.55 toks/s]
Processed prompts:  68%|   | 174/256 [00:23<00:11,  7.38it/s, est. speed input: 7731.81 toks/s, output: 7.55 toks/s]
Processed prompts:  69%|   | 176/256 [00:23<00:10,  7.39it/s, est. speed input: 7730.04 toks/s, output: 7.55 toks/s]
Processed prompts:  70%|   | 178/256 [00:23<00:10,  7.39it/s, est. speed input: 7728.44 toks/s, output: 7.55 toks/s]
Processed prompts:  70%|   | 180/256 [00:23<00:10,  7.39it/s, est. speed input: 7726.43 toks/s, output: 7.55 toks/s]
Processed prompts:  71%|   | 182/256 [00:24<00:10,  7.40it/s, est. speed input: 7725.07 toks/s, output: 7.54 toks/s]
Processed prompts:  72%|  | 184/256 [00:24<00:09,  7.42it/s, est. speed input: 7724.04 toks/s, output: 7.54 toks/s]
Processed prompts:  73%|  | 186/256 [00:24<00:09,  7.41it/s, est. speed input: 7722.30 toks/s, output: 7.54 toks/s]
Processed prompts:  73%|  | 188/256 [00:24<00:09,  7.37it/s, est. speed input: 7719.30 toks/s, output: 7.54 toks/s]
Processed prompts:  74%|  | 190/256 [00:25<00:08,  7.39it/s, est. speed input: 7718.27 toks/s, output: 7.54 toks/s]
Processed prompts:  75%|  | 192/256 [00:25<00:08,  7.41it/s, est. speed input: 7717.49 toks/s, output: 7.54 toks/s]
Processed prompts:  76%|  | 194/256 [00:25<00:08,  7.43it/s, est. speed input: 7716.95 toks/s, output: 7.54 toks/s]
Processed prompts:  77%|  | 196/256 [00:26<00:08,  7.39it/s, est. speed input: 7714.21 toks/s, output: 7.53 toks/s]
Processed prompts:  77%|  | 198/256 [00:26<00:07,  7.42it/s, est. speed input: 7713.66 toks/s, output: 7.53 toks/s]
Processed prompts:  78%|  | 200/256 [00:26<00:07,  7.43it/s, est. speed input: 7712.99 toks/s, output: 7.53 toks/s]
Processed prompts:  79%|  | 202/256 [00:26<00:06,  8.31it/s, est. speed input: 7739.22 toks/s, output: 7.56 toks/s]
Processed prompts:  80%|  | 204/256 [00:27<00:06,  7.97it/s, est. speed input: 7736.32 toks/s, output: 7.55 toks/s]
Processed prompts:  80%|  | 206/256 [00:27<00:06,  7.82it/s, est. speed input: 7735.66 toks/s, output: 7.55 toks/s]
Processed prompts:  81%| | 208/256 [00:27<00:06,  7.69it/s, est. speed input: 7734.13 toks/s, output: 7.55 toks/s]
Processed prompts:  82%| | 210/256 [00:27<00:06,  7.63it/s, est. speed input: 7733.45 toks/s, output: 7.55 toks/s]
Processed prompts:  83%| | 212/256 [00:28<00:05,  7.54it/s, est. speed input: 7731.26 toks/s, output: 7.55 toks/s]
Processed prompts:  84%| | 214/256 [00:28<00:05,  7.50it/s, est. speed input: 7730.04 toks/s, output: 7.55 toks/s]
Processed prompts:  84%| | 216/256 [00:28<00:05,  7.47it/s, est. speed input: 7728.69 toks/s, output: 7.55 toks/s]
Processed prompts:  85%| | 218/256 [00:28<00:05,  7.47it/s, est. speed input: 7728.00 toks/s, output: 7.55 toks/s]
Processed prompts:  86%| | 220/256 [00:29<00:04,  7.43it/s, est. speed input: 7725.91 toks/s, output: 7.54 toks/s]
Processed prompts:  87%| | 222/256 [00:29<00:04,  7.42it/s, est. speed input: 7724.53 toks/s, output: 7.54 toks/s]
Processed prompts:  88%| | 224/256 [00:29<00:04,  7.43it/s, est. speed input: 7723.55 toks/s, output: 7.54 toks/s]
Processed prompts:  88%| | 226/256 [00:29<00:04,  7.43it/s, est. speed input: 7722.68 toks/s, output: 7.54 toks/s]
Processed prompts:  89%| | 228/256 [00:30<00:03,  7.38it/s, est. speed input: 7720.06 toks/s, output: 7.54 toks/s]
Processed prompts:  90%| | 230/256 [00:30<00:03,  7.40it/s, est. speed input: 7719.25 toks/s, output: 7.54 toks/s]
Processed prompts:  91%| | 232/256 [00:30<00:03,  7.41it/s, est. speed input: 7718.31 toks/s, output: 7.54 toks/s]
Processed prompts:  91%|| 234/256 [00:31<00:02,  7.41it/s, est. speed input: 7717.24 toks/s, output: 7.54 toks/s]
Processed prompts:  92%|| 236/256 [00:31<00:02,  7.39it/s, est. speed input: 7715.50 toks/s, output: 7.53 toks/s]
Processed prompts:  93%|| 238/256 [00:31<00:02,  7.39it/s, est. speed input: 7714.24 toks/s, output: 7.53 toks/s]
Processed prompts:  94%|| 240/256 [00:31<00:02,  7.41it/s, est. speed input: 7713.52 toks/s, output: 7.53 toks/s]
Processed prompts:  95%|| 242/256 [00:32<00:01,  7.41it/s, est. speed input: 7712.42 toks/s, output: 7.53 toks/s]
Processed prompts:  95%|| 244/256 [00:32<00:01,  7.37it/s, est. speed input: 7710.17 toks/s, output: 7.53 toks/s]
Processed prompts:  96%|| 246/256 [00:32<00:01,  7.39it/s, est. speed input: 7709.42 toks/s, output: 7.53 toks/s]
Processed prompts:  97%|| 248/256 [00:32<00:01,  7.41it/s, est. speed input: 7708.91 toks/s, output: 7.53 toks/s]
Processed prompts:  98%|| 250/256 [00:33<00:00,  7.43it/s, est. speed input: 7708.35 toks/s, output: 7.53 toks/s]
Processed prompts:  98%|| 252/256 [00:33<00:00,  7.39it/s, est. speed input: 7706.36 toks/s, output: 7.53 toks/s]
Processed prompts:  99%|| 254/256 [00:33<00:00,  7.41it/s, est. speed input: 7706.02 toks/s, output: 7.53 toks/s]
Processed prompts: 100%|| 256/256 [00:33<00:00,  8.71it/s, est. speed input: 7735.49 toks/s, output: 7.55 toks/s]
Processed prompts: 100%|| 256/256 [00:33<00:00,  8.71it/s, est. speed input: 7735.49 toks/s, output: 7.55 toks/s]
Processed prompts: 100%|| 256/256 [00:33<00:00,  7.55it/s, est. speed input: 7735.49 toks/s, output: 7.55 toks/s]
[rank0]:[W126 18:18:55.252150087 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-26 18:18:57
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Qwen2.5-7B-FP8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 18:19:02 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 18:19:02 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1591318) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1591318) WARNING 01-26 18:19:55 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 7.16 requests/s, 7336.61 total tokens/s, 7.16 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-26 18:19:02] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 18:19:02] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 18:19:02] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 18:19:02] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:19:02] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:19:02] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:19:02] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:19:02] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:19:02] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 18:19:02] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 18:19:02] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 18:19:02] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 18:19:02] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 18:19:02] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 18:19:05] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 18:19:06] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 18:19:06] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 18:19:06] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:19:06] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:19:06] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:19:06] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:19:06] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:19:06] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 18:19:06] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 18:19:06] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 18:19:06] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 18:19:06] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 18:19:06] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1591318) [2026-01-26 18:19:06] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1591318) [2026-01-26 18:19:06] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1591318) [2026-01-26 18:19:06] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1591318) [2026-01-26 18:19:06] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1591318) [2026-01-26 18:19:06] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1591318) [2026-01-26 18:19:06] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1591318) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1591318) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:20<00:20, 20.21s/it]
(EngineCore_DP0 pid=1591318) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:40<00:00, 20.30s/it]
(EngineCore_DP0 pid=1591318) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:40<00:00, 20.28s/it]
(EngineCore_DP0 pid=1591318) 
(EngineCore_DP0 pid=1591318) [2026-01-26 18:19:48] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=1591318) [2026-01-26 18:19:48] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10321920 bytes
(EngineCore_DP0 pid=1591318) [2026-01-26 18:19:48] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=1591318) [2026-01-26 18:19:48] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8028160 bytes
(EngineCore_DP0 pid=1591318) [2026-01-26 18:19:48] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=1591318) [2026-01-26 18:19:48] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 84869120 bytes
(EngineCore_DP0 pid=1591318) [2026-01-26 18:19:48] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=1591318) [2026-01-26 18:19:48] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 42434560 bytes
(EngineCore_DP0 pid=1591318) 2026-01-26 18:19:54,151 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1591318) 2026-01-26 18:19:54,254 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   8%|         | 40/512 [00:00<00:01, 386.15it/s]
Adding requests:  15%|        | 79/512 [00:00<00:01, 372.76it/s]
Adding requests:  23%|       | 117/512 [00:00<00:01, 370.12it/s]
Adding requests:  30%|       | 156/512 [00:00<00:00, 377.13it/s]
Adding requests:  38%|      | 195/512 [00:00<00:00, 378.49it/s]
Adding requests:  46%|     | 237/512 [00:00<00:00, 392.00it/s]
Adding requests:  54%|    | 278/512 [00:00<00:00, 396.95it/s]
Adding requests:  63%|   | 321/512 [00:00<00:00, 404.62it/s]
Adding requests:  71%|   | 364/512 [00:00<00:00, 410.68it/s]
Adding requests:  80%|  | 408/512 [00:01<00:00, 417.31it/s]
Adding requests:  88%| | 450/512 [00:01<00:00, 416.98it/s]
Adding requests:  96%|| 493/512 [00:01<00:00, 420.48it/s]
Adding requests: 100%|| 512/512 [00:01<00:00, 403.31it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 10/512 [00:00<00:32, 15.50it/s, est. speed input: 15874.22 toks/s, output: 15.50 toks/s]
Processed prompts:   3%|         | 14/512 [00:01<00:45, 10.94it/s, est. speed input: 11952.95 toks/s, output: 11.67 toks/s]
Processed prompts:   4%|         | 18/512 [00:01<00:53,  9.25it/s, est. speed input: 10475.89 toks/s, output: 10.23 toks/s]
Processed prompts:   4%|         | 22/512 [00:02<00:57,  8.46it/s, est. speed input: 9730.58 toks/s, output: 9.50 toks/s]  
Processed prompts:   5%|         | 26/512 [00:02<01:00,  7.97it/s, est. speed input: 9247.39 toks/s, output: 9.03 toks/s]
Processed prompts:   6%|         | 30/512 [00:03<01:02,  7.71it/s, est. speed input: 8942.04 toks/s, output: 8.73 toks/s]
Processed prompts:   7%|         | 34/512 [00:03<01:03,  7.53it/s, est. speed input: 8717.84 toks/s, output: 8.51 toks/s]
Processed prompts:   7%|         | 38/512 [00:04<01:03,  7.42it/s, est. speed input: 8549.56 toks/s, output: 8.35 toks/s]
Processed prompts:   8%|         | 42/512 [00:05<01:04,  7.33it/s, est. speed input: 8412.40 toks/s, output: 8.22 toks/s]
Processed prompts:   9%|         | 46/512 [00:05<01:03,  7.28it/s, est. speed input: 8307.92 toks/s, output: 8.11 toks/s]
Processed prompts:  10%|         | 50/512 [00:06<01:03,  7.24it/s, est. speed input: 8218.89 toks/s, output: 8.03 toks/s]
Processed prompts:  11%|         | 54/512 [00:06<01:03,  7.23it/s, est. speed input: 8149.81 toks/s, output: 7.96 toks/s]
Processed prompts:  11%|        | 58/512 [00:07<01:03,  7.19it/s, est. speed input: 8082.52 toks/s, output: 7.89 toks/s]
Processed prompts:  12%|        | 62/512 [00:07<01:02,  7.18it/s, est. speed input: 8028.52 toks/s, output: 7.84 toks/s]
Processed prompts:  13%|        | 66/512 [00:08<01:02,  7.18it/s, est. speed input: 7985.03 toks/s, output: 7.80 toks/s]
Processed prompts:  14%|        | 70/512 [00:09<01:01,  7.16it/s, est. speed input: 7941.85 toks/s, output: 7.76 toks/s]
Processed prompts:  14%|        | 74/512 [00:09<01:01,  7.17it/s, est. speed input: 7907.97 toks/s, output: 7.72 toks/s]
Processed prompts:  15%|        | 78/512 [00:10<01:00,  7.15it/s, est. speed input: 7873.13 toks/s, output: 7.69 toks/s]
Processed prompts:  16%|        | 82/512 [00:10<01:00,  7.15it/s, est. speed input: 7844.24 toks/s, output: 7.66 toks/s]
Processed prompts:  17%|        | 86/512 [00:11<00:59,  7.13it/s, est. speed input: 7814.74 toks/s, output: 7.63 toks/s]
Processed prompts:  18%|        | 90/512 [00:11<00:59,  7.15it/s, est. speed input: 7792.98 toks/s, output: 7.61 toks/s]
Processed prompts:  18%|        | 94/512 [00:12<00:58,  7.14it/s, est. speed input: 7770.07 toks/s, output: 7.59 toks/s]
Processed prompts:  19%|        | 98/512 [00:12<00:57,  7.14it/s, est. speed input: 7750.66 toks/s, output: 7.57 toks/s]
Processed prompts:  20%|        | 102/512 [00:13<00:57,  7.14it/s, est. speed input: 7732.73 toks/s, output: 7.55 toks/s]
Processed prompts:  21%|        | 106/512 [00:14<00:56,  7.15it/s, est. speed input: 7717.33 toks/s, output: 7.54 toks/s]
Processed prompts:  21%|       | 110/512 [00:14<00:56,  7.13it/s, est. speed input: 7699.41 toks/s, output: 7.52 toks/s]
Processed prompts:  22%|       | 114/512 [00:15<00:55,  7.14it/s, est. speed input: 7685.86 toks/s, output: 7.51 toks/s]
Processed prompts:  23%|       | 118/512 [00:15<00:55,  7.12it/s, est. speed input: 7670.56 toks/s, output: 7.49 toks/s]
Processed prompts:  24%|       | 122/512 [00:16<00:54,  7.14it/s, est. speed input: 7659.34 toks/s, output: 7.48 toks/s]
Processed prompts:  25%|       | 126/512 [00:16<00:54,  7.12it/s, est. speed input: 7645.79 toks/s, output: 7.47 toks/s]
Processed prompts:  25%|       | 130/512 [00:17<00:53,  7.13it/s, est. speed input: 7635.27 toks/s, output: 7.46 toks/s]
Processed prompts:  26%|       | 134/512 [00:17<00:53,  7.13it/s, est. speed input: 7624.40 toks/s, output: 7.45 toks/s]
Processed prompts:  27%|       | 138/512 [00:18<00:52,  7.14it/s, est. speed input: 7616.11 toks/s, output: 7.44 toks/s]
Processed prompts:  28%|       | 142/512 [00:19<00:51,  7.13it/s, est. speed input: 7606.34 toks/s, output: 7.43 toks/s]
Processed prompts:  29%|       | 146/512 [00:19<00:51,  7.13it/s, est. speed input: 7597.55 toks/s, output: 7.42 toks/s]
Processed prompts:  29%|       | 150/512 [00:20<00:50,  7.14it/s, est. speed input: 7589.88 toks/s, output: 7.41 toks/s]
Processed prompts:  30%|       | 154/512 [00:20<00:50,  7.12it/s, est. speed input: 7580.99 toks/s, output: 7.40 toks/s]
Processed prompts:  31%|       | 158/512 [00:21<00:49,  7.12it/s, est. speed input: 7573.63 toks/s, output: 7.40 toks/s]
Processed prompts:  32%|      | 162/512 [00:21<00:49,  7.11it/s, est. speed input: 7565.43 toks/s, output: 7.39 toks/s]
Processed prompts:  32%|      | 166/512 [00:22<00:48,  7.12it/s, est. speed input: 7558.66 toks/s, output: 7.38 toks/s]
Processed prompts:  33%|      | 170/512 [00:23<00:48,  7.11it/s, est. speed input: 7551.10 toks/s, output: 7.37 toks/s]
Processed prompts:  34%|      | 174/512 [00:23<00:47,  7.13it/s, est. speed input: 7546.35 toks/s, output: 7.37 toks/s]
Processed prompts:  35%|      | 178/512 [00:24<00:46,  7.12it/s, est. speed input: 7540.11 toks/s, output: 7.36 toks/s]
Processed prompts:  36%|      | 182/512 [00:24<00:46,  7.14it/s, est. speed input: 7535.98 toks/s, output: 7.36 toks/s]
Processed prompts:  36%|      | 186/512 [00:25<00:45,  7.14it/s, est. speed input: 7530.87 toks/s, output: 7.35 toks/s]
Processed prompts:  37%|      | 190/512 [00:25<00:45,  7.14it/s, est. speed input: 7526.37 toks/s, output: 7.35 toks/s]
Processed prompts:  38%|      | 194/512 [00:26<00:44,  7.13it/s, est. speed input: 7521.04 toks/s, output: 7.34 toks/s]
Processed prompts:  39%|      | 198/512 [00:26<00:43,  7.14it/s, est. speed input: 7517.23 toks/s, output: 7.34 toks/s]
Processed prompts:  39%|      | 202/512 [00:27<00:40,  7.62it/s, est. speed input: 7545.48 toks/s, output: 7.37 toks/s]
Processed prompts:  40%|      | 206/512 [00:27<00:40,  7.47it/s, est. speed input: 7540.96 toks/s, output: 7.36 toks/s]
Processed prompts:  41%|      | 210/512 [00:28<00:41,  7.36it/s, est. speed input: 7535.48 toks/s, output: 7.36 toks/s]
Processed prompts:  42%|     | 214/512 [00:29<00:40,  7.30it/s, est. speed input: 7531.78 toks/s, output: 7.36 toks/s]
Processed prompts:  43%|     | 218/512 [00:29<00:40,  7.23it/s, est. speed input: 7526.38 toks/s, output: 7.35 toks/s]
Processed prompts:  43%|     | 222/512 [00:30<00:40,  7.21it/s, est. speed input: 7523.06 toks/s, output: 7.35 toks/s]
Processed prompts:  44%|     | 226/512 [00:30<00:39,  7.18it/s, est. speed input: 7518.49 toks/s, output: 7.34 toks/s]
Processed prompts:  45%|     | 230/512 [00:31<00:39,  7.18it/s, est. speed input: 7515.47 toks/s, output: 7.34 toks/s]
Processed prompts:  46%|     | 234/512 [00:31<00:38,  7.15it/s, est. speed input: 7510.69 toks/s, output: 7.33 toks/s]
Processed prompts:  46%|     | 238/512 [00:32<00:38,  7.16it/s, est. speed input: 7507.83 toks/s, output: 7.33 toks/s]
Processed prompts:  47%|     | 242/512 [00:33<00:37,  7.14it/s, est. speed input: 7504.15 toks/s, output: 7.33 toks/s]
Processed prompts:  48%|     | 246/512 [00:33<00:37,  7.14it/s, est. speed input: 7500.53 toks/s, output: 7.32 toks/s]
Processed prompts:  49%|     | 250/512 [00:34<00:36,  7.14it/s, est. speed input: 7497.46 toks/s, output: 7.32 toks/s]
Processed prompts:  50%|     | 254/512 [00:34<00:36,  7.13it/s, est. speed input: 7493.94 toks/s, output: 7.32 toks/s]
Processed prompts:  50%|     | 258/512 [00:35<00:35,  7.14it/s, est. speed input: 7491.59 toks/s, output: 7.32 toks/s]
Processed prompts:  51%|     | 262/512 [00:35<00:35,  7.12it/s, est. speed input: 7487.32 toks/s, output: 7.31 toks/s]
Processed prompts:  52%|    | 266/512 [00:36<00:34,  7.12it/s, est. speed input: 7484.65 toks/s, output: 7.31 toks/s]
Processed prompts:  53%|    | 270/512 [00:36<00:34,  7.11it/s, est. speed input: 7480.88 toks/s, output: 7.31 toks/s]
Processed prompts:  54%|    | 274/512 [00:37<00:33,  7.12it/s, est. speed input: 7478.53 toks/s, output: 7.30 toks/s]
Processed prompts:  54%|    | 278/512 [00:38<00:32,  7.12it/s, est. speed input: 7475.91 toks/s, output: 7.30 toks/s]
Processed prompts:  55%|    | 282/512 [00:38<00:32,  7.13it/s, est. speed input: 7473.74 toks/s, output: 7.30 toks/s]
Processed prompts:  56%|    | 286/512 [00:39<00:31,  7.13it/s, est. speed input: 7471.01 toks/s, output: 7.30 toks/s]
Processed prompts:  57%|    | 290/512 [00:39<00:31,  7.13it/s, est. speed input: 7468.97 toks/s, output: 7.29 toks/s]
Processed prompts:  57%|    | 294/512 [00:40<00:30,  7.12it/s, est. speed input: 7466.18 toks/s, output: 7.29 toks/s]
Processed prompts:  58%|    | 298/512 [00:40<00:30,  7.12it/s, est. speed input: 7463.72 toks/s, output: 7.29 toks/s]
Processed prompts:  59%|    | 302/512 [00:41<00:29,  7.11it/s, est. speed input: 7460.83 toks/s, output: 7.29 toks/s]
Processed prompts:  60%|    | 306/512 [00:41<00:26,  7.69it/s, est. speed input: 7483.61 toks/s, output: 7.31 toks/s]
Processed prompts:  61%|    | 310/512 [00:42<00:26,  7.50it/s, est. speed input: 7480.84 toks/s, output: 7.31 toks/s]
Processed prompts:  61%|   | 314/512 [00:42<00:26,  7.40it/s, est. speed input: 7479.08 toks/s, output: 7.30 toks/s]
Processed prompts:  62%|   | 318/512 [00:43<00:26,  7.32it/s, est. speed input: 7476.82 toks/s, output: 7.30 toks/s]
Processed prompts:  63%|   | 322/512 [00:44<00:26,  7.27it/s, est. speed input: 7474.80 toks/s, output: 7.30 toks/s]
Processed prompts:  64%|   | 326/512 [00:44<00:25,  7.22it/s, est. speed input: 7472.51 toks/s, output: 7.30 toks/s]
Processed prompts:  64%|   | 330/512 [00:45<00:25,  7.22it/s, est. speed input: 7471.29 toks/s, output: 7.30 toks/s]
Processed prompts:  65%|   | 334/512 [00:45<00:24,  7.18it/s, est. speed input: 7468.65 toks/s, output: 7.29 toks/s]
Processed prompts:  66%|   | 338/512 [00:46<00:24,  7.17it/s, est. speed input: 7466.87 toks/s, output: 7.29 toks/s]
Processed prompts:  67%|   | 342/512 [00:46<00:23,  7.15it/s, est. speed input: 7464.55 toks/s, output: 7.29 toks/s]
Processed prompts:  68%|   | 346/512 [00:47<00:23,  7.15it/s, est. speed input: 7462.82 toks/s, output: 7.29 toks/s]
Processed prompts:  68%|   | 350/512 [00:48<00:22,  7.13it/s, est. speed input: 7460.38 toks/s, output: 7.29 toks/s]
Processed prompts:  69%|   | 354/512 [00:48<00:22,  7.13it/s, est. speed input: 7458.66 toks/s, output: 7.28 toks/s]
Processed prompts:  70%|   | 358/512 [00:49<00:21,  7.14it/s, est. speed input: 7457.24 toks/s, output: 7.28 toks/s]
Processed prompts:  71%|   | 362/512 [00:49<00:21,  7.13it/s, est. speed input: 7455.13 toks/s, output: 7.28 toks/s]
Processed prompts:  71%|  | 366/512 [00:50<00:20,  7.13it/s, est. speed input: 7453.56 toks/s, output: 7.28 toks/s]
Processed prompts:  72%|  | 370/512 [00:50<00:19,  7.12it/s, est. speed input: 7451.46 toks/s, output: 7.28 toks/s]
Processed prompts:  73%|  | 374/512 [00:51<00:19,  7.13it/s, est. speed input: 7449.97 toks/s, output: 7.28 toks/s]
Processed prompts:  74%|  | 378/512 [00:51<00:18,  7.11it/s, est. speed input: 7447.76 toks/s, output: 7.27 toks/s]
Processed prompts:  75%|  | 382/512 [00:52<00:18,  7.11it/s, est. speed input: 7446.02 toks/s, output: 7.27 toks/s]
Processed prompts:  75%|  | 386/512 [00:53<00:17,  7.11it/s, est. speed input: 7444.25 toks/s, output: 7.27 toks/s]
Processed prompts:  76%|  | 390/512 [00:53<00:17,  7.12it/s, est. speed input: 7442.92 toks/s, output: 7.27 toks/s]
Processed prompts:  77%|  | 394/512 [00:54<00:16,  7.13it/s, est. speed input: 7441.62 toks/s, output: 7.27 toks/s]
Processed prompts:  78%|  | 398/512 [00:54<00:15,  7.13it/s, est. speed input: 7440.10 toks/s, output: 7.27 toks/s]
Processed prompts:  79%|  | 402/512 [00:55<00:15,  7.11it/s, est. speed input: 7438.11 toks/s, output: 7.26 toks/s]
Processed prompts:  79%|  | 406/512 [00:55<00:14,  7.12it/s, est. speed input: 7436.86 toks/s, output: 7.26 toks/s]
Processed prompts:  80%|  | 410/512 [00:56<00:14,  7.12it/s, est. speed input: 7435.22 toks/s, output: 7.26 toks/s]
Processed prompts:  81%|  | 414/512 [00:57<00:13,  7.13it/s, est. speed input: 7434.17 toks/s, output: 7.26 toks/s]
Processed prompts:  82%| | 418/512 [00:57<00:13,  7.11it/s, est. speed input: 7432.38 toks/s, output: 7.26 toks/s]
Processed prompts:  82%| | 422/512 [00:58<00:12,  7.11it/s, est. speed input: 7430.98 toks/s, output: 7.26 toks/s]
Processed prompts:  83%| | 426/512 [00:58<00:12,  7.11it/s, est. speed input: 7429.35 toks/s, output: 7.26 toks/s]
Processed prompts:  84%| | 430/512 [00:59<00:11,  7.12it/s, est. speed input: 7428.29 toks/s, output: 7.25 toks/s]
Processed prompts:  85%| | 434/512 [00:59<00:10,  7.70it/s, est. speed input: 7444.49 toks/s, output: 7.27 toks/s]
Processed prompts:  86%| | 438/512 [01:00<00:09,  7.53it/s, est. speed input: 7443.38 toks/s, output: 7.27 toks/s]
Processed prompts:  86%| | 442/512 [01:00<00:09,  7.38it/s, est. speed input: 7441.33 toks/s, output: 7.27 toks/s]
Processed prompts:  87%| | 446/512 [01:01<00:09,  7.30it/s, est. speed input: 7439.95 toks/s, output: 7.27 toks/s]
Processed prompts:  88%| | 450/512 [01:01<00:08,  7.23it/s, est. speed input: 7438.14 toks/s, output: 7.26 toks/s]
Processed prompts:  89%| | 454/512 [01:02<00:08,  7.18it/s, est. speed input: 7436.26 toks/s, output: 7.26 toks/s]
Processed prompts:  89%| | 458/512 [01:03<00:07,  7.16it/s, est. speed input: 7435.02 toks/s, output: 7.26 toks/s]
Processed prompts:  90%| | 462/512 [01:03<00:07,  7.13it/s, est. speed input: 7433.11 toks/s, output: 7.26 toks/s]
Processed prompts:  91%| | 466/512 [01:04<00:06,  7.13it/s, est. speed input: 7432.09 toks/s, output: 7.26 toks/s]
Processed prompts:  92%|| 470/512 [01:04<00:05,  7.12it/s, est. speed input: 7430.52 toks/s, output: 7.26 toks/s]
Processed prompts:  93%|| 474/512 [01:05<00:05,  7.13it/s, est. speed input: 7429.56 toks/s, output: 7.26 toks/s]
Processed prompts:  93%|| 478/512 [01:05<00:04,  7.10it/s, est. speed input: 7427.77 toks/s, output: 7.25 toks/s]
Processed prompts:  94%|| 482/512 [01:06<00:04,  7.11it/s, est. speed input: 7426.76 toks/s, output: 7.25 toks/s]
Processed prompts:  95%|| 486/512 [01:07<00:03,  7.10it/s, est. speed input: 7425.16 toks/s, output: 7.25 toks/s]
Processed prompts:  96%|| 490/512 [01:07<00:03,  7.12it/s, est. speed input: 7424.34 toks/s, output: 7.25 toks/s]
Processed prompts:  96%|| 494/512 [01:08<00:02,  7.11it/s, est. speed input: 7423.15 toks/s, output: 7.25 toks/s]
Processed prompts:  97%|| 498/512 [01:08<00:01,  7.14it/s, est. speed input: 7422.73 toks/s, output: 7.25 toks/s]
Processed prompts:  98%|| 502/512 [01:09<00:01,  7.12it/s, est. speed input: 7421.34 toks/s, output: 7.25 toks/s]
Processed prompts:  99%|| 506/512 [01:09<00:00,  7.14it/s, est. speed input: 7420.69 toks/s, output: 7.25 toks/s]
Processed prompts: 100%|| 510/512 [01:10<00:00,  7.64it/s, est. speed input: 7432.92 toks/s, output: 7.26 toks/s]
Processed prompts: 100%|| 512/512 [01:10<00:00,  7.64it/s, est. speed input: 7462.06 toks/s, output: 7.29 toks/s]
Processed prompts: 100%|| 512/512 [01:10<00:00,  7.29it/s, est. speed input: 7462.06 toks/s, output: 7.29 toks/s]
[rank0]:[W126 18:21:07.224875732 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-26 18:21:09
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Qwen2.5-7B-FP8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 18:21:16 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 18:21:16 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1593337) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1593337) WARNING 01-26 18:22:09 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 7.26 requests/s, 7444.30 total tokens/s, 7.26 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-26 18:21:16] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 18:21:16] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 18:21:16] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 18:21:16] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:21:16] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:21:16] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:21:16] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:21:16] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:21:16] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 18:21:16] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 18:21:16] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 18:21:16] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 18:21:16] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 18:21:16] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 18:21:19] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 18:21:19] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 18:21:19] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 18:21:19] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:21:19] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:21:19] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:21:19] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:21:19] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:21:19] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 18:21:19] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 18:21:19] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 18:21:19] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 18:21:19] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 18:21:19] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1593337) [2026-01-26 18:21:20] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1593337) [2026-01-26 18:21:20] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1593337) [2026-01-26 18:21:20] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1593337) [2026-01-26 18:21:20] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1593337) [2026-01-26 18:21:20] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1593337) [2026-01-26 18:21:20] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1593337) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1593337) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:19<00:19, 19.84s/it]
(EngineCore_DP0 pid=1593337) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:40<00:00, 20.09s/it]
(EngineCore_DP0 pid=1593337) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:40<00:00, 20.05s/it]
(EngineCore_DP0 pid=1593337) 
(EngineCore_DP0 pid=1593337) [2026-01-26 18:22:01] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=1593337) [2026-01-26 18:22:01] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10321920 bytes
(EngineCore_DP0 pid=1593337) [2026-01-26 18:22:01] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=1593337) [2026-01-26 18:22:01] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8028160 bytes
(EngineCore_DP0 pid=1593337) [2026-01-26 18:22:01] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=1593337) [2026-01-26 18:22:01] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 84869120 bytes
(EngineCore_DP0 pid=1593337) [2026-01-26 18:22:01] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=1593337) [2026-01-26 18:22:01] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 42434560 bytes
(EngineCore_DP0 pid=1593337) 2026-01-26 18:22:08,082 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1593337) 2026-01-26 18:22:08,298 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   4%|         | 41/1024 [00:00<00:02, 409.25it/s]
Adding requests:   8%|         | 82/1024 [00:00<00:02, 382.55it/s]
Adding requests:  12%|        | 121/1024 [00:00<00:02, 370.19it/s]
Adding requests:  16%|        | 161/1024 [00:00<00:02, 378.38it/s]
Adding requests:  20%|        | 203/1024 [00:00<00:02, 389.79it/s]
Adding requests:  24%|       | 245/1024 [00:00<00:01, 398.01it/s]
Adding requests:  28%|       | 286/1024 [00:00<00:01, 400.96it/s]
Adding requests:  32%|      | 330/1024 [00:00<00:01, 411.02it/s]
Adding requests:  36%|      | 372/1024 [00:00<00:01, 411.58it/s]
Adding requests:  41%|      | 416/1024 [00:01<00:01, 417.42it/s]
Adding requests:  45%|     | 458/1024 [00:01<00:01, 412.64it/s]
Adding requests:  49%|     | 502/1024 [00:01<00:01, 419.91it/s]
Adding requests:  53%|    | 545/1024 [00:01<00:01, 422.57it/s]
Adding requests:  57%|    | 588/1024 [00:01<00:01, 412.58it/s]
Adding requests:  62%|   | 630/1024 [00:01<00:00, 413.89it/s]
Adding requests:  66%|   | 672/1024 [00:01<00:00, 382.52it/s]
Adding requests:  70%|   | 715/1024 [00:01<00:00, 394.42it/s]
Adding requests:  74%|  | 755/1024 [00:01<00:00, 380.87it/s]
Adding requests:  78%|  | 797/1024 [00:01<00:00, 390.42it/s]
Adding requests:  82%| | 838/1024 [00:02<00:00, 393.22it/s]
Adding requests:  86%| | 879/1024 [00:02<00:00, 395.69it/s]
Adding requests:  90%| | 919/1024 [00:02<00:00, 395.56it/s]
Adding requests:  94%|| 959/1024 [00:02<00:00, 392.49it/s]
Adding requests:  98%|| 999/1024 [00:02<00:00, 387.85it/s]
Adding requests: 100%|| 1024/1024 [00:02<00:00, 397.14it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 18/1024 [00:00<00:53, 18.96it/s, est. speed input: 19418.89 toks/s, output: 18.96 toks/s]
Processed prompts:   3%|         | 26/1024 [00:02<01:25, 11.65it/s, est. speed input: 12971.68 toks/s, output: 12.67 toks/s]
Processed prompts:   3%|         | 34/1024 [00:03<01:43,  9.59it/s, est. speed input: 11040.48 toks/s, output: 10.78 toks/s]
Processed prompts:   4%|         | 42/1024 [00:04<01:53,  8.64it/s, est. speed input: 10095.34 toks/s, output: 9.86 toks/s] 
Processed prompts:   5%|         | 50/1024 [00:05<01:59,  8.14it/s, est. speed input: 9549.58 toks/s, output: 9.33 toks/s] 
Processed prompts:   6%|         | 58/1024 [00:06<02:03,  7.83it/s, est. speed input: 9187.62 toks/s, output: 8.97 toks/s]
Processed prompts:   6%|         | 66/1024 [00:07<02:05,  7.65it/s, est. speed input: 8933.72 toks/s, output: 8.72 toks/s]
Processed prompts:   7%|         | 74/1024 [00:08<02:06,  7.52it/s, est. speed input: 8740.06 toks/s, output: 8.54 toks/s]
Processed prompts:   8%|         | 82/1024 [00:09<02:06,  7.43it/s, est. speed input: 8591.72 toks/s, output: 8.39 toks/s]
Processed prompts:   9%|         | 90/1024 [00:10<02:06,  7.38it/s, est. speed input: 8474.74 toks/s, output: 8.28 toks/s]
Processed prompts:  10%|         | 98/1024 [00:11<02:06,  7.34it/s, est. speed input: 8376.10 toks/s, output: 8.18 toks/s]
Processed prompts:  10%|         | 106/1024 [00:13<02:05,  7.31it/s, est. speed input: 8295.84 toks/s, output: 8.10 toks/s]
Processed prompts:  11%|         | 114/1024 [00:14<02:04,  7.29it/s, est. speed input: 8227.01 toks/s, output: 8.03 toks/s]
Processed prompts:  12%|        | 122/1024 [00:15<02:03,  7.28it/s, est. speed input: 8169.07 toks/s, output: 7.98 toks/s]
Processed prompts:  13%|        | 130/1024 [00:16<02:02,  7.27it/s, est. speed input: 8118.96 toks/s, output: 7.93 toks/s]
Processed prompts:  13%|        | 138/1024 [00:17<02:02,  7.26it/s, est. speed input: 8073.84 toks/s, output: 7.88 toks/s]
Processed prompts:  14%|        | 146/1024 [00:18<02:00,  7.26it/s, est. speed input: 8036.13 toks/s, output: 7.85 toks/s]
Processed prompts:  15%|        | 154/1024 [00:19<01:59,  7.25it/s, est. speed input: 8001.33 toks/s, output: 7.81 toks/s]
Processed prompts:  16%|        | 162/1024 [00:20<01:58,  7.26it/s, est. speed input: 7971.93 toks/s, output: 7.79 toks/s]
Processed prompts:  17%|        | 170/1024 [00:21<01:57,  7.26it/s, est. speed input: 7944.39 toks/s, output: 7.76 toks/s]
Processed prompts:  17%|        | 178/1024 [00:23<01:56,  7.25it/s, est. speed input: 7919.30 toks/s, output: 7.73 toks/s]
Processed prompts:  18%|        | 186/1024 [00:24<01:55,  7.25it/s, est. speed input: 7896.64 toks/s, output: 7.71 toks/s]
Processed prompts:  19%|        | 194/1024 [00:25<01:54,  7.24it/s, est. speed input: 7874.81 toks/s, output: 7.69 toks/s]
Processed prompts:  20%|        | 202/1024 [00:26<01:50,  7.47it/s, est. speed input: 7888.99 toks/s, output: 7.70 toks/s]
Processed prompts:  21%|        | 210/1024 [00:27<01:49,  7.41it/s, est. speed input: 7871.35 toks/s, output: 7.69 toks/s]
Processed prompts:  21%|       | 218/1024 [00:28<01:49,  7.36it/s, est. speed input: 7853.29 toks/s, output: 7.67 toks/s]
Processed prompts:  22%|       | 226/1024 [00:29<01:48,  7.32it/s, est. speed input: 7837.24 toks/s, output: 7.65 toks/s]
Processed prompts:  23%|       | 234/1024 [00:30<01:48,  7.30it/s, est. speed input: 7822.61 toks/s, output: 7.64 toks/s]
Processed prompts:  24%|       | 242/1024 [00:31<01:47,  7.29it/s, est. speed input: 7809.51 toks/s, output: 7.63 toks/s]
Processed prompts:  24%|       | 250/1024 [00:32<01:46,  7.28it/s, est. speed input: 7796.85 toks/s, output: 7.61 toks/s]
Processed prompts:  25%|       | 258/1024 [00:33<01:45,  7.27it/s, est. speed input: 7784.66 toks/s, output: 7.60 toks/s]
Processed prompts:  26%|       | 266/1024 [00:35<01:44,  7.26it/s, est. speed input: 7772.18 toks/s, output: 7.59 toks/s]
Processed prompts:  27%|       | 274/1024 [00:36<01:43,  7.26it/s, est. speed input: 7761.87 toks/s, output: 7.58 toks/s]
Processed prompts:  28%|       | 282/1024 [00:37<01:42,  7.26it/s, est. speed input: 7752.01 toks/s, output: 7.57 toks/s]
Processed prompts:  28%|       | 290/1024 [00:38<01:41,  7.26it/s, est. speed input: 7742.95 toks/s, output: 7.56 toks/s]
Processed prompts:  29%|       | 298/1024 [00:39<01:40,  7.25it/s, est. speed input: 7733.40 toks/s, output: 7.55 toks/s]
Processed prompts:  30%|       | 306/1024 [00:40<01:35,  7.52it/s, est. speed input: 7749.81 toks/s, output: 7.57 toks/s]
Processed prompts:  31%|       | 314/1024 [00:41<01:35,  7.44it/s, est. speed input: 7741.69 toks/s, output: 7.56 toks/s]
Processed prompts:  31%|      | 322/1024 [00:42<01:35,  7.38it/s, est. speed input: 7732.92 toks/s, output: 7.55 toks/s]
Processed prompts:  32%|      | 330/1024 [00:43<01:34,  7.34it/s, est. speed input: 7724.97 toks/s, output: 7.54 toks/s]
Processed prompts:  33%|      | 338/1024 [00:44<01:33,  7.31it/s, est. speed input: 7717.91 toks/s, output: 7.54 toks/s]
Processed prompts:  34%|      | 346/1024 [00:45<01:32,  7.29it/s, est. speed input: 7710.71 toks/s, output: 7.53 toks/s]
Processed prompts:  35%|      | 354/1024 [00:47<01:32,  7.27it/s, est. speed input: 7703.44 toks/s, output: 7.52 toks/s]
Processed prompts:  35%|      | 362/1024 [00:48<01:31,  7.26it/s, est. speed input: 7696.63 toks/s, output: 7.52 toks/s]
Processed prompts:  36%|      | 370/1024 [00:49<01:30,  7.26it/s, est. speed input: 7690.77 toks/s, output: 7.51 toks/s]
Processed prompts:  37%|      | 378/1024 [00:50<01:29,  7.25it/s, est. speed input: 7684.71 toks/s, output: 7.50 toks/s]
Processed prompts:  38%|      | 386/1024 [00:51<01:28,  7.25it/s, est. speed input: 7678.66 toks/s, output: 7.50 toks/s]
Processed prompts:  38%|      | 394/1024 [00:52<01:27,  7.23it/s, est. speed input: 7672.29 toks/s, output: 7.49 toks/s]
Processed prompts:  39%|      | 402/1024 [00:53<01:25,  7.23it/s, est. speed input: 7666.82 toks/s, output: 7.49 toks/s]
Processed prompts:  40%|      | 410/1024 [00:54<01:24,  7.23it/s, est. speed input: 7661.53 toks/s, output: 7.48 toks/s]
Processed prompts:  41%|      | 418/1024 [00:55<01:23,  7.23it/s, est. speed input: 7656.39 toks/s, output: 7.48 toks/s]
Processed prompts:  42%|     | 426/1024 [00:57<01:22,  7.23it/s, est. speed input: 7651.51 toks/s, output: 7.47 toks/s]
Processed prompts:  42%|     | 434/1024 [00:57<01:18,  7.50it/s, est. speed input: 7664.16 toks/s, output: 7.48 toks/s]
Processed prompts:  43%|     | 442/1024 [00:59<01:18,  7.42it/s, est. speed input: 7659.41 toks/s, output: 7.48 toks/s]
Processed prompts:  44%|     | 450/1024 [01:00<01:17,  7.37it/s, est. speed input: 7655.21 toks/s, output: 7.48 toks/s]
Processed prompts:  45%|     | 458/1024 [01:01<01:17,  7.33it/s, est. speed input: 7651.00 toks/s, output: 7.47 toks/s]
Processed prompts:  46%|     | 466/1024 [01:02<01:16,  7.30it/s, est. speed input: 7646.64 toks/s, output: 7.47 toks/s]
Processed prompts:  46%|     | 474/1024 [01:03<01:15,  7.28it/s, est. speed input: 7642.56 toks/s, output: 7.46 toks/s]
Processed prompts:  47%|     | 482/1024 [01:04<01:14,  7.27it/s, est. speed input: 7638.86 toks/s, output: 7.46 toks/s]
Processed prompts:  48%|     | 490/1024 [01:05<01:13,  7.26it/s, est. speed input: 7634.96 toks/s, output: 7.46 toks/s]
Processed prompts:  49%|     | 498/1024 [01:06<01:12,  7.25it/s, est. speed input: 7631.16 toks/s, output: 7.45 toks/s]
Processed prompts:  49%|     | 506/1024 [01:07<01:11,  7.25it/s, est. speed input: 7627.56 toks/s, output: 7.45 toks/s]
Processed prompts:  50%|     | 514/1024 [01:09<01:10,  7.24it/s, est. speed input: 7623.71 toks/s, output: 7.45 toks/s]
Processed prompts:  51%|     | 522/1024 [01:10<01:09,  7.24it/s, est. speed input: 7620.41 toks/s, output: 7.44 toks/s]
Processed prompts:  52%|    | 530/1024 [01:11<01:08,  7.24it/s, est. speed input: 7617.34 toks/s, output: 7.44 toks/s]
Processed prompts:  53%|    | 538/1024 [01:12<01:07,  7.24it/s, est. speed input: 7613.93 toks/s, output: 7.44 toks/s]
Processed prompts:  53%|    | 546/1024 [01:13<01:06,  7.23it/s, est. speed input: 7610.63 toks/s, output: 7.43 toks/s]
Processed prompts:  54%|    | 554/1024 [01:14<01:04,  7.24it/s, est. speed input: 7607.80 toks/s, output: 7.43 toks/s]
Processed prompts:  55%|    | 562/1024 [01:15<01:03,  7.24it/s, est. speed input: 7605.08 toks/s, output: 7.43 toks/s]
Processed prompts:  56%|    | 570/1024 [01:16<01:02,  7.24it/s, est. speed input: 7602.37 toks/s, output: 7.42 toks/s]
Processed prompts:  56%|    | 578/1024 [01:17<01:01,  7.24it/s, est. speed input: 7599.48 toks/s, output: 7.42 toks/s]
Processed prompts:  57%|    | 586/1024 [01:18<01:00,  7.24it/s, est. speed input: 7596.82 toks/s, output: 7.42 toks/s]
Processed prompts:  58%|    | 594/1024 [01:20<00:59,  7.24it/s, est. speed input: 7594.51 toks/s, output: 7.42 toks/s]
Processed prompts:  59%|    | 602/1024 [01:21<00:58,  7.25it/s, est. speed input: 7592.24 toks/s, output: 7.41 toks/s]
Processed prompts:  60%|    | 610/1024 [01:22<00:57,  7.24it/s, est. speed input: 7589.86 toks/s, output: 7.41 toks/s]
Processed prompts:  60%|    | 618/1024 [01:23<00:56,  7.24it/s, est. speed input: 7587.19 toks/s, output: 7.41 toks/s]
Processed prompts:  61%|    | 626/1024 [01:24<00:54,  7.24it/s, est. speed input: 7585.03 toks/s, output: 7.41 toks/s]
Processed prompts:  62%|   | 634/1024 [01:25<00:53,  7.24it/s, est. speed input: 7583.02 toks/s, output: 7.41 toks/s]
Processed prompts:  63%|   | 642/1024 [01:26<00:52,  7.25it/s, est. speed input: 7581.11 toks/s, output: 7.40 toks/s]
Processed prompts:  63%|   | 650/1024 [01:27<00:51,  7.24it/s, est. speed input: 7578.90 toks/s, output: 7.40 toks/s]
Processed prompts:  64%|   | 658/1024 [01:28<00:50,  7.24it/s, est. speed input: 7576.75 toks/s, output: 7.40 toks/s]
Processed prompts:  65%|   | 666/1024 [01:30<00:49,  7.24it/s, est. speed input: 7574.74 toks/s, output: 7.40 toks/s]
Processed prompts:  66%|   | 674/1024 [01:31<00:48,  7.24it/s, est. speed input: 7572.63 toks/s, output: 7.40 toks/s]
Processed prompts:  67%|   | 682/1024 [01:32<00:47,  7.24it/s, est. speed input: 7570.76 toks/s, output: 7.39 toks/s]
Processed prompts:  67%|   | 690/1024 [01:33<00:46,  7.24it/s, est. speed input: 7569.14 toks/s, output: 7.39 toks/s]
Processed prompts:  68%|   | 698/1024 [01:34<00:44,  7.25it/s, est. speed input: 7567.40 toks/s, output: 7.39 toks/s]
Processed prompts:  69%|   | 706/1024 [01:35<00:43,  7.24it/s, est. speed input: 7565.61 toks/s, output: 7.39 toks/s]
Processed prompts:  70%|   | 714/1024 [01:36<00:42,  7.24it/s, est. speed input: 7563.75 toks/s, output: 7.39 toks/s]
Processed prompts:  71%|   | 722/1024 [01:37<00:41,  7.24it/s, est. speed input: 7562.09 toks/s, output: 7.38 toks/s]
Processed prompts:  71%|  | 730/1024 [01:38<00:40,  7.24it/s, est. speed input: 7560.48 toks/s, output: 7.38 toks/s]
Processed prompts:  72%|  | 738/1024 [01:39<00:39,  7.23it/s, est. speed input: 7558.58 toks/s, output: 7.38 toks/s]
Processed prompts:  73%|  | 746/1024 [01:41<00:38,  7.23it/s, est. speed input: 7556.81 toks/s, output: 7.38 toks/s]
Processed prompts:  74%|  | 754/1024 [01:42<00:37,  7.24it/s, est. speed input: 7555.34 toks/s, output: 7.38 toks/s]
Processed prompts:  74%|  | 762/1024 [01:43<00:36,  7.23it/s, est. speed input: 7553.71 toks/s, output: 7.38 toks/s]
Processed prompts:  75%|  | 770/1024 [01:44<00:35,  7.24it/s, est. speed input: 7552.26 toks/s, output: 7.38 toks/s]
Processed prompts:  76%|  | 778/1024 [01:45<00:34,  7.23it/s, est. speed input: 7550.69 toks/s, output: 7.37 toks/s]
Processed prompts:  77%|  | 786/1024 [01:46<00:31,  7.51it/s, est. speed input: 7558.72 toks/s, output: 7.38 toks/s]
Processed prompts:  78%|  | 794/1024 [01:47<00:30,  7.42it/s, est. speed input: 7557.10 toks/s, output: 7.38 toks/s]
Processed prompts:  78%|  | 802/1024 [01:48<00:30,  7.36it/s, est. speed input: 7555.59 toks/s, output: 7.38 toks/s]
Processed prompts:  79%|  | 810/1024 [01:49<00:29,  7.32it/s, est. speed input: 7554.09 toks/s, output: 7.38 toks/s]
Processed prompts:  80%|  | 818/1024 [01:50<00:28,  7.30it/s, est. speed input: 7552.64 toks/s, output: 7.38 toks/s]
Processed prompts:  81%|  | 826/1024 [01:52<00:27,  7.28it/s, est. speed input: 7551.27 toks/s, output: 7.37 toks/s]
Processed prompts:  81%| | 834/1024 [01:53<00:26,  7.27it/s, est. speed input: 7550.05 toks/s, output: 7.37 toks/s]
Processed prompts:  82%| | 842/1024 [01:54<00:25,  7.26it/s, est. speed input: 7548.52 toks/s, output: 7.37 toks/s]
Processed prompts:  83%| | 850/1024 [01:55<00:23,  7.25it/s, est. speed input: 7547.33 toks/s, output: 7.37 toks/s]
Processed prompts:  84%| | 858/1024 [01:56<00:22,  7.25it/s, est. speed input: 7546.03 toks/s, output: 7.37 toks/s]
Processed prompts:  85%| | 866/1024 [01:57<00:21,  7.24it/s, est. speed input: 7544.60 toks/s, output: 7.37 toks/s]
Processed prompts:  85%| | 874/1024 [01:58<00:20,  7.24it/s, est. speed input: 7543.38 toks/s, output: 7.37 toks/s]
Processed prompts:  86%| | 882/1024 [01:59<00:19,  7.24it/s, est. speed input: 7542.29 toks/s, output: 7.37 toks/s]
Processed prompts:  87%| | 890/1024 [02:00<00:18,  7.25it/s, est. speed input: 7541.23 toks/s, output: 7.36 toks/s]
Processed prompts:  88%| | 898/1024 [02:01<00:17,  7.24it/s, est. speed input: 7539.90 toks/s, output: 7.36 toks/s]
Processed prompts:  88%| | 906/1024 [02:03<00:16,  7.24it/s, est. speed input: 7538.79 toks/s, output: 7.36 toks/s]
Processed prompts:  89%| | 914/1024 [02:04<00:15,  7.24it/s, est. speed input: 7537.58 toks/s, output: 7.36 toks/s]
Processed prompts:  90%| | 922/1024 [02:05<00:14,  7.24it/s, est. speed input: 7536.54 toks/s, output: 7.36 toks/s]
Processed prompts:  91%| | 930/1024 [02:06<00:12,  7.24it/s, est. speed input: 7535.51 toks/s, output: 7.36 toks/s]
Processed prompts:  92%|| 938/1024 [02:07<00:11,  7.24it/s, est. speed input: 7534.29 toks/s, output: 7.36 toks/s]
Processed prompts:  92%|| 946/1024 [02:08<00:10,  7.23it/s, est. speed input: 7532.99 toks/s, output: 7.36 toks/s]
Processed prompts:  93%|| 954/1024 [02:09<00:09,  7.24it/s, est. speed input: 7532.24 toks/s, output: 7.36 toks/s]
Processed prompts:  94%|| 962/1024 [02:10<00:08,  7.23it/s, est. speed input: 7531.01 toks/s, output: 7.35 toks/s]
Processed prompts:  95%|| 970/1024 [02:11<00:07,  7.23it/s, est. speed input: 7529.93 toks/s, output: 7.35 toks/s]
Processed prompts:  96%|| 978/1024 [02:13<00:06,  7.24it/s, est. speed input: 7529.02 toks/s, output: 7.35 toks/s]
Processed prompts:  96%|| 986/1024 [02:14<00:05,  7.24it/s, est. speed input: 7528.04 toks/s, output: 7.35 toks/s]
Processed prompts:  97%|| 994/1024 [02:15<00:04,  7.23it/s, est. speed input: 7526.91 toks/s, output: 7.35 toks/s]
Processed prompts:  98%|| 1002/1024 [02:16<00:03,  7.23it/s, est. speed input: 7525.96 toks/s, output: 7.35 toks/s]
Processed prompts:  99%|| 1010/1024 [02:17<00:01,  7.23it/s, est. speed input: 7525.05 toks/s, output: 7.35 toks/s]
Processed prompts:  99%|| 1018/1024 [02:18<00:00,  7.50it/s, est. speed input: 7531.28 toks/s, output: 7.35 toks/s]
Processed prompts: 100%|| 1024/1024 [02:18<00:00,  7.50it/s, est. speed input: 7575.66 toks/s, output: 7.40 toks/s]
Processed prompts: 100%|| 1024/1024 [02:18<00:00,  7.40it/s, est. speed input: 7575.66 toks/s, output: 7.40 toks/s]
[rank0]:[W126 18:24:31.332472623 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-26 18:24:33
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Qwen2.5-7B-FP8_M16384.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 18:24:44 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 18:24:44 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1596380) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1596380) WARNING 01-26 18:25:41 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 7.33 requests/s, 7511.97 total tokens/s, 7.33 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-26 18:24:44] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 18:24:44] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 18:24:44] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 18:24:44] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:24:44] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:24:44] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:24:44] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:24:44] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:24:44] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 18:24:44] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 18:24:44] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 18:24:44] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 18:24:44] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 18:24:44] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 18:24:47] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 18:24:47] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 18:24:47] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 18:24:47] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:24:47] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:24:47] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:24:47] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:24:47] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:24:47] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 18:24:47] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 18:24:47] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 18:24:47] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 18:24:47] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 18:24:47] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1596380) [2026-01-26 18:24:48] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1596380) [2026-01-26 18:24:48] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1596380) [2026-01-26 18:24:48] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1596380) [2026-01-26 18:24:48] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1596380) [2026-01-26 18:24:48] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1596380) [2026-01-26 18:24:48] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1596380) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1596380) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:20<00:20, 20.72s/it]
(EngineCore_DP0 pid=1596380) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:41<00:00, 20.62s/it]
(EngineCore_DP0 pid=1596380) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:41<00:00, 20.64s/it]
(EngineCore_DP0 pid=1596380) 
(EngineCore_DP0 pid=1596380) [2026-01-26 18:25:30] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=1596380) [2026-01-26 18:25:30] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10321920 bytes
(EngineCore_DP0 pid=1596380) [2026-01-26 18:25:30] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=1596380) [2026-01-26 18:25:30] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8028160 bytes
(EngineCore_DP0 pid=1596380) [2026-01-26 18:25:30] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=1596380) [2026-01-26 18:25:30] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 84869120 bytes
(EngineCore_DP0 pid=1596380) [2026-01-26 18:25:30] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=1596380) [2026-01-26 18:25:30] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 42434560 bytes
(EngineCore_DP0 pid=1596380) 2026-01-26 18:25:38,111 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1596380) 2026-01-26 18:25:38,451 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   1%|         | 29/2048 [00:00<00:07, 285.03it/s]
Adding requests:   3%|         | 65/2048 [00:00<00:06, 325.40it/s]
Adding requests:   5%|         | 101/2048 [00:00<00:05, 338.79it/s]
Adding requests:   7%|         | 142/2048 [00:00<00:05, 366.07it/s]
Adding requests:   9%|         | 185/2048 [00:00<00:04, 385.42it/s]
Adding requests:  11%|         | 229/2048 [00:00<00:04, 402.55it/s]
Adding requests:  13%|        | 270/2048 [00:00<00:04, 404.55it/s]
Adding requests:  15%|        | 315/2048 [00:00<00:04, 418.58it/s]
Adding requests:  17%|        | 357/2048 [00:00<00:04, 415.29it/s]
Adding requests:  19%|        | 399/2048 [00:01<00:04, 412.10it/s]
Adding requests:  22%|       | 441/2048 [00:01<00:03, 408.99it/s]
Adding requests:  24%|       | 482/2048 [00:01<00:03, 408.45it/s]
Adding requests:  26%|       | 530/2048 [00:01<00:03, 428.85it/s]
Adding requests:  28%|       | 574/2048 [00:01<00:03, 429.04it/s]
Adding requests:  30%|       | 617/2048 [00:01<00:03, 411.07it/s]
Adding requests:  32%|      | 659/2048 [00:01<00:03, 405.39it/s]
Adding requests:  34%|      | 700/2048 [00:01<00:03, 404.91it/s]
Adding requests:  36%|      | 741/2048 [00:01<00:03, 395.17it/s]
Adding requests:  38%|      | 781/2048 [00:01<00:03, 374.86it/s]
Adding requests:  40%|      | 820/2048 [00:02<00:03, 376.97it/s]
Adding requests:  42%|     | 858/2048 [00:02<00:09, 124.36it/s]
Adding requests:  44%|     | 894/2048 [00:02<00:07, 151.73it/s]
Adding requests:  46%|     | 932/2048 [00:03<00:06, 184.23it/s]
Adding requests:  47%|     | 971/2048 [00:03<00:04, 219.16it/s]
Adding requests:  49%|     | 1010/2048 [00:03<00:04, 252.09it/s]
Adding requests:  51%|    | 1051/2048 [00:03<00:03, 285.20it/s]
Adding requests:  53%|    | 1091/2048 [00:03<00:03, 312.30it/s]
Adding requests:  55%|    | 1134/2048 [00:03<00:02, 341.74it/s]
Adding requests:  57%|    | 1175/2048 [00:03<00:02, 357.85it/s]
Adding requests:  59%|    | 1217/2048 [00:03<00:02, 372.51it/s]
Adding requests:  61%|   | 1258/2048 [00:03<00:02, 375.02it/s]
Adding requests:  63%|   | 1298/2048 [00:04<00:01, 381.64it/s]
Adding requests:  65%|   | 1338/2048 [00:04<00:01, 380.11it/s]
Adding requests:  67%|   | 1380/2048 [00:04<00:01, 389.00it/s]
Adding requests:  69%|   | 1421/2048 [00:04<00:01, 393.81it/s]
Adding requests:  71%|  | 1462/2048 [00:04<00:01, 398.27it/s]
Adding requests:  73%|  | 1505/2048 [00:04<00:01, 405.94it/s]
Adding requests:  75%|  | 1546/2048 [00:04<00:01, 406.15it/s]
Adding requests:  77%|  | 1587/2048 [00:04<00:01, 395.43it/s]
Adding requests:  79%|  | 1627/2048 [00:04<00:01, 393.33it/s]
Adding requests:  81%| | 1667/2048 [00:04<00:01, 379.26it/s]
Adding requests:  83%| | 1708/2048 [00:05<00:00, 384.11it/s]
Adding requests:  85%| | 1747/2048 [00:05<00:00, 377.18it/s]
Adding requests:  87%| | 1787/2048 [00:05<00:00, 383.04it/s]
Adding requests:  89%| | 1828/2048 [00:05<00:00, 390.57it/s]
Adding requests:  91%| | 1868/2048 [00:05<00:00, 388.31it/s]
Adding requests:  93%|| 1911/2048 [00:05<00:00, 398.88it/s]
Adding requests:  95%|| 1953/2048 [00:05<00:00, 404.41it/s]
Adding requests:  97%|| 1994/2048 [00:05<00:00, 401.77it/s]
Adding requests:  99%|| 2035/2048 [00:05<00:00, 362.89it/s]
Adding requests: 100%|| 2048/2048 [00:05<00:00, 344.10it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 34/2048 [00:00<00:51, 39.33it/s, est. speed input: 40271.02 toks/s, output: 39.33 toks/s]
Processed prompts:   2%|         | 50/2048 [00:03<02:24, 13.85it/s, est. speed input: 16346.70 toks/s, output: 15.96 toks/s]
Processed prompts:   3%|         | 66/2048 [00:05<03:09, 10.43it/s, est. speed input: 12691.08 toks/s, output: 12.39 toks/s]
Processed prompts:   4%|         | 82/2048 [00:07<03:36,  9.08it/s, est. speed input: 11156.38 toks/s, output: 10.89 toks/s]
Processed prompts:   5%|         | 98/2048 [00:09<03:52,  8.40it/s, est. speed input: 10320.61 toks/s, output: 10.08 toks/s]
Processed prompts:   6%|         | 114/2048 [00:11<04:01,  8.01it/s, est. speed input: 9793.76 toks/s, output: 9.56 toks/s] 
Processed prompts:   6%|         | 130/2048 [00:14<04:07,  7.75it/s, est. speed input: 9420.96 toks/s, output: 9.20 toks/s]
Processed prompts:   7%|         | 146/2048 [00:16<04:10,  7.60it/s, est. speed input: 9157.24 toks/s, output: 8.94 toks/s]
Processed prompts:   8%|         | 162/2048 [00:18<04:11,  7.50it/s, est. speed input: 8955.79 toks/s, output: 8.75 toks/s]
Processed prompts:   9%|         | 178/2048 [00:20<04:11,  7.43it/s, est. speed input: 8796.79 toks/s, output: 8.59 toks/s]
Processed prompts:   9%|         | 194/2048 [00:22<04:06,  7.53it/s, est. speed input: 8719.78 toks/s, output: 8.52 toks/s]
Processed prompts:  10%|         | 210/2048 [00:24<04:06,  7.44it/s, est. speed input: 8605.27 toks/s, output: 8.40 toks/s]
Processed prompts:  11%|         | 226/2048 [00:27<04:06,  7.39it/s, est. speed input: 8511.90 toks/s, output: 8.31 toks/s]
Processed prompts:  12%|        | 242/2048 [00:29<04:05,  7.36it/s, est. speed input: 8433.77 toks/s, output: 8.24 toks/s]
Processed prompts:  13%|        | 258/2048 [00:31<04:04,  7.33it/s, est. speed input: 8364.86 toks/s, output: 8.17 toks/s]
Processed prompts:  13%|        | 274/2048 [00:33<04:02,  7.32it/s, est. speed input: 8305.78 toks/s, output: 8.11 toks/s]
Processed prompts:  14%|        | 290/2048 [00:35<04:00,  7.30it/s, est. speed input: 8252.80 toks/s, output: 8.06 toks/s]
Processed prompts:  15%|        | 306/2048 [00:38<03:53,  7.44it/s, est. speed input: 8238.44 toks/s, output: 8.05 toks/s]
Processed prompts:  16%|        | 322/2048 [00:40<03:53,  7.39it/s, est. speed input: 8195.67 toks/s, output: 8.00 toks/s]
Processed prompts:  17%|        | 338/2048 [00:42<03:52,  7.36it/s, est. speed input: 8156.84 toks/s, output: 7.97 toks/s]
Processed prompts:  17%|        | 354/2048 [00:44<03:51,  7.33it/s, est. speed input: 8121.96 toks/s, output: 7.93 toks/s]
Processed prompts:  18%|        | 370/2048 [00:46<03:49,  7.32it/s, est. speed input: 8090.77 toks/s, output: 7.90 toks/s]
Processed prompts:  19%|        | 386/2048 [00:49<03:47,  7.30it/s, est. speed input: 8061.86 toks/s, output: 7.87 toks/s]
Processed prompts:  20%|        | 402/2048 [00:51<03:45,  7.29it/s, est. speed input: 8034.96 toks/s, output: 7.85 toks/s]
Processed prompts:  20%|        | 418/2048 [00:53<03:43,  7.29it/s, est. speed input: 8010.78 toks/s, output: 7.82 toks/s]
Processed prompts:  21%|        | 434/2048 [00:55<03:37,  7.43it/s, est. speed input: 8009.71 toks/s, output: 7.82 toks/s]
Processed prompts:  22%|       | 450/2048 [00:57<03:36,  7.38it/s, est. speed input: 7987.93 toks/s, output: 7.80 toks/s]
Processed prompts:  23%|       | 466/2048 [00:59<03:35,  7.35it/s, est. speed input: 7967.74 toks/s, output: 7.78 toks/s]
Processed prompts:  24%|       | 482/2048 [01:02<03:33,  7.32it/s, est. speed input: 7949.04 toks/s, output: 7.76 toks/s]
Processed prompts:  24%|       | 498/2048 [01:04<03:32,  7.30it/s, est. speed input: 7931.50 toks/s, output: 7.75 toks/s]
Processed prompts:  25%|       | 514/2048 [01:06<03:30,  7.29it/s, est. speed input: 7915.23 toks/s, output: 7.73 toks/s]
Processed prompts:  26%|       | 530/2048 [01:08<03:28,  7.29it/s, est. speed input: 7900.25 toks/s, output: 7.72 toks/s]
Processed prompts:  27%|       | 546/2048 [01:10<03:26,  7.28it/s, est. speed input: 7885.60 toks/s, output: 7.70 toks/s]
Processed prompts:  27%|       | 562/2048 [01:13<03:24,  7.27it/s, est. speed input: 7871.89 toks/s, output: 7.69 toks/s]
Processed prompts:  28%|       | 578/2048 [01:15<03:22,  7.27it/s, est. speed input: 7859.40 toks/s, output: 7.68 toks/s]
Processed prompts:  29%|       | 594/2048 [01:17<03:19,  7.27it/s, est. speed input: 7847.72 toks/s, output: 7.66 toks/s]
Processed prompts:  30%|       | 610/2048 [01:19<03:17,  7.27it/s, est. speed input: 7836.48 toks/s, output: 7.65 toks/s]
Processed prompts:  31%|       | 626/2048 [01:21<03:15,  7.27it/s, est. speed input: 7825.91 toks/s, output: 7.64 toks/s]
Processed prompts:  31%|      | 642/2048 [01:24<03:13,  7.27it/s, est. speed input: 7816.05 toks/s, output: 7.63 toks/s]
Processed prompts:  32%|      | 658/2048 [01:26<03:11,  7.27it/s, est. speed input: 7806.67 toks/s, output: 7.62 toks/s]
Processed prompts:  33%|      | 674/2048 [01:28<03:09,  7.27it/s, est. speed input: 7797.28 toks/s, output: 7.61 toks/s]
Processed prompts:  34%|      | 690/2048 [01:30<03:06,  7.27it/s, est. speed input: 7788.80 toks/s, output: 7.61 toks/s]
Processed prompts:  34%|      | 706/2048 [01:32<03:04,  7.27it/s, est. speed input: 7780.78 toks/s, output: 7.60 toks/s]
Processed prompts:  35%|      | 722/2048 [01:35<03:02,  7.27it/s, est. speed input: 7772.84 toks/s, output: 7.59 toks/s]
Processed prompts:  36%|      | 738/2048 [01:37<03:00,  7.27it/s, est. speed input: 7765.36 toks/s, output: 7.58 toks/s]
Processed prompts:  37%|      | 754/2048 [01:39<02:58,  7.27it/s, est. speed input: 7758.16 toks/s, output: 7.58 toks/s]
Processed prompts:  38%|      | 770/2048 [01:41<02:55,  7.26it/s, est. speed input: 7751.08 toks/s, output: 7.57 toks/s]
Processed prompts:  38%|      | 786/2048 [01:43<02:50,  7.42it/s, est. speed input: 7755.68 toks/s, output: 7.57 toks/s]
Processed prompts:  39%|      | 802/2048 [01:45<02:49,  7.37it/s, est. speed input: 7749.18 toks/s, output: 7.57 toks/s]
Processed prompts:  40%|      | 818/2048 [01:48<02:47,  7.34it/s, est. speed input: 7742.87 toks/s, output: 7.56 toks/s]
Processed prompts:  41%|      | 834/2048 [01:50<02:45,  7.32it/s, est. speed input: 7736.94 toks/s, output: 7.56 toks/s]
Processed prompts:  42%|     | 850/2048 [01:52<02:44,  7.30it/s, est. speed input: 7731.03 toks/s, output: 7.55 toks/s]
Processed prompts:  42%|     | 866/2048 [01:54<02:42,  7.30it/s, est. speed input: 7725.76 toks/s, output: 7.54 toks/s]
Processed prompts:  43%|     | 882/2048 [01:56<02:40,  7.28it/s, est. speed input: 7720.29 toks/s, output: 7.54 toks/s]
Processed prompts:  44%|     | 898/2048 [01:59<02:38,  7.28it/s, est. speed input: 7715.02 toks/s, output: 7.53 toks/s]
Processed prompts:  45%|     | 914/2048 [02:01<02:35,  7.27it/s, est. speed input: 7709.84 toks/s, output: 7.53 toks/s]
Processed prompts:  45%|     | 930/2048 [02:03<02:33,  7.27it/s, est. speed input: 7705.23 toks/s, output: 7.52 toks/s]
Processed prompts:  46%|     | 946/2048 [02:05<02:31,  7.27it/s, est. speed input: 7700.58 toks/s, output: 7.52 toks/s]
Processed prompts:  47%|     | 962/2048 [02:07<02:29,  7.27it/s, est. speed input: 7696.16 toks/s, output: 7.52 toks/s]
Processed prompts:  48%|     | 978/2048 [02:10<02:27,  7.27it/s, est. speed input: 7691.89 toks/s, output: 7.51 toks/s]
Processed prompts:  49%|     | 994/2048 [02:12<02:25,  7.27it/s, est. speed input: 7687.60 toks/s, output: 7.51 toks/s]
Processed prompts:  49%|     | 1010/2048 [02:14<02:22,  7.27it/s, est. speed input: 7683.74 toks/s, output: 7.50 toks/s]
Processed prompts:  50%|     | 1026/2048 [02:16<02:20,  7.27it/s, est. speed input: 7679.77 toks/s, output: 7.50 toks/s]
Processed prompts:  51%|     | 1042/2048 [02:19<02:18,  7.27it/s, est. speed input: 7675.93 toks/s, output: 7.50 toks/s]
Processed prompts:  52%|    | 1058/2048 [02:21<02:16,  7.27it/s, est. speed input: 7672.39 toks/s, output: 7.49 toks/s]
Processed prompts:  52%|    | 1074/2048 [02:23<02:14,  7.27it/s, est. speed input: 7668.85 toks/s, output: 7.49 toks/s]
Processed prompts:  53%|    | 1090/2048 [02:25<02:11,  7.27it/s, est. speed input: 7665.38 toks/s, output: 7.49 toks/s]
Processed prompts:  54%|    | 1106/2048 [02:27<02:09,  7.27it/s, est. speed input: 7662.10 toks/s, output: 7.48 toks/s]
Processed prompts:  55%|    | 1122/2048 [02:30<02:07,  7.27it/s, est. speed input: 7658.83 toks/s, output: 7.48 toks/s]
Processed prompts:  56%|    | 1138/2048 [02:32<02:05,  7.27it/s, est. speed input: 7655.72 toks/s, output: 7.48 toks/s]
Processed prompts:  56%|    | 1154/2048 [02:34<02:03,  7.26it/s, est. speed input: 7652.44 toks/s, output: 7.47 toks/s]
Processed prompts:  57%|    | 1170/2048 [02:36<02:00,  7.26it/s, est. speed input: 7649.24 toks/s, output: 7.47 toks/s]
Processed prompts:  58%|    | 1186/2048 [02:38<01:58,  7.26it/s, est. speed input: 7646.20 toks/s, output: 7.47 toks/s]
Processed prompts:  59%|    | 1202/2048 [02:40<01:54,  7.42it/s, est. speed input: 7650.84 toks/s, output: 7.47 toks/s]
Processed prompts:  59%|    | 1218/2048 [02:43<01:52,  7.37it/s, est. speed input: 7647.88 toks/s, output: 7.47 toks/s]
Processed prompts:  60%|    | 1234/2048 [02:45<01:48,  7.50it/s, est. speed input: 7652.27 toks/s, output: 7.47 toks/s]
Processed prompts:  61%|    | 1250/2048 [02:47<01:47,  7.43it/s, est. speed input: 7649.41 toks/s, output: 7.47 toks/s]
Processed prompts:  62%|   | 1266/2048 [02:49<01:46,  7.37it/s, est. speed input: 7646.56 toks/s, output: 7.47 toks/s]
Processed prompts:  63%|   | 1282/2048 [02:51<01:44,  7.34it/s, est. speed input: 7643.91 toks/s, output: 7.46 toks/s]
Processed prompts:  63%|   | 1298/2048 [02:53<01:42,  7.32it/s, est. speed input: 7641.24 toks/s, output: 7.46 toks/s]
Processed prompts:  64%|   | 1314/2048 [02:56<01:40,  7.31it/s, est. speed input: 7638.92 toks/s, output: 7.46 toks/s]
Processed prompts:  65%|   | 1330/2048 [02:58<01:36,  7.45it/s, est. speed input: 7642.95 toks/s, output: 7.46 toks/s]
Processed prompts:  66%|   | 1346/2048 [03:00<01:34,  7.39it/s, est. speed input: 7640.42 toks/s, output: 7.46 toks/s]
Processed prompts:  67%|   | 1362/2048 [03:02<01:33,  7.36it/s, est. speed input: 7638.13 toks/s, output: 7.46 toks/s]
Processed prompts:  67%|   | 1378/2048 [03:04<01:31,  7.33it/s, est. speed input: 7635.77 toks/s, output: 7.46 toks/s]
Processed prompts:  68%|   | 1394/2048 [03:07<01:29,  7.31it/s, est. speed input: 7633.29 toks/s, output: 7.45 toks/s]
Processed prompts:  69%|   | 1410/2048 [03:09<01:27,  7.29it/s, est. speed input: 7631.03 toks/s, output: 7.45 toks/s]
Processed prompts:  70%|   | 1426/2048 [03:11<01:25,  7.29it/s, est. speed input: 7628.85 toks/s, output: 7.45 toks/s]
Processed prompts:  70%|   | 1442/2048 [03:13<01:21,  7.43it/s, est. speed input: 7632.54 toks/s, output: 7.45 toks/s]
Processed prompts:  71%|   | 1458/2048 [03:15<01:18,  7.53it/s, est. speed input: 7636.18 toks/s, output: 7.46 toks/s]
Processed prompts:  72%|  | 1474/2048 [03:17<01:17,  7.45it/s, est. speed input: 7633.93 toks/s, output: 7.46 toks/s]
Processed prompts:  73%|  | 1490/2048 [03:19<01:15,  7.40it/s, est. speed input: 7631.91 toks/s, output: 7.45 toks/s]
Processed prompts:  74%|  | 1506/2048 [03:22<01:13,  7.36it/s, est. speed input: 7629.86 toks/s, output: 7.45 toks/s]
Processed prompts:  74%|  | 1522/2048 [03:24<01:10,  7.48it/s, est. speed input: 7633.40 toks/s, output: 7.45 toks/s]
Processed prompts:  75%|  | 1538/2048 [03:26<01:08,  7.42it/s, est. speed input: 7631.35 toks/s, output: 7.45 toks/s]
Processed prompts:  76%|  | 1554/2048 [03:28<01:05,  7.53it/s, est. speed input: 7634.87 toks/s, output: 7.46 toks/s]
Processed prompts:  77%|  | 1570/2048 [03:30<01:04,  7.45it/s, est. speed input: 7632.85 toks/s, output: 7.45 toks/s]
Processed prompts:  77%|  | 1586/2048 [03:32<01:02,  7.39it/s, est. speed input: 7630.83 toks/s, output: 7.45 toks/s]
Processed prompts:  78%|  | 1602/2048 [03:35<01:00,  7.35it/s, est. speed input: 7628.89 toks/s, output: 7.45 toks/s]
Processed prompts:  79%|  | 1618/2048 [03:37<00:57,  7.48it/s, est. speed input: 7632.24 toks/s, output: 7.45 toks/s]
Processed prompts:  80%|  | 1634/2048 [03:39<00:55,  7.42it/s, est. speed input: 7630.33 toks/s, output: 7.45 toks/s]
Processed prompts:  81%|  | 1650/2048 [03:41<00:54,  7.36it/s, est. speed input: 7628.23 toks/s, output: 7.45 toks/s]
Processed prompts:  81%| | 1666/2048 [03:43<00:52,  7.33it/s, est. speed input: 7626.33 toks/s, output: 7.45 toks/s]
Processed prompts:  82%| | 1682/2048 [03:45<00:50,  7.31it/s, est. speed input: 7624.50 toks/s, output: 7.45 toks/s]
Processed prompts:  83%| | 1698/2048 [03:48<00:47,  7.30it/s, est. speed input: 7622.78 toks/s, output: 7.44 toks/s]
Processed prompts:  84%| | 1714/2048 [03:50<00:45,  7.29it/s, est. speed input: 7620.96 toks/s, output: 7.44 toks/s]
Processed prompts:  84%| | 1730/2048 [03:52<00:42,  7.43it/s, est. speed input: 7624.22 toks/s, output: 7.45 toks/s]
Processed prompts:  85%| | 1746/2048 [03:54<00:39,  7.66it/s, est. speed input: 7630.92 toks/s, output: 7.45 toks/s]
Processed prompts:  86%| | 1762/2048 [03:56<00:37,  7.54it/s, est. speed input: 7629.17 toks/s, output: 7.45 toks/s]
Processed prompts:  87%| | 1778/2048 [03:58<00:36,  7.45it/s, est. speed input: 7627.44 toks/s, output: 7.45 toks/s]
Processed prompts:  88%| | 1794/2048 [04:00<00:34,  7.39it/s, est. speed input: 7625.56 toks/s, output: 7.45 toks/s]
Processed prompts:  88%| | 1810/2048 [04:03<00:32,  7.35it/s, est. speed input: 7623.93 toks/s, output: 7.45 toks/s]
Processed prompts:  89%| | 1826/2048 [04:05<00:30,  7.32it/s, est. speed input: 7622.19 toks/s, output: 7.44 toks/s]
Processed prompts:  90%| | 1842/2048 [04:07<00:28,  7.31it/s, est. speed input: 7620.55 toks/s, output: 7.44 toks/s]
Processed prompts:  91%| | 1858/2048 [04:09<00:26,  7.29it/s, est. speed input: 7618.89 toks/s, output: 7.44 toks/s]
Processed prompts:  92%|| 1874/2048 [04:11<00:23,  7.28it/s, est. speed input: 7617.34 toks/s, output: 7.44 toks/s]
Processed prompts:  92%|| 1890/2048 [04:13<00:21,  7.43it/s, est. speed input: 7620.40 toks/s, output: 7.44 toks/s]
Processed prompts:  93%|| 1906/2048 [04:16<00:19,  7.39it/s, est. speed input: 7618.91 toks/s, output: 7.44 toks/s]
Processed prompts:  94%|| 1922/2048 [04:18<00:17,  7.35it/s, est. speed input: 7617.41 toks/s, output: 7.44 toks/s]
Processed prompts:  95%|| 1938/2048 [04:20<00:15,  7.32it/s, est. speed input: 7615.83 toks/s, output: 7.44 toks/s]
Processed prompts:  95%|| 1954/2048 [04:22<00:12,  7.30it/s, est. speed input: 7614.25 toks/s, output: 7.44 toks/s]
Processed prompts:  96%|| 1970/2048 [04:24<00:10,  7.29it/s, est. speed input: 7612.75 toks/s, output: 7.43 toks/s]
Processed prompts:  97%|| 1986/2048 [04:27<00:08,  7.44it/s, est. speed input: 7615.71 toks/s, output: 7.44 toks/s]
Processed prompts:  98%|| 2002/2048 [04:29<00:06,  7.38it/s, est. speed input: 7614.15 toks/s, output: 7.44 toks/s]
Processed prompts:  99%|| 2018/2048 [04:31<00:04,  7.35it/s, est. speed input: 7612.75 toks/s, output: 7.43 toks/s]
Processed prompts:  99%|| 2034/2048 [04:33<00:01,  7.48it/s, est. speed input: 7615.60 toks/s, output: 7.44 toks/s]
Processed prompts: 100%|| 2048/2048 [04:33<00:00,  7.48it/s, est. speed input: 7668.01 toks/s, output: 7.49 toks/s]
Processed prompts: 100%|| 2048/2048 [04:33<00:00,  7.49it/s, est. speed input: 7668.01 toks/s, output: 7.49 toks/s]
[rank0]:[W126 18:30:21.574438540 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-26 18:30:23
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Qwen2.5-7B-FP8_M32768.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 18:30:41 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 18:30:41 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1601489) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1601489) WARNING 01-26 18:31:43 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 7.44 requests/s, 7625.99 total tokens/s, 7.44 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-26 18:30:41] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 18:30:41] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 18:30:41] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 18:30:41] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:30:41] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:30:41] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:30:41] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:30:41] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:30:41] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 18:30:41] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 18:30:41] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 18:30:41] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 18:30:41] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 18:30:41] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 18:30:44] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 18:30:44] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 18:30:44] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 18:30:44] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:30:44] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:30:44] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:30:44] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:30:44] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:30:44] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 18:30:45] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 18:30:45] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 18:30:45] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 18:30:45] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 18:30:45] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1601489) [2026-01-26 18:30:46] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1601489) [2026-01-26 18:30:46] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1601489) [2026-01-26 18:30:46] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1601489) [2026-01-26 18:30:46] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1601489) [2026-01-26 18:30:46] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1601489) [2026-01-26 18:30:46] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1601489) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1601489) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:20<00:20, 20.15s/it]
(EngineCore_DP0 pid=1601489) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:41<00:00, 20.68s/it]
(EngineCore_DP0 pid=1601489) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:41<00:00, 20.60s/it]
(EngineCore_DP0 pid=1601489) 
(EngineCore_DP0 pid=1601489) [2026-01-26 18:31:28] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=1601489) [2026-01-26 18:31:28] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10321920 bytes
(EngineCore_DP0 pid=1601489) [2026-01-26 18:31:28] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=1601489) [2026-01-26 18:31:28] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8028160 bytes
(EngineCore_DP0 pid=1601489) [2026-01-26 18:31:28] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=1601489) [2026-01-26 18:31:28] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 84869120 bytes
(EngineCore_DP0 pid=1601489) [2026-01-26 18:31:28] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=1601489) [2026-01-26 18:31:28] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 42434560 bytes
(EngineCore_DP0 pid=1601489) 2026-01-26 18:31:37,558 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1601489) 2026-01-26 18:31:38,128 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|          | 48/4096 [00:00<00:08, 465.69it/s]
Adding requests:   2%|         | 95/4096 [00:00<00:09, 405.83it/s]
Adding requests:   3%|         | 137/4096 [00:00<00:10, 386.73it/s]
Adding requests:   4%|         | 176/4096 [00:00<00:10, 386.29it/s]
Adding requests:   5%|         | 220/4096 [00:00<00:09, 402.91it/s]
Adding requests:   6%|         | 261/4096 [00:00<00:09, 399.65it/s]
Adding requests:   7%|         | 303/4096 [00:00<00:09, 404.85it/s]
Adding requests:   8%|         | 344/4096 [00:00<00:09, 405.23it/s]
Adding requests:   9%|         | 387/4096 [00:00<00:09, 411.28it/s]
Adding requests:  10%|         | 429/4096 [00:01<00:08, 410.94it/s]
Adding requests:  11%|        | 471/4096 [00:01<00:08, 413.61it/s]
Adding requests:  13%|        | 517/4096 [00:01<00:08, 426.41it/s]
Adding requests:  14%|        | 561/4096 [00:01<00:08, 427.75it/s]
Adding requests:  15%|        | 604/4096 [00:01<00:08, 415.04it/s]
Adding requests:  16%|        | 647/4096 [00:01<00:08, 415.88it/s]
Adding requests:  17%|        | 689/4096 [00:01<00:08, 414.67it/s]
Adding requests:  18%|        | 731/4096 [00:01<00:08, 409.11it/s]
Adding requests:  19%|        | 772/4096 [00:01<00:08, 408.35it/s]
Adding requests:  20%|        | 814/4096 [00:01<00:08, 409.00it/s]
Adding requests:  21%|        | 855/4096 [00:02<00:07, 407.00it/s]
Adding requests:  22%|       | 900/4096 [00:02<00:07, 417.24it/s]
Adding requests:  23%|       | 942/4096 [00:02<00:07, 409.97it/s]
Adding requests:  24%|       | 984/4096 [00:02<00:07, 412.83it/s]
Adding requests:  25%|       | 1026/4096 [00:02<00:07, 413.77it/s]
Adding requests:  26%|       | 1068/4096 [00:02<00:07, 409.78it/s]
Adding requests:  27%|       | 1110/4096 [00:02<00:07, 411.80it/s]
Adding requests:  28%|       | 1153/4096 [00:02<00:07, 415.97it/s]
Adding requests:  29%|       | 1195/4096 [00:02<00:07, 383.98it/s]
Adding requests:  30%|       | 1234/4096 [00:03<00:07, 378.21it/s]
Adding requests:  31%|       | 1275/4096 [00:03<00:07, 385.52it/s]
Adding requests:  32%|      | 1317/4096 [00:03<00:07, 393.51it/s]
Adding requests:  33%|      | 1359/4096 [00:03<00:06, 400.16it/s]
Adding requests:  34%|      | 1401/4096 [00:03<00:06, 405.55it/s]
Adding requests:  35%|      | 1444/4096 [00:03<00:06, 411.57it/s]
Adding requests:  36%|      | 1488/4096 [00:03<00:06, 417.45it/s]
Adding requests:  37%|      | 1530/4096 [00:03<00:06, 414.84it/s]
Adding requests:  38%|      | 1572/4096 [00:03<00:06, 412.63it/s]
Adding requests:  39%|      | 1614/4096 [00:03<00:06, 404.47it/s]
Adding requests:  40%|      | 1655/4096 [00:04<00:06, 397.36it/s]
Adding requests:  41%|     | 1697/4096 [00:04<00:05, 400.92it/s]
Adding requests:  42%|     | 1738/4096 [00:04<00:05, 403.44it/s]
Adding requests:  44%|     | 1783/4096 [00:04<00:05, 413.18it/s]
Adding requests:  45%|     | 1825/4096 [00:04<00:05, 408.08it/s]
Adding requests:  46%|     | 1867/4096 [00:04<00:05, 409.80it/s]
Adding requests:  47%|     | 1909/4096 [00:04<00:05, 404.66it/s]
Adding requests:  48%|     | 1952/4096 [00:04<00:05, 410.69it/s]
Adding requests:  49%|     | 1994/4096 [00:04<00:05, 401.59it/s]
Adding requests:  50%|     | 2035/4096 [00:05<00:05, 388.35it/s]
Adding requests:  51%|     | 2075/4096 [00:05<00:05, 390.38it/s]
Adding requests:  52%|    | 2116/4096 [00:05<00:05, 395.45it/s]
Adding requests:  53%|    | 2157/4096 [00:05<00:04, 398.98it/s]
Adding requests:  54%|    | 2197/4096 [00:05<00:04, 395.98it/s]
Adding requests:  55%|    | 2238/4096 [00:05<00:04, 398.27it/s]
Adding requests:  56%|    | 2284/4096 [00:05<00:04, 412.40it/s]
Adding requests:  57%|    | 2326/4096 [00:05<00:04, 413.92it/s]
Adding requests:  58%|    | 2370/4096 [00:05<00:04, 420.76it/s]
Adding requests:  59%|    | 2417/4096 [00:05<00:03, 431.62it/s]
Adding requests:  60%|    | 2461/4096 [00:06<00:04, 387.02it/s]
Adding requests:  61%|    | 2503/4096 [00:06<00:04, 395.06it/s]
Adding requests:  62%|   | 2549/4096 [00:06<00:03, 411.03it/s]
Adding requests:  63%|   | 2592/4096 [00:06<00:03, 416.16it/s]
Adding requests:  64%|   | 2635/4096 [00:06<00:03, 408.92it/s]
Adding requests:  65%|   | 2678/4096 [00:06<00:03, 411.61it/s]
Adding requests:  66%|   | 2720/4096 [00:06<00:03, 408.03it/s]
Adding requests:  67%|   | 2763/4096 [00:06<00:03, 413.56it/s]
Adding requests:  68%|   | 2805/4096 [00:06<00:03, 411.48it/s]
Adding requests:  70%|   | 2848/4096 [00:06<00:02, 416.65it/s]
Adding requests:  71%|   | 2890/4096 [00:07<00:02, 409.74it/s]
Adding requests:  72%|  | 2932/4096 [00:07<00:02, 405.40it/s]
Adding requests:  73%|  | 2979/4096 [00:07<00:02, 422.26it/s]
Adding requests:  74%|  | 3022/4096 [00:07<00:02, 418.37it/s]
Adding requests:  75%|  | 3067/4096 [00:07<00:02, 425.27it/s]
Adding requests:  76%|  | 3113/4096 [00:07<00:02, 433.71it/s]
Adding requests:  77%|  | 3157/4096 [00:07<00:02, 424.17it/s]
Adding requests:  78%|  | 3200/4096 [00:07<00:02, 421.19it/s]
Adding requests:  79%|  | 3246/4096 [00:07<00:01, 431.20it/s]
Adding requests:  80%|  | 3290/4096 [00:08<00:01, 414.61it/s]
Adding requests:  81%| | 3332/4096 [00:08<00:01, 414.17it/s]
Adding requests:  82%| | 3377/4096 [00:08<00:01, 421.62it/s]
Adding requests:  83%| | 3420/4096 [00:08<00:01, 418.60it/s]
Adding requests:  85%| | 3463/4096 [00:08<00:01, 421.43it/s]
Adding requests:  86%| | 3507/4096 [00:08<00:01, 424.20it/s]
Adding requests:  87%| | 3550/4096 [00:08<00:01, 419.63it/s]
Adding requests:  88%| | 3603/4096 [00:08<00:01, 449.11it/s]
Adding requests:  89%| | 3648/4096 [00:08<00:01, 433.12it/s]
Adding requests:  90%| | 3692/4096 [00:08<00:00, 424.54it/s]
Adding requests:  91%| | 3735/4096 [00:09<00:00, 416.71it/s]
Adding requests:  92%|| 3777/4096 [00:09<00:00, 394.43it/s]
Adding requests:  93%|| 3817/4096 [00:09<00:00, 359.77it/s]
Adding requests:  94%|| 3855/4096 [00:09<00:00, 364.86it/s]
Adding requests:  95%|| 3896/4096 [00:09<00:00, 375.56it/s]
Adding requests:  96%|| 3936/4096 [00:09<00:00, 380.75it/s]
Adding requests:  97%|| 3977/4096 [00:09<00:00, 387.53it/s]
Adding requests:  98%|| 4017/4096 [00:09<00:00, 382.69it/s]
Adding requests:  99%|| 4056/4096 [00:09<00:00, 379.78it/s]
Adding requests: 100%|| 4096/4096 [00:10<00:00, 406.85it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 66/4096 [00:03<03:20, 20.06it/s, est. speed input: 20543.23 toks/s, output: 20.06 toks/s]
Processed prompts:   2%|         | 98/4096 [00:07<05:39, 11.79it/s, est. speed input: 13165.79 toks/s, output: 12.86 toks/s]
Processed prompts:   3%|         | 130/4096 [00:11<06:50,  9.66it/s, est. speed input: 11136.14 toks/s, output: 10.88 toks/s]
Processed prompts:   4%|         | 162/4096 [00:16<07:30,  8.74it/s, est. speed input: 10188.58 toks/s, output: 9.95 toks/s] 
Processed prompts:   5%|         | 194/4096 [00:20<07:48,  8.33it/s, est. speed input: 9693.64 toks/s, output: 9.47 toks/s] 
Processed prompts:   6%|         | 226/4096 [00:24<08:04,  7.99it/s, est. speed input: 9317.62 toks/s, output: 9.10 toks/s]
Processed prompts:   6%|         | 258/4096 [00:29<08:12,  7.79it/s, est. speed input: 9055.54 toks/s, output: 8.84 toks/s]
Processed prompts:   7%|         | 290/4096 [00:33<08:11,  7.74it/s, est. speed input: 8898.18 toks/s, output: 8.69 toks/s]
Processed prompts:   8%|         | 322/4096 [00:37<08:15,  7.62it/s, est. speed input: 8743.46 toks/s, output: 8.54 toks/s]
Processed prompts:   9%|         | 354/4096 [00:42<08:15,  7.55it/s, est. speed input: 8620.56 toks/s, output: 8.42 toks/s]
Processed prompts:   9%|         | 386/4096 [00:46<08:15,  7.49it/s, est. speed input: 8519.70 toks/s, output: 8.32 toks/s]
Processed prompts:  10%|         | 418/4096 [00:50<08:08,  7.53it/s, est. speed input: 8460.70 toks/s, output: 8.26 toks/s]
Processed prompts:  11%|         | 450/4096 [00:54<08:07,  7.48it/s, est. speed input: 8388.74 toks/s, output: 8.19 toks/s]
Processed prompts:  12%|        | 482/4096 [00:59<08:05,  7.45it/s, est. speed input: 8326.92 toks/s, output: 8.13 toks/s]
Processed prompts:  13%|        | 514/4096 [01:03<08:02,  7.42it/s, est. speed input: 8273.87 toks/s, output: 8.08 toks/s]
Processed prompts:  13%|        | 546/4096 [01:07<07:59,  7.41it/s, est. speed input: 8227.40 toks/s, output: 8.03 toks/s]
Processed prompts:  14%|        | 578/4096 [01:12<07:55,  7.40it/s, est. speed input: 8186.57 toks/s, output: 7.99 toks/s]
Processed prompts:  15%|        | 610/4096 [01:16<07:51,  7.39it/s, est. speed input: 8150.57 toks/s, output: 7.96 toks/s]
Processed prompts:  16%|        | 642/4096 [01:20<07:47,  7.39it/s, est. speed input: 8119.20 toks/s, output: 7.93 toks/s]
Processed prompts:  16%|        | 674/4096 [01:25<07:43,  7.39it/s, est. speed input: 8090.73 toks/s, output: 7.90 toks/s]
Processed prompts:  17%|        | 706/4096 [01:29<07:39,  7.38it/s, est. speed input: 8063.99 toks/s, output: 7.87 toks/s]
Processed prompts:  18%|        | 738/4096 [01:33<07:35,  7.38it/s, est. speed input: 8040.18 toks/s, output: 7.85 toks/s]
Processed prompts:  19%|        | 770/4096 [01:38<07:26,  7.45it/s, est. speed input: 8030.05 toks/s, output: 7.84 toks/s]
Processed prompts:  20%|        | 802/4096 [01:42<07:23,  7.42it/s, est. speed input: 8009.41 toks/s, output: 7.82 toks/s]
Processed prompts:  20%|        | 834/4096 [01:46<07:20,  7.41it/s, est. speed input: 7990.87 toks/s, output: 7.80 toks/s]
Processed prompts:  21%|        | 866/4096 [01:51<07:16,  7.40it/s, est. speed input: 7973.54 toks/s, output: 7.79 toks/s]
Processed prompts:  22%|       | 898/4096 [01:55<07:12,  7.39it/s, est. speed input: 7957.86 toks/s, output: 7.77 toks/s]
Processed prompts:  23%|       | 930/4096 [01:59<07:08,  7.39it/s, est. speed input: 7943.13 toks/s, output: 7.76 toks/s]
Processed prompts:  23%|       | 962/4096 [02:04<07:04,  7.38it/s, est. speed input: 7929.12 toks/s, output: 7.74 toks/s]
Processed prompts:  24%|       | 994/4096 [02:08<07:00,  7.38it/s, est. speed input: 7916.58 toks/s, output: 7.73 toks/s]
Processed prompts:  25%|       | 1026/4096 [02:12<06:55,  7.38it/s, est. speed input: 7904.81 toks/s, output: 7.72 toks/s]
Processed prompts:  26%|       | 1058/4096 [02:17<06:51,  7.38it/s, est. speed input: 7893.46 toks/s, output: 7.71 toks/s]
Processed prompts:  27%|       | 1090/4096 [02:21<06:47,  7.37it/s, est. speed input: 7882.79 toks/s, output: 7.70 toks/s]
Processed prompts:  27%|       | 1122/4096 [02:25<06:43,  7.37it/s, est. speed input: 7872.73 toks/s, output: 7.69 toks/s]
Processed prompts:  28%|       | 1154/4096 [02:30<06:39,  7.37it/s, est. speed input: 7863.31 toks/s, output: 7.68 toks/s]
Processed prompts:  29%|       | 1186/4096 [02:34<06:31,  7.44it/s, est. speed input: 7861.48 toks/s, output: 7.68 toks/s]
Processed prompts:  30%|       | 1218/4096 [02:38<06:24,  7.49it/s, est. speed input: 7859.84 toks/s, output: 7.68 toks/s]
Processed prompts:  31%|       | 1250/4096 [02:43<06:21,  7.46it/s, est. speed input: 7851.51 toks/s, output: 7.67 toks/s]
Processed prompts:  31%|      | 1282/4096 [02:47<06:18,  7.43it/s, est. speed input: 7843.73 toks/s, output: 7.66 toks/s]
Processed prompts:  32%|      | 1314/4096 [02:51<06:11,  7.49it/s, est. speed input: 7842.71 toks/s, output: 7.66 toks/s]
Processed prompts:  33%|      | 1346/4096 [02:55<06:09,  7.45it/s, est. speed input: 7835.28 toks/s, output: 7.65 toks/s]
Processed prompts:  34%|      | 1378/4096 [03:00<06:06,  7.42it/s, est. speed input: 7828.06 toks/s, output: 7.64 toks/s]
Processed prompts:  34%|      | 1410/4096 [03:04<06:02,  7.41it/s, est. speed input: 7821.61 toks/s, output: 7.64 toks/s]
Processed prompts:  35%|      | 1442/4096 [03:08<05:53,  7.51it/s, est. speed input: 7824.63 toks/s, output: 7.64 toks/s]
Processed prompts:  36%|      | 1474/4096 [03:13<05:51,  7.47it/s, est. speed input: 7818.33 toks/s, output: 7.64 toks/s]
Processed prompts:  37%|      | 1506/4096 [03:17<05:44,  7.51it/s, est. speed input: 7817.96 toks/s, output: 7.63 toks/s]
Processed prompts:  38%|      | 1538/4096 [03:21<05:39,  7.54it/s, est. speed input: 7817.21 toks/s, output: 7.63 toks/s]
Processed prompts:  38%|      | 1570/4096 [03:25<05:37,  7.49it/s, est. speed input: 7811.51 toks/s, output: 7.63 toks/s]
Processed prompts:  39%|      | 1602/4096 [03:30<05:31,  7.52it/s, est. speed input: 7811.20 toks/s, output: 7.63 toks/s]
Processed prompts:  40%|      | 1634/4096 [03:34<05:29,  7.48it/s, est. speed input: 7805.78 toks/s, output: 7.62 toks/s]
Processed prompts:  41%|      | 1666/4096 [03:38<05:26,  7.44it/s, est. speed input: 7800.59 toks/s, output: 7.62 toks/s]
Processed prompts:  41%|     | 1698/4096 [03:43<05:23,  7.42it/s, est. speed input: 7795.56 toks/s, output: 7.61 toks/s]
Processed prompts:  42%|     | 1730/4096 [03:46<05:10,  7.62it/s, est. speed input: 7804.65 toks/s, output: 7.62 toks/s]
Processed prompts:  43%|     | 1762/4096 [03:51<05:09,  7.54it/s, est. speed input: 7799.90 toks/s, output: 7.62 toks/s]
Processed prompts:  44%|     | 1794/4096 [03:55<05:07,  7.49it/s, est. speed input: 7795.36 toks/s, output: 7.61 toks/s]
Processed prompts:  45%|     | 1826/4096 [03:59<05:04,  7.46it/s, est. speed input: 7790.99 toks/s, output: 7.61 toks/s]
Processed prompts:  45%|     | 1858/4096 [04:04<05:01,  7.43it/s, est. speed input: 7786.63 toks/s, output: 7.60 toks/s]
Processed prompts:  46%|     | 1890/4096 [04:08<04:54,  7.48it/s, est. speed input: 7786.66 toks/s, output: 7.60 toks/s]
Processed prompts:  47%|     | 1922/4096 [04:12<04:51,  7.45it/s, est. speed input: 7782.68 toks/s, output: 7.60 toks/s]
Processed prompts:  48%|     | 1954/4096 [04:17<04:48,  7.43it/s, est. speed input: 7778.69 toks/s, output: 7.60 toks/s]
Processed prompts:  48%|     | 1986/4096 [04:21<04:42,  7.48it/s, est. speed input: 7778.99 toks/s, output: 7.60 toks/s]
Processed prompts:  49%|     | 2018/4096 [04:25<04:39,  7.45it/s, est. speed input: 7775.05 toks/s, output: 7.59 toks/s]
Processed prompts:  50%|     | 2050/4096 [04:29<04:31,  7.54it/s, est. speed input: 7778.06 toks/s, output: 7.60 toks/s]
Processed prompts:  51%|     | 2082/4096 [04:34<04:28,  7.49it/s, est. speed input: 7774.35 toks/s, output: 7.59 toks/s]
Processed prompts:  52%|    | 2114/4096 [04:38<04:25,  7.46it/s, est. speed input: 7770.96 toks/s, output: 7.59 toks/s]
Processed prompts:  52%|    | 2146/4096 [04:42<04:22,  7.43it/s, est. speed input: 7767.42 toks/s, output: 7.59 toks/s]
Processed prompts:  53%|    | 2178/4096 [04:47<04:16,  7.48it/s, est. speed input: 7767.65 toks/s, output: 7.59 toks/s]
Processed prompts:  54%|    | 2210/4096 [04:51<04:13,  7.45it/s, est. speed input: 7764.47 toks/s, output: 7.58 toks/s]
Processed prompts:  55%|    | 2242/4096 [04:55<04:09,  7.43it/s, est. speed input: 7761.39 toks/s, output: 7.58 toks/s]
Processed prompts:  56%|    | 2274/4096 [05:00<04:05,  7.41it/s, est. speed input: 7758.36 toks/s, output: 7.58 toks/s]
Processed prompts:  56%|    | 2306/4096 [05:04<04:01,  7.40it/s, est. speed input: 7755.27 toks/s, output: 7.57 toks/s]
Processed prompts:  57%|    | 2338/4096 [05:08<03:55,  7.46it/s, est. speed input: 7755.63 toks/s, output: 7.57 toks/s]
Processed prompts:  58%|    | 2370/4096 [05:13<03:52,  7.43it/s, est. speed input: 7752.69 toks/s, output: 7.57 toks/s]
Processed prompts:  59%|    | 2402/4096 [05:17<03:48,  7.41it/s, est. speed input: 7749.78 toks/s, output: 7.57 toks/s]
Processed prompts:  59%|    | 2434/4096 [05:21<03:44,  7.40it/s, est. speed input: 7746.96 toks/s, output: 7.57 toks/s]
Processed prompts:  60%|    | 2466/4096 [05:26<03:40,  7.39it/s, est. speed input: 7744.29 toks/s, output: 7.56 toks/s]
Processed prompts:  61%|    | 2498/4096 [05:30<03:36,  7.38it/s, est. speed input: 7741.60 toks/s, output: 7.56 toks/s]
Processed prompts:  62%|   | 2530/4096 [05:34<03:30,  7.45it/s, est. speed input: 7742.24 toks/s, output: 7.56 toks/s]
Processed prompts:  63%|   | 2562/4096 [05:38<03:26,  7.42it/s, est. speed input: 7739.76 toks/s, output: 7.56 toks/s]
Processed prompts:  63%|   | 2594/4096 [05:43<03:20,  7.48it/s, est. speed input: 7740.27 toks/s, output: 7.56 toks/s]
Processed prompts:  64%|   | 2626/4096 [05:47<03:17,  7.45it/s, est. speed input: 7737.93 toks/s, output: 7.56 toks/s]
Processed prompts:  65%|   | 2658/4096 [05:51<03:11,  7.49it/s, est. speed input: 7738.56 toks/s, output: 7.56 toks/s]
Processed prompts:  66%|   | 2690/4096 [05:56<03:08,  7.46it/s, est. speed input: 7736.20 toks/s, output: 7.55 toks/s]
Processed prompts:  66%|   | 2722/4096 [06:00<03:03,  7.50it/s, est. speed input: 7736.91 toks/s, output: 7.56 toks/s]
Processed prompts:  67%|   | 2754/4096 [06:04<02:59,  7.46it/s, est. speed input: 7734.62 toks/s, output: 7.55 toks/s]
Processed prompts:  68%|   | 2786/4096 [06:08<02:56,  7.43it/s, est. speed input: 7732.45 toks/s, output: 7.55 toks/s]
Processed prompts:  69%|   | 2818/4096 [06:13<02:52,  7.42it/s, est. speed input: 7730.37 toks/s, output: 7.55 toks/s]
Processed prompts:  70%|   | 2850/4096 [06:17<02:48,  7.40it/s, est. speed input: 7728.21 toks/s, output: 7.55 toks/s]
Processed prompts:  70%|   | 2882/4096 [06:21<02:39,  7.61it/s, est. speed input: 7734.45 toks/s, output: 7.55 toks/s]
Processed prompts:  71%|   | 2914/4096 [06:25<02:35,  7.61it/s, est. speed input: 7735.01 toks/s, output: 7.55 toks/s]
Processed prompts:  72%|  | 2946/4096 [06:30<02:32,  7.54it/s, est. speed input: 7732.96 toks/s, output: 7.55 toks/s]
Processed prompts:  73%|  | 2978/4096 [06:34<02:27,  7.55it/s, est. speed input: 7733.50 toks/s, output: 7.55 toks/s]
Processed prompts:  73%|  | 3010/4096 [06:38<02:24,  7.50it/s, est. speed input: 7731.36 toks/s, output: 7.55 toks/s]
Processed prompts:  74%|  | 3042/4096 [06:43<02:21,  7.46it/s, est. speed input: 7729.37 toks/s, output: 7.55 toks/s]
Processed prompts:  75%|  | 3074/4096 [06:47<02:17,  7.43it/s, est. speed input: 7727.51 toks/s, output: 7.55 toks/s]
Processed prompts:  76%|  | 3106/4096 [06:51<02:13,  7.41it/s, est. speed input: 7725.54 toks/s, output: 7.54 toks/s]
Processed prompts:  77%|  | 3138/4096 [06:56<02:09,  7.40it/s, est. speed input: 7723.58 toks/s, output: 7.54 toks/s]
Processed prompts:  77%|  | 3170/4096 [07:00<02:04,  7.46it/s, est. speed input: 7724.16 toks/s, output: 7.54 toks/s]
Processed prompts:  78%|  | 3202/4096 [07:04<02:00,  7.43it/s, est. speed input: 7722.34 toks/s, output: 7.54 toks/s]
Processed prompts:  79%|  | 3234/4096 [07:08<01:56,  7.41it/s, est. speed input: 7720.57 toks/s, output: 7.54 toks/s]
Processed prompts:  80%|  | 3266/4096 [07:13<01:52,  7.40it/s, est. speed input: 7718.73 toks/s, output: 7.54 toks/s]
Processed prompts:  81%|  | 3298/4096 [07:17<01:47,  7.39it/s, est. speed input: 7717.10 toks/s, output: 7.54 toks/s]
Processed prompts:  81%| | 3330/4096 [07:21<01:43,  7.39it/s, est. speed input: 7715.46 toks/s, output: 7.53 toks/s]
Processed prompts:  82%| | 3362/4096 [07:26<01:39,  7.38it/s, est. speed input: 7713.84 toks/s, output: 7.53 toks/s]
Processed prompts:  83%| | 3394/4096 [07:30<01:34,  7.45it/s, est. speed input: 7714.54 toks/s, output: 7.53 toks/s]
Processed prompts:  84%| | 3426/4096 [07:34<01:30,  7.42it/s, est. speed input: 7712.90 toks/s, output: 7.53 toks/s]
Processed prompts:  84%| | 3458/4096 [07:39<01:26,  7.41it/s, est. speed input: 7711.27 toks/s, output: 7.53 toks/s]
Processed prompts:  85%| | 3490/4096 [07:43<01:21,  7.39it/s, est. speed input: 7709.71 toks/s, output: 7.53 toks/s]
Processed prompts:  86%| | 3522/4096 [07:47<01:17,  7.39it/s, est. speed input: 7708.17 toks/s, output: 7.53 toks/s]
Processed prompts:  87%| | 3554/4096 [07:52<01:12,  7.45it/s, est. speed input: 7708.97 toks/s, output: 7.53 toks/s]
Processed prompts:  88%| | 3586/4096 [07:56<01:08,  7.43it/s, est. speed input: 7707.43 toks/s, output: 7.53 toks/s]
Processed prompts:  88%| | 3618/4096 [08:00<01:03,  7.48it/s, est. speed input: 7708.10 toks/s, output: 7.53 toks/s]
Processed prompts:  89%| | 3650/4096 [08:04<00:59,  7.45it/s, est. speed input: 7706.67 toks/s, output: 7.53 toks/s]
Processed prompts:  90%| | 3682/4096 [08:09<00:54,  7.54it/s, est. speed input: 7708.81 toks/s, output: 7.53 toks/s]
Processed prompts:  91%| | 3714/4096 [08:13<00:51,  7.49it/s, est. speed input: 7707.39 toks/s, output: 7.53 toks/s]
Processed prompts:  91%|| 3746/4096 [08:17<00:46,  7.45it/s, est. speed input: 7705.91 toks/s, output: 7.53 toks/s]
Processed prompts:  92%|| 3778/4096 [08:22<00:42,  7.42it/s, est. speed input: 7704.45 toks/s, output: 7.52 toks/s]
Processed prompts:  93%|| 3810/4096 [08:26<00:38,  7.41it/s, est. speed input: 7703.08 toks/s, output: 7.52 toks/s]
Processed prompts:  94%|| 3842/4096 [08:30<00:34,  7.39it/s, est. speed input: 7701.70 toks/s, output: 7.52 toks/s]
Processed prompts:  95%|| 3874/4096 [08:35<00:30,  7.39it/s, est. speed input: 7700.37 toks/s, output: 7.52 toks/s]
Processed prompts:  95%|| 3906/4096 [08:39<00:25,  7.45it/s, est. speed input: 7701.10 toks/s, output: 7.52 toks/s]
Processed prompts:  96%|| 3938/4096 [08:43<00:21,  7.50it/s, est. speed input: 7701.76 toks/s, output: 7.52 toks/s]
Processed prompts:  97%|| 3970/4096 [08:47<00:16,  7.46it/s, est. speed input: 7700.46 toks/s, output: 7.52 toks/s]
Processed prompts:  98%|| 4002/4096 [08:52<00:12,  7.50it/s, est. speed input: 7701.26 toks/s, output: 7.52 toks/s]
Processed prompts:  98%|| 4034/4096 [08:56<00:08,  7.53it/s, est. speed input: 7701.86 toks/s, output: 7.52 toks/s]
Processed prompts:  99%|| 4066/4096 [09:00<00:03,  7.60it/s, est. speed input: 7703.67 toks/s, output: 7.52 toks/s]
Processed prompts: 100%|| 4096/4096 [09:00<00:00,  7.60it/s, est. speed input: 7760.51 toks/s, output: 7.58 toks/s]
Processed prompts: 100%|| 4096/4096 [09:00<00:00,  7.58it/s, est. speed input: 7760.51 toks/s, output: 7.58 toks/s]
[rank0]:[W126 18:40:54.943358900 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-26 18:40:57
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Qwen2.5-7B-FP8_M65536.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 18:41:29 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 18:41:29 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1610544) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 303, in forward
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]     hidden_states = self.mlp(hidden_states)
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 108, in forward
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]     x, _ = self.down_proj(x)
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]            ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 1405, in forward
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]     output_parallel = self.quant_method.apply(self, input_parallel, bias_)
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 243, in quant_slide_fp8_triton
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]     out = torch.zeros(M_padded, K_out_padded, dtype=torch.float8_e4m3fn, device=x.device)
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866]           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866] torch.AcceleratorError: CUDA error: an illegal memory access was encountered
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866] Search for `cudaErrorIllegalAddress' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866] CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866] For debugging consider passing CUDA_LAUNCH_BLOCKING=1
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866] Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
(EngineCore_DP0 pid=1610544) ERROR 01-26 18:42:19 [core.py:866] 

STDERR:
[2026-01-26 18:41:29] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 18:41:29] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 18:41:29] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 18:41:29] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:41:29] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:41:29] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:41:29] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:41:29] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:41:29] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 18:41:29] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 18:41:29] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 18:41:29] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 18:41:29] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 18:41:29] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 18:41:32] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 18:41:32] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 18:41:32] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 18:41:32] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:41:32] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:41:32] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:41:32] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:41:32] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:41:32] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 18:41:32] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 18:41:32] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 18:41:32] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 18:41:32] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 18:41:32] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1610544) [2026-01-26 18:41:34] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1610544) [2026-01-26 18:41:34] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1610544) [2026-01-26 18:41:34] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1610544) [2026-01-26 18:41:34] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=1610544) [2026-01-26 18:41:34] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1610544) [2026-01-26 18:41:34] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1610544) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1610544) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:21<00:21, 21.31s/it]
(EngineCore_DP0 pid=1610544) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:42<00:00, 21.29s/it]
(EngineCore_DP0 pid=1610544) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:42<00:00, 21.29s/it]
(EngineCore_DP0 pid=1610544) 
(EngineCore_DP0 pid=1610544) [2026-01-26 18:42:17] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=1610544) [2026-01-26 18:42:17] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10321920 bytes
(EngineCore_DP0 pid=1610544) [2026-01-26 18:42:17] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=1610544) [2026-01-26 18:42:17] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8028160 bytes
(EngineCore_DP0 pid=1610544) [2026-01-26 18:42:17] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=1610544) [2026-01-26 18:42:17] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 84869120 bytes
(EngineCore_DP0 pid=1610544) [2026-01-26 18:42:17] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=1610544) [2026-01-26 18:42:17] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 42434560 bytes
(EngineCore_DP0 pid=1610544) Process EngineCore_DP0:
(EngineCore_DP0 pid=1610544) Traceback (most recent call last):
(EngineCore_DP0 pid=1610544)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=1610544)     self.run()
(EngineCore_DP0 pid=1610544)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=1610544)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=1610544)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=1610544)     raise e
(EngineCore_DP0 pid=1610544)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1610544)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1610544)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1610544)     super().__init__(
(EngineCore_DP0 pid=1610544)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=1610544)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=1610544)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=1610544)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=1610544)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=1610544)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=1610544)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=1610544)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=1610544)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=1610544)     return func(*args, **kwargs)
(EngineCore_DP0 pid=1610544)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=1610544)     return func(*args, **kwargs)
(EngineCore_DP0 pid=1610544)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=1610544)     self.model_runner.profile_run()
(EngineCore_DP0 pid=1610544)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=1610544)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=1610544)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=1610544)     return func(*args, **kwargs)
(EngineCore_DP0 pid=1610544)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=1610544)     outputs = self.model(
(EngineCore_DP0 pid=1610544)               ^^^^^^^^^^^
(EngineCore_DP0 pid=1610544)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1610544)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1610544)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1610544)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1610544)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=1610544)     hidden_states = self.model(
(EngineCore_DP0 pid=1610544)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=1610544)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=1610544)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=1610544)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=1610544)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=1610544)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1610544)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1610544)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1610544)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1610544)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 303, in forward
(EngineCore_DP0 pid=1610544)     hidden_states = self.mlp(hidden_states)
(EngineCore_DP0 pid=1610544)                     ^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1610544)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1610544)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1610544)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1610544)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 108, in forward
(EngineCore_DP0 pid=1610544)     x, _ = self.down_proj(x)
(EngineCore_DP0 pid=1610544)            ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1610544)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1610544)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1610544)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1610544)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 1405, in forward
(EngineCore_DP0 pid=1610544)     output_parallel = self.quant_method.apply(self, input_parallel, bias_)
(EngineCore_DP0 pid=1610544)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=1610544)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=1610544)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=1610544)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=1610544)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=1610544)     return self._linear_fn(
(EngineCore_DP0 pid=1610544)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=1610544)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=1610544)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=1610544)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=1610544)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=1610544)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=1610544)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=1610544)     return fn(input, L)
(EngineCore_DP0 pid=1610544)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 243, in quant_slide_fp8_triton
(EngineCore_DP0 pid=1610544)     out = torch.zeros(M_padded, K_out_padded, dtype=torch.float8_e4m3fn, device=x.device)
(EngineCore_DP0 pid=1610544)           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1610544) torch.AcceleratorError: CUDA error: an illegal memory access was encountered
(EngineCore_DP0 pid=1610544) Search for `cudaErrorIllegalAddress' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
(EngineCore_DP0 pid=1610544) CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
(EngineCore_DP0 pid=1610544) For debugging consider passing CUDA_LAUNCH_BLOCKING=1
(EngineCore_DP0 pid=1610544) Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
(EngineCore_DP0 pid=1610544) 
[rank0]:[W126 18:42:19.097930897 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=65536

========== M=512 ==========
Time: 2026-01-27 08:03:30
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_4
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_4 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Qwen2.5-14B-FP8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-27 08:03:36 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-27 08:03:36 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=2289554) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2289554) WARNING 01-27 08:05:13 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 8.00 requests/s, 4104.51 total tokens/s, 8.00 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-27 08:03:36] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 08:03:36] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 08:03:36] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 08:03:36] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:03:36] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:03:36] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:03:36] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:03:36] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:03:36] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 08:03:36] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 08:03:36] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 08:03:36] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 08:03:36] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 08:03:36] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-27 08:03:40] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 08:03:40] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 08:03:40] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 08:03:40] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:03:40] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:03:40] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:03:40] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:03:40] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:03:40] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 08:03:40] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 08:03:40] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 08:03:40] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 08:03:40] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 08:03:40] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=2289554) [2026-01-27 08:03:41] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=2289554) [2026-01-27 08:03:41] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2289554) [2026-01-27 08:03:41] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=2289554) [2026-01-27 08:03:41] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=2289554) [2026-01-27 08:03:41] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=2289554) [2026-01-27 08:03:41] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=2289554) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=2289554) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:25,  8.66s/it]
(EngineCore_DP0 pid=2289554) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:34<00:37, 18.66s/it]
(EngineCore_DP0 pid=2289554) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:55<00:19, 19.87s/it]
(EngineCore_DP0 pid=2289554) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:22<00:00, 22.67s/it]
(EngineCore_DP0 pid=2289554) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:22<00:00, 20.65s/it]
(EngineCore_DP0 pid=2289554) 
(EngineCore_DP0 pid=2289554) [2026-01-27 08:05:05] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 5120] -> 1D uint8
(EngineCore_DP0 pid=2289554) [2026-01-27 08:05:05] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 22937600 bytes
(EngineCore_DP0 pid=2289554) [2026-01-27 08:05:05] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 5120] -> 1D uint8
(EngineCore_DP0 pid=2289554) [2026-01-27 08:05:05] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16384000 bytes
(EngineCore_DP0 pid=2289554) [2026-01-27 08:05:05] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 5120] -> 1D uint8
(EngineCore_DP0 pid=2289554) [2026-01-27 08:05:05] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 88473600 bytes
(EngineCore_DP0 pid=2289554) [2026-01-27 08:05:05] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 13824] -> 1D uint8
(EngineCore_DP0 pid=2289554) [2026-01-27 08:05:05] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 44236800 bytes
(EngineCore_DP0 pid=2289554) 2026-01-27 08:05:12,964 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=2289554) 2026-01-27 08:05:13,020 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:   1%|          | 1/128 [00:00<01:04,  1.96it/s]
Adding requests:   2%|         | 2/128 [00:00<00:37,  3.40it/s]
Adding requests:   3%|         | 4/128 [00:00<00:19,  6.33it/s]
Adding requests:   5%|         | 6/128 [00:00<00:13,  9.20it/s]
Adding requests:   7%|         | 9/128 [00:01<00:09, 12.97it/s]
Adding requests:  10%|         | 13/128 [00:01<00:06, 18.55it/s]
Adding requests:  14%|        | 18/128 [00:01<00:04, 25.91it/s]
Adding requests:  20%|        | 25/128 [00:01<00:02, 36.13it/s]
Adding requests:  27%|       | 35/128 [00:01<00:01, 52.24it/s]
Adding requests:  47%|     | 60/128 [00:01<00:00, 104.76it/s]
Adding requests:  72%|  | 92/128 [00:01<00:00, 163.59it/s]
Adding requests: 100%|| 128/128 [00:01<00:00, 71.40it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   8%|         | 10/128 [00:00<00:01, 70.06it/s, est. speed input: 35875.94 toks/s, output: 70.06 toks/s]
Processed prompts:  14%|        | 18/128 [00:01<00:07, 14.39it/s, est. speed input: 8492.59 toks/s, output: 16.59 toks/s] 
Processed prompts:  17%|        | 22/128 [00:01<00:08, 12.04it/s, est. speed input: 7220.38 toks/s, output: 14.10 toks/s]
Processed prompts:  20%|        | 25/128 [00:01<00:09, 10.96it/s, est. speed input: 6679.72 toks/s, output: 13.05 toks/s]
Processed prompts:  21%|        | 27/128 [00:02<00:09, 10.43it/s, est. speed input: 6425.64 toks/s, output: 12.55 toks/s]
Processed prompts:  23%|       | 29/128 [00:02<00:09,  9.96it/s, est. speed input: 6218.55 toks/s, output: 12.15 toks/s]
Processed prompts:  24%|       | 31/128 [00:02<00:10,  9.57it/s, est. speed input: 6046.76 toks/s, output: 11.81 toks/s]
Processed prompts:  26%|       | 33/128 [00:02<00:10,  9.28it/s, est. speed input: 5906.67 toks/s, output: 11.54 toks/s]
Processed prompts:  27%|       | 35/128 [00:03<00:10,  9.06it/s, est. speed input: 5787.79 toks/s, output: 11.30 toks/s]
Processed prompts:  28%|       | 36/128 [00:03<00:10,  8.97it/s, est. speed input: 5735.42 toks/s, output: 11.20 toks/s]
Processed prompts:  29%|       | 37/128 [00:03<00:10,  8.89it/s, est. speed input: 5687.01 toks/s, output: 11.11 toks/s]
Processed prompts:  30%|       | 38/128 [00:03<00:10,  8.83it/s, est. speed input: 5644.35 toks/s, output: 11.02 toks/s]
Processed prompts:  30%|       | 39/128 [00:03<00:10,  8.76it/s, est. speed input: 5602.40 toks/s, output: 10.94 toks/s]
Processed prompts:  31%|      | 40/128 [00:03<00:10,  8.62it/s, est. speed input: 5556.30 toks/s, output: 10.85 toks/s]
Processed prompts:  32%|      | 41/128 [00:03<00:10,  8.55it/s, est. speed input: 5515.80 toks/s, output: 10.77 toks/s]
Processed prompts:  33%|      | 42/128 [00:03<00:10,  8.55it/s, est. speed input: 5481.75 toks/s, output: 10.71 toks/s]
Processed prompts:  34%|      | 43/128 [00:04<00:09,  8.56it/s, est. speed input: 5450.97 toks/s, output: 10.65 toks/s]
Processed prompts:  34%|      | 44/128 [00:04<00:09,  8.54it/s, est. speed input: 5419.62 toks/s, output: 10.59 toks/s]
Processed prompts:  35%|      | 45/128 [00:04<00:09,  8.52it/s, est. speed input: 5389.57 toks/s, output: 10.53 toks/s]
Processed prompts:  36%|      | 46/128 [00:04<00:09,  8.50it/s, est. speed input: 5361.06 toks/s, output: 10.47 toks/s]
Processed prompts:  37%|      | 47/128 [00:04<00:09,  8.50it/s, est. speed input: 5334.46 toks/s, output: 10.42 toks/s]
Processed prompts:  38%|      | 48/128 [00:04<00:09,  8.49it/s, est. speed input: 5309.22 toks/s, output: 10.37 toks/s]
Processed prompts:  38%|      | 49/128 [00:04<00:09,  8.40it/s, est. speed input: 5280.41 toks/s, output: 10.31 toks/s]
Processed prompts:  39%|      | 50/128 [00:04<00:09,  8.39it/s, est. speed input: 5256.25 toks/s, output: 10.27 toks/s]
Processed prompts:  40%|      | 51/128 [00:04<00:09,  8.41it/s, est. speed input: 5234.29 toks/s, output: 10.22 toks/s]
Processed prompts:  41%|      | 52/128 [00:05<00:09,  8.44it/s, est. speed input: 5214.20 toks/s, output: 10.18 toks/s]
Processed prompts:  41%|     | 53/128 [00:05<00:08,  8.46it/s, est. speed input: 5194.67 toks/s, output: 10.15 toks/s]
Processed prompts:  42%|     | 54/128 [00:05<00:08,  8.44it/s, est. speed input: 5174.66 toks/s, output: 10.11 toks/s]
Processed prompts:  43%|     | 55/128 [00:05<00:08,  8.46it/s, est. speed input: 5157.13 toks/s, output: 10.07 toks/s]
Processed prompts:  44%|     | 56/128 [00:05<00:08,  8.48it/s, est. speed input: 5140.47 toks/s, output: 10.04 toks/s]
Processed prompts:  45%|     | 57/128 [00:05<00:08,  8.53it/s, est. speed input: 5126.00 toks/s, output: 10.01 toks/s]
Processed prompts:  45%|     | 58/128 [00:05<00:08,  8.35it/s, est. speed input: 5103.50 toks/s, output: 9.97 toks/s] 
Processed prompts:  46%|     | 59/128 [00:05<00:08,  8.41it/s, est. speed input: 5088.97 toks/s, output: 9.94 toks/s]
Processed prompts:  47%|     | 60/128 [00:06<00:08,  8.42it/s, est. speed input: 5073.87 toks/s, output: 9.91 toks/s]
Processed prompts:  48%|     | 61/128 [00:06<00:07,  8.46it/s, est. speed input: 5060.85 toks/s, output: 9.88 toks/s]
Processed prompts:  48%|     | 62/128 [00:06<00:07,  8.46it/s, est. speed input: 5047.09 toks/s, output: 9.86 toks/s]
Processed prompts:  49%|     | 63/128 [00:06<00:07,  8.46it/s, est. speed input: 5033.88 toks/s, output: 9.83 toks/s]
Processed prompts:  50%|     | 64/128 [00:06<00:07,  8.47it/s, est. speed input: 5021.65 toks/s, output: 9.81 toks/s]
Processed prompts:  51%|     | 65/128 [00:06<00:07,  8.46it/s, est. speed input: 5008.90 toks/s, output: 9.78 toks/s]
Processed prompts:  52%|    | 66/128 [00:06<00:07,  8.41it/s, est. speed input: 4995.45 toks/s, output: 9.76 toks/s]
Processed prompts:  52%|    | 67/128 [00:06<00:07,  8.29it/s, est. speed input: 4979.28 toks/s, output: 9.73 toks/s]
Processed prompts:  53%|    | 68/128 [00:07<00:07,  8.39it/s, est. speed input: 4970.24 toks/s, output: 9.71 toks/s]
Processed prompts:  54%|    | 69/128 [00:07<00:07,  8.39it/s, est. speed input: 4958.84 toks/s, output: 9.69 toks/s]
Processed prompts:  55%|    | 70/128 [00:07<00:06,  8.47it/s, est. speed input: 4950.64 toks/s, output: 9.67 toks/s]
Processed prompts:  55%|    | 71/128 [00:07<00:06,  8.50it/s, est. speed input: 4941.76 toks/s, output: 9.65 toks/s]
Processed prompts:  56%|    | 72/128 [00:07<00:06,  8.52it/s, est. speed input: 4932.96 toks/s, output: 9.63 toks/s]
Processed prompts:  57%|    | 73/128 [00:07<00:06,  8.53it/s, est. speed input: 4924.50 toks/s, output: 9.62 toks/s]
Processed prompts:  58%|    | 74/128 [00:07<00:06,  8.54it/s, est. speed input: 4916.20 toks/s, output: 9.60 toks/s]
Processed prompts:  59%|    | 75/128 [00:07<00:06,  8.51it/s, est. speed input: 4907.15 toks/s, output: 9.58 toks/s]
Processed prompts:  59%|    | 76/128 [00:07<00:06,  8.34it/s, est. speed input: 4894.16 toks/s, output: 9.56 toks/s]
Processed prompts:  60%|    | 77/128 [00:08<00:06,  8.38it/s, est. speed input: 4886.15 toks/s, output: 9.54 toks/s]
Processed prompts:  61%|    | 78/128 [00:08<00:05,  8.45it/s, est. speed input: 4879.34 toks/s, output: 9.53 toks/s]
Processed prompts:  62%|   | 79/128 [00:08<00:05,  8.44it/s, est. speed input: 4871.18 toks/s, output: 9.51 toks/s]
Processed prompts:  62%|   | 80/128 [00:08<00:05,  8.46it/s, est. speed input: 4863.87 toks/s, output: 9.50 toks/s]
Processed prompts:  63%|   | 81/128 [00:08<00:05,  8.47it/s, est. speed input: 4856.96 toks/s, output: 9.49 toks/s]
Processed prompts:  64%|   | 82/128 [00:08<00:05,  8.46it/s, est. speed input: 4849.47 toks/s, output: 9.47 toks/s]
Processed prompts:  65%|   | 83/128 [00:08<00:05,  8.45it/s, est. speed input: 4842.28 toks/s, output: 9.46 toks/s]
Processed prompts:  66%|   | 84/128 [00:08<00:05,  8.45it/s, est. speed input: 4835.45 toks/s, output: 9.44 toks/s]
Processed prompts:  66%|   | 85/128 [00:09<00:05,  8.31it/s, est. speed input: 4825.17 toks/s, output: 9.42 toks/s]
Processed prompts:  67%|   | 86/128 [00:09<00:05,  8.37it/s, est. speed input: 4819.22 toks/s, output: 9.41 toks/s]
Processed prompts:  68%|   | 87/128 [00:09<00:04,  8.42it/s, est. speed input: 4813.55 toks/s, output: 9.40 toks/s]
Processed prompts:  69%|   | 88/128 [00:09<00:04,  8.43it/s, est. speed input: 4807.34 toks/s, output: 9.39 toks/s]
Processed prompts:  70%|   | 89/128 [00:09<00:04,  8.44it/s, est. speed input: 4801.48 toks/s, output: 9.38 toks/s]
Processed prompts:  70%|   | 90/128 [00:09<00:04,  8.52it/s, est. speed input: 4797.49 toks/s, output: 9.37 toks/s]
Processed prompts:  71%|   | 91/128 [00:09<00:04,  8.48it/s, est. speed input: 4791.37 toks/s, output: 9.36 toks/s]
Processed prompts:  72%|  | 92/128 [00:09<00:04,  8.50it/s, est. speed input: 4786.44 toks/s, output: 9.35 toks/s]
Processed prompts:  73%|  | 93/128 [00:09<00:04,  8.47it/s, est. speed input: 4780.55 toks/s, output: 9.34 toks/s]
Processed prompts:  73%|  | 94/128 [00:10<00:04,  8.34it/s, est. speed input: 4772.49 toks/s, output: 9.32 toks/s]
Processed prompts:  74%|  | 95/128 [00:10<00:03,  8.40it/s, est. speed input: 4767.85 toks/s, output: 9.31 toks/s]
Processed prompts:  75%|  | 96/128 [00:10<00:03,  8.40it/s, est. speed input: 4762.45 toks/s, output: 9.30 toks/s]
Processed prompts:  76%|  | 97/128 [00:10<00:03,  8.46it/s, est. speed input: 4758.42 toks/s, output: 9.29 toks/s]
Processed prompts:  77%|  | 98/128 [00:10<00:03,  8.46it/s, est. speed input: 4753.61 toks/s, output: 9.28 toks/s]
Processed prompts:  77%|  | 99/128 [00:10<00:03,  8.49it/s, est. speed input: 4749.53 toks/s, output: 9.28 toks/s]
Processed prompts:  78%|  | 100/128 [00:10<00:03,  8.47it/s, est. speed input: 4744.82 toks/s, output: 9.27 toks/s]
Processed prompts:  79%|  | 101/128 [00:10<00:03,  8.49it/s, est. speed input: 4740.81 toks/s, output: 9.26 toks/s]
Processed prompts:  80%|  | 102/128 [00:11<00:03,  8.48it/s, est. speed input: 4736.37 toks/s, output: 9.25 toks/s]
Processed prompts:  80%|  | 103/128 [00:11<00:02,  8.40it/s, est. speed input: 4730.66 toks/s, output: 9.24 toks/s]
Processed prompts:  81%| | 104/128 [00:11<00:02,  8.42it/s, est. speed input: 4726.38 toks/s, output: 9.23 toks/s]
Processed prompts:  82%| | 105/128 [00:11<00:02,  8.45it/s, est. speed input: 4722.63 toks/s, output: 9.22 toks/s]
Processed prompts:  83%| | 106/128 [00:11<00:02,  8.48it/s, est. speed input: 4719.17 toks/s, output: 9.22 toks/s]
Processed prompts:  84%| | 107/128 [00:11<00:02,  8.52it/s, est. speed input: 4716.13 toks/s, output: 9.21 toks/s]
Processed prompts:  84%| | 108/128 [00:11<00:02,  8.53it/s, est. speed input: 4712.69 toks/s, output: 9.20 toks/s]
Processed prompts:  85%| | 109/128 [00:11<00:02,  8.55it/s, est. speed input: 4709.59 toks/s, output: 9.20 toks/s]
Processed prompts:  86%| | 110/128 [00:11<00:02,  8.52it/s, est. speed input: 4705.90 toks/s, output: 9.19 toks/s]
Processed prompts:  87%| | 111/128 [00:12<00:02,  8.47it/s, est. speed input: 4701.62 toks/s, output: 9.18 toks/s]
Processed prompts:  88%| | 112/128 [00:12<00:01,  8.38it/s, est. speed input: 4696.56 toks/s, output: 9.17 toks/s]
Processed prompts:  88%| | 113/128 [00:12<00:01,  8.41it/s, est. speed input: 4693.16 toks/s, output: 9.17 toks/s]
Processed prompts:  89%| | 114/128 [00:12<00:01,  8.42it/s, est. speed input: 4689.67 toks/s, output: 9.16 toks/s]
Processed prompts:  90%| | 115/128 [00:12<00:01,  8.46it/s, est. speed input: 4686.69 toks/s, output: 9.15 toks/s]
Processed prompts:  91%| | 116/128 [00:12<00:01,  8.48it/s, est. speed input: 4683.77 toks/s, output: 9.15 toks/s]
Processed prompts:  91%|| 117/128 [00:12<00:01,  8.45it/s, est. speed input: 4680.13 toks/s, output: 9.14 toks/s]
Processed prompts:  92%|| 118/128 [00:12<00:01,  8.43it/s, est. speed input: 4676.48 toks/s, output: 9.13 toks/s]
Processed prompts:  93%|| 119/128 [00:13<00:01,  8.46it/s, est. speed input: 4673.71 toks/s, output: 9.13 toks/s]
Processed prompts:  94%|| 120/128 [00:13<00:00,  8.40it/s, est. speed input: 4669.64 toks/s, output: 9.12 toks/s]
Processed prompts:  95%|| 121/128 [00:13<00:00,  8.36it/s, est. speed input: 4665.66 toks/s, output: 9.11 toks/s]
Processed prompts:  95%|| 122/128 [00:13<00:00,  8.44it/s, est. speed input: 4663.48 toks/s, output: 9.11 toks/s]
Processed prompts:  96%|| 123/128 [00:13<00:00,  8.49it/s, est. speed input: 4661.31 toks/s, output: 9.10 toks/s]
Processed prompts:  97%|| 124/128 [00:13<00:00,  8.49it/s, est. speed input: 4658.59 toks/s, output: 9.10 toks/s]
Processed prompts:  98%|| 125/128 [00:13<00:00,  8.49it/s, est. speed input: 4655.92 toks/s, output: 9.09 toks/s]
Processed prompts:  98%|| 126/128 [00:13<00:00,  8.46it/s, est. speed input: 4652.91 toks/s, output: 9.09 toks/s]
Processed prompts:  99%|| 127/128 [00:13<00:00,  8.48it/s, est. speed input: 4650.48 toks/s, output: 9.08 toks/s]
Processed prompts: 100%|| 128/128 [00:14<00:00,  8.53it/s, est. speed input: 4648.64 toks/s, output: 9.08 toks/s]
Processed prompts: 100%|| 128/128 [00:14<00:00,  8.53it/s, est. speed input: 4648.64 toks/s, output: 9.08 toks/s]
Processed prompts: 100%|| 128/128 [00:14<00:00,  9.08it/s, est. speed input: 4648.64 toks/s, output: 9.08 toks/s]
[rank0]:[W127 08:05:30.494559913 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-27 08:05:44
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Qwen2.5-14B-FP8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-27 08:05:50 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-27 08:05:51 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=2291612) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2291612) WARNING 01-27 08:07:28 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 4.22 requests/s, 4327.27 total tokens/s, 4.22 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-27 08:05:50] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 08:05:50] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 08:05:50] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 08:05:50] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:05:50] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:05:50] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:05:50] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:05:50] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:05:50] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 08:05:50] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 08:05:50] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 08:05:50] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 08:05:50] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 08:05:50] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-27 08:05:54] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 08:05:54] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 08:05:54] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 08:05:54] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:05:54] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:05:54] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:05:54] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:05:54] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:05:54] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 08:05:54] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 08:05:54] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 08:05:54] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 08:05:54] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 08:05:54] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=2291612) [2026-01-27 08:05:55] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=2291612) [2026-01-27 08:05:55] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2291612) [2026-01-27 08:05:55] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=2291612) [2026-01-27 08:05:55] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=2291612) [2026-01-27 08:05:55] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=2291612) [2026-01-27 08:05:55] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=2291612) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=2291612) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:25,  8.37s/it]
(EngineCore_DP0 pid=2291612) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:35<00:38, 19.12s/it]
(EngineCore_DP0 pid=2291612) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:56<00:20, 20.29s/it]
(EngineCore_DP0 pid=2291612) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:23<00:00, 23.05s/it]
(EngineCore_DP0 pid=2291612) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:23<00:00, 21.00s/it]
(EngineCore_DP0 pid=2291612) 
(EngineCore_DP0 pid=2291612) [2026-01-27 08:07:20] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 5120] -> 1D uint8
(EngineCore_DP0 pid=2291612) [2026-01-27 08:07:21] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 22937600 bytes
(EngineCore_DP0 pid=2291612) [2026-01-27 08:07:21] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 5120] -> 1D uint8
(EngineCore_DP0 pid=2291612) [2026-01-27 08:07:21] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16384000 bytes
(EngineCore_DP0 pid=2291612) [2026-01-27 08:07:21] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 5120] -> 1D uint8
(EngineCore_DP0 pid=2291612) [2026-01-27 08:07:21] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 88473600 bytes
(EngineCore_DP0 pid=2291612) [2026-01-27 08:07:21] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 13824] -> 1D uint8
(EngineCore_DP0 pid=2291612) [2026-01-27 08:07:21] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 44236800 bytes
(EngineCore_DP0 pid=2291612) 2026-01-27 08:07:28,171 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=2291612) 2026-01-27 08:07:28,266 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  36%|      | 46/128 [00:00<00:00, 457.83it/s]
Adding requests:  73%|  | 94/128 [00:00<00:00, 470.02it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 471.62it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:37,  3.40it/s, est. speed input: 3484.55 toks/s, output: 3.40 toks/s]
Processed prompts:   2%|         | 2/128 [00:00<00:32,  3.92it/s, est. speed input: 3923.35 toks/s, output: 3.83 toks/s]
Processed prompts:   2%|         | 3/128 [00:00<00:30,  4.09it/s, est. speed input: 4077.11 toks/s, output: 3.98 toks/s]
Processed prompts:   3%|         | 4/128 [00:00<00:29,  4.17it/s, est. speed input: 4154.67 toks/s, output: 4.06 toks/s]
Processed prompts:   4%|         | 5/128 [00:01<00:29,  4.22it/s, est. speed input: 4200.72 toks/s, output: 4.10 toks/s]
Processed prompts:   5%|         | 6/128 [00:01<00:28,  4.23it/s, est. speed input: 4225.90 toks/s, output: 4.13 toks/s]
Processed prompts:   5%|         | 7/128 [00:01<00:28,  4.27it/s, est. speed input: 4259.26 toks/s, output: 4.16 toks/s]
Processed prompts:   6%|         | 8/128 [00:01<00:27,  4.29it/s, est. speed input: 4279.02 toks/s, output: 4.18 toks/s]
Processed prompts:   7%|         | 9/128 [00:02<00:27,  4.30it/s, est. speed input: 4295.12 toks/s, output: 4.19 toks/s]
Processed prompts:   8%|         | 10/128 [00:02<00:27,  4.26it/s, est. speed input: 4294.67 toks/s, output: 4.19 toks/s]
Processed prompts:   9%|         | 11/128 [00:02<00:27,  4.27it/s, est. speed input: 4301.69 toks/s, output: 4.20 toks/s]
Processed prompts:   9%|         | 12/128 [00:02<00:27,  4.28it/s, est. speed input: 4311.40 toks/s, output: 4.21 toks/s]
Processed prompts:  10%|         | 13/128 [00:03<00:26,  4.30it/s, est. speed input: 4321.07 toks/s, output: 4.22 toks/s]
Processed prompts:  11%|         | 14/128 [00:03<00:26,  4.29it/s, est. speed input: 4324.39 toks/s, output: 4.22 toks/s]
Processed prompts:  12%|        | 15/128 [00:03<00:26,  4.26it/s, est. speed input: 4323.00 toks/s, output: 4.22 toks/s]
Processed prompts:  12%|        | 16/128 [00:03<00:26,  4.27it/s, est. speed input: 4328.07 toks/s, output: 4.23 toks/s]
Processed prompts:  13%|        | 17/128 [00:04<00:25,  4.29it/s, est. speed input: 4333.10 toks/s, output: 4.23 toks/s]
Processed prompts:  14%|        | 18/128 [00:04<00:25,  4.28it/s, est. speed input: 4334.94 toks/s, output: 4.23 toks/s]
Processed prompts:  15%|        | 19/128 [00:04<00:25,  4.26it/s, est. speed input: 4333.87 toks/s, output: 4.23 toks/s]
Processed prompts:  16%|        | 20/128 [00:04<00:25,  4.27it/s, est. speed input: 4337.12 toks/s, output: 4.24 toks/s]
Processed prompts:  16%|        | 21/128 [00:04<00:24,  4.29it/s, est. speed input: 4342.05 toks/s, output: 4.24 toks/s]
Processed prompts:  17%|        | 22/128 [00:05<00:24,  4.30it/s, est. speed input: 4345.04 toks/s, output: 4.24 toks/s]
Processed prompts:  18%|        | 23/128 [00:05<00:24,  4.30it/s, est. speed input: 4348.15 toks/s, output: 4.25 toks/s]
Processed prompts:  19%|        | 24/128 [00:05<00:24,  4.27it/s, est. speed input: 4346.16 toks/s, output: 4.24 toks/s]
Processed prompts:  20%|        | 25/128 [00:05<00:24,  4.28it/s, est. speed input: 4349.01 toks/s, output: 4.25 toks/s]
Processed prompts:  20%|        | 26/128 [00:06<00:23,  4.29it/s, est. speed input: 4351.00 toks/s, output: 4.25 toks/s]
Processed prompts:  21%|        | 27/128 [00:06<00:23,  4.30it/s, est. speed input: 4354.03 toks/s, output: 4.25 toks/s]
Processed prompts:  22%|       | 28/128 [00:06<00:23,  4.28it/s, est. speed input: 4353.68 toks/s, output: 4.25 toks/s]
Processed prompts:  23%|       | 29/128 [00:06<00:23,  4.29it/s, est. speed input: 4355.04 toks/s, output: 4.25 toks/s]
Processed prompts:  23%|       | 30/128 [00:07<00:22,  4.28it/s, est. speed input: 4355.30 toks/s, output: 4.25 toks/s]
Processed prompts:  24%|       | 31/128 [00:07<00:22,  4.28it/s, est. speed input: 4356.09 toks/s, output: 4.25 toks/s]
Processed prompts:  25%|       | 32/128 [00:07<00:22,  4.29it/s, est. speed input: 4357.75 toks/s, output: 4.26 toks/s]
Processed prompts:  26%|       | 33/128 [00:07<00:22,  4.25it/s, est. speed input: 4354.77 toks/s, output: 4.25 toks/s]
Processed prompts:  27%|       | 34/128 [00:07<00:21,  4.28it/s, est. speed input: 4357.98 toks/s, output: 4.26 toks/s]
Processed prompts:  27%|       | 35/128 [00:08<00:21,  4.30it/s, est. speed input: 4360.41 toks/s, output: 4.26 toks/s]
Processed prompts:  28%|       | 36/128 [00:08<00:21,  4.30it/s, est. speed input: 4362.10 toks/s, output: 4.26 toks/s]
Processed prompts:  29%|       | 37/128 [00:08<00:21,  4.30it/s, est. speed input: 4362.80 toks/s, output: 4.26 toks/s]
Processed prompts:  30%|       | 38/128 [00:08<00:21,  4.29it/s, est. speed input: 4362.59 toks/s, output: 4.26 toks/s]
Processed prompts:  30%|       | 39/128 [00:09<00:20,  4.30it/s, est. speed input: 4364.23 toks/s, output: 4.26 toks/s]
Processed prompts:  31%|      | 40/128 [00:09<00:20,  4.29it/s, est. speed input: 4364.93 toks/s, output: 4.26 toks/s]
Processed prompts:  32%|      | 41/128 [00:09<00:20,  4.29it/s, est. speed input: 4365.44 toks/s, output: 4.26 toks/s]
Processed prompts:  33%|      | 42/128 [00:09<00:20,  4.24it/s, est. speed input: 4362.06 toks/s, output: 4.26 toks/s]
Processed prompts:  34%|      | 43/128 [00:10<00:19,  4.27it/s, est. speed input: 4364.09 toks/s, output: 4.26 toks/s]
Processed prompts:  34%|      | 44/128 [00:10<00:19,  4.26it/s, est. speed input: 4363.51 toks/s, output: 4.26 toks/s]
Processed prompts:  35%|      | 45/128 [00:10<00:19,  4.28it/s, est. speed input: 4364.58 toks/s, output: 4.26 toks/s]
Processed prompts:  36%|      | 46/128 [00:10<00:19,  4.28it/s, est. speed input: 4365.47 toks/s, output: 4.26 toks/s]
Processed prompts:  37%|      | 47/128 [00:11<00:18,  4.27it/s, est. speed input: 4364.62 toks/s, output: 4.26 toks/s]
Processed prompts:  38%|      | 48/128 [00:11<00:18,  4.27it/s, est. speed input: 4364.85 toks/s, output: 4.26 toks/s]
Processed prompts:  38%|      | 49/128 [00:11<00:18,  4.28it/s, est. speed input: 4366.05 toks/s, output: 4.26 toks/s]
Processed prompts:  39%|      | 50/128 [00:11<00:18,  4.29it/s, est. speed input: 4366.83 toks/s, output: 4.26 toks/s]
Processed prompts:  40%|      | 51/128 [00:11<00:18,  4.26it/s, est. speed input: 4365.57 toks/s, output: 4.26 toks/s]
Processed prompts:  41%|      | 52/128 [00:12<00:17,  4.26it/s, est. speed input: 4365.22 toks/s, output: 4.26 toks/s]
Processed prompts:  41%|     | 53/128 [00:12<00:17,  4.26it/s, est. speed input: 4365.45 toks/s, output: 4.26 toks/s]
Processed prompts:  42%|     | 54/128 [00:12<00:17,  4.27it/s, est. speed input: 4365.83 toks/s, output: 4.26 toks/s]
Processed prompts:  43%|     | 55/128 [00:12<00:17,  4.27it/s, est. speed input: 4366.09 toks/s, output: 4.26 toks/s]
Processed prompts:  44%|     | 56/128 [00:13<00:16,  4.25it/s, est. speed input: 4364.74 toks/s, output: 4.26 toks/s]
Processed prompts:  45%|     | 57/128 [00:13<00:16,  4.26it/s, est. speed input: 4365.17 toks/s, output: 4.26 toks/s]
Processed prompts:  45%|     | 58/128 [00:13<00:16,  4.27it/s, est. speed input: 4365.68 toks/s, output: 4.26 toks/s]
Processed prompts:  46%|     | 59/128 [00:13<00:16,  4.28it/s, est. speed input: 4366.33 toks/s, output: 4.26 toks/s]
Processed prompts:  47%|     | 60/128 [00:14<00:15,  4.26it/s, est. speed input: 4365.80 toks/s, output: 4.26 toks/s]
Processed prompts:  48%|     | 61/128 [00:14<00:15,  4.29it/s, est. speed input: 4366.97 toks/s, output: 4.26 toks/s]
Processed prompts:  48%|     | 62/128 [00:14<00:15,  4.29it/s, est. speed input: 4367.49 toks/s, output: 4.27 toks/s]
Processed prompts:  49%|     | 63/128 [00:14<00:15,  4.29it/s, est. speed input: 4368.17 toks/s, output: 4.27 toks/s]
Processed prompts:  50%|     | 64/128 [00:14<00:14,  4.31it/s, est. speed input: 4369.28 toks/s, output: 4.27 toks/s]
Processed prompts:  51%|     | 65/128 [00:15<00:14,  4.28it/s, est. speed input: 4368.74 toks/s, output: 4.27 toks/s]
Processed prompts:  52%|    | 66/128 [00:15<00:14,  4.28it/s, est. speed input: 4368.94 toks/s, output: 4.27 toks/s]
Processed prompts:  52%|    | 67/128 [00:15<00:14,  4.29it/s, est. speed input: 4369.67 toks/s, output: 4.27 toks/s]
Processed prompts:  53%|    | 68/128 [00:15<00:13,  4.30it/s, est. speed input: 4370.33 toks/s, output: 4.27 toks/s]
Processed prompts:  54%|    | 69/128 [00:16<00:13,  4.26it/s, est. speed input: 4368.92 toks/s, output: 4.27 toks/s]
Processed prompts:  55%|    | 70/128 [00:16<00:13,  4.27it/s, est. speed input: 4369.14 toks/s, output: 4.27 toks/s]
Processed prompts:  55%|    | 71/128 [00:16<00:13,  4.26it/s, est. speed input: 4368.62 toks/s, output: 4.27 toks/s]
Processed prompts:  56%|    | 72/128 [00:16<00:13,  4.25it/s, est. speed input: 4368.39 toks/s, output: 4.27 toks/s]
Processed prompts:  57%|    | 73/128 [00:17<00:12,  4.27it/s, est. speed input: 4368.99 toks/s, output: 4.27 toks/s]
Processed prompts:  58%|    | 74/128 [00:17<00:12,  4.25it/s, est. speed input: 4368.28 toks/s, output: 4.27 toks/s]
Processed prompts:  59%|    | 75/128 [00:17<00:12,  4.25it/s, est. speed input: 4368.13 toks/s, output: 4.27 toks/s]
Processed prompts:  59%|    | 76/128 [00:17<00:12,  4.27it/s, est. speed input: 4368.55 toks/s, output: 4.27 toks/s]
Processed prompts:  60%|    | 77/128 [00:18<00:11,  4.28it/s, est. speed input: 4369.02 toks/s, output: 4.27 toks/s]
Processed prompts:  61%|    | 78/128 [00:18<00:11,  4.25it/s, est. speed input: 4368.17 toks/s, output: 4.27 toks/s]
Processed prompts:  62%|   | 79/128 [00:18<00:11,  4.26it/s, est. speed input: 4368.43 toks/s, output: 4.27 toks/s]
Processed prompts:  62%|   | 80/128 [00:18<00:11,  4.27it/s, est. speed input: 4368.59 toks/s, output: 4.27 toks/s]
Processed prompts:  63%|   | 81/128 [00:18<00:11,  4.27it/s, est. speed input: 4368.59 toks/s, output: 4.27 toks/s]
Processed prompts:  64%|   | 82/128 [00:19<00:10,  4.27it/s, est. speed input: 4368.85 toks/s, output: 4.27 toks/s]
Processed prompts:  65%|   | 83/128 [00:19<00:10,  4.25it/s, est. speed input: 4368.07 toks/s, output: 4.27 toks/s]
Processed prompts:  66%|   | 84/128 [00:19<00:10,  4.26it/s, est. speed input: 4368.17 toks/s, output: 4.27 toks/s]
Processed prompts:  66%|   | 85/128 [00:19<00:10,  4.26it/s, est. speed input: 4368.27 toks/s, output: 4.27 toks/s]
Processed prompts:  67%|   | 86/128 [00:20<00:09,  4.26it/s, est. speed input: 4368.07 toks/s, output: 4.27 toks/s]
Processed prompts:  68%|   | 87/128 [00:20<00:09,  4.24it/s, est. speed input: 4367.18 toks/s, output: 4.26 toks/s]
Processed prompts:  69%|   | 88/128 [00:20<00:09,  4.25it/s, est. speed input: 4367.35 toks/s, output: 4.26 toks/s]
Processed prompts:  70%|   | 89/128 [00:20<00:09,  4.27it/s, est. speed input: 4368.02 toks/s, output: 4.27 toks/s]
Processed prompts:  70%|   | 90/128 [00:21<00:08,  4.27it/s, est. speed input: 4368.04 toks/s, output: 4.27 toks/s]
Processed prompts:  71%|   | 91/128 [00:21<00:08,  4.28it/s, est. speed input: 4368.43 toks/s, output: 4.27 toks/s]
Processed prompts:  72%|  | 92/128 [00:21<00:08,  4.27it/s, est. speed input: 4368.04 toks/s, output: 4.27 toks/s]
Processed prompts:  73%|  | 93/128 [00:21<00:08,  4.25it/s, est. speed input: 4367.64 toks/s, output: 4.27 toks/s]
Processed prompts:  73%|  | 94/128 [00:22<00:07,  4.26it/s, est. speed input: 4367.55 toks/s, output: 4.27 toks/s]
Processed prompts:  74%|  | 95/128 [00:22<00:07,  4.25it/s, est. speed input: 4367.14 toks/s, output: 4.26 toks/s]
Processed prompts:  75%|  | 96/128 [00:22<00:07,  4.23it/s, est. speed input: 4366.30 toks/s, output: 4.26 toks/s]
Processed prompts:  76%|  | 97/128 [00:22<00:07,  4.25it/s, est. speed input: 4366.58 toks/s, output: 4.26 toks/s]
Processed prompts:  77%|  | 98/128 [00:22<00:07,  4.27it/s, est. speed input: 4367.06 toks/s, output: 4.26 toks/s]
Processed prompts:  77%|  | 99/128 [00:23<00:06,  4.27it/s, est. speed input: 4367.08 toks/s, output: 4.26 toks/s]
Processed prompts:  78%|  | 100/128 [00:23<00:06,  4.27it/s, est. speed input: 4367.21 toks/s, output: 4.26 toks/s]
Processed prompts:  79%|  | 101/128 [00:23<00:06,  4.24it/s, est. speed input: 4366.21 toks/s, output: 4.26 toks/s]
Processed prompts:  80%|  | 102/128 [00:23<00:06,  4.25it/s, est. speed input: 4366.20 toks/s, output: 4.26 toks/s]
Processed prompts:  80%|  | 103/128 [00:24<00:05,  4.25it/s, est. speed input: 4366.17 toks/s, output: 4.26 toks/s]
Processed prompts:  81%| | 104/128 [00:24<00:05,  4.27it/s, est. speed input: 4366.57 toks/s, output: 4.26 toks/s]
Processed prompts:  82%| | 105/128 [00:24<00:05,  4.24it/s, est. speed input: 4365.56 toks/s, output: 4.26 toks/s]
Processed prompts:  83%| | 106/128 [00:24<00:05,  4.23it/s, est. speed input: 4365.18 toks/s, output: 4.26 toks/s]
Processed prompts:  84%| | 107/128 [00:25<00:04,  4.25it/s, est. speed input: 4365.62 toks/s, output: 4.26 toks/s]
Processed prompts:  84%| | 108/128 [00:25<00:04,  4.25it/s, est. speed input: 4365.53 toks/s, output: 4.26 toks/s]
Processed prompts:  85%| | 109/128 [00:25<00:04,  4.26it/s, est. speed input: 4365.64 toks/s, output: 4.26 toks/s]
Processed prompts:  86%| | 110/128 [00:25<00:04,  4.23it/s, est. speed input: 4364.68 toks/s, output: 4.26 toks/s]
Processed prompts:  87%| | 111/128 [00:26<00:04,  4.24it/s, est. speed input: 4364.67 toks/s, output: 4.26 toks/s]
Processed prompts:  88%| | 112/128 [00:26<00:03,  4.26it/s, est. speed input: 4364.95 toks/s, output: 4.26 toks/s]
Processed prompts:  88%| | 113/128 [00:26<00:03,  4.28it/s, est. speed input: 4365.47 toks/s, output: 4.26 toks/s]
Processed prompts:  89%| | 114/128 [00:26<00:03,  4.25it/s, est. speed input: 4364.75 toks/s, output: 4.26 toks/s]
Processed prompts:  90%| | 115/128 [00:26<00:03,  4.24it/s, est. speed input: 4364.48 toks/s, output: 4.26 toks/s]
Processed prompts:  91%| | 116/128 [00:27<00:02,  4.25it/s, est. speed input: 4364.61 toks/s, output: 4.26 toks/s]
Processed prompts:  91%|| 117/128 [00:27<00:02,  4.25it/s, est. speed input: 4364.36 toks/s, output: 4.26 toks/s]
Processed prompts:  92%|| 118/128 [00:27<00:02,  4.25it/s, est. speed input: 4364.43 toks/s, output: 4.26 toks/s]
Processed prompts:  93%|| 119/128 [00:27<00:02,  4.23it/s, est. speed input: 4363.63 toks/s, output: 4.26 toks/s]
Processed prompts:  94%|| 120/128 [00:28<00:01,  4.25it/s, est. speed input: 4363.92 toks/s, output: 4.26 toks/s]
Processed prompts:  95%|| 121/128 [00:28<00:01,  4.24it/s, est. speed input: 4363.68 toks/s, output: 4.26 toks/s]
Processed prompts:  95%|| 122/128 [00:28<00:01,  4.27it/s, est. speed input: 4364.22 toks/s, output: 4.26 toks/s]
Processed prompts:  96%|| 123/128 [00:28<00:01,  4.23it/s, est. speed input: 4363.12 toks/s, output: 4.26 toks/s]
Processed prompts:  97%|| 124/128 [00:29<00:00,  4.24it/s, est. speed input: 4363.10 toks/s, output: 4.26 toks/s]
Processed prompts:  98%|| 125/128 [00:29<00:00,  4.25it/s, est. speed input: 4363.33 toks/s, output: 4.26 toks/s]
Processed prompts:  98%|| 126/128 [00:29<00:00,  4.27it/s, est. speed input: 4363.67 toks/s, output: 4.26 toks/s]
Processed prompts:  99%|| 127/128 [00:29<00:00,  4.28it/s, est. speed input: 4364.10 toks/s, output: 4.26 toks/s]
Processed prompts: 100%|| 128/128 [00:30<00:00,  4.26it/s, est. speed input: 4363.63 toks/s, output: 4.26 toks/s]
Processed prompts: 100%|| 128/128 [00:30<00:00,  4.26it/s, est. speed input: 4363.63 toks/s, output: 4.26 toks/s]
Processed prompts: 100%|| 128/128 [00:30<00:00,  4.26it/s, est. speed input: 4363.63 toks/s, output: 4.26 toks/s]
[rank0]:[W127 08:07:59.538444981 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-27 08:08:02
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Qwen2.5-14B-FP8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-27 08:08:09 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-27 08:08:10 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=2293730) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2293730) WARNING 01-27 08:09:54 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 4.07 requests/s, 4176.48 total tokens/s, 4.07 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-27 08:08:09] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 08:08:09] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 08:08:09] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 08:08:09] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:08:09] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:08:09] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:08:09] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:08:09] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:08:09] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 08:08:09] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 08:08:09] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 08:08:09] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 08:08:09] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 08:08:09] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-27 08:08:13] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 08:08:13] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 08:08:13] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 08:08:13] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:08:13] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:08:13] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:08:13] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:08:13] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:08:13] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 08:08:13] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 08:08:13] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 08:08:13] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 08:08:13] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 08:08:13] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=2293730) [2026-01-27 08:08:14] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=2293730) [2026-01-27 08:08:14] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2293730) [2026-01-27 08:08:14] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=2293730) [2026-01-27 08:08:14] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=2293730) [2026-01-27 08:08:14] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=2293730) [2026-01-27 08:08:14] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=2293730) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=2293730) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:26,  8.71s/it]
(EngineCore_DP0 pid=2293730) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:35<00:39, 19.53s/it]
(EngineCore_DP0 pid=2293730) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:57<00:20, 20.46s/it]
(EngineCore_DP0 pid=2293730) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:24<00:00, 23.13s/it]
(EngineCore_DP0 pid=2293730) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:24<00:00, 21.15s/it]
(EngineCore_DP0 pid=2293730) 
(EngineCore_DP0 pid=2293730) [2026-01-27 08:09:40] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 5120] -> 1D uint8
(EngineCore_DP0 pid=2293730) [2026-01-27 08:09:40] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 22937600 bytes
(EngineCore_DP0 pid=2293730) [2026-01-27 08:09:40] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 5120] -> 1D uint8
(EngineCore_DP0 pid=2293730) [2026-01-27 08:09:40] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16384000 bytes
(EngineCore_DP0 pid=2293730) [2026-01-27 08:09:40] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 5120] -> 1D uint8
(EngineCore_DP0 pid=2293730) [2026-01-27 08:09:40] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 88473600 bytes
(EngineCore_DP0 pid=2293730) [2026-01-27 08:09:40] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 13824] -> 1D uint8
(EngineCore_DP0 pid=2293730) [2026-01-27 08:09:40] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 44236800 bytes
(EngineCore_DP0 pid=2293730) 2026-01-27 08:09:48,474 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=2293730) 2026-01-27 08:09:48,811 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:   0%|          | 1/256 [00:01<04:44,  1.12s/it]
Adding requests:   1%|          | 2/256 [00:01<02:32,  1.67it/s]
Adding requests:   1%|          | 3/256 [00:01<01:37,  2.60it/s]
Adding requests:   2%|         | 5/256 [00:01<00:54,  4.63it/s]
Adding requests:   3%|         | 7/256 [00:01<00:36,  6.88it/s]
Adding requests:   4%|         | 10/256 [00:01<00:22, 10.97it/s]
Adding requests:   5%|         | 13/256 [00:01<00:16, 14.49it/s]
Adding requests:   8%|         | 20/256 [00:02<00:08, 26.71it/s]
Adding requests:  14%|        | 35/256 [00:02<00:03, 56.02it/s]
Adding requests:  20%|        | 52/256 [00:02<00:02, 83.41it/s]
Adding requests:  28%|       | 71/256 [00:02<00:01, 110.36it/s]
Adding requests:  36%|      | 93/256 [00:02<00:01, 139.86it/s]
Adding requests:  47%|     | 120/256 [00:02<00:00, 175.22it/s]
Adding requests:  59%|    | 152/256 [00:02<00:00, 215.12it/s]
Adding requests:  71%|   | 182/256 [00:02<00:00, 239.05it/s]
Adding requests:  85%| | 218/256 [00:02<00:00, 273.70it/s]
Adding requests:  99%|| 253/256 [00:03<00:00, 295.69it/s]
Adding requests: 100%|| 256/256 [00:03<00:00, 84.85it/s] 

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   3%|         | 7/256 [00:00<00:03, 68.12it/s, est. speed input: 69776.09 toks/s, output: 68.12 toks/s]
Processed prompts:   5%|         | 14/256 [00:01<00:30,  7.87it/s, est. speed input: 9295.17 toks/s, output: 9.08 toks/s] 
Processed prompts:   7%|         | 18/256 [00:02<00:38,  6.11it/s, est. speed input: 7370.49 toks/s, output: 7.20 toks/s]
Processed prompts:   8%|         | 20/256 [00:02<00:41,  5.63it/s, est. speed input: 6879.00 toks/s, output: 6.72 toks/s]
Processed prompts:   9%|         | 22/256 [00:03<00:44,  5.23it/s, est. speed input: 6512.25 toks/s, output: 6.36 toks/s]
Processed prompts:   9%|         | 23/256 [00:03<00:53,  4.36it/s, est. speed input: 5975.13 toks/s, output: 5.84 toks/s]
Processed prompts:  10%|         | 25/256 [00:04<00:53,  4.31it/s, est. speed input: 5792.63 toks/s, output: 5.66 toks/s]
Processed prompts:  11%|         | 27/256 [00:04<00:53,  4.26it/s, est. speed input: 5640.73 toks/s, output: 5.51 toks/s]
Processed prompts:  11%|        | 29/256 [00:05<00:53,  4.24it/s, est. speed input: 5519.40 toks/s, output: 5.39 toks/s]
Processed prompts:  12%|        | 31/256 [00:05<00:53,  4.20it/s, est. speed input: 5411.99 toks/s, output: 5.29 toks/s]
Processed prompts:  13%|        | 33/256 [00:06<00:53,  4.21it/s, est. speed input: 5329.66 toks/s, output: 5.20 toks/s]
Processed prompts:  14%|        | 35/256 [00:06<00:52,  4.18it/s, est. speed input: 5250.34 toks/s, output: 5.13 toks/s]
Processed prompts:  14%|        | 37/256 [00:07<00:52,  4.18it/s, est. speed input: 5186.80 toks/s, output: 5.07 toks/s]
Processed prompts:  15%|        | 39/256 [00:07<00:51,  4.18it/s, est. speed input: 5130.11 toks/s, output: 5.01 toks/s]
Processed prompts:  16%|        | 41/256 [00:08<00:51,  4.18it/s, est. speed input: 5081.44 toks/s, output: 4.96 toks/s]
Processed prompts:  17%|        | 43/256 [00:08<00:51,  4.17it/s, est. speed input: 5034.72 toks/s, output: 4.92 toks/s]
Processed prompts:  18%|        | 45/256 [00:09<00:50,  4.17it/s, est. speed input: 4995.90 toks/s, output: 4.88 toks/s]
Processed prompts:  18%|        | 47/256 [00:09<00:50,  4.17it/s, est. speed input: 4959.91 toks/s, output: 4.84 toks/s]
Processed prompts:  19%|        | 49/256 [00:10<00:49,  4.16it/s, est. speed input: 4925.49 toks/s, output: 4.81 toks/s]
Processed prompts:  20%|        | 51/256 [00:10<00:49,  4.17it/s, est. speed input: 4897.07 toks/s, output: 4.78 toks/s]
Processed prompts:  21%|        | 53/256 [00:11<00:48,  4.15it/s, est. speed input: 4867.64 toks/s, output: 4.75 toks/s]
Processed prompts:  21%|       | 55/256 [00:11<00:48,  4.17it/s, est. speed input: 4844.43 toks/s, output: 4.73 toks/s]
Processed prompts:  22%|       | 57/256 [00:12<00:47,  4.16it/s, est. speed input: 4820.49 toks/s, output: 4.71 toks/s]
Processed prompts:  23%|       | 59/256 [00:12<00:47,  4.17it/s, est. speed input: 4800.54 toks/s, output: 4.69 toks/s]
Processed prompts:  24%|       | 61/256 [00:13<00:46,  4.16it/s, est. speed input: 4780.13 toks/s, output: 4.67 toks/s]
Processed prompts:  25%|       | 63/256 [00:13<00:46,  4.18it/s, est. speed input: 4763.38 toks/s, output: 4.65 toks/s]
Processed prompts:  25%|       | 65/256 [00:14<00:45,  4.18it/s, est. speed input: 4746.72 toks/s, output: 4.64 toks/s]
Processed prompts:  26%|       | 67/256 [00:14<00:45,  4.16it/s, est. speed input: 4729.44 toks/s, output: 4.62 toks/s]
Processed prompts:  27%|       | 69/256 [00:14<00:44,  4.17it/s, est. speed input: 4715.50 toks/s, output: 4.60 toks/s]
Processed prompts:  28%|       | 71/256 [00:15<00:44,  4.16it/s, est. speed input: 4700.43 toks/s, output: 4.59 toks/s]
Processed prompts:  29%|       | 73/256 [00:15<00:43,  4.16it/s, est. speed input: 4687.12 toks/s, output: 4.58 toks/s]
Processed prompts:  29%|       | 75/256 [00:16<00:43,  4.16it/s, est. speed input: 4674.41 toks/s, output: 4.56 toks/s]
Processed prompts:  30%|       | 77/256 [00:16<00:42,  4.17it/s, est. speed input: 4663.76 toks/s, output: 4.55 toks/s]
Processed prompts:  31%|       | 79/256 [00:17<00:42,  4.16it/s, est. speed input: 4651.54 toks/s, output: 4.54 toks/s]
Processed prompts:  32%|      | 81/256 [00:17<00:42,  4.15it/s, est. speed input: 4640.58 toks/s, output: 4.53 toks/s]
Processed prompts:  32%|      | 83/256 [00:18<00:41,  4.16it/s, est. speed input: 4630.67 toks/s, output: 4.52 toks/s]
Processed prompts:  33%|      | 85/256 [00:18<00:41,  4.17it/s, est. speed input: 4622.01 toks/s, output: 4.51 toks/s]
Processed prompts:  34%|      | 87/256 [00:19<00:40,  4.17it/s, est. speed input: 4613.30 toks/s, output: 4.51 toks/s]
Processed prompts:  35%|      | 89/256 [00:19<00:40,  4.15it/s, est. speed input: 4603.80 toks/s, output: 4.50 toks/s]
Processed prompts:  36%|      | 91/256 [00:20<00:39,  4.17it/s, est. speed input: 4596.45 toks/s, output: 4.49 toks/s]
Processed prompts:  36%|      | 93/256 [00:20<00:39,  4.15it/s, est. speed input: 4587.52 toks/s, output: 4.48 toks/s]
Processed prompts:  37%|      | 95/256 [00:21<00:38,  4.16it/s, est. speed input: 4580.64 toks/s, output: 4.47 toks/s]
Processed prompts:  38%|      | 97/256 [00:21<00:38,  4.15it/s, est. speed input: 4573.02 toks/s, output: 4.47 toks/s]
Processed prompts:  39%|      | 99/256 [00:22<00:37,  4.16it/s, est. speed input: 4566.23 toks/s, output: 4.46 toks/s]
Processed prompts:  39%|      | 101/256 [00:22<00:37,  4.14it/s, est. speed input: 4558.53 toks/s, output: 4.45 toks/s]
Processed prompts:  40%|      | 103/256 [00:23<00:36,  4.15it/s, est. speed input: 4552.75 toks/s, output: 4.45 toks/s]
Processed prompts:  41%|      | 105/256 [00:23<00:36,  4.15it/s, est. speed input: 4546.15 toks/s, output: 4.44 toks/s]
Processed prompts:  42%|     | 107/256 [00:24<00:35,  4.16it/s, est. speed input: 4540.80 toks/s, output: 4.43 toks/s]
Processed prompts:  43%|     | 109/256 [00:24<00:35,  4.16it/s, est. speed input: 4535.43 toks/s, output: 4.43 toks/s]
Processed prompts:  43%|     | 111/256 [00:25<00:34,  4.15it/s, est. speed input: 4529.42 toks/s, output: 4.42 toks/s]
Processed prompts:  44%|     | 113/256 [00:25<00:34,  4.15it/s, est. speed input: 4524.32 toks/s, output: 4.42 toks/s]
Processed prompts:  45%|     | 115/256 [00:26<00:34,  4.13it/s, est. speed input: 4517.95 toks/s, output: 4.41 toks/s]
Processed prompts:  46%|     | 117/256 [00:26<00:33,  4.14it/s, est. speed input: 4513.07 toks/s, output: 4.41 toks/s]
Processed prompts:  46%|     | 119/256 [00:27<00:33,  4.13it/s, est. speed input: 4507.85 toks/s, output: 4.40 toks/s]
Processed prompts:  47%|     | 121/256 [00:27<00:32,  4.14it/s, est. speed input: 4503.44 toks/s, output: 4.40 toks/s]
Processed prompts:  48%|     | 123/256 [00:28<00:32,  4.13it/s, est. speed input: 4498.05 toks/s, output: 4.39 toks/s]
Processed prompts:  49%|     | 125/256 [00:28<00:31,  4.14it/s, est. speed input: 4494.26 toks/s, output: 4.39 toks/s]
Processed prompts:  50%|     | 127/256 [00:28<00:31,  4.12it/s, est. speed input: 4488.99 toks/s, output: 4.38 toks/s]
Processed prompts:  50%|     | 129/256 [00:29<00:30,  4.13it/s, est. speed input: 4484.98 toks/s, output: 4.38 toks/s]
Processed prompts:  51%|     | 131/256 [00:29<00:30,  4.14it/s, est. speed input: 4481.54 toks/s, output: 4.38 toks/s]
Processed prompts:  52%|    | 133/256 [00:30<00:29,  4.13it/s, est. speed input: 4477.08 toks/s, output: 4.37 toks/s]
Processed prompts:  53%|    | 135/256 [00:30<00:29,  4.13it/s, est. speed input: 4473.38 toks/s, output: 4.37 toks/s]
Processed prompts:  54%|    | 137/256 [00:31<00:28,  4.12it/s, est. speed input: 4469.12 toks/s, output: 4.36 toks/s]
Processed prompts:  54%|    | 139/256 [00:31<00:28,  4.14it/s, est. speed input: 4466.25 toks/s, output: 4.36 toks/s]
Processed prompts:  55%|    | 141/256 [00:32<00:27,  4.13it/s, est. speed input: 4462.50 toks/s, output: 4.36 toks/s]
Processed prompts:  56%|    | 143/256 [00:32<00:27,  4.14it/s, est. speed input: 4459.39 toks/s, output: 4.35 toks/s]
Processed prompts:  57%|    | 145/256 [00:33<00:26,  4.13it/s, est. speed input: 4455.86 toks/s, output: 4.35 toks/s]
Processed prompts:  57%|    | 147/256 [00:33<00:26,  4.14it/s, est. speed input: 4453.10 toks/s, output: 4.35 toks/s]
Processed prompts:  58%|    | 149/256 [00:34<00:25,  4.13it/s, est. speed input: 4449.72 toks/s, output: 4.35 toks/s]
Processed prompts:  59%|    | 151/256 [00:34<00:25,  4.13it/s, est. speed input: 4446.61 toks/s, output: 4.34 toks/s]
Processed prompts:  60%|    | 153/256 [00:35<00:24,  4.14it/s, est. speed input: 4443.97 toks/s, output: 4.34 toks/s]
Processed prompts:  61%|    | 155/256 [00:35<00:24,  4.13it/s, est. speed input: 4440.80 toks/s, output: 4.34 toks/s]
Processed prompts:  61%|   | 157/256 [00:36<00:23,  4.14it/s, est. speed input: 4438.44 toks/s, output: 4.33 toks/s]
Processed prompts:  62%|   | 159/256 [00:36<00:23,  4.13it/s, est. speed input: 4435.56 toks/s, output: 4.33 toks/s]
Processed prompts:  63%|   | 161/256 [00:37<00:22,  4.14it/s, est. speed input: 4433.20 toks/s, output: 4.33 toks/s]
Processed prompts:  64%|   | 163/256 [00:37<00:22,  4.13it/s, est. speed input: 4430.46 toks/s, output: 4.33 toks/s]
Processed prompts:  64%|   | 165/256 [00:38<00:21,  4.14it/s, est. speed input: 4428.08 toks/s, output: 4.32 toks/s]
Processed prompts:  65%|   | 167/256 [00:38<00:21,  4.13it/s, est. speed input: 4425.31 toks/s, output: 4.32 toks/s]
Processed prompts:  66%|   | 169/256 [00:39<00:21,  4.13it/s, est. speed input: 4422.92 toks/s, output: 4.32 toks/s]
Processed prompts:  67%|   | 171/256 [00:39<00:20,  4.12it/s, est. speed input: 4420.25 toks/s, output: 4.32 toks/s]
Processed prompts:  68%|   | 173/256 [00:40<00:20,  4.13it/s, est. speed input: 4418.21 toks/s, output: 4.31 toks/s]
Processed prompts:  68%|   | 175/256 [00:40<00:19,  4.14it/s, est. speed input: 4416.27 toks/s, output: 4.31 toks/s]
Processed prompts:  69%|   | 177/256 [00:41<00:19,  4.14it/s, est. speed input: 4414.13 toks/s, output: 4.31 toks/s]
Processed prompts:  70%|   | 179/256 [00:41<00:18,  4.15it/s, est. speed input: 4412.49 toks/s, output: 4.31 toks/s]
Processed prompts:  71%|   | 181/256 [00:42<00:18,  4.14it/s, est. speed input: 4410.31 toks/s, output: 4.31 toks/s]
Processed prompts:  71%|  | 183/256 [00:42<00:17,  4.15it/s, est. speed input: 4408.73 toks/s, output: 4.31 toks/s]
Processed prompts:  72%|  | 185/256 [00:42<00:17,  4.14it/s, est. speed input: 4406.37 toks/s, output: 4.30 toks/s]
Processed prompts:  73%|  | 187/256 [00:43<00:16,  4.14it/s, est. speed input: 4404.74 toks/s, output: 4.30 toks/s]
Processed prompts:  74%|  | 189/256 [00:43<00:16,  4.13it/s, est. speed input: 4402.50 toks/s, output: 4.30 toks/s]
Processed prompts:  75%|  | 191/256 [00:44<00:15,  4.15it/s, est. speed input: 4401.25 toks/s, output: 4.30 toks/s]
Processed prompts:  75%|  | 193/256 [00:44<00:15,  4.13it/s, est. speed input: 4398.87 toks/s, output: 4.30 toks/s]
Processed prompts:  76%|  | 195/256 [00:45<00:14,  4.13it/s, est. speed input: 4397.29 toks/s, output: 4.29 toks/s]
Processed prompts:  77%|  | 197/256 [00:45<00:14,  4.13it/s, est. speed input: 4395.52 toks/s, output: 4.29 toks/s]
Processed prompts:  78%|  | 199/256 [00:46<00:13,  4.13it/s, est. speed input: 4393.87 toks/s, output: 4.29 toks/s]
Processed prompts:  79%|  | 201/256 [00:46<00:11,  4.72it/s, est. speed input: 4410.96 toks/s, output: 4.31 toks/s]
Processed prompts:  79%|  | 203/256 [00:47<00:11,  4.52it/s, est. speed input: 4408.86 toks/s, output: 4.31 toks/s]
Processed prompts:  80%|  | 205/256 [00:47<00:11,  4.40it/s, est. speed input: 4407.21 toks/s, output: 4.30 toks/s]
Processed prompts:  81%|  | 207/256 [00:48<00:11,  4.31it/s, est. speed input: 4405.12 toks/s, output: 4.30 toks/s]
Processed prompts:  82%| | 209/256 [00:48<00:11,  4.26it/s, est. speed input: 4403.59 toks/s, output: 4.30 toks/s]
Processed prompts:  82%| | 211/256 [00:49<00:10,  4.22it/s, est. speed input: 4402.05 toks/s, output: 4.30 toks/s]
Processed prompts:  83%| | 213/256 [00:49<00:10,  4.20it/s, est. speed input: 4400.38 toks/s, output: 4.30 toks/s]
Processed prompts:  84%| | 215/256 [00:50<00:09,  4.19it/s, est. speed input: 4399.16 toks/s, output: 4.30 toks/s]
Processed prompts:  85%| | 217/256 [00:50<00:09,  4.17it/s, est. speed input: 4397.42 toks/s, output: 4.29 toks/s]
Processed prompts:  86%| | 219/256 [00:51<00:08,  4.16it/s, est. speed input: 4396.01 toks/s, output: 4.29 toks/s]
Processed prompts:  86%| | 221/256 [00:51<00:08,  4.15it/s, est. speed input: 4394.42 toks/s, output: 4.29 toks/s]
Processed prompts:  87%| | 223/256 [00:51<00:07,  4.15it/s, est. speed input: 4392.99 toks/s, output: 4.29 toks/s]
Processed prompts:  88%| | 225/256 [00:52<00:07,  4.13it/s, est. speed input: 4391.16 toks/s, output: 4.29 toks/s]
Processed prompts:  89%| | 227/256 [00:52<00:06,  4.14it/s, est. speed input: 4390.03 toks/s, output: 4.29 toks/s]
Processed prompts:  89%| | 229/256 [00:53<00:06,  4.13it/s, est. speed input: 4388.27 toks/s, output: 4.29 toks/s]
Processed prompts:  90%| | 231/256 [00:53<00:06,  4.14it/s, est. speed input: 4387.17 toks/s, output: 4.28 toks/s]
Processed prompts:  91%| | 233/256 [00:54<00:05,  4.15it/s, est. speed input: 4386.05 toks/s, output: 4.28 toks/s]
Processed prompts:  92%|| 235/256 [00:54<00:05,  4.14it/s, est. speed input: 4384.55 toks/s, output: 4.28 toks/s]
Processed prompts:  93%|| 237/256 [00:55<00:04,  4.15it/s, est. speed input: 4383.62 toks/s, output: 4.28 toks/s]
Processed prompts:  93%|| 239/256 [00:55<00:04,  4.14it/s, est. speed input: 4382.13 toks/s, output: 4.28 toks/s]
Processed prompts:  94%|| 241/256 [00:56<00:03,  4.14it/s, est. speed input: 4381.00 toks/s, output: 4.28 toks/s]
Processed prompts:  95%|| 243/256 [00:56<00:03,  4.14it/s, est. speed input: 4379.65 toks/s, output: 4.28 toks/s]
Processed prompts:  96%|| 245/256 [00:57<00:02,  4.14it/s, est. speed input: 4378.48 toks/s, output: 4.28 toks/s]
Processed prompts:  96%|| 247/256 [00:57<00:02,  4.13it/s, est. speed input: 4377.17 toks/s, output: 4.27 toks/s]
Processed prompts:  97%|| 249/256 [00:58<00:01,  4.14it/s, est. speed input: 4376.12 toks/s, output: 4.27 toks/s]
Processed prompts:  98%|| 251/256 [00:58<00:01,  4.13it/s, est. speed input: 4374.64 toks/s, output: 4.27 toks/s]
Processed prompts:  99%|| 253/256 [00:59<00:00,  4.14it/s, est. speed input: 4373.69 toks/s, output: 4.27 toks/s]
Processed prompts: 100%|| 255/256 [00:59<00:00,  4.13it/s, est. speed input: 4372.44 toks/s, output: 4.27 toks/s]
Processed prompts: 100%|| 256/256 [00:59<00:00,  4.13it/s, est. speed input: 4389.58 toks/s, output: 4.29 toks/s]
Processed prompts: 100%|| 256/256 [00:59<00:00,  4.29it/s, est. speed input: 4389.58 toks/s, output: 4.29 toks/s]
[rank0]:[W127 08:10:58.797177413 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-27 08:11:14
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Qwen2.5-14B-FP8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-27 08:11:19 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-27 08:11:19 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=2296530) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2296530) WARNING 01-27 08:12:57 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 4.17 requests/s, 4273.25 total tokens/s, 4.17 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-27 08:11:19] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 08:11:19] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 08:11:19] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 08:11:19] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:11:19] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:11:19] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:11:19] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:11:19] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:11:19] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 08:11:19] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 08:11:19] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 08:11:19] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 08:11:19] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 08:11:19] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-27 08:11:23] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 08:11:23] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 08:11:23] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 08:11:23] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:11:23] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:11:23] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:11:23] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:11:23] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:11:23] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 08:11:23] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 08:11:23] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 08:11:23] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 08:11:23] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 08:11:23] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=2296530) [2026-01-27 08:11:24] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=2296530) [2026-01-27 08:11:24] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2296530) [2026-01-27 08:11:24] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=2296530) [2026-01-27 08:11:24] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=2296530) [2026-01-27 08:11:24] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=2296530) [2026-01-27 08:11:24] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=2296530) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=2296530) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:25,  8.50s/it]
(EngineCore_DP0 pid=2296530) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:35<00:38, 19.09s/it]
(EngineCore_DP0 pid=2296530) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:56<00:20, 20.03s/it]
(EngineCore_DP0 pid=2296530) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:23<00:00, 22.76s/it]
(EngineCore_DP0 pid=2296530) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:23<00:00, 20.77s/it]
(EngineCore_DP0 pid=2296530) 
(EngineCore_DP0 pid=2296530) [2026-01-27 08:12:48] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 5120] -> 1D uint8
(EngineCore_DP0 pid=2296530) [2026-01-27 08:12:48] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 22937600 bytes
(EngineCore_DP0 pid=2296530) [2026-01-27 08:12:48] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 5120] -> 1D uint8
(EngineCore_DP0 pid=2296530) [2026-01-27 08:12:48] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16384000 bytes
(EngineCore_DP0 pid=2296530) [2026-01-27 08:12:48] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 5120] -> 1D uint8
(EngineCore_DP0 pid=2296530) [2026-01-27 08:12:48] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 88473600 bytes
(EngineCore_DP0 pid=2296530) [2026-01-27 08:12:48] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 13824] -> 1D uint8
(EngineCore_DP0 pid=2296530) [2026-01-27 08:12:48] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 44236800 bytes
(EngineCore_DP0 pid=2296530) 2026-01-27 08:12:55,686 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=2296530) 2026-01-27 08:12:56,259 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   9%|         | 48/512 [00:00<00:00, 471.75it/s]
Adding requests:  19%|        | 96/512 [00:00<00:01, 390.70it/s]
Adding requests:  27%|       | 138/512 [00:00<00:00, 401.07it/s]
Adding requests:  35%|      | 179/512 [00:00<00:00, 398.49it/s]
Adding requests:  44%|     | 224/512 [00:00<00:00, 411.98it/s]
Adding requests:  52%|    | 266/512 [00:00<00:00, 412.21it/s]
Adding requests:  61%|    | 310/512 [00:00<00:00, 418.84it/s]
Adding requests:  69%|   | 355/512 [00:00<00:00, 426.21it/s]
Adding requests:  78%|  | 401/512 [00:00<00:00, 436.03it/s]
Adding requests:  87%| | 445/512 [00:01<00:00, 426.77it/s]
Adding requests:  96%|| 491/512 [00:01<00:00, 435.00it/s]
Adding requests: 100%|| 512/512 [00:01<00:00, 422.04it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 2/512 [00:00<00:26, 19.40it/s, est. speed input: 19869.85 toks/s, output: 19.40 toks/s]
Processed prompts:   1%|          | 6/512 [00:01<01:36,  5.23it/s, est. speed input: 5778.69 toks/s, output: 5.64 toks/s]  
Processed prompts:   2%|         | 10/512 [00:02<01:47,  4.65it/s, est. speed input: 5083.51 toks/s, output: 4.96 toks/s]
Processed prompts:   3%|         | 14/512 [00:02<01:52,  4.44it/s, est. speed input: 4828.52 toks/s, output: 4.72 toks/s]
Processed prompts:   4%|         | 18/512 [00:03<01:53,  4.34it/s, est. speed input: 4691.84 toks/s, output: 4.58 toks/s]
Processed prompts:   4%|         | 22/512 [00:04<01:54,  4.28it/s, est. speed input: 4611.54 toks/s, output: 4.50 toks/s]
Processed prompts:   5%|         | 26/512 [00:05<01:54,  4.24it/s, est. speed input: 4556.11 toks/s, output: 4.45 toks/s]
Processed prompts:   6%|         | 30/512 [00:06<01:53,  4.23it/s, est. speed input: 4519.80 toks/s, output: 4.41 toks/s]
Processed prompts:   7%|         | 34/512 [00:07<01:53,  4.22it/s, est. speed input: 4491.19 toks/s, output: 4.39 toks/s]
Processed prompts:   7%|         | 38/512 [00:08<01:52,  4.21it/s, est. speed input: 4468.81 toks/s, output: 4.36 toks/s]
Processed prompts:   8%|         | 42/512 [00:09<01:51,  4.20it/s, est. speed input: 4450.15 toks/s, output: 4.35 toks/s]
Processed prompts:   9%|         | 46/512 [00:10<01:51,  4.19it/s, est. speed input: 4434.75 toks/s, output: 4.33 toks/s]
Processed prompts:  10%|         | 50/512 [00:11<01:50,  4.19it/s, est. speed input: 4421.88 toks/s, output: 4.32 toks/s]
Processed prompts:  11%|         | 54/512 [00:12<01:49,  4.18it/s, est. speed input: 4410.87 toks/s, output: 4.31 toks/s]
Processed prompts:  11%|        | 58/512 [00:13<01:48,  4.18it/s, est. speed input: 4401.69 toks/s, output: 4.30 toks/s]
Processed prompts:  12%|        | 62/512 [00:14<01:47,  4.18it/s, est. speed input: 4393.93 toks/s, output: 4.29 toks/s]
Processed prompts:  13%|        | 66/512 [00:15<01:46,  4.19it/s, est. speed input: 4387.44 toks/s, output: 4.28 toks/s]
Processed prompts:  14%|        | 70/512 [00:16<01:45,  4.18it/s, est. speed input: 4380.17 toks/s, output: 4.28 toks/s]
Processed prompts:  14%|        | 74/512 [00:17<01:44,  4.18it/s, est. speed input: 4375.31 toks/s, output: 4.27 toks/s]
Processed prompts:  15%|        | 78/512 [00:18<01:43,  4.18it/s, est. speed input: 4370.63 toks/s, output: 4.27 toks/s]
Processed prompts:  16%|        | 82/512 [00:19<01:42,  4.18it/s, est. speed input: 4365.28 toks/s, output: 4.26 toks/s]
Processed prompts:  17%|        | 86/512 [00:20<01:42,  4.18it/s, est. speed input: 4360.83 toks/s, output: 4.26 toks/s]
Processed prompts:  18%|        | 90/512 [00:21<01:41,  4.18it/s, est. speed input: 4357.12 toks/s, output: 4.26 toks/s]
Processed prompts:  18%|        | 94/512 [00:22<01:40,  4.17it/s, est. speed input: 4353.08 toks/s, output: 4.25 toks/s]
Processed prompts:  19%|        | 98/512 [00:23<01:39,  4.17it/s, est. speed input: 4349.38 toks/s, output: 4.25 toks/s]
Processed prompts:  20%|        | 102/512 [00:24<01:38,  4.17it/s, est. speed input: 4345.65 toks/s, output: 4.24 toks/s]
Processed prompts:  21%|        | 106/512 [00:24<01:37,  4.16it/s, est. speed input: 4342.37 toks/s, output: 4.24 toks/s]
Processed prompts:  21%|       | 110/512 [00:25<01:36,  4.16it/s, est. speed input: 4339.07 toks/s, output: 4.24 toks/s]
Processed prompts:  22%|       | 114/512 [00:26<01:35,  4.17it/s, est. speed input: 4337.23 toks/s, output: 4.24 toks/s]
Processed prompts:  23%|       | 118/512 [00:27<01:34,  4.16it/s, est. speed input: 4334.09 toks/s, output: 4.23 toks/s]
Processed prompts:  24%|       | 122/512 [00:28<01:33,  4.16it/s, est. speed input: 4331.67 toks/s, output: 4.23 toks/s]
Processed prompts:  25%|       | 126/512 [00:29<01:32,  4.16it/s, est. speed input: 4329.03 toks/s, output: 4.23 toks/s]
Processed prompts:  25%|       | 130/512 [00:30<01:33,  4.07it/s, est. speed input: 4317.05 toks/s, output: 4.22 toks/s]
Processed prompts:  26%|       | 134/512 [00:31<01:32,  4.10it/s, est. speed input: 4316.04 toks/s, output: 4.21 toks/s]
Processed prompts:  27%|       | 138/512 [00:32<01:30,  4.12it/s, est. speed input: 4314.67 toks/s, output: 4.21 toks/s]
Processed prompts:  28%|       | 142/512 [00:33<01:29,  4.13it/s, est. speed input: 4313.07 toks/s, output: 4.21 toks/s]
Processed prompts:  29%|       | 146/512 [00:34<01:28,  4.14it/s, est. speed input: 4311.39 toks/s, output: 4.21 toks/s]
Processed prompts:  29%|       | 150/512 [00:35<01:27,  4.15it/s, est. speed input: 4310.06 toks/s, output: 4.21 toks/s]
Processed prompts:  30%|       | 154/512 [00:36<01:26,  4.15it/s, est. speed input: 4308.54 toks/s, output: 4.21 toks/s]
Processed prompts:  31%|       | 158/512 [00:37<01:25,  4.15it/s, est. speed input: 4307.48 toks/s, output: 4.21 toks/s]
Processed prompts:  32%|      | 162/512 [00:38<01:24,  4.16it/s, est. speed input: 4306.83 toks/s, output: 4.21 toks/s]
Processed prompts:  32%|      | 166/512 [00:39<01:23,  4.16it/s, est. speed input: 4305.54 toks/s, output: 4.20 toks/s]
Processed prompts:  33%|      | 170/512 [00:40<01:22,  4.16it/s, est. speed input: 4304.14 toks/s, output: 4.20 toks/s]
Processed prompts:  34%|      | 174/512 [00:41<01:21,  4.16it/s, est. speed input: 4303.07 toks/s, output: 4.20 toks/s]
Processed prompts:  35%|      | 178/512 [00:42<01:20,  4.16it/s, est. speed input: 4302.25 toks/s, output: 4.20 toks/s]
Processed prompts:  36%|      | 182/512 [00:43<01:19,  4.16it/s, est. speed input: 4301.41 toks/s, output: 4.20 toks/s]
Processed prompts:  36%|      | 186/512 [00:44<01:18,  4.15it/s, est. speed input: 4300.07 toks/s, output: 4.20 toks/s]
Processed prompts:  37%|      | 190/512 [00:45<01:17,  4.15it/s, est. speed input: 4298.94 toks/s, output: 4.20 toks/s]
Processed prompts:  38%|      | 194/512 [00:46<01:16,  4.15it/s, est. speed input: 4298.11 toks/s, output: 4.20 toks/s]
Processed prompts:  39%|      | 198/512 [00:47<01:15,  4.16it/s, est. speed input: 4297.33 toks/s, output: 4.20 toks/s]
Processed prompts:  39%|      | 202/512 [00:47<01:10,  4.43it/s, est. speed input: 4314.07 toks/s, output: 4.21 toks/s]
Processed prompts:  40%|      | 206/512 [00:48<01:10,  4.35it/s, est. speed input: 4313.29 toks/s, output: 4.21 toks/s]
Processed prompts:  41%|      | 210/512 [00:49<01:10,  4.29it/s, est. speed input: 4312.11 toks/s, output: 4.21 toks/s]
Processed prompts:  42%|     | 214/512 [00:50<01:10,  4.24it/s, est. speed input: 4310.88 toks/s, output: 4.21 toks/s]
Processed prompts:  43%|     | 218/512 [00:51<01:09,  4.22it/s, est. speed input: 4309.79 toks/s, output: 4.21 toks/s]
Processed prompts:  43%|     | 222/512 [00:52<01:09,  4.20it/s, est. speed input: 4308.86 toks/s, output: 4.21 toks/s]
Processed prompts:  44%|     | 226/512 [00:53<01:08,  4.19it/s, est. speed input: 4307.91 toks/s, output: 4.21 toks/s]
Processed prompts:  45%|     | 230/512 [00:54<01:07,  4.18it/s, est. speed input: 4307.04 toks/s, output: 4.21 toks/s]
Processed prompts:  46%|     | 234/512 [00:55<01:06,  4.17it/s, est. speed input: 4306.01 toks/s, output: 4.21 toks/s]
Processed prompts:  46%|     | 238/512 [00:56<01:05,  4.16it/s, est. speed input: 4304.99 toks/s, output: 4.20 toks/s]
Processed prompts:  47%|     | 242/512 [00:57<01:04,  4.16it/s, est. speed input: 4304.36 toks/s, output: 4.20 toks/s]
Processed prompts:  48%|     | 246/512 [00:58<01:04,  4.15it/s, est. speed input: 4303.18 toks/s, output: 4.20 toks/s]
Processed prompts:  49%|     | 250/512 [00:59<01:03,  4.16it/s, est. speed input: 4302.51 toks/s, output: 4.20 toks/s]
Processed prompts:  50%|     | 254/512 [01:00<01:02,  4.16it/s, est. speed input: 4301.78 toks/s, output: 4.20 toks/s]
Processed prompts:  50%|     | 258/512 [01:01<01:01,  4.15it/s, est. speed input: 4300.79 toks/s, output: 4.20 toks/s]
Processed prompts:  51%|     | 262/512 [01:02<01:00,  4.15it/s, est. speed input: 4299.99 toks/s, output: 4.20 toks/s]
Processed prompts:  52%|    | 266/512 [01:03<00:59,  4.14it/s, est. speed input: 4298.53 toks/s, output: 4.20 toks/s]
Processed prompts:  53%|    | 270/512 [01:04<00:58,  4.14it/s, est. speed input: 4297.79 toks/s, output: 4.20 toks/s]
Processed prompts:  54%|    | 274/512 [01:05<00:57,  4.15it/s, est. speed input: 4297.50 toks/s, output: 4.20 toks/s]
Processed prompts:  54%|    | 278/512 [01:06<00:56,  4.15it/s, est. speed input: 4296.85 toks/s, output: 4.20 toks/s]
Processed prompts:  55%|    | 282/512 [01:07<00:55,  4.15it/s, est. speed input: 4296.21 toks/s, output: 4.20 toks/s]
Processed prompts:  56%|    | 286/512 [01:08<00:54,  4.15it/s, est. speed input: 4295.50 toks/s, output: 4.19 toks/s]
Processed prompts:  57%|    | 290/512 [01:09<00:53,  4.14it/s, est. speed input: 4294.53 toks/s, output: 4.19 toks/s]
Processed prompts:  57%|    | 294/512 [01:10<00:52,  4.15it/s, est. speed input: 4294.01 toks/s, output: 4.19 toks/s]
Processed prompts:  58%|    | 298/512 [01:11<00:51,  4.14it/s, est. speed input: 4293.23 toks/s, output: 4.19 toks/s]
Processed prompts:  59%|    | 302/512 [01:12<00:50,  4.14it/s, est. speed input: 4292.56 toks/s, output: 4.19 toks/s]
Processed prompts:  60%|    | 306/512 [01:12<00:46,  4.45it/s, est. speed input: 4304.90 toks/s, output: 4.20 toks/s]
Processed prompts:  61%|    | 310/512 [01:13<00:46,  4.36it/s, est. speed input: 4304.23 toks/s, output: 4.20 toks/s]
Processed prompts:  61%|   | 314/512 [01:14<00:46,  4.28it/s, est. speed input: 4303.21 toks/s, output: 4.20 toks/s]
Processed prompts:  62%|   | 318/512 [01:15<00:45,  4.25it/s, est. speed input: 4302.86 toks/s, output: 4.20 toks/s]
Processed prompts:  63%|   | 322/512 [01:16<00:45,  4.22it/s, est. speed input: 4302.19 toks/s, output: 4.20 toks/s]
Processed prompts:  64%|   | 326/512 [01:17<00:44,  4.20it/s, est. speed input: 4301.63 toks/s, output: 4.20 toks/s]
Processed prompts:  64%|   | 330/512 [01:18<00:43,  4.18it/s, est. speed input: 4300.82 toks/s, output: 4.20 toks/s]
Processed prompts:  65%|   | 334/512 [01:19<00:42,  4.17it/s, est. speed input: 4300.15 toks/s, output: 4.20 toks/s]
Processed prompts:  66%|   | 338/512 [01:20<00:41,  4.16it/s, est. speed input: 4299.54 toks/s, output: 4.20 toks/s]
Processed prompts:  67%|   | 342/512 [01:21<00:40,  4.16it/s, est. speed input: 4298.87 toks/s, output: 4.20 toks/s]
Processed prompts:  68%|   | 346/512 [01:22<00:39,  4.16it/s, est. speed input: 4298.38 toks/s, output: 4.20 toks/s]
Processed prompts:  68%|   | 350/512 [01:23<00:39,  4.15it/s, est. speed input: 4297.57 toks/s, output: 4.20 toks/s]
Processed prompts:  69%|   | 354/512 [01:24<00:38,  4.15it/s, est. speed input: 4296.93 toks/s, output: 4.20 toks/s]
Processed prompts:  70%|   | 358/512 [01:25<00:37,  4.15it/s, est. speed input: 4296.27 toks/s, output: 4.20 toks/s]
Processed prompts:  71%|   | 362/512 [01:26<00:36,  4.15it/s, est. speed input: 4295.86 toks/s, output: 4.20 toks/s]
Processed prompts:  71%|  | 366/512 [01:27<00:35,  4.15it/s, est. speed input: 4295.37 toks/s, output: 4.19 toks/s]
Processed prompts:  72%|  | 370/512 [01:28<00:34,  4.15it/s, est. speed input: 4294.98 toks/s, output: 4.19 toks/s]
Processed prompts:  73%|  | 374/512 [01:29<00:33,  4.15it/s, est. speed input: 4294.45 toks/s, output: 4.19 toks/s]
Processed prompts:  74%|  | 378/512 [01:30<00:32,  4.15it/s, est. speed input: 4293.92 toks/s, output: 4.19 toks/s]
Processed prompts:  75%|  | 382/512 [01:31<00:31,  4.15it/s, est. speed input: 4293.44 toks/s, output: 4.19 toks/s]
Processed prompts:  75%|  | 386/512 [01:32<00:30,  4.15it/s, est. speed input: 4292.94 toks/s, output: 4.19 toks/s]
Processed prompts:  76%|  | 390/512 [01:33<00:29,  4.15it/s, est. speed input: 4292.42 toks/s, output: 4.19 toks/s]
Processed prompts:  77%|  | 394/512 [01:34<00:28,  4.15it/s, est. speed input: 4292.01 toks/s, output: 4.19 toks/s]
Processed prompts:  78%|  | 398/512 [01:34<00:27,  4.15it/s, est. speed input: 4291.67 toks/s, output: 4.19 toks/s]
Processed prompts:  79%|  | 402/512 [01:35<00:26,  4.14it/s, est. speed input: 4291.03 toks/s, output: 4.19 toks/s]
Processed prompts:  79%|  | 406/512 [01:36<00:25,  4.14it/s, est. speed input: 4290.47 toks/s, output: 4.19 toks/s]
Processed prompts:  80%|  | 410/512 [01:37<00:24,  4.14it/s, est. speed input: 4290.08 toks/s, output: 4.19 toks/s]
Processed prompts:  81%|  | 414/512 [01:38<00:23,  4.14it/s, est. speed input: 4289.55 toks/s, output: 4.19 toks/s]
Processed prompts:  82%| | 418/512 [01:39<00:22,  4.14it/s, est. speed input: 4289.12 toks/s, output: 4.19 toks/s]
Processed prompts:  82%| | 422/512 [01:40<00:21,  4.14it/s, est. speed input: 4288.62 toks/s, output: 4.19 toks/s]
Processed prompts:  83%| | 426/512 [01:41<00:20,  4.15it/s, est. speed input: 4288.32 toks/s, output: 4.19 toks/s]
Processed prompts:  84%| | 430/512 [01:42<00:19,  4.14it/s, est. speed input: 4287.76 toks/s, output: 4.19 toks/s]
Processed prompts:  85%| | 434/512 [01:43<00:17,  4.44it/s, est. speed input: 4296.26 toks/s, output: 4.20 toks/s]
Processed prompts:  86%| | 438/512 [01:44<00:17,  4.35it/s, est. speed input: 4295.76 toks/s, output: 4.20 toks/s]
Processed prompts:  86%| | 442/512 [01:45<00:16,  4.28it/s, est. speed input: 4295.23 toks/s, output: 4.19 toks/s]
Processed prompts:  87%| | 446/512 [01:46<00:15,  4.24it/s, est. speed input: 4294.87 toks/s, output: 4.19 toks/s]
Processed prompts:  88%| | 450/512 [01:47<00:14,  4.21it/s, est. speed input: 4294.34 toks/s, output: 4.19 toks/s]
Processed prompts:  89%| | 454/512 [01:48<00:13,  4.19it/s, est. speed input: 4293.87 toks/s, output: 4.19 toks/s]
Processed prompts:  89%| | 458/512 [01:49<00:12,  4.17it/s, est. speed input: 4293.26 toks/s, output: 4.19 toks/s]
Processed prompts:  90%| | 462/512 [01:50<00:12,  4.16it/s, est. speed input: 4292.82 toks/s, output: 4.19 toks/s]
Processed prompts:  91%| | 466/512 [01:51<00:11,  4.16it/s, est. speed input: 4292.40 toks/s, output: 4.19 toks/s]
Processed prompts:  92%|| 470/512 [01:52<00:10,  4.16it/s, est. speed input: 4292.09 toks/s, output: 4.19 toks/s]
Processed prompts:  93%|| 474/512 [01:53<00:09,  4.15it/s, est. speed input: 4291.61 toks/s, output: 4.19 toks/s]
Processed prompts:  93%|| 478/512 [01:54<00:08,  4.14it/s, est. speed input: 4291.09 toks/s, output: 4.19 toks/s]
Processed prompts:  94%|| 482/512 [01:55<00:07,  4.14it/s, est. speed input: 4290.60 toks/s, output: 4.19 toks/s]
Processed prompts:  95%|| 486/512 [01:56<00:06,  4.14it/s, est. speed input: 4290.06 toks/s, output: 4.19 toks/s]
Processed prompts:  96%|| 490/512 [01:56<00:05,  4.14it/s, est. speed input: 4289.79 toks/s, output: 4.19 toks/s]
Processed prompts:  96%|| 494/512 [01:57<00:04,  4.14it/s, est. speed input: 4289.29 toks/s, output: 4.19 toks/s]
Processed prompts:  97%|| 498/512 [01:58<00:03,  4.14it/s, est. speed input: 4288.83 toks/s, output: 4.19 toks/s]
Processed prompts:  98%|| 502/512 [01:59<00:02,  4.13it/s, est. speed input: 4288.29 toks/s, output: 4.19 toks/s]
Processed prompts:  99%|| 506/512 [02:00<00:01,  4.13it/s, est. speed input: 4287.73 toks/s, output: 4.19 toks/s]
Processed prompts: 100%|| 510/512 [02:01<00:00,  4.43it/s, est. speed input: 4294.96 toks/s, output: 4.19 toks/s]
Processed prompts: 100%|| 512/512 [02:01<00:00,  4.43it/s, est. speed input: 4311.79 toks/s, output: 4.21 toks/s]
Processed prompts: 100%|| 512/512 [02:01<00:00,  4.21it/s, est. speed input: 4311.79 toks/s, output: 4.21 toks/s]
[rank0]:[W127 08:15:00.620062280 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-27 08:15:03
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Qwen2.5-14B-FP8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-27 08:15:14 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-27 08:15:14 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=2299949) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2299949) WARNING 01-27 08:16:56 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 4.10 requests/s, 4207.10 total tokens/s, 4.10 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-27 08:15:14] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 08:15:14] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 08:15:14] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 08:15:14] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:15:14] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:15:14] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:15:14] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:15:14] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:15:14] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 08:15:14] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 08:15:14] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 08:15:14] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 08:15:14] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 08:15:14] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-27 08:15:17] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 08:15:17] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 08:15:17] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 08:15:17] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:15:17] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:15:17] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:15:17] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:15:17] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:15:17] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 08:15:17] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 08:15:17] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 08:15:17] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 08:15:17] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 08:15:17] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=2299949) [2026-01-27 08:15:19] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=2299949) [2026-01-27 08:15:19] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2299949) [2026-01-27 08:15:19] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=2299949) [2026-01-27 08:15:19] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=2299949) [2026-01-27 08:15:19] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=2299949) [2026-01-27 08:15:19] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=2299949) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=2299949) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:26,  8.73s/it]
(EngineCore_DP0 pid=2299949) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:35<00:39, 19.57s/it]
(EngineCore_DP0 pid=2299949) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:57<00:20, 20.58s/it]
(EngineCore_DP0 pid=2299949) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:24<00:00, 23.19s/it]
(EngineCore_DP0 pid=2299949) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:24<00:00, 21.21s/it]
(EngineCore_DP0 pid=2299949) 
(EngineCore_DP0 pid=2299949) [2026-01-27 08:16:45] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 5120] -> 1D uint8
(EngineCore_DP0 pid=2299949) [2026-01-27 08:16:45] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 22937600 bytes
(EngineCore_DP0 pid=2299949) [2026-01-27 08:16:45] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 5120] -> 1D uint8
(EngineCore_DP0 pid=2299949) [2026-01-27 08:16:45] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16384000 bytes
(EngineCore_DP0 pid=2299949) [2026-01-27 08:16:45] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 5120] -> 1D uint8
(EngineCore_DP0 pid=2299949) [2026-01-27 08:16:45] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 88473600 bytes
(EngineCore_DP0 pid=2299949) [2026-01-27 08:16:45] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 13824] -> 1D uint8
(EngineCore_DP0 pid=2299949) [2026-01-27 08:16:45] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 44236800 bytes
(EngineCore_DP0 pid=2299949) 2026-01-27 08:16:53,491 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=2299949) 2026-01-27 08:16:54,415 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   0%|          | 1/1024 [00:00<06:01,  2.83it/s]
Adding requests:   0%|          | 3/1024 [00:00<02:47,  6.09it/s]
Adding requests:   0%|          | 5/1024 [00:00<01:50,  9.22it/s]
Adding requests:   1%|          | 9/1024 [00:00<01:02, 16.32it/s]
Adding requests:   2%|         | 19/1024 [00:00<00:26, 37.57it/s]
Adding requests:   5%|         | 47/1024 [00:00<00:09, 101.75it/s]
Adding requests:   8%|         | 78/1024 [00:01<00:05, 157.77it/s]
Adding requests:  12%|        | 119/1024 [00:01<00:03, 227.65it/s]
Adding requests:  16%|        | 163/1024 [00:01<00:03, 286.20it/s]
Adding requests:  20%|        | 209/1024 [00:01<00:02, 336.12it/s]
Adding requests:  25%|       | 253/1024 [00:01<00:02, 365.61it/s]
Adding requests:  29%|       | 298/1024 [00:01<00:01, 390.35it/s]
Adding requests:  34%|      | 345/1024 [00:01<00:01, 412.92it/s]
Adding requests:  38%|      | 392/1024 [00:01<00:01, 429.81it/s]
Adding requests:  43%|     | 439/1024 [00:01<00:01, 441.13it/s]
Adding requests:  47%|     | 484/1024 [00:02<00:01, 425.11it/s]
Adding requests:  52%|    | 533/1024 [00:02<00:01, 433.18it/s]
Adding requests:  56%|    | 577/1024 [00:02<00:01, 426.85it/s]
Adding requests:  61%|    | 620/1024 [00:02<00:00, 422.39it/s]
Adding requests:  65%|   | 663/1024 [00:02<00:00, 422.34it/s]
Adding requests:  69%|   | 708/1024 [00:02<00:00, 428.80it/s]
Adding requests:  73%|  | 751/1024 [00:02<00:00, 425.25it/s]
Adding requests:  78%|  | 795/1024 [00:02<00:00, 428.52it/s]
Adding requests:  82%| | 839/1024 [00:02<00:00, 431.00it/s]
Adding requests:  86%| | 884/1024 [00:02<00:00, 435.00it/s]
Adding requests:  91%| | 928/1024 [00:03<00:00, 432.37it/s]
Adding requests:  95%|| 973/1024 [00:03<00:00, 435.45it/s]
Adding requests:  99%|| 1017/1024 [00:03<00:00, 428.23it/s]
Adding requests: 100%|| 1024/1024 [00:03<00:00, 312.93it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 7/1024 [00:00<01:25, 11.96it/s, est. speed input: 12243.90 toks/s, output: 11.96 toks/s]
Processed prompts:   1%|         | 15/1024 [00:02<03:02,  5.52it/s, est. speed input: 6110.16 toks/s, output: 5.97 toks/s] 
Processed prompts:   2%|         | 23/1024 [00:04<03:30,  4.76it/s, est. speed input: 5288.75 toks/s, output: 5.16 toks/s]
Processed prompts:   3%|         | 31/1024 [00:06<03:41,  4.49it/s, est. speed input: 4968.50 toks/s, output: 4.85 toks/s]
Processed prompts:   4%|         | 39/1024 [00:08<03:46,  4.36it/s, est. speed input: 4801.61 toks/s, output: 4.69 toks/s]
Processed prompts:   5%|         | 47/1024 [00:10<03:48,  4.28it/s, est. speed input: 4693.59 toks/s, output: 4.58 toks/s]
Processed prompts:   5%|         | 55/1024 [00:12<03:49,  4.22it/s, est. speed input: 4617.21 toks/s, output: 4.51 toks/s]
Processed prompts:   6%|         | 63/1024 [00:14<03:49,  4.19it/s, est. speed input: 4562.32 toks/s, output: 4.46 toks/s]
Processed prompts:   7%|         | 71/1024 [00:16<03:48,  4.17it/s, est. speed input: 4520.99 toks/s, output: 4.42 toks/s]
Processed prompts:   8%|         | 79/1024 [00:18<03:47,  4.15it/s, est. speed input: 4487.73 toks/s, output: 4.38 toks/s]
Processed prompts:   8%|         | 87/1024 [00:19<03:45,  4.15it/s, est. speed input: 4464.11 toks/s, output: 4.36 toks/s]
Processed prompts:   9%|         | 95/1024 [00:21<03:44,  4.14it/s, est. speed input: 4441.64 toks/s, output: 4.34 toks/s]
Processed prompts:  10%|         | 103/1024 [00:23<03:42,  4.13it/s, est. speed input: 4422.90 toks/s, output: 4.32 toks/s]
Processed prompts:  11%|         | 111/1024 [00:25<03:41,  4.13it/s, est. speed input: 4407.98 toks/s, output: 4.30 toks/s]
Processed prompts:  12%|        | 119/1024 [00:27<03:39,  4.13it/s, est. speed input: 4395.41 toks/s, output: 4.29 toks/s]
Processed prompts:  12%|        | 127/1024 [00:29<03:39,  4.09it/s, est. speed input: 4376.53 toks/s, output: 4.27 toks/s]
Processed prompts:  13%|        | 135/1024 [00:31<03:36,  4.10it/s, est. speed input: 4366.99 toks/s, output: 4.26 toks/s]
Processed prompts:  14%|        | 143/1024 [00:33<03:34,  4.10it/s, est. speed input: 4357.53 toks/s, output: 4.26 toks/s]
Processed prompts:  15%|        | 151/1024 [00:35<03:32,  4.11it/s, est. speed input: 4349.53 toks/s, output: 4.25 toks/s]
Processed prompts:  16%|        | 159/1024 [00:37<03:30,  4.11it/s, est. speed input: 4341.93 toks/s, output: 4.24 toks/s]
Processed prompts:  16%|        | 167/1024 [00:39<03:28,  4.11it/s, est. speed input: 4335.81 toks/s, output: 4.23 toks/s]
Processed prompts:  17%|        | 175/1024 [00:41<03:26,  4.11it/s, est. speed input: 4330.36 toks/s, output: 4.23 toks/s]
Processed prompts:  18%|        | 183/1024 [00:43<03:24,  4.12it/s, est. speed input: 4325.40 toks/s, output: 4.22 toks/s]
Processed prompts:  19%|        | 191/1024 [00:45<03:22,  4.11it/s, est. speed input: 4320.56 toks/s, output: 4.22 toks/s]
Processed prompts:  19%|        | 199/1024 [00:47<03:14,  4.23it/s, est. speed input: 4332.84 toks/s, output: 4.23 toks/s]
Processed prompts:  20%|        | 207/1024 [00:48<03:14,  4.20it/s, est. speed input: 4327.98 toks/s, output: 4.23 toks/s]
Processed prompts:  21%|        | 215/1024 [00:50<03:13,  4.17it/s, est. speed input: 4323.52 toks/s, output: 4.22 toks/s]
Processed prompts:  22%|       | 223/1024 [00:52<03:12,  4.15it/s, est. speed input: 4319.18 toks/s, output: 4.22 toks/s]
Processed prompts:  23%|       | 231/1024 [00:54<03:11,  4.14it/s, est. speed input: 4315.17 toks/s, output: 4.21 toks/s]
Processed prompts:  23%|       | 239/1024 [00:56<03:10,  4.13it/s, est. speed input: 4311.51 toks/s, output: 4.21 toks/s]
Processed prompts:  24%|       | 247/1024 [00:58<03:08,  4.12it/s, est. speed input: 4308.11 toks/s, output: 4.21 toks/s]
Processed prompts:  25%|       | 255/1024 [01:00<03:06,  4.12it/s, est. speed input: 4304.49 toks/s, output: 4.20 toks/s]
Processed prompts:  26%|       | 263/1024 [01:02<03:04,  4.12it/s, est. speed input: 4301.61 toks/s, output: 4.20 toks/s]
Processed prompts:  26%|       | 271/1024 [01:04<03:02,  4.12it/s, est. speed input: 4299.06 toks/s, output: 4.20 toks/s]
Processed prompts:  27%|       | 279/1024 [01:06<03:01,  4.11it/s, est. speed input: 4296.32 toks/s, output: 4.20 toks/s]
Processed prompts:  28%|       | 287/1024 [01:08<02:59,  4.11it/s, est. speed input: 4293.68 toks/s, output: 4.19 toks/s]
Processed prompts:  29%|       | 295/1024 [01:10<02:57,  4.11it/s, est. speed input: 4291.25 toks/s, output: 4.19 toks/s]
Processed prompts:  30%|       | 303/1024 [01:12<02:50,  4.24it/s, est. speed input: 4300.79 toks/s, output: 4.20 toks/s]
Processed prompts:  30%|       | 311/1024 [01:14<02:49,  4.20it/s, est. speed input: 4298.31 toks/s, output: 4.20 toks/s]
Processed prompts:  31%|       | 319/1024 [01:16<02:49,  4.17it/s, est. speed input: 4295.70 toks/s, output: 4.20 toks/s]
Processed prompts:  32%|      | 327/1024 [01:17<02:47,  4.15it/s, est. speed input: 4293.51 toks/s, output: 4.19 toks/s]
Processed prompts:  33%|      | 335/1024 [01:19<02:46,  4.14it/s, est. speed input: 4291.28 toks/s, output: 4.19 toks/s]
Processed prompts:  33%|      | 343/1024 [01:21<02:45,  4.12it/s, est. speed input: 4289.01 toks/s, output: 4.19 toks/s]
Processed prompts:  34%|      | 351/1024 [01:23<02:43,  4.12it/s, est. speed input: 4287.40 toks/s, output: 4.19 toks/s]
Processed prompts:  35%|      | 359/1024 [01:25<02:41,  4.12it/s, est. speed input: 4285.44 toks/s, output: 4.18 toks/s]
Processed prompts:  36%|      | 367/1024 [01:27<02:39,  4.12it/s, est. speed input: 4283.77 toks/s, output: 4.18 toks/s]
Processed prompts:  37%|      | 375/1024 [01:29<02:37,  4.11it/s, est. speed input: 4282.10 toks/s, output: 4.18 toks/s]
Processed prompts:  37%|      | 383/1024 [01:31<02:35,  4.11it/s, est. speed input: 4280.32 toks/s, output: 4.18 toks/s]
Processed prompts:  38%|      | 391/1024 [01:33<02:34,  4.11it/s, est. speed input: 4278.83 toks/s, output: 4.18 toks/s]
Processed prompts:  39%|      | 399/1024 [01:35<02:32,  4.11it/s, est. speed input: 4277.39 toks/s, output: 4.18 toks/s]
Processed prompts:  40%|      | 407/1024 [01:37<02:30,  4.11it/s, est. speed input: 4275.97 toks/s, output: 4.18 toks/s]
Processed prompts:  41%|      | 415/1024 [01:39<02:28,  4.10it/s, est. speed input: 4274.13 toks/s, output: 4.17 toks/s]
Processed prompts:  41%|     | 423/1024 [01:41<02:26,  4.10it/s, est. speed input: 4272.53 toks/s, output: 4.17 toks/s]
Processed prompts:  42%|     | 431/1024 [01:43<02:20,  4.23it/s, est. speed input: 4279.39 toks/s, output: 4.18 toks/s]
Processed prompts:  43%|     | 439/1024 [01:45<02:19,  4.19it/s, est. speed input: 4278.12 toks/s, output: 4.18 toks/s]
Processed prompts:  44%|     | 447/1024 [01:47<02:18,  4.16it/s, est. speed input: 4276.67 toks/s, output: 4.18 toks/s]
Processed prompts:  44%|     | 455/1024 [01:48<02:17,  4.15it/s, est. speed input: 4275.45 toks/s, output: 4.18 toks/s]
Processed prompts:  45%|     | 463/1024 [01:50<02:15,  4.13it/s, est. speed input: 4274.13 toks/s, output: 4.17 toks/s]
Processed prompts:  46%|     | 471/1024 [01:52<02:14,  4.13it/s, est. speed input: 4272.90 toks/s, output: 4.17 toks/s]
Processed prompts:  47%|     | 479/1024 [01:54<02:12,  4.12it/s, est. speed input: 4271.72 toks/s, output: 4.17 toks/s]
Processed prompts:  48%|     | 487/1024 [01:56<02:10,  4.12it/s, est. speed input: 4270.76 toks/s, output: 4.17 toks/s]
Processed prompts:  48%|     | 495/1024 [01:58<02:08,  4.11it/s, est. speed input: 4269.61 toks/s, output: 4.17 toks/s]
Processed prompts:  49%|     | 503/1024 [02:00<02:06,  4.11it/s, est. speed input: 4268.46 toks/s, output: 4.17 toks/s]
Processed prompts:  50%|     | 511/1024 [02:02<02:04,  4.11it/s, est. speed input: 4267.43 toks/s, output: 4.17 toks/s]
Processed prompts:  51%|     | 519/1024 [02:04<02:03,  4.10it/s, est. speed input: 4266.31 toks/s, output: 4.17 toks/s]
Processed prompts:  51%|    | 527/1024 [02:06<02:01,  4.10it/s, est. speed input: 4265.33 toks/s, output: 4.17 toks/s]
Processed prompts:  52%|    | 535/1024 [02:08<01:59,  4.11it/s, est. speed input: 4264.52 toks/s, output: 4.16 toks/s]
Processed prompts:  53%|    | 543/1024 [02:10<01:57,  4.11it/s, est. speed input: 4263.60 toks/s, output: 4.16 toks/s]
Processed prompts:  54%|    | 551/1024 [02:12<01:55,  4.11it/s, est. speed input: 4262.72 toks/s, output: 4.16 toks/s]
Processed prompts:  55%|    | 559/1024 [02:14<01:53,  4.10it/s, est. speed input: 4261.80 toks/s, output: 4.16 toks/s]
Processed prompts:  55%|    | 567/1024 [02:16<01:51,  4.10it/s, est. speed input: 4260.91 toks/s, output: 4.16 toks/s]
Processed prompts:  56%|    | 575/1024 [02:18<01:49,  4.11it/s, est. speed input: 4260.17 toks/s, output: 4.16 toks/s]
Processed prompts:  57%|    | 583/1024 [02:20<01:47,  4.11it/s, est. speed input: 4259.41 toks/s, output: 4.16 toks/s]
Processed prompts:  58%|    | 591/1024 [02:22<01:45,  4.10it/s, est. speed input: 4258.53 toks/s, output: 4.16 toks/s]
Processed prompts:  58%|    | 599/1024 [02:24<01:43,  4.09it/s, est. speed input: 4257.36 toks/s, output: 4.16 toks/s]
Processed prompts:  59%|    | 607/1024 [02:26<01:42,  4.08it/s, est. speed input: 4255.85 toks/s, output: 4.16 toks/s]
Processed prompts:  60%|    | 615/1024 [02:28<01:40,  4.06it/s, est. speed input: 4254.04 toks/s, output: 4.15 toks/s]
Processed prompts:  61%|    | 623/1024 [02:29<01:38,  4.08it/s, est. speed input: 4253.35 toks/s, output: 4.15 toks/s]
Processed prompts:  62%|   | 631/1024 [02:31<01:36,  4.09it/s, est. speed input: 4252.76 toks/s, output: 4.15 toks/s]
Processed prompts:  62%|   | 639/1024 [02:33<01:34,  4.08it/s, est. speed input: 4251.81 toks/s, output: 4.15 toks/s]
Processed prompts:  63%|   | 647/1024 [02:35<01:32,  4.09it/s, est. speed input: 4251.03 toks/s, output: 4.15 toks/s]
Processed prompts:  64%|   | 655/1024 [02:37<01:30,  4.09it/s, est. speed input: 4250.43 toks/s, output: 4.15 toks/s]
Processed prompts:  65%|   | 663/1024 [02:39<01:28,  4.10it/s, est. speed input: 4250.01 toks/s, output: 4.15 toks/s]
Processed prompts:  66%|   | 671/1024 [02:41<01:26,  4.10it/s, est. speed input: 4249.38 toks/s, output: 4.15 toks/s]
Processed prompts:  66%|   | 679/1024 [02:43<01:24,  4.10it/s, est. speed input: 4248.95 toks/s, output: 4.15 toks/s]
Processed prompts:  67%|   | 687/1024 [02:45<01:22,  4.10it/s, est. speed input: 4248.32 toks/s, output: 4.15 toks/s]
Processed prompts:  68%|   | 695/1024 [02:47<01:20,  4.11it/s, est. speed input: 4247.90 toks/s, output: 4.15 toks/s]
Processed prompts:  69%|   | 703/1024 [02:49<01:18,  4.10it/s, est. speed input: 4247.37 toks/s, output: 4.15 toks/s]
Processed prompts:  69%|   | 711/1024 [02:51<01:16,  4.10it/s, est. speed input: 4246.86 toks/s, output: 4.15 toks/s]
Processed prompts:  70%|   | 719/1024 [02:53<01:14,  4.10it/s, est. speed input: 4246.35 toks/s, output: 4.15 toks/s]
Processed prompts:  71%|   | 727/1024 [02:55<01:12,  4.11it/s, est. speed input: 4245.97 toks/s, output: 4.15 toks/s]
Processed prompts:  72%|  | 735/1024 [02:57<01:10,  4.11it/s, est. speed input: 4245.50 toks/s, output: 4.15 toks/s]
Processed prompts:  73%|  | 743/1024 [02:59<01:08,  4.10it/s, est. speed input: 4244.93 toks/s, output: 4.15 toks/s]
Processed prompts:  73%|  | 751/1024 [03:01<01:06,  4.10it/s, est. speed input: 4244.47 toks/s, output: 4.14 toks/s]
Processed prompts:  74%|  | 759/1024 [03:03<01:04,  4.10it/s, est. speed input: 4243.87 toks/s, output: 4.14 toks/s]
Processed prompts:  75%|  | 767/1024 [03:05<01:02,  4.10it/s, est. speed input: 4243.47 toks/s, output: 4.14 toks/s]
Processed prompts:  76%|  | 775/1024 [03:07<01:00,  4.10it/s, est. speed input: 4243.11 toks/s, output: 4.14 toks/s]
Processed prompts:  76%|  | 783/1024 [03:08<00:56,  4.24it/s, est. speed input: 4247.21 toks/s, output: 4.15 toks/s]
Processed prompts:  77%|  | 791/1024 [03:10<00:55,  4.20it/s, est. speed input: 4246.86 toks/s, output: 4.15 toks/s]
Processed prompts:  78%|  | 799/1024 [03:12<00:53,  4.17it/s, est. speed input: 4246.34 toks/s, output: 4.15 toks/s]
Processed prompts:  79%|  | 807/1024 [03:14<00:52,  4.14it/s, est. speed input: 4245.71 toks/s, output: 4.15 toks/s]
Processed prompts:  80%|  | 815/1024 [03:16<00:50,  4.13it/s, est. speed input: 4245.34 toks/s, output: 4.15 toks/s]
Processed prompts:  80%|  | 823/1024 [03:18<00:48,  4.12it/s, est. speed input: 4244.89 toks/s, output: 4.15 toks/s]
Processed prompts:  81%|  | 831/1024 [03:20<00:46,  4.11it/s, est. speed input: 4244.35 toks/s, output: 4.14 toks/s]
Processed prompts:  82%| | 839/1024 [03:22<00:45,  4.10it/s, est. speed input: 4243.44 toks/s, output: 4.14 toks/s]
Processed prompts:  83%| | 847/1024 [03:24<00:43,  4.09it/s, est. speed input: 4242.91 toks/s, output: 4.14 toks/s]
Processed prompts:  83%| | 855/1024 [03:26<00:41,  4.09it/s, est. speed input: 4242.46 toks/s, output: 4.14 toks/s]
Processed prompts:  84%| | 863/1024 [03:28<00:39,  4.09it/s, est. speed input: 4241.94 toks/s, output: 4.14 toks/s]
Processed prompts:  85%| | 871/1024 [03:30<00:37,  4.08it/s, est. speed input: 4241.02 toks/s, output: 4.14 toks/s]
Processed prompts:  86%| | 879/1024 [03:32<00:35,  4.06it/s, est. speed input: 4239.79 toks/s, output: 4.14 toks/s]
Processed prompts:  87%| | 887/1024 [03:34<00:33,  4.05it/s, est. speed input: 4238.71 toks/s, output: 4.14 toks/s]
Processed prompts:  87%| | 895/1024 [03:36<00:31,  4.04it/s, est. speed input: 4237.59 toks/s, output: 4.14 toks/s]
Processed prompts:  88%| | 903/1024 [03:38<00:29,  4.05it/s, est. speed input: 4236.85 toks/s, output: 4.14 toks/s]
Processed prompts:  89%| | 911/1024 [03:40<00:27,  4.06it/s, est. speed input: 4236.31 toks/s, output: 4.14 toks/s]
Processed prompts:  90%| | 919/1024 [03:42<00:25,  4.07it/s, est. speed input: 4236.05 toks/s, output: 4.14 toks/s]
Processed prompts:  91%| | 927/1024 [03:44<00:23,  4.08it/s, est. speed input: 4235.69 toks/s, output: 4.14 toks/s]
Processed prompts:  91%|| 935/1024 [03:46<00:21,  4.08it/s, est. speed input: 4235.33 toks/s, output: 4.14 toks/s]
Processed prompts:  92%|| 943/1024 [03:48<00:19,  4.09it/s, est. speed input: 4234.99 toks/s, output: 4.14 toks/s]
Processed prompts:  93%|| 951/1024 [03:49<00:17,  4.09it/s, est. speed input: 4234.66 toks/s, output: 4.14 toks/s]
Processed prompts:  94%|| 959/1024 [03:51<00:15,  4.09it/s, est. speed input: 4234.25 toks/s, output: 4.14 toks/s]
Processed prompts:  94%|| 967/1024 [03:53<00:13,  4.09it/s, est. speed input: 4233.93 toks/s, output: 4.13 toks/s]
Processed prompts:  95%|| 975/1024 [03:55<00:11,  4.09it/s, est. speed input: 4233.57 toks/s, output: 4.13 toks/s]
Processed prompts:  96%|| 983/1024 [03:57<00:10,  4.10it/s, est. speed input: 4233.29 toks/s, output: 4.13 toks/s]
Processed prompts:  97%|| 991/1024 [03:59<00:08,  4.10it/s, est. speed input: 4233.01 toks/s, output: 4.13 toks/s]
Processed prompts:  98%|| 999/1024 [04:01<00:06,  4.10it/s, est. speed input: 4232.66 toks/s, output: 4.13 toks/s]
Processed prompts:  98%|| 1007/1024 [04:03<00:04,  4.09it/s, est. speed input: 4232.19 toks/s, output: 4.13 toks/s]
Processed prompts:  99%|| 1015/1024 [04:05<00:02,  4.09it/s, est. speed input: 4231.96 toks/s, output: 4.13 toks/s]
Processed prompts: 100%|| 1023/1024 [04:06<00:00,  5.24it/s, est. speed input: 4256.06 toks/s, output: 4.16 toks/s]
Processed prompts: 100%|| 1024/1024 [04:06<00:00,  5.24it/s, est. speed input: 4260.22 toks/s, output: 4.16 toks/s]
Processed prompts: 100%|| 1024/1024 [04:06<00:00,  4.16it/s, est. speed input: 4260.22 toks/s, output: 4.16 toks/s]
[rank0]:[W127 08:21:06.733278804 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-27 08:21:19
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Qwen2.5-14B-FP8_M16384.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-27 08:21:32 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-27 08:21:32 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=2306759) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2306759) WARNING 01-27 08:23:27 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 1.10 requests/s, 1131.80 total tokens/s, 1.10 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-27 08:21:32] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 08:21:32] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 08:21:32] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 08:21:32] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:21:32] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:21:32] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:21:32] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:21:32] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:21:32] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 08:21:32] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 08:21:32] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 08:21:32] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 08:21:32] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 08:21:32] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-27 08:21:35] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 08:21:35] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 08:21:35] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 08:21:35] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:21:35] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:21:35] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:21:35] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:21:35] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:21:35] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 08:21:35] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 08:21:35] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 08:21:35] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 08:21:35] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 08:21:35] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=2306759) [2026-01-27 08:21:37] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=2306759) [2026-01-27 08:21:37] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2306759) [2026-01-27 08:21:37] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=2306759) [2026-01-27 08:21:37] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=2306759) [2026-01-27 08:21:37] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=2306759) [2026-01-27 08:21:37] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=2306759) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=2306759) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:24,  8.14s/it]
(EngineCore_DP0 pid=2306759) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:34<00:38, 19.07s/it]
(EngineCore_DP0 pid=2306759) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:56<00:20, 20.25s/it]
(EngineCore_DP0 pid=2306759) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:23<00:00, 22.80s/it]
(EngineCore_DP0 pid=2306759) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:23<00:00, 20.81s/it]
(EngineCore_DP0 pid=2306759) 
(EngineCore_DP0 pid=2306759) [2026-01-27 08:23:01] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 5120] -> 1D uint8
(EngineCore_DP0 pid=2306759) [2026-01-27 08:23:01] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 22937600 bytes
(EngineCore_DP0 pid=2306759) [2026-01-27 08:23:01] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 5120] -> 1D uint8
(EngineCore_DP0 pid=2306759) [2026-01-27 08:23:01] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16384000 bytes
(EngineCore_DP0 pid=2306759) [2026-01-27 08:23:01] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 5120] -> 1D uint8
(EngineCore_DP0 pid=2306759) [2026-01-27 08:23:01] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 88473600 bytes
(EngineCore_DP0 pid=2306759) [2026-01-27 08:23:01] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 13824] -> 1D uint8
(EngineCore_DP0 pid=2306759) [2026-01-27 08:23:01] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 44236800 bytes
(EngineCore_DP0 pid=2306759) 2026-01-27 08:23:11,841 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=2306759) 2026-01-27 08:23:15,962 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   2%|         | 46/2048 [00:00<00:04, 459.64it/s]
Adding requests:   4%|         | 92/2048 [00:00<00:04, 392.44it/s]
Adding requests:   6%|         | 132/2048 [00:00<00:05, 370.53it/s]
Adding requests:   9%|         | 175/2048 [00:00<00:04, 391.67it/s]
Adding requests:  11%|         | 229/2048 [00:00<00:04, 440.90it/s]
Adding requests:  14%|        | 281/2048 [00:00<00:03, 464.10it/s]
Adding requests:  16%|        | 328/2048 [00:00<00:03, 461.87it/s]
Adding requests:  19%|        | 385/2048 [00:00<00:03, 494.21it/s]
Adding requests:  22%|       | 442/2048 [00:00<00:03, 516.18it/s]
Adding requests:  24%|       | 494/2048 [00:01<00:03, 512.06it/s]
Adding requests:  27%|       | 553/2048 [00:01<00:02, 534.03it/s]
Adding requests:  30%|       | 607/2048 [00:01<00:02, 534.19it/s]
Adding requests:  32%|      | 661/2048 [00:01<00:02, 515.44it/s]
Adding requests:  35%|      | 717/2048 [00:01<00:02, 527.20it/s]
Adding requests:  38%|      | 770/2048 [00:01<00:02, 523.54it/s]
Adding requests:  40%|      | 823/2048 [00:01<00:02, 514.18it/s]
Adding requests:  43%|     | 878/2048 [00:01<00:02, 522.27it/s]
Adding requests:  45%|     | 931/2048 [00:01<00:02, 523.47it/s]
Adding requests:  48%|     | 984/2048 [00:02<00:02, 358.54it/s]
Adding requests:  50%|     | 1030/2048 [00:02<00:02, 381.07it/s]
Adding requests:  53%|    | 1084/2048 [00:02<00:02, 418.51it/s]
Adding requests:  56%|    | 1139/2048 [00:02<00:02, 450.46it/s]
Adding requests:  58%|    | 1188/2048 [00:02<00:01, 446.38it/s]
Adding requests:  61%|    | 1245/2048 [00:02<00:01, 477.96it/s]
Adding requests:  63%|   | 1299/2048 [00:02<00:01, 493.33it/s]
Adding requests:  66%|   | 1350/2048 [00:02<00:01, 488.01it/s]
Adding requests:  69%|   | 1405/2048 [00:02<00:01, 504.28it/s]
Adding requests:  71%|  | 1460/2048 [00:03<00:01, 514.52it/s]
Adding requests:  74%|  | 1513/2048 [00:03<00:01, 510.80it/s]
Adding requests:  76%|  | 1565/2048 [00:03<00:00, 512.61it/s]
Adding requests:  79%|  | 1618/2048 [00:03<00:00, 511.87it/s]
Adding requests:  82%| | 1670/2048 [00:03<00:00, 492.64it/s]
Adding requests:  84%| | 1727/2048 [00:03<00:00, 512.90it/s]
Adding requests:  87%| | 1782/2048 [00:03<00:00, 521.20it/s]
Adding requests:  90%| | 1835/2048 [00:03<00:00, 510.67it/s]
Adding requests:  92%|| 1891/2048 [00:03<00:00, 523.87it/s]
Adding requests:  95%|| 1944/2048 [00:04<00:00, 523.68it/s]
Adding requests:  98%|| 1997/2048 [00:04<00:00, 513.79it/s]
Adding requests: 100%|| 2048/2048 [00:04<00:00, 486.08it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 2/2048 [00:10<3:01:29,  5.32s/it, est. speed input: 192.39 toks/s, output: 0.19 toks/s]
Processed prompts:   1%|          | 18/2048 [00:25<42:39,  1.26s/it, est. speed input: 733.46 toks/s, output: 0.72 toks/s] 
Processed prompts:   2%|         | 34/2048 [00:39<35:32,  1.06s/it, est. speed input: 878.98 toks/s, output: 0.86 toks/s]
Processed prompts:   2%|         | 50/2048 [00:54<32:57,  1.01it/s, est. speed input: 946.56 toks/s, output: 0.92 toks/s]
Processed prompts:   3%|         | 66/2048 [01:08<31:37,  1.04it/s, est. speed input: 985.33 toks/s, output: 0.96 toks/s]
Processed prompts:   4%|         | 82/2048 [01:23<30:45,  1.07it/s, est. speed input: 1010.68 toks/s, output: 0.99 toks/s]
Processed prompts:   5%|         | 98/2048 [01:37<30:09,  1.08it/s, est. speed input: 1028.44 toks/s, output: 1.00 toks/s]
Processed prompts:   6%|         | 114/2048 [01:52<29:40,  1.09it/s, est. speed input: 1041.64 toks/s, output: 1.02 toks/s]
Processed prompts:   6%|         | 130/2048 [02:06<29:17,  1.09it/s, est. speed input: 1051.53 toks/s, output: 1.03 toks/s]
Processed prompts:   7%|         | 146/2048 [02:21<28:56,  1.10it/s, est. speed input: 1059.64 toks/s, output: 1.03 toks/s]
Processed prompts:   8%|         | 162/2048 [02:35<28:37,  1.10it/s, est. speed input: 1066.25 toks/s, output: 1.04 toks/s]
Processed prompts:   9%|         | 178/2048 [02:50<28:20,  1.10it/s, est. speed input: 1071.70 toks/s, output: 1.05 toks/s]
Processed prompts:   9%|         | 194/2048 [03:04<28:12,  1.10it/s, est. speed input: 1074.94 toks/s, output: 1.05 toks/s]
Processed prompts:  10%|         | 210/2048 [03:19<27:56,  1.10it/s, est. speed input: 1078.64 toks/s, output: 1.05 toks/s]
Processed prompts:  11%|         | 226/2048 [03:33<27:37,  1.10it/s, est. speed input: 1082.18 toks/s, output: 1.06 toks/s]
Processed prompts:  12%|        | 242/2048 [03:48<27:27,  1.10it/s, est. speed input: 1084.28 toks/s, output: 1.06 toks/s]
Processed prompts:  13%|        | 258/2048 [04:03<27:09,  1.10it/s, est. speed input: 1087.03 toks/s, output: 1.06 toks/s]
Processed prompts:  13%|        | 274/2048 [04:17<26:52,  1.10it/s, est. speed input: 1089.44 toks/s, output: 1.06 toks/s]
Processed prompts:  14%|        | 290/2048 [04:32<26:38,  1.10it/s, est. speed input: 1091.35 toks/s, output: 1.07 toks/s]
Processed prompts:  15%|        | 306/2048 [04:46<26:28,  1.10it/s, est. speed input: 1092.59 toks/s, output: 1.07 toks/s]
Processed prompts:  16%|        | 322/2048 [05:01<26:12,  1.10it/s, est. speed input: 1094.21 toks/s, output: 1.07 toks/s]
Processed prompts:  17%|        | 338/2048 [05:15<25:54,  1.10it/s, est. speed input: 1095.93 toks/s, output: 1.07 toks/s]
Processed prompts:  17%|        | 354/2048 [05:30<25:39,  1.10it/s, est. speed input: 1097.38 toks/s, output: 1.07 toks/s]
Processed prompts:  18%|        | 370/2048 [05:44<25:22,  1.10it/s, est. speed input: 1098.81 toks/s, output: 1.07 toks/s]
Processed prompts:  19%|        | 386/2048 [05:59<25:08,  1.10it/s, est. speed input: 1100.01 toks/s, output: 1.07 toks/s]
Processed prompts:  20%|        | 402/2048 [06:13<24:51,  1.10it/s, est. speed input: 1101.29 toks/s, output: 1.08 toks/s]
Processed prompts:  20%|        | 418/2048 [06:28<24:36,  1.10it/s, est. speed input: 1102.44 toks/s, output: 1.08 toks/s]
Processed prompts:  21%|        | 434/2048 [06:43<24:30,  1.10it/s, est. speed input: 1102.67 toks/s, output: 1.08 toks/s]
Processed prompts:  22%|       | 450/2048 [06:57<24:12,  1.10it/s, est. speed input: 1103.71 toks/s, output: 1.08 toks/s]
Processed prompts:  23%|       | 466/2048 [07:12<23:57,  1.10it/s, est. speed input: 1104.53 toks/s, output: 1.08 toks/s]
Processed prompts:  24%|       | 482/2048 [07:26<23:40,  1.10it/s, est. speed input: 1105.47 toks/s, output: 1.08 toks/s]
Processed prompts:  24%|       | 498/2048 [07:40<23:25,  1.10it/s, est. speed input: 1106.20 toks/s, output: 1.08 toks/s]
Processed prompts:  25%|       | 514/2048 [07:55<23:09,  1.10it/s, est. speed input: 1107.02 toks/s, output: 1.08 toks/s]
Processed prompts:  26%|       | 530/2048 [08:09<22:55,  1.10it/s, est. speed input: 1107.67 toks/s, output: 1.08 toks/s]
Processed prompts:  27%|       | 546/2048 [08:24<22:39,  1.10it/s, est. speed input: 1108.41 toks/s, output: 1.08 toks/s]
Processed prompts:  27%|       | 562/2048 [08:38<22:26,  1.10it/s, est. speed input: 1109.00 toks/s, output: 1.08 toks/s]
Processed prompts:  28%|       | 578/2048 [08:53<22:10,  1.11it/s, est. speed input: 1109.68 toks/s, output: 1.08 toks/s]
Processed prompts:  29%|       | 594/2048 [09:07<21:55,  1.11it/s, est. speed input: 1110.30 toks/s, output: 1.08 toks/s]
Processed prompts:  30%|       | 610/2048 [09:22<21:41,  1.10it/s, est. speed input: 1110.79 toks/s, output: 1.08 toks/s]
Processed prompts:  31%|       | 626/2048 [09:36<21:26,  1.11it/s, est. speed input: 1111.38 toks/s, output: 1.09 toks/s]
Processed prompts:  31%|      | 642/2048 [09:51<21:12,  1.10it/s, est. speed input: 1111.83 toks/s, output: 1.09 toks/s]
Processed prompts:  32%|      | 658/2048 [10:05<20:57,  1.11it/s, est. speed input: 1112.36 toks/s, output: 1.09 toks/s]
Processed prompts:  33%|      | 674/2048 [10:20<20:43,  1.10it/s, est. speed input: 1112.76 toks/s, output: 1.09 toks/s]
Processed prompts:  34%|      | 690/2048 [10:34<20:27,  1.11it/s, est. speed input: 1113.28 toks/s, output: 1.09 toks/s]
Processed prompts:  34%|      | 706/2048 [10:49<20:14,  1.11it/s, est. speed input: 1113.65 toks/s, output: 1.09 toks/s]
Processed prompts:  35%|      | 722/2048 [11:03<19:59,  1.11it/s, est. speed input: 1114.09 toks/s, output: 1.09 toks/s]
Processed prompts:  36%|      | 738/2048 [11:18<19:43,  1.11it/s, est. speed input: 1114.53 toks/s, output: 1.09 toks/s]
Processed prompts:  37%|      | 754/2048 [11:32<19:30,  1.11it/s, est. speed input: 1114.85 toks/s, output: 1.09 toks/s]
Processed prompts:  38%|      | 770/2048 [11:47<19:15,  1.11it/s, est. speed input: 1115.24 toks/s, output: 1.09 toks/s]
Processed prompts:  38%|      | 786/2048 [12:01<19:06,  1.10it/s, est. speed input: 1115.21 toks/s, output: 1.09 toks/s]
Processed prompts:  39%|      | 802/2048 [12:16<18:49,  1.10it/s, est. speed input: 1115.59 toks/s, output: 1.09 toks/s]
Processed prompts:  40%|      | 818/2048 [12:30<18:35,  1.10it/s, est. speed input: 1115.88 toks/s, output: 1.09 toks/s]
Processed prompts:  41%|      | 834/2048 [12:45<18:19,  1.10it/s, est. speed input: 1116.23 toks/s, output: 1.09 toks/s]
Processed prompts:  42%|     | 850/2048 [12:59<18:04,  1.10it/s, est. speed input: 1116.49 toks/s, output: 1.09 toks/s]
Processed prompts:  42%|     | 866/2048 [13:14<17:49,  1.11it/s, est. speed input: 1116.83 toks/s, output: 1.09 toks/s]
Processed prompts:  43%|     | 882/2048 [13:28<17:34,  1.11it/s, est. speed input: 1117.10 toks/s, output: 1.09 toks/s]
Processed prompts:  44%|     | 898/2048 [13:42<17:19,  1.11it/s, est. speed input: 1117.42 toks/s, output: 1.09 toks/s]
Processed prompts:  45%|     | 914/2048 [13:57<17:04,  1.11it/s, est. speed input: 1117.71 toks/s, output: 1.09 toks/s]
Processed prompts:  45%|     | 930/2048 [14:11<16:50,  1.11it/s, est. speed input: 1117.96 toks/s, output: 1.09 toks/s]
Processed prompts:  46%|     | 946/2048 [14:26<16:35,  1.11it/s, est. speed input: 1118.24 toks/s, output: 1.09 toks/s]
Processed prompts:  47%|     | 962/2048 [14:40<16:21,  1.11it/s, est. speed input: 1118.48 toks/s, output: 1.09 toks/s]
Processed prompts:  48%|     | 978/2048 [14:55<16:06,  1.11it/s, est. speed input: 1118.74 toks/s, output: 1.09 toks/s]
Processed prompts:  49%|     | 994/2048 [15:09<15:52,  1.11it/s, est. speed input: 1118.93 toks/s, output: 1.09 toks/s]
Processed prompts:  49%|     | 1010/2048 [15:24<15:37,  1.11it/s, est. speed input: 1119.18 toks/s, output: 1.09 toks/s]
Processed prompts:  50%|     | 1026/2048 [15:38<15:23,  1.11it/s, est. speed input: 1119.38 toks/s, output: 1.09 toks/s]
Processed prompts:  51%|     | 1042/2048 [15:53<15:08,  1.11it/s, est. speed input: 1119.61 toks/s, output: 1.09 toks/s]
Processed prompts:  52%|    | 1058/2048 [16:07<14:54,  1.11it/s, est. speed input: 1119.83 toks/s, output: 1.09 toks/s]
Processed prompts:  52%|    | 1074/2048 [16:21<14:40,  1.11it/s, est. speed input: 1120.01 toks/s, output: 1.09 toks/s]
Processed prompts:  53%|    | 1090/2048 [16:36<14:25,  1.11it/s, est. speed input: 1120.22 toks/s, output: 1.09 toks/s]
Processed prompts:  54%|    | 1106/2048 [16:50<14:11,  1.11it/s, est. speed input: 1120.39 toks/s, output: 1.09 toks/s]
Processed prompts:  55%|    | 1122/2048 [17:05<13:56,  1.11it/s, est. speed input: 1120.59 toks/s, output: 1.09 toks/s]
Processed prompts:  56%|    | 1138/2048 [17:19<13:42,  1.11it/s, est. speed input: 1120.72 toks/s, output: 1.09 toks/s]
Processed prompts:  56%|    | 1154/2048 [17:34<13:27,  1.11it/s, est. speed input: 1120.92 toks/s, output: 1.09 toks/s]
Processed prompts:  57%|    | 1170/2048 [17:48<13:13,  1.11it/s, est. speed input: 1121.05 toks/s, output: 1.09 toks/s]
Processed prompts:  58%|    | 1186/2048 [18:03<12:58,  1.11it/s, est. speed input: 1121.24 toks/s, output: 1.09 toks/s]
Processed prompts:  59%|    | 1202/2048 [18:17<12:47,  1.10it/s, est. speed input: 1121.21 toks/s, output: 1.09 toks/s]
Processed prompts:  59%|    | 1218/2048 [18:32<12:32,  1.10it/s, est. speed input: 1121.34 toks/s, output: 1.10 toks/s]
Processed prompts:  60%|    | 1234/2048 [18:46<12:16,  1.10it/s, est. speed input: 1121.51 toks/s, output: 1.10 toks/s]
Processed prompts:  61%|    | 1250/2048 [19:01<12:02,  1.10it/s, est. speed input: 1121.63 toks/s, output: 1.10 toks/s]
Processed prompts:  62%|   | 1266/2048 [19:15<11:47,  1.11it/s, est. speed input: 1121.81 toks/s, output: 1.10 toks/s]
Processed prompts:  63%|   | 1282/2048 [19:30<11:32,  1.11it/s, est. speed input: 1121.92 toks/s, output: 1.10 toks/s]
Processed prompts:  63%|   | 1298/2048 [19:44<11:17,  1.11it/s, est. speed input: 1122.07 toks/s, output: 1.10 toks/s]
Processed prompts:  64%|   | 1314/2048 [19:59<11:03,  1.11it/s, est. speed input: 1122.19 toks/s, output: 1.10 toks/s]
Processed prompts:  65%|   | 1330/2048 [20:13<10:48,  1.11it/s, est. speed input: 1122.35 toks/s, output: 1.10 toks/s]
Processed prompts:  66%|   | 1346/2048 [20:27<10:34,  1.11it/s, est. speed input: 1122.45 toks/s, output: 1.10 toks/s]
Processed prompts:  67%|   | 1362/2048 [20:42<10:19,  1.11it/s, est. speed input: 1122.60 toks/s, output: 1.10 toks/s]
Processed prompts:  67%|   | 1378/2048 [20:56<10:04,  1.11it/s, est. speed input: 1122.75 toks/s, output: 1.10 toks/s]
Processed prompts:  68%|   | 1394/2048 [21:11<09:51,  1.11it/s, est. speed input: 1122.80 toks/s, output: 1.10 toks/s]
Processed prompts:  69%|   | 1410/2048 [21:25<09:36,  1.11it/s, est. speed input: 1122.94 toks/s, output: 1.10 toks/s]
Processed prompts:  70%|   | 1426/2048 [21:40<09:22,  1.11it/s, est. speed input: 1123.03 toks/s, output: 1.10 toks/s]
Processed prompts:  70%|   | 1442/2048 [21:54<09:07,  1.11it/s, est. speed input: 1123.16 toks/s, output: 1.10 toks/s]
Processed prompts:  71%|   | 1458/2048 [22:09<08:53,  1.11it/s, est. speed input: 1123.25 toks/s, output: 1.10 toks/s]
Processed prompts:  72%|  | 1474/2048 [22:23<08:38,  1.11it/s, est. speed input: 1123.38 toks/s, output: 1.10 toks/s]
Processed prompts:  73%|  | 1490/2048 [22:38<08:24,  1.11it/s, est. speed input: 1123.47 toks/s, output: 1.10 toks/s]
Processed prompts:  74%|  | 1506/2048 [22:52<08:09,  1.11it/s, est. speed input: 1123.59 toks/s, output: 1.10 toks/s]
Processed prompts:  74%|  | 1522/2048 [23:06<07:54,  1.11it/s, est. speed input: 1123.72 toks/s, output: 1.10 toks/s]
Processed prompts:  75%|  | 1538/2048 [23:21<07:40,  1.11it/s, est. speed input: 1123.79 toks/s, output: 1.10 toks/s]
Processed prompts:  76%|  | 1554/2048 [23:36<07:28,  1.10it/s, est. speed input: 1123.74 toks/s, output: 1.10 toks/s]
Processed prompts:  77%|  | 1570/2048 [23:50<07:13,  1.10it/s, est. speed input: 1123.83 toks/s, output: 1.10 toks/s]
Processed prompts:  77%|  | 1586/2048 [24:04<06:58,  1.11it/s, est. speed input: 1123.94 toks/s, output: 1.10 toks/s]
Processed prompts:  78%|  | 1602/2048 [24:19<06:43,  1.11it/s, est. speed input: 1124.02 toks/s, output: 1.10 toks/s]
Processed prompts:  79%|  | 1618/2048 [24:34<06:30,  1.10it/s, est. speed input: 1123.98 toks/s, output: 1.10 toks/s]
Processed prompts:  80%|  | 1634/2048 [24:48<06:15,  1.10it/s, est. speed input: 1124.04 toks/s, output: 1.10 toks/s]
Processed prompts:  81%|  | 1650/2048 [25:03<06:00,  1.10it/s, est. speed input: 1124.15 toks/s, output: 1.10 toks/s]
Processed prompts:  81%| | 1666/2048 [25:17<05:45,  1.11it/s, est. speed input: 1124.25 toks/s, output: 1.10 toks/s]
Processed prompts:  82%| | 1682/2048 [25:31<05:31,  1.11it/s, est. speed input: 1124.31 toks/s, output: 1.10 toks/s]
Processed prompts:  83%| | 1698/2048 [25:46<05:16,  1.11it/s, est. speed input: 1124.42 toks/s, output: 1.10 toks/s]
Processed prompts:  84%| | 1714/2048 [26:00<05:02,  1.11it/s, est. speed input: 1124.48 toks/s, output: 1.10 toks/s]
Processed prompts:  84%| | 1730/2048 [26:15<04:48,  1.10it/s, est. speed input: 1124.43 toks/s, output: 1.10 toks/s]
Processed prompts:  85%| | 1746/2048 [26:30<04:35,  1.10it/s, est. speed input: 1124.30 toks/s, output: 1.10 toks/s]
Processed prompts:  86%| | 1762/2048 [26:44<04:19,  1.10it/s, est. speed input: 1124.41 toks/s, output: 1.10 toks/s]
Processed prompts:  87%| | 1778/2048 [26:59<04:05,  1.10it/s, est. speed input: 1124.47 toks/s, output: 1.10 toks/s]
Processed prompts:  88%| | 1794/2048 [27:13<03:50,  1.10it/s, est. speed input: 1124.57 toks/s, output: 1.10 toks/s]
Processed prompts:  88%| | 1810/2048 [27:28<03:35,  1.10it/s, est. speed input: 1124.63 toks/s, output: 1.10 toks/s]
Processed prompts:  89%| | 1826/2048 [27:42<03:20,  1.11it/s, est. speed input: 1124.73 toks/s, output: 1.10 toks/s]
Processed prompts:  90%| | 1842/2048 [27:56<03:06,  1.11it/s, est. speed input: 1124.82 toks/s, output: 1.10 toks/s]
Processed prompts:  91%| | 1858/2048 [28:11<02:51,  1.11it/s, est. speed input: 1124.88 toks/s, output: 1.10 toks/s]
Processed prompts:  92%|| 1874/2048 [28:25<02:37,  1.11it/s, est. speed input: 1124.98 toks/s, output: 1.10 toks/s]
Processed prompts:  92%|| 1890/2048 [28:40<02:22,  1.11it/s, est. speed input: 1125.04 toks/s, output: 1.10 toks/s]
Processed prompts:  93%|| 1906/2048 [28:54<02:08,  1.11it/s, est. speed input: 1125.12 toks/s, output: 1.10 toks/s]
Processed prompts:  94%|| 1922/2048 [29:09<01:53,  1.11it/s, est. speed input: 1125.18 toks/s, output: 1.10 toks/s]
Processed prompts:  95%|| 1938/2048 [29:23<01:39,  1.11it/s, est. speed input: 1125.27 toks/s, output: 1.10 toks/s]
Processed prompts:  95%|| 1954/2048 [29:38<01:24,  1.11it/s, est. speed input: 1125.31 toks/s, output: 1.10 toks/s]
Processed prompts:  96%|| 1970/2048 [29:52<01:10,  1.11it/s, est. speed input: 1125.39 toks/s, output: 1.10 toks/s]
Processed prompts:  97%|| 1986/2048 [30:06<00:55,  1.11it/s, est. speed input: 1125.47 toks/s, output: 1.10 toks/s]
Processed prompts:  98%|| 2002/2048 [30:21<00:41,  1.11it/s, est. speed input: 1125.51 toks/s, output: 1.10 toks/s]
Processed prompts:  99%|| 2018/2048 [30:35<00:27,  1.11it/s, est. speed input: 1125.59 toks/s, output: 1.10 toks/s]
Processed prompts:  99%|| 2034/2048 [30:50<00:12,  1.10it/s, est. speed input: 1125.53 toks/s, output: 1.10 toks/s]
Processed prompts: 100%|| 2048/2048 [30:50<00:00,  1.10it/s, est. speed input: 1133.27 toks/s, output: 1.11 toks/s]
Processed prompts: 100%|| 2048/2048 [30:50<00:00,  1.11it/s, est. speed input: 1133.27 toks/s, output: 1.11 toks/s]
[rank0]:[W127 08:54:22.961520909 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-27 08:54:26
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Qwen2.5-14B-FP8_M32768.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-27 08:54:48 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-27 08:54:48 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=2360568) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2360568) WARNING 01-27 08:56:42 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 4.05 requests/s, 4152.62 total tokens/s, 4.05 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-27 08:54:48] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 08:54:48] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 08:54:48] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 08:54:48] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:54:48] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:54:48] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:54:48] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:54:48] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:54:48] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 08:54:48] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 08:54:48] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 08:54:48] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 08:54:48] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 08:54:48] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-27 08:54:51] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 08:54:51] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 08:54:51] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 08:54:51] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:54:51] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:54:51] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:54:51] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:54:51] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 08:54:51] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 08:54:51] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 08:54:51] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 08:54:51] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 08:54:51] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 08:54:51] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=2360568) [2026-01-27 08:54:52] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=2360568) [2026-01-27 08:54:52] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2360568) [2026-01-27 08:54:52] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=2360568) [2026-01-27 08:54:52] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=2360568) [2026-01-27 08:54:52] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=2360568) [2026-01-27 08:54:52] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=2360568) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=2360568) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:25,  8.58s/it]
(EngineCore_DP0 pid=2360568) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:35<00:38, 19.23s/it]
(EngineCore_DP0 pid=2360568) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:57<00:20, 20.45s/it]
(EngineCore_DP0 pid=2360568) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:24<00:00, 23.10s/it]
(EngineCore_DP0 pid=2360568) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:24<00:00, 21.08s/it]
(EngineCore_DP0 pid=2360568) 
(EngineCore_DP0 pid=2360568) [2026-01-27 08:56:18] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 5120] -> 1D uint8
(EngineCore_DP0 pid=2360568) [2026-01-27 08:56:18] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 22937600 bytes
(EngineCore_DP0 pid=2360568) [2026-01-27 08:56:18] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 5120] -> 1D uint8
(EngineCore_DP0 pid=2360568) [2026-01-27 08:56:18] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16384000 bytes
(EngineCore_DP0 pid=2360568) [2026-01-27 08:56:18] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 5120] -> 1D uint8
(EngineCore_DP0 pid=2360568) [2026-01-27 08:56:18] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 88473600 bytes
(EngineCore_DP0 pid=2360568) [2026-01-27 08:56:18] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 13824] -> 1D uint8
(EngineCore_DP0 pid=2360568) [2026-01-27 08:56:18] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 44236800 bytes
(EngineCore_DP0 pid=2360568) 2026-01-27 08:56:32,772 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=2360568) 2026-01-27 08:56:35,890 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   0%|          | 1/4096 [00:00<14:47,  4.61it/s]
Adding requests:   0%|          | 3/4096 [00:00<06:44, 10.11it/s]
Adding requests:   0%|          | 5/4096 [00:00<05:08, 13.28it/s]
Adding requests:   0%|          | 9/4096 [00:00<03:22, 20.19it/s]
Adding requests:   0%|          | 17/4096 [00:00<01:51, 36.58it/s]
Adding requests:   1%|          | 33/4096 [00:00<00:56, 71.95it/s]
Adding requests:   1%|         | 53/4096 [00:00<00:37, 109.00it/s]
Adding requests:   2%|         | 87/4096 [00:00<00:22, 176.65it/s]
Adding requests:   3%|         | 121/4096 [00:01<00:17, 223.55it/s]
Adding requests:   4%|         | 161/4096 [00:01<00:14, 268.84it/s]
Adding requests:   5%|         | 204/4096 [00:01<00:12, 315.15it/s]
Adding requests:   6%|         | 245/4096 [00:01<00:11, 340.55it/s]
Adding requests:   7%|         | 288/4096 [00:01<00:10, 364.97it/s]
Adding requests:   8%|         | 334/4096 [00:01<00:09, 392.32it/s]
Adding requests:   9%|         | 374/4096 [00:01<00:09, 373.62it/s]
Adding requests:  10%|         | 419/4096 [00:01<00:09, 393.17it/s]
Adding requests:  11%|        | 461/4096 [00:01<00:09, 399.04it/s]
Adding requests:  12%|        | 504/4096 [00:02<00:08, 404.03it/s]
Adding requests:  13%|        | 547/4096 [00:02<00:08, 410.15it/s]
Adding requests:  14%|        | 592/4096 [00:02<00:08, 419.94it/s]
Adding requests:  16%|        | 635/4096 [00:02<00:08, 419.63it/s]
Adding requests:  17%|        | 678/4096 [00:02<00:08, 412.38it/s]
Adding requests:  18%|        | 721/4096 [00:02<00:08, 417.13it/s]
Adding requests:  19%|        | 763/4096 [00:02<00:08, 411.26it/s]
Adding requests:  20%|        | 806/4096 [00:02<00:07, 416.08it/s]
Adding requests:  21%|        | 848/4096 [00:02<00:07, 412.33it/s]
Adding requests:  22%|       | 891/4096 [00:02<00:07, 417.17it/s]
Adding requests:  23%|       | 934/4096 [00:03<00:07, 418.11it/s]
Adding requests:  24%|       | 977/4096 [00:03<00:07, 420.61it/s]
Adding requests:  25%|       | 1020/4096 [00:03<00:07, 416.63it/s]
Adding requests:  26%|       | 1063/4096 [00:03<00:07, 419.16it/s]
Adding requests:  27%|       | 1105/4096 [00:03<00:07, 415.32it/s]
Adding requests:  28%|       | 1149/4096 [00:03<00:07, 419.69it/s]
Adding requests:  29%|       | 1192/4096 [00:03<00:07, 408.07it/s]
Adding requests:  30%|       | 1233/4096 [00:03<00:07, 404.19it/s]
Adding requests:  31%|       | 1276/4096 [00:03<00:06, 410.82it/s]
Adding requests:  32%|      | 1318/4096 [00:03<00:06, 409.33it/s]
Adding requests:  33%|      | 1362/4096 [00:04<00:06, 416.23it/s]
Adding requests:  34%|      | 1405/4096 [00:04<00:06, 419.48it/s]
Adding requests:  35%|      | 1447/4096 [00:04<00:06, 414.36it/s]
Adding requests:  36%|      | 1492/4096 [00:04<00:06, 423.56it/s]
Adding requests:  37%|      | 1535/4096 [00:04<00:06, 421.93it/s]
Adding requests:  39%|      | 1578/4096 [00:04<00:05, 421.20it/s]
Adding requests:  40%|      | 1621/4096 [00:04<00:05, 416.16it/s]
Adding requests:  41%|      | 1663/4096 [00:04<00:05, 408.95it/s]
Adding requests:  42%|     | 1706/4096 [00:04<00:05, 414.10it/s]
Adding requests:  43%|     | 1751/4096 [00:05<00:05, 421.45it/s]
Adding requests:  44%|     | 1794/4096 [00:05<00:05, 406.84it/s]
Adding requests:  45%|     | 1838/4096 [00:05<00:05, 415.89it/s]
Adding requests:  46%|     | 1884/4096 [00:05<00:05, 428.12it/s]
Adding requests:  47%|     | 1927/4096 [00:05<00:05, 422.82it/s]
Adding requests:  48%|     | 1971/4096 [00:05<00:04, 426.31it/s]
Adding requests:  49%|     | 2015/4096 [00:05<00:04, 426.70it/s]
Adding requests:  50%|     | 2058/4096 [00:05<00:04, 424.63it/s]
Adding requests:  51%|    | 2101/4096 [00:05<00:04, 419.59it/s]
Adding requests:  52%|    | 2144/4096 [00:05<00:04, 420.63it/s]
Adding requests:  53%|    | 2187/4096 [00:06<00:04, 417.78it/s]
Adding requests:  54%|    | 2229/4096 [00:06<00:04, 414.49it/s]
Adding requests:  55%|    | 2272/4096 [00:06<00:04, 416.94it/s]
Adding requests:  57%|    | 2317/4096 [00:06<00:04, 424.92it/s]
Adding requests:  58%|    | 2362/4096 [00:06<00:04, 430.62it/s]
Adding requests:  59%|    | 2406/4096 [00:06<00:03, 427.98it/s]
Adding requests:  60%|    | 2449/4096 [00:06<00:04, 402.41it/s]
Adding requests:  61%|    | 2495/4096 [00:06<00:03, 416.47it/s]
Adding requests:  62%|   | 2540/4096 [00:06<00:03, 425.03it/s]
Adding requests:  63%|   | 2586/4096 [00:06<00:03, 434.12it/s]
Adding requests:  64%|   | 2630/4096 [00:07<00:03, 432.63it/s]
Adding requests:  65%|   | 2674/4096 [00:07<00:03, 421.61it/s]
Adding requests:  66%|   | 2717/4096 [00:07<00:03, 421.60it/s]
Adding requests:  67%|   | 2762/4096 [00:07<00:03, 428.26it/s]
Adding requests:  69%|   | 2808/4096 [00:07<00:02, 437.01it/s]
Adding requests:  70%|   | 2853/4096 [00:07<00:02, 439.91it/s]
Adding requests:  71%|   | 2898/4096 [00:07<00:02, 431.52it/s]
Adding requests:  72%|  | 2944/4096 [00:07<00:02, 438.50it/s]
Adding requests:  73%|  | 2990/4096 [00:07<00:02, 443.65it/s]
Adding requests:  74%|  | 3036/4096 [00:08<00:02, 445.17it/s]
Adding requests:  75%|  | 3081/4096 [00:08<00:02, 442.34it/s]
Adding requests:  76%|  | 3126/4096 [00:08<00:02, 432.21it/s]
Adding requests:  77%|  | 3170/4096 [00:08<00:02, 415.69it/s]
Adding requests:  78%|  | 3213/4096 [00:08<00:02, 419.10it/s]
Adding requests:  80%|  | 3257/4096 [00:08<00:01, 422.54it/s]
Adding requests:  81%|  | 3300/4096 [00:08<00:01, 416.71it/s]
Adding requests:  82%| | 3346/4096 [00:08<00:01, 426.95it/s]
Adding requests:  83%| | 3389/4096 [00:08<00:01, 421.97it/s]
Adding requests:  84%| | 3434/4096 [00:08<00:01, 429.77it/s]
Adding requests:  85%| | 3481/4096 [00:09<00:01, 438.88it/s]
Adding requests:  86%| | 3525/4096 [00:09<00:01, 434.97it/s]
Adding requests:  87%| | 3571/4096 [00:09<00:01, 441.68it/s]
Adding requests:  88%| | 3616/4096 [00:09<00:01, 428.83it/s]
Adding requests:  89%| | 3659/4096 [00:09<00:01, 427.47it/s]
Adding requests:  90%| | 3703/4096 [00:09<00:00, 431.12it/s]
Adding requests:  91%|| 3747/4096 [00:09<00:00, 423.63it/s]
Adding requests:  93%|| 3790/4096 [00:09<00:00, 424.20it/s]
Adding requests:  94%|| 3833/4096 [00:09<00:00, 402.85it/s]
Adding requests:  95%|| 3875/4096 [00:10<00:00, 405.99it/s]
Adding requests:  96%|| 3918/4096 [00:10<00:00, 412.47it/s]
Adding requests:  97%|| 3960/4096 [00:10<00:00, 411.09it/s]
Adding requests:  98%|| 4002/4096 [00:10<00:00, 409.31it/s]
Adding requests:  99%|| 4045/4096 [00:10<00:00, 411.66it/s]
Adding requests: 100%|| 4087/4096 [00:10<00:00, 395.66it/s]
Adding requests: 100%|| 4096/4096 [00:10<00:00, 387.77it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 41/4096 [00:07<12:14,  5.52it/s, est. speed input: 5653.53 toks/s, output: 5.52 toks/s]
Processed prompts:   2%|         | 73/4096 [00:15<14:25,  4.65it/s, est. speed input: 4888.48 toks/s, output: 4.77 toks/s]
Processed prompts:   3%|         | 105/4096 [00:23<15:11,  4.38it/s, est. speed input: 4643.05 toks/s, output: 4.53 toks/s]
Processed prompts:   3%|         | 137/4096 [00:31<15:30,  4.25it/s, est. speed input: 4520.49 toks/s, output: 4.41 toks/s]
Processed prompts:   4%|         | 169/4096 [00:38<15:38,  4.19it/s, est. speed input: 4448.70 toks/s, output: 4.34 toks/s]
Processed prompts:   5%|         | 201/4096 [00:46<15:33,  4.17it/s, est. speed input: 4414.35 toks/s, output: 4.31 toks/s]
Processed prompts:   6%|         | 233/4096 [00:54<15:34,  4.13it/s, est. speed input: 4375.86 toks/s, output: 4.27 toks/s]
Processed prompts:   6%|         | 265/4096 [01:02<15:32,  4.11it/s, est. speed input: 4347.37 toks/s, output: 4.25 toks/s]
Processed prompts:   7%|         | 297/4096 [01:10<15:22,  4.12it/s, est. speed input: 4335.76 toks/s, output: 4.23 toks/s]
Processed prompts:   8%|         | 329/4096 [01:18<15:19,  4.09it/s, est. speed input: 4316.05 toks/s, output: 4.21 toks/s]
Processed prompts:   9%|         | 361/4096 [01:25<15:15,  4.08it/s, est. speed input: 4300.43 toks/s, output: 4.20 toks/s]
Processed prompts:  10%|         | 393/4096 [01:33<15:10,  4.07it/s, est. speed input: 4286.67 toks/s, output: 4.19 toks/s]
Processed prompts:  10%|         | 425/4096 [01:41<14:57,  4.09it/s, est. speed input: 4282.86 toks/s, output: 4.18 toks/s]
Processed prompts:  11%|         | 457/4096 [01:49<14:52,  4.08it/s, est. speed input: 4272.74 toks/s, output: 4.17 toks/s]
Processed prompts:  12%|        | 489/4096 [01:57<14:47,  4.07it/s, est. speed input: 4263.70 toks/s, output: 4.16 toks/s]
Processed prompts:  13%|        | 521/4096 [02:05<14:40,  4.06it/s, est. speed input: 4256.30 toks/s, output: 4.16 toks/s]
Processed prompts:  14%|        | 553/4096 [02:13<14:33,  4.06it/s, est. speed input: 4249.63 toks/s, output: 4.15 toks/s]
Processed prompts:  14%|        | 585/4096 [02:21<14:26,  4.05it/s, est. speed input: 4243.38 toks/s, output: 4.14 toks/s]
Processed prompts:  15%|        | 617/4096 [02:29<14:18,  4.05it/s, est. speed input: 4238.07 toks/s, output: 4.14 toks/s]
Processed prompts:  16%|        | 649/4096 [02:36<14:11,  4.05it/s, est. speed input: 4233.41 toks/s, output: 4.13 toks/s]
Processed prompts:  17%|        | 681/4096 [02:44<14:03,  4.05it/s, est. speed input: 4228.99 toks/s, output: 4.13 toks/s]
Processed prompts:  17%|        | 713/4096 [02:52<13:55,  4.05it/s, est. speed input: 4225.27 toks/s, output: 4.13 toks/s]
Processed prompts:  18%|        | 745/4096 [03:00<13:48,  4.05it/s, est. speed input: 4221.49 toks/s, output: 4.12 toks/s]
Processed prompts:  19%|        | 777/4096 [03:08<13:35,  4.07it/s, est. speed input: 4221.80 toks/s, output: 4.12 toks/s]
Processed prompts:  20%|        | 809/4096 [03:16<13:28,  4.06it/s, est. speed input: 4218.72 toks/s, output: 4.12 toks/s]
Processed prompts:  21%|        | 841/4096 [03:24<13:21,  4.06it/s, est. speed input: 4215.90 toks/s, output: 4.12 toks/s]
Processed prompts:  21%|       | 873/4096 [03:32<13:15,  4.05it/s, est. speed input: 4212.89 toks/s, output: 4.11 toks/s]
Processed prompts:  22%|       | 905/4096 [03:40<13:07,  4.05it/s, est. speed input: 4210.33 toks/s, output: 4.11 toks/s]
Processed prompts:  23%|       | 937/4096 [03:48<13:00,  4.05it/s, est. speed input: 4207.79 toks/s, output: 4.11 toks/s]
Processed prompts:  24%|       | 969/4096 [03:55<12:52,  4.05it/s, est. speed input: 4205.50 toks/s, output: 4.11 toks/s]
Processed prompts:  24%|       | 1001/4096 [04:03<12:45,  4.05it/s, est. speed input: 4203.44 toks/s, output: 4.10 toks/s]
Processed prompts:  25%|       | 1033/4096 [04:11<12:37,  4.04it/s, est. speed input: 4201.22 toks/s, output: 4.10 toks/s]
Processed prompts:  26%|       | 1065/4096 [04:19<12:29,  4.04it/s, est. speed input: 4199.41 toks/s, output: 4.10 toks/s]
Processed prompts:  27%|       | 1097/4096 [04:27<12:21,  4.04it/s, est. speed input: 4197.63 toks/s, output: 4.10 toks/s]
Processed prompts:  28%|       | 1129/4096 [04:35<12:14,  4.04it/s, est. speed input: 4195.76 toks/s, output: 4.10 toks/s]
Processed prompts:  28%|       | 1161/4096 [04:43<12:06,  4.04it/s, est. speed input: 4194.07 toks/s, output: 4.10 toks/s]
Processed prompts:  29%|       | 1193/4096 [04:51<11:53,  4.07it/s, est. speed input: 4195.16 toks/s, output: 4.10 toks/s]
Processed prompts:  30%|       | 1225/4096 [04:59<11:47,  4.06it/s, est. speed input: 4193.59 toks/s, output: 4.10 toks/s]
Processed prompts:  31%|       | 1257/4096 [05:07<11:40,  4.05it/s, est. speed input: 4192.01 toks/s, output: 4.09 toks/s]
Processed prompts:  31%|      | 1289/4096 [05:14<11:33,  4.05it/s, est. speed input: 4190.73 toks/s, output: 4.09 toks/s]
Processed prompts:  32%|      | 1321/4096 [05:22<11:25,  4.05it/s, est. speed input: 4189.57 toks/s, output: 4.09 toks/s]
Processed prompts:  33%|      | 1353/4096 [05:30<11:18,  4.04it/s, est. speed input: 4188.21 toks/s, output: 4.09 toks/s]
Processed prompts:  34%|      | 1385/4096 [05:38<11:10,  4.04it/s, est. speed input: 4187.03 toks/s, output: 4.09 toks/s]
Processed prompts:  35%|      | 1417/4096 [05:46<11:02,  4.04it/s, est. speed input: 4186.08 toks/s, output: 4.09 toks/s]
Processed prompts:  35%|      | 1449/4096 [05:54<10:54,  4.04it/s, est. speed input: 4184.92 toks/s, output: 4.09 toks/s]
Processed prompts:  36%|      | 1481/4096 [06:02<10:46,  4.04it/s, est. speed input: 4183.95 toks/s, output: 4.09 toks/s]
Processed prompts:  37%|      | 1513/4096 [06:10<10:38,  4.04it/s, est. speed input: 4183.08 toks/s, output: 4.09 toks/s]
Processed prompts:  38%|      | 1545/4096 [06:18<10:26,  4.07it/s, est. speed input: 4183.98 toks/s, output: 4.09 toks/s]
Processed prompts:  39%|      | 1577/4096 [06:26<10:20,  4.06it/s, est. speed input: 4182.92 toks/s, output: 4.08 toks/s]
Processed prompts:  39%|      | 1609/4096 [06:33<10:09,  4.08it/s, est. speed input: 4183.74 toks/s, output: 4.09 toks/s]
Processed prompts:  40%|      | 1641/4096 [06:41<10:03,  4.07it/s, est. speed input: 4182.83 toks/s, output: 4.08 toks/s]
Processed prompts:  41%|      | 1673/4096 [06:49<09:57,  4.06it/s, est. speed input: 4181.74 toks/s, output: 4.08 toks/s]
Processed prompts:  42%|     | 1705/4096 [06:57<09:50,  4.05it/s, est. speed input: 4180.80 toks/s, output: 4.08 toks/s]
Processed prompts:  42%|     | 1737/4096 [07:04<09:30,  4.14it/s, est. speed input: 4185.59 toks/s, output: 4.09 toks/s]
Processed prompts:  43%|     | 1769/4096 [07:12<09:26,  4.11it/s, est. speed input: 4184.66 toks/s, output: 4.09 toks/s]
Processed prompts:  44%|     | 1801/4096 [07:20<09:22,  4.08it/s, est. speed input: 4183.62 toks/s, output: 4.09 toks/s]
Processed prompts:  45%|     | 1833/4096 [07:28<09:16,  4.07it/s, est. speed input: 4182.75 toks/s, output: 4.08 toks/s]
Processed prompts:  46%|     | 1865/4096 [07:36<09:09,  4.06it/s, est. speed input: 4181.92 toks/s, output: 4.08 toks/s]
Processed prompts:  46%|     | 1897/4096 [07:44<09:02,  4.05it/s, est. speed input: 4181.10 toks/s, output: 4.08 toks/s]
Processed prompts:  47%|     | 1929/4096 [07:52<08:55,  4.05it/s, est. speed input: 4180.23 toks/s, output: 4.08 toks/s]
Processed prompts:  48%|     | 1961/4096 [08:00<08:48,  4.04it/s, est. speed input: 4179.40 toks/s, output: 4.08 toks/s]
Processed prompts:  49%|     | 1993/4096 [08:08<08:40,  4.04it/s, est. speed input: 4178.62 toks/s, output: 4.08 toks/s]
Processed prompts:  49%|     | 2025/4096 [08:16<08:32,  4.04it/s, est. speed input: 4177.98 toks/s, output: 4.08 toks/s]
Processed prompts:  50%|     | 2057/4096 [08:24<08:24,  4.04it/s, est. speed input: 4177.24 toks/s, output: 4.08 toks/s]
Processed prompts:  51%|     | 2089/4096 [08:32<08:17,  4.04it/s, est. speed input: 4176.55 toks/s, output: 4.08 toks/s]
Processed prompts:  52%|    | 2121/4096 [08:40<08:09,  4.04it/s, est. speed input: 4175.84 toks/s, output: 4.08 toks/s]
Processed prompts:  53%|    | 2153/4096 [08:48<08:01,  4.04it/s, est. speed input: 4175.15 toks/s, output: 4.08 toks/s]
Processed prompts:  53%|    | 2185/4096 [08:55<07:50,  4.06it/s, est. speed input: 4175.79 toks/s, output: 4.08 toks/s]
Processed prompts:  54%|    | 2217/4096 [09:03<07:43,  4.05it/s, est. speed input: 4175.21 toks/s, output: 4.08 toks/s]
Processed prompts:  55%|    | 2249/4096 [09:11<07:36,  4.05it/s, est. speed input: 4174.58 toks/s, output: 4.08 toks/s]
Processed prompts:  56%|    | 2281/4096 [09:19<07:28,  4.04it/s, est. speed input: 4173.98 toks/s, output: 4.08 toks/s]
Processed prompts:  56%|    | 2313/4096 [09:27<07:21,  4.04it/s, est. speed input: 4173.41 toks/s, output: 4.08 toks/s]
Processed prompts:  57%|    | 2345/4096 [09:35<07:13,  4.04it/s, est. speed input: 4172.90 toks/s, output: 4.08 toks/s]
Processed prompts:  58%|    | 2377/4096 [09:43<07:05,  4.04it/s, est. speed input: 4172.32 toks/s, output: 4.07 toks/s]
Processed prompts:  59%|    | 2409/4096 [09:51<06:57,  4.04it/s, est. speed input: 4171.82 toks/s, output: 4.07 toks/s]
Processed prompts:  60%|    | 2441/4096 [09:59<06:49,  4.04it/s, est. speed input: 4171.32 toks/s, output: 4.07 toks/s]
Processed prompts:  60%|    | 2473/4096 [10:07<06:41,  4.04it/s, est. speed input: 4170.93 toks/s, output: 4.07 toks/s]
Processed prompts:  61%|    | 2505/4096 [10:15<06:34,  4.04it/s, est. speed input: 4170.40 toks/s, output: 4.07 toks/s]
Processed prompts:  62%|   | 2537/4096 [10:22<06:25,  4.04it/s, est. speed input: 4169.99 toks/s, output: 4.07 toks/s]
Processed prompts:  63%|   | 2569/4096 [10:30<06:18,  4.04it/s, est. speed input: 4169.52 toks/s, output: 4.07 toks/s]
Processed prompts:  64%|   | 2601/4096 [10:38<06:07,  4.06it/s, est. speed input: 4170.15 toks/s, output: 4.07 toks/s]
Processed prompts:  64%|   | 2633/4096 [10:46<06:00,  4.06it/s, est. speed input: 4169.74 toks/s, output: 4.07 toks/s]
Processed prompts:  65%|   | 2665/4096 [10:54<05:53,  4.05it/s, est. speed input: 4169.25 toks/s, output: 4.07 toks/s]
Processed prompts:  66%|   | 2697/4096 [11:02<05:45,  4.04it/s, est. speed input: 4168.76 toks/s, output: 4.07 toks/s]
Processed prompts:  67%|   | 2729/4096 [11:10<05:36,  4.07it/s, est. speed input: 4169.41 toks/s, output: 4.07 toks/s]
Processed prompts:  67%|   | 2761/4096 [11:18<05:29,  4.06it/s, est. speed input: 4168.94 toks/s, output: 4.07 toks/s]
Processed prompts:  68%|   | 2793/4096 [11:26<05:21,  4.05it/s, est. speed input: 4168.45 toks/s, output: 4.07 toks/s]
Processed prompts:  69%|   | 2825/4096 [11:34<05:14,  4.05it/s, est. speed input: 4168.05 toks/s, output: 4.07 toks/s]
Processed prompts:  70%|   | 2857/4096 [11:41<05:06,  4.04it/s, est. speed input: 4167.66 toks/s, output: 4.07 toks/s]
Processed prompts:  71%|   | 2889/4096 [11:49<04:56,  4.07it/s, est. speed input: 4168.27 toks/s, output: 4.07 toks/s]
Processed prompts:  71%|  | 2921/4096 [11:57<04:47,  4.08it/s, est. speed input: 4168.82 toks/s, output: 4.07 toks/s]
Processed prompts:  72%|  | 2953/4096 [12:05<04:40,  4.07it/s, est. speed input: 4168.40 toks/s, output: 4.07 toks/s]
Processed prompts:  73%|  | 2985/4096 [12:13<04:33,  4.06it/s, est. speed input: 4168.06 toks/s, output: 4.07 toks/s]
Processed prompts:  74%|  | 3017/4096 [12:21<04:26,  4.05it/s, est. speed input: 4167.65 toks/s, output: 4.07 toks/s]
Processed prompts:  74%|  | 3049/4096 [12:29<04:18,  4.05it/s, est. speed input: 4167.28 toks/s, output: 4.07 toks/s]
Processed prompts:  75%|  | 3081/4096 [12:37<04:11,  4.04it/s, est. speed input: 4166.90 toks/s, output: 4.07 toks/s]
Processed prompts:  76%|  | 3113/4096 [12:45<04:03,  4.04it/s, est. speed input: 4166.50 toks/s, output: 4.07 toks/s]
Processed prompts:  77%|  | 3145/4096 [12:53<03:55,  4.04it/s, est. speed input: 4166.14 toks/s, output: 4.07 toks/s]
Processed prompts:  78%|  | 3177/4096 [13:00<03:47,  4.04it/s, est. speed input: 4165.74 toks/s, output: 4.07 toks/s]
Processed prompts:  78%|  | 3209/4096 [13:08<03:39,  4.04it/s, est. speed input: 4165.41 toks/s, output: 4.07 toks/s]
Processed prompts:  79%|  | 3241/4096 [13:16<03:31,  4.04it/s, est. speed input: 4165.11 toks/s, output: 4.07 toks/s]
Processed prompts:  80%|  | 3273/4096 [13:24<03:23,  4.04it/s, est. speed input: 4164.77 toks/s, output: 4.07 toks/s]
Processed prompts:  81%|  | 3305/4096 [13:32<03:16,  4.03it/s, est. speed input: 4164.39 toks/s, output: 4.07 toks/s]
Processed prompts:  81%| | 3337/4096 [13:40<03:08,  4.03it/s, est. speed input: 4164.03 toks/s, output: 4.07 toks/s]
Processed prompts:  82%| | 3369/4096 [13:48<03:00,  4.03it/s, est. speed input: 4163.70 toks/s, output: 4.07 toks/s]
Processed prompts:  83%| | 3401/4096 [13:56<02:52,  4.03it/s, est. speed input: 4163.35 toks/s, output: 4.07 toks/s]
Processed prompts:  84%| | 3433/4096 [14:04<02:44,  4.03it/s, est. speed input: 4163.06 toks/s, output: 4.07 toks/s]
Processed prompts:  85%| | 3465/4096 [14:12<02:36,  4.03it/s, est. speed input: 4162.77 toks/s, output: 4.07 toks/s]
Processed prompts:  85%| | 3497/4096 [14:20<02:28,  4.03it/s, est. speed input: 4162.44 toks/s, output: 4.06 toks/s]
Processed prompts:  86%| | 3529/4096 [14:28<02:20,  4.03it/s, est. speed input: 4162.16 toks/s, output: 4.06 toks/s]
Processed prompts:  87%| | 3561/4096 [14:36<02:12,  4.03it/s, est. speed input: 4161.84 toks/s, output: 4.06 toks/s]
Processed prompts:  88%| | 3593/4096 [14:44<02:04,  4.03it/s, est. speed input: 4161.59 toks/s, output: 4.06 toks/s]
Processed prompts:  89%| | 3625/4096 [14:52<01:56,  4.03it/s, est. speed input: 4161.34 toks/s, output: 4.06 toks/s]
Processed prompts:  89%| | 3657/4096 [14:59<01:48,  4.04it/s, est. speed input: 4161.12 toks/s, output: 4.06 toks/s]
Processed prompts:  90%| | 3689/4096 [15:07<01:40,  4.06it/s, est. speed input: 4161.68 toks/s, output: 4.06 toks/s]
Processed prompts:  91%| | 3721/4096 [15:15<01:32,  4.05it/s, est. speed input: 4161.42 toks/s, output: 4.06 toks/s]
Processed prompts:  92%|| 3753/4096 [15:23<01:24,  4.05it/s, est. speed input: 4161.18 toks/s, output: 4.06 toks/s]
Processed prompts:  92%|| 3785/4096 [15:31<01:16,  4.05it/s, est. speed input: 4160.95 toks/s, output: 4.06 toks/s]
Processed prompts:  93%|| 3817/4096 [15:39<01:08,  4.04it/s, est. speed input: 4160.74 toks/s, output: 4.06 toks/s]
Processed prompts:  94%|| 3849/4096 [15:47<01:01,  4.04it/s, est. speed input: 4160.45 toks/s, output: 4.06 toks/s]
Processed prompts:  95%|| 3881/4096 [15:55<00:53,  4.04it/s, est. speed input: 4160.22 toks/s, output: 4.06 toks/s]
Processed prompts:  96%|| 3913/4096 [16:03<00:45,  4.06it/s, est. speed input: 4160.74 toks/s, output: 4.06 toks/s]
Processed prompts:  96%|| 3945/4096 [16:10<00:37,  4.05it/s, est. speed input: 4160.47 toks/s, output: 4.06 toks/s]
Processed prompts:  97%|| 3977/4096 [16:18<00:29,  4.05it/s, est. speed input: 4160.24 toks/s, output: 4.06 toks/s]
Processed prompts:  98%|| 4009/4096 [16:26<00:21,  4.07it/s, est. speed input: 4160.74 toks/s, output: 4.06 toks/s]
Processed prompts:  99%|| 4041/4096 [16:34<00:13,  4.06it/s, est. speed input: 4160.46 toks/s, output: 4.06 toks/s]
Processed prompts:  99%|| 4073/4096 [16:40<00:05,  4.40it/s, est. speed input: 4168.84 toks/s, output: 4.07 toks/s]
Processed prompts: 100%|| 4096/4096 [16:40<00:00,  4.40it/s, est. speed input: 4192.38 toks/s, output: 4.09 toks/s]
Processed prompts: 100%|| 4096/4096 [16:40<00:00,  4.09it/s, est. speed input: 4192.38 toks/s, output: 4.09 toks/s]
[rank0]:[W127 09:13:40.614794478 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-27 09:13:45
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_4
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_4 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_4/json/Qwen2.5-14B-FP8_M65536.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-27 09:14:20 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-27 09:14:20 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=2391670) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2391670) WARNING 01-27 09:16:29 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 4.05 requests/s, 4147.11 total tokens/s, 4.05 output tokens/s
Total num prompt tokens:  8388608
Total num output tokens:  8192

STDERR:
[2026-01-27 09:14:20] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 09:14:20] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 09:14:20] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 09:14:20] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 09:14:20] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 09:14:20] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 09:14:20] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 09:14:20] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 09:14:20] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 09:14:20] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 09:14:20] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 09:14:20] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 09:14:20] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 09:14:20] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-27 09:14:24] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 09:14:24] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 09:14:24] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 09:14:24] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 09:14:24] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 09:14:24] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 09:14:24] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 09:14:24] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 09:14:24] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 09:14:24] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 09:14:24] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 09:14:24] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 09:14:24] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 09:14:24] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=2391670) [2026-01-27 09:14:25] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=2391670) [2026-01-27 09:14:25] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2391670) [2026-01-27 09:14:25] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=2391670) [2026-01-27 09:14:25] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=2391670) [2026-01-27 09:14:25] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=2391670) [2026-01-27 09:14:25] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=2391670) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=2391670) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:25,  8.40s/it]
(EngineCore_DP0 pid=2391670) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:35<00:38, 19.11s/it]
(EngineCore_DP0 pid=2391670) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:56<00:19, 19.98s/it]
(EngineCore_DP0 pid=2391670) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:23<00:00, 22.78s/it]
(EngineCore_DP0 pid=2391670) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:23<00:00, 20.77s/it]
(EngineCore_DP0 pid=2391670) 
(EngineCore_DP0 pid=2391670) [2026-01-27 09:15:49] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 5120] -> 1D uint8
(EngineCore_DP0 pid=2391670) [2026-01-27 09:15:50] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 22937600 bytes
(EngineCore_DP0 pid=2391670) [2026-01-27 09:15:50] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 5120] -> 1D uint8
(EngineCore_DP0 pid=2391670) [2026-01-27 09:15:50] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16384000 bytes
(EngineCore_DP0 pid=2391670) [2026-01-27 09:15:50] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 5120] -> 1D uint8
(EngineCore_DP0 pid=2391670) [2026-01-27 09:15:50] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 88473600 bytes
(EngineCore_DP0 pid=2391670) [2026-01-27 09:15:50] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 13824] -> 1D uint8
(EngineCore_DP0 pid=2391670) [2026-01-27 09:15:50] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 44236800 bytes
(EngineCore_DP0 pid=2391670) 2026-01-27 09:16:10,623 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=2391670) 2026-01-27 09:16:16,998 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/8192 [00:00<?, ?it/s]
Adding requests:   0%|          | 1/8192 [00:00<1:19:10,  1.72it/s]
Adding requests:   0%|          | 2/8192 [00:00<45:53,  2.97it/s]  
Adding requests:   0%|          | 4/8192 [00:00<24:11,  5.64it/s]
Adding requests:   0%|          | 7/8192 [00:01<14:03,  9.71it/s]
Adding requests:   0%|          | 12/8192 [00:01<07:55, 17.20it/s]
Adding requests:   0%|          | 20/8192 [00:01<04:24, 30.88it/s]
Adding requests:   1%|          | 41/8192 [00:01<01:50, 73.50it/s]
Adding requests:   1%|          | 69/8192 [00:01<01:04, 125.06it/s]
Adding requests:   1%|          | 97/8192 [00:01<00:48, 165.39it/s]
Adding requests:   2%|         | 127/8192 [00:01<00:40, 201.42it/s]
Adding requests:   2%|         | 159/8192 [00:01<00:34, 233.89it/s]
Adding requests:   2%|         | 192/8192 [00:01<00:30, 260.83it/s]
Adding requests:   3%|         | 223/8192 [00:01<00:29, 274.58it/s]
Adding requests:   3%|         | 253/8192 [00:02<00:28, 280.58it/s]
Adding requests:   4%|         | 287/8192 [00:02<00:26, 296.71it/s]
Adding requests:   4%|         | 319/8192 [00:02<00:26, 302.24it/s]
Adding requests:   4%|         | 359/8192 [00:02<00:23, 330.45it/s]
Adding requests:   5%|         | 404/8192 [00:02<00:21, 364.06it/s]
Adding requests:   5%|         | 442/8192 [00:02<00:21, 365.60it/s]
Adding requests:   6%|         | 487/8192 [00:02<00:19, 390.19it/s]
Adding requests:   6%|         | 528/8192 [00:02<00:19, 395.25it/s]
Adding requests:   7%|         | 571/8192 [00:02<00:18, 405.05it/s]
Adding requests:   7%|         | 612/8192 [00:03<00:19, 396.30it/s]
Adding requests:   8%|         | 652/8192 [00:03<00:19, 392.84it/s]
Adding requests:   8%|         | 696/8192 [00:03<00:18, 406.34it/s]
Adding requests:   9%|         | 737/8192 [00:03<00:19, 376.79it/s]
Adding requests:   9%|         | 778/8192 [00:03<00:19, 385.60it/s]
Adding requests:  10%|         | 821/8192 [00:03<00:18, 398.22it/s]
Adding requests:  11%|         | 862/8192 [00:03<00:18, 393.83it/s]
Adding requests:  11%|         | 902/8192 [00:03<00:18, 391.84it/s]
Adding requests:  12%|        | 945/8192 [00:03<00:18, 400.84it/s]
Adding requests:  12%|        | 986/8192 [00:03<00:18, 391.17it/s]
Adding requests:  13%|        | 1026/8192 [00:04<00:18, 384.06it/s]
Adding requests:  13%|        | 1071/8192 [00:04<00:17, 402.13it/s]
Adding requests:  14%|        | 1112/8192 [00:04<00:18, 387.33it/s]
Adding requests:  14%|        | 1153/8192 [00:04<00:18, 389.93it/s]
Adding requests:  15%|        | 1195/8192 [00:04<00:17, 397.76it/s]
Adding requests:  15%|        | 1235/8192 [00:04<00:17, 390.20it/s]
Adding requests:  16%|        | 1275/8192 [00:04<00:17, 386.80it/s]
Adding requests:  16%|        | 1319/8192 [00:04<00:17, 400.51it/s]
Adding requests:  17%|        | 1360/8192 [00:04<00:17, 397.96it/s]
Adding requests:  17%|        | 1400/8192 [00:05<00:17, 397.44it/s]
Adding requests:  18%|        | 1441/8192 [00:05<00:16, 398.97it/s]
Adding requests:  18%|        | 1483/8192 [00:05<00:16, 404.17it/s]
Adding requests:  19%|        | 1526/8192 [00:05<00:16, 409.90it/s]
Adding requests:  19%|        | 1568/8192 [00:05<00:16, 408.52it/s]
Adding requests:  20%|        | 1609/8192 [00:05<00:16, 389.79it/s]
Adding requests:  20%|        | 1649/8192 [00:05<00:17, 383.53it/s]
Adding requests:  21%|        | 1688/8192 [00:05<00:17, 379.27it/s]
Adding requests:  21%|        | 1732/8192 [00:05<00:16, 394.31it/s]
Adding requests:  22%|       | 1773/8192 [00:05<00:16, 396.61it/s]
Adding requests:  22%|       | 1813/8192 [00:06<00:16, 387.82it/s]
Adding requests:  23%|       | 1859/8192 [00:06<00:15, 406.65it/s]
Adding requests:  23%|       | 1900/8192 [00:06<00:16, 382.84it/s]
Adding requests:  24%|       | 1939/8192 [00:06<00:16, 384.05it/s]
Adding requests:  24%|       | 1983/8192 [00:06<00:15, 397.53it/s]
Adding requests:  25%|       | 2023/8192 [00:06<00:15, 386.41it/s]
Adding requests:  25%|       | 2063/8192 [00:06<00:15, 389.74it/s]
Adding requests:  26%|       | 2108/8192 [00:06<00:15, 403.81it/s]
Adding requests:  26%|       | 2149/8192 [00:06<00:15, 399.64it/s]
Adding requests:  27%|       | 2190/8192 [00:07<00:15, 387.46it/s]
Adding requests:  27%|       | 2233/8192 [00:07<00:14, 398.55it/s]
Adding requests:  28%|       | 2273/8192 [00:07<00:15, 392.11it/s]
Adding requests:  28%|       | 2314/8192 [00:07<00:14, 395.54it/s]
Adding requests:  29%|       | 2357/8192 [00:07<00:14, 405.54it/s]
Adding requests:  29%|       | 2398/8192 [00:07<00:14, 404.48it/s]
Adding requests:  30%|       | 2439/8192 [00:07<00:14, 405.91it/s]
Adding requests:  30%|       | 2482/8192 [00:07<00:13, 410.29it/s]
Adding requests:  31%|       | 2525/8192 [00:07<00:13, 415.45it/s]
Adding requests:  31%|      | 2571/8192 [00:07<00:13, 425.97it/s]
Adding requests:  32%|      | 2614/8192 [00:08<00:13, 419.53it/s]
Adding requests:  32%|      | 2657/8192 [00:08<00:13, 419.79it/s]
Adding requests:  33%|      | 2699/8192 [00:08<00:13, 406.74it/s]
Adding requests:  33%|      | 2740/8192 [00:08<00:13, 396.55it/s]
Adding requests:  34%|      | 2785/8192 [00:08<00:13, 411.45it/s]
Adding requests:  35%|      | 2829/8192 [00:08<00:12, 416.12it/s]
Adding requests:  35%|      | 2871/8192 [00:08<00:13, 408.48it/s]
Adding requests:  36%|      | 2918/8192 [00:08<00:12, 422.93it/s]
Adding requests:  36%|      | 2961/8192 [00:08<00:12, 421.36it/s]
Adding requests:  37%|      | 3004/8192 [00:08<00:12, 416.53it/s]
Adding requests:  37%|      | 3048/8192 [00:09<00:12, 421.04it/s]
Adding requests:  38%|      | 3091/8192 [00:09<00:12, 413.18it/s]
Adding requests:  38%|      | 3134/8192 [00:09<00:12, 417.62it/s]
Adding requests:  39%|      | 3176/8192 [00:09<00:12, 409.24it/s]
Adding requests:  39%|      | 3217/8192 [00:09<00:12, 405.56it/s]
Adding requests:  40%|      | 3258/8192 [00:09<00:12, 391.03it/s]
Adding requests:  40%|      | 3298/8192 [00:09<00:12, 385.48it/s]
Adding requests:  41%|      | 3337/8192 [00:09<00:12, 380.71it/s]
Adding requests:  41%|      | 3378/8192 [00:09<00:12, 387.70it/s]
Adding requests:  42%|     | 3421/8192 [00:10<00:12, 389.25it/s]
Adding requests:  42%|     | 3461/8192 [00:10<00:12, 389.57it/s]
Adding requests:  43%|     | 3501/8192 [00:10<00:11, 392.07it/s]
Adding requests:  43%|     | 3545/8192 [00:10<00:11, 404.61it/s]
Adding requests:  44%|     | 3589/8192 [00:10<00:11, 412.46it/s]
Adding requests:  44%|     | 3631/8192 [00:10<00:11, 411.45it/s]
Adding requests:  45%|     | 3673/8192 [00:10<00:10, 412.26it/s]
Adding requests:  45%|     | 3722/8192 [00:10<00:10, 432.09it/s]
Adding requests:  46%|     | 3766/8192 [00:10<00:10, 415.73it/s]
Adding requests:  46%|     | 3808/8192 [00:10<00:10, 404.87it/s]
Adding requests:  47%|     | 3852/8192 [00:11<00:10, 412.81it/s]
Adding requests:  48%|     | 3894/8192 [00:11<00:10, 410.18it/s]
Adding requests:  48%|     | 3936/8192 [00:11<00:10, 390.78it/s]
Adding requests:  49%|     | 3983/8192 [00:11<00:10, 411.30it/s]
Adding requests:  49%|     | 4025/8192 [00:11<00:10, 389.39it/s]
Adding requests:  50%|     | 4065/8192 [00:11<00:10, 385.30it/s]
Adding requests:  50%|     | 4113/8192 [00:11<00:09, 409.30it/s]
Adding requests:  51%|     | 4155/8192 [00:11<00:09, 403.99it/s]
Adding requests:  51%|     | 4196/8192 [00:11<00:10, 397.55it/s]
Adding requests:  52%|    | 4241/8192 [00:12<00:09, 411.77it/s]
Adding requests:  52%|    | 4283/8192 [00:12<00:09, 398.67it/s]
Adding requests:  53%|    | 4324/8192 [00:12<00:09, 391.42it/s]
Adding requests:  53%|    | 4369/8192 [00:12<00:09, 405.93it/s]
Adding requests:  54%|    | 4410/8192 [00:12<00:09, 388.26it/s]
Adding requests:  54%|    | 4452/8192 [00:12<00:09, 394.48it/s]
Adding requests:  55%|    | 4492/8192 [00:12<00:09, 394.39it/s]
Adding requests:  55%|    | 4532/8192 [00:12<00:09, 387.36it/s]
Adding requests:  56%|    | 4572/8192 [00:12<00:09, 390.43it/s]
Adding requests:  56%|    | 4615/8192 [00:13<00:08, 400.42it/s]
Adding requests:  57%|    | 4656/8192 [00:13<00:09, 375.76it/s]
Adding requests:  57%|    | 4696/8192 [00:13<00:09, 382.06it/s]
Adding requests:  58%|    | 4739/8192 [00:13<00:08, 393.41it/s]
Adding requests:  58%|    | 4779/8192 [00:13<00:08, 385.80it/s]
Adding requests:  59%|    | 4819/8192 [00:13<00:08, 388.10it/s]
Adding requests:  59%|    | 4858/8192 [00:13<00:08, 386.42it/s]
Adding requests:  60%|    | 4901/8192 [00:13<00:08, 398.69it/s]
Adding requests:  60%|    | 4944/8192 [00:13<00:07, 407.88it/s]
Adding requests:  61%|    | 4985/8192 [00:13<00:08, 397.28it/s]
Adding requests:  61%|   | 5034/8192 [00:14<00:07, 422.78it/s]
Adding requests:  62%|   | 5077/8192 [00:14<00:07, 424.18it/s]
Adding requests:  62%|   | 5120/8192 [00:14<00:07, 409.36it/s]
Adding requests:  63%|   | 5167/8192 [00:14<00:07, 424.13it/s]
Adding requests:  64%|   | 5210/8192 [00:14<00:07, 408.73it/s]
Adding requests:  64%|   | 5252/8192 [00:14<00:07, 408.41it/s]
Adding requests:  65%|   | 5299/8192 [00:14<00:06, 425.22it/s]
Adding requests:  65%|   | 5342/8192 [00:14<00:06, 413.20it/s]
Adding requests:  66%|   | 5384/8192 [00:14<00:06, 413.80it/s]
Adding requests:  66%|   | 5428/8192 [00:15<00:06, 421.32it/s]
Adding requests:  67%|   | 5471/8192 [00:15<00:06, 416.16it/s]
Adding requests:  67%|   | 5517/8192 [00:15<00:06, 426.85it/s]
Adding requests:  68%|   | 5560/8192 [00:15<00:06, 427.47it/s]
Adding requests:  68%|   | 5603/8192 [00:15<00:06, 413.92it/s]
Adding requests:  69%|   | 5647/8192 [00:15<00:06, 420.40it/s]
Adding requests:  69%|   | 5690/8192 [00:15<00:06, 414.84it/s]
Adding requests:  70%|   | 5735/8192 [00:15<00:05, 421.91it/s]
Adding requests:  71%|   | 5778/8192 [00:15<00:05, 410.92it/s]
Adding requests:  71%|   | 5820/8192 [00:15<00:05, 405.12it/s]
Adding requests:  72%|  | 5864/8192 [00:16<00:05, 413.68it/s]
Adding requests:  72%|  | 5906/8192 [00:16<00:05, 408.84it/s]
Adding requests:  73%|  | 5948/8192 [00:16<00:05, 409.97it/s]
Adding requests:  73%|  | 5995/8192 [00:16<00:05, 426.53it/s]
Adding requests:  74%|  | 6038/8192 [00:16<00:05, 371.32it/s]
Adding requests:  74%|  | 6077/8192 [00:16<00:05, 374.64it/s]
Adding requests:  75%|  | 6119/8192 [00:16<00:05, 386.40it/s]
Adding requests:  75%|  | 6162/8192 [00:16<00:05, 397.65it/s]
Adding requests:  76%|  | 6203/8192 [00:16<00:05, 389.99it/s]
Adding requests:  76%|  | 6251/8192 [00:17<00:04, 413.31it/s]
Adding requests:  77%|  | 6293/8192 [00:17<00:04, 401.96it/s]
Adding requests:  77%|  | 6335/8192 [00:17<00:04, 405.89it/s]
Adding requests:  78%|  | 6382/8192 [00:17<00:04, 424.02it/s]
Adding requests:  78%|  | 6425/8192 [00:17<00:04, 409.63it/s]
Adding requests:  79%|  | 6467/8192 [00:17<00:04, 390.16it/s]
Adding requests:  79%|  | 6511/8192 [00:17<00:04, 402.67it/s]
Adding requests:  80%|  | 6552/8192 [00:17<00:04, 399.64it/s]
Adding requests:  80%|  | 6593/8192 [00:17<00:04, 390.95it/s]
Adding requests:  81%|  | 6635/8192 [00:18<00:03, 397.45it/s]
Adding requests:  81%| | 6675/8192 [00:18<00:03, 392.98it/s]
Adding requests:  82%| | 6718/8192 [00:18<00:03, 403.08it/s]
Adding requests:  83%| | 6759/8192 [00:18<00:03, 404.92it/s]
Adding requests:  83%| | 6803/8192 [00:18<00:03, 411.91it/s]
Adding requests:  84%| | 6845/8192 [00:18<00:03, 393.70it/s]
Adding requests:  84%| | 6885/8192 [00:18<00:03, 390.35it/s]
Adding requests:  85%| | 6927/8192 [00:18<00:03, 396.49it/s]
Adding requests:  85%| | 6967/8192 [00:18<00:03, 386.52it/s]
Adding requests:  86%| | 7011/8192 [00:18<00:02, 398.87it/s]
Adding requests:  86%| | 7055/8192 [00:19<00:02, 409.43it/s]
Adding requests:  87%| | 7097/8192 [00:19<00:02, 398.39it/s]
Adding requests:  87%| | 7137/8192 [00:19<00:02, 396.97it/s]
Adding requests:  88%| | 7183/8192 [00:19<00:02, 413.38it/s]
Adding requests:  88%| | 7225/8192 [00:19<00:02, 411.53it/s]
Adding requests:  89%| | 7268/8192 [00:19<00:02, 415.04it/s]
Adding requests:  89%| | 7311/8192 [00:19<00:02, 419.21it/s]
Adding requests:  90%| | 7353/8192 [00:19<00:02, 407.22it/s]
Adding requests:  90%| | 7394/8192 [00:19<00:02, 385.29it/s]
Adding requests:  91%| | 7441/8192 [00:20<00:01, 407.21it/s]
Adding requests:  91%|| 7483/8192 [00:20<00:01, 402.59it/s]
Adding requests:  92%|| 7526/8192 [00:20<00:01, 408.81it/s]
Adding requests:  92%|| 7570/8192 [00:20<00:01, 417.56it/s]
Adding requests:  93%|| 7612/8192 [00:20<00:01, 406.11it/s]
Adding requests:  93%|| 7654/8192 [00:20<00:01, 406.20it/s]
Adding requests:  94%|| 7695/8192 [00:20<00:01, 402.41it/s]
Adding requests:  94%|| 7736/8192 [00:20<00:01, 383.92it/s]
Adding requests:  95%|| 7776/8192 [00:20<00:01, 386.94it/s]
Adding requests:  95%|| 7818/8192 [00:20<00:00, 394.72it/s]
Adding requests:  96%|| 7861/8192 [00:21<00:00, 402.18it/s]
Adding requests:  96%|| 7903/8192 [00:21<00:00, 404.95it/s]
Adding requests:  97%|| 7946/8192 [00:21<00:00, 411.66it/s]
Adding requests:  98%|| 7993/8192 [00:21<00:00, 427.50it/s]
Adding requests:  98%|| 8036/8192 [00:21<00:00, 415.89it/s]
Adding requests:  99%|| 8080/8192 [00:21<00:00, 419.72it/s]
Adding requests:  99%|| 8123/8192 [00:21<00:00, 415.56it/s]
Adding requests: 100%|| 8165/8192 [00:21<00:00, 405.55it/s]
Adding requests: 100%|| 8192/8192 [00:21<00:00, 374.72it/s]

Processed prompts:   0%|          | 0/8192 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 70/8192 [00:11<22:50,  5.93it/s, est. speed input: 6068.92 toks/s, output: 5.93 toks/s]
Processed prompts:   2%|         | 134/8192 [00:27<28:37,  4.69it/s, est. speed input: 4965.86 toks/s, output: 4.85 toks/s]
Processed prompts:   2%|         | 198/8192 [00:43<30:13,  4.41it/s, est. speed input: 4689.57 toks/s, output: 4.58 toks/s]
Processed prompts:   3%|         | 262/8192 [00:58<30:51,  4.28it/s, est. speed input: 4559.39 toks/s, output: 4.45 toks/s]
Processed prompts:   4%|         | 326/8192 [01:14<31:16,  4.19it/s, est. speed input: 4469.35 toks/s, output: 4.36 toks/s]
Processed prompts:   5%|         | 390/8192 [01:30<31:14,  4.16it/s, est. speed input: 4424.04 toks/s, output: 4.32 toks/s]
Processed prompts:   6%|         | 454/8192 [01:46<31:17,  4.12it/s, est. speed input: 4381.02 toks/s, output: 4.28 toks/s]
Processed prompts:   6%|         | 518/8192 [02:01<31:14,  4.09it/s, est. speed input: 4348.96 toks/s, output: 4.25 toks/s]
Processed prompts:   7%|         | 582/8192 [02:17<31:06,  4.08it/s, est. speed input: 4324.50 toks/s, output: 4.22 toks/s]
Processed prompts:   8%|         | 646/8192 [02:33<30:56,  4.06it/s, est. speed input: 4304.59 toks/s, output: 4.20 toks/s]
Processed prompts:   9%|         | 710/8192 [02:49<30:44,  4.06it/s, est. speed input: 4288.55 toks/s, output: 4.19 toks/s]
Processed prompts:   9%|         | 774/8192 [03:05<30:22,  4.07it/s, est. speed input: 4281.44 toks/s, output: 4.18 toks/s]
Processed prompts:  10%|         | 838/8192 [03:20<30:10,  4.06it/s, est. speed input: 4269.94 toks/s, output: 4.17 toks/s]
Processed prompts:  11%|         | 902/8192 [03:36<29:58,  4.05it/s, est. speed input: 4260.06 toks/s, output: 4.16 toks/s]
Processed prompts:  12%|        | 966/8192 [03:52<29:44,  4.05it/s, est. speed input: 4251.52 toks/s, output: 4.15 toks/s]
Processed prompts:  13%|        | 1030/8192 [04:08<29:30,  4.05it/s, est. speed input: 4244.01 toks/s, output: 4.14 toks/s]
Processed prompts:  13%|        | 1094/8192 [04:24<29:15,  4.04it/s, est. speed input: 4237.33 toks/s, output: 4.14 toks/s]
Processed prompts:  14%|        | 1158/8192 [04:39<28:52,  4.06it/s, est. speed input: 4235.25 toks/s, output: 4.14 toks/s]
Processed prompts:  15%|        | 1222/8192 [04:55<28:39,  4.05it/s, est. speed input: 4229.74 toks/s, output: 4.13 toks/s]
Processed prompts:  16%|        | 1286/8192 [05:11<28:25,  4.05it/s, est. speed input: 4224.91 toks/s, output: 4.13 toks/s]
Processed prompts:  16%|        | 1350/8192 [05:27<28:11,  4.04it/s, est. speed input: 4220.33 toks/s, output: 4.12 toks/s]
Processed prompts:  17%|        | 1414/8192 [05:43<27:57,  4.04it/s, est. speed input: 4216.10 toks/s, output: 4.12 toks/s]
Processed prompts:  18%|        | 1478/8192 [05:59<27:42,  4.04it/s, est. speed input: 4212.39 toks/s, output: 4.11 toks/s]
Processed prompts:  19%|        | 1542/8192 [06:14<27:18,  4.06it/s, est. speed input: 4211.97 toks/s, output: 4.11 toks/s]
Processed prompts:  20%|        | 1606/8192 [06:30<26:57,  4.07it/s, est. speed input: 4211.43 toks/s, output: 4.11 toks/s]
Processed prompts:  20%|        | 1670/8192 [06:46<26:46,  4.06it/s, est. speed input: 4208.39 toks/s, output: 4.11 toks/s]
Processed prompts:  21%|        | 1734/8192 [07:01<26:26,  4.07it/s, est. speed input: 4207.98 toks/s, output: 4.11 toks/s]
Processed prompts:  22%|       | 1798/8192 [07:17<26:14,  4.06it/s, est. speed input: 4205.37 toks/s, output: 4.11 toks/s]
Processed prompts:  23%|       | 1862/8192 [07:33<26:01,  4.05it/s, est. speed input: 4202.79 toks/s, output: 4.10 toks/s]
Processed prompts:  24%|       | 1926/8192 [07:49<25:47,  4.05it/s, est. speed input: 4200.45 toks/s, output: 4.10 toks/s]
Processed prompts:  24%|       | 1990/8192 [08:05<25:33,  4.04it/s, est. speed input: 4198.19 toks/s, output: 4.10 toks/s]
Processed prompts:  25%|       | 2054/8192 [08:21<25:18,  4.04it/s, est. speed input: 4196.10 toks/s, output: 4.10 toks/s]
Processed prompts:  26%|       | 2118/8192 [08:37<25:03,  4.04it/s, est. speed input: 4194.09 toks/s, output: 4.10 toks/s]
Processed prompts:  27%|       | 2182/8192 [08:52<24:41,  4.06it/s, est. speed input: 4194.16 toks/s, output: 4.10 toks/s]
Processed prompts:  27%|       | 2246/8192 [09:08<24:28,  4.05it/s, est. speed input: 4192.34 toks/s, output: 4.09 toks/s]
Processed prompts:  28%|       | 2310/8192 [09:24<24:13,  4.05it/s, est. speed input: 4190.65 toks/s, output: 4.09 toks/s]
Processed prompts:  29%|       | 2374/8192 [09:40<23:59,  4.04it/s, est. speed input: 4188.98 toks/s, output: 4.09 toks/s]
Processed prompts:  30%|       | 2438/8192 [09:56<23:44,  4.04it/s, est. speed input: 4187.41 toks/s, output: 4.09 toks/s]
Processed prompts:  31%|       | 2502/8192 [10:12<23:29,  4.04it/s, est. speed input: 4185.90 toks/s, output: 4.09 toks/s]
Processed prompts:  31%|      | 2566/8192 [10:27<23:07,  4.06it/s, est. speed input: 4186.19 toks/s, output: 4.09 toks/s]
Processed prompts:  32%|      | 2630/8192 [10:43<22:53,  4.05it/s, est. speed input: 4184.78 toks/s, output: 4.09 toks/s]
Processed prompts:  33%|      | 2694/8192 [10:59<22:32,  4.06it/s, est. speed input: 4185.14 toks/s, output: 4.09 toks/s]
Processed prompts:  34%|      | 2758/8192 [11:15<22:20,  4.05it/s, est. speed input: 4183.85 toks/s, output: 4.09 toks/s]
Processed prompts:  34%|      | 2822/8192 [11:30<22:05,  4.05it/s, est. speed input: 4182.72 toks/s, output: 4.08 toks/s]
Processed prompts:  35%|      | 2886/8192 [11:46<21:40,  4.08it/s, est. speed input: 4184.15 toks/s, output: 4.09 toks/s]
Processed prompts:  36%|      | 2950/8192 [12:02<21:29,  4.06it/s, est. speed input: 4182.95 toks/s, output: 4.08 toks/s]
Processed prompts:  37%|      | 3014/8192 [12:18<21:16,  4.06it/s, est. speed input: 4181.83 toks/s, output: 4.08 toks/s]
Processed prompts:  38%|      | 3078/8192 [12:33<21:02,  4.05it/s, est. speed input: 4180.77 toks/s, output: 4.08 toks/s]
Processed prompts:  38%|      | 3142/8192 [12:49<20:48,  4.04it/s, est. speed input: 4179.68 toks/s, output: 4.08 toks/s]
Processed prompts:  39%|      | 3206/8192 [13:05<20:34,  4.04it/s, est. speed input: 4178.66 toks/s, output: 4.08 toks/s]
Processed prompts:  40%|      | 3270/8192 [13:21<20:18,  4.04it/s, est. speed input: 4177.75 toks/s, output: 4.08 toks/s]
Processed prompts:  41%|      | 3334/8192 [13:37<20:03,  4.04it/s, est. speed input: 4176.78 toks/s, output: 4.08 toks/s]
Processed prompts:  41%|     | 3398/8192 [13:53<19:48,  4.04it/s, est. speed input: 4175.87 toks/s, output: 4.08 toks/s]
Processed prompts:  42%|     | 3462/8192 [14:09<19:32,  4.04it/s, est. speed input: 4175.06 toks/s, output: 4.08 toks/s]
Processed prompts:  43%|     | 3526/8192 [14:24<19:16,  4.03it/s, est. speed input: 4174.22 toks/s, output: 4.08 toks/s]
Processed prompts:  44%|     | 3590/8192 [14:40<19:00,  4.03it/s, est. speed input: 4173.44 toks/s, output: 4.08 toks/s]
Processed prompts:  45%|     | 3654/8192 [14:56<18:39,  4.05it/s, est. speed input: 4173.85 toks/s, output: 4.08 toks/s]
Processed prompts:  45%|     | 3718/8192 [15:12<18:25,  4.05it/s, est. speed input: 4173.09 toks/s, output: 4.08 toks/s]
Processed prompts:  46%|     | 3782/8192 [15:28<18:10,  4.04it/s, est. speed input: 4172.38 toks/s, output: 4.07 toks/s]
Processed prompts:  47%|     | 3846/8192 [15:44<17:55,  4.04it/s, est. speed input: 4171.68 toks/s, output: 4.07 toks/s]
Processed prompts:  48%|     | 3910/8192 [15:59<17:35,  4.06it/s, est. speed input: 4172.12 toks/s, output: 4.07 toks/s]
Processed prompts:  49%|     | 3974/8192 [16:15<17:16,  4.07it/s, est. speed input: 4172.52 toks/s, output: 4.07 toks/s]
Processed prompts:  49%|     | 4038/8192 [16:30<16:58,  4.08it/s, est. speed input: 4172.98 toks/s, output: 4.08 toks/s]
Processed prompts:  50%|     | 4102/8192 [16:46<16:45,  4.07it/s, est. speed input: 4172.29 toks/s, output: 4.07 toks/s]
Processed prompts:  51%|     | 4166/8192 [17:02<16:32,  4.06it/s, est. speed input: 4171.63 toks/s, output: 4.07 toks/s]
Processed prompts:  52%|    | 4230/8192 [17:18<16:18,  4.05it/s, est. speed input: 4171.04 toks/s, output: 4.07 toks/s]
Processed prompts:  52%|    | 4294/8192 [17:34<16:03,  4.04it/s, est. speed input: 4170.42 toks/s, output: 4.07 toks/s]
Processed prompts:  53%|    | 4358/8192 [17:50<15:49,  4.04it/s, est. speed input: 4169.75 toks/s, output: 4.07 toks/s]
Processed prompts:  54%|    | 4422/8192 [18:05<15:29,  4.06it/s, est. speed input: 4170.17 toks/s, output: 4.07 toks/s]
Processed prompts:  55%|    | 4486/8192 [18:21<15:14,  4.05it/s, est. speed input: 4169.60 toks/s, output: 4.07 toks/s]
Processed prompts:  56%|    | 4550/8192 [18:37<14:55,  4.07it/s, est. speed input: 4169.98 toks/s, output: 4.07 toks/s]
Processed prompts:  56%|    | 4614/8192 [18:53<14:42,  4.05it/s, est. speed input: 4169.39 toks/s, output: 4.07 toks/s]
Processed prompts:  57%|    | 4678/8192 [19:09<14:27,  4.05it/s, est. speed input: 4168.87 toks/s, output: 4.07 toks/s]
Processed prompts:  58%|    | 4742/8192 [19:24<14:12,  4.04it/s, est. speed input: 4168.38 toks/s, output: 4.07 toks/s]
Processed prompts:  59%|    | 4806/8192 [19:40<13:57,  4.04it/s, est. speed input: 4167.89 toks/s, output: 4.07 toks/s]
Processed prompts:  59%|    | 4870/8192 [19:56<13:38,  4.06it/s, est. speed input: 4168.27 toks/s, output: 4.07 toks/s]
Processed prompts:  60%|    | 4934/8192 [20:12<13:20,  4.07it/s, est. speed input: 4168.58 toks/s, output: 4.07 toks/s]
Processed prompts:  61%|    | 4998/8192 [20:27<13:06,  4.06it/s, est. speed input: 4168.09 toks/s, output: 4.07 toks/s]
Processed prompts:  62%|   | 5062/8192 [20:43<12:52,  4.05it/s, est. speed input: 4167.63 toks/s, output: 4.07 toks/s]
Processed prompts:  63%|   | 5126/8192 [20:59<12:37,  4.05it/s, est. speed input: 4167.13 toks/s, output: 4.07 toks/s]
Processed prompts:  63%|   | 5190/8192 [21:15<12:19,  4.06it/s, est. speed input: 4167.51 toks/s, output: 4.07 toks/s]
Processed prompts:  64%|   | 5254/8192 [21:30<12:01,  4.07it/s, est. speed input: 4167.84 toks/s, output: 4.07 toks/s]
Processed prompts:  65%|   | 5318/8192 [21:46<11:47,  4.06it/s, est. speed input: 4167.38 toks/s, output: 4.07 toks/s]
Processed prompts:  66%|   | 5382/8192 [22:02<11:33,  4.05it/s, est. speed input: 4166.92 toks/s, output: 4.07 toks/s]
Processed prompts:  66%|   | 5446/8192 [22:18<11:18,  4.05it/s, est. speed input: 4166.46 toks/s, output: 4.07 toks/s]
Processed prompts:  67%|   | 5510/8192 [22:34<11:00,  4.06it/s, est. speed input: 4166.90 toks/s, output: 4.07 toks/s]
Processed prompts:  68%|   | 5574/8192 [22:49<10:42,  4.07it/s, est. speed input: 4167.23 toks/s, output: 4.07 toks/s]
Processed prompts:  69%|   | 5638/8192 [23:05<10:28,  4.06it/s, est. speed input: 4166.79 toks/s, output: 4.07 toks/s]
Processed prompts:  70%|   | 5702/8192 [23:21<10:14,  4.05it/s, est. speed input: 4166.37 toks/s, output: 4.07 toks/s]
Processed prompts:  70%|   | 5766/8192 [23:37<09:59,  4.05it/s, est. speed input: 4165.95 toks/s, output: 4.07 toks/s]
Processed prompts:  71%|   | 5830/8192 [23:53<09:44,  4.04it/s, est. speed input: 4165.54 toks/s, output: 4.07 toks/s]
Processed prompts:  72%|  | 5894/8192 [24:08<09:26,  4.06it/s, est. speed input: 4165.90 toks/s, output: 4.07 toks/s]
Processed prompts:  73%|  | 5958/8192 [24:24<09:08,  4.07it/s, est. speed input: 4166.23 toks/s, output: 4.07 toks/s]
Processed prompts:  74%|  | 6022/8192 [24:40<08:54,  4.06it/s, est. speed input: 4165.83 toks/s, output: 4.07 toks/s]
Processed prompts:  74%|  | 6086/8192 [24:56<08:39,  4.05it/s, est. speed input: 4165.42 toks/s, output: 4.07 toks/s]
Processed prompts:  75%|  | 6150/8192 [25:12<08:24,  4.04it/s, est. speed input: 4165.03 toks/s, output: 4.07 toks/s]
Processed prompts:  76%|  | 6214/8192 [25:27<08:09,  4.04it/s, est. speed input: 4164.64 toks/s, output: 4.07 toks/s]
Processed prompts:  77%|  | 6278/8192 [25:43<07:54,  4.04it/s, est. speed input: 4164.26 toks/s, output: 4.07 toks/s]
Processed prompts:  77%|  | 6342/8192 [25:59<07:38,  4.04it/s, est. speed input: 4163.92 toks/s, output: 4.07 toks/s]
Processed prompts:  78%|  | 6406/8192 [26:15<07:22,  4.04it/s, est. speed input: 4163.57 toks/s, output: 4.07 toks/s]
Processed prompts:  79%|  | 6470/8192 [26:31<07:06,  4.03it/s, est. speed input: 4163.21 toks/s, output: 4.07 toks/s]
Processed prompts:  80%|  | 6534/8192 [26:47<06:51,  4.03it/s, est. speed input: 4162.88 toks/s, output: 4.07 toks/s]
Processed prompts:  81%|  | 6598/8192 [27:03<06:35,  4.03it/s, est. speed input: 4162.54 toks/s, output: 4.06 toks/s]
Processed prompts:  81%| | 6662/8192 [27:18<06:19,  4.03it/s, est. speed input: 4162.23 toks/s, output: 4.06 toks/s]
Processed prompts:  82%| | 6726/8192 [27:34<06:03,  4.03it/s, est. speed input: 4161.91 toks/s, output: 4.06 toks/s]
Processed prompts:  83%| | 6790/8192 [27:50<05:47,  4.03it/s, est. speed input: 4161.62 toks/s, output: 4.06 toks/s]
Processed prompts:  84%| | 6854/8192 [28:06<05:31,  4.03it/s, est. speed input: 4161.29 toks/s, output: 4.06 toks/s]
Processed prompts:  84%| | 6918/8192 [28:22<05:15,  4.03it/s, est. speed input: 4160.98 toks/s, output: 4.06 toks/s]
Processed prompts:  85%| | 6982/8192 [28:38<05:00,  4.03it/s, est. speed input: 4160.69 toks/s, output: 4.06 toks/s]
Processed prompts:  86%| | 7046/8192 [28:54<04:44,  4.03it/s, est. speed input: 4160.38 toks/s, output: 4.06 toks/s]
Processed prompts:  87%| | 7110/8192 [29:10<04:28,  4.03it/s, est. speed input: 4160.10 toks/s, output: 4.06 toks/s]
Processed prompts:  88%| | 7174/8192 [29:25<04:12,  4.03it/s, est. speed input: 4159.83 toks/s, output: 4.06 toks/s]
Processed prompts:  88%| | 7238/8192 [29:41<03:56,  4.03it/s, est. speed input: 4159.53 toks/s, output: 4.06 toks/s]
Processed prompts:  89%| | 7302/8192 [29:57<03:40,  4.03it/s, est. speed input: 4159.25 toks/s, output: 4.06 toks/s]
Processed prompts:  90%| | 7366/8192 [30:13<03:24,  4.03it/s, est. speed input: 4159.00 toks/s, output: 4.06 toks/s]
Processed prompts:  91%| | 7430/8192 [30:29<03:09,  4.03it/s, est. speed input: 4158.63 toks/s, output: 4.06 toks/s]
Processed prompts:  91%|| 7494/8192 [30:45<02:53,  4.02it/s, est. speed input: 4158.14 toks/s, output: 4.06 toks/s]
Processed prompts:  92%|| 7558/8192 [31:01<02:37,  4.02it/s, est. speed input: 4157.84 toks/s, output: 4.06 toks/s]
Processed prompts:  93%|| 7622/8192 [31:17<02:20,  4.04it/s, est. speed input: 4158.13 toks/s, output: 4.06 toks/s]
Processed prompts:  94%|| 7686/8192 [31:32<02:05,  4.04it/s, est. speed input: 4157.85 toks/s, output: 4.06 toks/s]
Processed prompts:  95%|| 7750/8192 [31:48<01:49,  4.04it/s, est. speed input: 4157.61 toks/s, output: 4.06 toks/s]
Processed prompts:  95%|| 7814/8192 [32:04<01:33,  4.03it/s, est. speed input: 4157.35 toks/s, output: 4.06 toks/s]
Processed prompts:  96%|| 7878/8192 [32:20<01:17,  4.03it/s, est. speed input: 4157.11 toks/s, output: 4.06 toks/s]
Processed prompts:  97%|| 7942/8192 [32:36<01:01,  4.03it/s, est. speed input: 4156.86 toks/s, output: 4.06 toks/s]
Processed prompts:  98%|| 8006/8192 [32:52<00:46,  4.03it/s, est. speed input: 4156.59 toks/s, output: 4.06 toks/s]
Processed prompts:  99%|| 8070/8192 [33:08<00:30,  4.03it/s, est. speed input: 4156.34 toks/s, output: 4.06 toks/s]
Processed prompts:  99%|| 8134/8192 [33:22<00:14,  4.13it/s, est. speed input: 4158.64 toks/s, output: 4.06 toks/s]
Processed prompts: 100%|| 8192/8192 [33:22<00:00,  4.13it/s, est. speed input: 4188.29 toks/s, output: 4.09 toks/s]
Processed prompts: 100%|| 8192/8192 [33:22<00:00,  4.09it/s, est. speed input: 4188.29 toks/s, output: 4.09 toks/s]
[rank0]:[W127 09:50:23.428261379 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

