
========== M=16 ==========
Time: 2026-01-25 18:49:58
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10
Params: prompt_len=16, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 17 --max-num-batched-tokens 17 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-1B-FP8_M16.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 18:50:01 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 18:50:01 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=303457) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=303457) 
(EngineCore_DP0 pid=303457) 
(EngineCore_DP0 pid=303457) ================================================================
(EngineCore_DP0 pid=303457) Internal Triton PTX codegen error
(EngineCore_DP0 pid=303457) `ptxas` stderr:
(EngineCore_DP0 pid=303457) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=303457) 
(EngineCore_DP0 pid=303457) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpknb86adt.ptx -o /tmp/tmpknb86adt.ptx.o
(EngineCore_DP0 pid=303457) 
(EngineCore_DP0 pid=303457) 
(EngineCore_DP0 pid=303457) //
(EngineCore_DP0 pid=303457) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=303457) //
(EngineCore_DP0 pid=303457) 
(EngineCore_DP0 pid=303457) .version 8.7
(EngineCore_DP0 pid=303457) .target sm_121a
(EngineCore_DP0 pid=303457) .address_size 64
(EngineCore_DP0 pid=303457) 
(EngineCore_DP0 pid=303457) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=303457) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=303457)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=303457) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=303457) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=303457) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=303457) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=303457) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=303457) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=303457) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=303457) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=303457) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=303457) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=303457) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=303457) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=303457) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=303457) )
(EngineCore_DP0 pid=303457) .reqntid 512
(EngineCore_DP0 pid=303457) {
(EngineCore_DP0 pid=303457) 	.reg .pred 	%p<20>;
(EngineCore_DP0 pid=303457) 	.reg .b16 	%rs<37>;
(EngineCore_DP0 pid=303457) 	.reg .b32 	%r<118>;
(EngineCore_DP0 pid=303457) 	.reg .b64 	%rd<13>;
(EngineCore_DP0 pid=303457) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=303457) $L__func_begin0:
(EngineCore_DP0 pid=303457) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=303457) 
(EngineCore_DP0 pid=303457) // %bb.0:
(EngineCore_DP0 pid=303457) 	ld.param.b32 	%r20, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=303457) 	ld.param.b32 	%r19, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=303457) 	ld.param.b32 	%r18, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=303457) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=303457) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=303457) $L__tmp0:
(EngineCore_DP0 pid=303457) 	.loc	1 177 24                        // quant_slide_tuned_Llama3.2-1B.py:177:24
(EngineCore_DP0 pid=303457) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=303457) 	ld.param.b32 	%r22, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=303457) 	.loc	1 182 26                        // quant_slide_tuned_Llama3.2-1B.py:182:26
(EngineCore_DP0 pid=303457) 	mul.lo.s32 	%r23, %r22, %r1;
(EngineCore_DP0 pid=303457) 	.loc	1 182 20                        // quant_slide_tuned_Llama3.2-1B.py:182:20
(EngineCore_DP0 pid=303457) 	mad.wide.s32 	%rd1, %r23, 2, %rd4;
(EngineCore_DP0 pid=303457) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=303457) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=303457) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=303457) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=303457) 	setp.lt.s32 	%p1, %r19, 1;
(EngineCore_DP0 pid=303457) 	mov.b32 	%r116, 0f2B8CBCCC;
(EngineCore_DP0 pid=303457) 	setp.eq.b32 	%p19, %r2, 0;
(EngineCore_DP0 pid=303457) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=303457) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=303457) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=303457) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=303457) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=303457) 	shr.u32 	%r32, %r2, 3;
(EngineCore_DP0 pid=303457) 	and.b32 	%r33, %r32, 60;
(EngineCore_DP0 pid=303457) 	mov.b32 	%r34, global_smem;
(EngineCore_DP0 pid=303457) 	add.s32 	%r44, %r34, %r33;
(EngineCore_DP0 pid=303457) 	shl.b32 	%r35, %r2, 2;
(EngineCore_DP0 pid=303457) 	add.s32 	%r47, %r34, %r35;
(EngineCore_DP0 pid=303457) 	mov.b32 	%r40, 0;
(EngineCore_DP0 pid=303457) 	mov.b32 	%r114, 0f00000000;
(EngineCore_DP0 pid=303457) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=303457) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=303457) 	mov.b32 	%r115, %r40;
(EngineCore_DP0 pid=303457) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=303457) 	.loc	1 189 22                        // quant_slide_tuned_Llama3.2-1B.py:189:22
(EngineCore_DP0 pid=303457) 	add.s32 	%r50, %r4, %r115;
(EngineCore_DP0 pid=303457) 	setp.lt.s32 	%p2, %r50, %r18;
(EngineCore_DP0 pid=303457) 	.loc	1 190 29                        // quant_slide_tuned_Llama3.2-1B.py:190:29
(EngineCore_DP0 pid=303457) 	mad.wide.s32 	%rd6, %r50, 2, %rd1;
(EngineCore_DP0 pid=303457) 	.loc	1 190 21                        // quant_slide_tuned_Llama3.2-1B.py:190:21
(EngineCore_DP0 pid=303457) 	// begin inline asm
(EngineCore_DP0 pid=303457) 	mov.u32 %r36, %r40;
(EngineCore_DP0 pid=303457) 	mov.u32 %r37, %r40;
(EngineCore_DP0 pid=303457) 	mov.u32 %r38, %r40;
(EngineCore_DP0 pid=303457) 	mov.u32 %r39, %r40;
(EngineCore_DP0 pid=303457) 	@%p2 ld.global.v4.b32 { %r36, %r37, %r38, %r39 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=303457) 	// end inline asm
(EngineCore_DP0 pid=303457) 	mov.b32 	{%rs1, %rs2}, %r36;
(EngineCore_DP0 pid=303457) 	mov.b32 	{%rs3, %rs4}, %r37;
(EngineCore_DP0 pid=303457) 	mov.b32 	{%rs5, %rs6}, %r38;
(EngineCore_DP0 pid=303457) 	mov.b32 	{%rs7, %rs8}, %r39;
(EngineCore_DP0 pid=303457) 	.loc	1 191 50                        // quant_slide_tuned_Llama3.2-1B.py:191:50
(EngineCore_DP0 pid=303457) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=303457) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=303457) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=303457) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=303457) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=303457) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=303457) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=303457) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=303457) $L__tmp1:
(EngineCore_DP0 pid=303457) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=303457) 	bar.sync 	0;
(EngineCore_DP0 pid=303457) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=303457) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=303457) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=303457) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=303457) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=303457) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=303457) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=303457) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=303457) 	cvt.f32.bf16 	%r51, %rs23;
(EngineCore_DP0 pid=303457) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=303457) 	shfl.sync.bfly.b32 	%r52, %r51, 16, 31, -1;
(EngineCore_DP0 pid=303457) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=303457) 	max.f32 	%r53, %r51, %r52;
(EngineCore_DP0 pid=303457) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=303457) 	shfl.sync.bfly.b32 	%r54, %r53, 8, 31, -1;
(EngineCore_DP0 pid=303457) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=303457) 	max.f32 	%r55, %r53, %r54;
(EngineCore_DP0 pid=303457) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=303457) 	shfl.sync.bfly.b32 	%r56, %r55, 4, 31, -1;
(EngineCore_DP0 pid=303457) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=303457) 	max.f32 	%r57, %r55, %r56;
(EngineCore_DP0 pid=303457) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=303457) 	shfl.sync.bfly.b32 	%r58, %r57, 2, 31, -1;
(EngineCore_DP0 pid=303457) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=303457) 	max.f32 	%r59, %r57, %r58;
(EngineCore_DP0 pid=303457) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=303457) 	shfl.sync.bfly.b32 	%r60, %r59, 1, 31, -1;
(EngineCore_DP0 pid=303457) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=303457) 	max.f32 	%r45, %r59, %r60;
(EngineCore_DP0 pid=303457) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=303457) 	// begin inline asm
(EngineCore_DP0 pid=303457) 	@%p3 st.shared.b32 [ %r44 + 0 ], %r45;
(EngineCore_DP0 pid=303457) 	// end inline asm
(EngineCore_DP0 pid=303457) 	bar.sync 	0;
(EngineCore_DP0 pid=303457) 	// begin inline asm
(EngineCore_DP0 pid=303457) 	@%p4 ld.shared.b32 %r46, [ %r47 + 0 ];
(EngineCore_DP0 pid=303457) 	// end inline asm
(EngineCore_DP0 pid=303457) 	shfl.sync.bfly.b32 	%r61, %r46, 8, 31, -1;
(EngineCore_DP0 pid=303457) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=303457) 	max.f32 	%r62, %r46, %r61;
(EngineCore_DP0 pid=303457) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=303457) 	shfl.sync.bfly.b32 	%r63, %r62, 4, 31, -1;
(EngineCore_DP0 pid=303457) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=303457) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=303457) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=303457) 	shfl.sync.bfly.b32 	%r65, %r64, 2, 31, -1;
(EngineCore_DP0 pid=303457) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=303457) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=303457) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=303457) 	shfl.sync.bfly.b32 	%r67, %r66, 1, 31, -1;
(EngineCore_DP0 pid=303457) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=303457) 	max.f32 	%r49, %r66, %r67;
(EngineCore_DP0 pid=303457) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=303457) 	// begin inline asm
(EngineCore_DP0 pid=303457) 	@%p19 st.shared.b32 [ %r47 + 0 ], %r49;
(EngineCore_DP0 pid=303457) 	// end inline asm
(EngineCore_DP0 pid=303457) 	bar.sync 	0;
(EngineCore_DP0 pid=303457) 	ld.shared.b32 	%r68, [global_smem];
(EngineCore_DP0 pid=303457) $L__tmp2:
(EngineCore_DP0 pid=303457) 	.loc	1 191 36                        // quant_slide_tuned_Llama3.2-1B.py:191:36
(EngineCore_DP0 pid=303457) 	max.f32 	%r114, %r114, %r68;
(EngineCore_DP0 pid=303457) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=303457) 	add.s32 	%r115, %r115, 4096;
(EngineCore_DP0 pid=303457) 	setp.lt.s32 	%p6, %r115, %r19;
(EngineCore_DP0 pid=303457) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=303457) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=303457) 	.loc	1 193 32                        // quant_slide_tuned_Llama3.2-1B.py:193:32
(EngineCore_DP0 pid=303457) 	max.f32 	%r116, %r114, 0f2B8CBCCC;
(EngineCore_DP0 pid=303457) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=303457) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=303457) 	mov.b32 	%r70, 0f43E00000;
(EngineCore_DP0 pid=303457) 	.loc	1 194 32                        // quant_slide_tuned_Llama3.2-1B.py:194:32
(EngineCore_DP0 pid=303457) 	div.full.f32 	%r71, %r116, %r70;
(EngineCore_DP0 pid=303457) 	.loc	1 194 41                        // quant_slide_tuned_Llama3.2-1B.py:194:41
(EngineCore_DP0 pid=303457) 	max.f32 	%r69, %r71, 0f36924925;
(EngineCore_DP0 pid=303457) 	.loc	1 196 25                        // quant_slide_tuned_Llama3.2-1B.py:196:25
(EngineCore_DP0 pid=303457) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=303457) 	.loc	1 196 30                        // quant_slide_tuned_Llama3.2-1B.py:196:30
(EngineCore_DP0 pid=303457) 	// begin inline asm
(EngineCore_DP0 pid=303457) 	@%p19 st.global.b32 [ %rd7 + 0 ], { %r69 };
(EngineCore_DP0 pid=303457) 	// end inline asm
(EngineCore_DP0 pid=303457) 	.loc	1 199 29                        // quant_slide_tuned_Llama3.2-1B.py:199:29
(EngineCore_DP0 pid=303457) 	shl.b32 	%r15, %r20, 2;
(EngineCore_DP0 pid=303457) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=303457) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=303457) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=303457) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=303457) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=303457) 	ld.param.b32 	%r24, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=303457) 	shr.s32 	%r25, %r24, 31;
(EngineCore_DP0 pid=303457) 	shr.u32 	%r26, %r25, 30;
(EngineCore_DP0 pid=303457) 	add.s32 	%r27, %r24, %r26;
(EngineCore_DP0 pid=303457) 	shr.s32 	%r28, %r27, 2;
(EngineCore_DP0 pid=303457) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=303457) 	mul.lo.s32 	%r29, %r28, %r1;
(EngineCore_DP0 pid=303457) 	mad.wide.s32 	%rd2, %r29, 4, %rd5;
(EngineCore_DP0 pid=303457) 	div.full.f32 	%r14, %r70, %r116;
(EngineCore_DP0 pid=303457) 	mov.b32 	%r117, 0;
(EngineCore_DP0 pid=303457) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=303457)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=303457) 	.loc	1 203 30                        // quant_slide_tuned_Llama3.2-1B.py:203:30
(EngineCore_DP0 pid=303457) 	add.s32 	%r83, %r3, %r117;
(EngineCore_DP0 pid=303457) 	setp.lt.s32 	%p13, %r83, %r15;
(EngineCore_DP0 pid=303457) 	.loc	1 206 24                        // quant_slide_tuned_Llama3.2-1B.py:206:24
(EngineCore_DP0 pid=303457) 	shr.s32 	%r84, %r83, 31;
(EngineCore_DP0 pid=303457) 	shr.u32 	%r85, %r84, 30;
(EngineCore_DP0 pid=303457) 	add.s32 	%r86, %r83, %r85;
(EngineCore_DP0 pid=303457) 	shr.s32 	%r87, %r86, 2;
(EngineCore_DP0 pid=303457) 	.loc	1 207 23                        // quant_slide_tuned_Llama3.2-1B.py:207:23
(EngineCore_DP0 pid=303457) 	and.b32 	%r88, %r86, 2147483644;
(EngineCore_DP0 pid=303457) 	sub.s32 	%r89, %r83, %r88;
(EngineCore_DP0 pid=303457) 	.loc	1 208 30                        // quant_slide_tuned_Llama3.2-1B.py:208:30
(EngineCore_DP0 pid=303457) 	shl.b32 	%r90, %r89, 1;
(EngineCore_DP0 pid=303457) 	.loc	1 208 26                        // quant_slide_tuned_Llama3.2-1B.py:208:26
(EngineCore_DP0 pid=303457) 	mad.lo.s32 	%r91, %r87, 10, %r90;
(EngineCore_DP0 pid=303457) 	.loc	1 211 53                        // quant_slide_tuned_Llama3.2-1B.py:211:53
(EngineCore_DP0 pid=303457) 	setp.lt.s32 	%p14, %r91, %r18;
(EngineCore_DP0 pid=303457) 	.loc	1 211 37                        // quant_slide_tuned_Llama3.2-1B.py:211:37
(EngineCore_DP0 pid=303457) 	and.pred 	%p9, %p13, %p14;
(EngineCore_DP0 pid=303457) 	.loc	1 210 29                        // quant_slide_tuned_Llama3.2-1B.py:210:29
(EngineCore_DP0 pid=303457) 	mad.wide.s32 	%rd8, %r91, 2, %rd1;
(EngineCore_DP0 pid=303457) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=303457) 	.loc	1 210 21                        // quant_slide_tuned_Llama3.2-1B.py:210:21
(EngineCore_DP0 pid=303457) 	// begin inline asm
(EngineCore_DP0 pid=303457) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=303457) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=303457) 	// end inline asm
(EngineCore_DP0 pid=303457) 	.loc	1 211 79                        // quant_slide_tuned_Llama3.2-1B.py:211:79
(EngineCore_DP0 pid=303457) 	cvt.f32.bf16 	%r92, %rs24;
(EngineCore_DP0 pid=303457) 	.loc	1 213 48                        // quant_slide_tuned_Llama3.2-1B.py:213:48
(EngineCore_DP0 pid=303457) 	or.b32 	%r93, %r91, 1;
(EngineCore_DP0 pid=303457) 	.loc	1 213 53                        // quant_slide_tuned_Llama3.2-1B.py:213:53
(EngineCore_DP0 pid=303457) 	setp.lt.s32 	%p15, %r93, %r18;
(EngineCore_DP0 pid=303457) 	.loc	1 213 37                        // quant_slide_tuned_Llama3.2-1B.py:213:37
(EngineCore_DP0 pid=303457) 	and.pred 	%p10, %p13, %p15;
(EngineCore_DP0 pid=303457) 	.loc	1 212 39                        // quant_slide_tuned_Llama3.2-1B.py:212:39
(EngineCore_DP0 pid=303457) 	add.s64 	%rd9, %rd8, 2;
(EngineCore_DP0 pid=303457) 	.loc	1 212 21                        // quant_slide_tuned_Llama3.2-1B.py:212:21
(EngineCore_DP0 pid=303457) 	// begin inline asm
(EngineCore_DP0 pid=303457) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=303457) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=303457) 	// end inline asm
(EngineCore_DP0 pid=303457) 	.loc	1 213 79                        // quant_slide_tuned_Llama3.2-1B.py:213:79
(EngineCore_DP0 pid=303457) 	cvt.f32.bf16 	%r94, %rs26;
(EngineCore_DP0 pid=303457) 	.loc	1 215 48                        // quant_slide_tuned_Llama3.2-1B.py:215:48
(EngineCore_DP0 pid=303457) 	add.s32 	%r95, %r91, 2;
(EngineCore_DP0 pid=303457) 	.loc	1 215 53                        // quant_slide_tuned_Llama3.2-1B.py:215:53
(EngineCore_DP0 pid=303457) 	setp.lt.s32 	%p16, %r95, %r18;
(EngineCore_DP0 pid=303457) 	.loc	1 215 37                        // quant_slide_tuned_Llama3.2-1B.py:215:37
(EngineCore_DP0 pid=303457) 	and.pred 	%p11, %p13, %p16;
(EngineCore_DP0 pid=303457) 	.loc	1 214 39                        // quant_slide_tuned_Llama3.2-1B.py:214:39
(EngineCore_DP0 pid=303457) 	add.s64 	%rd10, %rd8, 4;
(EngineCore_DP0 pid=303457) 	.loc	1 214 21                        // quant_slide_tuned_Llama3.2-1B.py:214:21
(EngineCore_DP0 pid=303457) 	// begin inline asm
(EngineCore_DP0 pid=303457) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=303457) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=303457) 	// end inline asm
(EngineCore_DP0 pid=303457) 	.loc	1 215 79                        // quant_slide_tuned_Llama3.2-1B.py:215:79
(EngineCore_DP0 pid=303457) 	cvt.f32.bf16 	%r96, %rs28;
(EngineCore_DP0 pid=303457) 	.loc	1 217 48                        // quant_slide_tuned_Llama3.2-1B.py:217:48
(EngineCore_DP0 pid=303457) 	add.s32 	%r97, %r91, 3;
(EngineCore_DP0 pid=303457) 	.loc	1 217 53                        // quant_slide_tuned_Llama3.2-1B.py:217:53
(EngineCore_DP0 pid=303457) 	setp.lt.s32 	%p17, %r97, %r18;
(EngineCore_DP0 pid=303457) 	.loc	1 217 37                        // quant_slide_tuned_Llama3.2-1B.py:217:37
(EngineCore_DP0 pid=303457) 	and.pred 	%p12, %p13, %p17;
(EngineCore_DP0 pid=303457) 	.loc	1 216 39                        // quant_slide_tuned_Llama3.2-1B.py:216:39
(EngineCore_DP0 pid=303457) 	add.s64 	%rd11, %rd8, 6;
(EngineCore_DP0 pid=303457) 	.loc	1 216 21                        // quant_slide_tuned_Llama3.2-1B.py:216:21
(EngineCore_DP0 pid=303457) 	// begin inline asm
(EngineCore_DP0 pid=303457) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=303457) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=303457) 	// end inline asm
(EngineCore_DP0 pid=303457) 	.loc	1 217 79                        // quant_slide_tuned_Llama3.2-1B.py:217:79
(EngineCore_DP0 pid=303457) 	cvt.f32.bf16 	%r98, %rs30;
(EngineCore_DP0 pid=303457) 	.loc	1 219 27                        // quant_slide_tuned_Llama3.2-1B.py:219:27
(EngineCore_DP0 pid=303457) 	mul.f32 	%r99, %r14, %r92;
(EngineCore_DP0 pid=303457) 	mov.b32 	%r100, 0f43E00000;
(EngineCore_DP0 pid=303457) 	.loc	1 219 48                        // quant_slide_tuned_Llama3.2-1B.py:219:48
(EngineCore_DP0 pid=303457) 	min.xorsign.abs.f32 	%r73, %r99, %r100;
(EngineCore_DP0 pid=303457) 	.loc	1 219 60                        // quant_slide_tuned_Llama3.2-1B.py:219:60
(EngineCore_DP0 pid=303457) 	// begin inline asm
(EngineCore_DP0 pid=303457) 	cvt.rn.satfinite.e4m3x2.f32  %rs32, %r74, %r73; 
(EngineCore_DP0 pid=303457) 
(EngineCore_DP0 pid=303457) 	// end inline asm
(EngineCore_DP0 pid=303457) 	.loc	1 220 27                        // quant_slide_tuned_Llama3.2-1B.py:220:27
(EngineCore_DP0 pid=303457) 	mul.f32 	%r101, %r14, %r94;
(EngineCore_DP0 pid=303457) 	.loc	1 220 48                        // quant_slide_tuned_Llama3.2-1B.py:220:48
(EngineCore_DP0 pid=303457) 	min.xorsign.abs.f32 	%r75, %r101, %r100;
(EngineCore_DP0 pid=303457) 	.loc	1 220 60                        // quant_slide_tuned_Llama3.2-1B.py:220:60
(EngineCore_DP0 pid=303457) 	// begin inline asm
(EngineCore_DP0 pid=303457) 	cvt.rn.satfinite.e4m3x2.f32  %rs33, %r76, %r75; 
(EngineCore_DP0 pid=303457) 
(EngineCore_DP0 pid=303457) 	// end inline asm
(EngineCore_DP0 pid=303457) 	.loc	1 221 27                        // quant_slide_tuned_Llama3.2-1B.py:221:27
(EngineCore_DP0 pid=303457) 	mul.f32 	%r102, %r14, %r96;
(EngineCore_DP0 pid=303457) 	.loc	1 221 48                        // quant_slide_tuned_Llama3.2-1B.py:221:48
(EngineCore_DP0 pid=303457) 	min.xorsign.abs.f32 	%r77, %r102, %r100;
(EngineCore_DP0 pid=303457) 	.loc	1 221 60                        // quant_slide_tuned_Llama3.2-1B.py:221:60
(EngineCore_DP0 pid=303457) 	// begin inline asm
(EngineCore_DP0 pid=303457) 	cvt.rn.satfinite.e4m3x2.f32  %rs34, %r78, %r77; 
(EngineCore_DP0 pid=303457) 
(EngineCore_DP0 pid=303457) 	// end inline asm
(EngineCore_DP0 pid=303457) 	.loc	1 222 27                        // quant_slide_tuned_Llama3.2-1B.py:222:27
(EngineCore_DP0 pid=303457) 	mul.f32 	%r103, %r14, %r98;
(EngineCore_DP0 pid=303457) 	.loc	1 222 48                        // quant_slide_tuned_Llama3.2-1B.py:222:48
(EngineCore_DP0 pid=303457) 	min.xorsign.abs.f32 	%r79, %r103, %r100;
(EngineCore_DP0 pid=303457) 	.loc	1 222 60                        // quant_slide_tuned_Llama3.2-1B.py:222:60
(EngineCore_DP0 pid=303457) 	// begin inline asm
(EngineCore_DP0 pid=303457) 	cvt.rn.satfinite.e4m3x2.f32  %rs35, %r80, %r79; 
(EngineCore_DP0 pid=303457) 
(EngineCore_DP0 pid=303457) 	// end inline asm
(EngineCore_DP0 pid=303457) 	.loc	1 224 45                        // quant_slide_tuned_Llama3.2-1B.py:224:45
(EngineCore_DP0 pid=303457) 	cvt.u32.u16 	%r104, %rs32;
(EngineCore_DP0 pid=303457) 	and.b32 	%r105, %r104, 255;
(EngineCore_DP0 pid=303457) 	.loc	1 226 45                        // quant_slide_tuned_Llama3.2-1B.py:226:45
(EngineCore_DP0 pid=303457) 	cvt.u32.u16 	%r106, %rs34;
(EngineCore_DP0 pid=303457) 	and.b32 	%r107, %r106, 255;
(EngineCore_DP0 pid=303457) 	.loc	1 227 45                        // quant_slide_tuned_Llama3.2-1B.py:227:45
(EngineCore_DP0 pid=303457) 	cvt.u32.u16 	%r108, %rs35;
(EngineCore_DP0 pid=303457) 	.loc	1 229 30                        // quant_slide_tuned_Llama3.2-1B.py:229:30
(EngineCore_DP0 pid=303457) 	and.b16 	%rs36, %rs33, 255;
(EngineCore_DP0 pid=303457) 	mul.wide.u16 	%r109, %rs36, 256;
(EngineCore_DP0 pid=303457) 	.loc	1 229 24                        // quant_slide_tuned_Llama3.2-1B.py:229:24
(EngineCore_DP0 pid=303457) 	or.b32 	%r110, %r109, %r105;
(EngineCore_DP0 pid=303457) 	.loc	1 229 42                        // quant_slide_tuned_Llama3.2-1B.py:229:42
(EngineCore_DP0 pid=303457) 	shl.b32 	%r111, %r107, 16;
(EngineCore_DP0 pid=303457) 	.loc	1 229 36                        // quant_slide_tuned_Llama3.2-1B.py:229:36
(EngineCore_DP0 pid=303457) 	or.b32 	%r112, %r110, %r111;
(EngineCore_DP0 pid=303457) 	.loc	1 229 55                        // quant_slide_tuned_Llama3.2-1B.py:229:55
(EngineCore_DP0 pid=303457) 	shl.b32 	%r113, %r108, 24;
(EngineCore_DP0 pid=303457) 	.loc	1 229 49                        // quant_slide_tuned_Llama3.2-1B.py:229:49
(EngineCore_DP0 pid=303457) 	or.b32 	%r81, %r112, %r113;
(EngineCore_DP0 pid=303457) 	.loc	1 230 29                        // quant_slide_tuned_Llama3.2-1B.py:230:29
(EngineCore_DP0 pid=303457) 	mad.wide.s32 	%rd12, %r83, 4, %rd2;
(EngineCore_DP0 pid=303457) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-1B.py:230:39
(EngineCore_DP0 pid=303457) 	// begin inline asm
(EngineCore_DP0 pid=303457) 	@%p13 st.global.b32 [ %rd12 + 0 ], { %r81 };
(EngineCore_DP0 pid=303457) 	// end inline asm
(EngineCore_DP0 pid=303457) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=303457) 	add.s32 	%r117, %r117, 512;
(EngineCore_DP0 pid=303457) 	setp.lt.s32 	%p18, %r117, %r15;
(EngineCore_DP0 pid=303457) 	@%p18 bra 	$L__BB0_6;
(EngineCore_DP0 pid=303457) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=303457) 	.loc	1 201 4                         // quant_slide_tuned_Llama3.2-1B.py:201:4
(EngineCore_DP0 pid=303457) 	ret;
(EngineCore_DP0 pid=303457) $L__tmp3:
(EngineCore_DP0 pid=303457) $L__func_end0:
(EngineCore_DP0 pid=303457)                                         // -- End function
(EngineCore_DP0 pid=303457) }
(EngineCore_DP0 pid=303457) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=303457) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=303457) 	.section	.debug_abbrev
(EngineCore_DP0 pid=303457) 	{
(EngineCore_DP0 pid=303457) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=303457) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=303457) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=303457) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=303457) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=303457) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=303457) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=303457) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=303457) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=303457) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=303457) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=303457) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=303457) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=303457) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=303457) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=303457) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=303457) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=303457) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=303457) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=303457) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=303457) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=303457) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=303457) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=303457) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=303457) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=303457) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=303457) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=303457) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=303457) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=303457) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=303457) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=303457) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=303457) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=303457) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=303457) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=303457) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=303457) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=303457) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=303457) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=303457) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=303457) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=303457) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=303457) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=303457) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=303457) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=303457) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=303457) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=303457) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=303457) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=303457) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=303457) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=303457) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=303457) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=303457) 	}
(EngineCore_DP0 pid=303457) 	.section	.debug_info
(EngineCore_DP0 pid=303457) 	{
(EngineCore_DP0 pid=303457) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=303457) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=303457) .b8 0
(EngineCore_DP0 pid=303457) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=303457) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=303457) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=303457) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=303457) .b8 114
(EngineCore_DP0 pid=303457) .b8 105
(EngineCore_DP0 pid=303457) .b8 116
(EngineCore_DP0 pid=303457) .b8 111
(EngineCore_DP0 pid=303457) .b8 110
(EngineCore_DP0 pid=303457) .b8 0
(EngineCore_DP0 pid=303457) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=303457) .b8 0
(EngineCore_DP0 pid=303457) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=303457) .b8 117
(EngineCore_DP0 pid=303457) .b8 97
(EngineCore_DP0 pid=303457) .b8 110
(EngineCore_DP0 pid=303457) .b8 116
(EngineCore_DP0 pid=303457) .b8 95
(EngineCore_DP0 pid=303457) .b8 115
(EngineCore_DP0 pid=303457) .b8 108
(EngineCore_DP0 pid=303457) .b8 105
(EngineCore_DP0 pid=303457) .b8 100
(EngineCore_DP0 pid=303457) .b8 101
(EngineCore_DP0 pid=303457) .b8 95
(EngineCore_DP0 pid=303457) .b8 116
(EngineCore_DP0 pid=303457) .b8 117
(EngineCore_DP0 pid=303457) .b8 110
(EngineCore_DP0 pid=303457) .b8 101
(EngineCore_DP0 pid=303457) .b8 100
(EngineCore_DP0 pid=303457) .b8 95
(EngineCore_DP0 pid=303457) .b8 76
(EngineCore_DP0 pid=303457) .b8 108
(EngineCore_DP0 pid=303457) .b8 97
(EngineCore_DP0 pid=303457) .b8 109
(EngineCore_DP0 pid=303457) .b8 97
(EngineCore_DP0 pid=303457) .b8 51
(EngineCore_DP0 pid=303457) .b8 46
(EngineCore_DP0 pid=303457) .b8 50
(EngineCore_DP0 pid=303457) .b8 45
(EngineCore_DP0 pid=303457) .b8 49
(EngineCore_DP0 pid=303457) .b8 66
(EngineCore_DP0 pid=303457) .b8 46
(EngineCore_DP0 pid=303457) .b8 112
(EngineCore_DP0 pid=303457) .b8 121
(EngineCore_DP0 pid=303457) .b8 0
(EngineCore_DP0 pid=303457) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=303457) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=303457) .b8 114
(EngineCore_DP0 pid=303457) .b8 111
(EngineCore_DP0 pid=303457) .b8 111
(EngineCore_DP0 pid=303457) .b8 116
(EngineCore_DP0 pid=303457) .b8 47
(EngineCore_DP0 pid=303457) .b8 118
(EngineCore_DP0 pid=303457) .b8 108
(EngineCore_DP0 pid=303457) .b8 108
(EngineCore_DP0 pid=303457) .b8 109
(EngineCore_DP0 pid=303457) .b8 98
(EngineCore_DP0 pid=303457) .b8 101
(EngineCore_DP0 pid=303457) .b8 110
(EngineCore_DP0 pid=303457) .b8 99
(EngineCore_DP0 pid=303457) .b8 104
(EngineCore_DP0 pid=303457) .b8 47
(EngineCore_DP0 pid=303457) .b8 115
(EngineCore_DP0 pid=303457) .b8 108
(EngineCore_DP0 pid=303457) .b8 105
(EngineCore_DP0 pid=303457) .b8 100
(EngineCore_DP0 pid=303457) .b8 101
(EngineCore_DP0 pid=303457) .b8 115
(EngineCore_DP0 pid=303457) .b8 112
(EngineCore_DP0 pid=303457) .b8 97
(EngineCore_DP0 pid=303457) .b8 114
(EngineCore_DP0 pid=303457) .b8 115
(EngineCore_DP0 pid=303457) .b8 101
(EngineCore_DP0 pid=303457) .b8 47
(EngineCore_DP0 pid=303457) .b8 99
(EngineCore_DP0 pid=303457) .b8 115
(EngineCore_DP0 pid=303457) .b8 114
(EngineCore_DP0 pid=303457) .b8 99
(EngineCore_DP0 pid=303457) .b8 47
(EngineCore_DP0 pid=303457) .b8 102
(EngineCore_DP0 pid=303457) .b8 117
(EngineCore_DP0 pid=303457) .b8 115
(EngineCore_DP0 pid=303457) .b8 101
(EngineCore_DP0 pid=303457) .b8 100
(EngineCore_DP0 pid=303457) .b8 95
(EngineCore_DP0 pid=303457) .b8 113
(EngineCore_DP0 pid=303457) .b8 117
(EngineCore_DP0 pid=303457) .b8 97
(EngineCore_DP0 pid=303457) .b8 110
(EngineCore_DP0 pid=303457) .b8 116
(EngineCore_DP0 pid=303457) .b8 95
(EngineCore_DP0 pid=303457) .b8 115
(EngineCore_DP0 pid=303457) .b8 108
(EngineCore_DP0 pid=303457) .b8 105
(EngineCore_DP0 pid=303457) .b8 100
(EngineCore_DP0 pid=303457) .b8 101
(EngineCore_DP0 pid=303457) .b8 95
(EngineCore_DP0 pid=303457) .b8 116
(EngineCore_DP0 pid=303457) .b8 114
(EngineCore_DP0 pid=303457) .b8 105
(EngineCore_DP0 pid=303457) .b8 116
(EngineCore_DP0 pid=303457) .b8 111
(EngineCore_DP0 pid=303457) .b8 110
(EngineCore_DP0 pid=303457) .b8 47
(EngineCore_DP0 pid=303457) .b8 98
(EngineCore_DP0 pid=303457) .b8 117
(EngineCore_DP0 pid=303457) .b8 105
(EngineCore_DP0 pid=303457) .b8 108
(EngineCore_DP0 pid=303457) .b8 100
(EngineCore_DP0 pid=303457) .b8 47
(EngineCore_DP0 pid=303457) .b8 71
(EngineCore_DP0 pid=303457) .b8 66
(EngineCore_DP0 pid=303457) .b8 49
(EngineCore_DP0 pid=303457) .b8 48
(EngineCore_DP0 pid=303457) .b8 95
(EngineCore_DP0 pid=303457) .b8 99
(EngineCore_DP0 pid=303457) .b8 99
(EngineCore_DP0 pid=303457) .b8 49
(EngineCore_DP0 pid=303457) .b8 50
(EngineCore_DP0 pid=303457) .b8 49
(EngineCore_DP0 pid=303457) .b8 95
(EngineCore_DP0 pid=303457) .b8 112
(EngineCore_DP0 pid=303457) .b8 121
(EngineCore_DP0 pid=303457) .b8 51
(EngineCore_DP0 pid=303457) .b8 49
(EngineCore_DP0 pid=303457) .b8 50
(EngineCore_DP0 pid=303457) .b8 95
(EngineCore_DP0 pid=303457) .b8 99
(EngineCore_DP0 pid=303457) .b8 117
(EngineCore_DP0 pid=303457) .b8 49
(EngineCore_DP0 pid=303457) .b8 50
(EngineCore_DP0 pid=303457) .b8 57
(EngineCore_DP0 pid=303457) .b8 95
(EngineCore_DP0 pid=303457) .b8 97
(EngineCore_DP0 pid=303457) .b8 97
(EngineCore_DP0 pid=303457) .b8 114
(EngineCore_DP0 pid=303457) .b8 99
(EngineCore_DP0 pid=303457) .b8 104
(EngineCore_DP0 pid=303457) .b8 54
(EngineCore_DP0 pid=303457) .b8 52
(EngineCore_DP0 pid=303457) .b8 0
(EngineCore_DP0 pid=303457) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=303457) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=303457) .b8 113
(EngineCore_DP0 pid=303457) .b8 117
(EngineCore_DP0 pid=303457) .b8 97
(EngineCore_DP0 pid=303457) .b8 110
(EngineCore_DP0 pid=303457) .b8 116
(EngineCore_DP0 pid=303457) .b8 95
(EngineCore_DP0 pid=303457) .b8 115
(EngineCore_DP0 pid=303457) .b8 108
(EngineCore_DP0 pid=303457) .b8 105
(EngineCore_DP0 pid=303457) .b8 100
(EngineCore_DP0 pid=303457) .b8 101
(EngineCore_DP0 pid=303457) .b8 95
(EngineCore_DP0 pid=303457) .b8 102
(EngineCore_DP0 pid=303457) .b8 112
(EngineCore_DP0 pid=303457) .b8 56
(EngineCore_DP0 pid=303457) .b8 95
(EngineCore_DP0 pid=303457) .b8 107
(EngineCore_DP0 pid=303457) .b8 101
(EngineCore_DP0 pid=303457) .b8 114
(EngineCore_DP0 pid=303457) .b8 110
(EngineCore_DP0 pid=303457) .b8 101
(EngineCore_DP0 pid=303457) .b8 108
(EngineCore_DP0 pid=303457) .b8 0
(EngineCore_DP0 pid=303457) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=303457) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=303457) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=303457) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=303457) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=303457) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=303457) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=303457) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=303457) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=303457) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=303457) .b8 191                                 // DW_AT_call_line
(EngineCore_DP0 pid=303457) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=303457) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=303457) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=303457) 	}
(EngineCore_DP0 pid=303457) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=303457) 
(EngineCore_DP0 pid=303457) ================================================================
(EngineCore_DP0 pid=303457) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=303457) 
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpknb86adt.ptx', '-o', '/tmp/tmpknb86adt.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866] 
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866] 
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866] 
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpknb86adt.ptx -o /tmp/tmpknb86adt.ptx.o
(EngineCore_DP0 pid=303457) ERROR 01-25 18:50:18 [core.py:866] 

STDERR:
[2026-01-25 18:50:01] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 18:50:01] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 18:50:01] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 18:50:01] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:50:01] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:50:01] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:50:01] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:50:01] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:50:01] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 18:50:01] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 18:50:01] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 18:50:01] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 18:50:01] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 18:50:01] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 18:50:05] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 18:50:05] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 18:50:05] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 18:50:05] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:50:05] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:50:05] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:50:05] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:50:05] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:50:05] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 18:50:05] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 18:50:05] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 18:50:05] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 18:50:05] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 18:50:05] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=303457) [2026-01-25 18:50:06] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=303457) [2026-01-25 18:50:06] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=303457) [2026-01-25 18:50:06] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=303457) [2026-01-25 18:50:06] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=303457) [2026-01-25 18:50:06] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=303457) [2026-01-25 18:50:06] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=303457) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=303457) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.85s/it]
(EngineCore_DP0 pid=303457) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.85s/it]
(EngineCore_DP0 pid=303457) 
(EngineCore_DP0 pid=303457) [2026-01-25 18:50:17] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=303457) [2026-01-25 18:50:17] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6340608 bytes
(EngineCore_DP0 pid=303457) [2026-01-25 18:50:17] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=303457) [2026-01-25 18:50:17] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 4227072 bytes
(EngineCore_DP0 pid=303457) [2026-01-25 18:50:17] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=303457) [2026-01-25 18:50:17] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 33816576 bytes
(EngineCore_DP0 pid=303457) [2026-01-25 18:50:17] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=303457) [2026-01-25 18:50:17] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16809984 bytes
(EngineCore_DP0 pid=303457) Process EngineCore_DP0:
(EngineCore_DP0 pid=303457) Traceback (most recent call last):
(EngineCore_DP0 pid=303457)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=303457)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=303457)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=303457)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=303457) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpknb86adt.ptx', '-o', '/tmp/tmpknb86adt.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=303457) 
(EngineCore_DP0 pid=303457) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=303457) 
(EngineCore_DP0 pid=303457) Traceback (most recent call last):
(EngineCore_DP0 pid=303457)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=303457)     self.run()
(EngineCore_DP0 pid=303457)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=303457)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=303457)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=303457)     raise e
(EngineCore_DP0 pid=303457)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=303457)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=303457)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=303457)     super().__init__(
(EngineCore_DP0 pid=303457)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=303457)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=303457)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=303457)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=303457)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=303457)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=303457)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=303457)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=303457)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=303457)     return func(*args, **kwargs)
(EngineCore_DP0 pid=303457)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=303457)     return func(*args, **kwargs)
(EngineCore_DP0 pid=303457)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=303457)     self.model_runner.profile_run()
(EngineCore_DP0 pid=303457)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=303457)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=303457)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=303457)     return func(*args, **kwargs)
(EngineCore_DP0 pid=303457)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=303457)     outputs = self.model(
(EngineCore_DP0 pid=303457)               ^^^^^^^^^^^
(EngineCore_DP0 pid=303457)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=303457)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=303457)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=303457)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=303457)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=303457)     model_output = self.model(
(EngineCore_DP0 pid=303457)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=303457)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=303457)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=303457)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=303457)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=303457)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=303457)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=303457)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=303457)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=303457)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=303457)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=303457)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=303457)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=303457)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=303457)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=303457)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=303457)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=303457)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=303457)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=303457)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=303457)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=303457)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=303457)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=303457)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=303457)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=303457)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=303457)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=303457)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=303457)     return self._linear_fn(
(EngineCore_DP0 pid=303457)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=303457)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=303457)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=303457)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=303457)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=303457)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=303457)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=303457)     return fn(input, L)
(EngineCore_DP0 pid=303457)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=303457)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=303457)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=303457)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=303457)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=303457)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=303457)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=303457)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=303457)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=303457)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=303457)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=303457)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=303457)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=303457)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303457)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=303457)     raise PTXASError(error)
(EngineCore_DP0 pid=303457) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=303457) `ptxas` stderr:
(EngineCore_DP0 pid=303457) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=303457) 
(EngineCore_DP0 pid=303457) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpknb86adt.ptx -o /tmp/tmpknb86adt.ptx.o
(EngineCore_DP0 pid=303457) 
[rank0]:[W125 18:50:18.083720646 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=16

========== M=128 ==========
Time: 2026-01-25 18:50:20
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10
Params: prompt_len=128, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10 --dataset-name random --input-len 128 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 129 --max-num-batched-tokens 129 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-1B-FP8_M128.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 18:50:24 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 18:50:24 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=303946) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=303946) 
(EngineCore_DP0 pid=303946) 
(EngineCore_DP0 pid=303946) ================================================================
(EngineCore_DP0 pid=303946) Internal Triton PTX codegen error
(EngineCore_DP0 pid=303946) `ptxas` stderr:
(EngineCore_DP0 pid=303946) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=303946) 
(EngineCore_DP0 pid=303946) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp6uxxuyi0.ptx -o /tmp/tmp6uxxuyi0.ptx.o
(EngineCore_DP0 pid=303946) 
(EngineCore_DP0 pid=303946) 
(EngineCore_DP0 pid=303946) //
(EngineCore_DP0 pid=303946) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=303946) //
(EngineCore_DP0 pid=303946) 
(EngineCore_DP0 pid=303946) .version 8.7
(EngineCore_DP0 pid=303946) .target sm_121a
(EngineCore_DP0 pid=303946) .address_size 64
(EngineCore_DP0 pid=303946) 
(EngineCore_DP0 pid=303946) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=303946) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=303946)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=303946) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=303946) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=303946) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=303946) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=303946) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=303946) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=303946) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=303946) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=303946) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=303946) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=303946) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=303946) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=303946) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=303946) )
(EngineCore_DP0 pid=303946) .reqntid 128
(EngineCore_DP0 pid=303946) {
(EngineCore_DP0 pid=303946) 	.reg .pred 	%p<29>;
(EngineCore_DP0 pid=303946) 	.reg .b16 	%rs<73>;
(EngineCore_DP0 pid=303946) 	.reg .b32 	%r<156>;
(EngineCore_DP0 pid=303946) 	.reg .b64 	%rd<18>;
(EngineCore_DP0 pid=303946) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=303946) $L__func_begin0:
(EngineCore_DP0 pid=303946) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=303946) 
(EngineCore_DP0 pid=303946) // %bb.0:
(EngineCore_DP0 pid=303946) 	ld.param.b32 	%r25, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=303946) 	ld.param.b32 	%r24, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=303946) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=303946) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=303946) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=303946) $L__tmp0:
(EngineCore_DP0 pid=303946) 	.loc	1 177 24                        // quant_slide_tuned_Llama3.2-1B.py:177:24
(EngineCore_DP0 pid=303946) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=303946) 	ld.param.b32 	%r27, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=303946) 	.loc	1 182 26                        // quant_slide_tuned_Llama3.2-1B.py:182:26
(EngineCore_DP0 pid=303946) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=303946) 	.loc	1 182 20                        // quant_slide_tuned_Llama3.2-1B.py:182:20
(EngineCore_DP0 pid=303946) 	mad.wide.s32 	%rd1, %r28, 2, %rd4;
(EngineCore_DP0 pid=303946) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=303946) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=303946) 	and.b32 	%r3, %r2, 127;
(EngineCore_DP0 pid=303946) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=303946) 	setp.lt.s32 	%p1, %r24, 1;
(EngineCore_DP0 pid=303946) 	mov.b32 	%r154, 0f2B8CBCCC;
(EngineCore_DP0 pid=303946) 	setp.eq.b32 	%p28, %r2, 0;
(EngineCore_DP0 pid=303946) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=303946) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=303946) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=303946) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=303946) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=303946) 	shr.u32 	%r37, %r2, 3;
(EngineCore_DP0 pid=303946) 	and.b32 	%r38, %r37, 12;
(EngineCore_DP0 pid=303946) 	mov.b32 	%r39, global_smem;
(EngineCore_DP0 pid=303946) 	add.s32 	%r57, %r39, %r38;
(EngineCore_DP0 pid=303946) 	shl.b32 	%r40, %r2, 2;
(EngineCore_DP0 pid=303946) 	add.s32 	%r60, %r39, %r40;
(EngineCore_DP0 pid=303946) 	mov.b32 	%r45, 0;
(EngineCore_DP0 pid=303946) 	mov.b32 	%r152, 0f00000000;
(EngineCore_DP0 pid=303946) 	setp.lt.u32 	%p5, %r2, 4;
(EngineCore_DP0 pid=303946) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=303946) 	mov.b32 	%r153, %r45;
(EngineCore_DP0 pid=303946) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=303946) 	.loc	1 188 19                        // quant_slide_tuned_Llama3.2-1B.py:188:19
(EngineCore_DP0 pid=303946) 	add.s32 	%r63, %r4, %r153;
(EngineCore_DP0 pid=303946) 	.loc	1 189 22                        // quant_slide_tuned_Llama3.2-1B.py:189:22
(EngineCore_DP0 pid=303946) 	add.s32 	%r64, %r63, 1024;
(EngineCore_DP0 pid=303946) 	setp.lt.s32 	%p2, %r63, %r23;
(EngineCore_DP0 pid=303946) 	setp.lt.s32 	%p3, %r64, %r23;
(EngineCore_DP0 pid=303946) 	.loc	1 190 29                        // quant_slide_tuned_Llama3.2-1B.py:190:29
(EngineCore_DP0 pid=303946) 	mad.wide.s32 	%rd6, %r63, 2, %rd1;
(EngineCore_DP0 pid=303946) 	add.s64 	%rd7, %rd6, 2048;
(EngineCore_DP0 pid=303946) 	.loc	1 190 21                        // quant_slide_tuned_Llama3.2-1B.py:190:21
(EngineCore_DP0 pid=303946) 	// begin inline asm
(EngineCore_DP0 pid=303946) 	mov.u32 %r41, %r45;
(EngineCore_DP0 pid=303946) 	mov.u32 %r42, %r45;
(EngineCore_DP0 pid=303946) 	mov.u32 %r43, %r45;
(EngineCore_DP0 pid=303946) 	mov.u32 %r44, %r45;
(EngineCore_DP0 pid=303946) 	@%p2 ld.global.v4.b32 { %r41, %r42, %r43, %r44 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=303946) 	// end inline asm
(EngineCore_DP0 pid=303946) 	mov.b32 	{%rs1, %rs2}, %r41;
(EngineCore_DP0 pid=303946) 	mov.b32 	{%rs3, %rs4}, %r42;
(EngineCore_DP0 pid=303946) 	mov.b32 	{%rs5, %rs6}, %r43;
(EngineCore_DP0 pid=303946) 	mov.b32 	{%rs7, %rs8}, %r44;
(EngineCore_DP0 pid=303946) 	// begin inline asm
(EngineCore_DP0 pid=303946) 	mov.u32 %r49, %r45;
(EngineCore_DP0 pid=303946) 	mov.u32 %r50, %r45;
(EngineCore_DP0 pid=303946) 	mov.u32 %r51, %r45;
(EngineCore_DP0 pid=303946) 	mov.u32 %r52, %r45;
(EngineCore_DP0 pid=303946) 	@%p3 ld.global.v4.b32 { %r49, %r50, %r51, %r52 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=303946) 	// end inline asm
(EngineCore_DP0 pid=303946) 	mov.b32 	{%rs9, %rs10}, %r49;
(EngineCore_DP0 pid=303946) 	mov.b32 	{%rs11, %rs12}, %r50;
(EngineCore_DP0 pid=303946) 	mov.b32 	{%rs13, %rs14}, %r51;
(EngineCore_DP0 pid=303946) 	mov.b32 	{%rs15, %rs16}, %r52;
(EngineCore_DP0 pid=303946) 	.loc	1 191 50                        // quant_slide_tuned_Llama3.2-1B.py:191:50
(EngineCore_DP0 pid=303946) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=303946) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=303946) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=303946) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=303946) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=303946) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=303946) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=303946) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=303946) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=303946) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=303946) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=303946) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=303946) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=303946) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=303946) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=303946) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=303946) $L__tmp1:
(EngineCore_DP0 pid=303946) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=303946) 	bar.sync 	0;
(EngineCore_DP0 pid=303946) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=303946) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=303946) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=303946) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=303946) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=303946) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=303946) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=303946) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=303946) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=303946) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=303946) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=303946) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=303946) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=303946) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=303946) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=303946) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=303946) 	cvt.f32.bf16 	%r65, %rs47;
(EngineCore_DP0 pid=303946) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=303946) 	shfl.sync.bfly.b32 	%r66, %r65, 16, 31, -1;
(EngineCore_DP0 pid=303946) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=303946) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=303946) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=303946) 	shfl.sync.bfly.b32 	%r68, %r67, 8, 31, -1;
(EngineCore_DP0 pid=303946) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=303946) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=303946) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=303946) 	shfl.sync.bfly.b32 	%r70, %r69, 4, 31, -1;
(EngineCore_DP0 pid=303946) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=303946) 	max.f32 	%r71, %r69, %r70;
(EngineCore_DP0 pid=303946) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=303946) 	shfl.sync.bfly.b32 	%r72, %r71, 2, 31, -1;
(EngineCore_DP0 pid=303946) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=303946) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=303946) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=303946) 	shfl.sync.bfly.b32 	%r74, %r73, 1, 31, -1;
(EngineCore_DP0 pid=303946) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=303946) 	max.f32 	%r58, %r73, %r74;
(EngineCore_DP0 pid=303946) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=303946) 	// begin inline asm
(EngineCore_DP0 pid=303946) 	@%p4 st.shared.b32 [ %r57 + 0 ], %r58;
(EngineCore_DP0 pid=303946) 	// end inline asm
(EngineCore_DP0 pid=303946) 	bar.sync 	0;
(EngineCore_DP0 pid=303946) 	// begin inline asm
(EngineCore_DP0 pid=303946) 	@%p5 ld.shared.b32 %r59, [ %r60 + 0 ];
(EngineCore_DP0 pid=303946) 	// end inline asm
(EngineCore_DP0 pid=303946) 	shfl.sync.bfly.b32 	%r75, %r59, 2, 31, -1;
(EngineCore_DP0 pid=303946) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=303946) 	max.f32 	%r76, %r59, %r75;
(EngineCore_DP0 pid=303946) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=303946) 	shfl.sync.bfly.b32 	%r77, %r76, 1, 31, -1;
(EngineCore_DP0 pid=303946) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=303946) 	max.f32 	%r62, %r76, %r77;
(EngineCore_DP0 pid=303946) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=303946) 	// begin inline asm
(EngineCore_DP0 pid=303946) 	@%p28 st.shared.b32 [ %r60 + 0 ], %r62;
(EngineCore_DP0 pid=303946) 	// end inline asm
(EngineCore_DP0 pid=303946) 	bar.sync 	0;
(EngineCore_DP0 pid=303946) 	ld.shared.b32 	%r78, [global_smem];
(EngineCore_DP0 pid=303946) $L__tmp2:
(EngineCore_DP0 pid=303946) 	.loc	1 191 36                        // quant_slide_tuned_Llama3.2-1B.py:191:36
(EngineCore_DP0 pid=303946) 	max.f32 	%r152, %r152, %r78;
(EngineCore_DP0 pid=303946) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=303946) 	add.s32 	%r153, %r153, 2048;
(EngineCore_DP0 pid=303946) 	setp.lt.s32 	%p7, %r153, %r24;
(EngineCore_DP0 pid=303946) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=303946) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=303946) 	.loc	1 193 32                        // quant_slide_tuned_Llama3.2-1B.py:193:32
(EngineCore_DP0 pid=303946) 	max.f32 	%r154, %r152, 0f2B8CBCCC;
(EngineCore_DP0 pid=303946) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=303946) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=303946) 	mov.b32 	%r80, 0f43E00000;
(EngineCore_DP0 pid=303946) 	.loc	1 194 32                        // quant_slide_tuned_Llama3.2-1B.py:194:32
(EngineCore_DP0 pid=303946) 	div.full.f32 	%r81, %r154, %r80;
(EngineCore_DP0 pid=303946) 	.loc	1 194 41                        // quant_slide_tuned_Llama3.2-1B.py:194:41
(EngineCore_DP0 pid=303946) 	max.f32 	%r79, %r81, 0f36924925;
(EngineCore_DP0 pid=303946) 	.loc	1 196 25                        // quant_slide_tuned_Llama3.2-1B.py:196:25
(EngineCore_DP0 pid=303946) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=303946) 	.loc	1 196 30                        // quant_slide_tuned_Llama3.2-1B.py:196:30
(EngineCore_DP0 pid=303946) 	// begin inline asm
(EngineCore_DP0 pid=303946) 	@%p28 st.global.b32 [ %rd8 + 0 ], { %r79 };
(EngineCore_DP0 pid=303946) 	// end inline asm
(EngineCore_DP0 pid=303946) 	.loc	1 199 29                        // quant_slide_tuned_Llama3.2-1B.py:199:29
(EngineCore_DP0 pid=303946) 	shl.b32 	%r15, %r25, 2;
(EngineCore_DP0 pid=303946) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=303946) 	setp.lt.s32 	%p9, %r15, 1;
(EngineCore_DP0 pid=303946) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=303946) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=303946) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=303946) 	ld.param.b32 	%r29, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=303946) 	shr.s32 	%r30, %r29, 31;
(EngineCore_DP0 pid=303946) 	shr.u32 	%r31, %r30, 30;
(EngineCore_DP0 pid=303946) 	add.s32 	%r32, %r29, %r31;
(EngineCore_DP0 pid=303946) 	shr.s32 	%r33, %r32, 2;
(EngineCore_DP0 pid=303946) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=303946) 	mul.lo.s32 	%r34, %r33, %r1;
(EngineCore_DP0 pid=303946) 	mad.wide.s32 	%rd2, %r34, 4, %rd5;
(EngineCore_DP0 pid=303946) 	div.full.f32 	%r14, %r80, %r154;
(EngineCore_DP0 pid=303946) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=303946) 	mov.b32 	%r155, 0;
(EngineCore_DP0 pid=303946) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=303946)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=303946) 	.loc	1 202 31                        // quant_slide_tuned_Llama3.2-1B.py:202:31
(EngineCore_DP0 pid=303946) 	add.s32 	%r93, %r16, %r155;
(EngineCore_DP0 pid=303946) 	.loc	1 203 30                        // quant_slide_tuned_Llama3.2-1B.py:203:30
(EngineCore_DP0 pid=303946) 	add.s32 	%r94, %r93, 1;
(EngineCore_DP0 pid=303946) 	setp.lt.s32 	%p18, %r93, %r15;
(EngineCore_DP0 pid=303946) 	.loc	1 206 24                        // quant_slide_tuned_Llama3.2-1B.py:206:24
(EngineCore_DP0 pid=303946) 	shr.s32 	%r95, %r93, 31;
(EngineCore_DP0 pid=303946) 	shr.u32 	%r96, %r95, 30;
(EngineCore_DP0 pid=303946) 	add.s32 	%r97, %r93, %r96;
(EngineCore_DP0 pid=303946) 	shr.s32 	%r98, %r97, 2;
(EngineCore_DP0 pid=303946) 	.loc	1 207 23                        // quant_slide_tuned_Llama3.2-1B.py:207:23
(EngineCore_DP0 pid=303946) 	shr.s32 	%r99, %r94, 31;
(EngineCore_DP0 pid=303946) 	shr.u32 	%r100, %r99, 30;
(EngineCore_DP0 pid=303946) 	add.s32 	%r101, %r94, %r100;
(EngineCore_DP0 pid=303946) 	and.b32 	%r102, %r101, 2147483644;
(EngineCore_DP0 pid=303946) 	sub.s32 	%r103, %r94, %r102;
(EngineCore_DP0 pid=303946) 	and.b32 	%r104, %r97, 2147483644;
(EngineCore_DP0 pid=303946) 	sub.s32 	%r105, %r93, %r104;
(EngineCore_DP0 pid=303946) 	.loc	1 208 22                        // quant_slide_tuned_Llama3.2-1B.py:208:22
(EngineCore_DP0 pid=303946) 	mul.lo.s32 	%r106, %r98, 10;
(EngineCore_DP0 pid=303946) 	.loc	1 208 30                        // quant_slide_tuned_Llama3.2-1B.py:208:30
(EngineCore_DP0 pid=303946) 	shl.b32 	%r107, %r105, 1;
(EngineCore_DP0 pid=303946) 	shl.b32 	%r108, %r103, 1;
(EngineCore_DP0 pid=303946) 	.loc	1 208 26                        // quant_slide_tuned_Llama3.2-1B.py:208:26
(EngineCore_DP0 pid=303946) 	add.s32 	%r109, %r106, %r108;
(EngineCore_DP0 pid=303946) 	add.s32 	%r110, %r106, %r107;
(EngineCore_DP0 pid=303946) 	.loc	1 211 53                        // quant_slide_tuned_Llama3.2-1B.py:211:53
(EngineCore_DP0 pid=303946) 	setp.lt.s32 	%p19, %r110, %r23;
(EngineCore_DP0 pid=303946) 	setp.lt.s32 	%p20, %r109, %r23;
(EngineCore_DP0 pid=303946) 	.loc	1 211 37                        // quant_slide_tuned_Llama3.2-1B.py:211:37
(EngineCore_DP0 pid=303946) 	and.pred 	%p10, %p18, %p19;
(EngineCore_DP0 pid=303946) 	and.pred 	%p11, %p18, %p20;
(EngineCore_DP0 pid=303946) 	.loc	1 210 29                        // quant_slide_tuned_Llama3.2-1B.py:210:29
(EngineCore_DP0 pid=303946) 	mad.wide.s32 	%rd9, %r110, 2, %rd1;
(EngineCore_DP0 pid=303946) 	mad.wide.s32 	%rd10, %r109, 2, %rd1;
(EngineCore_DP0 pid=303946) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=303946) 	.loc	1 210 21                        // quant_slide_tuned_Llama3.2-1B.py:210:21
(EngineCore_DP0 pid=303946) 	// begin inline asm
(EngineCore_DP0 pid=303946) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=303946) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=303946) 	// end inline asm
(EngineCore_DP0 pid=303946) 	// begin inline asm
(EngineCore_DP0 pid=303946) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=303946) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=303946) 	// end inline asm
(EngineCore_DP0 pid=303946) 	.loc	1 211 79                        // quant_slide_tuned_Llama3.2-1B.py:211:79
(EngineCore_DP0 pid=303946) 	cvt.f32.bf16 	%r111, %rs48;
(EngineCore_DP0 pid=303946) 	cvt.f32.bf16 	%r112, %rs50;
(EngineCore_DP0 pid=303946) 	.loc	1 213 48                        // quant_slide_tuned_Llama3.2-1B.py:213:48
(EngineCore_DP0 pid=303946) 	or.b32 	%r113, %r110, 1;
(EngineCore_DP0 pid=303946) 	or.b32 	%r114, %r109, 1;
(EngineCore_DP0 pid=303946) 	.loc	1 213 53                        // quant_slide_tuned_Llama3.2-1B.py:213:53
(EngineCore_DP0 pid=303946) 	setp.lt.s32 	%p21, %r113, %r23;
(EngineCore_DP0 pid=303946) 	setp.lt.s32 	%p22, %r114, %r23;
(EngineCore_DP0 pid=303946) 	.loc	1 213 37                        // quant_slide_tuned_Llama3.2-1B.py:213:37
(EngineCore_DP0 pid=303946) 	and.pred 	%p12, %p18, %p21;
(EngineCore_DP0 pid=303946) 	and.pred 	%p13, %p18, %p22;
(EngineCore_DP0 pid=303946) 	.loc	1 212 39                        // quant_slide_tuned_Llama3.2-1B.py:212:39
(EngineCore_DP0 pid=303946) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=303946) 	add.s64 	%rd12, %rd10, 2;
(EngineCore_DP0 pid=303946) 	.loc	1 212 21                        // quant_slide_tuned_Llama3.2-1B.py:212:21
(EngineCore_DP0 pid=303946) 	// begin inline asm
(EngineCore_DP0 pid=303946) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=303946) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=303946) 	// end inline asm
(EngineCore_DP0 pid=303946) 	// begin inline asm
(EngineCore_DP0 pid=303946) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=303946) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=303946) 	// end inline asm
(EngineCore_DP0 pid=303946) 	.loc	1 213 79                        // quant_slide_tuned_Llama3.2-1B.py:213:79
(EngineCore_DP0 pid=303946) 	cvt.f32.bf16 	%r115, %rs52;
(EngineCore_DP0 pid=303946) 	cvt.f32.bf16 	%r116, %rs54;
(EngineCore_DP0 pid=303946) 	.loc	1 217 48                        // quant_slide_tuned_Llama3.2-1B.py:217:48
(EngineCore_DP0 pid=303946) 	add.s32 	%r117, %r110, 2;
(EngineCore_DP0 pid=303946) 	add.s32 	%r118, %r109, 2;
(EngineCore_DP0 pid=303946) 	add.s32 	%r119, %r110, 3;
(EngineCore_DP0 pid=303946) 	add.s32 	%r120, %r109, 3;
(EngineCore_DP0 pid=303946) 	.loc	1 217 53                        // quant_slide_tuned_Llama3.2-1B.py:217:53
(EngineCore_DP0 pid=303946) 	setp.lt.s32 	%p23, %r120, %r23;
(EngineCore_DP0 pid=303946) 	setp.lt.s32 	%p24, %r119, %r23;
(EngineCore_DP0 pid=303946) 	setp.lt.s32 	%p25, %r118, %r23;
(EngineCore_DP0 pid=303946) 	setp.lt.s32 	%p26, %r117, %r23;
(EngineCore_DP0 pid=303946) 	.loc	1 215 37                        // quant_slide_tuned_Llama3.2-1B.py:215:37
(EngineCore_DP0 pid=303946) 	and.pred 	%p14, %p18, %p26;
(EngineCore_DP0 pid=303946) 	and.pred 	%p15, %p18, %p25;
(EngineCore_DP0 pid=303946) 	.loc	1 214 39                        // quant_slide_tuned_Llama3.2-1B.py:214:39
(EngineCore_DP0 pid=303946) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=303946) 	add.s64 	%rd14, %rd10, 4;
(EngineCore_DP0 pid=303946) 	.loc	1 214 21                        // quant_slide_tuned_Llama3.2-1B.py:214:21
(EngineCore_DP0 pid=303946) 	// begin inline asm
(EngineCore_DP0 pid=303946) 	mov.u16 %rs56, %rs49;
(EngineCore_DP0 pid=303946) 	@%p14 ld.global.b16 { %rs56 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=303946) 	// end inline asm
(EngineCore_DP0 pid=303946) 	// begin inline asm
(EngineCore_DP0 pid=303946) 	mov.u16 %rs58, %rs49;
(EngineCore_DP0 pid=303946) 	@%p15 ld.global.b16 { %rs58 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=303946) 	// end inline asm
(EngineCore_DP0 pid=303946) 	.loc	1 215 79                        // quant_slide_tuned_Llama3.2-1B.py:215:79
(EngineCore_DP0 pid=303946) 	cvt.f32.bf16 	%r121, %rs56;
(EngineCore_DP0 pid=303946) 	cvt.f32.bf16 	%r122, %rs58;
(EngineCore_DP0 pid=303946) 	.loc	1 217 37                        // quant_slide_tuned_Llama3.2-1B.py:217:37
(EngineCore_DP0 pid=303946) 	and.pred 	%p16, %p18, %p24;
(EngineCore_DP0 pid=303946) 	and.pred 	%p17, %p18, %p23;
(EngineCore_DP0 pid=303946) 	.loc	1 216 39                        // quant_slide_tuned_Llama3.2-1B.py:216:39
(EngineCore_DP0 pid=303946) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=303946) 	add.s64 	%rd16, %rd10, 6;
(EngineCore_DP0 pid=303946) 	.loc	1 216 21                        // quant_slide_tuned_Llama3.2-1B.py:216:21
(EngineCore_DP0 pid=303946) 	// begin inline asm
(EngineCore_DP0 pid=303946) 	mov.u16 %rs60, %rs49;
(EngineCore_DP0 pid=303946) 	@%p16 ld.global.b16 { %rs60 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=303946) 	// end inline asm
(EngineCore_DP0 pid=303946) 	// begin inline asm
(EngineCore_DP0 pid=303946) 	mov.u16 %rs62, %rs49;
(EngineCore_DP0 pid=303946) 	@%p17 ld.global.b16 { %rs62 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=303946) 	// end inline asm
(EngineCore_DP0 pid=303946) 	.loc	1 217 79                        // quant_slide_tuned_Llama3.2-1B.py:217:79
(EngineCore_DP0 pid=303946) 	cvt.f32.bf16 	%r123, %rs60;
(EngineCore_DP0 pid=303946) 	cvt.f32.bf16 	%r124, %rs62;
(EngineCore_DP0 pid=303946) 	.loc	1 219 27                        // quant_slide_tuned_Llama3.2-1B.py:219:27
(EngineCore_DP0 pid=303946) 	mul.f32 	%r125, %r14, %r111;
(EngineCore_DP0 pid=303946) 	mul.f32 	%r126, %r14, %r112;
(EngineCore_DP0 pid=303946) 	mov.b32 	%r127, 0f43E00000;
(EngineCore_DP0 pid=303946) 	.loc	1 219 48                        // quant_slide_tuned_Llama3.2-1B.py:219:48
(EngineCore_DP0 pid=303946) 	min.xorsign.abs.f32 	%r83, %r125, %r127;
(EngineCore_DP0 pid=303946) 	min.xorsign.abs.f32 	%r84, %r126, %r127;
(EngineCore_DP0 pid=303946) 	.loc	1 219 60                        // quant_slide_tuned_Llama3.2-1B.py:219:60
(EngineCore_DP0 pid=303946) 	// begin inline asm
(EngineCore_DP0 pid=303946) 	cvt.rn.satfinite.e4m3x2.f32  %rs64, %r84, %r83; 
(EngineCore_DP0 pid=303946) 
(EngineCore_DP0 pid=303946) 	// end inline asm
(EngineCore_DP0 pid=303946) 	shr.u16 	%rs68, %rs64, 8;
(EngineCore_DP0 pid=303946) 	.loc	1 220 27                        // quant_slide_tuned_Llama3.2-1B.py:220:27
(EngineCore_DP0 pid=303946) 	mul.f32 	%r128, %r14, %r115;
(EngineCore_DP0 pid=303946) 	mul.f32 	%r129, %r14, %r116;
(EngineCore_DP0 pid=303946) 	.loc	1 220 48                        // quant_slide_tuned_Llama3.2-1B.py:220:48
(EngineCore_DP0 pid=303946) 	min.xorsign.abs.f32 	%r85, %r128, %r127;
(EngineCore_DP0 pid=303946) 	min.xorsign.abs.f32 	%r86, %r129, %r127;
(EngineCore_DP0 pid=303946) 	.loc	1 220 60                        // quant_slide_tuned_Llama3.2-1B.py:220:60
(EngineCore_DP0 pid=303946) 	// begin inline asm
(EngineCore_DP0 pid=303946) 	cvt.rn.satfinite.e4m3x2.f32  %rs65, %r86, %r85; 
(EngineCore_DP0 pid=303946) 
(EngineCore_DP0 pid=303946) 	// end inline asm
(EngineCore_DP0 pid=303946) 	shr.u16 	%rs69, %rs65, 8;
(EngineCore_DP0 pid=303946) 	.loc	1 221 27                        // quant_slide_tuned_Llama3.2-1B.py:221:27
(EngineCore_DP0 pid=303946) 	mul.f32 	%r130, %r14, %r121;
(EngineCore_DP0 pid=303946) 	mul.f32 	%r131, %r14, %r122;
(EngineCore_DP0 pid=303946) 	.loc	1 221 48                        // quant_slide_tuned_Llama3.2-1B.py:221:48
(EngineCore_DP0 pid=303946) 	min.xorsign.abs.f32 	%r87, %r130, %r127;
(EngineCore_DP0 pid=303946) 	min.xorsign.abs.f32 	%r88, %r131, %r127;
(EngineCore_DP0 pid=303946) 	.loc	1 221 60                        // quant_slide_tuned_Llama3.2-1B.py:221:60
(EngineCore_DP0 pid=303946) 	// begin inline asm
(EngineCore_DP0 pid=303946) 	cvt.rn.satfinite.e4m3x2.f32  %rs66, %r88, %r87; 
(EngineCore_DP0 pid=303946) 
(EngineCore_DP0 pid=303946) 	// end inline asm
(EngineCore_DP0 pid=303946) 	shr.u16 	%rs70, %rs66, 8;
(EngineCore_DP0 pid=303946) 	.loc	1 222 27                        // quant_slide_tuned_Llama3.2-1B.py:222:27
(EngineCore_DP0 pid=303946) 	mul.f32 	%r132, %r14, %r123;
(EngineCore_DP0 pid=303946) 	mul.f32 	%r133, %r14, %r124;
(EngineCore_DP0 pid=303946) 	.loc	1 222 48                        // quant_slide_tuned_Llama3.2-1B.py:222:48
(EngineCore_DP0 pid=303946) 	min.xorsign.abs.f32 	%r89, %r132, %r127;
(EngineCore_DP0 pid=303946) 	min.xorsign.abs.f32 	%r90, %r133, %r127;
(EngineCore_DP0 pid=303946) 	.loc	1 222 60                        // quant_slide_tuned_Llama3.2-1B.py:222:60
(EngineCore_DP0 pid=303946) 	// begin inline asm
(EngineCore_DP0 pid=303946) 	cvt.rn.satfinite.e4m3x2.f32  %rs67, %r90, %r89; 
(EngineCore_DP0 pid=303946) 
(EngineCore_DP0 pid=303946) 	// end inline asm
(EngineCore_DP0 pid=303946) 	shr.u16 	%rs71, %rs67, 8;
(EngineCore_DP0 pid=303946) 	.loc	1 224 45                        // quant_slide_tuned_Llama3.2-1B.py:224:45
(EngineCore_DP0 pid=303946) 	cvt.u32.u16 	%r134, %rs64;
(EngineCore_DP0 pid=303946) 	and.b32 	%r135, %r134, 255;
(EngineCore_DP0 pid=303946) 	cvt.u32.u16 	%r136, %rs68;
(EngineCore_DP0 pid=303946) 	.loc	1 226 45                        // quant_slide_tuned_Llama3.2-1B.py:226:45
(EngineCore_DP0 pid=303946) 	cvt.u32.u16 	%r137, %rs66;
(EngineCore_DP0 pid=303946) 	and.b32 	%r138, %r137, 255;
(EngineCore_DP0 pid=303946) 	cvt.u32.u16 	%r139, %rs70;
(EngineCore_DP0 pid=303946) 	.loc	1 227 45                        // quant_slide_tuned_Llama3.2-1B.py:227:45
(EngineCore_DP0 pid=303946) 	cvt.u32.u16 	%r140, %rs67;
(EngineCore_DP0 pid=303946) 	cvt.u32.u16 	%r141, %rs71;
(EngineCore_DP0 pid=303946) 	.loc	1 229 30                        // quant_slide_tuned_Llama3.2-1B.py:229:30
(EngineCore_DP0 pid=303946) 	and.b16 	%rs72, %rs65, 255;
(EngineCore_DP0 pid=303946) 	mul.wide.u16 	%r142, %rs72, 256;
(EngineCore_DP0 pid=303946) 	mul.wide.u16 	%r143, %rs69, 256;
(EngineCore_DP0 pid=303946) 	.loc	1 229 24                        // quant_slide_tuned_Llama3.2-1B.py:229:24
(EngineCore_DP0 pid=303946) 	or.b32 	%r144, %r142, %r135;
(EngineCore_DP0 pid=303946) 	or.b32 	%r145, %r143, %r136;
(EngineCore_DP0 pid=303946) 	.loc	1 229 42                        // quant_slide_tuned_Llama3.2-1B.py:229:42
(EngineCore_DP0 pid=303946) 	shl.b32 	%r146, %r138, 16;
(EngineCore_DP0 pid=303946) 	shl.b32 	%r147, %r139, 16;
(EngineCore_DP0 pid=303946) 	.loc	1 229 36                        // quant_slide_tuned_Llama3.2-1B.py:229:36
(EngineCore_DP0 pid=303946) 	or.b32 	%r148, %r144, %r146;
(EngineCore_DP0 pid=303946) 	or.b32 	%r149, %r145, %r147;
(EngineCore_DP0 pid=303946) 	.loc	1 229 55                        // quant_slide_tuned_Llama3.2-1B.py:229:55
(EngineCore_DP0 pid=303946) 	shl.b32 	%r150, %r140, 24;
(EngineCore_DP0 pid=303946) 	shl.b32 	%r151, %r141, 24;
(EngineCore_DP0 pid=303946) 	.loc	1 229 49                        // quant_slide_tuned_Llama3.2-1B.py:229:49
(EngineCore_DP0 pid=303946) 	or.b32 	%r91, %r148, %r150;
(EngineCore_DP0 pid=303946) 	or.b32 	%r92, %r149, %r151;
(EngineCore_DP0 pid=303946) 	.loc	1 230 29                        // quant_slide_tuned_Llama3.2-1B.py:230:29
(EngineCore_DP0 pid=303946) 	mad.wide.s32 	%rd17, %r93, 4, %rd2;
(EngineCore_DP0 pid=303946) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-1B.py:230:39
(EngineCore_DP0 pid=303946) 	// begin inline asm
(EngineCore_DP0 pid=303946) 	@%p18 st.global.v2.b32 [ %rd17 + 0 ], { %r91, %r92 };
(EngineCore_DP0 pid=303946) 	// end inline asm
(EngineCore_DP0 pid=303946) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=303946) 	add.s32 	%r155, %r155, 256;
(EngineCore_DP0 pid=303946) 	setp.lt.s32 	%p27, %r155, %r15;
(EngineCore_DP0 pid=303946) 	@%p27 bra 	$L__BB0_6;
(EngineCore_DP0 pid=303946) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=303946) 	.loc	1 201 4                         // quant_slide_tuned_Llama3.2-1B.py:201:4
(EngineCore_DP0 pid=303946) 	ret;
(EngineCore_DP0 pid=303946) $L__tmp3:
(EngineCore_DP0 pid=303946) $L__func_end0:
(EngineCore_DP0 pid=303946)                                         // -- End function
(EngineCore_DP0 pid=303946) }
(EngineCore_DP0 pid=303946) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=303946) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=303946) 	.section	.debug_abbrev
(EngineCore_DP0 pid=303946) 	{
(EngineCore_DP0 pid=303946) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=303946) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=303946) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=303946) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=303946) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=303946) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=303946) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=303946) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=303946) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=303946) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=303946) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=303946) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=303946) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=303946) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=303946) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=303946) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=303946) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=303946) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=303946) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=303946) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=303946) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=303946) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=303946) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=303946) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=303946) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=303946) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=303946) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=303946) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=303946) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=303946) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=303946) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=303946) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=303946) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=303946) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=303946) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=303946) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=303946) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=303946) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=303946) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=303946) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=303946) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=303946) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=303946) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=303946) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=303946) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=303946) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=303946) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=303946) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=303946) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=303946) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=303946) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=303946) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=303946) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=303946) 	}
(EngineCore_DP0 pid=303946) 	.section	.debug_info
(EngineCore_DP0 pid=303946) 	{
(EngineCore_DP0 pid=303946) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=303946) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=303946) .b8 0
(EngineCore_DP0 pid=303946) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=303946) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=303946) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=303946) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=303946) .b8 114
(EngineCore_DP0 pid=303946) .b8 105
(EngineCore_DP0 pid=303946) .b8 116
(EngineCore_DP0 pid=303946) .b8 111
(EngineCore_DP0 pid=303946) .b8 110
(EngineCore_DP0 pid=303946) .b8 0
(EngineCore_DP0 pid=303946) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=303946) .b8 0
(EngineCore_DP0 pid=303946) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=303946) .b8 117
(EngineCore_DP0 pid=303946) .b8 97
(EngineCore_DP0 pid=303946) .b8 110
(EngineCore_DP0 pid=303946) .b8 116
(EngineCore_DP0 pid=303946) .b8 95
(EngineCore_DP0 pid=303946) .b8 115
(EngineCore_DP0 pid=303946) .b8 108
(EngineCore_DP0 pid=303946) .b8 105
(EngineCore_DP0 pid=303946) .b8 100
(EngineCore_DP0 pid=303946) .b8 101
(EngineCore_DP0 pid=303946) .b8 95
(EngineCore_DP0 pid=303946) .b8 116
(EngineCore_DP0 pid=303946) .b8 117
(EngineCore_DP0 pid=303946) .b8 110
(EngineCore_DP0 pid=303946) .b8 101
(EngineCore_DP0 pid=303946) .b8 100
(EngineCore_DP0 pid=303946) .b8 95
(EngineCore_DP0 pid=303946) .b8 76
(EngineCore_DP0 pid=303946) .b8 108
(EngineCore_DP0 pid=303946) .b8 97
(EngineCore_DP0 pid=303946) .b8 109
(EngineCore_DP0 pid=303946) .b8 97
(EngineCore_DP0 pid=303946) .b8 51
(EngineCore_DP0 pid=303946) .b8 46
(EngineCore_DP0 pid=303946) .b8 50
(EngineCore_DP0 pid=303946) .b8 45
(EngineCore_DP0 pid=303946) .b8 49
(EngineCore_DP0 pid=303946) .b8 66
(EngineCore_DP0 pid=303946) .b8 46
(EngineCore_DP0 pid=303946) .b8 112
(EngineCore_DP0 pid=303946) .b8 121
(EngineCore_DP0 pid=303946) .b8 0
(EngineCore_DP0 pid=303946) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=303946) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=303946) .b8 114
(EngineCore_DP0 pid=303946) .b8 111
(EngineCore_DP0 pid=303946) .b8 111
(EngineCore_DP0 pid=303946) .b8 116
(EngineCore_DP0 pid=303946) .b8 47
(EngineCore_DP0 pid=303946) .b8 118
(EngineCore_DP0 pid=303946) .b8 108
(EngineCore_DP0 pid=303946) .b8 108
(EngineCore_DP0 pid=303946) .b8 109
(EngineCore_DP0 pid=303946) .b8 98
(EngineCore_DP0 pid=303946) .b8 101
(EngineCore_DP0 pid=303946) .b8 110
(EngineCore_DP0 pid=303946) .b8 99
(EngineCore_DP0 pid=303946) .b8 104
(EngineCore_DP0 pid=303946) .b8 47
(EngineCore_DP0 pid=303946) .b8 115
(EngineCore_DP0 pid=303946) .b8 108
(EngineCore_DP0 pid=303946) .b8 105
(EngineCore_DP0 pid=303946) .b8 100
(EngineCore_DP0 pid=303946) .b8 101
(EngineCore_DP0 pid=303946) .b8 115
(EngineCore_DP0 pid=303946) .b8 112
(EngineCore_DP0 pid=303946) .b8 97
(EngineCore_DP0 pid=303946) .b8 114
(EngineCore_DP0 pid=303946) .b8 115
(EngineCore_DP0 pid=303946) .b8 101
(EngineCore_DP0 pid=303946) .b8 47
(EngineCore_DP0 pid=303946) .b8 99
(EngineCore_DP0 pid=303946) .b8 115
(EngineCore_DP0 pid=303946) .b8 114
(EngineCore_DP0 pid=303946) .b8 99
(EngineCore_DP0 pid=303946) .b8 47
(EngineCore_DP0 pid=303946) .b8 102
(EngineCore_DP0 pid=303946) .b8 117
(EngineCore_DP0 pid=303946) .b8 115
(EngineCore_DP0 pid=303946) .b8 101
(EngineCore_DP0 pid=303946) .b8 100
(EngineCore_DP0 pid=303946) .b8 95
(EngineCore_DP0 pid=303946) .b8 113
(EngineCore_DP0 pid=303946) .b8 117
(EngineCore_DP0 pid=303946) .b8 97
(EngineCore_DP0 pid=303946) .b8 110
(EngineCore_DP0 pid=303946) .b8 116
(EngineCore_DP0 pid=303946) .b8 95
(EngineCore_DP0 pid=303946) .b8 115
(EngineCore_DP0 pid=303946) .b8 108
(EngineCore_DP0 pid=303946) .b8 105
(EngineCore_DP0 pid=303946) .b8 100
(EngineCore_DP0 pid=303946) .b8 101
(EngineCore_DP0 pid=303946) .b8 95
(EngineCore_DP0 pid=303946) .b8 116
(EngineCore_DP0 pid=303946) .b8 114
(EngineCore_DP0 pid=303946) .b8 105
(EngineCore_DP0 pid=303946) .b8 116
(EngineCore_DP0 pid=303946) .b8 111
(EngineCore_DP0 pid=303946) .b8 110
(EngineCore_DP0 pid=303946) .b8 47
(EngineCore_DP0 pid=303946) .b8 98
(EngineCore_DP0 pid=303946) .b8 117
(EngineCore_DP0 pid=303946) .b8 105
(EngineCore_DP0 pid=303946) .b8 108
(EngineCore_DP0 pid=303946) .b8 100
(EngineCore_DP0 pid=303946) .b8 47
(EngineCore_DP0 pid=303946) .b8 71
(EngineCore_DP0 pid=303946) .b8 66
(EngineCore_DP0 pid=303946) .b8 49
(EngineCore_DP0 pid=303946) .b8 48
(EngineCore_DP0 pid=303946) .b8 95
(EngineCore_DP0 pid=303946) .b8 99
(EngineCore_DP0 pid=303946) .b8 99
(EngineCore_DP0 pid=303946) .b8 49
(EngineCore_DP0 pid=303946) .b8 50
(EngineCore_DP0 pid=303946) .b8 49
(EngineCore_DP0 pid=303946) .b8 95
(EngineCore_DP0 pid=303946) .b8 112
(EngineCore_DP0 pid=303946) .b8 121
(EngineCore_DP0 pid=303946) .b8 51
(EngineCore_DP0 pid=303946) .b8 49
(EngineCore_DP0 pid=303946) .b8 50
(EngineCore_DP0 pid=303946) .b8 95
(EngineCore_DP0 pid=303946) .b8 99
(EngineCore_DP0 pid=303946) .b8 117
(EngineCore_DP0 pid=303946) .b8 49
(EngineCore_DP0 pid=303946) .b8 50
(EngineCore_DP0 pid=303946) .b8 57
(EngineCore_DP0 pid=303946) .b8 95
(EngineCore_DP0 pid=303946) .b8 97
(EngineCore_DP0 pid=303946) .b8 97
(EngineCore_DP0 pid=303946) .b8 114
(EngineCore_DP0 pid=303946) .b8 99
(EngineCore_DP0 pid=303946) .b8 104
(EngineCore_DP0 pid=303946) .b8 54
(EngineCore_DP0 pid=303946) .b8 52
(EngineCore_DP0 pid=303946) .b8 0
(EngineCore_DP0 pid=303946) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=303946) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=303946) .b8 113
(EngineCore_DP0 pid=303946) .b8 117
(EngineCore_DP0 pid=303946) .b8 97
(EngineCore_DP0 pid=303946) .b8 110
(EngineCore_DP0 pid=303946) .b8 116
(EngineCore_DP0 pid=303946) .b8 95
(EngineCore_DP0 pid=303946) .b8 115
(EngineCore_DP0 pid=303946) .b8 108
(EngineCore_DP0 pid=303946) .b8 105
(EngineCore_DP0 pid=303946) .b8 100
(EngineCore_DP0 pid=303946) .b8 101
(EngineCore_DP0 pid=303946) .b8 95
(EngineCore_DP0 pid=303946) .b8 102
(EngineCore_DP0 pid=303946) .b8 112
(EngineCore_DP0 pid=303946) .b8 56
(EngineCore_DP0 pid=303946) .b8 95
(EngineCore_DP0 pid=303946) .b8 107
(EngineCore_DP0 pid=303946) .b8 101
(EngineCore_DP0 pid=303946) .b8 114
(EngineCore_DP0 pid=303946) .b8 110
(EngineCore_DP0 pid=303946) .b8 101
(EngineCore_DP0 pid=303946) .b8 108
(EngineCore_DP0 pid=303946) .b8 0
(EngineCore_DP0 pid=303946) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=303946) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=303946) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=303946) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=303946) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=303946) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=303946) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=303946) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=303946) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=303946) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=303946) .b8 191                                 // DW_AT_call_line
(EngineCore_DP0 pid=303946) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=303946) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=303946) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=303946) 	}
(EngineCore_DP0 pid=303946) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=303946) 
(EngineCore_DP0 pid=303946) ================================================================
(EngineCore_DP0 pid=303946) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=303946) 
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp6uxxuyi0.ptx', '-o', '/tmp/tmp6uxxuyi0.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866] 
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866] 
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866] 
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp6uxxuyi0.ptx -o /tmp/tmp6uxxuyi0.ptx.o
(EngineCore_DP0 pid=303946) ERROR 01-25 18:50:40 [core.py:866] 

STDERR:
[2026-01-25 18:50:24] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 18:50:24] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 18:50:24] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 18:50:24] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:50:24] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:50:24] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:50:24] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:50:24] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:50:24] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 18:50:24] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 18:50:24] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 18:50:24] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 18:50:24] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 18:50:24] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 18:50:27] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 18:50:27] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 18:50:27] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 18:50:27] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:50:27] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:50:27] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:50:27] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:50:27] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:50:27] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 18:50:27] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 18:50:27] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 18:50:27] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 18:50:27] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 18:50:27] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=303946) [2026-01-25 18:50:28] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=303946) [2026-01-25 18:50:28] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=303946) [2026-01-25 18:50:28] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=303946) [2026-01-25 18:50:28] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=303946) [2026-01-25 18:50:28] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=303946) [2026-01-25 18:50:28] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=303946) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=303946) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.91s/it]
(EngineCore_DP0 pid=303946) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.91s/it]
(EngineCore_DP0 pid=303946) 
(EngineCore_DP0 pid=303946) [2026-01-25 18:50:39] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=303946) [2026-01-25 18:50:40] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6340608 bytes
(EngineCore_DP0 pid=303946) [2026-01-25 18:50:40] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=303946) [2026-01-25 18:50:40] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 4227072 bytes
(EngineCore_DP0 pid=303946) [2026-01-25 18:50:40] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=303946) [2026-01-25 18:50:40] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 33816576 bytes
(EngineCore_DP0 pid=303946) [2026-01-25 18:50:40] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=303946) [2026-01-25 18:50:40] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16809984 bytes
(EngineCore_DP0 pid=303946) Process EngineCore_DP0:
(EngineCore_DP0 pid=303946) Traceback (most recent call last):
(EngineCore_DP0 pid=303946)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=303946)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=303946)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=303946)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=303946) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp6uxxuyi0.ptx', '-o', '/tmp/tmp6uxxuyi0.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=303946) 
(EngineCore_DP0 pid=303946) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=303946) 
(EngineCore_DP0 pid=303946) Traceback (most recent call last):
(EngineCore_DP0 pid=303946)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=303946)     self.run()
(EngineCore_DP0 pid=303946)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=303946)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=303946)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=303946)     raise e
(EngineCore_DP0 pid=303946)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=303946)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=303946)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=303946)     super().__init__(
(EngineCore_DP0 pid=303946)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=303946)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=303946)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=303946)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=303946)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=303946)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=303946)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=303946)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=303946)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=303946)     return func(*args, **kwargs)
(EngineCore_DP0 pid=303946)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=303946)     return func(*args, **kwargs)
(EngineCore_DP0 pid=303946)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=303946)     self.model_runner.profile_run()
(EngineCore_DP0 pid=303946)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=303946)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=303946)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=303946)     return func(*args, **kwargs)
(EngineCore_DP0 pid=303946)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=303946)     outputs = self.model(
(EngineCore_DP0 pid=303946)               ^^^^^^^^^^^
(EngineCore_DP0 pid=303946)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=303946)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=303946)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=303946)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=303946)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=303946)     model_output = self.model(
(EngineCore_DP0 pid=303946)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=303946)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=303946)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=303946)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=303946)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=303946)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=303946)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=303946)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=303946)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=303946)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=303946)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=303946)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=303946)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=303946)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=303946)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=303946)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=303946)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=303946)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=303946)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=303946)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=303946)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=303946)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=303946)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=303946)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=303946)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=303946)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=303946)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=303946)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=303946)     return self._linear_fn(
(EngineCore_DP0 pid=303946)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=303946)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=303946)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=303946)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=303946)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=303946)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=303946)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=303946)     return fn(input, L)
(EngineCore_DP0 pid=303946)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=303946)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=303946)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=303946)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=303946)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=303946)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=303946)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=303946)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=303946)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=303946)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=303946)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=303946)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=303946)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=303946)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=303946)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=303946)     raise PTXASError(error)
(EngineCore_DP0 pid=303946) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=303946) `ptxas` stderr:
(EngineCore_DP0 pid=303946) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=303946) 
(EngineCore_DP0 pid=303946) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp6uxxuyi0.ptx -o /tmp/tmp6uxxuyi0.ptx.o
(EngineCore_DP0 pid=303946) 
[rank0]:[W125 18:50:41.389400150 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=128

========== M=256 ==========
Time: 2026-01-25 18:50:42
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10
Params: prompt_len=256, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10 --dataset-name random --input-len 256 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 257 --max-num-batched-tokens 257 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-1B-FP8_M256.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 18:50:46 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 18:50:46 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=304449) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=304449) 
(EngineCore_DP0 pid=304449) 
(EngineCore_DP0 pid=304449) ================================================================
(EngineCore_DP0 pid=304449) Internal Triton PTX codegen error
(EngineCore_DP0 pid=304449) `ptxas` stderr:
(EngineCore_DP0 pid=304449) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=304449) 
(EngineCore_DP0 pid=304449) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpniw2xc4c.ptx -o /tmp/tmpniw2xc4c.ptx.o
(EngineCore_DP0 pid=304449) 
(EngineCore_DP0 pid=304449) 
(EngineCore_DP0 pid=304449) //
(EngineCore_DP0 pid=304449) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=304449) //
(EngineCore_DP0 pid=304449) 
(EngineCore_DP0 pid=304449) .version 8.7
(EngineCore_DP0 pid=304449) .target sm_121a
(EngineCore_DP0 pid=304449) .address_size 64
(EngineCore_DP0 pid=304449) 
(EngineCore_DP0 pid=304449) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=304449) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=304449)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=304449) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=304449) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=304449) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=304449) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=304449) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=304449) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=304449) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=304449) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=304449) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=304449) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=304449) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=304449) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=304449) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=304449) )
(EngineCore_DP0 pid=304449) .reqntid 1024
(EngineCore_DP0 pid=304449) {
(EngineCore_DP0 pid=304449) 	.reg .pred 	%p<20>;
(EngineCore_DP0 pid=304449) 	.reg .b16 	%rs<25>;
(EngineCore_DP0 pid=304449) 	.reg .b32 	%r<115>;
(EngineCore_DP0 pid=304449) 	.reg .b64 	%rd<13>;
(EngineCore_DP0 pid=304449) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=304449) $L__func_begin0:
(EngineCore_DP0 pid=304449) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=304449) 
(EngineCore_DP0 pid=304449) // %bb.0:
(EngineCore_DP0 pid=304449) 	ld.param.b32 	%r19, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=304449) 	ld.param.b32 	%r18, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=304449) 	ld.param.b32 	%r17, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=304449) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=304449) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=304449) $L__tmp0:
(EngineCore_DP0 pid=304449) 	.loc	1 177 24                        // quant_slide_tuned_Llama3.2-1B.py:177:24
(EngineCore_DP0 pid=304449) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=304449) 	ld.param.b32 	%r21, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=304449) 	.loc	1 182 26                        // quant_slide_tuned_Llama3.2-1B.py:182:26
(EngineCore_DP0 pid=304449) 	mul.lo.s32 	%r22, %r21, %r1;
(EngineCore_DP0 pid=304449) 	.loc	1 182 20                        // quant_slide_tuned_Llama3.2-1B.py:182:20
(EngineCore_DP0 pid=304449) 	mad.wide.s32 	%rd1, %r22, 2, %rd4;
(EngineCore_DP0 pid=304449) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=304449) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=304449) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=304449) 	setp.lt.s32 	%p1, %r18, 1;
(EngineCore_DP0 pid=304449) 	mov.b32 	%r113, 0f2B8CBCCC;
(EngineCore_DP0 pid=304449) 	setp.eq.b32 	%p19, %r2, 0;
(EngineCore_DP0 pid=304449) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=304449) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=304449) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=304449) 	shl.b32 	%r3, %r2, 2;
(EngineCore_DP0 pid=304449) 	and.b32 	%r4, %r2, 31;
(EngineCore_DP0 pid=304449) 	shr.u32 	%r31, %r2, 3;
(EngineCore_DP0 pid=304449) 	and.b32 	%r32, %r31, 124;
(EngineCore_DP0 pid=304449) 	mov.b32 	%r33, global_smem;
(EngineCore_DP0 pid=304449) 	add.s32 	%r39, %r33, %r32;
(EngineCore_DP0 pid=304449) 	add.s32 	%r42, %r33, %r3;
(EngineCore_DP0 pid=304449) 	mov.b32 	%r37, 0;
(EngineCore_DP0 pid=304449) 	mov.b32 	%r111, 0f00000000;
(EngineCore_DP0 pid=304449) 	setp.lt.u32 	%p4, %r2, 32;
(EngineCore_DP0 pid=304449) 	setp.eq.b32 	%p3, %r4, 0;
(EngineCore_DP0 pid=304449) 	mov.b32 	%r112, %r37;
(EngineCore_DP0 pid=304449) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=304449) 	.loc	1 189 22                        // quant_slide_tuned_Llama3.2-1B.py:189:22
(EngineCore_DP0 pid=304449) 	add.s32 	%r45, %r3, %r112;
(EngineCore_DP0 pid=304449) 	setp.lt.s32 	%p2, %r45, %r17;
(EngineCore_DP0 pid=304449) 	.loc	1 190 29                        // quant_slide_tuned_Llama3.2-1B.py:190:29
(EngineCore_DP0 pid=304449) 	mad.wide.s32 	%rd6, %r45, 2, %rd1;
(EngineCore_DP0 pid=304449) 	.loc	1 190 21                        // quant_slide_tuned_Llama3.2-1B.py:190:21
(EngineCore_DP0 pid=304449) 	// begin inline asm
(EngineCore_DP0 pid=304449) 	mov.u32 %r35, %r37;
(EngineCore_DP0 pid=304449) 	mov.u32 %r36, %r37;
(EngineCore_DP0 pid=304449) 	@%p2 ld.global.v2.b32 { %r35, %r36 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=304449) 	// end inline asm
(EngineCore_DP0 pid=304449) 	mov.b32 	{%rs1, %rs2}, %r35;
(EngineCore_DP0 pid=304449) 	mov.b32 	{%rs3, %rs4}, %r36;
(EngineCore_DP0 pid=304449) 	.loc	1 191 50                        // quant_slide_tuned_Llama3.2-1B.py:191:50
(EngineCore_DP0 pid=304449) 	abs.bf16 	%rs5, %rs1;
(EngineCore_DP0 pid=304449) 	abs.bf16 	%rs6, %rs2;
(EngineCore_DP0 pid=304449) 	abs.bf16 	%rs7, %rs3;
(EngineCore_DP0 pid=304449) 	abs.bf16 	%rs8, %rs4;
(EngineCore_DP0 pid=304449) $L__tmp1:
(EngineCore_DP0 pid=304449) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=304449) 	bar.sync 	0;
(EngineCore_DP0 pid=304449) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=304449) 	max.bf16 	%rs9, %rs5, %rs6;
(EngineCore_DP0 pid=304449) 	max.bf16 	%rs10, %rs9, %rs7;
(EngineCore_DP0 pid=304449) 	max.bf16 	%rs11, %rs10, %rs8;
(EngineCore_DP0 pid=304449) 	cvt.f32.bf16 	%r46, %rs11;
(EngineCore_DP0 pid=304449) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=304449) 	shfl.sync.bfly.b32 	%r47, %r46, 16, 31, -1;
(EngineCore_DP0 pid=304449) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=304449) 	max.f32 	%r48, %r46, %r47;
(EngineCore_DP0 pid=304449) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=304449) 	shfl.sync.bfly.b32 	%r49, %r48, 8, 31, -1;
(EngineCore_DP0 pid=304449) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=304449) 	max.f32 	%r50, %r48, %r49;
(EngineCore_DP0 pid=304449) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=304449) 	shfl.sync.bfly.b32 	%r51, %r50, 4, 31, -1;
(EngineCore_DP0 pid=304449) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=304449) 	max.f32 	%r52, %r50, %r51;
(EngineCore_DP0 pid=304449) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=304449) 	shfl.sync.bfly.b32 	%r53, %r52, 2, 31, -1;
(EngineCore_DP0 pid=304449) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=304449) 	max.f32 	%r54, %r52, %r53;
(EngineCore_DP0 pid=304449) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=304449) 	shfl.sync.bfly.b32 	%r55, %r54, 1, 31, -1;
(EngineCore_DP0 pid=304449) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=304449) 	max.f32 	%r40, %r54, %r55;
(EngineCore_DP0 pid=304449) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=304449) 	// begin inline asm
(EngineCore_DP0 pid=304449) 	@%p3 st.shared.b32 [ %r39 + 0 ], %r40;
(EngineCore_DP0 pid=304449) 	// end inline asm
(EngineCore_DP0 pid=304449) 	bar.sync 	0;
(EngineCore_DP0 pid=304449) 	// begin inline asm
(EngineCore_DP0 pid=304449) 	@%p4 ld.shared.b32 %r41, [ %r42 + 0 ];
(EngineCore_DP0 pid=304449) 	// end inline asm
(EngineCore_DP0 pid=304449) 	shfl.sync.bfly.b32 	%r56, %r41, 16, 31, -1;
(EngineCore_DP0 pid=304449) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=304449) 	max.f32 	%r57, %r41, %r56;
(EngineCore_DP0 pid=304449) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=304449) 	shfl.sync.bfly.b32 	%r58, %r57, 8, 31, -1;
(EngineCore_DP0 pid=304449) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=304449) 	max.f32 	%r59, %r57, %r58;
(EngineCore_DP0 pid=304449) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=304449) 	shfl.sync.bfly.b32 	%r60, %r59, 4, 31, -1;
(EngineCore_DP0 pid=304449) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=304449) 	max.f32 	%r61, %r59, %r60;
(EngineCore_DP0 pid=304449) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=304449) 	shfl.sync.bfly.b32 	%r62, %r61, 2, 31, -1;
(EngineCore_DP0 pid=304449) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=304449) 	max.f32 	%r63, %r61, %r62;
(EngineCore_DP0 pid=304449) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=304449) 	shfl.sync.bfly.b32 	%r64, %r63, 1, 31, -1;
(EngineCore_DP0 pid=304449) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=304449) 	max.f32 	%r44, %r63, %r64;
(EngineCore_DP0 pid=304449) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=304449) 	// begin inline asm
(EngineCore_DP0 pid=304449) 	@%p19 st.shared.b32 [ %r42 + 0 ], %r44;
(EngineCore_DP0 pid=304449) 	// end inline asm
(EngineCore_DP0 pid=304449) 	bar.sync 	0;
(EngineCore_DP0 pid=304449) 	ld.shared.b32 	%r65, [global_smem];
(EngineCore_DP0 pid=304449) $L__tmp2:
(EngineCore_DP0 pid=304449) 	.loc	1 191 36                        // quant_slide_tuned_Llama3.2-1B.py:191:36
(EngineCore_DP0 pid=304449) 	max.f32 	%r111, %r111, %r65;
(EngineCore_DP0 pid=304449) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=304449) 	add.s32 	%r112, %r112, 4096;
(EngineCore_DP0 pid=304449) 	setp.lt.s32 	%p6, %r112, %r18;
(EngineCore_DP0 pid=304449) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=304449) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=304449) 	.loc	1 193 32                        // quant_slide_tuned_Llama3.2-1B.py:193:32
(EngineCore_DP0 pid=304449) 	max.f32 	%r113, %r111, 0f2B8CBCCC;
(EngineCore_DP0 pid=304449) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=304449) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=304449) 	mov.b32 	%r67, 0f43E00000;
(EngineCore_DP0 pid=304449) 	.loc	1 194 32                        // quant_slide_tuned_Llama3.2-1B.py:194:32
(EngineCore_DP0 pid=304449) 	div.full.f32 	%r68, %r113, %r67;
(EngineCore_DP0 pid=304449) 	.loc	1 194 41                        // quant_slide_tuned_Llama3.2-1B.py:194:41
(EngineCore_DP0 pid=304449) 	max.f32 	%r66, %r68, 0f36924925;
(EngineCore_DP0 pid=304449) 	.loc	1 196 25                        // quant_slide_tuned_Llama3.2-1B.py:196:25
(EngineCore_DP0 pid=304449) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=304449) 	.loc	1 196 30                        // quant_slide_tuned_Llama3.2-1B.py:196:30
(EngineCore_DP0 pid=304449) 	// begin inline asm
(EngineCore_DP0 pid=304449) 	@%p19 st.global.b32 [ %rd7 + 0 ], { %r66 };
(EngineCore_DP0 pid=304449) 	// end inline asm
(EngineCore_DP0 pid=304449) 	.loc	1 199 29                        // quant_slide_tuned_Llama3.2-1B.py:199:29
(EngineCore_DP0 pid=304449) 	shl.b32 	%r14, %r19, 2;
(EngineCore_DP0 pid=304449) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=304449) 	setp.lt.s32 	%p8, %r14, 1;
(EngineCore_DP0 pid=304449) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=304449) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=304449) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=304449) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=304449) 	shr.s32 	%r24, %r23, 31;
(EngineCore_DP0 pid=304449) 	shr.u32 	%r25, %r24, 30;
(EngineCore_DP0 pid=304449) 	add.s32 	%r26, %r23, %r25;
(EngineCore_DP0 pid=304449) 	shr.s32 	%r27, %r26, 2;
(EngineCore_DP0 pid=304449) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=304449) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=304449) 	mad.wide.s32 	%rd2, %r28, 4, %rd5;
(EngineCore_DP0 pid=304449) 	div.full.f32 	%r13, %r67, %r113;
(EngineCore_DP0 pid=304449) 	mov.b32 	%r114, 0;
(EngineCore_DP0 pid=304449) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=304449)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=304449) 	.loc	1 203 30                        // quant_slide_tuned_Llama3.2-1B.py:203:30
(EngineCore_DP0 pid=304449) 	add.s32 	%r80, %r2, %r114;
(EngineCore_DP0 pid=304449) 	setp.lt.s32 	%p13, %r80, %r14;
(EngineCore_DP0 pid=304449) 	.loc	1 206 24                        // quant_slide_tuned_Llama3.2-1B.py:206:24
(EngineCore_DP0 pid=304449) 	shr.s32 	%r81, %r80, 31;
(EngineCore_DP0 pid=304449) 	shr.u32 	%r82, %r81, 30;
(EngineCore_DP0 pid=304449) 	add.s32 	%r83, %r80, %r82;
(EngineCore_DP0 pid=304449) 	shr.s32 	%r84, %r83, 2;
(EngineCore_DP0 pid=304449) 	.loc	1 207 23                        // quant_slide_tuned_Llama3.2-1B.py:207:23
(EngineCore_DP0 pid=304449) 	and.b32 	%r85, %r83, 2147483644;
(EngineCore_DP0 pid=304449) 	sub.s32 	%r86, %r80, %r85;
(EngineCore_DP0 pid=304449) 	.loc	1 208 30                        // quant_slide_tuned_Llama3.2-1B.py:208:30
(EngineCore_DP0 pid=304449) 	shl.b32 	%r87, %r86, 1;
(EngineCore_DP0 pid=304449) 	.loc	1 208 26                        // quant_slide_tuned_Llama3.2-1B.py:208:26
(EngineCore_DP0 pid=304449) 	mad.lo.s32 	%r88, %r84, 10, %r87;
(EngineCore_DP0 pid=304449) 	.loc	1 211 53                        // quant_slide_tuned_Llama3.2-1B.py:211:53
(EngineCore_DP0 pid=304449) 	setp.lt.s32 	%p14, %r88, %r17;
(EngineCore_DP0 pid=304449) 	.loc	1 211 37                        // quant_slide_tuned_Llama3.2-1B.py:211:37
(EngineCore_DP0 pid=304449) 	and.pred 	%p9, %p13, %p14;
(EngineCore_DP0 pid=304449) 	.loc	1 210 29                        // quant_slide_tuned_Llama3.2-1B.py:210:29
(EngineCore_DP0 pid=304449) 	mad.wide.s32 	%rd8, %r88, 2, %rd1;
(EngineCore_DP0 pid=304449) 	mov.b16 	%rs13, 0;
(EngineCore_DP0 pid=304449) 	.loc	1 210 21                        // quant_slide_tuned_Llama3.2-1B.py:210:21
(EngineCore_DP0 pid=304449) 	// begin inline asm
(EngineCore_DP0 pid=304449) 	mov.u16 %rs12, %rs13;
(EngineCore_DP0 pid=304449) 	@%p9 ld.global.b16 { %rs12 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=304449) 	// end inline asm
(EngineCore_DP0 pid=304449) 	.loc	1 211 79                        // quant_slide_tuned_Llama3.2-1B.py:211:79
(EngineCore_DP0 pid=304449) 	cvt.f32.bf16 	%r89, %rs12;
(EngineCore_DP0 pid=304449) 	.loc	1 213 48                        // quant_slide_tuned_Llama3.2-1B.py:213:48
(EngineCore_DP0 pid=304449) 	or.b32 	%r90, %r88, 1;
(EngineCore_DP0 pid=304449) 	.loc	1 213 53                        // quant_slide_tuned_Llama3.2-1B.py:213:53
(EngineCore_DP0 pid=304449) 	setp.lt.s32 	%p15, %r90, %r17;
(EngineCore_DP0 pid=304449) 	.loc	1 213 37                        // quant_slide_tuned_Llama3.2-1B.py:213:37
(EngineCore_DP0 pid=304449) 	and.pred 	%p10, %p13, %p15;
(EngineCore_DP0 pid=304449) 	.loc	1 212 39                        // quant_slide_tuned_Llama3.2-1B.py:212:39
(EngineCore_DP0 pid=304449) 	add.s64 	%rd9, %rd8, 2;
(EngineCore_DP0 pid=304449) 	.loc	1 212 21                        // quant_slide_tuned_Llama3.2-1B.py:212:21
(EngineCore_DP0 pid=304449) 	// begin inline asm
(EngineCore_DP0 pid=304449) 	mov.u16 %rs14, %rs13;
(EngineCore_DP0 pid=304449) 	@%p10 ld.global.b16 { %rs14 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=304449) 	// end inline asm
(EngineCore_DP0 pid=304449) 	.loc	1 213 79                        // quant_slide_tuned_Llama3.2-1B.py:213:79
(EngineCore_DP0 pid=304449) 	cvt.f32.bf16 	%r91, %rs14;
(EngineCore_DP0 pid=304449) 	.loc	1 215 48                        // quant_slide_tuned_Llama3.2-1B.py:215:48
(EngineCore_DP0 pid=304449) 	add.s32 	%r92, %r88, 2;
(EngineCore_DP0 pid=304449) 	.loc	1 215 53                        // quant_slide_tuned_Llama3.2-1B.py:215:53
(EngineCore_DP0 pid=304449) 	setp.lt.s32 	%p16, %r92, %r17;
(EngineCore_DP0 pid=304449) 	.loc	1 215 37                        // quant_slide_tuned_Llama3.2-1B.py:215:37
(EngineCore_DP0 pid=304449) 	and.pred 	%p11, %p13, %p16;
(EngineCore_DP0 pid=304449) 	.loc	1 214 39                        // quant_slide_tuned_Llama3.2-1B.py:214:39
(EngineCore_DP0 pid=304449) 	add.s64 	%rd10, %rd8, 4;
(EngineCore_DP0 pid=304449) 	.loc	1 214 21                        // quant_slide_tuned_Llama3.2-1B.py:214:21
(EngineCore_DP0 pid=304449) 	// begin inline asm
(EngineCore_DP0 pid=304449) 	mov.u16 %rs16, %rs13;
(EngineCore_DP0 pid=304449) 	@%p11 ld.global.b16 { %rs16 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=304449) 	// end inline asm
(EngineCore_DP0 pid=304449) 	.loc	1 215 79                        // quant_slide_tuned_Llama3.2-1B.py:215:79
(EngineCore_DP0 pid=304449) 	cvt.f32.bf16 	%r93, %rs16;
(EngineCore_DP0 pid=304449) 	.loc	1 217 48                        // quant_slide_tuned_Llama3.2-1B.py:217:48
(EngineCore_DP0 pid=304449) 	add.s32 	%r94, %r88, 3;
(EngineCore_DP0 pid=304449) 	.loc	1 217 53                        // quant_slide_tuned_Llama3.2-1B.py:217:53
(EngineCore_DP0 pid=304449) 	setp.lt.s32 	%p17, %r94, %r17;
(EngineCore_DP0 pid=304449) 	.loc	1 217 37                        // quant_slide_tuned_Llama3.2-1B.py:217:37
(EngineCore_DP0 pid=304449) 	and.pred 	%p12, %p13, %p17;
(EngineCore_DP0 pid=304449) 	.loc	1 216 39                        // quant_slide_tuned_Llama3.2-1B.py:216:39
(EngineCore_DP0 pid=304449) 	add.s64 	%rd11, %rd8, 6;
(EngineCore_DP0 pid=304449) 	.loc	1 216 21                        // quant_slide_tuned_Llama3.2-1B.py:216:21
(EngineCore_DP0 pid=304449) 	// begin inline asm
(EngineCore_DP0 pid=304449) 	mov.u16 %rs18, %rs13;
(EngineCore_DP0 pid=304449) 	@%p12 ld.global.b16 { %rs18 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=304449) 	// end inline asm
(EngineCore_DP0 pid=304449) 	.loc	1 217 79                        // quant_slide_tuned_Llama3.2-1B.py:217:79
(EngineCore_DP0 pid=304449) 	cvt.f32.bf16 	%r95, %rs18;
(EngineCore_DP0 pid=304449) 	.loc	1 219 27                        // quant_slide_tuned_Llama3.2-1B.py:219:27
(EngineCore_DP0 pid=304449) 	mul.f32 	%r96, %r13, %r89;
(EngineCore_DP0 pid=304449) 	mov.b32 	%r97, 0f43E00000;
(EngineCore_DP0 pid=304449) 	.loc	1 219 48                        // quant_slide_tuned_Llama3.2-1B.py:219:48
(EngineCore_DP0 pid=304449) 	min.xorsign.abs.f32 	%r70, %r96, %r97;
(EngineCore_DP0 pid=304449) 	.loc	1 219 60                        // quant_slide_tuned_Llama3.2-1B.py:219:60
(EngineCore_DP0 pid=304449) 	// begin inline asm
(EngineCore_DP0 pid=304449) 	cvt.rn.satfinite.e4m3x2.f32  %rs20, %r71, %r70; 
(EngineCore_DP0 pid=304449) 
(EngineCore_DP0 pid=304449) 	// end inline asm
(EngineCore_DP0 pid=304449) 	.loc	1 220 27                        // quant_slide_tuned_Llama3.2-1B.py:220:27
(EngineCore_DP0 pid=304449) 	mul.f32 	%r98, %r13, %r91;
(EngineCore_DP0 pid=304449) 	.loc	1 220 48                        // quant_slide_tuned_Llama3.2-1B.py:220:48
(EngineCore_DP0 pid=304449) 	min.xorsign.abs.f32 	%r72, %r98, %r97;
(EngineCore_DP0 pid=304449) 	.loc	1 220 60                        // quant_slide_tuned_Llama3.2-1B.py:220:60
(EngineCore_DP0 pid=304449) 	// begin inline asm
(EngineCore_DP0 pid=304449) 	cvt.rn.satfinite.e4m3x2.f32  %rs21, %r73, %r72; 
(EngineCore_DP0 pid=304449) 
(EngineCore_DP0 pid=304449) 	// end inline asm
(EngineCore_DP0 pid=304449) 	.loc	1 221 27                        // quant_slide_tuned_Llama3.2-1B.py:221:27
(EngineCore_DP0 pid=304449) 	mul.f32 	%r99, %r13, %r93;
(EngineCore_DP0 pid=304449) 	.loc	1 221 48                        // quant_slide_tuned_Llama3.2-1B.py:221:48
(EngineCore_DP0 pid=304449) 	min.xorsign.abs.f32 	%r74, %r99, %r97;
(EngineCore_DP0 pid=304449) 	.loc	1 221 60                        // quant_slide_tuned_Llama3.2-1B.py:221:60
(EngineCore_DP0 pid=304449) 	// begin inline asm
(EngineCore_DP0 pid=304449) 	cvt.rn.satfinite.e4m3x2.f32  %rs22, %r75, %r74; 
(EngineCore_DP0 pid=304449) 
(EngineCore_DP0 pid=304449) 	// end inline asm
(EngineCore_DP0 pid=304449) 	.loc	1 222 27                        // quant_slide_tuned_Llama3.2-1B.py:222:27
(EngineCore_DP0 pid=304449) 	mul.f32 	%r100, %r13, %r95;
(EngineCore_DP0 pid=304449) 	.loc	1 222 48                        // quant_slide_tuned_Llama3.2-1B.py:222:48
(EngineCore_DP0 pid=304449) 	min.xorsign.abs.f32 	%r76, %r100, %r97;
(EngineCore_DP0 pid=304449) 	.loc	1 222 60                        // quant_slide_tuned_Llama3.2-1B.py:222:60
(EngineCore_DP0 pid=304449) 	// begin inline asm
(EngineCore_DP0 pid=304449) 	cvt.rn.satfinite.e4m3x2.f32  %rs23, %r77, %r76; 
(EngineCore_DP0 pid=304449) 
(EngineCore_DP0 pid=304449) 	// end inline asm
(EngineCore_DP0 pid=304449) 	.loc	1 224 45                        // quant_slide_tuned_Llama3.2-1B.py:224:45
(EngineCore_DP0 pid=304449) 	cvt.u32.u16 	%r101, %rs20;
(EngineCore_DP0 pid=304449) 	and.b32 	%r102, %r101, 255;
(EngineCore_DP0 pid=304449) 	.loc	1 226 45                        // quant_slide_tuned_Llama3.2-1B.py:226:45
(EngineCore_DP0 pid=304449) 	cvt.u32.u16 	%r103, %rs22;
(EngineCore_DP0 pid=304449) 	and.b32 	%r104, %r103, 255;
(EngineCore_DP0 pid=304449) 	.loc	1 227 45                        // quant_slide_tuned_Llama3.2-1B.py:227:45
(EngineCore_DP0 pid=304449) 	cvt.u32.u16 	%r105, %rs23;
(EngineCore_DP0 pid=304449) 	.loc	1 229 30                        // quant_slide_tuned_Llama3.2-1B.py:229:30
(EngineCore_DP0 pid=304449) 	and.b16 	%rs24, %rs21, 255;
(EngineCore_DP0 pid=304449) 	mul.wide.u16 	%r106, %rs24, 256;
(EngineCore_DP0 pid=304449) 	.loc	1 229 24                        // quant_slide_tuned_Llama3.2-1B.py:229:24
(EngineCore_DP0 pid=304449) 	or.b32 	%r107, %r106, %r102;
(EngineCore_DP0 pid=304449) 	.loc	1 229 42                        // quant_slide_tuned_Llama3.2-1B.py:229:42
(EngineCore_DP0 pid=304449) 	shl.b32 	%r108, %r104, 16;
(EngineCore_DP0 pid=304449) 	.loc	1 229 36                        // quant_slide_tuned_Llama3.2-1B.py:229:36
(EngineCore_DP0 pid=304449) 	or.b32 	%r109, %r107, %r108;
(EngineCore_DP0 pid=304449) 	.loc	1 229 55                        // quant_slide_tuned_Llama3.2-1B.py:229:55
(EngineCore_DP0 pid=304449) 	shl.b32 	%r110, %r105, 24;
(EngineCore_DP0 pid=304449) 	.loc	1 229 49                        // quant_slide_tuned_Llama3.2-1B.py:229:49
(EngineCore_DP0 pid=304449) 	or.b32 	%r78, %r109, %r110;
(EngineCore_DP0 pid=304449) 	.loc	1 230 29                        // quant_slide_tuned_Llama3.2-1B.py:230:29
(EngineCore_DP0 pid=304449) 	mad.wide.s32 	%rd12, %r80, 4, %rd2;
(EngineCore_DP0 pid=304449) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-1B.py:230:39
(EngineCore_DP0 pid=304449) 	// begin inline asm
(EngineCore_DP0 pid=304449) 	@%p13 st.global.b32 [ %rd12 + 0 ], { %r78 };
(EngineCore_DP0 pid=304449) 	// end inline asm
(EngineCore_DP0 pid=304449) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=304449) 	add.s32 	%r114, %r114, 1024;
(EngineCore_DP0 pid=304449) 	setp.lt.s32 	%p18, %r114, %r14;
(EngineCore_DP0 pid=304449) 	@%p18 bra 	$L__BB0_6;
(EngineCore_DP0 pid=304449) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=304449) 	.loc	1 201 4                         // quant_slide_tuned_Llama3.2-1B.py:201:4
(EngineCore_DP0 pid=304449) 	ret;
(EngineCore_DP0 pid=304449) $L__tmp3:
(EngineCore_DP0 pid=304449) $L__func_end0:
(EngineCore_DP0 pid=304449)                                         // -- End function
(EngineCore_DP0 pid=304449) }
(EngineCore_DP0 pid=304449) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=304449) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=304449) 	.section	.debug_abbrev
(EngineCore_DP0 pid=304449) 	{
(EngineCore_DP0 pid=304449) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=304449) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=304449) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=304449) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=304449) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=304449) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=304449) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=304449) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=304449) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=304449) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=304449) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=304449) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=304449) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=304449) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=304449) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=304449) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=304449) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=304449) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=304449) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=304449) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=304449) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=304449) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=304449) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=304449) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=304449) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=304449) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=304449) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=304449) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=304449) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=304449) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=304449) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=304449) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=304449) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=304449) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=304449) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=304449) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=304449) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=304449) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=304449) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=304449) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=304449) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=304449) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=304449) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=304449) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=304449) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=304449) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=304449) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=304449) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=304449) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=304449) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=304449) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=304449) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=304449) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=304449) 	}
(EngineCore_DP0 pid=304449) 	.section	.debug_info
(EngineCore_DP0 pid=304449) 	{
(EngineCore_DP0 pid=304449) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=304449) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=304449) .b8 0
(EngineCore_DP0 pid=304449) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=304449) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=304449) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=304449) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=304449) .b8 114
(EngineCore_DP0 pid=304449) .b8 105
(EngineCore_DP0 pid=304449) .b8 116
(EngineCore_DP0 pid=304449) .b8 111
(EngineCore_DP0 pid=304449) .b8 110
(EngineCore_DP0 pid=304449) .b8 0
(EngineCore_DP0 pid=304449) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=304449) .b8 0
(EngineCore_DP0 pid=304449) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=304449) .b8 117
(EngineCore_DP0 pid=304449) .b8 97
(EngineCore_DP0 pid=304449) .b8 110
(EngineCore_DP0 pid=304449) .b8 116
(EngineCore_DP0 pid=304449) .b8 95
(EngineCore_DP0 pid=304449) .b8 115
(EngineCore_DP0 pid=304449) .b8 108
(EngineCore_DP0 pid=304449) .b8 105
(EngineCore_DP0 pid=304449) .b8 100
(EngineCore_DP0 pid=304449) .b8 101
(EngineCore_DP0 pid=304449) .b8 95
(EngineCore_DP0 pid=304449) .b8 116
(EngineCore_DP0 pid=304449) .b8 117
(EngineCore_DP0 pid=304449) .b8 110
(EngineCore_DP0 pid=304449) .b8 101
(EngineCore_DP0 pid=304449) .b8 100
(EngineCore_DP0 pid=304449) .b8 95
(EngineCore_DP0 pid=304449) .b8 76
(EngineCore_DP0 pid=304449) .b8 108
(EngineCore_DP0 pid=304449) .b8 97
(EngineCore_DP0 pid=304449) .b8 109
(EngineCore_DP0 pid=304449) .b8 97
(EngineCore_DP0 pid=304449) .b8 51
(EngineCore_DP0 pid=304449) .b8 46
(EngineCore_DP0 pid=304449) .b8 50
(EngineCore_DP0 pid=304449) .b8 45
(EngineCore_DP0 pid=304449) .b8 49
(EngineCore_DP0 pid=304449) .b8 66
(EngineCore_DP0 pid=304449) .b8 46
(EngineCore_DP0 pid=304449) .b8 112
(EngineCore_DP0 pid=304449) .b8 121
(EngineCore_DP0 pid=304449) .b8 0
(EngineCore_DP0 pid=304449) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=304449) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=304449) .b8 114
(EngineCore_DP0 pid=304449) .b8 111
(EngineCore_DP0 pid=304449) .b8 111
(EngineCore_DP0 pid=304449) .b8 116
(EngineCore_DP0 pid=304449) .b8 47
(EngineCore_DP0 pid=304449) .b8 118
(EngineCore_DP0 pid=304449) .b8 108
(EngineCore_DP0 pid=304449) .b8 108
(EngineCore_DP0 pid=304449) .b8 109
(EngineCore_DP0 pid=304449) .b8 98
(EngineCore_DP0 pid=304449) .b8 101
(EngineCore_DP0 pid=304449) .b8 110
(EngineCore_DP0 pid=304449) .b8 99
(EngineCore_DP0 pid=304449) .b8 104
(EngineCore_DP0 pid=304449) .b8 47
(EngineCore_DP0 pid=304449) .b8 115
(EngineCore_DP0 pid=304449) .b8 108
(EngineCore_DP0 pid=304449) .b8 105
(EngineCore_DP0 pid=304449) .b8 100
(EngineCore_DP0 pid=304449) .b8 101
(EngineCore_DP0 pid=304449) .b8 115
(EngineCore_DP0 pid=304449) .b8 112
(EngineCore_DP0 pid=304449) .b8 97
(EngineCore_DP0 pid=304449) .b8 114
(EngineCore_DP0 pid=304449) .b8 115
(EngineCore_DP0 pid=304449) .b8 101
(EngineCore_DP0 pid=304449) .b8 47
(EngineCore_DP0 pid=304449) .b8 99
(EngineCore_DP0 pid=304449) .b8 115
(EngineCore_DP0 pid=304449) .b8 114
(EngineCore_DP0 pid=304449) .b8 99
(EngineCore_DP0 pid=304449) .b8 47
(EngineCore_DP0 pid=304449) .b8 102
(EngineCore_DP0 pid=304449) .b8 117
(EngineCore_DP0 pid=304449) .b8 115
(EngineCore_DP0 pid=304449) .b8 101
(EngineCore_DP0 pid=304449) .b8 100
(EngineCore_DP0 pid=304449) .b8 95
(EngineCore_DP0 pid=304449) .b8 113
(EngineCore_DP0 pid=304449) .b8 117
(EngineCore_DP0 pid=304449) .b8 97
(EngineCore_DP0 pid=304449) .b8 110
(EngineCore_DP0 pid=304449) .b8 116
(EngineCore_DP0 pid=304449) .b8 95
(EngineCore_DP0 pid=304449) .b8 115
(EngineCore_DP0 pid=304449) .b8 108
(EngineCore_DP0 pid=304449) .b8 105
(EngineCore_DP0 pid=304449) .b8 100
(EngineCore_DP0 pid=304449) .b8 101
(EngineCore_DP0 pid=304449) .b8 95
(EngineCore_DP0 pid=304449) .b8 116
(EngineCore_DP0 pid=304449) .b8 114
(EngineCore_DP0 pid=304449) .b8 105
(EngineCore_DP0 pid=304449) .b8 116
(EngineCore_DP0 pid=304449) .b8 111
(EngineCore_DP0 pid=304449) .b8 110
(EngineCore_DP0 pid=304449) .b8 47
(EngineCore_DP0 pid=304449) .b8 98
(EngineCore_DP0 pid=304449) .b8 117
(EngineCore_DP0 pid=304449) .b8 105
(EngineCore_DP0 pid=304449) .b8 108
(EngineCore_DP0 pid=304449) .b8 100
(EngineCore_DP0 pid=304449) .b8 47
(EngineCore_DP0 pid=304449) .b8 71
(EngineCore_DP0 pid=304449) .b8 66
(EngineCore_DP0 pid=304449) .b8 49
(EngineCore_DP0 pid=304449) .b8 48
(EngineCore_DP0 pid=304449) .b8 95
(EngineCore_DP0 pid=304449) .b8 99
(EngineCore_DP0 pid=304449) .b8 99
(EngineCore_DP0 pid=304449) .b8 49
(EngineCore_DP0 pid=304449) .b8 50
(EngineCore_DP0 pid=304449) .b8 49
(EngineCore_DP0 pid=304449) .b8 95
(EngineCore_DP0 pid=304449) .b8 112
(EngineCore_DP0 pid=304449) .b8 121
(EngineCore_DP0 pid=304449) .b8 51
(EngineCore_DP0 pid=304449) .b8 49
(EngineCore_DP0 pid=304449) .b8 50
(EngineCore_DP0 pid=304449) .b8 95
(EngineCore_DP0 pid=304449) .b8 99
(EngineCore_DP0 pid=304449) .b8 117
(EngineCore_DP0 pid=304449) .b8 49
(EngineCore_DP0 pid=304449) .b8 50
(EngineCore_DP0 pid=304449) .b8 57
(EngineCore_DP0 pid=304449) .b8 95
(EngineCore_DP0 pid=304449) .b8 97
(EngineCore_DP0 pid=304449) .b8 97
(EngineCore_DP0 pid=304449) .b8 114
(EngineCore_DP0 pid=304449) .b8 99
(EngineCore_DP0 pid=304449) .b8 104
(EngineCore_DP0 pid=304449) .b8 54
(EngineCore_DP0 pid=304449) .b8 52
(EngineCore_DP0 pid=304449) .b8 0
(EngineCore_DP0 pid=304449) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=304449) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=304449) .b8 113
(EngineCore_DP0 pid=304449) .b8 117
(EngineCore_DP0 pid=304449) .b8 97
(EngineCore_DP0 pid=304449) .b8 110
(EngineCore_DP0 pid=304449) .b8 116
(EngineCore_DP0 pid=304449) .b8 95
(EngineCore_DP0 pid=304449) .b8 115
(EngineCore_DP0 pid=304449) .b8 108
(EngineCore_DP0 pid=304449) .b8 105
(EngineCore_DP0 pid=304449) .b8 100
(EngineCore_DP0 pid=304449) .b8 101
(EngineCore_DP0 pid=304449) .b8 95
(EngineCore_DP0 pid=304449) .b8 102
(EngineCore_DP0 pid=304449) .b8 112
(EngineCore_DP0 pid=304449) .b8 56
(EngineCore_DP0 pid=304449) .b8 95
(EngineCore_DP0 pid=304449) .b8 107
(EngineCore_DP0 pid=304449) .b8 101
(EngineCore_DP0 pid=304449) .b8 114
(EngineCore_DP0 pid=304449) .b8 110
(EngineCore_DP0 pid=304449) .b8 101
(EngineCore_DP0 pid=304449) .b8 108
(EngineCore_DP0 pid=304449) .b8 0
(EngineCore_DP0 pid=304449) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=304449) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=304449) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=304449) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=304449) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=304449) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=304449) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=304449) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=304449) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=304449) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=304449) .b8 191                                 // DW_AT_call_line
(EngineCore_DP0 pid=304449) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=304449) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=304449) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=304449) 	}
(EngineCore_DP0 pid=304449) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=304449) 
(EngineCore_DP0 pid=304449) ================================================================
(EngineCore_DP0 pid=304449) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=304449) 
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpniw2xc4c.ptx', '-o', '/tmp/tmpniw2xc4c.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866] 
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866] 
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866] 
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpniw2xc4c.ptx -o /tmp/tmpniw2xc4c.ptx.o
(EngineCore_DP0 pid=304449) ERROR 01-25 18:51:03 [core.py:866] 

STDERR:
[2026-01-25 18:50:46] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 18:50:46] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 18:50:46] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 18:50:46] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:50:46] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:50:46] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:50:46] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:50:46] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:50:46] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 18:50:46] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 18:50:46] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 18:50:46] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 18:50:46] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 18:50:46] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 18:50:49] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 18:50:49] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 18:50:49] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 18:50:49] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:50:49] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:50:49] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:50:49] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:50:49] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:50:49] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 18:50:49] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 18:50:49] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 18:50:49] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 18:50:49] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 18:50:49] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=304449) [2026-01-25 18:50:50] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=304449) [2026-01-25 18:50:50] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=304449) [2026-01-25 18:50:50] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=304449) [2026-01-25 18:50:50] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=304449) [2026-01-25 18:50:50] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=304449) [2026-01-25 18:50:50] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=304449) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=304449) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:11<00:00, 11.07s/it]
(EngineCore_DP0 pid=304449) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:11<00:00, 11.07s/it]
(EngineCore_DP0 pid=304449) 
(EngineCore_DP0 pid=304449) [2026-01-25 18:51:02] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=304449) [2026-01-25 18:51:02] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6340608 bytes
(EngineCore_DP0 pid=304449) [2026-01-25 18:51:02] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=304449) [2026-01-25 18:51:02] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 4227072 bytes
(EngineCore_DP0 pid=304449) [2026-01-25 18:51:02] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=304449) [2026-01-25 18:51:02] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 33816576 bytes
(EngineCore_DP0 pid=304449) [2026-01-25 18:51:02] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=304449) [2026-01-25 18:51:02] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16809984 bytes
(EngineCore_DP0 pid=304449) Process EngineCore_DP0:
(EngineCore_DP0 pid=304449) Traceback (most recent call last):
(EngineCore_DP0 pid=304449)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=304449)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=304449)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=304449)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=304449) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpniw2xc4c.ptx', '-o', '/tmp/tmpniw2xc4c.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=304449) 
(EngineCore_DP0 pid=304449) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=304449) 
(EngineCore_DP0 pid=304449) Traceback (most recent call last):
(EngineCore_DP0 pid=304449)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=304449)     self.run()
(EngineCore_DP0 pid=304449)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=304449)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=304449)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=304449)     raise e
(EngineCore_DP0 pid=304449)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=304449)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=304449)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=304449)     super().__init__(
(EngineCore_DP0 pid=304449)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=304449)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=304449)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=304449)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=304449)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=304449)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=304449)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=304449)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=304449)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=304449)     return func(*args, **kwargs)
(EngineCore_DP0 pid=304449)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=304449)     return func(*args, **kwargs)
(EngineCore_DP0 pid=304449)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=304449)     self.model_runner.profile_run()
(EngineCore_DP0 pid=304449)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=304449)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=304449)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=304449)     return func(*args, **kwargs)
(EngineCore_DP0 pid=304449)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=304449)     outputs = self.model(
(EngineCore_DP0 pid=304449)               ^^^^^^^^^^^
(EngineCore_DP0 pid=304449)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=304449)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=304449)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=304449)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=304449)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=304449)     model_output = self.model(
(EngineCore_DP0 pid=304449)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=304449)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=304449)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=304449)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=304449)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=304449)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=304449)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=304449)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=304449)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=304449)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=304449)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=304449)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=304449)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=304449)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=304449)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=304449)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=304449)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=304449)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=304449)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=304449)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=304449)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=304449)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=304449)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=304449)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=304449)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=304449)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=304449)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=304449)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=304449)     return self._linear_fn(
(EngineCore_DP0 pid=304449)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=304449)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=304449)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=304449)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=304449)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=304449)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=304449)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=304449)     return fn(input, L)
(EngineCore_DP0 pid=304449)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=304449)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=304449)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=304449)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=304449)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=304449)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=304449)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=304449)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=304449)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=304449)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=304449)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=304449)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=304449)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=304449)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=304449)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=304449)     raise PTXASError(error)
(EngineCore_DP0 pid=304449) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=304449) `ptxas` stderr:
(EngineCore_DP0 pid=304449) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=304449) 
(EngineCore_DP0 pid=304449) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpniw2xc4c.ptx -o /tmp/tmpniw2xc4c.ptx.o
(EngineCore_DP0 pid=304449) 
[rank0]:[W125 18:51:03.715683787 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=256

========== M=512 ==========
Time: 2026-01-25 19:23:46
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-1B-FP8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:23:50 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:23:50 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=346479) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=346479) 
(EngineCore_DP0 pid=346479) 
(EngineCore_DP0 pid=346479) ================================================================
(EngineCore_DP0 pid=346479) Internal Triton PTX codegen error
(EngineCore_DP0 pid=346479) `ptxas` stderr:
(EngineCore_DP0 pid=346479) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=346479) 
(EngineCore_DP0 pid=346479) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpw9a2y1se.ptx -o /tmp/tmpw9a2y1se.ptx.o
(EngineCore_DP0 pid=346479) 
(EngineCore_DP0 pid=346479) 
(EngineCore_DP0 pid=346479) //
(EngineCore_DP0 pid=346479) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=346479) //
(EngineCore_DP0 pid=346479) 
(EngineCore_DP0 pid=346479) .version 8.7
(EngineCore_DP0 pid=346479) .target sm_121a
(EngineCore_DP0 pid=346479) .address_size 64
(EngineCore_DP0 pid=346479) 
(EngineCore_DP0 pid=346479) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=346479) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=346479)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=346479) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=346479) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=346479) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=346479) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=346479) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=346479) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=346479) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=346479) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=346479) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=346479) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=346479) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=346479) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=346479) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=346479) )
(EngineCore_DP0 pid=346479) .reqntid 1024
(EngineCore_DP0 pid=346479) {
(EngineCore_DP0 pid=346479) 	.reg .pred 	%p<20>;
(EngineCore_DP0 pid=346479) 	.reg .b16 	%rs<25>;
(EngineCore_DP0 pid=346479) 	.reg .b32 	%r<115>;
(EngineCore_DP0 pid=346479) 	.reg .b64 	%rd<13>;
(EngineCore_DP0 pid=346479) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=346479) $L__func_begin0:
(EngineCore_DP0 pid=346479) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=346479) 
(EngineCore_DP0 pid=346479) // %bb.0:
(EngineCore_DP0 pid=346479) 	ld.param.b32 	%r19, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=346479) 	ld.param.b32 	%r18, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=346479) 	ld.param.b32 	%r17, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=346479) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=346479) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=346479) $L__tmp0:
(EngineCore_DP0 pid=346479) 	.loc	1 177 24                        // quant_slide_tuned_Llama3.2-1B.py:177:24
(EngineCore_DP0 pid=346479) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=346479) 	ld.param.b32 	%r21, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=346479) 	.loc	1 182 26                        // quant_slide_tuned_Llama3.2-1B.py:182:26
(EngineCore_DP0 pid=346479) 	mul.lo.s32 	%r22, %r21, %r1;
(EngineCore_DP0 pid=346479) 	.loc	1 182 20                        // quant_slide_tuned_Llama3.2-1B.py:182:20
(EngineCore_DP0 pid=346479) 	mad.wide.s32 	%rd1, %r22, 2, %rd4;
(EngineCore_DP0 pid=346479) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=346479) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=346479) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=346479) 	setp.lt.s32 	%p1, %r18, 1;
(EngineCore_DP0 pid=346479) 	mov.b32 	%r113, 0f2B8CBCCC;
(EngineCore_DP0 pid=346479) 	setp.eq.b32 	%p19, %r2, 0;
(EngineCore_DP0 pid=346479) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=346479) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=346479) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=346479) 	shl.b32 	%r3, %r2, 2;
(EngineCore_DP0 pid=346479) 	and.b32 	%r4, %r2, 31;
(EngineCore_DP0 pid=346479) 	shr.u32 	%r31, %r2, 3;
(EngineCore_DP0 pid=346479) 	and.b32 	%r32, %r31, 124;
(EngineCore_DP0 pid=346479) 	mov.b32 	%r33, global_smem;
(EngineCore_DP0 pid=346479) 	add.s32 	%r39, %r33, %r32;
(EngineCore_DP0 pid=346479) 	add.s32 	%r42, %r33, %r3;
(EngineCore_DP0 pid=346479) 	mov.b32 	%r37, 0;
(EngineCore_DP0 pid=346479) 	mov.b32 	%r111, 0f00000000;
(EngineCore_DP0 pid=346479) 	setp.lt.u32 	%p4, %r2, 32;
(EngineCore_DP0 pid=346479) 	setp.eq.b32 	%p3, %r4, 0;
(EngineCore_DP0 pid=346479) 	mov.b32 	%r112, %r37;
(EngineCore_DP0 pid=346479) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=346479) 	.loc	1 189 22                        // quant_slide_tuned_Llama3.2-1B.py:189:22
(EngineCore_DP0 pid=346479) 	add.s32 	%r45, %r3, %r112;
(EngineCore_DP0 pid=346479) 	setp.lt.s32 	%p2, %r45, %r17;
(EngineCore_DP0 pid=346479) 	.loc	1 190 29                        // quant_slide_tuned_Llama3.2-1B.py:190:29
(EngineCore_DP0 pid=346479) 	mad.wide.s32 	%rd6, %r45, 2, %rd1;
(EngineCore_DP0 pid=346479) 	.loc	1 190 21                        // quant_slide_tuned_Llama3.2-1B.py:190:21
(EngineCore_DP0 pid=346479) 	// begin inline asm
(EngineCore_DP0 pid=346479) 	mov.u32 %r35, %r37;
(EngineCore_DP0 pid=346479) 	mov.u32 %r36, %r37;
(EngineCore_DP0 pid=346479) 	@%p2 ld.global.v2.b32 { %r35, %r36 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=346479) 	// end inline asm
(EngineCore_DP0 pid=346479) 	mov.b32 	{%rs1, %rs2}, %r35;
(EngineCore_DP0 pid=346479) 	mov.b32 	{%rs3, %rs4}, %r36;
(EngineCore_DP0 pid=346479) 	.loc	1 191 50                        // quant_slide_tuned_Llama3.2-1B.py:191:50
(EngineCore_DP0 pid=346479) 	abs.bf16 	%rs5, %rs1;
(EngineCore_DP0 pid=346479) 	abs.bf16 	%rs6, %rs2;
(EngineCore_DP0 pid=346479) 	abs.bf16 	%rs7, %rs3;
(EngineCore_DP0 pid=346479) 	abs.bf16 	%rs8, %rs4;
(EngineCore_DP0 pid=346479) $L__tmp1:
(EngineCore_DP0 pid=346479) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=346479) 	bar.sync 	0;
(EngineCore_DP0 pid=346479) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=346479) 	max.bf16 	%rs9, %rs5, %rs6;
(EngineCore_DP0 pid=346479) 	max.bf16 	%rs10, %rs9, %rs7;
(EngineCore_DP0 pid=346479) 	max.bf16 	%rs11, %rs10, %rs8;
(EngineCore_DP0 pid=346479) 	cvt.f32.bf16 	%r46, %rs11;
(EngineCore_DP0 pid=346479) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=346479) 	shfl.sync.bfly.b32 	%r47, %r46, 16, 31, -1;
(EngineCore_DP0 pid=346479) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=346479) 	max.f32 	%r48, %r46, %r47;
(EngineCore_DP0 pid=346479) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=346479) 	shfl.sync.bfly.b32 	%r49, %r48, 8, 31, -1;
(EngineCore_DP0 pid=346479) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=346479) 	max.f32 	%r50, %r48, %r49;
(EngineCore_DP0 pid=346479) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=346479) 	shfl.sync.bfly.b32 	%r51, %r50, 4, 31, -1;
(EngineCore_DP0 pid=346479) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=346479) 	max.f32 	%r52, %r50, %r51;
(EngineCore_DP0 pid=346479) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=346479) 	shfl.sync.bfly.b32 	%r53, %r52, 2, 31, -1;
(EngineCore_DP0 pid=346479) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=346479) 	max.f32 	%r54, %r52, %r53;
(EngineCore_DP0 pid=346479) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=346479) 	shfl.sync.bfly.b32 	%r55, %r54, 1, 31, -1;
(EngineCore_DP0 pid=346479) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=346479) 	max.f32 	%r40, %r54, %r55;
(EngineCore_DP0 pid=346479) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=346479) 	// begin inline asm
(EngineCore_DP0 pid=346479) 	@%p3 st.shared.b32 [ %r39 + 0 ], %r40;
(EngineCore_DP0 pid=346479) 	// end inline asm
(EngineCore_DP0 pid=346479) 	bar.sync 	0;
(EngineCore_DP0 pid=346479) 	// begin inline asm
(EngineCore_DP0 pid=346479) 	@%p4 ld.shared.b32 %r41, [ %r42 + 0 ];
(EngineCore_DP0 pid=346479) 	// end inline asm
(EngineCore_DP0 pid=346479) 	shfl.sync.bfly.b32 	%r56, %r41, 16, 31, -1;
(EngineCore_DP0 pid=346479) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=346479) 	max.f32 	%r57, %r41, %r56;
(EngineCore_DP0 pid=346479) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=346479) 	shfl.sync.bfly.b32 	%r58, %r57, 8, 31, -1;
(EngineCore_DP0 pid=346479) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=346479) 	max.f32 	%r59, %r57, %r58;
(EngineCore_DP0 pid=346479) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=346479) 	shfl.sync.bfly.b32 	%r60, %r59, 4, 31, -1;
(EngineCore_DP0 pid=346479) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=346479) 	max.f32 	%r61, %r59, %r60;
(EngineCore_DP0 pid=346479) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=346479) 	shfl.sync.bfly.b32 	%r62, %r61, 2, 31, -1;
(EngineCore_DP0 pid=346479) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=346479) 	max.f32 	%r63, %r61, %r62;
(EngineCore_DP0 pid=346479) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=346479) 	shfl.sync.bfly.b32 	%r64, %r63, 1, 31, -1;
(EngineCore_DP0 pid=346479) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=346479) 	max.f32 	%r44, %r63, %r64;
(EngineCore_DP0 pid=346479) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=346479) 	// begin inline asm
(EngineCore_DP0 pid=346479) 	@%p19 st.shared.b32 [ %r42 + 0 ], %r44;
(EngineCore_DP0 pid=346479) 	// end inline asm
(EngineCore_DP0 pid=346479) 	bar.sync 	0;
(EngineCore_DP0 pid=346479) 	ld.shared.b32 	%r65, [global_smem];
(EngineCore_DP0 pid=346479) $L__tmp2:
(EngineCore_DP0 pid=346479) 	.loc	1 191 36                        // quant_slide_tuned_Llama3.2-1B.py:191:36
(EngineCore_DP0 pid=346479) 	max.f32 	%r111, %r111, %r65;
(EngineCore_DP0 pid=346479) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=346479) 	add.s32 	%r112, %r112, 4096;
(EngineCore_DP0 pid=346479) 	setp.lt.s32 	%p6, %r112, %r18;
(EngineCore_DP0 pid=346479) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=346479) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=346479) 	.loc	1 193 32                        // quant_slide_tuned_Llama3.2-1B.py:193:32
(EngineCore_DP0 pid=346479) 	max.f32 	%r113, %r111, 0f2B8CBCCC;
(EngineCore_DP0 pid=346479) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=346479) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=346479) 	mov.b32 	%r67, 0f43E00000;
(EngineCore_DP0 pid=346479) 	.loc	1 194 32                        // quant_slide_tuned_Llama3.2-1B.py:194:32
(EngineCore_DP0 pid=346479) 	div.full.f32 	%r68, %r113, %r67;
(EngineCore_DP0 pid=346479) 	.loc	1 194 41                        // quant_slide_tuned_Llama3.2-1B.py:194:41
(EngineCore_DP0 pid=346479) 	max.f32 	%r66, %r68, 0f36924925;
(EngineCore_DP0 pid=346479) 	.loc	1 196 25                        // quant_slide_tuned_Llama3.2-1B.py:196:25
(EngineCore_DP0 pid=346479) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=346479) 	.loc	1 196 30                        // quant_slide_tuned_Llama3.2-1B.py:196:30
(EngineCore_DP0 pid=346479) 	// begin inline asm
(EngineCore_DP0 pid=346479) 	@%p19 st.global.b32 [ %rd7 + 0 ], { %r66 };
(EngineCore_DP0 pid=346479) 	// end inline asm
(EngineCore_DP0 pid=346479) 	.loc	1 199 29                        // quant_slide_tuned_Llama3.2-1B.py:199:29
(EngineCore_DP0 pid=346479) 	shl.b32 	%r14, %r19, 2;
(EngineCore_DP0 pid=346479) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=346479) 	setp.lt.s32 	%p8, %r14, 1;
(EngineCore_DP0 pid=346479) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=346479) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=346479) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=346479) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=346479) 	shr.s32 	%r24, %r23, 31;
(EngineCore_DP0 pid=346479) 	shr.u32 	%r25, %r24, 30;
(EngineCore_DP0 pid=346479) 	add.s32 	%r26, %r23, %r25;
(EngineCore_DP0 pid=346479) 	shr.s32 	%r27, %r26, 2;
(EngineCore_DP0 pid=346479) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=346479) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=346479) 	mad.wide.s32 	%rd2, %r28, 4, %rd5;
(EngineCore_DP0 pid=346479) 	div.full.f32 	%r13, %r67, %r113;
(EngineCore_DP0 pid=346479) 	mov.b32 	%r114, 0;
(EngineCore_DP0 pid=346479) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=346479)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=346479) 	.loc	1 203 30                        // quant_slide_tuned_Llama3.2-1B.py:203:30
(EngineCore_DP0 pid=346479) 	add.s32 	%r80, %r2, %r114;
(EngineCore_DP0 pid=346479) 	setp.lt.s32 	%p13, %r80, %r14;
(EngineCore_DP0 pid=346479) 	.loc	1 206 24                        // quant_slide_tuned_Llama3.2-1B.py:206:24
(EngineCore_DP0 pid=346479) 	shr.s32 	%r81, %r80, 31;
(EngineCore_DP0 pid=346479) 	shr.u32 	%r82, %r81, 30;
(EngineCore_DP0 pid=346479) 	add.s32 	%r83, %r80, %r82;
(EngineCore_DP0 pid=346479) 	shr.s32 	%r84, %r83, 2;
(EngineCore_DP0 pid=346479) 	.loc	1 207 23                        // quant_slide_tuned_Llama3.2-1B.py:207:23
(EngineCore_DP0 pid=346479) 	and.b32 	%r85, %r83, 2147483644;
(EngineCore_DP0 pid=346479) 	sub.s32 	%r86, %r80, %r85;
(EngineCore_DP0 pid=346479) 	.loc	1 208 30                        // quant_slide_tuned_Llama3.2-1B.py:208:30
(EngineCore_DP0 pid=346479) 	shl.b32 	%r87, %r86, 1;
(EngineCore_DP0 pid=346479) 	.loc	1 208 26                        // quant_slide_tuned_Llama3.2-1B.py:208:26
(EngineCore_DP0 pid=346479) 	mad.lo.s32 	%r88, %r84, 10, %r87;
(EngineCore_DP0 pid=346479) 	.loc	1 211 53                        // quant_slide_tuned_Llama3.2-1B.py:211:53
(EngineCore_DP0 pid=346479) 	setp.lt.s32 	%p14, %r88, %r17;
(EngineCore_DP0 pid=346479) 	.loc	1 211 37                        // quant_slide_tuned_Llama3.2-1B.py:211:37
(EngineCore_DP0 pid=346479) 	and.pred 	%p9, %p13, %p14;
(EngineCore_DP0 pid=346479) 	.loc	1 210 29                        // quant_slide_tuned_Llama3.2-1B.py:210:29
(EngineCore_DP0 pid=346479) 	mad.wide.s32 	%rd8, %r88, 2, %rd1;
(EngineCore_DP0 pid=346479) 	mov.b16 	%rs13, 0;
(EngineCore_DP0 pid=346479) 	.loc	1 210 21                        // quant_slide_tuned_Llama3.2-1B.py:210:21
(EngineCore_DP0 pid=346479) 	// begin inline asm
(EngineCore_DP0 pid=346479) 	mov.u16 %rs12, %rs13;
(EngineCore_DP0 pid=346479) 	@%p9 ld.global.b16 { %rs12 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=346479) 	// end inline asm
(EngineCore_DP0 pid=346479) 	.loc	1 211 79                        // quant_slide_tuned_Llama3.2-1B.py:211:79
(EngineCore_DP0 pid=346479) 	cvt.f32.bf16 	%r89, %rs12;
(EngineCore_DP0 pid=346479) 	.loc	1 213 48                        // quant_slide_tuned_Llama3.2-1B.py:213:48
(EngineCore_DP0 pid=346479) 	or.b32 	%r90, %r88, 1;
(EngineCore_DP0 pid=346479) 	.loc	1 213 53                        // quant_slide_tuned_Llama3.2-1B.py:213:53
(EngineCore_DP0 pid=346479) 	setp.lt.s32 	%p15, %r90, %r17;
(EngineCore_DP0 pid=346479) 	.loc	1 213 37                        // quant_slide_tuned_Llama3.2-1B.py:213:37
(EngineCore_DP0 pid=346479) 	and.pred 	%p10, %p13, %p15;
(EngineCore_DP0 pid=346479) 	.loc	1 212 39                        // quant_slide_tuned_Llama3.2-1B.py:212:39
(EngineCore_DP0 pid=346479) 	add.s64 	%rd9, %rd8, 2;
(EngineCore_DP0 pid=346479) 	.loc	1 212 21                        // quant_slide_tuned_Llama3.2-1B.py:212:21
(EngineCore_DP0 pid=346479) 	// begin inline asm
(EngineCore_DP0 pid=346479) 	mov.u16 %rs14, %rs13;
(EngineCore_DP0 pid=346479) 	@%p10 ld.global.b16 { %rs14 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=346479) 	// end inline asm
(EngineCore_DP0 pid=346479) 	.loc	1 213 79                        // quant_slide_tuned_Llama3.2-1B.py:213:79
(EngineCore_DP0 pid=346479) 	cvt.f32.bf16 	%r91, %rs14;
(EngineCore_DP0 pid=346479) 	.loc	1 215 48                        // quant_slide_tuned_Llama3.2-1B.py:215:48
(EngineCore_DP0 pid=346479) 	add.s32 	%r92, %r88, 2;
(EngineCore_DP0 pid=346479) 	.loc	1 215 53                        // quant_slide_tuned_Llama3.2-1B.py:215:53
(EngineCore_DP0 pid=346479) 	setp.lt.s32 	%p16, %r92, %r17;
(EngineCore_DP0 pid=346479) 	.loc	1 215 37                        // quant_slide_tuned_Llama3.2-1B.py:215:37
(EngineCore_DP0 pid=346479) 	and.pred 	%p11, %p13, %p16;
(EngineCore_DP0 pid=346479) 	.loc	1 214 39                        // quant_slide_tuned_Llama3.2-1B.py:214:39
(EngineCore_DP0 pid=346479) 	add.s64 	%rd10, %rd8, 4;
(EngineCore_DP0 pid=346479) 	.loc	1 214 21                        // quant_slide_tuned_Llama3.2-1B.py:214:21
(EngineCore_DP0 pid=346479) 	// begin inline asm
(EngineCore_DP0 pid=346479) 	mov.u16 %rs16, %rs13;
(EngineCore_DP0 pid=346479) 	@%p11 ld.global.b16 { %rs16 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=346479) 	// end inline asm
(EngineCore_DP0 pid=346479) 	.loc	1 215 79                        // quant_slide_tuned_Llama3.2-1B.py:215:79
(EngineCore_DP0 pid=346479) 	cvt.f32.bf16 	%r93, %rs16;
(EngineCore_DP0 pid=346479) 	.loc	1 217 48                        // quant_slide_tuned_Llama3.2-1B.py:217:48
(EngineCore_DP0 pid=346479) 	add.s32 	%r94, %r88, 3;
(EngineCore_DP0 pid=346479) 	.loc	1 217 53                        // quant_slide_tuned_Llama3.2-1B.py:217:53
(EngineCore_DP0 pid=346479) 	setp.lt.s32 	%p17, %r94, %r17;
(EngineCore_DP0 pid=346479) 	.loc	1 217 37                        // quant_slide_tuned_Llama3.2-1B.py:217:37
(EngineCore_DP0 pid=346479) 	and.pred 	%p12, %p13, %p17;
(EngineCore_DP0 pid=346479) 	.loc	1 216 39                        // quant_slide_tuned_Llama3.2-1B.py:216:39
(EngineCore_DP0 pid=346479) 	add.s64 	%rd11, %rd8, 6;
(EngineCore_DP0 pid=346479) 	.loc	1 216 21                        // quant_slide_tuned_Llama3.2-1B.py:216:21
(EngineCore_DP0 pid=346479) 	// begin inline asm
(EngineCore_DP0 pid=346479) 	mov.u16 %rs18, %rs13;
(EngineCore_DP0 pid=346479) 	@%p12 ld.global.b16 { %rs18 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=346479) 	// end inline asm
(EngineCore_DP0 pid=346479) 	.loc	1 217 79                        // quant_slide_tuned_Llama3.2-1B.py:217:79
(EngineCore_DP0 pid=346479) 	cvt.f32.bf16 	%r95, %rs18;
(EngineCore_DP0 pid=346479) 	.loc	1 219 27                        // quant_slide_tuned_Llama3.2-1B.py:219:27
(EngineCore_DP0 pid=346479) 	mul.f32 	%r96, %r13, %r89;
(EngineCore_DP0 pid=346479) 	mov.b32 	%r97, 0f43E00000;
(EngineCore_DP0 pid=346479) 	.loc	1 219 48                        // quant_slide_tuned_Llama3.2-1B.py:219:48
(EngineCore_DP0 pid=346479) 	min.xorsign.abs.f32 	%r70, %r96, %r97;
(EngineCore_DP0 pid=346479) 	.loc	1 219 60                        // quant_slide_tuned_Llama3.2-1B.py:219:60
(EngineCore_DP0 pid=346479) 	// begin inline asm
(EngineCore_DP0 pid=346479) 	cvt.rn.satfinite.e4m3x2.f32  %rs20, %r71, %r70; 
(EngineCore_DP0 pid=346479) 
(EngineCore_DP0 pid=346479) 	// end inline asm
(EngineCore_DP0 pid=346479) 	.loc	1 220 27                        // quant_slide_tuned_Llama3.2-1B.py:220:27
(EngineCore_DP0 pid=346479) 	mul.f32 	%r98, %r13, %r91;
(EngineCore_DP0 pid=346479) 	.loc	1 220 48                        // quant_slide_tuned_Llama3.2-1B.py:220:48
(EngineCore_DP0 pid=346479) 	min.xorsign.abs.f32 	%r72, %r98, %r97;
(EngineCore_DP0 pid=346479) 	.loc	1 220 60                        // quant_slide_tuned_Llama3.2-1B.py:220:60
(EngineCore_DP0 pid=346479) 	// begin inline asm
(EngineCore_DP0 pid=346479) 	cvt.rn.satfinite.e4m3x2.f32  %rs21, %r73, %r72; 
(EngineCore_DP0 pid=346479) 
(EngineCore_DP0 pid=346479) 	// end inline asm
(EngineCore_DP0 pid=346479) 	.loc	1 221 27                        // quant_slide_tuned_Llama3.2-1B.py:221:27
(EngineCore_DP0 pid=346479) 	mul.f32 	%r99, %r13, %r93;
(EngineCore_DP0 pid=346479) 	.loc	1 221 48                        // quant_slide_tuned_Llama3.2-1B.py:221:48
(EngineCore_DP0 pid=346479) 	min.xorsign.abs.f32 	%r74, %r99, %r97;
(EngineCore_DP0 pid=346479) 	.loc	1 221 60                        // quant_slide_tuned_Llama3.2-1B.py:221:60
(EngineCore_DP0 pid=346479) 	// begin inline asm
(EngineCore_DP0 pid=346479) 	cvt.rn.satfinite.e4m3x2.f32  %rs22, %r75, %r74; 
(EngineCore_DP0 pid=346479) 
(EngineCore_DP0 pid=346479) 	// end inline asm
(EngineCore_DP0 pid=346479) 	.loc	1 222 27                        // quant_slide_tuned_Llama3.2-1B.py:222:27
(EngineCore_DP0 pid=346479) 	mul.f32 	%r100, %r13, %r95;
(EngineCore_DP0 pid=346479) 	.loc	1 222 48                        // quant_slide_tuned_Llama3.2-1B.py:222:48
(EngineCore_DP0 pid=346479) 	min.xorsign.abs.f32 	%r76, %r100, %r97;
(EngineCore_DP0 pid=346479) 	.loc	1 222 60                        // quant_slide_tuned_Llama3.2-1B.py:222:60
(EngineCore_DP0 pid=346479) 	// begin inline asm
(EngineCore_DP0 pid=346479) 	cvt.rn.satfinite.e4m3x2.f32  %rs23, %r77, %r76; 
(EngineCore_DP0 pid=346479) 
(EngineCore_DP0 pid=346479) 	// end inline asm
(EngineCore_DP0 pid=346479) 	.loc	1 224 45                        // quant_slide_tuned_Llama3.2-1B.py:224:45
(EngineCore_DP0 pid=346479) 	cvt.u32.u16 	%r101, %rs20;
(EngineCore_DP0 pid=346479) 	and.b32 	%r102, %r101, 255;
(EngineCore_DP0 pid=346479) 	.loc	1 226 45                        // quant_slide_tuned_Llama3.2-1B.py:226:45
(EngineCore_DP0 pid=346479) 	cvt.u32.u16 	%r103, %rs22;
(EngineCore_DP0 pid=346479) 	and.b32 	%r104, %r103, 255;
(EngineCore_DP0 pid=346479) 	.loc	1 227 45                        // quant_slide_tuned_Llama3.2-1B.py:227:45
(EngineCore_DP0 pid=346479) 	cvt.u32.u16 	%r105, %rs23;
(EngineCore_DP0 pid=346479) 	.loc	1 229 30                        // quant_slide_tuned_Llama3.2-1B.py:229:30
(EngineCore_DP0 pid=346479) 	and.b16 	%rs24, %rs21, 255;
(EngineCore_DP0 pid=346479) 	mul.wide.u16 	%r106, %rs24, 256;
(EngineCore_DP0 pid=346479) 	.loc	1 229 24                        // quant_slide_tuned_Llama3.2-1B.py:229:24
(EngineCore_DP0 pid=346479) 	or.b32 	%r107, %r106, %r102;
(EngineCore_DP0 pid=346479) 	.loc	1 229 42                        // quant_slide_tuned_Llama3.2-1B.py:229:42
(EngineCore_DP0 pid=346479) 	shl.b32 	%r108, %r104, 16;
(EngineCore_DP0 pid=346479) 	.loc	1 229 36                        // quant_slide_tuned_Llama3.2-1B.py:229:36
(EngineCore_DP0 pid=346479) 	or.b32 	%r109, %r107, %r108;
(EngineCore_DP0 pid=346479) 	.loc	1 229 55                        // quant_slide_tuned_Llama3.2-1B.py:229:55
(EngineCore_DP0 pid=346479) 	shl.b32 	%r110, %r105, 24;
(EngineCore_DP0 pid=346479) 	.loc	1 229 49                        // quant_slide_tuned_Llama3.2-1B.py:229:49
(EngineCore_DP0 pid=346479) 	or.b32 	%r78, %r109, %r110;
(EngineCore_DP0 pid=346479) 	.loc	1 230 29                        // quant_slide_tuned_Llama3.2-1B.py:230:29
(EngineCore_DP0 pid=346479) 	mad.wide.s32 	%rd12, %r80, 4, %rd2;
(EngineCore_DP0 pid=346479) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-1B.py:230:39
(EngineCore_DP0 pid=346479) 	// begin inline asm
(EngineCore_DP0 pid=346479) 	@%p13 st.global.b32 [ %rd12 + 0 ], { %r78 };
(EngineCore_DP0 pid=346479) 	// end inline asm
(EngineCore_DP0 pid=346479) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=346479) 	add.s32 	%r114, %r114, 1024;
(EngineCore_DP0 pid=346479) 	setp.lt.s32 	%p18, %r114, %r14;
(EngineCore_DP0 pid=346479) 	@%p18 bra 	$L__BB0_6;
(EngineCore_DP0 pid=346479) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=346479) 	.loc	1 201 4                         // quant_slide_tuned_Llama3.2-1B.py:201:4
(EngineCore_DP0 pid=346479) 	ret;
(EngineCore_DP0 pid=346479) $L__tmp3:
(EngineCore_DP0 pid=346479) $L__func_end0:
(EngineCore_DP0 pid=346479)                                         // -- End function
(EngineCore_DP0 pid=346479) }
(EngineCore_DP0 pid=346479) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=346479) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=346479) 	.section	.debug_abbrev
(EngineCore_DP0 pid=346479) 	{
(EngineCore_DP0 pid=346479) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=346479) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=346479) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=346479) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=346479) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=346479) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=346479) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=346479) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=346479) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=346479) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=346479) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=346479) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=346479) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=346479) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=346479) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=346479) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=346479) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=346479) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=346479) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=346479) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=346479) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=346479) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=346479) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=346479) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=346479) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=346479) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=346479) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=346479) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=346479) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=346479) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=346479) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=346479) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=346479) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=346479) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=346479) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=346479) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=346479) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=346479) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=346479) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=346479) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=346479) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=346479) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=346479) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=346479) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=346479) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=346479) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=346479) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=346479) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=346479) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=346479) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=346479) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=346479) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=346479) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=346479) 	}
(EngineCore_DP0 pid=346479) 	.section	.debug_info
(EngineCore_DP0 pid=346479) 	{
(EngineCore_DP0 pid=346479) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=346479) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=346479) .b8 0
(EngineCore_DP0 pid=346479) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=346479) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=346479) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=346479) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=346479) .b8 114
(EngineCore_DP0 pid=346479) .b8 105
(EngineCore_DP0 pid=346479) .b8 116
(EngineCore_DP0 pid=346479) .b8 111
(EngineCore_DP0 pid=346479) .b8 110
(EngineCore_DP0 pid=346479) .b8 0
(EngineCore_DP0 pid=346479) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=346479) .b8 0
(EngineCore_DP0 pid=346479) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=346479) .b8 117
(EngineCore_DP0 pid=346479) .b8 97
(EngineCore_DP0 pid=346479) .b8 110
(EngineCore_DP0 pid=346479) .b8 116
(EngineCore_DP0 pid=346479) .b8 95
(EngineCore_DP0 pid=346479) .b8 115
(EngineCore_DP0 pid=346479) .b8 108
(EngineCore_DP0 pid=346479) .b8 105
(EngineCore_DP0 pid=346479) .b8 100
(EngineCore_DP0 pid=346479) .b8 101
(EngineCore_DP0 pid=346479) .b8 95
(EngineCore_DP0 pid=346479) .b8 116
(EngineCore_DP0 pid=346479) .b8 117
(EngineCore_DP0 pid=346479) .b8 110
(EngineCore_DP0 pid=346479) .b8 101
(EngineCore_DP0 pid=346479) .b8 100
(EngineCore_DP0 pid=346479) .b8 95
(EngineCore_DP0 pid=346479) .b8 76
(EngineCore_DP0 pid=346479) .b8 108
(EngineCore_DP0 pid=346479) .b8 97
(EngineCore_DP0 pid=346479) .b8 109
(EngineCore_DP0 pid=346479) .b8 97
(EngineCore_DP0 pid=346479) .b8 51
(EngineCore_DP0 pid=346479) .b8 46
(EngineCore_DP0 pid=346479) .b8 50
(EngineCore_DP0 pid=346479) .b8 45
(EngineCore_DP0 pid=346479) .b8 49
(EngineCore_DP0 pid=346479) .b8 66
(EngineCore_DP0 pid=346479) .b8 46
(EngineCore_DP0 pid=346479) .b8 112
(EngineCore_DP0 pid=346479) .b8 121
(EngineCore_DP0 pid=346479) .b8 0
(EngineCore_DP0 pid=346479) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=346479) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=346479) .b8 114
(EngineCore_DP0 pid=346479) .b8 111
(EngineCore_DP0 pid=346479) .b8 111
(EngineCore_DP0 pid=346479) .b8 116
(EngineCore_DP0 pid=346479) .b8 47
(EngineCore_DP0 pid=346479) .b8 118
(EngineCore_DP0 pid=346479) .b8 108
(EngineCore_DP0 pid=346479) .b8 108
(EngineCore_DP0 pid=346479) .b8 109
(EngineCore_DP0 pid=346479) .b8 98
(EngineCore_DP0 pid=346479) .b8 101
(EngineCore_DP0 pid=346479) .b8 110
(EngineCore_DP0 pid=346479) .b8 99
(EngineCore_DP0 pid=346479) .b8 104
(EngineCore_DP0 pid=346479) .b8 47
(EngineCore_DP0 pid=346479) .b8 115
(EngineCore_DP0 pid=346479) .b8 108
(EngineCore_DP0 pid=346479) .b8 105
(EngineCore_DP0 pid=346479) .b8 100
(EngineCore_DP0 pid=346479) .b8 101
(EngineCore_DP0 pid=346479) .b8 115
(EngineCore_DP0 pid=346479) .b8 112
(EngineCore_DP0 pid=346479) .b8 97
(EngineCore_DP0 pid=346479) .b8 114
(EngineCore_DP0 pid=346479) .b8 115
(EngineCore_DP0 pid=346479) .b8 101
(EngineCore_DP0 pid=346479) .b8 47
(EngineCore_DP0 pid=346479) .b8 99
(EngineCore_DP0 pid=346479) .b8 115
(EngineCore_DP0 pid=346479) .b8 114
(EngineCore_DP0 pid=346479) .b8 99
(EngineCore_DP0 pid=346479) .b8 47
(EngineCore_DP0 pid=346479) .b8 102
(EngineCore_DP0 pid=346479) .b8 117
(EngineCore_DP0 pid=346479) .b8 115
(EngineCore_DP0 pid=346479) .b8 101
(EngineCore_DP0 pid=346479) .b8 100
(EngineCore_DP0 pid=346479) .b8 95
(EngineCore_DP0 pid=346479) .b8 113
(EngineCore_DP0 pid=346479) .b8 117
(EngineCore_DP0 pid=346479) .b8 97
(EngineCore_DP0 pid=346479) .b8 110
(EngineCore_DP0 pid=346479) .b8 116
(EngineCore_DP0 pid=346479) .b8 95
(EngineCore_DP0 pid=346479) .b8 115
(EngineCore_DP0 pid=346479) .b8 108
(EngineCore_DP0 pid=346479) .b8 105
(EngineCore_DP0 pid=346479) .b8 100
(EngineCore_DP0 pid=346479) .b8 101
(EngineCore_DP0 pid=346479) .b8 95
(EngineCore_DP0 pid=346479) .b8 116
(EngineCore_DP0 pid=346479) .b8 114
(EngineCore_DP0 pid=346479) .b8 105
(EngineCore_DP0 pid=346479) .b8 116
(EngineCore_DP0 pid=346479) .b8 111
(EngineCore_DP0 pid=346479) .b8 110
(EngineCore_DP0 pid=346479) .b8 47
(EngineCore_DP0 pid=346479) .b8 98
(EngineCore_DP0 pid=346479) .b8 117
(EngineCore_DP0 pid=346479) .b8 105
(EngineCore_DP0 pid=346479) .b8 108
(EngineCore_DP0 pid=346479) .b8 100
(EngineCore_DP0 pid=346479) .b8 47
(EngineCore_DP0 pid=346479) .b8 71
(EngineCore_DP0 pid=346479) .b8 66
(EngineCore_DP0 pid=346479) .b8 49
(EngineCore_DP0 pid=346479) .b8 48
(EngineCore_DP0 pid=346479) .b8 95
(EngineCore_DP0 pid=346479) .b8 99
(EngineCore_DP0 pid=346479) .b8 99
(EngineCore_DP0 pid=346479) .b8 49
(EngineCore_DP0 pid=346479) .b8 50
(EngineCore_DP0 pid=346479) .b8 49
(EngineCore_DP0 pid=346479) .b8 95
(EngineCore_DP0 pid=346479) .b8 112
(EngineCore_DP0 pid=346479) .b8 121
(EngineCore_DP0 pid=346479) .b8 51
(EngineCore_DP0 pid=346479) .b8 49
(EngineCore_DP0 pid=346479) .b8 50
(EngineCore_DP0 pid=346479) .b8 95
(EngineCore_DP0 pid=346479) .b8 99
(EngineCore_DP0 pid=346479) .b8 117
(EngineCore_DP0 pid=346479) .b8 49
(EngineCore_DP0 pid=346479) .b8 50
(EngineCore_DP0 pid=346479) .b8 57
(EngineCore_DP0 pid=346479) .b8 95
(EngineCore_DP0 pid=346479) .b8 97
(EngineCore_DP0 pid=346479) .b8 97
(EngineCore_DP0 pid=346479) .b8 114
(EngineCore_DP0 pid=346479) .b8 99
(EngineCore_DP0 pid=346479) .b8 104
(EngineCore_DP0 pid=346479) .b8 54
(EngineCore_DP0 pid=346479) .b8 52
(EngineCore_DP0 pid=346479) .b8 0
(EngineCore_DP0 pid=346479) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=346479) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=346479) .b8 113
(EngineCore_DP0 pid=346479) .b8 117
(EngineCore_DP0 pid=346479) .b8 97
(EngineCore_DP0 pid=346479) .b8 110
(EngineCore_DP0 pid=346479) .b8 116
(EngineCore_DP0 pid=346479) .b8 95
(EngineCore_DP0 pid=346479) .b8 115
(EngineCore_DP0 pid=346479) .b8 108
(EngineCore_DP0 pid=346479) .b8 105
(EngineCore_DP0 pid=346479) .b8 100
(EngineCore_DP0 pid=346479) .b8 101
(EngineCore_DP0 pid=346479) .b8 95
(EngineCore_DP0 pid=346479) .b8 102
(EngineCore_DP0 pid=346479) .b8 112
(EngineCore_DP0 pid=346479) .b8 56
(EngineCore_DP0 pid=346479) .b8 95
(EngineCore_DP0 pid=346479) .b8 107
(EngineCore_DP0 pid=346479) .b8 101
(EngineCore_DP0 pid=346479) .b8 114
(EngineCore_DP0 pid=346479) .b8 110
(EngineCore_DP0 pid=346479) .b8 101
(EngineCore_DP0 pid=346479) .b8 108
(EngineCore_DP0 pid=346479) .b8 0
(EngineCore_DP0 pid=346479) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=346479) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=346479) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=346479) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=346479) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=346479) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=346479) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=346479) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=346479) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=346479) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=346479) .b8 191                                 // DW_AT_call_line
(EngineCore_DP0 pid=346479) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=346479) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=346479) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=346479) 	}
(EngineCore_DP0 pid=346479) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=346479) 
(EngineCore_DP0 pid=346479) ================================================================
(EngineCore_DP0 pid=346479) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=346479) 
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpw9a2y1se.ptx', '-o', '/tmp/tmpw9a2y1se.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866] 
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866] 
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866] 
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpw9a2y1se.ptx -o /tmp/tmpw9a2y1se.ptx.o
(EngineCore_DP0 pid=346479) ERROR 01-25 19:24:07 [core.py:866] 

STDERR:
[2026-01-25 19:23:50] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:23:50] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:23:50] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:23:50] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:23:50] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:23:50] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:23:50] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:23:50] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:23:50] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:23:50] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:23:50] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:23:50] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:23:50] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:23:50] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:23:53] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:23:53] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:23:53] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:23:53] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:23:53] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:23:53] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:23:53] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:23:53] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:23:53] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:23:53] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:23:53] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:23:53] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:23:53] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:23:53] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=346479) [2026-01-25 19:23:54] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=346479) [2026-01-25 19:23:54] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=346479) [2026-01-25 19:23:54] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=346479) [2026-01-25 19:23:54] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=346479) [2026-01-25 19:23:54] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=346479) [2026-01-25 19:23:54] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=346479) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=346479) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.88s/it]
(EngineCore_DP0 pid=346479) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.88s/it]
(EngineCore_DP0 pid=346479) 
(EngineCore_DP0 pid=346479) [2026-01-25 19:24:06] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=346479) [2026-01-25 19:24:06] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6340608 bytes
(EngineCore_DP0 pid=346479) [2026-01-25 19:24:06] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=346479) [2026-01-25 19:24:06] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 4227072 bytes
(EngineCore_DP0 pid=346479) [2026-01-25 19:24:06] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=346479) [2026-01-25 19:24:06] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 33816576 bytes
(EngineCore_DP0 pid=346479) [2026-01-25 19:24:06] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=346479) [2026-01-25 19:24:06] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16809984 bytes
(EngineCore_DP0 pid=346479) Process EngineCore_DP0:
(EngineCore_DP0 pid=346479) Traceback (most recent call last):
(EngineCore_DP0 pid=346479)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=346479)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=346479)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=346479)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=346479) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpw9a2y1se.ptx', '-o', '/tmp/tmpw9a2y1se.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=346479) 
(EngineCore_DP0 pid=346479) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=346479) 
(EngineCore_DP0 pid=346479) Traceback (most recent call last):
(EngineCore_DP0 pid=346479)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=346479)     self.run()
(EngineCore_DP0 pid=346479)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=346479)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=346479)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=346479)     raise e
(EngineCore_DP0 pid=346479)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=346479)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=346479)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=346479)     super().__init__(
(EngineCore_DP0 pid=346479)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=346479)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=346479)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=346479)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=346479)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=346479)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=346479)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=346479)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=346479)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=346479)     return func(*args, **kwargs)
(EngineCore_DP0 pid=346479)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=346479)     return func(*args, **kwargs)
(EngineCore_DP0 pid=346479)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=346479)     self.model_runner.profile_run()
(EngineCore_DP0 pid=346479)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=346479)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=346479)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=346479)     return func(*args, **kwargs)
(EngineCore_DP0 pid=346479)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=346479)     outputs = self.model(
(EngineCore_DP0 pid=346479)               ^^^^^^^^^^^
(EngineCore_DP0 pid=346479)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=346479)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=346479)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=346479)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=346479)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=346479)     model_output = self.model(
(EngineCore_DP0 pid=346479)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=346479)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=346479)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=346479)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=346479)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=346479)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=346479)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=346479)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=346479)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=346479)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=346479)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=346479)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=346479)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=346479)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=346479)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=346479)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=346479)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=346479)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=346479)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=346479)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=346479)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=346479)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=346479)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=346479)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=346479)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=346479)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=346479)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=346479)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=346479)     return self._linear_fn(
(EngineCore_DP0 pid=346479)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=346479)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=346479)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=346479)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=346479)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=346479)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=346479)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=346479)     return fn(input, L)
(EngineCore_DP0 pid=346479)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=346479)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=346479)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=346479)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=346479)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=346479)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=346479)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=346479)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=346479)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=346479)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=346479)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=346479)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=346479)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=346479)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346479)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=346479)     raise PTXASError(error)
(EngineCore_DP0 pid=346479) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=346479) `ptxas` stderr:
(EngineCore_DP0 pid=346479) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=346479) 
(EngineCore_DP0 pid=346479) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpw9a2y1se.ptx -o /tmp/tmpw9a2y1se.ptx.o
(EngineCore_DP0 pid=346479) 
[rank0]:[W125 19:24:07.537460721 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=512

========== M=1024 ==========
Time: 2026-01-25 19:24:08
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-1B-FP8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:24:12 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:24:12 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=346998) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=346998) 
(EngineCore_DP0 pid=346998) 
(EngineCore_DP0 pid=346998) ================================================================
(EngineCore_DP0 pid=346998) Internal Triton PTX codegen error
(EngineCore_DP0 pid=346998) `ptxas` stderr:
(EngineCore_DP0 pid=346998) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=346998) 
(EngineCore_DP0 pid=346998) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpklq06np0.ptx -o /tmp/tmpklq06np0.ptx.o
(EngineCore_DP0 pid=346998) 
(EngineCore_DP0 pid=346998) 
(EngineCore_DP0 pid=346998) //
(EngineCore_DP0 pid=346998) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=346998) //
(EngineCore_DP0 pid=346998) 
(EngineCore_DP0 pid=346998) .version 8.7
(EngineCore_DP0 pid=346998) .target sm_121a
(EngineCore_DP0 pid=346998) .address_size 64
(EngineCore_DP0 pid=346998) 
(EngineCore_DP0 pid=346998) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=346998) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=346998)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=346998) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=346998) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=346998) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=346998) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=346998) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=346998) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=346998) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=346998) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=346998) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=346998) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=346998) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=346998) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=346998) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=346998) )
(EngineCore_DP0 pid=346998) .reqntid 512
(EngineCore_DP0 pid=346998) {
(EngineCore_DP0 pid=346998) 	.reg .pred 	%p<21>;
(EngineCore_DP0 pid=346998) 	.reg .b16 	%rs<61>;
(EngineCore_DP0 pid=346998) 	.reg .b32 	%r<127>;
(EngineCore_DP0 pid=346998) 	.reg .b64 	%rd<14>;
(EngineCore_DP0 pid=346998) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=346998) $L__func_begin0:
(EngineCore_DP0 pid=346998) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=346998) 
(EngineCore_DP0 pid=346998) // %bb.0:
(EngineCore_DP0 pid=346998) 	ld.param.b32 	%r20, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=346998) 	ld.param.b32 	%r19, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=346998) 	ld.param.b32 	%r18, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=346998) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=346998) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=346998) $L__tmp0:
(EngineCore_DP0 pid=346998) 	.loc	1 177 24                        // quant_slide_tuned_Llama3.2-1B.py:177:24
(EngineCore_DP0 pid=346998) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=346998) 	ld.param.b32 	%r22, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=346998) 	.loc	1 182 26                        // quant_slide_tuned_Llama3.2-1B.py:182:26
(EngineCore_DP0 pid=346998) 	mul.lo.s32 	%r23, %r22, %r1;
(EngineCore_DP0 pid=346998) 	.loc	1 182 20                        // quant_slide_tuned_Llama3.2-1B.py:182:20
(EngineCore_DP0 pid=346998) 	mad.wide.s32 	%rd1, %r23, 2, %rd4;
(EngineCore_DP0 pid=346998) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=346998) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=346998) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=346998) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=346998) 	setp.lt.s32 	%p1, %r19, 1;
(EngineCore_DP0 pid=346998) 	mov.b32 	%r125, 0f2B8CBCCC;
(EngineCore_DP0 pid=346998) 	setp.eq.b32 	%p20, %r2, 0;
(EngineCore_DP0 pid=346998) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=346998) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=346998) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=346998) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=346998) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=346998) 	shr.u32 	%r32, %r2, 3;
(EngineCore_DP0 pid=346998) 	and.b32 	%r33, %r32, 60;
(EngineCore_DP0 pid=346998) 	mov.b32 	%r34, global_smem;
(EngineCore_DP0 pid=346998) 	add.s32 	%r52, %r34, %r33;
(EngineCore_DP0 pid=346998) 	shl.b32 	%r35, %r2, 2;
(EngineCore_DP0 pid=346998) 	add.s32 	%r55, %r34, %r35;
(EngineCore_DP0 pid=346998) 	mov.b32 	%r40, 0;
(EngineCore_DP0 pid=346998) 	mov.b32 	%r123, 0f00000000;
(EngineCore_DP0 pid=346998) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=346998) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=346998) 	mov.b32 	%r124, %r40;
(EngineCore_DP0 pid=346998) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=346998) 	.loc	1 188 19                        // quant_slide_tuned_Llama3.2-1B.py:188:19
(EngineCore_DP0 pid=346998) 	add.s32 	%r58, %r4, %r124;
(EngineCore_DP0 pid=346998) 	.loc	1 189 22                        // quant_slide_tuned_Llama3.2-1B.py:189:22
(EngineCore_DP0 pid=346998) 	add.s32 	%r59, %r58, 4096;
(EngineCore_DP0 pid=346998) 	setp.lt.s32 	%p2, %r58, %r18;
(EngineCore_DP0 pid=346998) 	setp.lt.s32 	%p3, %r59, %r18;
(EngineCore_DP0 pid=346998) 	.loc	1 190 29                        // quant_slide_tuned_Llama3.2-1B.py:190:29
(EngineCore_DP0 pid=346998) 	mad.wide.s32 	%rd6, %r58, 2, %rd1;
(EngineCore_DP0 pid=346998) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=346998) 	.loc	1 190 21                        // quant_slide_tuned_Llama3.2-1B.py:190:21
(EngineCore_DP0 pid=346998) 	// begin inline asm
(EngineCore_DP0 pid=346998) 	mov.u32 %r36, %r40;
(EngineCore_DP0 pid=346998) 	mov.u32 %r37, %r40;
(EngineCore_DP0 pid=346998) 	mov.u32 %r38, %r40;
(EngineCore_DP0 pid=346998) 	mov.u32 %r39, %r40;
(EngineCore_DP0 pid=346998) 	@%p2 ld.global.v4.b32 { %r36, %r37, %r38, %r39 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=346998) 	// end inline asm
(EngineCore_DP0 pid=346998) 	mov.b32 	{%rs1, %rs2}, %r36;
(EngineCore_DP0 pid=346998) 	mov.b32 	{%rs3, %rs4}, %r37;
(EngineCore_DP0 pid=346998) 	mov.b32 	{%rs5, %rs6}, %r38;
(EngineCore_DP0 pid=346998) 	mov.b32 	{%rs7, %rs8}, %r39;
(EngineCore_DP0 pid=346998) 	// begin inline asm
(EngineCore_DP0 pid=346998) 	mov.u32 %r44, %r40;
(EngineCore_DP0 pid=346998) 	mov.u32 %r45, %r40;
(EngineCore_DP0 pid=346998) 	mov.u32 %r46, %r40;
(EngineCore_DP0 pid=346998) 	mov.u32 %r47, %r40;
(EngineCore_DP0 pid=346998) 	@%p3 ld.global.v4.b32 { %r44, %r45, %r46, %r47 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=346998) 	// end inline asm
(EngineCore_DP0 pid=346998) 	mov.b32 	{%rs9, %rs10}, %r44;
(EngineCore_DP0 pid=346998) 	mov.b32 	{%rs11, %rs12}, %r45;
(EngineCore_DP0 pid=346998) 	mov.b32 	{%rs13, %rs14}, %r46;
(EngineCore_DP0 pid=346998) 	mov.b32 	{%rs15, %rs16}, %r47;
(EngineCore_DP0 pid=346998) 	.loc	1 191 50                        // quant_slide_tuned_Llama3.2-1B.py:191:50
(EngineCore_DP0 pid=346998) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=346998) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=346998) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=346998) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=346998) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=346998) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=346998) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=346998) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=346998) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=346998) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=346998) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=346998) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=346998) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=346998) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=346998) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=346998) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=346998) $L__tmp1:
(EngineCore_DP0 pid=346998) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=346998) 	bar.sync 	0;
(EngineCore_DP0 pid=346998) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=346998) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=346998) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=346998) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=346998) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=346998) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=346998) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=346998) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=346998) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=346998) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=346998) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=346998) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=346998) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=346998) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=346998) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=346998) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=346998) 	cvt.f32.bf16 	%r60, %rs47;
(EngineCore_DP0 pid=346998) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=346998) 	shfl.sync.bfly.b32 	%r61, %r60, 16, 31, -1;
(EngineCore_DP0 pid=346998) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=346998) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=346998) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=346998) 	shfl.sync.bfly.b32 	%r63, %r62, 8, 31, -1;
(EngineCore_DP0 pid=346998) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=346998) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=346998) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=346998) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=346998) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=346998) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=346998) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=346998) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=346998) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=346998) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=346998) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=346998) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=346998) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=346998) 	max.f32 	%r53, %r68, %r69;
(EngineCore_DP0 pid=346998) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=346998) 	// begin inline asm
(EngineCore_DP0 pid=346998) 	@%p4 st.shared.b32 [ %r52 + 0 ], %r53;
(EngineCore_DP0 pid=346998) 	// end inline asm
(EngineCore_DP0 pid=346998) 	bar.sync 	0;
(EngineCore_DP0 pid=346998) 	// begin inline asm
(EngineCore_DP0 pid=346998) 	@%p5 ld.shared.b32 %r54, [ %r55 + 0 ];
(EngineCore_DP0 pid=346998) 	// end inline asm
(EngineCore_DP0 pid=346998) 	shfl.sync.bfly.b32 	%r70, %r54, 8, 31, -1;
(EngineCore_DP0 pid=346998) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=346998) 	max.f32 	%r71, %r54, %r70;
(EngineCore_DP0 pid=346998) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=346998) 	shfl.sync.bfly.b32 	%r72, %r71, 4, 31, -1;
(EngineCore_DP0 pid=346998) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=346998) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=346998) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=346998) 	shfl.sync.bfly.b32 	%r74, %r73, 2, 31, -1;
(EngineCore_DP0 pid=346998) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=346998) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=346998) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=346998) 	shfl.sync.bfly.b32 	%r76, %r75, 1, 31, -1;
(EngineCore_DP0 pid=346998) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=346998) 	max.f32 	%r57, %r75, %r76;
(EngineCore_DP0 pid=346998) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=346998) 	// begin inline asm
(EngineCore_DP0 pid=346998) 	@%p20 st.shared.b32 [ %r55 + 0 ], %r57;
(EngineCore_DP0 pid=346998) 	// end inline asm
(EngineCore_DP0 pid=346998) 	bar.sync 	0;
(EngineCore_DP0 pid=346998) 	ld.shared.b32 	%r77, [global_smem];
(EngineCore_DP0 pid=346998) $L__tmp2:
(EngineCore_DP0 pid=346998) 	.loc	1 191 36                        // quant_slide_tuned_Llama3.2-1B.py:191:36
(EngineCore_DP0 pid=346998) 	max.f32 	%r123, %r123, %r77;
(EngineCore_DP0 pid=346998) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=346998) 	add.s32 	%r124, %r124, 8192;
(EngineCore_DP0 pid=346998) 	setp.lt.s32 	%p7, %r124, %r19;
(EngineCore_DP0 pid=346998) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=346998) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=346998) 	.loc	1 193 32                        // quant_slide_tuned_Llama3.2-1B.py:193:32
(EngineCore_DP0 pid=346998) 	max.f32 	%r125, %r123, 0f2B8CBCCC;
(EngineCore_DP0 pid=346998) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=346998) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=346998) 	mov.b32 	%r79, 0f43E00000;
(EngineCore_DP0 pid=346998) 	.loc	1 194 32                        // quant_slide_tuned_Llama3.2-1B.py:194:32
(EngineCore_DP0 pid=346998) 	div.full.f32 	%r80, %r125, %r79;
(EngineCore_DP0 pid=346998) 	.loc	1 194 41                        // quant_slide_tuned_Llama3.2-1B.py:194:41
(EngineCore_DP0 pid=346998) 	max.f32 	%r78, %r80, 0f36924925;
(EngineCore_DP0 pid=346998) 	.loc	1 196 25                        // quant_slide_tuned_Llama3.2-1B.py:196:25
(EngineCore_DP0 pid=346998) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=346998) 	.loc	1 196 30                        // quant_slide_tuned_Llama3.2-1B.py:196:30
(EngineCore_DP0 pid=346998) 	// begin inline asm
(EngineCore_DP0 pid=346998) 	@%p20 st.global.b32 [ %rd8 + 0 ], { %r78 };
(EngineCore_DP0 pid=346998) 	// end inline asm
(EngineCore_DP0 pid=346998) 	.loc	1 199 29                        // quant_slide_tuned_Llama3.2-1B.py:199:29
(EngineCore_DP0 pid=346998) 	shl.b32 	%r15, %r20, 2;
(EngineCore_DP0 pid=346998) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=346998) 	setp.lt.s32 	%p9, %r15, 1;
(EngineCore_DP0 pid=346998) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=346998) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=346998) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=346998) 	ld.param.b32 	%r24, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=346998) 	shr.s32 	%r25, %r24, 31;
(EngineCore_DP0 pid=346998) 	shr.u32 	%r26, %r25, 30;
(EngineCore_DP0 pid=346998) 	add.s32 	%r27, %r24, %r26;
(EngineCore_DP0 pid=346998) 	shr.s32 	%r28, %r27, 2;
(EngineCore_DP0 pid=346998) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=346998) 	mul.lo.s32 	%r29, %r28, %r1;
(EngineCore_DP0 pid=346998) 	mad.wide.s32 	%rd2, %r29, 4, %rd5;
(EngineCore_DP0 pid=346998) 	div.full.f32 	%r14, %r79, %r125;
(EngineCore_DP0 pid=346998) 	mov.b32 	%r126, 0;
(EngineCore_DP0 pid=346998) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=346998)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=346998) 	.loc	1 203 30                        // quant_slide_tuned_Llama3.2-1B.py:203:30
(EngineCore_DP0 pid=346998) 	add.s32 	%r92, %r3, %r126;
(EngineCore_DP0 pid=346998) 	setp.lt.s32 	%p14, %r92, %r15;
(EngineCore_DP0 pid=346998) 	.loc	1 206 24                        // quant_slide_tuned_Llama3.2-1B.py:206:24
(EngineCore_DP0 pid=346998) 	shr.s32 	%r93, %r92, 31;
(EngineCore_DP0 pid=346998) 	shr.u32 	%r94, %r93, 30;
(EngineCore_DP0 pid=346998) 	add.s32 	%r95, %r92, %r94;
(EngineCore_DP0 pid=346998) 	shr.s32 	%r96, %r95, 2;
(EngineCore_DP0 pid=346998) 	.loc	1 207 23                        // quant_slide_tuned_Llama3.2-1B.py:207:23
(EngineCore_DP0 pid=346998) 	and.b32 	%r97, %r95, 2147483644;
(EngineCore_DP0 pid=346998) 	sub.s32 	%r98, %r92, %r97;
(EngineCore_DP0 pid=346998) 	.loc	1 208 30                        // quant_slide_tuned_Llama3.2-1B.py:208:30
(EngineCore_DP0 pid=346998) 	shl.b32 	%r99, %r98, 1;
(EngineCore_DP0 pid=346998) 	.loc	1 208 26                        // quant_slide_tuned_Llama3.2-1B.py:208:26
(EngineCore_DP0 pid=346998) 	mad.lo.s32 	%r100, %r96, 10, %r99;
(EngineCore_DP0 pid=346998) 	.loc	1 211 53                        // quant_slide_tuned_Llama3.2-1B.py:211:53
(EngineCore_DP0 pid=346998) 	setp.lt.s32 	%p15, %r100, %r18;
(EngineCore_DP0 pid=346998) 	.loc	1 211 37                        // quant_slide_tuned_Llama3.2-1B.py:211:37
(EngineCore_DP0 pid=346998) 	and.pred 	%p10, %p14, %p15;
(EngineCore_DP0 pid=346998) 	.loc	1 210 29                        // quant_slide_tuned_Llama3.2-1B.py:210:29
(EngineCore_DP0 pid=346998) 	mad.wide.s32 	%rd9, %r100, 2, %rd1;
(EngineCore_DP0 pid=346998) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=346998) 	.loc	1 210 21                        // quant_slide_tuned_Llama3.2-1B.py:210:21
(EngineCore_DP0 pid=346998) 	// begin inline asm
(EngineCore_DP0 pid=346998) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=346998) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=346998) 	// end inline asm
(EngineCore_DP0 pid=346998) 	.loc	1 211 79                        // quant_slide_tuned_Llama3.2-1B.py:211:79
(EngineCore_DP0 pid=346998) 	cvt.f32.bf16 	%r101, %rs48;
(EngineCore_DP0 pid=346998) 	.loc	1 213 48                        // quant_slide_tuned_Llama3.2-1B.py:213:48
(EngineCore_DP0 pid=346998) 	or.b32 	%r102, %r100, 1;
(EngineCore_DP0 pid=346998) 	.loc	1 213 53                        // quant_slide_tuned_Llama3.2-1B.py:213:53
(EngineCore_DP0 pid=346998) 	setp.lt.s32 	%p16, %r102, %r18;
(EngineCore_DP0 pid=346998) 	.loc	1 213 37                        // quant_slide_tuned_Llama3.2-1B.py:213:37
(EngineCore_DP0 pid=346998) 	and.pred 	%p11, %p14, %p16;
(EngineCore_DP0 pid=346998) 	.loc	1 212 39                        // quant_slide_tuned_Llama3.2-1B.py:212:39
(EngineCore_DP0 pid=346998) 	add.s64 	%rd10, %rd9, 2;
(EngineCore_DP0 pid=346998) 	.loc	1 212 21                        // quant_slide_tuned_Llama3.2-1B.py:212:21
(EngineCore_DP0 pid=346998) 	// begin inline asm
(EngineCore_DP0 pid=346998) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=346998) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=346998) 	// end inline asm
(EngineCore_DP0 pid=346998) 	.loc	1 213 79                        // quant_slide_tuned_Llama3.2-1B.py:213:79
(EngineCore_DP0 pid=346998) 	cvt.f32.bf16 	%r103, %rs50;
(EngineCore_DP0 pid=346998) 	.loc	1 215 48                        // quant_slide_tuned_Llama3.2-1B.py:215:48
(EngineCore_DP0 pid=346998) 	add.s32 	%r104, %r100, 2;
(EngineCore_DP0 pid=346998) 	.loc	1 215 53                        // quant_slide_tuned_Llama3.2-1B.py:215:53
(EngineCore_DP0 pid=346998) 	setp.lt.s32 	%p17, %r104, %r18;
(EngineCore_DP0 pid=346998) 	.loc	1 215 37                        // quant_slide_tuned_Llama3.2-1B.py:215:37
(EngineCore_DP0 pid=346998) 	and.pred 	%p12, %p14, %p17;
(EngineCore_DP0 pid=346998) 	.loc	1 214 39                        // quant_slide_tuned_Llama3.2-1B.py:214:39
(EngineCore_DP0 pid=346998) 	add.s64 	%rd11, %rd9, 4;
(EngineCore_DP0 pid=346998) 	.loc	1 214 21                        // quant_slide_tuned_Llama3.2-1B.py:214:21
(EngineCore_DP0 pid=346998) 	// begin inline asm
(EngineCore_DP0 pid=346998) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=346998) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=346998) 	// end inline asm
(EngineCore_DP0 pid=346998) 	.loc	1 215 79                        // quant_slide_tuned_Llama3.2-1B.py:215:79
(EngineCore_DP0 pid=346998) 	cvt.f32.bf16 	%r105, %rs52;
(EngineCore_DP0 pid=346998) 	.loc	1 217 48                        // quant_slide_tuned_Llama3.2-1B.py:217:48
(EngineCore_DP0 pid=346998) 	add.s32 	%r106, %r100, 3;
(EngineCore_DP0 pid=346998) 	.loc	1 217 53                        // quant_slide_tuned_Llama3.2-1B.py:217:53
(EngineCore_DP0 pid=346998) 	setp.lt.s32 	%p18, %r106, %r18;
(EngineCore_DP0 pid=346998) 	.loc	1 217 37                        // quant_slide_tuned_Llama3.2-1B.py:217:37
(EngineCore_DP0 pid=346998) 	and.pred 	%p13, %p14, %p18;
(EngineCore_DP0 pid=346998) 	.loc	1 216 39                        // quant_slide_tuned_Llama3.2-1B.py:216:39
(EngineCore_DP0 pid=346998) 	add.s64 	%rd12, %rd9, 6;
(EngineCore_DP0 pid=346998) 	.loc	1 216 21                        // quant_slide_tuned_Llama3.2-1B.py:216:21
(EngineCore_DP0 pid=346998) 	// begin inline asm
(EngineCore_DP0 pid=346998) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=346998) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=346998) 	// end inline asm
(EngineCore_DP0 pid=346998) 	.loc	1 217 79                        // quant_slide_tuned_Llama3.2-1B.py:217:79
(EngineCore_DP0 pid=346998) 	cvt.f32.bf16 	%r107, %rs54;
(EngineCore_DP0 pid=346998) 	.loc	1 219 27                        // quant_slide_tuned_Llama3.2-1B.py:219:27
(EngineCore_DP0 pid=346998) 	mul.f32 	%r108, %r14, %r101;
(EngineCore_DP0 pid=346998) 	mov.b32 	%r109, 0f43E00000;
(EngineCore_DP0 pid=346998) 	.loc	1 219 48                        // quant_slide_tuned_Llama3.2-1B.py:219:48
(EngineCore_DP0 pid=346998) 	min.xorsign.abs.f32 	%r82, %r108, %r109;
(EngineCore_DP0 pid=346998) 	.loc	1 219 60                        // quant_slide_tuned_Llama3.2-1B.py:219:60
(EngineCore_DP0 pid=346998) 	// begin inline asm
(EngineCore_DP0 pid=346998) 	cvt.rn.satfinite.e4m3x2.f32  %rs56, %r83, %r82; 
(EngineCore_DP0 pid=346998) 
(EngineCore_DP0 pid=346998) 	// end inline asm
(EngineCore_DP0 pid=346998) 	.loc	1 220 27                        // quant_slide_tuned_Llama3.2-1B.py:220:27
(EngineCore_DP0 pid=346998) 	mul.f32 	%r110, %r14, %r103;
(EngineCore_DP0 pid=346998) 	.loc	1 220 48                        // quant_slide_tuned_Llama3.2-1B.py:220:48
(EngineCore_DP0 pid=346998) 	min.xorsign.abs.f32 	%r84, %r110, %r109;
(EngineCore_DP0 pid=346998) 	.loc	1 220 60                        // quant_slide_tuned_Llama3.2-1B.py:220:60
(EngineCore_DP0 pid=346998) 	// begin inline asm
(EngineCore_DP0 pid=346998) 	cvt.rn.satfinite.e4m3x2.f32  %rs57, %r85, %r84; 
(EngineCore_DP0 pid=346998) 
(EngineCore_DP0 pid=346998) 	// end inline asm
(EngineCore_DP0 pid=346998) 	.loc	1 221 27                        // quant_slide_tuned_Llama3.2-1B.py:221:27
(EngineCore_DP0 pid=346998) 	mul.f32 	%r111, %r14, %r105;
(EngineCore_DP0 pid=346998) 	.loc	1 221 48                        // quant_slide_tuned_Llama3.2-1B.py:221:48
(EngineCore_DP0 pid=346998) 	min.xorsign.abs.f32 	%r86, %r111, %r109;
(EngineCore_DP0 pid=346998) 	.loc	1 221 60                        // quant_slide_tuned_Llama3.2-1B.py:221:60
(EngineCore_DP0 pid=346998) 	// begin inline asm
(EngineCore_DP0 pid=346998) 	cvt.rn.satfinite.e4m3x2.f32  %rs58, %r87, %r86; 
(EngineCore_DP0 pid=346998) 
(EngineCore_DP0 pid=346998) 	// end inline asm
(EngineCore_DP0 pid=346998) 	.loc	1 222 27                        // quant_slide_tuned_Llama3.2-1B.py:222:27
(EngineCore_DP0 pid=346998) 	mul.f32 	%r112, %r14, %r107;
(EngineCore_DP0 pid=346998) 	.loc	1 222 48                        // quant_slide_tuned_Llama3.2-1B.py:222:48
(EngineCore_DP0 pid=346998) 	min.xorsign.abs.f32 	%r88, %r112, %r109;
(EngineCore_DP0 pid=346998) 	.loc	1 222 60                        // quant_slide_tuned_Llama3.2-1B.py:222:60
(EngineCore_DP0 pid=346998) 	// begin inline asm
(EngineCore_DP0 pid=346998) 	cvt.rn.satfinite.e4m3x2.f32  %rs59, %r89, %r88; 
(EngineCore_DP0 pid=346998) 
(EngineCore_DP0 pid=346998) 	// end inline asm
(EngineCore_DP0 pid=346998) 	.loc	1 224 45                        // quant_slide_tuned_Llama3.2-1B.py:224:45
(EngineCore_DP0 pid=346998) 	cvt.u32.u16 	%r113, %rs56;
(EngineCore_DP0 pid=346998) 	and.b32 	%r114, %r113, 255;
(EngineCore_DP0 pid=346998) 	.loc	1 226 45                        // quant_slide_tuned_Llama3.2-1B.py:226:45
(EngineCore_DP0 pid=346998) 	cvt.u32.u16 	%r115, %rs58;
(EngineCore_DP0 pid=346998) 	and.b32 	%r116, %r115, 255;
(EngineCore_DP0 pid=346998) 	.loc	1 227 45                        // quant_slide_tuned_Llama3.2-1B.py:227:45
(EngineCore_DP0 pid=346998) 	cvt.u32.u16 	%r117, %rs59;
(EngineCore_DP0 pid=346998) 	.loc	1 229 30                        // quant_slide_tuned_Llama3.2-1B.py:229:30
(EngineCore_DP0 pid=346998) 	and.b16 	%rs60, %rs57, 255;
(EngineCore_DP0 pid=346998) 	mul.wide.u16 	%r118, %rs60, 256;
(EngineCore_DP0 pid=346998) 	.loc	1 229 24                        // quant_slide_tuned_Llama3.2-1B.py:229:24
(EngineCore_DP0 pid=346998) 	or.b32 	%r119, %r118, %r114;
(EngineCore_DP0 pid=346998) 	.loc	1 229 42                        // quant_slide_tuned_Llama3.2-1B.py:229:42
(EngineCore_DP0 pid=346998) 	shl.b32 	%r120, %r116, 16;
(EngineCore_DP0 pid=346998) 	.loc	1 229 36                        // quant_slide_tuned_Llama3.2-1B.py:229:36
(EngineCore_DP0 pid=346998) 	or.b32 	%r121, %r119, %r120;
(EngineCore_DP0 pid=346998) 	.loc	1 229 55                        // quant_slide_tuned_Llama3.2-1B.py:229:55
(EngineCore_DP0 pid=346998) 	shl.b32 	%r122, %r117, 24;
(EngineCore_DP0 pid=346998) 	.loc	1 229 49                        // quant_slide_tuned_Llama3.2-1B.py:229:49
(EngineCore_DP0 pid=346998) 	or.b32 	%r90, %r121, %r122;
(EngineCore_DP0 pid=346998) 	.loc	1 230 29                        // quant_slide_tuned_Llama3.2-1B.py:230:29
(EngineCore_DP0 pid=346998) 	mad.wide.s32 	%rd13, %r92, 4, %rd2;
(EngineCore_DP0 pid=346998) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-1B.py:230:39
(EngineCore_DP0 pid=346998) 	// begin inline asm
(EngineCore_DP0 pid=346998) 	@%p14 st.global.b32 [ %rd13 + 0 ], { %r90 };
(EngineCore_DP0 pid=346998) 	// end inline asm
(EngineCore_DP0 pid=346998) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=346998) 	add.s32 	%r126, %r126, 512;
(EngineCore_DP0 pid=346998) 	setp.lt.s32 	%p19, %r126, %r15;
(EngineCore_DP0 pid=346998) 	@%p19 bra 	$L__BB0_6;
(EngineCore_DP0 pid=346998) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=346998) 	.loc	1 201 4                         // quant_slide_tuned_Llama3.2-1B.py:201:4
(EngineCore_DP0 pid=346998) 	ret;
(EngineCore_DP0 pid=346998) $L__tmp3:
(EngineCore_DP0 pid=346998) $L__func_end0:
(EngineCore_DP0 pid=346998)                                         // -- End function
(EngineCore_DP0 pid=346998) }
(EngineCore_DP0 pid=346998) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=346998) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=346998) 	.section	.debug_abbrev
(EngineCore_DP0 pid=346998) 	{
(EngineCore_DP0 pid=346998) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=346998) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=346998) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=346998) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=346998) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=346998) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=346998) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=346998) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=346998) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=346998) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=346998) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=346998) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=346998) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=346998) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=346998) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=346998) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=346998) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=346998) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=346998) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=346998) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=346998) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=346998) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=346998) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=346998) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=346998) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=346998) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=346998) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=346998) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=346998) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=346998) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=346998) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=346998) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=346998) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=346998) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=346998) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=346998) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=346998) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=346998) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=346998) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=346998) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=346998) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=346998) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=346998) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=346998) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=346998) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=346998) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=346998) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=346998) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=346998) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=346998) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=346998) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=346998) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=346998) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=346998) 	}
(EngineCore_DP0 pid=346998) 	.section	.debug_info
(EngineCore_DP0 pid=346998) 	{
(EngineCore_DP0 pid=346998) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=346998) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=346998) .b8 0
(EngineCore_DP0 pid=346998) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=346998) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=346998) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=346998) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=346998) .b8 114
(EngineCore_DP0 pid=346998) .b8 105
(EngineCore_DP0 pid=346998) .b8 116
(EngineCore_DP0 pid=346998) .b8 111
(EngineCore_DP0 pid=346998) .b8 110
(EngineCore_DP0 pid=346998) .b8 0
(EngineCore_DP0 pid=346998) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=346998) .b8 0
(EngineCore_DP0 pid=346998) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=346998) .b8 117
(EngineCore_DP0 pid=346998) .b8 97
(EngineCore_DP0 pid=346998) .b8 110
(EngineCore_DP0 pid=346998) .b8 116
(EngineCore_DP0 pid=346998) .b8 95
(EngineCore_DP0 pid=346998) .b8 115
(EngineCore_DP0 pid=346998) .b8 108
(EngineCore_DP0 pid=346998) .b8 105
(EngineCore_DP0 pid=346998) .b8 100
(EngineCore_DP0 pid=346998) .b8 101
(EngineCore_DP0 pid=346998) .b8 95
(EngineCore_DP0 pid=346998) .b8 116
(EngineCore_DP0 pid=346998) .b8 117
(EngineCore_DP0 pid=346998) .b8 110
(EngineCore_DP0 pid=346998) .b8 101
(EngineCore_DP0 pid=346998) .b8 100
(EngineCore_DP0 pid=346998) .b8 95
(EngineCore_DP0 pid=346998) .b8 76
(EngineCore_DP0 pid=346998) .b8 108
(EngineCore_DP0 pid=346998) .b8 97
(EngineCore_DP0 pid=346998) .b8 109
(EngineCore_DP0 pid=346998) .b8 97
(EngineCore_DP0 pid=346998) .b8 51
(EngineCore_DP0 pid=346998) .b8 46
(EngineCore_DP0 pid=346998) .b8 50
(EngineCore_DP0 pid=346998) .b8 45
(EngineCore_DP0 pid=346998) .b8 49
(EngineCore_DP0 pid=346998) .b8 66
(EngineCore_DP0 pid=346998) .b8 46
(EngineCore_DP0 pid=346998) .b8 112
(EngineCore_DP0 pid=346998) .b8 121
(EngineCore_DP0 pid=346998) .b8 0
(EngineCore_DP0 pid=346998) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=346998) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=346998) .b8 114
(EngineCore_DP0 pid=346998) .b8 111
(EngineCore_DP0 pid=346998) .b8 111
(EngineCore_DP0 pid=346998) .b8 116
(EngineCore_DP0 pid=346998) .b8 47
(EngineCore_DP0 pid=346998) .b8 118
(EngineCore_DP0 pid=346998) .b8 108
(EngineCore_DP0 pid=346998) .b8 108
(EngineCore_DP0 pid=346998) .b8 109
(EngineCore_DP0 pid=346998) .b8 98
(EngineCore_DP0 pid=346998) .b8 101
(EngineCore_DP0 pid=346998) .b8 110
(EngineCore_DP0 pid=346998) .b8 99
(EngineCore_DP0 pid=346998) .b8 104
(EngineCore_DP0 pid=346998) .b8 47
(EngineCore_DP0 pid=346998) .b8 115
(EngineCore_DP0 pid=346998) .b8 108
(EngineCore_DP0 pid=346998) .b8 105
(EngineCore_DP0 pid=346998) .b8 100
(EngineCore_DP0 pid=346998) .b8 101
(EngineCore_DP0 pid=346998) .b8 115
(EngineCore_DP0 pid=346998) .b8 112
(EngineCore_DP0 pid=346998) .b8 97
(EngineCore_DP0 pid=346998) .b8 114
(EngineCore_DP0 pid=346998) .b8 115
(EngineCore_DP0 pid=346998) .b8 101
(EngineCore_DP0 pid=346998) .b8 47
(EngineCore_DP0 pid=346998) .b8 99
(EngineCore_DP0 pid=346998) .b8 115
(EngineCore_DP0 pid=346998) .b8 114
(EngineCore_DP0 pid=346998) .b8 99
(EngineCore_DP0 pid=346998) .b8 47
(EngineCore_DP0 pid=346998) .b8 102
(EngineCore_DP0 pid=346998) .b8 117
(EngineCore_DP0 pid=346998) .b8 115
(EngineCore_DP0 pid=346998) .b8 101
(EngineCore_DP0 pid=346998) .b8 100
(EngineCore_DP0 pid=346998) .b8 95
(EngineCore_DP0 pid=346998) .b8 113
(EngineCore_DP0 pid=346998) .b8 117
(EngineCore_DP0 pid=346998) .b8 97
(EngineCore_DP0 pid=346998) .b8 110
(EngineCore_DP0 pid=346998) .b8 116
(EngineCore_DP0 pid=346998) .b8 95
(EngineCore_DP0 pid=346998) .b8 115
(EngineCore_DP0 pid=346998) .b8 108
(EngineCore_DP0 pid=346998) .b8 105
(EngineCore_DP0 pid=346998) .b8 100
(EngineCore_DP0 pid=346998) .b8 101
(EngineCore_DP0 pid=346998) .b8 95
(EngineCore_DP0 pid=346998) .b8 116
(EngineCore_DP0 pid=346998) .b8 114
(EngineCore_DP0 pid=346998) .b8 105
(EngineCore_DP0 pid=346998) .b8 116
(EngineCore_DP0 pid=346998) .b8 111
(EngineCore_DP0 pid=346998) .b8 110
(EngineCore_DP0 pid=346998) .b8 47
(EngineCore_DP0 pid=346998) .b8 98
(EngineCore_DP0 pid=346998) .b8 117
(EngineCore_DP0 pid=346998) .b8 105
(EngineCore_DP0 pid=346998) .b8 108
(EngineCore_DP0 pid=346998) .b8 100
(EngineCore_DP0 pid=346998) .b8 47
(EngineCore_DP0 pid=346998) .b8 71
(EngineCore_DP0 pid=346998) .b8 66
(EngineCore_DP0 pid=346998) .b8 49
(EngineCore_DP0 pid=346998) .b8 48
(EngineCore_DP0 pid=346998) .b8 95
(EngineCore_DP0 pid=346998) .b8 99
(EngineCore_DP0 pid=346998) .b8 99
(EngineCore_DP0 pid=346998) .b8 49
(EngineCore_DP0 pid=346998) .b8 50
(EngineCore_DP0 pid=346998) .b8 49
(EngineCore_DP0 pid=346998) .b8 95
(EngineCore_DP0 pid=346998) .b8 112
(EngineCore_DP0 pid=346998) .b8 121
(EngineCore_DP0 pid=346998) .b8 51
(EngineCore_DP0 pid=346998) .b8 49
(EngineCore_DP0 pid=346998) .b8 50
(EngineCore_DP0 pid=346998) .b8 95
(EngineCore_DP0 pid=346998) .b8 99
(EngineCore_DP0 pid=346998) .b8 117
(EngineCore_DP0 pid=346998) .b8 49
(EngineCore_DP0 pid=346998) .b8 50
(EngineCore_DP0 pid=346998) .b8 57
(EngineCore_DP0 pid=346998) .b8 95
(EngineCore_DP0 pid=346998) .b8 97
(EngineCore_DP0 pid=346998) .b8 97
(EngineCore_DP0 pid=346998) .b8 114
(EngineCore_DP0 pid=346998) .b8 99
(EngineCore_DP0 pid=346998) .b8 104
(EngineCore_DP0 pid=346998) .b8 54
(EngineCore_DP0 pid=346998) .b8 52
(EngineCore_DP0 pid=346998) .b8 0
(EngineCore_DP0 pid=346998) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=346998) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=346998) .b8 113
(EngineCore_DP0 pid=346998) .b8 117
(EngineCore_DP0 pid=346998) .b8 97
(EngineCore_DP0 pid=346998) .b8 110
(EngineCore_DP0 pid=346998) .b8 116
(EngineCore_DP0 pid=346998) .b8 95
(EngineCore_DP0 pid=346998) .b8 115
(EngineCore_DP0 pid=346998) .b8 108
(EngineCore_DP0 pid=346998) .b8 105
(EngineCore_DP0 pid=346998) .b8 100
(EngineCore_DP0 pid=346998) .b8 101
(EngineCore_DP0 pid=346998) .b8 95
(EngineCore_DP0 pid=346998) .b8 102
(EngineCore_DP0 pid=346998) .b8 112
(EngineCore_DP0 pid=346998) .b8 56
(EngineCore_DP0 pid=346998) .b8 95
(EngineCore_DP0 pid=346998) .b8 107
(EngineCore_DP0 pid=346998) .b8 101
(EngineCore_DP0 pid=346998) .b8 114
(EngineCore_DP0 pid=346998) .b8 110
(EngineCore_DP0 pid=346998) .b8 101
(EngineCore_DP0 pid=346998) .b8 108
(EngineCore_DP0 pid=346998) .b8 0
(EngineCore_DP0 pid=346998) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=346998) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=346998) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=346998) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=346998) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=346998) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=346998) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=346998) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=346998) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=346998) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=346998) .b8 191                                 // DW_AT_call_line
(EngineCore_DP0 pid=346998) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=346998) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=346998) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=346998) 	}
(EngineCore_DP0 pid=346998) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=346998) 
(EngineCore_DP0 pid=346998) ================================================================
(EngineCore_DP0 pid=346998) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=346998) 
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpklq06np0.ptx', '-o', '/tmp/tmpklq06np0.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866] 
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866] 
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866] 
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpklq06np0.ptx -o /tmp/tmpklq06np0.ptx.o
(EngineCore_DP0 pid=346998) ERROR 01-25 19:24:29 [core.py:866] 

STDERR:
[2026-01-25 19:24:12] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:24:12] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:24:12] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:24:12] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:24:12] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:24:12] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:24:12] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:24:12] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:24:12] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:24:12] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:24:12] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:24:12] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:24:12] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:24:12] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:24:16] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:24:16] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:24:16] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:24:16] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:24:16] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:24:16] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:24:16] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:24:16] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:24:16] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:24:16] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:24:16] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:24:16] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:24:16] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:24:16] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=346998) [2026-01-25 19:24:17] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=346998) [2026-01-25 19:24:17] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=346998) [2026-01-25 19:24:17] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=346998) [2026-01-25 19:24:17] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=346998) [2026-01-25 19:24:17] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=346998) [2026-01-25 19:24:17] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=346998) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=346998) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.91s/it]
(EngineCore_DP0 pid=346998) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.91s/it]
(EngineCore_DP0 pid=346998) 
(EngineCore_DP0 pid=346998) [2026-01-25 19:24:28] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=346998) [2026-01-25 19:24:28] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6340608 bytes
(EngineCore_DP0 pid=346998) [2026-01-25 19:24:28] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=346998) [2026-01-25 19:24:28] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 4227072 bytes
(EngineCore_DP0 pid=346998) [2026-01-25 19:24:28] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=346998) [2026-01-25 19:24:28] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 33816576 bytes
(EngineCore_DP0 pid=346998) [2026-01-25 19:24:28] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=346998) [2026-01-25 19:24:28] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16809984 bytes
(EngineCore_DP0 pid=346998) Process EngineCore_DP0:
(EngineCore_DP0 pid=346998) Traceback (most recent call last):
(EngineCore_DP0 pid=346998)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=346998)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=346998)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=346998)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=346998) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpklq06np0.ptx', '-o', '/tmp/tmpklq06np0.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=346998) 
(EngineCore_DP0 pid=346998) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=346998) 
(EngineCore_DP0 pid=346998) Traceback (most recent call last):
(EngineCore_DP0 pid=346998)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=346998)     self.run()
(EngineCore_DP0 pid=346998)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=346998)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=346998)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=346998)     raise e
(EngineCore_DP0 pid=346998)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=346998)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=346998)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=346998)     super().__init__(
(EngineCore_DP0 pid=346998)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=346998)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=346998)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=346998)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=346998)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=346998)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=346998)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=346998)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=346998)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=346998)     return func(*args, **kwargs)
(EngineCore_DP0 pid=346998)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=346998)     return func(*args, **kwargs)
(EngineCore_DP0 pid=346998)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=346998)     self.model_runner.profile_run()
(EngineCore_DP0 pid=346998)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=346998)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=346998)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=346998)     return func(*args, **kwargs)
(EngineCore_DP0 pid=346998)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=346998)     outputs = self.model(
(EngineCore_DP0 pid=346998)               ^^^^^^^^^^^
(EngineCore_DP0 pid=346998)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=346998)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=346998)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=346998)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=346998)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=346998)     model_output = self.model(
(EngineCore_DP0 pid=346998)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=346998)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=346998)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=346998)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=346998)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=346998)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=346998)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=346998)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=346998)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=346998)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=346998)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=346998)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=346998)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=346998)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=346998)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=346998)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=346998)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=346998)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=346998)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=346998)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=346998)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=346998)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=346998)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=346998)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=346998)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=346998)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=346998)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=346998)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=346998)     return self._linear_fn(
(EngineCore_DP0 pid=346998)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=346998)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=346998)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=346998)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=346998)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=346998)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=346998)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=346998)     return fn(input, L)
(EngineCore_DP0 pid=346998)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=346998)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=346998)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=346998)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=346998)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=346998)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=346998)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=346998)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=346998)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=346998)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=346998)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=346998)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=346998)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=346998)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=346998)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=346998)     raise PTXASError(error)
(EngineCore_DP0 pid=346998) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=346998) `ptxas` stderr:
(EngineCore_DP0 pid=346998) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=346998) 
(EngineCore_DP0 pid=346998) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpklq06np0.ptx -o /tmp/tmpklq06np0.ptx.o
(EngineCore_DP0 pid=346998) 
[rank0]:[W125 19:24:29.034243466 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=1024

========== M=2048 ==========
Time: 2026-01-25 19:24:31
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-1B-FP8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:24:35 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:24:35 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=347488) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=347488) 
(EngineCore_DP0 pid=347488) 
(EngineCore_DP0 pid=347488) ================================================================
(EngineCore_DP0 pid=347488) Internal Triton PTX codegen error
(EngineCore_DP0 pid=347488) `ptxas` stderr:
(EngineCore_DP0 pid=347488) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=347488) 
(EngineCore_DP0 pid=347488) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmprzoyjcd4.ptx -o /tmp/tmprzoyjcd4.ptx.o
(EngineCore_DP0 pid=347488) 
(EngineCore_DP0 pid=347488) 
(EngineCore_DP0 pid=347488) //
(EngineCore_DP0 pid=347488) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=347488) //
(EngineCore_DP0 pid=347488) 
(EngineCore_DP0 pid=347488) .version 8.7
(EngineCore_DP0 pid=347488) .target sm_121a
(EngineCore_DP0 pid=347488) .address_size 64
(EngineCore_DP0 pid=347488) 
(EngineCore_DP0 pid=347488) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=347488) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=347488)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=347488) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=347488) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=347488) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=347488) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=347488) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=347488) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=347488) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=347488) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=347488) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=347488) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=347488) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=347488) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=347488) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=347488) )
(EngineCore_DP0 pid=347488) .reqntid 512
(EngineCore_DP0 pid=347488) {
(EngineCore_DP0 pid=347488) 	.reg .pred 	%p<21>;
(EngineCore_DP0 pid=347488) 	.reg .b16 	%rs<61>;
(EngineCore_DP0 pid=347488) 	.reg .b32 	%r<127>;
(EngineCore_DP0 pid=347488) 	.reg .b64 	%rd<14>;
(EngineCore_DP0 pid=347488) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=347488) $L__func_begin0:
(EngineCore_DP0 pid=347488) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=347488) 
(EngineCore_DP0 pid=347488) // %bb.0:
(EngineCore_DP0 pid=347488) 	ld.param.b32 	%r20, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=347488) 	ld.param.b32 	%r19, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=347488) 	ld.param.b32 	%r18, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=347488) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=347488) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=347488) $L__tmp0:
(EngineCore_DP0 pid=347488) 	.loc	1 177 24                        // quant_slide_tuned_Llama3.2-1B.py:177:24
(EngineCore_DP0 pid=347488) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=347488) 	ld.param.b32 	%r22, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=347488) 	.loc	1 182 26                        // quant_slide_tuned_Llama3.2-1B.py:182:26
(EngineCore_DP0 pid=347488) 	mul.lo.s32 	%r23, %r22, %r1;
(EngineCore_DP0 pid=347488) 	.loc	1 182 20                        // quant_slide_tuned_Llama3.2-1B.py:182:20
(EngineCore_DP0 pid=347488) 	mad.wide.s32 	%rd1, %r23, 2, %rd4;
(EngineCore_DP0 pid=347488) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=347488) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=347488) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=347488) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=347488) 	setp.lt.s32 	%p1, %r19, 1;
(EngineCore_DP0 pid=347488) 	mov.b32 	%r125, 0f2B8CBCCC;
(EngineCore_DP0 pid=347488) 	setp.eq.b32 	%p20, %r2, 0;
(EngineCore_DP0 pid=347488) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=347488) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=347488) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=347488) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=347488) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=347488) 	shr.u32 	%r32, %r2, 3;
(EngineCore_DP0 pid=347488) 	and.b32 	%r33, %r32, 60;
(EngineCore_DP0 pid=347488) 	mov.b32 	%r34, global_smem;
(EngineCore_DP0 pid=347488) 	add.s32 	%r52, %r34, %r33;
(EngineCore_DP0 pid=347488) 	shl.b32 	%r35, %r2, 2;
(EngineCore_DP0 pid=347488) 	add.s32 	%r55, %r34, %r35;
(EngineCore_DP0 pid=347488) 	mov.b32 	%r40, 0;
(EngineCore_DP0 pid=347488) 	mov.b32 	%r123, 0f00000000;
(EngineCore_DP0 pid=347488) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=347488) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=347488) 	mov.b32 	%r124, %r40;
(EngineCore_DP0 pid=347488) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=347488) 	.loc	1 188 19                        // quant_slide_tuned_Llama3.2-1B.py:188:19
(EngineCore_DP0 pid=347488) 	add.s32 	%r58, %r4, %r124;
(EngineCore_DP0 pid=347488) 	.loc	1 189 22                        // quant_slide_tuned_Llama3.2-1B.py:189:22
(EngineCore_DP0 pid=347488) 	add.s32 	%r59, %r58, 4096;
(EngineCore_DP0 pid=347488) 	setp.lt.s32 	%p2, %r58, %r18;
(EngineCore_DP0 pid=347488) 	setp.lt.s32 	%p3, %r59, %r18;
(EngineCore_DP0 pid=347488) 	.loc	1 190 29                        // quant_slide_tuned_Llama3.2-1B.py:190:29
(EngineCore_DP0 pid=347488) 	mad.wide.s32 	%rd6, %r58, 2, %rd1;
(EngineCore_DP0 pid=347488) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=347488) 	.loc	1 190 21                        // quant_slide_tuned_Llama3.2-1B.py:190:21
(EngineCore_DP0 pid=347488) 	// begin inline asm
(EngineCore_DP0 pid=347488) 	mov.u32 %r36, %r40;
(EngineCore_DP0 pid=347488) 	mov.u32 %r37, %r40;
(EngineCore_DP0 pid=347488) 	mov.u32 %r38, %r40;
(EngineCore_DP0 pid=347488) 	mov.u32 %r39, %r40;
(EngineCore_DP0 pid=347488) 	@%p2 ld.global.v4.b32 { %r36, %r37, %r38, %r39 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=347488) 	// end inline asm
(EngineCore_DP0 pid=347488) 	mov.b32 	{%rs1, %rs2}, %r36;
(EngineCore_DP0 pid=347488) 	mov.b32 	{%rs3, %rs4}, %r37;
(EngineCore_DP0 pid=347488) 	mov.b32 	{%rs5, %rs6}, %r38;
(EngineCore_DP0 pid=347488) 	mov.b32 	{%rs7, %rs8}, %r39;
(EngineCore_DP0 pid=347488) 	// begin inline asm
(EngineCore_DP0 pid=347488) 	mov.u32 %r44, %r40;
(EngineCore_DP0 pid=347488) 	mov.u32 %r45, %r40;
(EngineCore_DP0 pid=347488) 	mov.u32 %r46, %r40;
(EngineCore_DP0 pid=347488) 	mov.u32 %r47, %r40;
(EngineCore_DP0 pid=347488) 	@%p3 ld.global.v4.b32 { %r44, %r45, %r46, %r47 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=347488) 	// end inline asm
(EngineCore_DP0 pid=347488) 	mov.b32 	{%rs9, %rs10}, %r44;
(EngineCore_DP0 pid=347488) 	mov.b32 	{%rs11, %rs12}, %r45;
(EngineCore_DP0 pid=347488) 	mov.b32 	{%rs13, %rs14}, %r46;
(EngineCore_DP0 pid=347488) 	mov.b32 	{%rs15, %rs16}, %r47;
(EngineCore_DP0 pid=347488) 	.loc	1 191 50                        // quant_slide_tuned_Llama3.2-1B.py:191:50
(EngineCore_DP0 pid=347488) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=347488) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=347488) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=347488) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=347488) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=347488) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=347488) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=347488) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=347488) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=347488) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=347488) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=347488) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=347488) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=347488) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=347488) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=347488) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=347488) $L__tmp1:
(EngineCore_DP0 pid=347488) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=347488) 	bar.sync 	0;
(EngineCore_DP0 pid=347488) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=347488) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=347488) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=347488) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=347488) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=347488) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=347488) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=347488) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=347488) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=347488) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=347488) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=347488) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=347488) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=347488) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=347488) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=347488) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=347488) 	cvt.f32.bf16 	%r60, %rs47;
(EngineCore_DP0 pid=347488) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=347488) 	shfl.sync.bfly.b32 	%r61, %r60, 16, 31, -1;
(EngineCore_DP0 pid=347488) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=347488) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=347488) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=347488) 	shfl.sync.bfly.b32 	%r63, %r62, 8, 31, -1;
(EngineCore_DP0 pid=347488) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=347488) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=347488) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=347488) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=347488) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=347488) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=347488) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=347488) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=347488) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=347488) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=347488) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=347488) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=347488) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=347488) 	max.f32 	%r53, %r68, %r69;
(EngineCore_DP0 pid=347488) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=347488) 	// begin inline asm
(EngineCore_DP0 pid=347488) 	@%p4 st.shared.b32 [ %r52 + 0 ], %r53;
(EngineCore_DP0 pid=347488) 	// end inline asm
(EngineCore_DP0 pid=347488) 	bar.sync 	0;
(EngineCore_DP0 pid=347488) 	// begin inline asm
(EngineCore_DP0 pid=347488) 	@%p5 ld.shared.b32 %r54, [ %r55 + 0 ];
(EngineCore_DP0 pid=347488) 	// end inline asm
(EngineCore_DP0 pid=347488) 	shfl.sync.bfly.b32 	%r70, %r54, 8, 31, -1;
(EngineCore_DP0 pid=347488) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=347488) 	max.f32 	%r71, %r54, %r70;
(EngineCore_DP0 pid=347488) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=347488) 	shfl.sync.bfly.b32 	%r72, %r71, 4, 31, -1;
(EngineCore_DP0 pid=347488) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=347488) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=347488) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=347488) 	shfl.sync.bfly.b32 	%r74, %r73, 2, 31, -1;
(EngineCore_DP0 pid=347488) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=347488) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=347488) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=347488) 	shfl.sync.bfly.b32 	%r76, %r75, 1, 31, -1;
(EngineCore_DP0 pid=347488) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=347488) 	max.f32 	%r57, %r75, %r76;
(EngineCore_DP0 pid=347488) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=347488) 	// begin inline asm
(EngineCore_DP0 pid=347488) 	@%p20 st.shared.b32 [ %r55 + 0 ], %r57;
(EngineCore_DP0 pid=347488) 	// end inline asm
(EngineCore_DP0 pid=347488) 	bar.sync 	0;
(EngineCore_DP0 pid=347488) 	ld.shared.b32 	%r77, [global_smem];
(EngineCore_DP0 pid=347488) $L__tmp2:
(EngineCore_DP0 pid=347488) 	.loc	1 191 36                        // quant_slide_tuned_Llama3.2-1B.py:191:36
(EngineCore_DP0 pid=347488) 	max.f32 	%r123, %r123, %r77;
(EngineCore_DP0 pid=347488) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=347488) 	add.s32 	%r124, %r124, 8192;
(EngineCore_DP0 pid=347488) 	setp.lt.s32 	%p7, %r124, %r19;
(EngineCore_DP0 pid=347488) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=347488) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=347488) 	.loc	1 193 32                        // quant_slide_tuned_Llama3.2-1B.py:193:32
(EngineCore_DP0 pid=347488) 	max.f32 	%r125, %r123, 0f2B8CBCCC;
(EngineCore_DP0 pid=347488) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=347488) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=347488) 	mov.b32 	%r79, 0f43E00000;
(EngineCore_DP0 pid=347488) 	.loc	1 194 32                        // quant_slide_tuned_Llama3.2-1B.py:194:32
(EngineCore_DP0 pid=347488) 	div.full.f32 	%r80, %r125, %r79;
(EngineCore_DP0 pid=347488) 	.loc	1 194 41                        // quant_slide_tuned_Llama3.2-1B.py:194:41
(EngineCore_DP0 pid=347488) 	max.f32 	%r78, %r80, 0f36924925;
(EngineCore_DP0 pid=347488) 	.loc	1 196 25                        // quant_slide_tuned_Llama3.2-1B.py:196:25
(EngineCore_DP0 pid=347488) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=347488) 	.loc	1 196 30                        // quant_slide_tuned_Llama3.2-1B.py:196:30
(EngineCore_DP0 pid=347488) 	// begin inline asm
(EngineCore_DP0 pid=347488) 	@%p20 st.global.b32 [ %rd8 + 0 ], { %r78 };
(EngineCore_DP0 pid=347488) 	// end inline asm
(EngineCore_DP0 pid=347488) 	.loc	1 199 29                        // quant_slide_tuned_Llama3.2-1B.py:199:29
(EngineCore_DP0 pid=347488) 	shl.b32 	%r15, %r20, 2;
(EngineCore_DP0 pid=347488) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=347488) 	setp.lt.s32 	%p9, %r15, 1;
(EngineCore_DP0 pid=347488) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=347488) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=347488) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=347488) 	ld.param.b32 	%r24, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=347488) 	shr.s32 	%r25, %r24, 31;
(EngineCore_DP0 pid=347488) 	shr.u32 	%r26, %r25, 30;
(EngineCore_DP0 pid=347488) 	add.s32 	%r27, %r24, %r26;
(EngineCore_DP0 pid=347488) 	shr.s32 	%r28, %r27, 2;
(EngineCore_DP0 pid=347488) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=347488) 	mul.lo.s32 	%r29, %r28, %r1;
(EngineCore_DP0 pid=347488) 	mad.wide.s32 	%rd2, %r29, 4, %rd5;
(EngineCore_DP0 pid=347488) 	div.full.f32 	%r14, %r79, %r125;
(EngineCore_DP0 pid=347488) 	mov.b32 	%r126, 0;
(EngineCore_DP0 pid=347488) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=347488)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=347488) 	.loc	1 203 30                        // quant_slide_tuned_Llama3.2-1B.py:203:30
(EngineCore_DP0 pid=347488) 	add.s32 	%r92, %r3, %r126;
(EngineCore_DP0 pid=347488) 	setp.lt.s32 	%p14, %r92, %r15;
(EngineCore_DP0 pid=347488) 	.loc	1 206 24                        // quant_slide_tuned_Llama3.2-1B.py:206:24
(EngineCore_DP0 pid=347488) 	shr.s32 	%r93, %r92, 31;
(EngineCore_DP0 pid=347488) 	shr.u32 	%r94, %r93, 30;
(EngineCore_DP0 pid=347488) 	add.s32 	%r95, %r92, %r94;
(EngineCore_DP0 pid=347488) 	shr.s32 	%r96, %r95, 2;
(EngineCore_DP0 pid=347488) 	.loc	1 207 23                        // quant_slide_tuned_Llama3.2-1B.py:207:23
(EngineCore_DP0 pid=347488) 	and.b32 	%r97, %r95, 2147483644;
(EngineCore_DP0 pid=347488) 	sub.s32 	%r98, %r92, %r97;
(EngineCore_DP0 pid=347488) 	.loc	1 208 30                        // quant_slide_tuned_Llama3.2-1B.py:208:30
(EngineCore_DP0 pid=347488) 	shl.b32 	%r99, %r98, 1;
(EngineCore_DP0 pid=347488) 	.loc	1 208 26                        // quant_slide_tuned_Llama3.2-1B.py:208:26
(EngineCore_DP0 pid=347488) 	mad.lo.s32 	%r100, %r96, 10, %r99;
(EngineCore_DP0 pid=347488) 	.loc	1 211 53                        // quant_slide_tuned_Llama3.2-1B.py:211:53
(EngineCore_DP0 pid=347488) 	setp.lt.s32 	%p15, %r100, %r18;
(EngineCore_DP0 pid=347488) 	.loc	1 211 37                        // quant_slide_tuned_Llama3.2-1B.py:211:37
(EngineCore_DP0 pid=347488) 	and.pred 	%p10, %p14, %p15;
(EngineCore_DP0 pid=347488) 	.loc	1 210 29                        // quant_slide_tuned_Llama3.2-1B.py:210:29
(EngineCore_DP0 pid=347488) 	mad.wide.s32 	%rd9, %r100, 2, %rd1;
(EngineCore_DP0 pid=347488) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=347488) 	.loc	1 210 21                        // quant_slide_tuned_Llama3.2-1B.py:210:21
(EngineCore_DP0 pid=347488) 	// begin inline asm
(EngineCore_DP0 pid=347488) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=347488) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=347488) 	// end inline asm
(EngineCore_DP0 pid=347488) 	.loc	1 211 79                        // quant_slide_tuned_Llama3.2-1B.py:211:79
(EngineCore_DP0 pid=347488) 	cvt.f32.bf16 	%r101, %rs48;
(EngineCore_DP0 pid=347488) 	.loc	1 213 48                        // quant_slide_tuned_Llama3.2-1B.py:213:48
(EngineCore_DP0 pid=347488) 	or.b32 	%r102, %r100, 1;
(EngineCore_DP0 pid=347488) 	.loc	1 213 53                        // quant_slide_tuned_Llama3.2-1B.py:213:53
(EngineCore_DP0 pid=347488) 	setp.lt.s32 	%p16, %r102, %r18;
(EngineCore_DP0 pid=347488) 	.loc	1 213 37                        // quant_slide_tuned_Llama3.2-1B.py:213:37
(EngineCore_DP0 pid=347488) 	and.pred 	%p11, %p14, %p16;
(EngineCore_DP0 pid=347488) 	.loc	1 212 39                        // quant_slide_tuned_Llama3.2-1B.py:212:39
(EngineCore_DP0 pid=347488) 	add.s64 	%rd10, %rd9, 2;
(EngineCore_DP0 pid=347488) 	.loc	1 212 21                        // quant_slide_tuned_Llama3.2-1B.py:212:21
(EngineCore_DP0 pid=347488) 	// begin inline asm
(EngineCore_DP0 pid=347488) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=347488) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=347488) 	// end inline asm
(EngineCore_DP0 pid=347488) 	.loc	1 213 79                        // quant_slide_tuned_Llama3.2-1B.py:213:79
(EngineCore_DP0 pid=347488) 	cvt.f32.bf16 	%r103, %rs50;
(EngineCore_DP0 pid=347488) 	.loc	1 215 48                        // quant_slide_tuned_Llama3.2-1B.py:215:48
(EngineCore_DP0 pid=347488) 	add.s32 	%r104, %r100, 2;
(EngineCore_DP0 pid=347488) 	.loc	1 215 53                        // quant_slide_tuned_Llama3.2-1B.py:215:53
(EngineCore_DP0 pid=347488) 	setp.lt.s32 	%p17, %r104, %r18;
(EngineCore_DP0 pid=347488) 	.loc	1 215 37                        // quant_slide_tuned_Llama3.2-1B.py:215:37
(EngineCore_DP0 pid=347488) 	and.pred 	%p12, %p14, %p17;
(EngineCore_DP0 pid=347488) 	.loc	1 214 39                        // quant_slide_tuned_Llama3.2-1B.py:214:39
(EngineCore_DP0 pid=347488) 	add.s64 	%rd11, %rd9, 4;
(EngineCore_DP0 pid=347488) 	.loc	1 214 21                        // quant_slide_tuned_Llama3.2-1B.py:214:21
(EngineCore_DP0 pid=347488) 	// begin inline asm
(EngineCore_DP0 pid=347488) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=347488) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=347488) 	// end inline asm
(EngineCore_DP0 pid=347488) 	.loc	1 215 79                        // quant_slide_tuned_Llama3.2-1B.py:215:79
(EngineCore_DP0 pid=347488) 	cvt.f32.bf16 	%r105, %rs52;
(EngineCore_DP0 pid=347488) 	.loc	1 217 48                        // quant_slide_tuned_Llama3.2-1B.py:217:48
(EngineCore_DP0 pid=347488) 	add.s32 	%r106, %r100, 3;
(EngineCore_DP0 pid=347488) 	.loc	1 217 53                        // quant_slide_tuned_Llama3.2-1B.py:217:53
(EngineCore_DP0 pid=347488) 	setp.lt.s32 	%p18, %r106, %r18;
(EngineCore_DP0 pid=347488) 	.loc	1 217 37                        // quant_slide_tuned_Llama3.2-1B.py:217:37
(EngineCore_DP0 pid=347488) 	and.pred 	%p13, %p14, %p18;
(EngineCore_DP0 pid=347488) 	.loc	1 216 39                        // quant_slide_tuned_Llama3.2-1B.py:216:39
(EngineCore_DP0 pid=347488) 	add.s64 	%rd12, %rd9, 6;
(EngineCore_DP0 pid=347488) 	.loc	1 216 21                        // quant_slide_tuned_Llama3.2-1B.py:216:21
(EngineCore_DP0 pid=347488) 	// begin inline asm
(EngineCore_DP0 pid=347488) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=347488) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=347488) 	// end inline asm
(EngineCore_DP0 pid=347488) 	.loc	1 217 79                        // quant_slide_tuned_Llama3.2-1B.py:217:79
(EngineCore_DP0 pid=347488) 	cvt.f32.bf16 	%r107, %rs54;
(EngineCore_DP0 pid=347488) 	.loc	1 219 27                        // quant_slide_tuned_Llama3.2-1B.py:219:27
(EngineCore_DP0 pid=347488) 	mul.f32 	%r108, %r14, %r101;
(EngineCore_DP0 pid=347488) 	mov.b32 	%r109, 0f43E00000;
(EngineCore_DP0 pid=347488) 	.loc	1 219 48                        // quant_slide_tuned_Llama3.2-1B.py:219:48
(EngineCore_DP0 pid=347488) 	min.xorsign.abs.f32 	%r82, %r108, %r109;
(EngineCore_DP0 pid=347488) 	.loc	1 219 60                        // quant_slide_tuned_Llama3.2-1B.py:219:60
(EngineCore_DP0 pid=347488) 	// begin inline asm
(EngineCore_DP0 pid=347488) 	cvt.rn.satfinite.e4m3x2.f32  %rs56, %r83, %r82; 
(EngineCore_DP0 pid=347488) 
(EngineCore_DP0 pid=347488) 	// end inline asm
(EngineCore_DP0 pid=347488) 	.loc	1 220 27                        // quant_slide_tuned_Llama3.2-1B.py:220:27
(EngineCore_DP0 pid=347488) 	mul.f32 	%r110, %r14, %r103;
(EngineCore_DP0 pid=347488) 	.loc	1 220 48                        // quant_slide_tuned_Llama3.2-1B.py:220:48
(EngineCore_DP0 pid=347488) 	min.xorsign.abs.f32 	%r84, %r110, %r109;
(EngineCore_DP0 pid=347488) 	.loc	1 220 60                        // quant_slide_tuned_Llama3.2-1B.py:220:60
(EngineCore_DP0 pid=347488) 	// begin inline asm
(EngineCore_DP0 pid=347488) 	cvt.rn.satfinite.e4m3x2.f32  %rs57, %r85, %r84; 
(EngineCore_DP0 pid=347488) 
(EngineCore_DP0 pid=347488) 	// end inline asm
(EngineCore_DP0 pid=347488) 	.loc	1 221 27                        // quant_slide_tuned_Llama3.2-1B.py:221:27
(EngineCore_DP0 pid=347488) 	mul.f32 	%r111, %r14, %r105;
(EngineCore_DP0 pid=347488) 	.loc	1 221 48                        // quant_slide_tuned_Llama3.2-1B.py:221:48
(EngineCore_DP0 pid=347488) 	min.xorsign.abs.f32 	%r86, %r111, %r109;
(EngineCore_DP0 pid=347488) 	.loc	1 221 60                        // quant_slide_tuned_Llama3.2-1B.py:221:60
(EngineCore_DP0 pid=347488) 	// begin inline asm
(EngineCore_DP0 pid=347488) 	cvt.rn.satfinite.e4m3x2.f32  %rs58, %r87, %r86; 
(EngineCore_DP0 pid=347488) 
(EngineCore_DP0 pid=347488) 	// end inline asm
(EngineCore_DP0 pid=347488) 	.loc	1 222 27                        // quant_slide_tuned_Llama3.2-1B.py:222:27
(EngineCore_DP0 pid=347488) 	mul.f32 	%r112, %r14, %r107;
(EngineCore_DP0 pid=347488) 	.loc	1 222 48                        // quant_slide_tuned_Llama3.2-1B.py:222:48
(EngineCore_DP0 pid=347488) 	min.xorsign.abs.f32 	%r88, %r112, %r109;
(EngineCore_DP0 pid=347488) 	.loc	1 222 60                        // quant_slide_tuned_Llama3.2-1B.py:222:60
(EngineCore_DP0 pid=347488) 	// begin inline asm
(EngineCore_DP0 pid=347488) 	cvt.rn.satfinite.e4m3x2.f32  %rs59, %r89, %r88; 
(EngineCore_DP0 pid=347488) 
(EngineCore_DP0 pid=347488) 	// end inline asm
(EngineCore_DP0 pid=347488) 	.loc	1 224 45                        // quant_slide_tuned_Llama3.2-1B.py:224:45
(EngineCore_DP0 pid=347488) 	cvt.u32.u16 	%r113, %rs56;
(EngineCore_DP0 pid=347488) 	and.b32 	%r114, %r113, 255;
(EngineCore_DP0 pid=347488) 	.loc	1 226 45                        // quant_slide_tuned_Llama3.2-1B.py:226:45
(EngineCore_DP0 pid=347488) 	cvt.u32.u16 	%r115, %rs58;
(EngineCore_DP0 pid=347488) 	and.b32 	%r116, %r115, 255;
(EngineCore_DP0 pid=347488) 	.loc	1 227 45                        // quant_slide_tuned_Llama3.2-1B.py:227:45
(EngineCore_DP0 pid=347488) 	cvt.u32.u16 	%r117, %rs59;
(EngineCore_DP0 pid=347488) 	.loc	1 229 30                        // quant_slide_tuned_Llama3.2-1B.py:229:30
(EngineCore_DP0 pid=347488) 	and.b16 	%rs60, %rs57, 255;
(EngineCore_DP0 pid=347488) 	mul.wide.u16 	%r118, %rs60, 256;
(EngineCore_DP0 pid=347488) 	.loc	1 229 24                        // quant_slide_tuned_Llama3.2-1B.py:229:24
(EngineCore_DP0 pid=347488) 	or.b32 	%r119, %r118, %r114;
(EngineCore_DP0 pid=347488) 	.loc	1 229 42                        // quant_slide_tuned_Llama3.2-1B.py:229:42
(EngineCore_DP0 pid=347488) 	shl.b32 	%r120, %r116, 16;
(EngineCore_DP0 pid=347488) 	.loc	1 229 36                        // quant_slide_tuned_Llama3.2-1B.py:229:36
(EngineCore_DP0 pid=347488) 	or.b32 	%r121, %r119, %r120;
(EngineCore_DP0 pid=347488) 	.loc	1 229 55                        // quant_slide_tuned_Llama3.2-1B.py:229:55
(EngineCore_DP0 pid=347488) 	shl.b32 	%r122, %r117, 24;
(EngineCore_DP0 pid=347488) 	.loc	1 229 49                        // quant_slide_tuned_Llama3.2-1B.py:229:49
(EngineCore_DP0 pid=347488) 	or.b32 	%r90, %r121, %r122;
(EngineCore_DP0 pid=347488) 	.loc	1 230 29                        // quant_slide_tuned_Llama3.2-1B.py:230:29
(EngineCore_DP0 pid=347488) 	mad.wide.s32 	%rd13, %r92, 4, %rd2;
(EngineCore_DP0 pid=347488) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-1B.py:230:39
(EngineCore_DP0 pid=347488) 	// begin inline asm
(EngineCore_DP0 pid=347488) 	@%p14 st.global.b32 [ %rd13 + 0 ], { %r90 };
(EngineCore_DP0 pid=347488) 	// end inline asm
(EngineCore_DP0 pid=347488) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=347488) 	add.s32 	%r126, %r126, 512;
(EngineCore_DP0 pid=347488) 	setp.lt.s32 	%p19, %r126, %r15;
(EngineCore_DP0 pid=347488) 	@%p19 bra 	$L__BB0_6;
(EngineCore_DP0 pid=347488) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=347488) 	.loc	1 201 4                         // quant_slide_tuned_Llama3.2-1B.py:201:4
(EngineCore_DP0 pid=347488) 	ret;
(EngineCore_DP0 pid=347488) $L__tmp3:
(EngineCore_DP0 pid=347488) $L__func_end0:
(EngineCore_DP0 pid=347488)                                         // -- End function
(EngineCore_DP0 pid=347488) }
(EngineCore_DP0 pid=347488) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=347488) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=347488) 	.section	.debug_abbrev
(EngineCore_DP0 pid=347488) 	{
(EngineCore_DP0 pid=347488) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=347488) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=347488) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=347488) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=347488) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=347488) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=347488) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=347488) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=347488) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=347488) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=347488) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=347488) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=347488) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=347488) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=347488) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=347488) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=347488) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=347488) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=347488) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=347488) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=347488) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=347488) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=347488) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=347488) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=347488) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=347488) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=347488) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=347488) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=347488) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=347488) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=347488) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=347488) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=347488) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=347488) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=347488) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=347488) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=347488) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=347488) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=347488) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=347488) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=347488) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=347488) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=347488) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=347488) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=347488) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=347488) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=347488) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=347488) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=347488) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=347488) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=347488) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=347488) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=347488) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=347488) 	}
(EngineCore_DP0 pid=347488) 	.section	.debug_info
(EngineCore_DP0 pid=347488) 	{
(EngineCore_DP0 pid=347488) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=347488) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=347488) .b8 0
(EngineCore_DP0 pid=347488) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=347488) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=347488) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=347488) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=347488) .b8 114
(EngineCore_DP0 pid=347488) .b8 105
(EngineCore_DP0 pid=347488) .b8 116
(EngineCore_DP0 pid=347488) .b8 111
(EngineCore_DP0 pid=347488) .b8 110
(EngineCore_DP0 pid=347488) .b8 0
(EngineCore_DP0 pid=347488) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=347488) .b8 0
(EngineCore_DP0 pid=347488) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=347488) .b8 117
(EngineCore_DP0 pid=347488) .b8 97
(EngineCore_DP0 pid=347488) .b8 110
(EngineCore_DP0 pid=347488) .b8 116
(EngineCore_DP0 pid=347488) .b8 95
(EngineCore_DP0 pid=347488) .b8 115
(EngineCore_DP0 pid=347488) .b8 108
(EngineCore_DP0 pid=347488) .b8 105
(EngineCore_DP0 pid=347488) .b8 100
(EngineCore_DP0 pid=347488) .b8 101
(EngineCore_DP0 pid=347488) .b8 95
(EngineCore_DP0 pid=347488) .b8 116
(EngineCore_DP0 pid=347488) .b8 117
(EngineCore_DP0 pid=347488) .b8 110
(EngineCore_DP0 pid=347488) .b8 101
(EngineCore_DP0 pid=347488) .b8 100
(EngineCore_DP0 pid=347488) .b8 95
(EngineCore_DP0 pid=347488) .b8 76
(EngineCore_DP0 pid=347488) .b8 108
(EngineCore_DP0 pid=347488) .b8 97
(EngineCore_DP0 pid=347488) .b8 109
(EngineCore_DP0 pid=347488) .b8 97
(EngineCore_DP0 pid=347488) .b8 51
(EngineCore_DP0 pid=347488) .b8 46
(EngineCore_DP0 pid=347488) .b8 50
(EngineCore_DP0 pid=347488) .b8 45
(EngineCore_DP0 pid=347488) .b8 49
(EngineCore_DP0 pid=347488) .b8 66
(EngineCore_DP0 pid=347488) .b8 46
(EngineCore_DP0 pid=347488) .b8 112
(EngineCore_DP0 pid=347488) .b8 121
(EngineCore_DP0 pid=347488) .b8 0
(EngineCore_DP0 pid=347488) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=347488) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=347488) .b8 114
(EngineCore_DP0 pid=347488) .b8 111
(EngineCore_DP0 pid=347488) .b8 111
(EngineCore_DP0 pid=347488) .b8 116
(EngineCore_DP0 pid=347488) .b8 47
(EngineCore_DP0 pid=347488) .b8 118
(EngineCore_DP0 pid=347488) .b8 108
(EngineCore_DP0 pid=347488) .b8 108
(EngineCore_DP0 pid=347488) .b8 109
(EngineCore_DP0 pid=347488) .b8 98
(EngineCore_DP0 pid=347488) .b8 101
(EngineCore_DP0 pid=347488) .b8 110
(EngineCore_DP0 pid=347488) .b8 99
(EngineCore_DP0 pid=347488) .b8 104
(EngineCore_DP0 pid=347488) .b8 47
(EngineCore_DP0 pid=347488) .b8 115
(EngineCore_DP0 pid=347488) .b8 108
(EngineCore_DP0 pid=347488) .b8 105
(EngineCore_DP0 pid=347488) .b8 100
(EngineCore_DP0 pid=347488) .b8 101
(EngineCore_DP0 pid=347488) .b8 115
(EngineCore_DP0 pid=347488) .b8 112
(EngineCore_DP0 pid=347488) .b8 97
(EngineCore_DP0 pid=347488) .b8 114
(EngineCore_DP0 pid=347488) .b8 115
(EngineCore_DP0 pid=347488) .b8 101
(EngineCore_DP0 pid=347488) .b8 47
(EngineCore_DP0 pid=347488) .b8 99
(EngineCore_DP0 pid=347488) .b8 115
(EngineCore_DP0 pid=347488) .b8 114
(EngineCore_DP0 pid=347488) .b8 99
(EngineCore_DP0 pid=347488) .b8 47
(EngineCore_DP0 pid=347488) .b8 102
(EngineCore_DP0 pid=347488) .b8 117
(EngineCore_DP0 pid=347488) .b8 115
(EngineCore_DP0 pid=347488) .b8 101
(EngineCore_DP0 pid=347488) .b8 100
(EngineCore_DP0 pid=347488) .b8 95
(EngineCore_DP0 pid=347488) .b8 113
(EngineCore_DP0 pid=347488) .b8 117
(EngineCore_DP0 pid=347488) .b8 97
(EngineCore_DP0 pid=347488) .b8 110
(EngineCore_DP0 pid=347488) .b8 116
(EngineCore_DP0 pid=347488) .b8 95
(EngineCore_DP0 pid=347488) .b8 115
(EngineCore_DP0 pid=347488) .b8 108
(EngineCore_DP0 pid=347488) .b8 105
(EngineCore_DP0 pid=347488) .b8 100
(EngineCore_DP0 pid=347488) .b8 101
(EngineCore_DP0 pid=347488) .b8 95
(EngineCore_DP0 pid=347488) .b8 116
(EngineCore_DP0 pid=347488) .b8 114
(EngineCore_DP0 pid=347488) .b8 105
(EngineCore_DP0 pid=347488) .b8 116
(EngineCore_DP0 pid=347488) .b8 111
(EngineCore_DP0 pid=347488) .b8 110
(EngineCore_DP0 pid=347488) .b8 47
(EngineCore_DP0 pid=347488) .b8 98
(EngineCore_DP0 pid=347488) .b8 117
(EngineCore_DP0 pid=347488) .b8 105
(EngineCore_DP0 pid=347488) .b8 108
(EngineCore_DP0 pid=347488) .b8 100
(EngineCore_DP0 pid=347488) .b8 47
(EngineCore_DP0 pid=347488) .b8 71
(EngineCore_DP0 pid=347488) .b8 66
(EngineCore_DP0 pid=347488) .b8 49
(EngineCore_DP0 pid=347488) .b8 48
(EngineCore_DP0 pid=347488) .b8 95
(EngineCore_DP0 pid=347488) .b8 99
(EngineCore_DP0 pid=347488) .b8 99
(EngineCore_DP0 pid=347488) .b8 49
(EngineCore_DP0 pid=347488) .b8 50
(EngineCore_DP0 pid=347488) .b8 49
(EngineCore_DP0 pid=347488) .b8 95
(EngineCore_DP0 pid=347488) .b8 112
(EngineCore_DP0 pid=347488) .b8 121
(EngineCore_DP0 pid=347488) .b8 51
(EngineCore_DP0 pid=347488) .b8 49
(EngineCore_DP0 pid=347488) .b8 50
(EngineCore_DP0 pid=347488) .b8 95
(EngineCore_DP0 pid=347488) .b8 99
(EngineCore_DP0 pid=347488) .b8 117
(EngineCore_DP0 pid=347488) .b8 49
(EngineCore_DP0 pid=347488) .b8 50
(EngineCore_DP0 pid=347488) .b8 57
(EngineCore_DP0 pid=347488) .b8 95
(EngineCore_DP0 pid=347488) .b8 97
(EngineCore_DP0 pid=347488) .b8 97
(EngineCore_DP0 pid=347488) .b8 114
(EngineCore_DP0 pid=347488) .b8 99
(EngineCore_DP0 pid=347488) .b8 104
(EngineCore_DP0 pid=347488) .b8 54
(EngineCore_DP0 pid=347488) .b8 52
(EngineCore_DP0 pid=347488) .b8 0
(EngineCore_DP0 pid=347488) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=347488) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=347488) .b8 113
(EngineCore_DP0 pid=347488) .b8 117
(EngineCore_DP0 pid=347488) .b8 97
(EngineCore_DP0 pid=347488) .b8 110
(EngineCore_DP0 pid=347488) .b8 116
(EngineCore_DP0 pid=347488) .b8 95
(EngineCore_DP0 pid=347488) .b8 115
(EngineCore_DP0 pid=347488) .b8 108
(EngineCore_DP0 pid=347488) .b8 105
(EngineCore_DP0 pid=347488) .b8 100
(EngineCore_DP0 pid=347488) .b8 101
(EngineCore_DP0 pid=347488) .b8 95
(EngineCore_DP0 pid=347488) .b8 102
(EngineCore_DP0 pid=347488) .b8 112
(EngineCore_DP0 pid=347488) .b8 56
(EngineCore_DP0 pid=347488) .b8 95
(EngineCore_DP0 pid=347488) .b8 107
(EngineCore_DP0 pid=347488) .b8 101
(EngineCore_DP0 pid=347488) .b8 114
(EngineCore_DP0 pid=347488) .b8 110
(EngineCore_DP0 pid=347488) .b8 101
(EngineCore_DP0 pid=347488) .b8 108
(EngineCore_DP0 pid=347488) .b8 0
(EngineCore_DP0 pid=347488) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=347488) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=347488) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=347488) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=347488) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=347488) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=347488) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=347488) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=347488) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=347488) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=347488) .b8 191                                 // DW_AT_call_line
(EngineCore_DP0 pid=347488) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=347488) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=347488) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=347488) 	}
(EngineCore_DP0 pid=347488) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=347488) 
(EngineCore_DP0 pid=347488) ================================================================
(EngineCore_DP0 pid=347488) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=347488) 
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmprzoyjcd4.ptx', '-o', '/tmp/tmprzoyjcd4.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866] 
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866] 
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866] 
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmprzoyjcd4.ptx -o /tmp/tmprzoyjcd4.ptx.o
(EngineCore_DP0 pid=347488) ERROR 01-25 19:24:52 [core.py:866] 

STDERR:
[2026-01-25 19:24:35] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:24:35] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:24:35] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:24:35] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:24:35] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:24:35] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:24:35] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:24:35] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:24:35] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:24:35] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:24:35] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:24:35] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:24:35] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:24:35] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:24:39] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:24:39] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:24:39] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:24:39] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:24:39] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:24:39] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:24:39] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:24:39] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:24:39] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:24:39] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:24:39] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:24:39] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:24:39] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:24:39] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=347488) [2026-01-25 19:24:40] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=347488) [2026-01-25 19:24:40] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=347488) [2026-01-25 19:24:40] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=347488) [2026-01-25 19:24:40] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=347488) [2026-01-25 19:24:40] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=347488) [2026-01-25 19:24:40] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=347488) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=347488) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:11<00:00, 11.10s/it]
(EngineCore_DP0 pid=347488) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:11<00:00, 11.10s/it]
(EngineCore_DP0 pid=347488) 
(EngineCore_DP0 pid=347488) [2026-01-25 19:24:51] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=347488) [2026-01-25 19:24:51] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6340608 bytes
(EngineCore_DP0 pid=347488) [2026-01-25 19:24:51] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=347488) [2026-01-25 19:24:51] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 4227072 bytes
(EngineCore_DP0 pid=347488) [2026-01-25 19:24:51] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=347488) [2026-01-25 19:24:51] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 33816576 bytes
(EngineCore_DP0 pid=347488) [2026-01-25 19:24:51] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=347488) [2026-01-25 19:24:51] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16809984 bytes
(EngineCore_DP0 pid=347488) Process EngineCore_DP0:
(EngineCore_DP0 pid=347488) Traceback (most recent call last):
(EngineCore_DP0 pid=347488)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=347488)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=347488)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=347488)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=347488) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmprzoyjcd4.ptx', '-o', '/tmp/tmprzoyjcd4.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=347488) 
(EngineCore_DP0 pid=347488) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=347488) 
(EngineCore_DP0 pid=347488) Traceback (most recent call last):
(EngineCore_DP0 pid=347488)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=347488)     self.run()
(EngineCore_DP0 pid=347488)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=347488)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=347488)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=347488)     raise e
(EngineCore_DP0 pid=347488)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=347488)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=347488)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=347488)     super().__init__(
(EngineCore_DP0 pid=347488)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=347488)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=347488)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=347488)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=347488)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=347488)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=347488)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=347488)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=347488)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=347488)     return func(*args, **kwargs)
(EngineCore_DP0 pid=347488)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=347488)     return func(*args, **kwargs)
(EngineCore_DP0 pid=347488)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=347488)     self.model_runner.profile_run()
(EngineCore_DP0 pid=347488)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=347488)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=347488)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=347488)     return func(*args, **kwargs)
(EngineCore_DP0 pid=347488)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=347488)     outputs = self.model(
(EngineCore_DP0 pid=347488)               ^^^^^^^^^^^
(EngineCore_DP0 pid=347488)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=347488)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=347488)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=347488)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=347488)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=347488)     model_output = self.model(
(EngineCore_DP0 pid=347488)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=347488)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=347488)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=347488)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=347488)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=347488)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=347488)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=347488)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=347488)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=347488)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=347488)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=347488)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=347488)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=347488)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=347488)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=347488)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=347488)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=347488)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=347488)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=347488)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=347488)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=347488)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=347488)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=347488)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=347488)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=347488)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=347488)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=347488)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=347488)     return self._linear_fn(
(EngineCore_DP0 pid=347488)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=347488)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=347488)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=347488)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=347488)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=347488)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=347488)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=347488)     return fn(input, L)
(EngineCore_DP0 pid=347488)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=347488)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=347488)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=347488)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=347488)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=347488)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=347488)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=347488)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=347488)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=347488)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=347488)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=347488)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=347488)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=347488)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=347488)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=347488)     raise PTXASError(error)
(EngineCore_DP0 pid=347488) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=347488) `ptxas` stderr:
(EngineCore_DP0 pid=347488) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=347488) 
(EngineCore_DP0 pid=347488) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmprzoyjcd4.ptx -o /tmp/tmprzoyjcd4.ptx.o
(EngineCore_DP0 pid=347488) 
[rank0]:[W125 19:24:52.171704680 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=2048

========== M=4096 ==========
Time: 2026-01-25 19:24:54
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-1B-FP8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:24:59 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:24:59 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=348013) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=348013) 
(EngineCore_DP0 pid=348013) 
(EngineCore_DP0 pid=348013) ================================================================
(EngineCore_DP0 pid=348013) Internal Triton PTX codegen error
(EngineCore_DP0 pid=348013) `ptxas` stderr:
(EngineCore_DP0 pid=348013) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=348013) 
(EngineCore_DP0 pid=348013) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpxveqvkd0.ptx -o /tmp/tmpxveqvkd0.ptx.o
(EngineCore_DP0 pid=348013) 
(EngineCore_DP0 pid=348013) 
(EngineCore_DP0 pid=348013) //
(EngineCore_DP0 pid=348013) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=348013) //
(EngineCore_DP0 pid=348013) 
(EngineCore_DP0 pid=348013) .version 8.7
(EngineCore_DP0 pid=348013) .target sm_121a
(EngineCore_DP0 pid=348013) .address_size 64
(EngineCore_DP0 pid=348013) 
(EngineCore_DP0 pid=348013) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=348013) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=348013)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=348013) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=348013) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=348013) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=348013) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=348013) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=348013) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=348013) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=348013) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=348013) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=348013) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=348013) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=348013) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=348013) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=348013) )
(EngineCore_DP0 pid=348013) .reqntid 512
(EngineCore_DP0 pid=348013) {
(EngineCore_DP0 pid=348013) 	.reg .pred 	%p<21>;
(EngineCore_DP0 pid=348013) 	.reg .b16 	%rs<61>;
(EngineCore_DP0 pid=348013) 	.reg .b32 	%r<127>;
(EngineCore_DP0 pid=348013) 	.reg .b64 	%rd<14>;
(EngineCore_DP0 pid=348013) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=348013) $L__func_begin0:
(EngineCore_DP0 pid=348013) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=348013) 
(EngineCore_DP0 pid=348013) // %bb.0:
(EngineCore_DP0 pid=348013) 	ld.param.b32 	%r20, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=348013) 	ld.param.b32 	%r19, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=348013) 	ld.param.b32 	%r18, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=348013) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=348013) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=348013) $L__tmp0:
(EngineCore_DP0 pid=348013) 	.loc	1 177 24                        // quant_slide_tuned_Llama3.2-1B.py:177:24
(EngineCore_DP0 pid=348013) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=348013) 	ld.param.b32 	%r22, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=348013) 	.loc	1 182 26                        // quant_slide_tuned_Llama3.2-1B.py:182:26
(EngineCore_DP0 pid=348013) 	mul.lo.s32 	%r23, %r22, %r1;
(EngineCore_DP0 pid=348013) 	.loc	1 182 20                        // quant_slide_tuned_Llama3.2-1B.py:182:20
(EngineCore_DP0 pid=348013) 	mad.wide.s32 	%rd1, %r23, 2, %rd4;
(EngineCore_DP0 pid=348013) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=348013) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=348013) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=348013) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=348013) 	setp.lt.s32 	%p1, %r19, 1;
(EngineCore_DP0 pid=348013) 	mov.b32 	%r125, 0f2B8CBCCC;
(EngineCore_DP0 pid=348013) 	setp.eq.b32 	%p20, %r2, 0;
(EngineCore_DP0 pid=348013) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=348013) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=348013) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=348013) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=348013) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=348013) 	shr.u32 	%r32, %r2, 3;
(EngineCore_DP0 pid=348013) 	and.b32 	%r33, %r32, 60;
(EngineCore_DP0 pid=348013) 	mov.b32 	%r34, global_smem;
(EngineCore_DP0 pid=348013) 	add.s32 	%r52, %r34, %r33;
(EngineCore_DP0 pid=348013) 	shl.b32 	%r35, %r2, 2;
(EngineCore_DP0 pid=348013) 	add.s32 	%r55, %r34, %r35;
(EngineCore_DP0 pid=348013) 	mov.b32 	%r40, 0;
(EngineCore_DP0 pid=348013) 	mov.b32 	%r123, 0f00000000;
(EngineCore_DP0 pid=348013) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=348013) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=348013) 	mov.b32 	%r124, %r40;
(EngineCore_DP0 pid=348013) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=348013) 	.loc	1 188 19                        // quant_slide_tuned_Llama3.2-1B.py:188:19
(EngineCore_DP0 pid=348013) 	add.s32 	%r58, %r4, %r124;
(EngineCore_DP0 pid=348013) 	.loc	1 189 22                        // quant_slide_tuned_Llama3.2-1B.py:189:22
(EngineCore_DP0 pid=348013) 	add.s32 	%r59, %r58, 4096;
(EngineCore_DP0 pid=348013) 	setp.lt.s32 	%p2, %r58, %r18;
(EngineCore_DP0 pid=348013) 	setp.lt.s32 	%p3, %r59, %r18;
(EngineCore_DP0 pid=348013) 	.loc	1 190 29                        // quant_slide_tuned_Llama3.2-1B.py:190:29
(EngineCore_DP0 pid=348013) 	mad.wide.s32 	%rd6, %r58, 2, %rd1;
(EngineCore_DP0 pid=348013) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=348013) 	.loc	1 190 21                        // quant_slide_tuned_Llama3.2-1B.py:190:21
(EngineCore_DP0 pid=348013) 	// begin inline asm
(EngineCore_DP0 pid=348013) 	mov.u32 %r36, %r40;
(EngineCore_DP0 pid=348013) 	mov.u32 %r37, %r40;
(EngineCore_DP0 pid=348013) 	mov.u32 %r38, %r40;
(EngineCore_DP0 pid=348013) 	mov.u32 %r39, %r40;
(EngineCore_DP0 pid=348013) 	@%p2 ld.global.v4.b32 { %r36, %r37, %r38, %r39 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=348013) 	// end inline asm
(EngineCore_DP0 pid=348013) 	mov.b32 	{%rs1, %rs2}, %r36;
(EngineCore_DP0 pid=348013) 	mov.b32 	{%rs3, %rs4}, %r37;
(EngineCore_DP0 pid=348013) 	mov.b32 	{%rs5, %rs6}, %r38;
(EngineCore_DP0 pid=348013) 	mov.b32 	{%rs7, %rs8}, %r39;
(EngineCore_DP0 pid=348013) 	// begin inline asm
(EngineCore_DP0 pid=348013) 	mov.u32 %r44, %r40;
(EngineCore_DP0 pid=348013) 	mov.u32 %r45, %r40;
(EngineCore_DP0 pid=348013) 	mov.u32 %r46, %r40;
(EngineCore_DP0 pid=348013) 	mov.u32 %r47, %r40;
(EngineCore_DP0 pid=348013) 	@%p3 ld.global.v4.b32 { %r44, %r45, %r46, %r47 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=348013) 	// end inline asm
(EngineCore_DP0 pid=348013) 	mov.b32 	{%rs9, %rs10}, %r44;
(EngineCore_DP0 pid=348013) 	mov.b32 	{%rs11, %rs12}, %r45;
(EngineCore_DP0 pid=348013) 	mov.b32 	{%rs13, %rs14}, %r46;
(EngineCore_DP0 pid=348013) 	mov.b32 	{%rs15, %rs16}, %r47;
(EngineCore_DP0 pid=348013) 	.loc	1 191 50                        // quant_slide_tuned_Llama3.2-1B.py:191:50
(EngineCore_DP0 pid=348013) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=348013) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=348013) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=348013) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=348013) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=348013) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=348013) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=348013) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=348013) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=348013) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=348013) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=348013) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=348013) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=348013) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=348013) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=348013) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=348013) $L__tmp1:
(EngineCore_DP0 pid=348013) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=348013) 	bar.sync 	0;
(EngineCore_DP0 pid=348013) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=348013) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=348013) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=348013) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=348013) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=348013) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=348013) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=348013) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=348013) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=348013) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=348013) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=348013) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=348013) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=348013) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=348013) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=348013) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=348013) 	cvt.f32.bf16 	%r60, %rs47;
(EngineCore_DP0 pid=348013) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=348013) 	shfl.sync.bfly.b32 	%r61, %r60, 16, 31, -1;
(EngineCore_DP0 pid=348013) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=348013) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=348013) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=348013) 	shfl.sync.bfly.b32 	%r63, %r62, 8, 31, -1;
(EngineCore_DP0 pid=348013) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=348013) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=348013) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=348013) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=348013) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=348013) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=348013) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=348013) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=348013) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=348013) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=348013) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=348013) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=348013) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=348013) 	max.f32 	%r53, %r68, %r69;
(EngineCore_DP0 pid=348013) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=348013) 	// begin inline asm
(EngineCore_DP0 pid=348013) 	@%p4 st.shared.b32 [ %r52 + 0 ], %r53;
(EngineCore_DP0 pid=348013) 	// end inline asm
(EngineCore_DP0 pid=348013) 	bar.sync 	0;
(EngineCore_DP0 pid=348013) 	// begin inline asm
(EngineCore_DP0 pid=348013) 	@%p5 ld.shared.b32 %r54, [ %r55 + 0 ];
(EngineCore_DP0 pid=348013) 	// end inline asm
(EngineCore_DP0 pid=348013) 	shfl.sync.bfly.b32 	%r70, %r54, 8, 31, -1;
(EngineCore_DP0 pid=348013) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=348013) 	max.f32 	%r71, %r54, %r70;
(EngineCore_DP0 pid=348013) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=348013) 	shfl.sync.bfly.b32 	%r72, %r71, 4, 31, -1;
(EngineCore_DP0 pid=348013) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=348013) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=348013) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=348013) 	shfl.sync.bfly.b32 	%r74, %r73, 2, 31, -1;
(EngineCore_DP0 pid=348013) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=348013) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=348013) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=348013) 	shfl.sync.bfly.b32 	%r76, %r75, 1, 31, -1;
(EngineCore_DP0 pid=348013) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=348013) 	max.f32 	%r57, %r75, %r76;
(EngineCore_DP0 pid=348013) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=348013) 	// begin inline asm
(EngineCore_DP0 pid=348013) 	@%p20 st.shared.b32 [ %r55 + 0 ], %r57;
(EngineCore_DP0 pid=348013) 	// end inline asm
(EngineCore_DP0 pid=348013) 	bar.sync 	0;
(EngineCore_DP0 pid=348013) 	ld.shared.b32 	%r77, [global_smem];
(EngineCore_DP0 pid=348013) $L__tmp2:
(EngineCore_DP0 pid=348013) 	.loc	1 191 36                        // quant_slide_tuned_Llama3.2-1B.py:191:36
(EngineCore_DP0 pid=348013) 	max.f32 	%r123, %r123, %r77;
(EngineCore_DP0 pid=348013) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=348013) 	add.s32 	%r124, %r124, 8192;
(EngineCore_DP0 pid=348013) 	setp.lt.s32 	%p7, %r124, %r19;
(EngineCore_DP0 pid=348013) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=348013) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=348013) 	.loc	1 193 32                        // quant_slide_tuned_Llama3.2-1B.py:193:32
(EngineCore_DP0 pid=348013) 	max.f32 	%r125, %r123, 0f2B8CBCCC;
(EngineCore_DP0 pid=348013) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=348013) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=348013) 	mov.b32 	%r79, 0f43E00000;
(EngineCore_DP0 pid=348013) 	.loc	1 194 32                        // quant_slide_tuned_Llama3.2-1B.py:194:32
(EngineCore_DP0 pid=348013) 	div.full.f32 	%r80, %r125, %r79;
(EngineCore_DP0 pid=348013) 	.loc	1 194 41                        // quant_slide_tuned_Llama3.2-1B.py:194:41
(EngineCore_DP0 pid=348013) 	max.f32 	%r78, %r80, 0f36924925;
(EngineCore_DP0 pid=348013) 	.loc	1 196 25                        // quant_slide_tuned_Llama3.2-1B.py:196:25
(EngineCore_DP0 pid=348013) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=348013) 	.loc	1 196 30                        // quant_slide_tuned_Llama3.2-1B.py:196:30
(EngineCore_DP0 pid=348013) 	// begin inline asm
(EngineCore_DP0 pid=348013) 	@%p20 st.global.b32 [ %rd8 + 0 ], { %r78 };
(EngineCore_DP0 pid=348013) 	// end inline asm
(EngineCore_DP0 pid=348013) 	.loc	1 199 29                        // quant_slide_tuned_Llama3.2-1B.py:199:29
(EngineCore_DP0 pid=348013) 	shl.b32 	%r15, %r20, 2;
(EngineCore_DP0 pid=348013) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=348013) 	setp.lt.s32 	%p9, %r15, 1;
(EngineCore_DP0 pid=348013) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=348013) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=348013) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=348013) 	ld.param.b32 	%r24, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=348013) 	shr.s32 	%r25, %r24, 31;
(EngineCore_DP0 pid=348013) 	shr.u32 	%r26, %r25, 30;
(EngineCore_DP0 pid=348013) 	add.s32 	%r27, %r24, %r26;
(EngineCore_DP0 pid=348013) 	shr.s32 	%r28, %r27, 2;
(EngineCore_DP0 pid=348013) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=348013) 	mul.lo.s32 	%r29, %r28, %r1;
(EngineCore_DP0 pid=348013) 	mad.wide.s32 	%rd2, %r29, 4, %rd5;
(EngineCore_DP0 pid=348013) 	div.full.f32 	%r14, %r79, %r125;
(EngineCore_DP0 pid=348013) 	mov.b32 	%r126, 0;
(EngineCore_DP0 pid=348013) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=348013)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=348013) 	.loc	1 203 30                        // quant_slide_tuned_Llama3.2-1B.py:203:30
(EngineCore_DP0 pid=348013) 	add.s32 	%r92, %r3, %r126;
(EngineCore_DP0 pid=348013) 	setp.lt.s32 	%p14, %r92, %r15;
(EngineCore_DP0 pid=348013) 	.loc	1 206 24                        // quant_slide_tuned_Llama3.2-1B.py:206:24
(EngineCore_DP0 pid=348013) 	shr.s32 	%r93, %r92, 31;
(EngineCore_DP0 pid=348013) 	shr.u32 	%r94, %r93, 30;
(EngineCore_DP0 pid=348013) 	add.s32 	%r95, %r92, %r94;
(EngineCore_DP0 pid=348013) 	shr.s32 	%r96, %r95, 2;
(EngineCore_DP0 pid=348013) 	.loc	1 207 23                        // quant_slide_tuned_Llama3.2-1B.py:207:23
(EngineCore_DP0 pid=348013) 	and.b32 	%r97, %r95, 2147483644;
(EngineCore_DP0 pid=348013) 	sub.s32 	%r98, %r92, %r97;
(EngineCore_DP0 pid=348013) 	.loc	1 208 30                        // quant_slide_tuned_Llama3.2-1B.py:208:30
(EngineCore_DP0 pid=348013) 	shl.b32 	%r99, %r98, 1;
(EngineCore_DP0 pid=348013) 	.loc	1 208 26                        // quant_slide_tuned_Llama3.2-1B.py:208:26
(EngineCore_DP0 pid=348013) 	mad.lo.s32 	%r100, %r96, 10, %r99;
(EngineCore_DP0 pid=348013) 	.loc	1 211 53                        // quant_slide_tuned_Llama3.2-1B.py:211:53
(EngineCore_DP0 pid=348013) 	setp.lt.s32 	%p15, %r100, %r18;
(EngineCore_DP0 pid=348013) 	.loc	1 211 37                        // quant_slide_tuned_Llama3.2-1B.py:211:37
(EngineCore_DP0 pid=348013) 	and.pred 	%p10, %p14, %p15;
(EngineCore_DP0 pid=348013) 	.loc	1 210 29                        // quant_slide_tuned_Llama3.2-1B.py:210:29
(EngineCore_DP0 pid=348013) 	mad.wide.s32 	%rd9, %r100, 2, %rd1;
(EngineCore_DP0 pid=348013) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=348013) 	.loc	1 210 21                        // quant_slide_tuned_Llama3.2-1B.py:210:21
(EngineCore_DP0 pid=348013) 	// begin inline asm
(EngineCore_DP0 pid=348013) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=348013) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=348013) 	// end inline asm
(EngineCore_DP0 pid=348013) 	.loc	1 211 79                        // quant_slide_tuned_Llama3.2-1B.py:211:79
(EngineCore_DP0 pid=348013) 	cvt.f32.bf16 	%r101, %rs48;
(EngineCore_DP0 pid=348013) 	.loc	1 213 48                        // quant_slide_tuned_Llama3.2-1B.py:213:48
(EngineCore_DP0 pid=348013) 	or.b32 	%r102, %r100, 1;
(EngineCore_DP0 pid=348013) 	.loc	1 213 53                        // quant_slide_tuned_Llama3.2-1B.py:213:53
(EngineCore_DP0 pid=348013) 	setp.lt.s32 	%p16, %r102, %r18;
(EngineCore_DP0 pid=348013) 	.loc	1 213 37                        // quant_slide_tuned_Llama3.2-1B.py:213:37
(EngineCore_DP0 pid=348013) 	and.pred 	%p11, %p14, %p16;
(EngineCore_DP0 pid=348013) 	.loc	1 212 39                        // quant_slide_tuned_Llama3.2-1B.py:212:39
(EngineCore_DP0 pid=348013) 	add.s64 	%rd10, %rd9, 2;
(EngineCore_DP0 pid=348013) 	.loc	1 212 21                        // quant_slide_tuned_Llama3.2-1B.py:212:21
(EngineCore_DP0 pid=348013) 	// begin inline asm
(EngineCore_DP0 pid=348013) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=348013) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=348013) 	// end inline asm
(EngineCore_DP0 pid=348013) 	.loc	1 213 79                        // quant_slide_tuned_Llama3.2-1B.py:213:79
(EngineCore_DP0 pid=348013) 	cvt.f32.bf16 	%r103, %rs50;
(EngineCore_DP0 pid=348013) 	.loc	1 215 48                        // quant_slide_tuned_Llama3.2-1B.py:215:48
(EngineCore_DP0 pid=348013) 	add.s32 	%r104, %r100, 2;
(EngineCore_DP0 pid=348013) 	.loc	1 215 53                        // quant_slide_tuned_Llama3.2-1B.py:215:53
(EngineCore_DP0 pid=348013) 	setp.lt.s32 	%p17, %r104, %r18;
(EngineCore_DP0 pid=348013) 	.loc	1 215 37                        // quant_slide_tuned_Llama3.2-1B.py:215:37
(EngineCore_DP0 pid=348013) 	and.pred 	%p12, %p14, %p17;
(EngineCore_DP0 pid=348013) 	.loc	1 214 39                        // quant_slide_tuned_Llama3.2-1B.py:214:39
(EngineCore_DP0 pid=348013) 	add.s64 	%rd11, %rd9, 4;
(EngineCore_DP0 pid=348013) 	.loc	1 214 21                        // quant_slide_tuned_Llama3.2-1B.py:214:21
(EngineCore_DP0 pid=348013) 	// begin inline asm
(EngineCore_DP0 pid=348013) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=348013) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=348013) 	// end inline asm
(EngineCore_DP0 pid=348013) 	.loc	1 215 79                        // quant_slide_tuned_Llama3.2-1B.py:215:79
(EngineCore_DP0 pid=348013) 	cvt.f32.bf16 	%r105, %rs52;
(EngineCore_DP0 pid=348013) 	.loc	1 217 48                        // quant_slide_tuned_Llama3.2-1B.py:217:48
(EngineCore_DP0 pid=348013) 	add.s32 	%r106, %r100, 3;
(EngineCore_DP0 pid=348013) 	.loc	1 217 53                        // quant_slide_tuned_Llama3.2-1B.py:217:53
(EngineCore_DP0 pid=348013) 	setp.lt.s32 	%p18, %r106, %r18;
(EngineCore_DP0 pid=348013) 	.loc	1 217 37                        // quant_slide_tuned_Llama3.2-1B.py:217:37
(EngineCore_DP0 pid=348013) 	and.pred 	%p13, %p14, %p18;
(EngineCore_DP0 pid=348013) 	.loc	1 216 39                        // quant_slide_tuned_Llama3.2-1B.py:216:39
(EngineCore_DP0 pid=348013) 	add.s64 	%rd12, %rd9, 6;
(EngineCore_DP0 pid=348013) 	.loc	1 216 21                        // quant_slide_tuned_Llama3.2-1B.py:216:21
(EngineCore_DP0 pid=348013) 	// begin inline asm
(EngineCore_DP0 pid=348013) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=348013) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=348013) 	// end inline asm
(EngineCore_DP0 pid=348013) 	.loc	1 217 79                        // quant_slide_tuned_Llama3.2-1B.py:217:79
(EngineCore_DP0 pid=348013) 	cvt.f32.bf16 	%r107, %rs54;
(EngineCore_DP0 pid=348013) 	.loc	1 219 27                        // quant_slide_tuned_Llama3.2-1B.py:219:27
(EngineCore_DP0 pid=348013) 	mul.f32 	%r108, %r14, %r101;
(EngineCore_DP0 pid=348013) 	mov.b32 	%r109, 0f43E00000;
(EngineCore_DP0 pid=348013) 	.loc	1 219 48                        // quant_slide_tuned_Llama3.2-1B.py:219:48
(EngineCore_DP0 pid=348013) 	min.xorsign.abs.f32 	%r82, %r108, %r109;
(EngineCore_DP0 pid=348013) 	.loc	1 219 60                        // quant_slide_tuned_Llama3.2-1B.py:219:60
(EngineCore_DP0 pid=348013) 	// begin inline asm
(EngineCore_DP0 pid=348013) 	cvt.rn.satfinite.e4m3x2.f32  %rs56, %r83, %r82; 
(EngineCore_DP0 pid=348013) 
(EngineCore_DP0 pid=348013) 	// end inline asm
(EngineCore_DP0 pid=348013) 	.loc	1 220 27                        // quant_slide_tuned_Llama3.2-1B.py:220:27
(EngineCore_DP0 pid=348013) 	mul.f32 	%r110, %r14, %r103;
(EngineCore_DP0 pid=348013) 	.loc	1 220 48                        // quant_slide_tuned_Llama3.2-1B.py:220:48
(EngineCore_DP0 pid=348013) 	min.xorsign.abs.f32 	%r84, %r110, %r109;
(EngineCore_DP0 pid=348013) 	.loc	1 220 60                        // quant_slide_tuned_Llama3.2-1B.py:220:60
(EngineCore_DP0 pid=348013) 	// begin inline asm
(EngineCore_DP0 pid=348013) 	cvt.rn.satfinite.e4m3x2.f32  %rs57, %r85, %r84; 
(EngineCore_DP0 pid=348013) 
(EngineCore_DP0 pid=348013) 	// end inline asm
(EngineCore_DP0 pid=348013) 	.loc	1 221 27                        // quant_slide_tuned_Llama3.2-1B.py:221:27
(EngineCore_DP0 pid=348013) 	mul.f32 	%r111, %r14, %r105;
(EngineCore_DP0 pid=348013) 	.loc	1 221 48                        // quant_slide_tuned_Llama3.2-1B.py:221:48
(EngineCore_DP0 pid=348013) 	min.xorsign.abs.f32 	%r86, %r111, %r109;
(EngineCore_DP0 pid=348013) 	.loc	1 221 60                        // quant_slide_tuned_Llama3.2-1B.py:221:60
(EngineCore_DP0 pid=348013) 	// begin inline asm
(EngineCore_DP0 pid=348013) 	cvt.rn.satfinite.e4m3x2.f32  %rs58, %r87, %r86; 
(EngineCore_DP0 pid=348013) 
(EngineCore_DP0 pid=348013) 	// end inline asm
(EngineCore_DP0 pid=348013) 	.loc	1 222 27                        // quant_slide_tuned_Llama3.2-1B.py:222:27
(EngineCore_DP0 pid=348013) 	mul.f32 	%r112, %r14, %r107;
(EngineCore_DP0 pid=348013) 	.loc	1 222 48                        // quant_slide_tuned_Llama3.2-1B.py:222:48
(EngineCore_DP0 pid=348013) 	min.xorsign.abs.f32 	%r88, %r112, %r109;
(EngineCore_DP0 pid=348013) 	.loc	1 222 60                        // quant_slide_tuned_Llama3.2-1B.py:222:60
(EngineCore_DP0 pid=348013) 	// begin inline asm
(EngineCore_DP0 pid=348013) 	cvt.rn.satfinite.e4m3x2.f32  %rs59, %r89, %r88; 
(EngineCore_DP0 pid=348013) 
(EngineCore_DP0 pid=348013) 	// end inline asm
(EngineCore_DP0 pid=348013) 	.loc	1 224 45                        // quant_slide_tuned_Llama3.2-1B.py:224:45
(EngineCore_DP0 pid=348013) 	cvt.u32.u16 	%r113, %rs56;
(EngineCore_DP0 pid=348013) 	and.b32 	%r114, %r113, 255;
(EngineCore_DP0 pid=348013) 	.loc	1 226 45                        // quant_slide_tuned_Llama3.2-1B.py:226:45
(EngineCore_DP0 pid=348013) 	cvt.u32.u16 	%r115, %rs58;
(EngineCore_DP0 pid=348013) 	and.b32 	%r116, %r115, 255;
(EngineCore_DP0 pid=348013) 	.loc	1 227 45                        // quant_slide_tuned_Llama3.2-1B.py:227:45
(EngineCore_DP0 pid=348013) 	cvt.u32.u16 	%r117, %rs59;
(EngineCore_DP0 pid=348013) 	.loc	1 229 30                        // quant_slide_tuned_Llama3.2-1B.py:229:30
(EngineCore_DP0 pid=348013) 	and.b16 	%rs60, %rs57, 255;
(EngineCore_DP0 pid=348013) 	mul.wide.u16 	%r118, %rs60, 256;
(EngineCore_DP0 pid=348013) 	.loc	1 229 24                        // quant_slide_tuned_Llama3.2-1B.py:229:24
(EngineCore_DP0 pid=348013) 	or.b32 	%r119, %r118, %r114;
(EngineCore_DP0 pid=348013) 	.loc	1 229 42                        // quant_slide_tuned_Llama3.2-1B.py:229:42
(EngineCore_DP0 pid=348013) 	shl.b32 	%r120, %r116, 16;
(EngineCore_DP0 pid=348013) 	.loc	1 229 36                        // quant_slide_tuned_Llama3.2-1B.py:229:36
(EngineCore_DP0 pid=348013) 	or.b32 	%r121, %r119, %r120;
(EngineCore_DP0 pid=348013) 	.loc	1 229 55                        // quant_slide_tuned_Llama3.2-1B.py:229:55
(EngineCore_DP0 pid=348013) 	shl.b32 	%r122, %r117, 24;
(EngineCore_DP0 pid=348013) 	.loc	1 229 49                        // quant_slide_tuned_Llama3.2-1B.py:229:49
(EngineCore_DP0 pid=348013) 	or.b32 	%r90, %r121, %r122;
(EngineCore_DP0 pid=348013) 	.loc	1 230 29                        // quant_slide_tuned_Llama3.2-1B.py:230:29
(EngineCore_DP0 pid=348013) 	mad.wide.s32 	%rd13, %r92, 4, %rd2;
(EngineCore_DP0 pid=348013) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-1B.py:230:39
(EngineCore_DP0 pid=348013) 	// begin inline asm
(EngineCore_DP0 pid=348013) 	@%p14 st.global.b32 [ %rd13 + 0 ], { %r90 };
(EngineCore_DP0 pid=348013) 	// end inline asm
(EngineCore_DP0 pid=348013) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=348013) 	add.s32 	%r126, %r126, 512;
(EngineCore_DP0 pid=348013) 	setp.lt.s32 	%p19, %r126, %r15;
(EngineCore_DP0 pid=348013) 	@%p19 bra 	$L__BB0_6;
(EngineCore_DP0 pid=348013) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=348013) 	.loc	1 201 4                         // quant_slide_tuned_Llama3.2-1B.py:201:4
(EngineCore_DP0 pid=348013) 	ret;
(EngineCore_DP0 pid=348013) $L__tmp3:
(EngineCore_DP0 pid=348013) $L__func_end0:
(EngineCore_DP0 pid=348013)                                         // -- End function
(EngineCore_DP0 pid=348013) }
(EngineCore_DP0 pid=348013) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=348013) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=348013) 	.section	.debug_abbrev
(EngineCore_DP0 pid=348013) 	{
(EngineCore_DP0 pid=348013) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=348013) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=348013) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=348013) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=348013) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=348013) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=348013) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=348013) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=348013) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=348013) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=348013) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=348013) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=348013) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=348013) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=348013) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=348013) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=348013) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=348013) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=348013) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=348013) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=348013) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=348013) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=348013) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=348013) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=348013) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=348013) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=348013) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=348013) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=348013) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=348013) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=348013) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=348013) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=348013) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=348013) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=348013) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=348013) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=348013) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=348013) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=348013) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=348013) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=348013) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=348013) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=348013) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=348013) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=348013) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=348013) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=348013) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=348013) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=348013) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=348013) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=348013) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=348013) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=348013) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=348013) 	}
(EngineCore_DP0 pid=348013) 	.section	.debug_info
(EngineCore_DP0 pid=348013) 	{
(EngineCore_DP0 pid=348013) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=348013) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=348013) .b8 0
(EngineCore_DP0 pid=348013) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=348013) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=348013) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=348013) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=348013) .b8 114
(EngineCore_DP0 pid=348013) .b8 105
(EngineCore_DP0 pid=348013) .b8 116
(EngineCore_DP0 pid=348013) .b8 111
(EngineCore_DP0 pid=348013) .b8 110
(EngineCore_DP0 pid=348013) .b8 0
(EngineCore_DP0 pid=348013) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=348013) .b8 0
(EngineCore_DP0 pid=348013) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=348013) .b8 117
(EngineCore_DP0 pid=348013) .b8 97
(EngineCore_DP0 pid=348013) .b8 110
(EngineCore_DP0 pid=348013) .b8 116
(EngineCore_DP0 pid=348013) .b8 95
(EngineCore_DP0 pid=348013) .b8 115
(EngineCore_DP0 pid=348013) .b8 108
(EngineCore_DP0 pid=348013) .b8 105
(EngineCore_DP0 pid=348013) .b8 100
(EngineCore_DP0 pid=348013) .b8 101
(EngineCore_DP0 pid=348013) .b8 95
(EngineCore_DP0 pid=348013) .b8 116
(EngineCore_DP0 pid=348013) .b8 117
(EngineCore_DP0 pid=348013) .b8 110
(EngineCore_DP0 pid=348013) .b8 101
(EngineCore_DP0 pid=348013) .b8 100
(EngineCore_DP0 pid=348013) .b8 95
(EngineCore_DP0 pid=348013) .b8 76
(EngineCore_DP0 pid=348013) .b8 108
(EngineCore_DP0 pid=348013) .b8 97
(EngineCore_DP0 pid=348013) .b8 109
(EngineCore_DP0 pid=348013) .b8 97
(EngineCore_DP0 pid=348013) .b8 51
(EngineCore_DP0 pid=348013) .b8 46
(EngineCore_DP0 pid=348013) .b8 50
(EngineCore_DP0 pid=348013) .b8 45
(EngineCore_DP0 pid=348013) .b8 49
(EngineCore_DP0 pid=348013) .b8 66
(EngineCore_DP0 pid=348013) .b8 46
(EngineCore_DP0 pid=348013) .b8 112
(EngineCore_DP0 pid=348013) .b8 121
(EngineCore_DP0 pid=348013) .b8 0
(EngineCore_DP0 pid=348013) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=348013) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=348013) .b8 114
(EngineCore_DP0 pid=348013) .b8 111
(EngineCore_DP0 pid=348013) .b8 111
(EngineCore_DP0 pid=348013) .b8 116
(EngineCore_DP0 pid=348013) .b8 47
(EngineCore_DP0 pid=348013) .b8 118
(EngineCore_DP0 pid=348013) .b8 108
(EngineCore_DP0 pid=348013) .b8 108
(EngineCore_DP0 pid=348013) .b8 109
(EngineCore_DP0 pid=348013) .b8 98
(EngineCore_DP0 pid=348013) .b8 101
(EngineCore_DP0 pid=348013) .b8 110
(EngineCore_DP0 pid=348013) .b8 99
(EngineCore_DP0 pid=348013) .b8 104
(EngineCore_DP0 pid=348013) .b8 47
(EngineCore_DP0 pid=348013) .b8 115
(EngineCore_DP0 pid=348013) .b8 108
(EngineCore_DP0 pid=348013) .b8 105
(EngineCore_DP0 pid=348013) .b8 100
(EngineCore_DP0 pid=348013) .b8 101
(EngineCore_DP0 pid=348013) .b8 115
(EngineCore_DP0 pid=348013) .b8 112
(EngineCore_DP0 pid=348013) .b8 97
(EngineCore_DP0 pid=348013) .b8 114
(EngineCore_DP0 pid=348013) .b8 115
(EngineCore_DP0 pid=348013) .b8 101
(EngineCore_DP0 pid=348013) .b8 47
(EngineCore_DP0 pid=348013) .b8 99
(EngineCore_DP0 pid=348013) .b8 115
(EngineCore_DP0 pid=348013) .b8 114
(EngineCore_DP0 pid=348013) .b8 99
(EngineCore_DP0 pid=348013) .b8 47
(EngineCore_DP0 pid=348013) .b8 102
(EngineCore_DP0 pid=348013) .b8 117
(EngineCore_DP0 pid=348013) .b8 115
(EngineCore_DP0 pid=348013) .b8 101
(EngineCore_DP0 pid=348013) .b8 100
(EngineCore_DP0 pid=348013) .b8 95
(EngineCore_DP0 pid=348013) .b8 113
(EngineCore_DP0 pid=348013) .b8 117
(EngineCore_DP0 pid=348013) .b8 97
(EngineCore_DP0 pid=348013) .b8 110
(EngineCore_DP0 pid=348013) .b8 116
(EngineCore_DP0 pid=348013) .b8 95
(EngineCore_DP0 pid=348013) .b8 115
(EngineCore_DP0 pid=348013) .b8 108
(EngineCore_DP0 pid=348013) .b8 105
(EngineCore_DP0 pid=348013) .b8 100
(EngineCore_DP0 pid=348013) .b8 101
(EngineCore_DP0 pid=348013) .b8 95
(EngineCore_DP0 pid=348013) .b8 116
(EngineCore_DP0 pid=348013) .b8 114
(EngineCore_DP0 pid=348013) .b8 105
(EngineCore_DP0 pid=348013) .b8 116
(EngineCore_DP0 pid=348013) .b8 111
(EngineCore_DP0 pid=348013) .b8 110
(EngineCore_DP0 pid=348013) .b8 47
(EngineCore_DP0 pid=348013) .b8 98
(EngineCore_DP0 pid=348013) .b8 117
(EngineCore_DP0 pid=348013) .b8 105
(EngineCore_DP0 pid=348013) .b8 108
(EngineCore_DP0 pid=348013) .b8 100
(EngineCore_DP0 pid=348013) .b8 47
(EngineCore_DP0 pid=348013) .b8 71
(EngineCore_DP0 pid=348013) .b8 66
(EngineCore_DP0 pid=348013) .b8 49
(EngineCore_DP0 pid=348013) .b8 48
(EngineCore_DP0 pid=348013) .b8 95
(EngineCore_DP0 pid=348013) .b8 99
(EngineCore_DP0 pid=348013) .b8 99
(EngineCore_DP0 pid=348013) .b8 49
(EngineCore_DP0 pid=348013) .b8 50
(EngineCore_DP0 pid=348013) .b8 49
(EngineCore_DP0 pid=348013) .b8 95
(EngineCore_DP0 pid=348013) .b8 112
(EngineCore_DP0 pid=348013) .b8 121
(EngineCore_DP0 pid=348013) .b8 51
(EngineCore_DP0 pid=348013) .b8 49
(EngineCore_DP0 pid=348013) .b8 50
(EngineCore_DP0 pid=348013) .b8 95
(EngineCore_DP0 pid=348013) .b8 99
(EngineCore_DP0 pid=348013) .b8 117
(EngineCore_DP0 pid=348013) .b8 49
(EngineCore_DP0 pid=348013) .b8 50
(EngineCore_DP0 pid=348013) .b8 57
(EngineCore_DP0 pid=348013) .b8 95
(EngineCore_DP0 pid=348013) .b8 97
(EngineCore_DP0 pid=348013) .b8 97
(EngineCore_DP0 pid=348013) .b8 114
(EngineCore_DP0 pid=348013) .b8 99
(EngineCore_DP0 pid=348013) .b8 104
(EngineCore_DP0 pid=348013) .b8 54
(EngineCore_DP0 pid=348013) .b8 52
(EngineCore_DP0 pid=348013) .b8 0
(EngineCore_DP0 pid=348013) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=348013) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=348013) .b8 113
(EngineCore_DP0 pid=348013) .b8 117
(EngineCore_DP0 pid=348013) .b8 97
(EngineCore_DP0 pid=348013) .b8 110
(EngineCore_DP0 pid=348013) .b8 116
(EngineCore_DP0 pid=348013) .b8 95
(EngineCore_DP0 pid=348013) .b8 115
(EngineCore_DP0 pid=348013) .b8 108
(EngineCore_DP0 pid=348013) .b8 105
(EngineCore_DP0 pid=348013) .b8 100
(EngineCore_DP0 pid=348013) .b8 101
(EngineCore_DP0 pid=348013) .b8 95
(EngineCore_DP0 pid=348013) .b8 102
(EngineCore_DP0 pid=348013) .b8 112
(EngineCore_DP0 pid=348013) .b8 56
(EngineCore_DP0 pid=348013) .b8 95
(EngineCore_DP0 pid=348013) .b8 107
(EngineCore_DP0 pid=348013) .b8 101
(EngineCore_DP0 pid=348013) .b8 114
(EngineCore_DP0 pid=348013) .b8 110
(EngineCore_DP0 pid=348013) .b8 101
(EngineCore_DP0 pid=348013) .b8 108
(EngineCore_DP0 pid=348013) .b8 0
(EngineCore_DP0 pid=348013) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=348013) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=348013) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=348013) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=348013) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=348013) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=348013) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=348013) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=348013) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=348013) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=348013) .b8 191                                 // DW_AT_call_line
(EngineCore_DP0 pid=348013) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=348013) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=348013) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=348013) 	}
(EngineCore_DP0 pid=348013) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=348013) 
(EngineCore_DP0 pid=348013) ================================================================
(EngineCore_DP0 pid=348013) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=348013) 
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpxveqvkd0.ptx', '-o', '/tmp/tmpxveqvkd0.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866] 
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866] 
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866] 
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpxveqvkd0.ptx -o /tmp/tmpxveqvkd0.ptx.o
(EngineCore_DP0 pid=348013) ERROR 01-25 19:25:16 [core.py:866] 

STDERR:
[2026-01-25 19:24:59] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:24:59] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:24:59] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:24:59] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:24:59] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:24:59] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:24:59] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:24:59] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:24:59] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:24:59] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:24:59] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:24:59] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:24:59] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:24:59] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:25:02] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:25:02] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:25:02] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:25:02] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:25:02] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:25:02] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:25:02] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:25:02] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:25:02] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:25:02] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:25:02] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:25:02] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:25:02] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:25:02] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=348013) [2026-01-25 19:25:03] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=348013) [2026-01-25 19:25:03] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=348013) [2026-01-25 19:25:03] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=348013) [2026-01-25 19:25:03] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=348013) [2026-01-25 19:25:03] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=348013) [2026-01-25 19:25:03] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=348013) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=348013) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.84s/it]
(EngineCore_DP0 pid=348013) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.84s/it]
(EngineCore_DP0 pid=348013) 
(EngineCore_DP0 pid=348013) [2026-01-25 19:25:15] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=348013) [2026-01-25 19:25:15] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6340608 bytes
(EngineCore_DP0 pid=348013) [2026-01-25 19:25:15] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=348013) [2026-01-25 19:25:15] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 4227072 bytes
(EngineCore_DP0 pid=348013) [2026-01-25 19:25:15] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=348013) [2026-01-25 19:25:15] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 33816576 bytes
(EngineCore_DP0 pid=348013) [2026-01-25 19:25:15] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=348013) [2026-01-25 19:25:15] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16809984 bytes
(EngineCore_DP0 pid=348013) Process EngineCore_DP0:
(EngineCore_DP0 pid=348013) Traceback (most recent call last):
(EngineCore_DP0 pid=348013)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=348013)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=348013)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=348013)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=348013) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpxveqvkd0.ptx', '-o', '/tmp/tmpxveqvkd0.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=348013) 
(EngineCore_DP0 pid=348013) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=348013) 
(EngineCore_DP0 pid=348013) Traceback (most recent call last):
(EngineCore_DP0 pid=348013)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=348013)     self.run()
(EngineCore_DP0 pid=348013)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=348013)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=348013)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=348013)     raise e
(EngineCore_DP0 pid=348013)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=348013)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=348013)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=348013)     super().__init__(
(EngineCore_DP0 pid=348013)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=348013)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=348013)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=348013)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=348013)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=348013)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=348013)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=348013)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=348013)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=348013)     return func(*args, **kwargs)
(EngineCore_DP0 pid=348013)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=348013)     return func(*args, **kwargs)
(EngineCore_DP0 pid=348013)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=348013)     self.model_runner.profile_run()
(EngineCore_DP0 pid=348013)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=348013)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=348013)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=348013)     return func(*args, **kwargs)
(EngineCore_DP0 pid=348013)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=348013)     outputs = self.model(
(EngineCore_DP0 pid=348013)               ^^^^^^^^^^^
(EngineCore_DP0 pid=348013)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=348013)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=348013)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=348013)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=348013)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=348013)     model_output = self.model(
(EngineCore_DP0 pid=348013)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=348013)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=348013)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=348013)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=348013)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=348013)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=348013)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=348013)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=348013)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=348013)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=348013)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=348013)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=348013)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=348013)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=348013)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=348013)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=348013)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=348013)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=348013)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=348013)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=348013)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=348013)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=348013)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=348013)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=348013)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=348013)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=348013)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=348013)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=348013)     return self._linear_fn(
(EngineCore_DP0 pid=348013)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=348013)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=348013)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=348013)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=348013)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=348013)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=348013)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=348013)     return fn(input, L)
(EngineCore_DP0 pid=348013)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=348013)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=348013)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=348013)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=348013)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=348013)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=348013)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=348013)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=348013)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=348013)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=348013)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=348013)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=348013)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=348013)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348013)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=348013)     raise PTXASError(error)
(EngineCore_DP0 pid=348013) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=348013) `ptxas` stderr:
(EngineCore_DP0 pid=348013) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=348013) 
(EngineCore_DP0 pid=348013) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpxveqvkd0.ptx -o /tmp/tmpxveqvkd0.ptx.o
(EngineCore_DP0 pid=348013) 
[rank0]:[W125 19:25:16.624450204 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=4096

========== M=8192 ==========
Time: 2026-01-25 19:25:17
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-1B-FP8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:25:24 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:25:24 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=348551) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=348551) 
(EngineCore_DP0 pid=348551) 
(EngineCore_DP0 pid=348551) ================================================================
(EngineCore_DP0 pid=348551) Internal Triton PTX codegen error
(EngineCore_DP0 pid=348551) `ptxas` stderr:
(EngineCore_DP0 pid=348551) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=348551) 
(EngineCore_DP0 pid=348551) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpvwpzwap5.ptx -o /tmp/tmpvwpzwap5.ptx.o
(EngineCore_DP0 pid=348551) 
(EngineCore_DP0 pid=348551) 
(EngineCore_DP0 pid=348551) //
(EngineCore_DP0 pid=348551) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=348551) //
(EngineCore_DP0 pid=348551) 
(EngineCore_DP0 pid=348551) .version 8.7
(EngineCore_DP0 pid=348551) .target sm_121a
(EngineCore_DP0 pid=348551) .address_size 64
(EngineCore_DP0 pid=348551) 
(EngineCore_DP0 pid=348551) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=348551) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=348551)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=348551) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=348551) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=348551) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=348551) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=348551) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=348551) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=348551) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=348551) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=348551) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=348551) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=348551) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=348551) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=348551) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=348551) )
(EngineCore_DP0 pid=348551) .reqntid 512
(EngineCore_DP0 pid=348551) {
(EngineCore_DP0 pid=348551) 	.reg .pred 	%p<44>;
(EngineCore_DP0 pid=348551) 	.reg .b16 	%rs<74>;
(EngineCore_DP0 pid=348551) 	.reg .b32 	%r<212>;
(EngineCore_DP0 pid=348551) 	.reg .b64 	%rd<25>;
(EngineCore_DP0 pid=348551) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=348551) $L__func_begin0:
(EngineCore_DP0 pid=348551) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=348551) 
(EngineCore_DP0 pid=348551) // %bb.0:
(EngineCore_DP0 pid=348551) 	ld.param.b32 	%r29, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=348551) 	ld.param.b32 	%r28, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=348551) 	ld.param.b32 	%r27, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=348551) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=348551) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=348551) $L__tmp0:
(EngineCore_DP0 pid=348551) 	.loc	1 177 24                        // quant_slide_tuned_Llama3.2-1B.py:177:24
(EngineCore_DP0 pid=348551) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=348551) 	ld.param.b32 	%r31, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=348551) 	.loc	1 182 26                        // quant_slide_tuned_Llama3.2-1B.py:182:26
(EngineCore_DP0 pid=348551) 	mul.lo.s32 	%r32, %r31, %r1;
(EngineCore_DP0 pid=348551) 	.loc	1 182 20                        // quant_slide_tuned_Llama3.2-1B.py:182:20
(EngineCore_DP0 pid=348551) 	mad.wide.s32 	%rd1, %r32, 2, %rd4;
(EngineCore_DP0 pid=348551) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=348551) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=348551) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=348551) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=348551) 	setp.lt.s32 	%p1, %r28, 1;
(EngineCore_DP0 pid=348551) 	mov.b32 	%r210, 0f2B8CBCCC;
(EngineCore_DP0 pid=348551) 	setp.eq.b32 	%p43, %r2, 0;
(EngineCore_DP0 pid=348551) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=348551) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=348551) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=348551) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=348551) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=348551) 	shr.u32 	%r41, %r2, 3;
(EngineCore_DP0 pid=348551) 	and.b32 	%r42, %r41, 60;
(EngineCore_DP0 pid=348551) 	mov.b32 	%r43, global_smem;
(EngineCore_DP0 pid=348551) 	add.s32 	%r53, %r43, %r42;
(EngineCore_DP0 pid=348551) 	shl.b32 	%r44, %r2, 2;
(EngineCore_DP0 pid=348551) 	add.s32 	%r56, %r43, %r44;
(EngineCore_DP0 pid=348551) 	mov.b32 	%r49, 0;
(EngineCore_DP0 pid=348551) 	mov.b32 	%r208, 0f00000000;
(EngineCore_DP0 pid=348551) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=348551) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=348551) 	mov.b32 	%r209, %r49;
(EngineCore_DP0 pid=348551) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=348551) 	.loc	1 189 22                        // quant_slide_tuned_Llama3.2-1B.py:189:22
(EngineCore_DP0 pid=348551) 	add.s32 	%r59, %r4, %r209;
(EngineCore_DP0 pid=348551) 	setp.lt.s32 	%p2, %r59, %r27;
(EngineCore_DP0 pid=348551) 	.loc	1 190 29                        // quant_slide_tuned_Llama3.2-1B.py:190:29
(EngineCore_DP0 pid=348551) 	mad.wide.s32 	%rd6, %r59, 2, %rd1;
(EngineCore_DP0 pid=348551) 	.loc	1 190 21                        // quant_slide_tuned_Llama3.2-1B.py:190:21
(EngineCore_DP0 pid=348551) 	// begin inline asm
(EngineCore_DP0 pid=348551) 	mov.u32 %r45, %r49;
(EngineCore_DP0 pid=348551) 	mov.u32 %r46, %r49;
(EngineCore_DP0 pid=348551) 	mov.u32 %r47, %r49;
(EngineCore_DP0 pid=348551) 	mov.u32 %r48, %r49;
(EngineCore_DP0 pid=348551) 	@%p2 ld.global.v4.b32 { %r45, %r46, %r47, %r48 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=348551) 	// end inline asm
(EngineCore_DP0 pid=348551) 	mov.b32 	{%rs1, %rs2}, %r45;
(EngineCore_DP0 pid=348551) 	mov.b32 	{%rs3, %rs4}, %r46;
(EngineCore_DP0 pid=348551) 	mov.b32 	{%rs5, %rs6}, %r47;
(EngineCore_DP0 pid=348551) 	mov.b32 	{%rs7, %rs8}, %r48;
(EngineCore_DP0 pid=348551) 	.loc	1 191 50                        // quant_slide_tuned_Llama3.2-1B.py:191:50
(EngineCore_DP0 pid=348551) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=348551) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=348551) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=348551) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=348551) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=348551) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=348551) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=348551) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=348551) $L__tmp1:
(EngineCore_DP0 pid=348551) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=348551) 	bar.sync 	0;
(EngineCore_DP0 pid=348551) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=348551) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=348551) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=348551) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=348551) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=348551) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=348551) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=348551) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=348551) 	cvt.f32.bf16 	%r60, %rs23;
(EngineCore_DP0 pid=348551) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=348551) 	shfl.sync.bfly.b32 	%r61, %r60, 16, 31, -1;
(EngineCore_DP0 pid=348551) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=348551) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=348551) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=348551) 	shfl.sync.bfly.b32 	%r63, %r62, 8, 31, -1;
(EngineCore_DP0 pid=348551) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=348551) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=348551) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=348551) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=348551) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=348551) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=348551) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=348551) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=348551) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=348551) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=348551) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=348551) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=348551) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=348551) 	max.f32 	%r54, %r68, %r69;
(EngineCore_DP0 pid=348551) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=348551) 	// begin inline asm
(EngineCore_DP0 pid=348551) 	@%p3 st.shared.b32 [ %r53 + 0 ], %r54;
(EngineCore_DP0 pid=348551) 	// end inline asm
(EngineCore_DP0 pid=348551) 	bar.sync 	0;
(EngineCore_DP0 pid=348551) 	// begin inline asm
(EngineCore_DP0 pid=348551) 	@%p4 ld.shared.b32 %r55, [ %r56 + 0 ];
(EngineCore_DP0 pid=348551) 	// end inline asm
(EngineCore_DP0 pid=348551) 	shfl.sync.bfly.b32 	%r70, %r55, 8, 31, -1;
(EngineCore_DP0 pid=348551) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=348551) 	max.f32 	%r71, %r55, %r70;
(EngineCore_DP0 pid=348551) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=348551) 	shfl.sync.bfly.b32 	%r72, %r71, 4, 31, -1;
(EngineCore_DP0 pid=348551) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=348551) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=348551) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=348551) 	shfl.sync.bfly.b32 	%r74, %r73, 2, 31, -1;
(EngineCore_DP0 pid=348551) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=348551) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=348551) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=348551) 	shfl.sync.bfly.b32 	%r76, %r75, 1, 31, -1;
(EngineCore_DP0 pid=348551) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=348551) 	max.f32 	%r58, %r75, %r76;
(EngineCore_DP0 pid=348551) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=348551) 	// begin inline asm
(EngineCore_DP0 pid=348551) 	@%p43 st.shared.b32 [ %r56 + 0 ], %r58;
(EngineCore_DP0 pid=348551) 	// end inline asm
(EngineCore_DP0 pid=348551) 	bar.sync 	0;
(EngineCore_DP0 pid=348551) 	ld.shared.b32 	%r77, [global_smem];
(EngineCore_DP0 pid=348551) $L__tmp2:
(EngineCore_DP0 pid=348551) 	.loc	1 191 36                        // quant_slide_tuned_Llama3.2-1B.py:191:36
(EngineCore_DP0 pid=348551) 	max.f32 	%r208, %r208, %r77;
(EngineCore_DP0 pid=348551) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=348551) 	add.s32 	%r209, %r209, 4096;
(EngineCore_DP0 pid=348551) 	setp.lt.s32 	%p6, %r209, %r28;
(EngineCore_DP0 pid=348551) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=348551) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=348551) 	.loc	1 193 32                        // quant_slide_tuned_Llama3.2-1B.py:193:32
(EngineCore_DP0 pid=348551) 	max.f32 	%r210, %r208, 0f2B8CBCCC;
(EngineCore_DP0 pid=348551) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=348551) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=348551) 	mov.b32 	%r79, 0f43E00000;
(EngineCore_DP0 pid=348551) 	.loc	1 194 32                        // quant_slide_tuned_Llama3.2-1B.py:194:32
(EngineCore_DP0 pid=348551) 	div.full.f32 	%r80, %r210, %r79;
(EngineCore_DP0 pid=348551) 	.loc	1 194 41                        // quant_slide_tuned_Llama3.2-1B.py:194:41
(EngineCore_DP0 pid=348551) 	max.f32 	%r78, %r80, 0f36924925;
(EngineCore_DP0 pid=348551) 	.loc	1 196 25                        // quant_slide_tuned_Llama3.2-1B.py:196:25
(EngineCore_DP0 pid=348551) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=348551) 	.loc	1 196 30                        // quant_slide_tuned_Llama3.2-1B.py:196:30
(EngineCore_DP0 pid=348551) 	// begin inline asm
(EngineCore_DP0 pid=348551) 	@%p43 st.global.b32 [ %rd7 + 0 ], { %r78 };
(EngineCore_DP0 pid=348551) 	// end inline asm
(EngineCore_DP0 pid=348551) 	.loc	1 199 29                        // quant_slide_tuned_Llama3.2-1B.py:199:29
(EngineCore_DP0 pid=348551) 	shl.b32 	%r15, %r29, 2;
(EngineCore_DP0 pid=348551) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=348551) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=348551) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=348551) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=348551) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=348551) 	ld.param.b32 	%r33, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=348551) 	shr.s32 	%r34, %r33, 31;
(EngineCore_DP0 pid=348551) 	shr.u32 	%r35, %r34, 30;
(EngineCore_DP0 pid=348551) 	add.s32 	%r36, %r33, %r35;
(EngineCore_DP0 pid=348551) 	shr.s32 	%r37, %r36, 2;
(EngineCore_DP0 pid=348551) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=348551) 	mul.lo.s32 	%r38, %r37, %r1;
(EngineCore_DP0 pid=348551) 	mad.wide.s32 	%rd2, %r38, 4, %rd5;
(EngineCore_DP0 pid=348551) 	div.full.f32 	%r14, %r79, %r210;
(EngineCore_DP0 pid=348551) 	shl.b32 	%r16, %r3, 2;
(EngineCore_DP0 pid=348551) 	mov.b32 	%r211, 0;
(EngineCore_DP0 pid=348551) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=348551)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=348551) 	.loc	1 202 31                        // quant_slide_tuned_Llama3.2-1B.py:202:31
(EngineCore_DP0 pid=348551) 	add.s32 	%r102, %r16, %r211;
(EngineCore_DP0 pid=348551) 	or.b32 	%r103, %r211, 2;
(EngineCore_DP0 pid=348551) 	or.b32 	%r104, %r211, 3;
(EngineCore_DP0 pid=348551) 	.loc	1 203 30                        // quant_slide_tuned_Llama3.2-1B.py:203:30
(EngineCore_DP0 pid=348551) 	setp.lt.s32 	%p25, %r102, %r15;
(EngineCore_DP0 pid=348551) 	.loc	1 206 24                        // quant_slide_tuned_Llama3.2-1B.py:206:24
(EngineCore_DP0 pid=348551) 	shr.s32 	%r105, %r102, 2;
(EngineCore_DP0 pid=348551) 	.loc	1 207 23                        // quant_slide_tuned_Llama3.2-1B.py:207:23
(EngineCore_DP0 pid=348551) 	add.s32 	%r106, %r211, 1;
(EngineCore_DP0 pid=348551) 	shr.s32 	%r107, %r106, 31;
(EngineCore_DP0 pid=348551) 	shr.u32 	%r108, %r107, 30;
(EngineCore_DP0 pid=348551) 	add.s32 	%r109, %r106, %r108;
(EngineCore_DP0 pid=348551) 	and.b32 	%r110, %r109, 2147483644;
(EngineCore_DP0 pid=348551) 	sub.s32 	%r111, %r106, %r110;
(EngineCore_DP0 pid=348551) 	.loc	1 208 30                        // quant_slide_tuned_Llama3.2-1B.py:208:30
(EngineCore_DP0 pid=348551) 	shl.b32 	%r112, %r111, 1;
(EngineCore_DP0 pid=348551) 	.loc	1 208 22                        // quant_slide_tuned_Llama3.2-1B.py:208:22
(EngineCore_DP0 pid=348551) 	mul.lo.s32 	%r113, %r105, 10;
(EngineCore_DP0 pid=348551) 	.loc	1 208 26                        // quant_slide_tuned_Llama3.2-1B.py:208:26
(EngineCore_DP0 pid=348551) 	add.s32 	%r114, %r113, %r112;
(EngineCore_DP0 pid=348551) 	.loc	1 207 23                        // quant_slide_tuned_Llama3.2-1B.py:207:23
(EngineCore_DP0 pid=348551) 	shr.s32 	%r115, %r211, 31;
(EngineCore_DP0 pid=348551) 	shr.u32 	%r116, %r115, 30;
(EngineCore_DP0 pid=348551) 	add.s32 	%r117, %r104, %r116;
(EngineCore_DP0 pid=348551) 	and.b32 	%r118, %r117, 2147483644;
(EngineCore_DP0 pid=348551) 	sub.s32 	%r119, %r104, %r118;
(EngineCore_DP0 pid=348551) 	add.s32 	%r120, %r103, %r116;
(EngineCore_DP0 pid=348551) 	and.b32 	%r121, %r120, 2147483644;
(EngineCore_DP0 pid=348551) 	sub.s32 	%r122, %r103, %r121;
(EngineCore_DP0 pid=348551) 	.loc	1 208 30                        // quant_slide_tuned_Llama3.2-1B.py:208:30
(EngineCore_DP0 pid=348551) 	shl.b32 	%r123, %r122, 1;
(EngineCore_DP0 pid=348551) 	shl.b32 	%r124, %r119, 1;
(EngineCore_DP0 pid=348551) 	.loc	1 208 26                        // quant_slide_tuned_Llama3.2-1B.py:208:26
(EngineCore_DP0 pid=348551) 	add.s32 	%r125, %r113, %r124;
(EngineCore_DP0 pid=348551) 	add.s32 	%r126, %r113, %r123;
(EngineCore_DP0 pid=348551) 	.loc	1 211 53                        // quant_slide_tuned_Llama3.2-1B.py:211:53
(EngineCore_DP0 pid=348551) 	setp.lt.s32 	%p26, %r113, %r27;
(EngineCore_DP0 pid=348551) 	setp.lt.s32 	%p27, %r114, %r27;
(EngineCore_DP0 pid=348551) 	setp.lt.s32 	%p28, %r126, %r27;
(EngineCore_DP0 pid=348551) 	setp.lt.s32 	%p29, %r125, %r27;
(EngineCore_DP0 pid=348551) 	.loc	1 211 37                        // quant_slide_tuned_Llama3.2-1B.py:211:37
(EngineCore_DP0 pid=348551) 	and.pred 	%p9, %p25, %p26;
(EngineCore_DP0 pid=348551) 	and.pred 	%p10, %p25, %p27;
(EngineCore_DP0 pid=348551) 	and.pred 	%p11, %p25, %p28;
(EngineCore_DP0 pid=348551) 	and.pred 	%p12, %p25, %p29;
(EngineCore_DP0 pid=348551) 	.loc	1 210 29                        // quant_slide_tuned_Llama3.2-1B.py:210:29
(EngineCore_DP0 pid=348551) 	mad.wide.s32 	%rd8, %r113, 2, %rd1;
(EngineCore_DP0 pid=348551) 	mad.wide.s32 	%rd9, %r114, 2, %rd1;
(EngineCore_DP0 pid=348551) 	mad.wide.s32 	%rd10, %r126, 2, %rd1;
(EngineCore_DP0 pid=348551) 	mad.wide.s32 	%rd11, %r125, 2, %rd1;
(EngineCore_DP0 pid=348551) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=348551) 	.loc	1 210 21                        // quant_slide_tuned_Llama3.2-1B.py:210:21
(EngineCore_DP0 pid=348551) 	// begin inline asm
(EngineCore_DP0 pid=348551) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=348551) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=348551) 	// end inline asm
(EngineCore_DP0 pid=348551) 	// begin inline asm
(EngineCore_DP0 pid=348551) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=348551) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=348551) 	// end inline asm
(EngineCore_DP0 pid=348551) 	// begin inline asm
(EngineCore_DP0 pid=348551) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=348551) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=348551) 	// end inline asm
(EngineCore_DP0 pid=348551) 	// begin inline asm
(EngineCore_DP0 pid=348551) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=348551) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=348551) 	// end inline asm
(EngineCore_DP0 pid=348551) 	.loc	1 211 79                        // quant_slide_tuned_Llama3.2-1B.py:211:79
(EngineCore_DP0 pid=348551) 	cvt.f32.bf16 	%r127, %rs24;
(EngineCore_DP0 pid=348551) 	cvt.f32.bf16 	%r128, %rs26;
(EngineCore_DP0 pid=348551) 	cvt.f32.bf16 	%r129, %rs28;
(EngineCore_DP0 pid=348551) 	cvt.f32.bf16 	%r130, %rs30;
(EngineCore_DP0 pid=348551) 	.loc	1 213 48                        // quant_slide_tuned_Llama3.2-1B.py:213:48
(EngineCore_DP0 pid=348551) 	or.b32 	%r131, %r113, 1;
(EngineCore_DP0 pid=348551) 	or.b32 	%r132, %r114, 1;
(EngineCore_DP0 pid=348551) 	or.b32 	%r133, %r126, 1;
(EngineCore_DP0 pid=348551) 	or.b32 	%r134, %r125, 1;
(EngineCore_DP0 pid=348551) 	.loc	1 213 53                        // quant_slide_tuned_Llama3.2-1B.py:213:53
(EngineCore_DP0 pid=348551) 	setp.lt.s32 	%p30, %r131, %r27;
(EngineCore_DP0 pid=348551) 	setp.lt.s32 	%p31, %r132, %r27;
(EngineCore_DP0 pid=348551) 	setp.lt.s32 	%p32, %r133, %r27;
(EngineCore_DP0 pid=348551) 	setp.lt.s32 	%p33, %r134, %r27;
(EngineCore_DP0 pid=348551) 	.loc	1 213 37                        // quant_slide_tuned_Llama3.2-1B.py:213:37
(EngineCore_DP0 pid=348551) 	and.pred 	%p13, %p25, %p30;
(EngineCore_DP0 pid=348551) 	and.pred 	%p14, %p25, %p31;
(EngineCore_DP0 pid=348551) 	and.pred 	%p15, %p25, %p32;
(EngineCore_DP0 pid=348551) 	and.pred 	%p16, %p25, %p33;
(EngineCore_DP0 pid=348551) 	.loc	1 212 39                        // quant_slide_tuned_Llama3.2-1B.py:212:39
(EngineCore_DP0 pid=348551) 	add.s64 	%rd12, %rd8, 2;
(EngineCore_DP0 pid=348551) 	add.s64 	%rd13, %rd9, 2;
(EngineCore_DP0 pid=348551) 	add.s64 	%rd14, %rd10, 2;
(EngineCore_DP0 pid=348551) 	add.s64 	%rd15, %rd11, 2;
(EngineCore_DP0 pid=348551) 	.loc	1 212 21                        // quant_slide_tuned_Llama3.2-1B.py:212:21
(EngineCore_DP0 pid=348551) 	// begin inline asm
(EngineCore_DP0 pid=348551) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=348551) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=348551) 	// end inline asm
(EngineCore_DP0 pid=348551) 	// begin inline asm
(EngineCore_DP0 pid=348551) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=348551) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=348551) 	// end inline asm
(EngineCore_DP0 pid=348551) 	// begin inline asm
(EngineCore_DP0 pid=348551) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=348551) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=348551) 	// end inline asm
(EngineCore_DP0 pid=348551) 	// begin inline asm
(EngineCore_DP0 pid=348551) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=348551) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=348551) 	// end inline asm
(EngineCore_DP0 pid=348551) 	.loc	1 213 79                        // quant_slide_tuned_Llama3.2-1B.py:213:79
(EngineCore_DP0 pid=348551) 	cvt.f32.bf16 	%r135, %rs32;
(EngineCore_DP0 pid=348551) 	cvt.f32.bf16 	%r136, %rs34;
(EngineCore_DP0 pid=348551) 	cvt.f32.bf16 	%r137, %rs36;
(EngineCore_DP0 pid=348551) 	cvt.f32.bf16 	%r138, %rs38;
(EngineCore_DP0 pid=348551) 	.loc	1 217 48                        // quant_slide_tuned_Llama3.2-1B.py:217:48
(EngineCore_DP0 pid=348551) 	add.s32 	%r139, %r114, 2;
(EngineCore_DP0 pid=348551) 	add.s32 	%r140, %r126, 2;
(EngineCore_DP0 pid=348551) 	add.s32 	%r141, %r125, 2;
(EngineCore_DP0 pid=348551) 	add.s32 	%r142, %r114, 3;
(EngineCore_DP0 pid=348551) 	add.s32 	%r143, %r126, 3;
(EngineCore_DP0 pid=348551) 	add.s32 	%r144, %r125, 3;
(EngineCore_DP0 pid=348551) 	add.s32 	%r145, %r113, 2;
(EngineCore_DP0 pid=348551) 	add.s32 	%r146, %r113, 3;
(EngineCore_DP0 pid=348551) 	.loc	1 217 53                        // quant_slide_tuned_Llama3.2-1B.py:217:53
(EngineCore_DP0 pid=348551) 	setp.lt.s32 	%p34, %r144, %r27;
(EngineCore_DP0 pid=348551) 	setp.lt.s32 	%p35, %r143, %r27;
(EngineCore_DP0 pid=348551) 	setp.lt.s32 	%p36, %r142, %r27;
(EngineCore_DP0 pid=348551) 	setp.lt.s32 	%p37, %r141, %r27;
(EngineCore_DP0 pid=348551) 	setp.lt.s32 	%p38, %r140, %r27;
(EngineCore_DP0 pid=348551) 	setp.lt.s32 	%p39, %r139, %r27;
(EngineCore_DP0 pid=348551) 	setp.lt.s32 	%p40, %r146, %r27;
(EngineCore_DP0 pid=348551) 	setp.lt.s32 	%p41, %r145, %r27;
(EngineCore_DP0 pid=348551) 	.loc	1 215 37                        // quant_slide_tuned_Llama3.2-1B.py:215:37
(EngineCore_DP0 pid=348551) 	and.pred 	%p17, %p25, %p41;
(EngineCore_DP0 pid=348551) 	and.pred 	%p18, %p25, %p39;
(EngineCore_DP0 pid=348551) 	and.pred 	%p19, %p25, %p38;
(EngineCore_DP0 pid=348551) 	and.pred 	%p20, %p25, %p37;
(EngineCore_DP0 pid=348551) 	.loc	1 214 39                        // quant_slide_tuned_Llama3.2-1B.py:214:39
(EngineCore_DP0 pid=348551) 	add.s64 	%rd16, %rd8, 4;
(EngineCore_DP0 pid=348551) 	add.s64 	%rd17, %rd9, 4;
(EngineCore_DP0 pid=348551) 	add.s64 	%rd18, %rd10, 4;
(EngineCore_DP0 pid=348551) 	add.s64 	%rd19, %rd11, 4;
(EngineCore_DP0 pid=348551) 	.loc	1 214 21                        // quant_slide_tuned_Llama3.2-1B.py:214:21
(EngineCore_DP0 pid=348551) 	// begin inline asm
(EngineCore_DP0 pid=348551) 	mov.u16 %rs40, %rs25;
(EngineCore_DP0 pid=348551) 	@%p17 ld.global.b16 { %rs40 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=348551) 	// end inline asm
(EngineCore_DP0 pid=348551) 	// begin inline asm
(EngineCore_DP0 pid=348551) 	mov.u16 %rs42, %rs25;
(EngineCore_DP0 pid=348551) 	@%p18 ld.global.b16 { %rs42 }, [ %rd17 + 0 ];
(EngineCore_DP0 pid=348551) 	// end inline asm
(EngineCore_DP0 pid=348551) 	// begin inline asm
(EngineCore_DP0 pid=348551) 	mov.u16 %rs44, %rs25;
(EngineCore_DP0 pid=348551) 	@%p19 ld.global.b16 { %rs44 }, [ %rd18 + 0 ];
(EngineCore_DP0 pid=348551) 	// end inline asm
(EngineCore_DP0 pid=348551) 	// begin inline asm
(EngineCore_DP0 pid=348551) 	mov.u16 %rs46, %rs25;
(EngineCore_DP0 pid=348551) 	@%p20 ld.global.b16 { %rs46 }, [ %rd19 + 0 ];
(EngineCore_DP0 pid=348551) 	// end inline asm
(EngineCore_DP0 pid=348551) 	.loc	1 215 79                        // quant_slide_tuned_Llama3.2-1B.py:215:79
(EngineCore_DP0 pid=348551) 	cvt.f32.bf16 	%r147, %rs40;
(EngineCore_DP0 pid=348551) 	cvt.f32.bf16 	%r148, %rs42;
(EngineCore_DP0 pid=348551) 	cvt.f32.bf16 	%r149, %rs44;
(EngineCore_DP0 pid=348551) 	cvt.f32.bf16 	%r150, %rs46;
(EngineCore_DP0 pid=348551) 	.loc	1 217 37                        // quant_slide_tuned_Llama3.2-1B.py:217:37
(EngineCore_DP0 pid=348551) 	and.pred 	%p21, %p25, %p40;
(EngineCore_DP0 pid=348551) 	and.pred 	%p22, %p25, %p36;
(EngineCore_DP0 pid=348551) 	and.pred 	%p23, %p25, %p35;
(EngineCore_DP0 pid=348551) 	and.pred 	%p24, %p25, %p34;
(EngineCore_DP0 pid=348551) 	.loc	1 216 39                        // quant_slide_tuned_Llama3.2-1B.py:216:39
(EngineCore_DP0 pid=348551) 	add.s64 	%rd20, %rd8, 6;
(EngineCore_DP0 pid=348551) 	add.s64 	%rd21, %rd9, 6;
(EngineCore_DP0 pid=348551) 	add.s64 	%rd22, %rd10, 6;
(EngineCore_DP0 pid=348551) 	add.s64 	%rd23, %rd11, 6;
(EngineCore_DP0 pid=348551) 	.loc	1 216 21                        // quant_slide_tuned_Llama3.2-1B.py:216:21
(EngineCore_DP0 pid=348551) 	// begin inline asm
(EngineCore_DP0 pid=348551) 	mov.u16 %rs48, %rs25;
(EngineCore_DP0 pid=348551) 	@%p21 ld.global.b16 { %rs48 }, [ %rd20 + 0 ];
(EngineCore_DP0 pid=348551) 	// end inline asm
(EngineCore_DP0 pid=348551) 	// begin inline asm
(EngineCore_DP0 pid=348551) 	mov.u16 %rs50, %rs25;
(EngineCore_DP0 pid=348551) 	@%p22 ld.global.b16 { %rs50 }, [ %rd21 + 0 ];
(EngineCore_DP0 pid=348551) 	// end inline asm
(EngineCore_DP0 pid=348551) 	// begin inline asm
(EngineCore_DP0 pid=348551) 	mov.u16 %rs52, %rs25;
(EngineCore_DP0 pid=348551) 	@%p23 ld.global.b16 { %rs52 }, [ %rd22 + 0 ];
(EngineCore_DP0 pid=348551) 	// end inline asm
(EngineCore_DP0 pid=348551) 	// begin inline asm
(EngineCore_DP0 pid=348551) 	mov.u16 %rs54, %rs25;
(EngineCore_DP0 pid=348551) 	@%p24 ld.global.b16 { %rs54 }, [ %rd23 + 0 ];
(EngineCore_DP0 pid=348551) 	// end inline asm
(EngineCore_DP0 pid=348551) 	.loc	1 217 79                        // quant_slide_tuned_Llama3.2-1B.py:217:79
(EngineCore_DP0 pid=348551) 	cvt.f32.bf16 	%r151, %rs48;
(EngineCore_DP0 pid=348551) 	cvt.f32.bf16 	%r152, %rs50;
(EngineCore_DP0 pid=348551) 	cvt.f32.bf16 	%r153, %rs52;
(EngineCore_DP0 pid=348551) 	cvt.f32.bf16 	%r154, %rs54;
(EngineCore_DP0 pid=348551) 	.loc	1 219 27                        // quant_slide_tuned_Llama3.2-1B.py:219:27
(EngineCore_DP0 pid=348551) 	mul.f32 	%r155, %r14, %r127;
(EngineCore_DP0 pid=348551) 	mul.f32 	%r156, %r14, %r128;
(EngineCore_DP0 pid=348551) 	mul.f32 	%r157, %r14, %r129;
(EngineCore_DP0 pid=348551) 	mul.f32 	%r158, %r14, %r130;
(EngineCore_DP0 pid=348551) 	mov.b32 	%r159, 0f43E00000;
(EngineCore_DP0 pid=348551) 	.loc	1 219 48                        // quant_slide_tuned_Llama3.2-1B.py:219:48
(EngineCore_DP0 pid=348551) 	min.xorsign.abs.f32 	%r82, %r155, %r159;
(EngineCore_DP0 pid=348551) 	min.xorsign.abs.f32 	%r83, %r156, %r159;
(EngineCore_DP0 pid=348551) 	min.xorsign.abs.f32 	%r84, %r157, %r159;
(EngineCore_DP0 pid=348551) 	min.xorsign.abs.f32 	%r85, %r158, %r159;
(EngineCore_DP0 pid=348551) 	.loc	1 219 60                        // quant_slide_tuned_Llama3.2-1B.py:219:60
(EngineCore_DP0 pid=348551) 	// begin inline asm
(EngineCore_DP0 pid=348551) 	cvt.rn.satfinite.e4m3x2.f32  %rs56, %r83, %r82; 
(EngineCore_DP0 pid=348551) 
(EngineCore_DP0 pid=348551) 	// end inline asm
(EngineCore_DP0 pid=348551) 	shr.u16 	%rs64, %rs56, 8;
(EngineCore_DP0 pid=348551) 	// begin inline asm
(EngineCore_DP0 pid=348551) 	cvt.rn.satfinite.e4m3x2.f32  %rs57, %r85, %r84; 
(EngineCore_DP0 pid=348551) 
(EngineCore_DP0 pid=348551) 	// end inline asm
(EngineCore_DP0 pid=348551) 	shr.u16 	%rs65, %rs57, 8;
(EngineCore_DP0 pid=348551) 	.loc	1 220 27                        // quant_slide_tuned_Llama3.2-1B.py:220:27
(EngineCore_DP0 pid=348551) 	mul.f32 	%r160, %r14, %r135;
(EngineCore_DP0 pid=348551) 	mul.f32 	%r161, %r14, %r136;
(EngineCore_DP0 pid=348551) 	mul.f32 	%r162, %r14, %r137;
(EngineCore_DP0 pid=348551) 	mul.f32 	%r163, %r14, %r138;
(EngineCore_DP0 pid=348551) 	.loc	1 220 48                        // quant_slide_tuned_Llama3.2-1B.py:220:48
(EngineCore_DP0 pid=348551) 	min.xorsign.abs.f32 	%r86, %r160, %r159;
(EngineCore_DP0 pid=348551) 	min.xorsign.abs.f32 	%r87, %r161, %r159;
(EngineCore_DP0 pid=348551) 	min.xorsign.abs.f32 	%r88, %r162, %r159;
(EngineCore_DP0 pid=348551) 	min.xorsign.abs.f32 	%r89, %r163, %r159;
(EngineCore_DP0 pid=348551) 	.loc	1 220 60                        // quant_slide_tuned_Llama3.2-1B.py:220:60
(EngineCore_DP0 pid=348551) 	// begin inline asm
(EngineCore_DP0 pid=348551) 	cvt.rn.satfinite.e4m3x2.f32  %rs58, %r87, %r86; 
(EngineCore_DP0 pid=348551) 
(EngineCore_DP0 pid=348551) 	// end inline asm
(EngineCore_DP0 pid=348551) 	shr.u16 	%rs66, %rs58, 8;
(EngineCore_DP0 pid=348551) 	// begin inline asm
(EngineCore_DP0 pid=348551) 	cvt.rn.satfinite.e4m3x2.f32  %rs59, %r89, %r88; 
(EngineCore_DP0 pid=348551) 
(EngineCore_DP0 pid=348551) 	// end inline asm
(EngineCore_DP0 pid=348551) 	shr.u16 	%rs67, %rs59, 8;
(EngineCore_DP0 pid=348551) 	.loc	1 221 27                        // quant_slide_tuned_Llama3.2-1B.py:221:27
(EngineCore_DP0 pid=348551) 	mul.f32 	%r164, %r14, %r147;
(EngineCore_DP0 pid=348551) 	mul.f32 	%r165, %r14, %r148;
(EngineCore_DP0 pid=348551) 	mul.f32 	%r166, %r14, %r149;
(EngineCore_DP0 pid=348551) 	mul.f32 	%r167, %r14, %r150;
(EngineCore_DP0 pid=348551) 	.loc	1 221 48                        // quant_slide_tuned_Llama3.2-1B.py:221:48
(EngineCore_DP0 pid=348551) 	min.xorsign.abs.f32 	%r90, %r164, %r159;
(EngineCore_DP0 pid=348551) 	min.xorsign.abs.f32 	%r91, %r165, %r159;
(EngineCore_DP0 pid=348551) 	min.xorsign.abs.f32 	%r92, %r166, %r159;
(EngineCore_DP0 pid=348551) 	min.xorsign.abs.f32 	%r93, %r167, %r159;
(EngineCore_DP0 pid=348551) 	.loc	1 221 60                        // quant_slide_tuned_Llama3.2-1B.py:221:60
(EngineCore_DP0 pid=348551) 	// begin inline asm
(EngineCore_DP0 pid=348551) 	cvt.rn.satfinite.e4m3x2.f32  %rs60, %r91, %r90; 
(EngineCore_DP0 pid=348551) 
(EngineCore_DP0 pid=348551) 	// end inline asm
(EngineCore_DP0 pid=348551) 	shr.u16 	%rs68, %rs60, 8;
(EngineCore_DP0 pid=348551) 	// begin inline asm
(EngineCore_DP0 pid=348551) 	cvt.rn.satfinite.e4m3x2.f32  %rs61, %r93, %r92; 
(EngineCore_DP0 pid=348551) 
(EngineCore_DP0 pid=348551) 	// end inline asm
(EngineCore_DP0 pid=348551) 	shr.u16 	%rs69, %rs61, 8;
(EngineCore_DP0 pid=348551) 	.loc	1 222 27                        // quant_slide_tuned_Llama3.2-1B.py:222:27
(EngineCore_DP0 pid=348551) 	mul.f32 	%r168, %r14, %r151;
(EngineCore_DP0 pid=348551) 	mul.f32 	%r169, %r14, %r152;
(EngineCore_DP0 pid=348551) 	mul.f32 	%r170, %r14, %r153;
(EngineCore_DP0 pid=348551) 	mul.f32 	%r171, %r14, %r154;
(EngineCore_DP0 pid=348551) 	.loc	1 222 48                        // quant_slide_tuned_Llama3.2-1B.py:222:48
(EngineCore_DP0 pid=348551) 	min.xorsign.abs.f32 	%r94, %r168, %r159;
(EngineCore_DP0 pid=348551) 	min.xorsign.abs.f32 	%r95, %r169, %r159;
(EngineCore_DP0 pid=348551) 	min.xorsign.abs.f32 	%r96, %r170, %r159;
(EngineCore_DP0 pid=348551) 	min.xorsign.abs.f32 	%r97, %r171, %r159;
(EngineCore_DP0 pid=348551) 	.loc	1 222 60                        // quant_slide_tuned_Llama3.2-1B.py:222:60
(EngineCore_DP0 pid=348551) 	// begin inline asm
(EngineCore_DP0 pid=348551) 	cvt.rn.satfinite.e4m3x2.f32  %rs62, %r95, %r94; 
(EngineCore_DP0 pid=348551) 
(EngineCore_DP0 pid=348551) 	// end inline asm
(EngineCore_DP0 pid=348551) 	shr.u16 	%rs70, %rs62, 8;
(EngineCore_DP0 pid=348551) 	// begin inline asm
(EngineCore_DP0 pid=348551) 	cvt.rn.satfinite.e4m3x2.f32  %rs63, %r97, %r96; 
(EngineCore_DP0 pid=348551) 
(EngineCore_DP0 pid=348551) 	// end inline asm
(EngineCore_DP0 pid=348551) 	shr.u16 	%rs71, %rs63, 8;
(EngineCore_DP0 pid=348551) 	.loc	1 224 45                        // quant_slide_tuned_Llama3.2-1B.py:224:45
(EngineCore_DP0 pid=348551) 	cvt.u32.u16 	%r172, %rs56;
(EngineCore_DP0 pid=348551) 	and.b32 	%r173, %r172, 255;
(EngineCore_DP0 pid=348551) 	cvt.u32.u16 	%r174, %rs64;
(EngineCore_DP0 pid=348551) 	cvt.u32.u16 	%r175, %rs57;
(EngineCore_DP0 pid=348551) 	and.b32 	%r176, %r175, 255;
(EngineCore_DP0 pid=348551) 	cvt.u32.u16 	%r177, %rs65;
(EngineCore_DP0 pid=348551) 	.loc	1 226 45                        // quant_slide_tuned_Llama3.2-1B.py:226:45
(EngineCore_DP0 pid=348551) 	cvt.u32.u16 	%r178, %rs60;
(EngineCore_DP0 pid=348551) 	and.b32 	%r179, %r178, 255;
(EngineCore_DP0 pid=348551) 	cvt.u32.u16 	%r180, %rs68;
(EngineCore_DP0 pid=348551) 	cvt.u32.u16 	%r181, %rs61;
(EngineCore_DP0 pid=348551) 	and.b32 	%r182, %r181, 255;
(EngineCore_DP0 pid=348551) 	cvt.u32.u16 	%r183, %rs69;
(EngineCore_DP0 pid=348551) 	.loc	1 227 45                        // quant_slide_tuned_Llama3.2-1B.py:227:45
(EngineCore_DP0 pid=348551) 	cvt.u32.u16 	%r184, %rs62;
(EngineCore_DP0 pid=348551) 	cvt.u32.u16 	%r185, %rs70;
(EngineCore_DP0 pid=348551) 	cvt.u32.u16 	%r186, %rs63;
(EngineCore_DP0 pid=348551) 	cvt.u32.u16 	%r187, %rs71;
(EngineCore_DP0 pid=348551) 	.loc	1 229 30                        // quant_slide_tuned_Llama3.2-1B.py:229:30
(EngineCore_DP0 pid=348551) 	and.b16 	%rs72, %rs58, 255;
(EngineCore_DP0 pid=348551) 	mul.wide.u16 	%r188, %rs72, 256;
(EngineCore_DP0 pid=348551) 	mul.wide.u16 	%r189, %rs66, 256;
(EngineCore_DP0 pid=348551) 	and.b16 	%rs73, %rs59, 255;
(EngineCore_DP0 pid=348551) 	mul.wide.u16 	%r190, %rs73, 256;
(EngineCore_DP0 pid=348551) 	mul.wide.u16 	%r191, %rs67, 256;
(EngineCore_DP0 pid=348551) 	.loc	1 229 24                        // quant_slide_tuned_Llama3.2-1B.py:229:24
(EngineCore_DP0 pid=348551) 	or.b32 	%r192, %r188, %r173;
(EngineCore_DP0 pid=348551) 	or.b32 	%r193, %r189, %r174;
(EngineCore_DP0 pid=348551) 	or.b32 	%r194, %r190, %r176;
(EngineCore_DP0 pid=348551) 	or.b32 	%r195, %r191, %r177;
(EngineCore_DP0 pid=348551) 	.loc	1 229 42                        // quant_slide_tuned_Llama3.2-1B.py:229:42
(EngineCore_DP0 pid=348551) 	shl.b32 	%r196, %r179, 16;
(EngineCore_DP0 pid=348551) 	shl.b32 	%r197, %r180, 16;
(EngineCore_DP0 pid=348551) 	shl.b32 	%r198, %r182, 16;
(EngineCore_DP0 pid=348551) 	shl.b32 	%r199, %r183, 16;
(EngineCore_DP0 pid=348551) 	.loc	1 229 36                        // quant_slide_tuned_Llama3.2-1B.py:229:36
(EngineCore_DP0 pid=348551) 	or.b32 	%r200, %r196, %r192;
(EngineCore_DP0 pid=348551) 	or.b32 	%r201, %r197, %r193;
(EngineCore_DP0 pid=348551) 	or.b32 	%r202, %r198, %r194;
(EngineCore_DP0 pid=348551) 	or.b32 	%r203, %r199, %r195;
(EngineCore_DP0 pid=348551) 	.loc	1 229 55                        // quant_slide_tuned_Llama3.2-1B.py:229:55
(EngineCore_DP0 pid=348551) 	shl.b32 	%r204, %r184, 24;
(EngineCore_DP0 pid=348551) 	shl.b32 	%r205, %r185, 24;
(EngineCore_DP0 pid=348551) 	shl.b32 	%r206, %r186, 24;
(EngineCore_DP0 pid=348551) 	shl.b32 	%r207, %r187, 24;
(EngineCore_DP0 pid=348551) 	.loc	1 229 49                        // quant_slide_tuned_Llama3.2-1B.py:229:49
(EngineCore_DP0 pid=348551) 	or.b32 	%r98, %r204, %r200;
(EngineCore_DP0 pid=348551) 	or.b32 	%r99, %r205, %r201;
(EngineCore_DP0 pid=348551) 	or.b32 	%r100, %r206, %r202;
(EngineCore_DP0 pid=348551) 	or.b32 	%r101, %r207, %r203;
(EngineCore_DP0 pid=348551) 	.loc	1 230 29                        // quant_slide_tuned_Llama3.2-1B.py:230:29
(EngineCore_DP0 pid=348551) 	mad.wide.s32 	%rd24, %r102, 4, %rd2;
(EngineCore_DP0 pid=348551) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-1B.py:230:39
(EngineCore_DP0 pid=348551) 	// begin inline asm
(EngineCore_DP0 pid=348551) 	@%p25 st.global.v4.b32 [ %rd24 + 0 ], { %r98, %r99, %r100, %r101 };
(EngineCore_DP0 pid=348551) 	// end inline asm
(EngineCore_DP0 pid=348551) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=348551) 	add.s32 	%r211, %r211, 2048;
(EngineCore_DP0 pid=348551) 	setp.lt.s32 	%p42, %r211, %r15;
(EngineCore_DP0 pid=348551) 	@%p42 bra 	$L__BB0_6;
(EngineCore_DP0 pid=348551) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=348551) 	.loc	1 201 4                         // quant_slide_tuned_Llama3.2-1B.py:201:4
(EngineCore_DP0 pid=348551) 	ret;
(EngineCore_DP0 pid=348551) $L__tmp3:
(EngineCore_DP0 pid=348551) $L__func_end0:
(EngineCore_DP0 pid=348551)                                         // -- End function
(EngineCore_DP0 pid=348551) }
(EngineCore_DP0 pid=348551) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=348551) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=348551) 	.section	.debug_abbrev
(EngineCore_DP0 pid=348551) 	{
(EngineCore_DP0 pid=348551) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=348551) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=348551) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=348551) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=348551) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=348551) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=348551) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=348551) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=348551) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=348551) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=348551) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=348551) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=348551) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=348551) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=348551) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=348551) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=348551) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=348551) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=348551) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=348551) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=348551) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=348551) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=348551) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=348551) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=348551) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=348551) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=348551) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=348551) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=348551) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=348551) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=348551) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=348551) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=348551) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=348551) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=348551) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=348551) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=348551) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=348551) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=348551) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=348551) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=348551) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=348551) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=348551) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=348551) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=348551) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=348551) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=348551) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=348551) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=348551) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=348551) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=348551) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=348551) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=348551) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=348551) 	}
(EngineCore_DP0 pid=348551) 	.section	.debug_info
(EngineCore_DP0 pid=348551) 	{
(EngineCore_DP0 pid=348551) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=348551) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=348551) .b8 0
(EngineCore_DP0 pid=348551) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=348551) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=348551) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=348551) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=348551) .b8 114
(EngineCore_DP0 pid=348551) .b8 105
(EngineCore_DP0 pid=348551) .b8 116
(EngineCore_DP0 pid=348551) .b8 111
(EngineCore_DP0 pid=348551) .b8 110
(EngineCore_DP0 pid=348551) .b8 0
(EngineCore_DP0 pid=348551) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=348551) .b8 0
(EngineCore_DP0 pid=348551) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=348551) .b8 117
(EngineCore_DP0 pid=348551) .b8 97
(EngineCore_DP0 pid=348551) .b8 110
(EngineCore_DP0 pid=348551) .b8 116
(EngineCore_DP0 pid=348551) .b8 95
(EngineCore_DP0 pid=348551) .b8 115
(EngineCore_DP0 pid=348551) .b8 108
(EngineCore_DP0 pid=348551) .b8 105
(EngineCore_DP0 pid=348551) .b8 100
(EngineCore_DP0 pid=348551) .b8 101
(EngineCore_DP0 pid=348551) .b8 95
(EngineCore_DP0 pid=348551) .b8 116
(EngineCore_DP0 pid=348551) .b8 117
(EngineCore_DP0 pid=348551) .b8 110
(EngineCore_DP0 pid=348551) .b8 101
(EngineCore_DP0 pid=348551) .b8 100
(EngineCore_DP0 pid=348551) .b8 95
(EngineCore_DP0 pid=348551) .b8 76
(EngineCore_DP0 pid=348551) .b8 108
(EngineCore_DP0 pid=348551) .b8 97
(EngineCore_DP0 pid=348551) .b8 109
(EngineCore_DP0 pid=348551) .b8 97
(EngineCore_DP0 pid=348551) .b8 51
(EngineCore_DP0 pid=348551) .b8 46
(EngineCore_DP0 pid=348551) .b8 50
(EngineCore_DP0 pid=348551) .b8 45
(EngineCore_DP0 pid=348551) .b8 49
(EngineCore_DP0 pid=348551) .b8 66
(EngineCore_DP0 pid=348551) .b8 46
(EngineCore_DP0 pid=348551) .b8 112
(EngineCore_DP0 pid=348551) .b8 121
(EngineCore_DP0 pid=348551) .b8 0
(EngineCore_DP0 pid=348551) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=348551) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=348551) .b8 114
(EngineCore_DP0 pid=348551) .b8 111
(EngineCore_DP0 pid=348551) .b8 111
(EngineCore_DP0 pid=348551) .b8 116
(EngineCore_DP0 pid=348551) .b8 47
(EngineCore_DP0 pid=348551) .b8 118
(EngineCore_DP0 pid=348551) .b8 108
(EngineCore_DP0 pid=348551) .b8 108
(EngineCore_DP0 pid=348551) .b8 109
(EngineCore_DP0 pid=348551) .b8 98
(EngineCore_DP0 pid=348551) .b8 101
(EngineCore_DP0 pid=348551) .b8 110
(EngineCore_DP0 pid=348551) .b8 99
(EngineCore_DP0 pid=348551) .b8 104
(EngineCore_DP0 pid=348551) .b8 47
(EngineCore_DP0 pid=348551) .b8 115
(EngineCore_DP0 pid=348551) .b8 108
(EngineCore_DP0 pid=348551) .b8 105
(EngineCore_DP0 pid=348551) .b8 100
(EngineCore_DP0 pid=348551) .b8 101
(EngineCore_DP0 pid=348551) .b8 115
(EngineCore_DP0 pid=348551) .b8 112
(EngineCore_DP0 pid=348551) .b8 97
(EngineCore_DP0 pid=348551) .b8 114
(EngineCore_DP0 pid=348551) .b8 115
(EngineCore_DP0 pid=348551) .b8 101
(EngineCore_DP0 pid=348551) .b8 47
(EngineCore_DP0 pid=348551) .b8 99
(EngineCore_DP0 pid=348551) .b8 115
(EngineCore_DP0 pid=348551) .b8 114
(EngineCore_DP0 pid=348551) .b8 99
(EngineCore_DP0 pid=348551) .b8 47
(EngineCore_DP0 pid=348551) .b8 102
(EngineCore_DP0 pid=348551) .b8 117
(EngineCore_DP0 pid=348551) .b8 115
(EngineCore_DP0 pid=348551) .b8 101
(EngineCore_DP0 pid=348551) .b8 100
(EngineCore_DP0 pid=348551) .b8 95
(EngineCore_DP0 pid=348551) .b8 113
(EngineCore_DP0 pid=348551) .b8 117
(EngineCore_DP0 pid=348551) .b8 97
(EngineCore_DP0 pid=348551) .b8 110
(EngineCore_DP0 pid=348551) .b8 116
(EngineCore_DP0 pid=348551) .b8 95
(EngineCore_DP0 pid=348551) .b8 115
(EngineCore_DP0 pid=348551) .b8 108
(EngineCore_DP0 pid=348551) .b8 105
(EngineCore_DP0 pid=348551) .b8 100
(EngineCore_DP0 pid=348551) .b8 101
(EngineCore_DP0 pid=348551) .b8 95
(EngineCore_DP0 pid=348551) .b8 116
(EngineCore_DP0 pid=348551) .b8 114
(EngineCore_DP0 pid=348551) .b8 105
(EngineCore_DP0 pid=348551) .b8 116
(EngineCore_DP0 pid=348551) .b8 111
(EngineCore_DP0 pid=348551) .b8 110
(EngineCore_DP0 pid=348551) .b8 47
(EngineCore_DP0 pid=348551) .b8 98
(EngineCore_DP0 pid=348551) .b8 117
(EngineCore_DP0 pid=348551) .b8 105
(EngineCore_DP0 pid=348551) .b8 108
(EngineCore_DP0 pid=348551) .b8 100
(EngineCore_DP0 pid=348551) .b8 47
(EngineCore_DP0 pid=348551) .b8 71
(EngineCore_DP0 pid=348551) .b8 66
(EngineCore_DP0 pid=348551) .b8 49
(EngineCore_DP0 pid=348551) .b8 48
(EngineCore_DP0 pid=348551) .b8 95
(EngineCore_DP0 pid=348551) .b8 99
(EngineCore_DP0 pid=348551) .b8 99
(EngineCore_DP0 pid=348551) .b8 49
(EngineCore_DP0 pid=348551) .b8 50
(EngineCore_DP0 pid=348551) .b8 49
(EngineCore_DP0 pid=348551) .b8 95
(EngineCore_DP0 pid=348551) .b8 112
(EngineCore_DP0 pid=348551) .b8 121
(EngineCore_DP0 pid=348551) .b8 51
(EngineCore_DP0 pid=348551) .b8 49
(EngineCore_DP0 pid=348551) .b8 50
(EngineCore_DP0 pid=348551) .b8 95
(EngineCore_DP0 pid=348551) .b8 99
(EngineCore_DP0 pid=348551) .b8 117
(EngineCore_DP0 pid=348551) .b8 49
(EngineCore_DP0 pid=348551) .b8 50
(EngineCore_DP0 pid=348551) .b8 57
(EngineCore_DP0 pid=348551) .b8 95
(EngineCore_DP0 pid=348551) .b8 97
(EngineCore_DP0 pid=348551) .b8 97
(EngineCore_DP0 pid=348551) .b8 114
(EngineCore_DP0 pid=348551) .b8 99
(EngineCore_DP0 pid=348551) .b8 104
(EngineCore_DP0 pid=348551) .b8 54
(EngineCore_DP0 pid=348551) .b8 52
(EngineCore_DP0 pid=348551) .b8 0
(EngineCore_DP0 pid=348551) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=348551) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=348551) .b8 113
(EngineCore_DP0 pid=348551) .b8 117
(EngineCore_DP0 pid=348551) .b8 97
(EngineCore_DP0 pid=348551) .b8 110
(EngineCore_DP0 pid=348551) .b8 116
(EngineCore_DP0 pid=348551) .b8 95
(EngineCore_DP0 pid=348551) .b8 115
(EngineCore_DP0 pid=348551) .b8 108
(EngineCore_DP0 pid=348551) .b8 105
(EngineCore_DP0 pid=348551) .b8 100
(EngineCore_DP0 pid=348551) .b8 101
(EngineCore_DP0 pid=348551) .b8 95
(EngineCore_DP0 pid=348551) .b8 102
(EngineCore_DP0 pid=348551) .b8 112
(EngineCore_DP0 pid=348551) .b8 56
(EngineCore_DP0 pid=348551) .b8 95
(EngineCore_DP0 pid=348551) .b8 107
(EngineCore_DP0 pid=348551) .b8 101
(EngineCore_DP0 pid=348551) .b8 114
(EngineCore_DP0 pid=348551) .b8 110
(EngineCore_DP0 pid=348551) .b8 101
(EngineCore_DP0 pid=348551) .b8 108
(EngineCore_DP0 pid=348551) .b8 0
(EngineCore_DP0 pid=348551) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=348551) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=348551) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=348551) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=348551) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=348551) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=348551) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=348551) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=348551) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=348551) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=348551) .b8 191                                 // DW_AT_call_line
(EngineCore_DP0 pid=348551) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=348551) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=348551) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=348551) 	}
(EngineCore_DP0 pid=348551) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=348551) 
(EngineCore_DP0 pid=348551) ================================================================
(EngineCore_DP0 pid=348551) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=348551) 
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpvwpzwap5.ptx', '-o', '/tmp/tmpvwpzwap5.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866] 
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866] 
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866] 
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpvwpzwap5.ptx -o /tmp/tmpvwpzwap5.ptx.o
(EngineCore_DP0 pid=348551) ERROR 01-25 19:25:41 [core.py:866] 

STDERR:
[2026-01-25 19:25:24] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:25:24] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:25:24] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:25:24] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:25:24] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:25:24] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:25:24] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:25:24] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:25:24] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:25:24] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:25:24] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:25:24] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:25:24] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:25:24] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:25:27] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:25:27] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:25:27] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:25:27] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:25:27] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:25:27] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:25:27] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:25:27] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:25:27] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:25:27] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:25:27] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:25:27] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:25:27] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:25:27] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=348551) [2026-01-25 19:25:28] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=348551) [2026-01-25 19:25:28] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=348551) [2026-01-25 19:25:28] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=348551) [2026-01-25 19:25:28] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=348551) [2026-01-25 19:25:28] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=348551) [2026-01-25 19:25:28] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=348551) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=348551) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:11<00:00, 11.17s/it]
(EngineCore_DP0 pid=348551) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:11<00:00, 11.17s/it]
(EngineCore_DP0 pid=348551) 
(EngineCore_DP0 pid=348551) [2026-01-25 19:25:40] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=348551) [2026-01-25 19:25:40] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6340608 bytes
(EngineCore_DP0 pid=348551) [2026-01-25 19:25:40] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=348551) [2026-01-25 19:25:40] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 4227072 bytes
(EngineCore_DP0 pid=348551) [2026-01-25 19:25:40] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=348551) [2026-01-25 19:25:40] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 33816576 bytes
(EngineCore_DP0 pid=348551) [2026-01-25 19:25:40] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=348551) [2026-01-25 19:25:40] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16809984 bytes
(EngineCore_DP0 pid=348551) Process EngineCore_DP0:
(EngineCore_DP0 pid=348551) Traceback (most recent call last):
(EngineCore_DP0 pid=348551)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=348551)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=348551)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=348551)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=348551) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpvwpzwap5.ptx', '-o', '/tmp/tmpvwpzwap5.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=348551) 
(EngineCore_DP0 pid=348551) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=348551) 
(EngineCore_DP0 pid=348551) Traceback (most recent call last):
(EngineCore_DP0 pid=348551)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=348551)     self.run()
(EngineCore_DP0 pid=348551)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=348551)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=348551)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=348551)     raise e
(EngineCore_DP0 pid=348551)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=348551)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=348551)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=348551)     super().__init__(
(EngineCore_DP0 pid=348551)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=348551)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=348551)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=348551)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=348551)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=348551)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=348551)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=348551)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=348551)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=348551)     return func(*args, **kwargs)
(EngineCore_DP0 pid=348551)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=348551)     return func(*args, **kwargs)
(EngineCore_DP0 pid=348551)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=348551)     self.model_runner.profile_run()
(EngineCore_DP0 pid=348551)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=348551)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=348551)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=348551)     return func(*args, **kwargs)
(EngineCore_DP0 pid=348551)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=348551)     outputs = self.model(
(EngineCore_DP0 pid=348551)               ^^^^^^^^^^^
(EngineCore_DP0 pid=348551)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=348551)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=348551)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=348551)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=348551)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=348551)     model_output = self.model(
(EngineCore_DP0 pid=348551)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=348551)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=348551)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=348551)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=348551)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=348551)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=348551)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=348551)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=348551)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=348551)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=348551)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=348551)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=348551)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=348551)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=348551)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=348551)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=348551)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=348551)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=348551)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=348551)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=348551)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=348551)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=348551)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=348551)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=348551)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=348551)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=348551)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=348551)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=348551)     return self._linear_fn(
(EngineCore_DP0 pid=348551)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=348551)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=348551)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=348551)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=348551)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=348551)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=348551)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=348551)     return fn(input, L)
(EngineCore_DP0 pid=348551)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=348551)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=348551)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=348551)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=348551)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=348551)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=348551)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=348551)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=348551)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=348551)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=348551)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=348551)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=348551)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=348551)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=348551)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=348551)     raise PTXASError(error)
(EngineCore_DP0 pid=348551) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=348551) `ptxas` stderr:
(EngineCore_DP0 pid=348551) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=348551) 
(EngineCore_DP0 pid=348551) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpvwpzwap5.ptx -o /tmp/tmpvwpzwap5.ptx.o
(EngineCore_DP0 pid=348551) 
[rank0]:[W125 19:25:41.916984704 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=8192

========== M=16384 ==========
Time: 2026-01-25 19:25:43
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-1B-FP8_M16384.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:25:52 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:25:52 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=349145) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=349145) 
(EngineCore_DP0 pid=349145) 
(EngineCore_DP0 pid=349145) ================================================================
(EngineCore_DP0 pid=349145) Internal Triton PTX codegen error
(EngineCore_DP0 pid=349145) `ptxas` stderr:
(EngineCore_DP0 pid=349145) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=349145) 
(EngineCore_DP0 pid=349145) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp11s6nh74.ptx -o /tmp/tmp11s6nh74.ptx.o
(EngineCore_DP0 pid=349145) 
(EngineCore_DP0 pid=349145) 
(EngineCore_DP0 pid=349145) //
(EngineCore_DP0 pid=349145) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=349145) //
(EngineCore_DP0 pid=349145) 
(EngineCore_DP0 pid=349145) .version 8.7
(EngineCore_DP0 pid=349145) .target sm_121a
(EngineCore_DP0 pid=349145) .address_size 64
(EngineCore_DP0 pid=349145) 
(EngineCore_DP0 pid=349145) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=349145) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=349145)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=349145) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=349145) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=349145) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=349145) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=349145) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=349145) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=349145) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=349145) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=349145) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=349145) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=349145) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=349145) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=349145) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=349145) )
(EngineCore_DP0 pid=349145) .reqntid 512
(EngineCore_DP0 pid=349145) {
(EngineCore_DP0 pid=349145) 	.reg .pred 	%p<44>;
(EngineCore_DP0 pid=349145) 	.reg .b16 	%rs<74>;
(EngineCore_DP0 pid=349145) 	.reg .b32 	%r<212>;
(EngineCore_DP0 pid=349145) 	.reg .b64 	%rd<25>;
(EngineCore_DP0 pid=349145) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=349145) $L__func_begin0:
(EngineCore_DP0 pid=349145) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=349145) 
(EngineCore_DP0 pid=349145) // %bb.0:
(EngineCore_DP0 pid=349145) 	ld.param.b32 	%r29, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=349145) 	ld.param.b32 	%r28, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=349145) 	ld.param.b32 	%r27, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=349145) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=349145) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=349145) $L__tmp0:
(EngineCore_DP0 pid=349145) 	.loc	1 177 24                        // quant_slide_tuned_Llama3.2-1B.py:177:24
(EngineCore_DP0 pid=349145) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=349145) 	ld.param.b32 	%r31, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=349145) 	.loc	1 182 26                        // quant_slide_tuned_Llama3.2-1B.py:182:26
(EngineCore_DP0 pid=349145) 	mul.lo.s32 	%r32, %r31, %r1;
(EngineCore_DP0 pid=349145) 	.loc	1 182 20                        // quant_slide_tuned_Llama3.2-1B.py:182:20
(EngineCore_DP0 pid=349145) 	mad.wide.s32 	%rd1, %r32, 2, %rd4;
(EngineCore_DP0 pid=349145) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=349145) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=349145) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=349145) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=349145) 	setp.lt.s32 	%p1, %r28, 1;
(EngineCore_DP0 pid=349145) 	mov.b32 	%r210, 0f2B8CBCCC;
(EngineCore_DP0 pid=349145) 	setp.eq.b32 	%p43, %r2, 0;
(EngineCore_DP0 pid=349145) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=349145) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=349145) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=349145) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=349145) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=349145) 	shr.u32 	%r41, %r2, 3;
(EngineCore_DP0 pid=349145) 	and.b32 	%r42, %r41, 60;
(EngineCore_DP0 pid=349145) 	mov.b32 	%r43, global_smem;
(EngineCore_DP0 pid=349145) 	add.s32 	%r53, %r43, %r42;
(EngineCore_DP0 pid=349145) 	shl.b32 	%r44, %r2, 2;
(EngineCore_DP0 pid=349145) 	add.s32 	%r56, %r43, %r44;
(EngineCore_DP0 pid=349145) 	mov.b32 	%r49, 0;
(EngineCore_DP0 pid=349145) 	mov.b32 	%r208, 0f00000000;
(EngineCore_DP0 pid=349145) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=349145) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=349145) 	mov.b32 	%r209, %r49;
(EngineCore_DP0 pid=349145) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=349145) 	.loc	1 189 22                        // quant_slide_tuned_Llama3.2-1B.py:189:22
(EngineCore_DP0 pid=349145) 	add.s32 	%r59, %r4, %r209;
(EngineCore_DP0 pid=349145) 	setp.lt.s32 	%p2, %r59, %r27;
(EngineCore_DP0 pid=349145) 	.loc	1 190 29                        // quant_slide_tuned_Llama3.2-1B.py:190:29
(EngineCore_DP0 pid=349145) 	mad.wide.s32 	%rd6, %r59, 2, %rd1;
(EngineCore_DP0 pid=349145) 	.loc	1 190 21                        // quant_slide_tuned_Llama3.2-1B.py:190:21
(EngineCore_DP0 pid=349145) 	// begin inline asm
(EngineCore_DP0 pid=349145) 	mov.u32 %r45, %r49;
(EngineCore_DP0 pid=349145) 	mov.u32 %r46, %r49;
(EngineCore_DP0 pid=349145) 	mov.u32 %r47, %r49;
(EngineCore_DP0 pid=349145) 	mov.u32 %r48, %r49;
(EngineCore_DP0 pid=349145) 	@%p2 ld.global.v4.b32 { %r45, %r46, %r47, %r48 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=349145) 	// end inline asm
(EngineCore_DP0 pid=349145) 	mov.b32 	{%rs1, %rs2}, %r45;
(EngineCore_DP0 pid=349145) 	mov.b32 	{%rs3, %rs4}, %r46;
(EngineCore_DP0 pid=349145) 	mov.b32 	{%rs5, %rs6}, %r47;
(EngineCore_DP0 pid=349145) 	mov.b32 	{%rs7, %rs8}, %r48;
(EngineCore_DP0 pid=349145) 	.loc	1 191 50                        // quant_slide_tuned_Llama3.2-1B.py:191:50
(EngineCore_DP0 pid=349145) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=349145) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=349145) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=349145) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=349145) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=349145) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=349145) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=349145) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=349145) $L__tmp1:
(EngineCore_DP0 pid=349145) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=349145) 	bar.sync 	0;
(EngineCore_DP0 pid=349145) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=349145) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=349145) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=349145) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=349145) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=349145) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=349145) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=349145) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=349145) 	cvt.f32.bf16 	%r60, %rs23;
(EngineCore_DP0 pid=349145) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=349145) 	shfl.sync.bfly.b32 	%r61, %r60, 16, 31, -1;
(EngineCore_DP0 pid=349145) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=349145) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=349145) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=349145) 	shfl.sync.bfly.b32 	%r63, %r62, 8, 31, -1;
(EngineCore_DP0 pid=349145) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=349145) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=349145) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=349145) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=349145) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=349145) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=349145) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=349145) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=349145) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=349145) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=349145) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=349145) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=349145) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=349145) 	max.f32 	%r54, %r68, %r69;
(EngineCore_DP0 pid=349145) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=349145) 	// begin inline asm
(EngineCore_DP0 pid=349145) 	@%p3 st.shared.b32 [ %r53 + 0 ], %r54;
(EngineCore_DP0 pid=349145) 	// end inline asm
(EngineCore_DP0 pid=349145) 	bar.sync 	0;
(EngineCore_DP0 pid=349145) 	// begin inline asm
(EngineCore_DP0 pid=349145) 	@%p4 ld.shared.b32 %r55, [ %r56 + 0 ];
(EngineCore_DP0 pid=349145) 	// end inline asm
(EngineCore_DP0 pid=349145) 	shfl.sync.bfly.b32 	%r70, %r55, 8, 31, -1;
(EngineCore_DP0 pid=349145) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=349145) 	max.f32 	%r71, %r55, %r70;
(EngineCore_DP0 pid=349145) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=349145) 	shfl.sync.bfly.b32 	%r72, %r71, 4, 31, -1;
(EngineCore_DP0 pid=349145) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=349145) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=349145) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=349145) 	shfl.sync.bfly.b32 	%r74, %r73, 2, 31, -1;
(EngineCore_DP0 pid=349145) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=349145) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=349145) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=349145) 	shfl.sync.bfly.b32 	%r76, %r75, 1, 31, -1;
(EngineCore_DP0 pid=349145) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=349145) 	max.f32 	%r58, %r75, %r76;
(EngineCore_DP0 pid=349145) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=349145) 	// begin inline asm
(EngineCore_DP0 pid=349145) 	@%p43 st.shared.b32 [ %r56 + 0 ], %r58;
(EngineCore_DP0 pid=349145) 	// end inline asm
(EngineCore_DP0 pid=349145) 	bar.sync 	0;
(EngineCore_DP0 pid=349145) 	ld.shared.b32 	%r77, [global_smem];
(EngineCore_DP0 pid=349145) $L__tmp2:
(EngineCore_DP0 pid=349145) 	.loc	1 191 36                        // quant_slide_tuned_Llama3.2-1B.py:191:36
(EngineCore_DP0 pid=349145) 	max.f32 	%r208, %r208, %r77;
(EngineCore_DP0 pid=349145) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=349145) 	add.s32 	%r209, %r209, 4096;
(EngineCore_DP0 pid=349145) 	setp.lt.s32 	%p6, %r209, %r28;
(EngineCore_DP0 pid=349145) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=349145) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=349145) 	.loc	1 193 32                        // quant_slide_tuned_Llama3.2-1B.py:193:32
(EngineCore_DP0 pid=349145) 	max.f32 	%r210, %r208, 0f2B8CBCCC;
(EngineCore_DP0 pid=349145) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=349145) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=349145) 	mov.b32 	%r79, 0f43E00000;
(EngineCore_DP0 pid=349145) 	.loc	1 194 32                        // quant_slide_tuned_Llama3.2-1B.py:194:32
(EngineCore_DP0 pid=349145) 	div.full.f32 	%r80, %r210, %r79;
(EngineCore_DP0 pid=349145) 	.loc	1 194 41                        // quant_slide_tuned_Llama3.2-1B.py:194:41
(EngineCore_DP0 pid=349145) 	max.f32 	%r78, %r80, 0f36924925;
(EngineCore_DP0 pid=349145) 	.loc	1 196 25                        // quant_slide_tuned_Llama3.2-1B.py:196:25
(EngineCore_DP0 pid=349145) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=349145) 	.loc	1 196 30                        // quant_slide_tuned_Llama3.2-1B.py:196:30
(EngineCore_DP0 pid=349145) 	// begin inline asm
(EngineCore_DP0 pid=349145) 	@%p43 st.global.b32 [ %rd7 + 0 ], { %r78 };
(EngineCore_DP0 pid=349145) 	// end inline asm
(EngineCore_DP0 pid=349145) 	.loc	1 199 29                        // quant_slide_tuned_Llama3.2-1B.py:199:29
(EngineCore_DP0 pid=349145) 	shl.b32 	%r15, %r29, 2;
(EngineCore_DP0 pid=349145) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=349145) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=349145) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=349145) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=349145) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=349145) 	ld.param.b32 	%r33, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=349145) 	shr.s32 	%r34, %r33, 31;
(EngineCore_DP0 pid=349145) 	shr.u32 	%r35, %r34, 30;
(EngineCore_DP0 pid=349145) 	add.s32 	%r36, %r33, %r35;
(EngineCore_DP0 pid=349145) 	shr.s32 	%r37, %r36, 2;
(EngineCore_DP0 pid=349145) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=349145) 	mul.lo.s32 	%r38, %r37, %r1;
(EngineCore_DP0 pid=349145) 	mad.wide.s32 	%rd2, %r38, 4, %rd5;
(EngineCore_DP0 pid=349145) 	div.full.f32 	%r14, %r79, %r210;
(EngineCore_DP0 pid=349145) 	shl.b32 	%r16, %r3, 2;
(EngineCore_DP0 pid=349145) 	mov.b32 	%r211, 0;
(EngineCore_DP0 pid=349145) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=349145)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=349145) 	.loc	1 202 31                        // quant_slide_tuned_Llama3.2-1B.py:202:31
(EngineCore_DP0 pid=349145) 	add.s32 	%r102, %r16, %r211;
(EngineCore_DP0 pid=349145) 	or.b32 	%r103, %r211, 2;
(EngineCore_DP0 pid=349145) 	or.b32 	%r104, %r211, 3;
(EngineCore_DP0 pid=349145) 	.loc	1 203 30                        // quant_slide_tuned_Llama3.2-1B.py:203:30
(EngineCore_DP0 pid=349145) 	setp.lt.s32 	%p25, %r102, %r15;
(EngineCore_DP0 pid=349145) 	.loc	1 206 24                        // quant_slide_tuned_Llama3.2-1B.py:206:24
(EngineCore_DP0 pid=349145) 	shr.s32 	%r105, %r102, 2;
(EngineCore_DP0 pid=349145) 	.loc	1 207 23                        // quant_slide_tuned_Llama3.2-1B.py:207:23
(EngineCore_DP0 pid=349145) 	add.s32 	%r106, %r211, 1;
(EngineCore_DP0 pid=349145) 	shr.s32 	%r107, %r106, 31;
(EngineCore_DP0 pid=349145) 	shr.u32 	%r108, %r107, 30;
(EngineCore_DP0 pid=349145) 	add.s32 	%r109, %r106, %r108;
(EngineCore_DP0 pid=349145) 	and.b32 	%r110, %r109, 2147483644;
(EngineCore_DP0 pid=349145) 	sub.s32 	%r111, %r106, %r110;
(EngineCore_DP0 pid=349145) 	.loc	1 208 30                        // quant_slide_tuned_Llama3.2-1B.py:208:30
(EngineCore_DP0 pid=349145) 	shl.b32 	%r112, %r111, 1;
(EngineCore_DP0 pid=349145) 	.loc	1 208 22                        // quant_slide_tuned_Llama3.2-1B.py:208:22
(EngineCore_DP0 pid=349145) 	mul.lo.s32 	%r113, %r105, 10;
(EngineCore_DP0 pid=349145) 	.loc	1 208 26                        // quant_slide_tuned_Llama3.2-1B.py:208:26
(EngineCore_DP0 pid=349145) 	add.s32 	%r114, %r113, %r112;
(EngineCore_DP0 pid=349145) 	.loc	1 207 23                        // quant_slide_tuned_Llama3.2-1B.py:207:23
(EngineCore_DP0 pid=349145) 	shr.s32 	%r115, %r211, 31;
(EngineCore_DP0 pid=349145) 	shr.u32 	%r116, %r115, 30;
(EngineCore_DP0 pid=349145) 	add.s32 	%r117, %r104, %r116;
(EngineCore_DP0 pid=349145) 	and.b32 	%r118, %r117, 2147483644;
(EngineCore_DP0 pid=349145) 	sub.s32 	%r119, %r104, %r118;
(EngineCore_DP0 pid=349145) 	add.s32 	%r120, %r103, %r116;
(EngineCore_DP0 pid=349145) 	and.b32 	%r121, %r120, 2147483644;
(EngineCore_DP0 pid=349145) 	sub.s32 	%r122, %r103, %r121;
(EngineCore_DP0 pid=349145) 	.loc	1 208 30                        // quant_slide_tuned_Llama3.2-1B.py:208:30
(EngineCore_DP0 pid=349145) 	shl.b32 	%r123, %r122, 1;
(EngineCore_DP0 pid=349145) 	shl.b32 	%r124, %r119, 1;
(EngineCore_DP0 pid=349145) 	.loc	1 208 26                        // quant_slide_tuned_Llama3.2-1B.py:208:26
(EngineCore_DP0 pid=349145) 	add.s32 	%r125, %r113, %r124;
(EngineCore_DP0 pid=349145) 	add.s32 	%r126, %r113, %r123;
(EngineCore_DP0 pid=349145) 	.loc	1 211 53                        // quant_slide_tuned_Llama3.2-1B.py:211:53
(EngineCore_DP0 pid=349145) 	setp.lt.s32 	%p26, %r113, %r27;
(EngineCore_DP0 pid=349145) 	setp.lt.s32 	%p27, %r114, %r27;
(EngineCore_DP0 pid=349145) 	setp.lt.s32 	%p28, %r126, %r27;
(EngineCore_DP0 pid=349145) 	setp.lt.s32 	%p29, %r125, %r27;
(EngineCore_DP0 pid=349145) 	.loc	1 211 37                        // quant_slide_tuned_Llama3.2-1B.py:211:37
(EngineCore_DP0 pid=349145) 	and.pred 	%p9, %p25, %p26;
(EngineCore_DP0 pid=349145) 	and.pred 	%p10, %p25, %p27;
(EngineCore_DP0 pid=349145) 	and.pred 	%p11, %p25, %p28;
(EngineCore_DP0 pid=349145) 	and.pred 	%p12, %p25, %p29;
(EngineCore_DP0 pid=349145) 	.loc	1 210 29                        // quant_slide_tuned_Llama3.2-1B.py:210:29
(EngineCore_DP0 pid=349145) 	mad.wide.s32 	%rd8, %r113, 2, %rd1;
(EngineCore_DP0 pid=349145) 	mad.wide.s32 	%rd9, %r114, 2, %rd1;
(EngineCore_DP0 pid=349145) 	mad.wide.s32 	%rd10, %r126, 2, %rd1;
(EngineCore_DP0 pid=349145) 	mad.wide.s32 	%rd11, %r125, 2, %rd1;
(EngineCore_DP0 pid=349145) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=349145) 	.loc	1 210 21                        // quant_slide_tuned_Llama3.2-1B.py:210:21
(EngineCore_DP0 pid=349145) 	// begin inline asm
(EngineCore_DP0 pid=349145) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=349145) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=349145) 	// end inline asm
(EngineCore_DP0 pid=349145) 	// begin inline asm
(EngineCore_DP0 pid=349145) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=349145) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=349145) 	// end inline asm
(EngineCore_DP0 pid=349145) 	// begin inline asm
(EngineCore_DP0 pid=349145) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=349145) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=349145) 	// end inline asm
(EngineCore_DP0 pid=349145) 	// begin inline asm
(EngineCore_DP0 pid=349145) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=349145) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=349145) 	// end inline asm
(EngineCore_DP0 pid=349145) 	.loc	1 211 79                        // quant_slide_tuned_Llama3.2-1B.py:211:79
(EngineCore_DP0 pid=349145) 	cvt.f32.bf16 	%r127, %rs24;
(EngineCore_DP0 pid=349145) 	cvt.f32.bf16 	%r128, %rs26;
(EngineCore_DP0 pid=349145) 	cvt.f32.bf16 	%r129, %rs28;
(EngineCore_DP0 pid=349145) 	cvt.f32.bf16 	%r130, %rs30;
(EngineCore_DP0 pid=349145) 	.loc	1 213 48                        // quant_slide_tuned_Llama3.2-1B.py:213:48
(EngineCore_DP0 pid=349145) 	or.b32 	%r131, %r113, 1;
(EngineCore_DP0 pid=349145) 	or.b32 	%r132, %r114, 1;
(EngineCore_DP0 pid=349145) 	or.b32 	%r133, %r126, 1;
(EngineCore_DP0 pid=349145) 	or.b32 	%r134, %r125, 1;
(EngineCore_DP0 pid=349145) 	.loc	1 213 53                        // quant_slide_tuned_Llama3.2-1B.py:213:53
(EngineCore_DP0 pid=349145) 	setp.lt.s32 	%p30, %r131, %r27;
(EngineCore_DP0 pid=349145) 	setp.lt.s32 	%p31, %r132, %r27;
(EngineCore_DP0 pid=349145) 	setp.lt.s32 	%p32, %r133, %r27;
(EngineCore_DP0 pid=349145) 	setp.lt.s32 	%p33, %r134, %r27;
(EngineCore_DP0 pid=349145) 	.loc	1 213 37                        // quant_slide_tuned_Llama3.2-1B.py:213:37
(EngineCore_DP0 pid=349145) 	and.pred 	%p13, %p25, %p30;
(EngineCore_DP0 pid=349145) 	and.pred 	%p14, %p25, %p31;
(EngineCore_DP0 pid=349145) 	and.pred 	%p15, %p25, %p32;
(EngineCore_DP0 pid=349145) 	and.pred 	%p16, %p25, %p33;
(EngineCore_DP0 pid=349145) 	.loc	1 212 39                        // quant_slide_tuned_Llama3.2-1B.py:212:39
(EngineCore_DP0 pid=349145) 	add.s64 	%rd12, %rd8, 2;
(EngineCore_DP0 pid=349145) 	add.s64 	%rd13, %rd9, 2;
(EngineCore_DP0 pid=349145) 	add.s64 	%rd14, %rd10, 2;
(EngineCore_DP0 pid=349145) 	add.s64 	%rd15, %rd11, 2;
(EngineCore_DP0 pid=349145) 	.loc	1 212 21                        // quant_slide_tuned_Llama3.2-1B.py:212:21
(EngineCore_DP0 pid=349145) 	// begin inline asm
(EngineCore_DP0 pid=349145) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=349145) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=349145) 	// end inline asm
(EngineCore_DP0 pid=349145) 	// begin inline asm
(EngineCore_DP0 pid=349145) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=349145) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=349145) 	// end inline asm
(EngineCore_DP0 pid=349145) 	// begin inline asm
(EngineCore_DP0 pid=349145) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=349145) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=349145) 	// end inline asm
(EngineCore_DP0 pid=349145) 	// begin inline asm
(EngineCore_DP0 pid=349145) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=349145) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=349145) 	// end inline asm
(EngineCore_DP0 pid=349145) 	.loc	1 213 79                        // quant_slide_tuned_Llama3.2-1B.py:213:79
(EngineCore_DP0 pid=349145) 	cvt.f32.bf16 	%r135, %rs32;
(EngineCore_DP0 pid=349145) 	cvt.f32.bf16 	%r136, %rs34;
(EngineCore_DP0 pid=349145) 	cvt.f32.bf16 	%r137, %rs36;
(EngineCore_DP0 pid=349145) 	cvt.f32.bf16 	%r138, %rs38;
(EngineCore_DP0 pid=349145) 	.loc	1 217 48                        // quant_slide_tuned_Llama3.2-1B.py:217:48
(EngineCore_DP0 pid=349145) 	add.s32 	%r139, %r114, 2;
(EngineCore_DP0 pid=349145) 	add.s32 	%r140, %r126, 2;
(EngineCore_DP0 pid=349145) 	add.s32 	%r141, %r125, 2;
(EngineCore_DP0 pid=349145) 	add.s32 	%r142, %r114, 3;
(EngineCore_DP0 pid=349145) 	add.s32 	%r143, %r126, 3;
(EngineCore_DP0 pid=349145) 	add.s32 	%r144, %r125, 3;
(EngineCore_DP0 pid=349145) 	add.s32 	%r145, %r113, 2;
(EngineCore_DP0 pid=349145) 	add.s32 	%r146, %r113, 3;
(EngineCore_DP0 pid=349145) 	.loc	1 217 53                        // quant_slide_tuned_Llama3.2-1B.py:217:53
(EngineCore_DP0 pid=349145) 	setp.lt.s32 	%p34, %r144, %r27;
(EngineCore_DP0 pid=349145) 	setp.lt.s32 	%p35, %r143, %r27;
(EngineCore_DP0 pid=349145) 	setp.lt.s32 	%p36, %r142, %r27;
(EngineCore_DP0 pid=349145) 	setp.lt.s32 	%p37, %r141, %r27;
(EngineCore_DP0 pid=349145) 	setp.lt.s32 	%p38, %r140, %r27;
(EngineCore_DP0 pid=349145) 	setp.lt.s32 	%p39, %r139, %r27;
(EngineCore_DP0 pid=349145) 	setp.lt.s32 	%p40, %r146, %r27;
(EngineCore_DP0 pid=349145) 	setp.lt.s32 	%p41, %r145, %r27;
(EngineCore_DP0 pid=349145) 	.loc	1 215 37                        // quant_slide_tuned_Llama3.2-1B.py:215:37
(EngineCore_DP0 pid=349145) 	and.pred 	%p17, %p25, %p41;
(EngineCore_DP0 pid=349145) 	and.pred 	%p18, %p25, %p39;
(EngineCore_DP0 pid=349145) 	and.pred 	%p19, %p25, %p38;
(EngineCore_DP0 pid=349145) 	and.pred 	%p20, %p25, %p37;
(EngineCore_DP0 pid=349145) 	.loc	1 214 39                        // quant_slide_tuned_Llama3.2-1B.py:214:39
(EngineCore_DP0 pid=349145) 	add.s64 	%rd16, %rd8, 4;
(EngineCore_DP0 pid=349145) 	add.s64 	%rd17, %rd9, 4;
(EngineCore_DP0 pid=349145) 	add.s64 	%rd18, %rd10, 4;
(EngineCore_DP0 pid=349145) 	add.s64 	%rd19, %rd11, 4;
(EngineCore_DP0 pid=349145) 	.loc	1 214 21                        // quant_slide_tuned_Llama3.2-1B.py:214:21
(EngineCore_DP0 pid=349145) 	// begin inline asm
(EngineCore_DP0 pid=349145) 	mov.u16 %rs40, %rs25;
(EngineCore_DP0 pid=349145) 	@%p17 ld.global.b16 { %rs40 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=349145) 	// end inline asm
(EngineCore_DP0 pid=349145) 	// begin inline asm
(EngineCore_DP0 pid=349145) 	mov.u16 %rs42, %rs25;
(EngineCore_DP0 pid=349145) 	@%p18 ld.global.b16 { %rs42 }, [ %rd17 + 0 ];
(EngineCore_DP0 pid=349145) 	// end inline asm
(EngineCore_DP0 pid=349145) 	// begin inline asm
(EngineCore_DP0 pid=349145) 	mov.u16 %rs44, %rs25;
(EngineCore_DP0 pid=349145) 	@%p19 ld.global.b16 { %rs44 }, [ %rd18 + 0 ];
(EngineCore_DP0 pid=349145) 	// end inline asm
(EngineCore_DP0 pid=349145) 	// begin inline asm
(EngineCore_DP0 pid=349145) 	mov.u16 %rs46, %rs25;
(EngineCore_DP0 pid=349145) 	@%p20 ld.global.b16 { %rs46 }, [ %rd19 + 0 ];
(EngineCore_DP0 pid=349145) 	// end inline asm
(EngineCore_DP0 pid=349145) 	.loc	1 215 79                        // quant_slide_tuned_Llama3.2-1B.py:215:79
(EngineCore_DP0 pid=349145) 	cvt.f32.bf16 	%r147, %rs40;
(EngineCore_DP0 pid=349145) 	cvt.f32.bf16 	%r148, %rs42;
(EngineCore_DP0 pid=349145) 	cvt.f32.bf16 	%r149, %rs44;
(EngineCore_DP0 pid=349145) 	cvt.f32.bf16 	%r150, %rs46;
(EngineCore_DP0 pid=349145) 	.loc	1 217 37                        // quant_slide_tuned_Llama3.2-1B.py:217:37
(EngineCore_DP0 pid=349145) 	and.pred 	%p21, %p25, %p40;
(EngineCore_DP0 pid=349145) 	and.pred 	%p22, %p25, %p36;
(EngineCore_DP0 pid=349145) 	and.pred 	%p23, %p25, %p35;
(EngineCore_DP0 pid=349145) 	and.pred 	%p24, %p25, %p34;
(EngineCore_DP0 pid=349145) 	.loc	1 216 39                        // quant_slide_tuned_Llama3.2-1B.py:216:39
(EngineCore_DP0 pid=349145) 	add.s64 	%rd20, %rd8, 6;
(EngineCore_DP0 pid=349145) 	add.s64 	%rd21, %rd9, 6;
(EngineCore_DP0 pid=349145) 	add.s64 	%rd22, %rd10, 6;
(EngineCore_DP0 pid=349145) 	add.s64 	%rd23, %rd11, 6;
(EngineCore_DP0 pid=349145) 	.loc	1 216 21                        // quant_slide_tuned_Llama3.2-1B.py:216:21
(EngineCore_DP0 pid=349145) 	// begin inline asm
(EngineCore_DP0 pid=349145) 	mov.u16 %rs48, %rs25;
(EngineCore_DP0 pid=349145) 	@%p21 ld.global.b16 { %rs48 }, [ %rd20 + 0 ];
(EngineCore_DP0 pid=349145) 	// end inline asm
(EngineCore_DP0 pid=349145) 	// begin inline asm
(EngineCore_DP0 pid=349145) 	mov.u16 %rs50, %rs25;
(EngineCore_DP0 pid=349145) 	@%p22 ld.global.b16 { %rs50 }, [ %rd21 + 0 ];
(EngineCore_DP0 pid=349145) 	// end inline asm
(EngineCore_DP0 pid=349145) 	// begin inline asm
(EngineCore_DP0 pid=349145) 	mov.u16 %rs52, %rs25;
(EngineCore_DP0 pid=349145) 	@%p23 ld.global.b16 { %rs52 }, [ %rd22 + 0 ];
(EngineCore_DP0 pid=349145) 	// end inline asm
(EngineCore_DP0 pid=349145) 	// begin inline asm
(EngineCore_DP0 pid=349145) 	mov.u16 %rs54, %rs25;
(EngineCore_DP0 pid=349145) 	@%p24 ld.global.b16 { %rs54 }, [ %rd23 + 0 ];
(EngineCore_DP0 pid=349145) 	// end inline asm
(EngineCore_DP0 pid=349145) 	.loc	1 217 79                        // quant_slide_tuned_Llama3.2-1B.py:217:79
(EngineCore_DP0 pid=349145) 	cvt.f32.bf16 	%r151, %rs48;
(EngineCore_DP0 pid=349145) 	cvt.f32.bf16 	%r152, %rs50;
(EngineCore_DP0 pid=349145) 	cvt.f32.bf16 	%r153, %rs52;
(EngineCore_DP0 pid=349145) 	cvt.f32.bf16 	%r154, %rs54;
(EngineCore_DP0 pid=349145) 	.loc	1 219 27                        // quant_slide_tuned_Llama3.2-1B.py:219:27
(EngineCore_DP0 pid=349145) 	mul.f32 	%r155, %r14, %r127;
(EngineCore_DP0 pid=349145) 	mul.f32 	%r156, %r14, %r128;
(EngineCore_DP0 pid=349145) 	mul.f32 	%r157, %r14, %r129;
(EngineCore_DP0 pid=349145) 	mul.f32 	%r158, %r14, %r130;
(EngineCore_DP0 pid=349145) 	mov.b32 	%r159, 0f43E00000;
(EngineCore_DP0 pid=349145) 	.loc	1 219 48                        // quant_slide_tuned_Llama3.2-1B.py:219:48
(EngineCore_DP0 pid=349145) 	min.xorsign.abs.f32 	%r82, %r155, %r159;
(EngineCore_DP0 pid=349145) 	min.xorsign.abs.f32 	%r83, %r156, %r159;
(EngineCore_DP0 pid=349145) 	min.xorsign.abs.f32 	%r84, %r157, %r159;
(EngineCore_DP0 pid=349145) 	min.xorsign.abs.f32 	%r85, %r158, %r159;
(EngineCore_DP0 pid=349145) 	.loc	1 219 60                        // quant_slide_tuned_Llama3.2-1B.py:219:60
(EngineCore_DP0 pid=349145) 	// begin inline asm
(EngineCore_DP0 pid=349145) 	cvt.rn.satfinite.e4m3x2.f32  %rs56, %r83, %r82; 
(EngineCore_DP0 pid=349145) 
(EngineCore_DP0 pid=349145) 	// end inline asm
(EngineCore_DP0 pid=349145) 	shr.u16 	%rs64, %rs56, 8;
(EngineCore_DP0 pid=349145) 	// begin inline asm
(EngineCore_DP0 pid=349145) 	cvt.rn.satfinite.e4m3x2.f32  %rs57, %r85, %r84; 
(EngineCore_DP0 pid=349145) 
(EngineCore_DP0 pid=349145) 	// end inline asm
(EngineCore_DP0 pid=349145) 	shr.u16 	%rs65, %rs57, 8;
(EngineCore_DP0 pid=349145) 	.loc	1 220 27                        // quant_slide_tuned_Llama3.2-1B.py:220:27
(EngineCore_DP0 pid=349145) 	mul.f32 	%r160, %r14, %r135;
(EngineCore_DP0 pid=349145) 	mul.f32 	%r161, %r14, %r136;
(EngineCore_DP0 pid=349145) 	mul.f32 	%r162, %r14, %r137;
(EngineCore_DP0 pid=349145) 	mul.f32 	%r163, %r14, %r138;
(EngineCore_DP0 pid=349145) 	.loc	1 220 48                        // quant_slide_tuned_Llama3.2-1B.py:220:48
(EngineCore_DP0 pid=349145) 	min.xorsign.abs.f32 	%r86, %r160, %r159;
(EngineCore_DP0 pid=349145) 	min.xorsign.abs.f32 	%r87, %r161, %r159;
(EngineCore_DP0 pid=349145) 	min.xorsign.abs.f32 	%r88, %r162, %r159;
(EngineCore_DP0 pid=349145) 	min.xorsign.abs.f32 	%r89, %r163, %r159;
(EngineCore_DP0 pid=349145) 	.loc	1 220 60                        // quant_slide_tuned_Llama3.2-1B.py:220:60
(EngineCore_DP0 pid=349145) 	// begin inline asm
(EngineCore_DP0 pid=349145) 	cvt.rn.satfinite.e4m3x2.f32  %rs58, %r87, %r86; 
(EngineCore_DP0 pid=349145) 
(EngineCore_DP0 pid=349145) 	// end inline asm
(EngineCore_DP0 pid=349145) 	shr.u16 	%rs66, %rs58, 8;
(EngineCore_DP0 pid=349145) 	// begin inline asm
(EngineCore_DP0 pid=349145) 	cvt.rn.satfinite.e4m3x2.f32  %rs59, %r89, %r88; 
(EngineCore_DP0 pid=349145) 
(EngineCore_DP0 pid=349145) 	// end inline asm
(EngineCore_DP0 pid=349145) 	shr.u16 	%rs67, %rs59, 8;
(EngineCore_DP0 pid=349145) 	.loc	1 221 27                        // quant_slide_tuned_Llama3.2-1B.py:221:27
(EngineCore_DP0 pid=349145) 	mul.f32 	%r164, %r14, %r147;
(EngineCore_DP0 pid=349145) 	mul.f32 	%r165, %r14, %r148;
(EngineCore_DP0 pid=349145) 	mul.f32 	%r166, %r14, %r149;
(EngineCore_DP0 pid=349145) 	mul.f32 	%r167, %r14, %r150;
(EngineCore_DP0 pid=349145) 	.loc	1 221 48                        // quant_slide_tuned_Llama3.2-1B.py:221:48
(EngineCore_DP0 pid=349145) 	min.xorsign.abs.f32 	%r90, %r164, %r159;
(EngineCore_DP0 pid=349145) 	min.xorsign.abs.f32 	%r91, %r165, %r159;
(EngineCore_DP0 pid=349145) 	min.xorsign.abs.f32 	%r92, %r166, %r159;
(EngineCore_DP0 pid=349145) 	min.xorsign.abs.f32 	%r93, %r167, %r159;
(EngineCore_DP0 pid=349145) 	.loc	1 221 60                        // quant_slide_tuned_Llama3.2-1B.py:221:60
(EngineCore_DP0 pid=349145) 	// begin inline asm
(EngineCore_DP0 pid=349145) 	cvt.rn.satfinite.e4m3x2.f32  %rs60, %r91, %r90; 
(EngineCore_DP0 pid=349145) 
(EngineCore_DP0 pid=349145) 	// end inline asm
(EngineCore_DP0 pid=349145) 	shr.u16 	%rs68, %rs60, 8;
(EngineCore_DP0 pid=349145) 	// begin inline asm
(EngineCore_DP0 pid=349145) 	cvt.rn.satfinite.e4m3x2.f32  %rs61, %r93, %r92; 
(EngineCore_DP0 pid=349145) 
(EngineCore_DP0 pid=349145) 	// end inline asm
(EngineCore_DP0 pid=349145) 	shr.u16 	%rs69, %rs61, 8;
(EngineCore_DP0 pid=349145) 	.loc	1 222 27                        // quant_slide_tuned_Llama3.2-1B.py:222:27
(EngineCore_DP0 pid=349145) 	mul.f32 	%r168, %r14, %r151;
(EngineCore_DP0 pid=349145) 	mul.f32 	%r169, %r14, %r152;
(EngineCore_DP0 pid=349145) 	mul.f32 	%r170, %r14, %r153;
(EngineCore_DP0 pid=349145) 	mul.f32 	%r171, %r14, %r154;
(EngineCore_DP0 pid=349145) 	.loc	1 222 48                        // quant_slide_tuned_Llama3.2-1B.py:222:48
(EngineCore_DP0 pid=349145) 	min.xorsign.abs.f32 	%r94, %r168, %r159;
(EngineCore_DP0 pid=349145) 	min.xorsign.abs.f32 	%r95, %r169, %r159;
(EngineCore_DP0 pid=349145) 	min.xorsign.abs.f32 	%r96, %r170, %r159;
(EngineCore_DP0 pid=349145) 	min.xorsign.abs.f32 	%r97, %r171, %r159;
(EngineCore_DP0 pid=349145) 	.loc	1 222 60                        // quant_slide_tuned_Llama3.2-1B.py:222:60
(EngineCore_DP0 pid=349145) 	// begin inline asm
(EngineCore_DP0 pid=349145) 	cvt.rn.satfinite.e4m3x2.f32  %rs62, %r95, %r94; 
(EngineCore_DP0 pid=349145) 
(EngineCore_DP0 pid=349145) 	// end inline asm
(EngineCore_DP0 pid=349145) 	shr.u16 	%rs70, %rs62, 8;
(EngineCore_DP0 pid=349145) 	// begin inline asm
(EngineCore_DP0 pid=349145) 	cvt.rn.satfinite.e4m3x2.f32  %rs63, %r97, %r96; 
(EngineCore_DP0 pid=349145) 
(EngineCore_DP0 pid=349145) 	// end inline asm
(EngineCore_DP0 pid=349145) 	shr.u16 	%rs71, %rs63, 8;
(EngineCore_DP0 pid=349145) 	.loc	1 224 45                        // quant_slide_tuned_Llama3.2-1B.py:224:45
(EngineCore_DP0 pid=349145) 	cvt.u32.u16 	%r172, %rs56;
(EngineCore_DP0 pid=349145) 	and.b32 	%r173, %r172, 255;
(EngineCore_DP0 pid=349145) 	cvt.u32.u16 	%r174, %rs64;
(EngineCore_DP0 pid=349145) 	cvt.u32.u16 	%r175, %rs57;
(EngineCore_DP0 pid=349145) 	and.b32 	%r176, %r175, 255;
(EngineCore_DP0 pid=349145) 	cvt.u32.u16 	%r177, %rs65;
(EngineCore_DP0 pid=349145) 	.loc	1 226 45                        // quant_slide_tuned_Llama3.2-1B.py:226:45
(EngineCore_DP0 pid=349145) 	cvt.u32.u16 	%r178, %rs60;
(EngineCore_DP0 pid=349145) 	and.b32 	%r179, %r178, 255;
(EngineCore_DP0 pid=349145) 	cvt.u32.u16 	%r180, %rs68;
(EngineCore_DP0 pid=349145) 	cvt.u32.u16 	%r181, %rs61;
(EngineCore_DP0 pid=349145) 	and.b32 	%r182, %r181, 255;
(EngineCore_DP0 pid=349145) 	cvt.u32.u16 	%r183, %rs69;
(EngineCore_DP0 pid=349145) 	.loc	1 227 45                        // quant_slide_tuned_Llama3.2-1B.py:227:45
(EngineCore_DP0 pid=349145) 	cvt.u32.u16 	%r184, %rs62;
(EngineCore_DP0 pid=349145) 	cvt.u32.u16 	%r185, %rs70;
(EngineCore_DP0 pid=349145) 	cvt.u32.u16 	%r186, %rs63;
(EngineCore_DP0 pid=349145) 	cvt.u32.u16 	%r187, %rs71;
(EngineCore_DP0 pid=349145) 	.loc	1 229 30                        // quant_slide_tuned_Llama3.2-1B.py:229:30
(EngineCore_DP0 pid=349145) 	and.b16 	%rs72, %rs58, 255;
(EngineCore_DP0 pid=349145) 	mul.wide.u16 	%r188, %rs72, 256;
(EngineCore_DP0 pid=349145) 	mul.wide.u16 	%r189, %rs66, 256;
(EngineCore_DP0 pid=349145) 	and.b16 	%rs73, %rs59, 255;
(EngineCore_DP0 pid=349145) 	mul.wide.u16 	%r190, %rs73, 256;
(EngineCore_DP0 pid=349145) 	mul.wide.u16 	%r191, %rs67, 256;
(EngineCore_DP0 pid=349145) 	.loc	1 229 24                        // quant_slide_tuned_Llama3.2-1B.py:229:24
(EngineCore_DP0 pid=349145) 	or.b32 	%r192, %r188, %r173;
(EngineCore_DP0 pid=349145) 	or.b32 	%r193, %r189, %r174;
(EngineCore_DP0 pid=349145) 	or.b32 	%r194, %r190, %r176;
(EngineCore_DP0 pid=349145) 	or.b32 	%r195, %r191, %r177;
(EngineCore_DP0 pid=349145) 	.loc	1 229 42                        // quant_slide_tuned_Llama3.2-1B.py:229:42
(EngineCore_DP0 pid=349145) 	shl.b32 	%r196, %r179, 16;
(EngineCore_DP0 pid=349145) 	shl.b32 	%r197, %r180, 16;
(EngineCore_DP0 pid=349145) 	shl.b32 	%r198, %r182, 16;
(EngineCore_DP0 pid=349145) 	shl.b32 	%r199, %r183, 16;
(EngineCore_DP0 pid=349145) 	.loc	1 229 36                        // quant_slide_tuned_Llama3.2-1B.py:229:36
(EngineCore_DP0 pid=349145) 	or.b32 	%r200, %r196, %r192;
(EngineCore_DP0 pid=349145) 	or.b32 	%r201, %r197, %r193;
(EngineCore_DP0 pid=349145) 	or.b32 	%r202, %r198, %r194;
(EngineCore_DP0 pid=349145) 	or.b32 	%r203, %r199, %r195;
(EngineCore_DP0 pid=349145) 	.loc	1 229 55                        // quant_slide_tuned_Llama3.2-1B.py:229:55
(EngineCore_DP0 pid=349145) 	shl.b32 	%r204, %r184, 24;
(EngineCore_DP0 pid=349145) 	shl.b32 	%r205, %r185, 24;
(EngineCore_DP0 pid=349145) 	shl.b32 	%r206, %r186, 24;
(EngineCore_DP0 pid=349145) 	shl.b32 	%r207, %r187, 24;
(EngineCore_DP0 pid=349145) 	.loc	1 229 49                        // quant_slide_tuned_Llama3.2-1B.py:229:49
(EngineCore_DP0 pid=349145) 	or.b32 	%r98, %r204, %r200;
(EngineCore_DP0 pid=349145) 	or.b32 	%r99, %r205, %r201;
(EngineCore_DP0 pid=349145) 	or.b32 	%r100, %r206, %r202;
(EngineCore_DP0 pid=349145) 	or.b32 	%r101, %r207, %r203;
(EngineCore_DP0 pid=349145) 	.loc	1 230 29                        // quant_slide_tuned_Llama3.2-1B.py:230:29
(EngineCore_DP0 pid=349145) 	mad.wide.s32 	%rd24, %r102, 4, %rd2;
(EngineCore_DP0 pid=349145) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-1B.py:230:39
(EngineCore_DP0 pid=349145) 	// begin inline asm
(EngineCore_DP0 pid=349145) 	@%p25 st.global.v4.b32 [ %rd24 + 0 ], { %r98, %r99, %r100, %r101 };
(EngineCore_DP0 pid=349145) 	// end inline asm
(EngineCore_DP0 pid=349145) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=349145) 	add.s32 	%r211, %r211, 2048;
(EngineCore_DP0 pid=349145) 	setp.lt.s32 	%p42, %r211, %r15;
(EngineCore_DP0 pid=349145) 	@%p42 bra 	$L__BB0_6;
(EngineCore_DP0 pid=349145) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=349145) 	.loc	1 201 4                         // quant_slide_tuned_Llama3.2-1B.py:201:4
(EngineCore_DP0 pid=349145) 	ret;
(EngineCore_DP0 pid=349145) $L__tmp3:
(EngineCore_DP0 pid=349145) $L__func_end0:
(EngineCore_DP0 pid=349145)                                         // -- End function
(EngineCore_DP0 pid=349145) }
(EngineCore_DP0 pid=349145) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=349145) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=349145) 	.section	.debug_abbrev
(EngineCore_DP0 pid=349145) 	{
(EngineCore_DP0 pid=349145) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=349145) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=349145) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=349145) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=349145) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=349145) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=349145) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=349145) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=349145) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=349145) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=349145) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=349145) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=349145) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=349145) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=349145) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=349145) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=349145) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=349145) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=349145) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=349145) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=349145) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=349145) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=349145) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=349145) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=349145) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=349145) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=349145) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=349145) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=349145) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=349145) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=349145) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=349145) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=349145) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=349145) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=349145) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=349145) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=349145) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=349145) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=349145) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=349145) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=349145) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=349145) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=349145) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=349145) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=349145) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=349145) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=349145) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=349145) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=349145) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=349145) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=349145) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=349145) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=349145) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=349145) 	}
(EngineCore_DP0 pid=349145) 	.section	.debug_info
(EngineCore_DP0 pid=349145) 	{
(EngineCore_DP0 pid=349145) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=349145) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=349145) .b8 0
(EngineCore_DP0 pid=349145) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=349145) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=349145) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=349145) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=349145) .b8 114
(EngineCore_DP0 pid=349145) .b8 105
(EngineCore_DP0 pid=349145) .b8 116
(EngineCore_DP0 pid=349145) .b8 111
(EngineCore_DP0 pid=349145) .b8 110
(EngineCore_DP0 pid=349145) .b8 0
(EngineCore_DP0 pid=349145) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=349145) .b8 0
(EngineCore_DP0 pid=349145) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=349145) .b8 117
(EngineCore_DP0 pid=349145) .b8 97
(EngineCore_DP0 pid=349145) .b8 110
(EngineCore_DP0 pid=349145) .b8 116
(EngineCore_DP0 pid=349145) .b8 95
(EngineCore_DP0 pid=349145) .b8 115
(EngineCore_DP0 pid=349145) .b8 108
(EngineCore_DP0 pid=349145) .b8 105
(EngineCore_DP0 pid=349145) .b8 100
(EngineCore_DP0 pid=349145) .b8 101
(EngineCore_DP0 pid=349145) .b8 95
(EngineCore_DP0 pid=349145) .b8 116
(EngineCore_DP0 pid=349145) .b8 117
(EngineCore_DP0 pid=349145) .b8 110
(EngineCore_DP0 pid=349145) .b8 101
(EngineCore_DP0 pid=349145) .b8 100
(EngineCore_DP0 pid=349145) .b8 95
(EngineCore_DP0 pid=349145) .b8 76
(EngineCore_DP0 pid=349145) .b8 108
(EngineCore_DP0 pid=349145) .b8 97
(EngineCore_DP0 pid=349145) .b8 109
(EngineCore_DP0 pid=349145) .b8 97
(EngineCore_DP0 pid=349145) .b8 51
(EngineCore_DP0 pid=349145) .b8 46
(EngineCore_DP0 pid=349145) .b8 50
(EngineCore_DP0 pid=349145) .b8 45
(EngineCore_DP0 pid=349145) .b8 49
(EngineCore_DP0 pid=349145) .b8 66
(EngineCore_DP0 pid=349145) .b8 46
(EngineCore_DP0 pid=349145) .b8 112
(EngineCore_DP0 pid=349145) .b8 121
(EngineCore_DP0 pid=349145) .b8 0
(EngineCore_DP0 pid=349145) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=349145) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=349145) .b8 114
(EngineCore_DP0 pid=349145) .b8 111
(EngineCore_DP0 pid=349145) .b8 111
(EngineCore_DP0 pid=349145) .b8 116
(EngineCore_DP0 pid=349145) .b8 47
(EngineCore_DP0 pid=349145) .b8 118
(EngineCore_DP0 pid=349145) .b8 108
(EngineCore_DP0 pid=349145) .b8 108
(EngineCore_DP0 pid=349145) .b8 109
(EngineCore_DP0 pid=349145) .b8 98
(EngineCore_DP0 pid=349145) .b8 101
(EngineCore_DP0 pid=349145) .b8 110
(EngineCore_DP0 pid=349145) .b8 99
(EngineCore_DP0 pid=349145) .b8 104
(EngineCore_DP0 pid=349145) .b8 47
(EngineCore_DP0 pid=349145) .b8 115
(EngineCore_DP0 pid=349145) .b8 108
(EngineCore_DP0 pid=349145) .b8 105
(EngineCore_DP0 pid=349145) .b8 100
(EngineCore_DP0 pid=349145) .b8 101
(EngineCore_DP0 pid=349145) .b8 115
(EngineCore_DP0 pid=349145) .b8 112
(EngineCore_DP0 pid=349145) .b8 97
(EngineCore_DP0 pid=349145) .b8 114
(EngineCore_DP0 pid=349145) .b8 115
(EngineCore_DP0 pid=349145) .b8 101
(EngineCore_DP0 pid=349145) .b8 47
(EngineCore_DP0 pid=349145) .b8 99
(EngineCore_DP0 pid=349145) .b8 115
(EngineCore_DP0 pid=349145) .b8 114
(EngineCore_DP0 pid=349145) .b8 99
(EngineCore_DP0 pid=349145) .b8 47
(EngineCore_DP0 pid=349145) .b8 102
(EngineCore_DP0 pid=349145) .b8 117
(EngineCore_DP0 pid=349145) .b8 115
(EngineCore_DP0 pid=349145) .b8 101
(EngineCore_DP0 pid=349145) .b8 100
(EngineCore_DP0 pid=349145) .b8 95
(EngineCore_DP0 pid=349145) .b8 113
(EngineCore_DP0 pid=349145) .b8 117
(EngineCore_DP0 pid=349145) .b8 97
(EngineCore_DP0 pid=349145) .b8 110
(EngineCore_DP0 pid=349145) .b8 116
(EngineCore_DP0 pid=349145) .b8 95
(EngineCore_DP0 pid=349145) .b8 115
(EngineCore_DP0 pid=349145) .b8 108
(EngineCore_DP0 pid=349145) .b8 105
(EngineCore_DP0 pid=349145) .b8 100
(EngineCore_DP0 pid=349145) .b8 101
(EngineCore_DP0 pid=349145) .b8 95
(EngineCore_DP0 pid=349145) .b8 116
(EngineCore_DP0 pid=349145) .b8 114
(EngineCore_DP0 pid=349145) .b8 105
(EngineCore_DP0 pid=349145) .b8 116
(EngineCore_DP0 pid=349145) .b8 111
(EngineCore_DP0 pid=349145) .b8 110
(EngineCore_DP0 pid=349145) .b8 47
(EngineCore_DP0 pid=349145) .b8 98
(EngineCore_DP0 pid=349145) .b8 117
(EngineCore_DP0 pid=349145) .b8 105
(EngineCore_DP0 pid=349145) .b8 108
(EngineCore_DP0 pid=349145) .b8 100
(EngineCore_DP0 pid=349145) .b8 47
(EngineCore_DP0 pid=349145) .b8 71
(EngineCore_DP0 pid=349145) .b8 66
(EngineCore_DP0 pid=349145) .b8 49
(EngineCore_DP0 pid=349145) .b8 48
(EngineCore_DP0 pid=349145) .b8 95
(EngineCore_DP0 pid=349145) .b8 99
(EngineCore_DP0 pid=349145) .b8 99
(EngineCore_DP0 pid=349145) .b8 49
(EngineCore_DP0 pid=349145) .b8 50
(EngineCore_DP0 pid=349145) .b8 49
(EngineCore_DP0 pid=349145) .b8 95
(EngineCore_DP0 pid=349145) .b8 112
(EngineCore_DP0 pid=349145) .b8 121
(EngineCore_DP0 pid=349145) .b8 51
(EngineCore_DP0 pid=349145) .b8 49
(EngineCore_DP0 pid=349145) .b8 50
(EngineCore_DP0 pid=349145) .b8 95
(EngineCore_DP0 pid=349145) .b8 99
(EngineCore_DP0 pid=349145) .b8 117
(EngineCore_DP0 pid=349145) .b8 49
(EngineCore_DP0 pid=349145) .b8 50
(EngineCore_DP0 pid=349145) .b8 57
(EngineCore_DP0 pid=349145) .b8 95
(EngineCore_DP0 pid=349145) .b8 97
(EngineCore_DP0 pid=349145) .b8 97
(EngineCore_DP0 pid=349145) .b8 114
(EngineCore_DP0 pid=349145) .b8 99
(EngineCore_DP0 pid=349145) .b8 104
(EngineCore_DP0 pid=349145) .b8 54
(EngineCore_DP0 pid=349145) .b8 52
(EngineCore_DP0 pid=349145) .b8 0
(EngineCore_DP0 pid=349145) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=349145) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=349145) .b8 113
(EngineCore_DP0 pid=349145) .b8 117
(EngineCore_DP0 pid=349145) .b8 97
(EngineCore_DP0 pid=349145) .b8 110
(EngineCore_DP0 pid=349145) .b8 116
(EngineCore_DP0 pid=349145) .b8 95
(EngineCore_DP0 pid=349145) .b8 115
(EngineCore_DP0 pid=349145) .b8 108
(EngineCore_DP0 pid=349145) .b8 105
(EngineCore_DP0 pid=349145) .b8 100
(EngineCore_DP0 pid=349145) .b8 101
(EngineCore_DP0 pid=349145) .b8 95
(EngineCore_DP0 pid=349145) .b8 102
(EngineCore_DP0 pid=349145) .b8 112
(EngineCore_DP0 pid=349145) .b8 56
(EngineCore_DP0 pid=349145) .b8 95
(EngineCore_DP0 pid=349145) .b8 107
(EngineCore_DP0 pid=349145) .b8 101
(EngineCore_DP0 pid=349145) .b8 114
(EngineCore_DP0 pid=349145) .b8 110
(EngineCore_DP0 pid=349145) .b8 101
(EngineCore_DP0 pid=349145) .b8 108
(EngineCore_DP0 pid=349145) .b8 0
(EngineCore_DP0 pid=349145) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=349145) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=349145) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=349145) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=349145) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=349145) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=349145) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=349145) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=349145) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=349145) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=349145) .b8 191                                 // DW_AT_call_line
(EngineCore_DP0 pid=349145) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=349145) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=349145) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=349145) 	}
(EngineCore_DP0 pid=349145) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=349145) 
(EngineCore_DP0 pid=349145) ================================================================
(EngineCore_DP0 pid=349145) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=349145) 
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp11s6nh74.ptx', '-o', '/tmp/tmp11s6nh74.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866] 
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866] 
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866] 
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp11s6nh74.ptx -o /tmp/tmp11s6nh74.ptx.o
(EngineCore_DP0 pid=349145) ERROR 01-25 19:26:09 [core.py:866] 

STDERR:
[2026-01-25 19:25:52] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:25:52] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:25:52] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:25:52] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:25:52] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:25:52] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:25:52] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:25:52] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:25:52] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:25:52] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:25:52] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:25:52] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:25:52] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:25:52] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:25:56] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:25:56] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:25:56] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:25:56] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:25:56] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:25:56] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:25:56] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:25:56] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:25:56] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:25:56] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:25:56] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:25:56] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:25:56] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:25:56] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=349145) [2026-01-25 19:25:56] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=349145) [2026-01-25 19:25:57] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=349145) [2026-01-25 19:25:57] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=349145) [2026-01-25 19:25:57] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=349145) [2026-01-25 19:25:57] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=349145) [2026-01-25 19:25:57] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=349145) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=349145) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.94s/it]
(EngineCore_DP0 pid=349145) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.94s/it]
(EngineCore_DP0 pid=349145) 
(EngineCore_DP0 pid=349145) [2026-01-25 19:26:08] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=349145) [2026-01-25 19:26:08] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6340608 bytes
(EngineCore_DP0 pid=349145) [2026-01-25 19:26:08] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=349145) [2026-01-25 19:26:08] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 4227072 bytes
(EngineCore_DP0 pid=349145) [2026-01-25 19:26:08] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=349145) [2026-01-25 19:26:08] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 33816576 bytes
(EngineCore_DP0 pid=349145) [2026-01-25 19:26:08] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=349145) [2026-01-25 19:26:08] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16809984 bytes
(EngineCore_DP0 pid=349145) Process EngineCore_DP0:
(EngineCore_DP0 pid=349145) Traceback (most recent call last):
(EngineCore_DP0 pid=349145)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=349145)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=349145)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=349145)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=349145) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp11s6nh74.ptx', '-o', '/tmp/tmp11s6nh74.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=349145) 
(EngineCore_DP0 pid=349145) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=349145) 
(EngineCore_DP0 pid=349145) Traceback (most recent call last):
(EngineCore_DP0 pid=349145)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=349145)     self.run()
(EngineCore_DP0 pid=349145)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=349145)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=349145)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=349145)     raise e
(EngineCore_DP0 pid=349145)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=349145)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=349145)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=349145)     super().__init__(
(EngineCore_DP0 pid=349145)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=349145)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=349145)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=349145)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=349145)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=349145)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=349145)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=349145)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=349145)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=349145)     return func(*args, **kwargs)
(EngineCore_DP0 pid=349145)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=349145)     return func(*args, **kwargs)
(EngineCore_DP0 pid=349145)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=349145)     self.model_runner.profile_run()
(EngineCore_DP0 pid=349145)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=349145)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=349145)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=349145)     return func(*args, **kwargs)
(EngineCore_DP0 pid=349145)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=349145)     outputs = self.model(
(EngineCore_DP0 pid=349145)               ^^^^^^^^^^^
(EngineCore_DP0 pid=349145)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=349145)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=349145)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=349145)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=349145)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=349145)     model_output = self.model(
(EngineCore_DP0 pid=349145)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=349145)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=349145)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=349145)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=349145)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=349145)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=349145)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=349145)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=349145)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=349145)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=349145)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=349145)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=349145)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=349145)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=349145)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=349145)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=349145)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=349145)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=349145)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=349145)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=349145)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=349145)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=349145)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=349145)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=349145)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=349145)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=349145)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=349145)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=349145)     return self._linear_fn(
(EngineCore_DP0 pid=349145)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=349145)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=349145)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=349145)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=349145)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=349145)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=349145)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=349145)     return fn(input, L)
(EngineCore_DP0 pid=349145)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=349145)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=349145)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=349145)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=349145)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=349145)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=349145)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=349145)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=349145)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=349145)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=349145)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=349145)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=349145)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=349145)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349145)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=349145)     raise PTXASError(error)
(EngineCore_DP0 pid=349145) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=349145) `ptxas` stderr:
(EngineCore_DP0 pid=349145) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=349145) 
(EngineCore_DP0 pid=349145) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp11s6nh74.ptx -o /tmp/tmp11s6nh74.ptx.o
(EngineCore_DP0 pid=349145) 
[rank0]:[W125 19:26:09.841258172 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=16384

========== M=32768 ==========
Time: 2026-01-25 19:26:11
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-1B-FP8_M32768.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:26:26 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:26:26 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=349798) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=349798) 
(EngineCore_DP0 pid=349798) 
(EngineCore_DP0 pid=349798) ================================================================
(EngineCore_DP0 pid=349798) Internal Triton PTX codegen error
(EngineCore_DP0 pid=349798) `ptxas` stderr:
(EngineCore_DP0 pid=349798) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=349798) 
(EngineCore_DP0 pid=349798) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpgr3ateil.ptx -o /tmp/tmpgr3ateil.ptx.o
(EngineCore_DP0 pid=349798) 
(EngineCore_DP0 pid=349798) 
(EngineCore_DP0 pid=349798) //
(EngineCore_DP0 pid=349798) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=349798) //
(EngineCore_DP0 pid=349798) 
(EngineCore_DP0 pid=349798) .version 8.7
(EngineCore_DP0 pid=349798) .target sm_121a
(EngineCore_DP0 pid=349798) .address_size 64
(EngineCore_DP0 pid=349798) 
(EngineCore_DP0 pid=349798) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=349798) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=349798)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=349798) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=349798) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=349798) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=349798) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=349798) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=349798) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=349798) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=349798) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=349798) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=349798) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=349798) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=349798) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=349798) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=349798) )
(EngineCore_DP0 pid=349798) .reqntid 512
(EngineCore_DP0 pid=349798) {
(EngineCore_DP0 pid=349798) 	.reg .pred 	%p<44>;
(EngineCore_DP0 pid=349798) 	.reg .b16 	%rs<74>;
(EngineCore_DP0 pid=349798) 	.reg .b32 	%r<212>;
(EngineCore_DP0 pid=349798) 	.reg .b64 	%rd<25>;
(EngineCore_DP0 pid=349798) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=349798) $L__func_begin0:
(EngineCore_DP0 pid=349798) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=349798) 
(EngineCore_DP0 pid=349798) // %bb.0:
(EngineCore_DP0 pid=349798) 	ld.param.b32 	%r29, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=349798) 	ld.param.b32 	%r28, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=349798) 	ld.param.b32 	%r27, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=349798) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=349798) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=349798) $L__tmp0:
(EngineCore_DP0 pid=349798) 	.loc	1 177 24                        // quant_slide_tuned_Llama3.2-1B.py:177:24
(EngineCore_DP0 pid=349798) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=349798) 	ld.param.b32 	%r31, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=349798) 	.loc	1 182 26                        // quant_slide_tuned_Llama3.2-1B.py:182:26
(EngineCore_DP0 pid=349798) 	mul.lo.s32 	%r32, %r31, %r1;
(EngineCore_DP0 pid=349798) 	.loc	1 182 20                        // quant_slide_tuned_Llama3.2-1B.py:182:20
(EngineCore_DP0 pid=349798) 	mad.wide.s32 	%rd1, %r32, 2, %rd4;
(EngineCore_DP0 pid=349798) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=349798) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=349798) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=349798) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=349798) 	setp.lt.s32 	%p1, %r28, 1;
(EngineCore_DP0 pid=349798) 	mov.b32 	%r210, 0f2B8CBCCC;
(EngineCore_DP0 pid=349798) 	setp.eq.b32 	%p43, %r2, 0;
(EngineCore_DP0 pid=349798) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=349798) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=349798) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=349798) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=349798) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=349798) 	shr.u32 	%r41, %r2, 3;
(EngineCore_DP0 pid=349798) 	and.b32 	%r42, %r41, 60;
(EngineCore_DP0 pid=349798) 	mov.b32 	%r43, global_smem;
(EngineCore_DP0 pid=349798) 	add.s32 	%r53, %r43, %r42;
(EngineCore_DP0 pid=349798) 	shl.b32 	%r44, %r2, 2;
(EngineCore_DP0 pid=349798) 	add.s32 	%r56, %r43, %r44;
(EngineCore_DP0 pid=349798) 	mov.b32 	%r49, 0;
(EngineCore_DP0 pid=349798) 	mov.b32 	%r208, 0f00000000;
(EngineCore_DP0 pid=349798) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=349798) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=349798) 	mov.b32 	%r209, %r49;
(EngineCore_DP0 pid=349798) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=349798) 	.loc	1 189 22                        // quant_slide_tuned_Llama3.2-1B.py:189:22
(EngineCore_DP0 pid=349798) 	add.s32 	%r59, %r4, %r209;
(EngineCore_DP0 pid=349798) 	setp.lt.s32 	%p2, %r59, %r27;
(EngineCore_DP0 pid=349798) 	.loc	1 190 29                        // quant_slide_tuned_Llama3.2-1B.py:190:29
(EngineCore_DP0 pid=349798) 	mad.wide.s32 	%rd6, %r59, 2, %rd1;
(EngineCore_DP0 pid=349798) 	.loc	1 190 21                        // quant_slide_tuned_Llama3.2-1B.py:190:21
(EngineCore_DP0 pid=349798) 	// begin inline asm
(EngineCore_DP0 pid=349798) 	mov.u32 %r45, %r49;
(EngineCore_DP0 pid=349798) 	mov.u32 %r46, %r49;
(EngineCore_DP0 pid=349798) 	mov.u32 %r47, %r49;
(EngineCore_DP0 pid=349798) 	mov.u32 %r48, %r49;
(EngineCore_DP0 pid=349798) 	@%p2 ld.global.v4.b32 { %r45, %r46, %r47, %r48 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=349798) 	// end inline asm
(EngineCore_DP0 pid=349798) 	mov.b32 	{%rs1, %rs2}, %r45;
(EngineCore_DP0 pid=349798) 	mov.b32 	{%rs3, %rs4}, %r46;
(EngineCore_DP0 pid=349798) 	mov.b32 	{%rs5, %rs6}, %r47;
(EngineCore_DP0 pid=349798) 	mov.b32 	{%rs7, %rs8}, %r48;
(EngineCore_DP0 pid=349798) 	.loc	1 191 50                        // quant_slide_tuned_Llama3.2-1B.py:191:50
(EngineCore_DP0 pid=349798) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=349798) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=349798) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=349798) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=349798) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=349798) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=349798) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=349798) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=349798) $L__tmp1:
(EngineCore_DP0 pid=349798) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=349798) 	bar.sync 	0;
(EngineCore_DP0 pid=349798) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=349798) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=349798) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=349798) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=349798) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=349798) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=349798) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=349798) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=349798) 	cvt.f32.bf16 	%r60, %rs23;
(EngineCore_DP0 pid=349798) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=349798) 	shfl.sync.bfly.b32 	%r61, %r60, 16, 31, -1;
(EngineCore_DP0 pid=349798) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=349798) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=349798) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=349798) 	shfl.sync.bfly.b32 	%r63, %r62, 8, 31, -1;
(EngineCore_DP0 pid=349798) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=349798) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=349798) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=349798) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=349798) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=349798) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=349798) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=349798) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=349798) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=349798) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=349798) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=349798) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=349798) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=349798) 	max.f32 	%r54, %r68, %r69;
(EngineCore_DP0 pid=349798) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=349798) 	// begin inline asm
(EngineCore_DP0 pid=349798) 	@%p3 st.shared.b32 [ %r53 + 0 ], %r54;
(EngineCore_DP0 pid=349798) 	// end inline asm
(EngineCore_DP0 pid=349798) 	bar.sync 	0;
(EngineCore_DP0 pid=349798) 	// begin inline asm
(EngineCore_DP0 pid=349798) 	@%p4 ld.shared.b32 %r55, [ %r56 + 0 ];
(EngineCore_DP0 pid=349798) 	// end inline asm
(EngineCore_DP0 pid=349798) 	shfl.sync.bfly.b32 	%r70, %r55, 8, 31, -1;
(EngineCore_DP0 pid=349798) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=349798) 	max.f32 	%r71, %r55, %r70;
(EngineCore_DP0 pid=349798) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=349798) 	shfl.sync.bfly.b32 	%r72, %r71, 4, 31, -1;
(EngineCore_DP0 pid=349798) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=349798) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=349798) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=349798) 	shfl.sync.bfly.b32 	%r74, %r73, 2, 31, -1;
(EngineCore_DP0 pid=349798) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=349798) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=349798) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=349798) 	shfl.sync.bfly.b32 	%r76, %r75, 1, 31, -1;
(EngineCore_DP0 pid=349798) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=349798) 	max.f32 	%r58, %r75, %r76;
(EngineCore_DP0 pid=349798) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=349798) 	// begin inline asm
(EngineCore_DP0 pid=349798) 	@%p43 st.shared.b32 [ %r56 + 0 ], %r58;
(EngineCore_DP0 pid=349798) 	// end inline asm
(EngineCore_DP0 pid=349798) 	bar.sync 	0;
(EngineCore_DP0 pid=349798) 	ld.shared.b32 	%r77, [global_smem];
(EngineCore_DP0 pid=349798) $L__tmp2:
(EngineCore_DP0 pid=349798) 	.loc	1 191 36                        // quant_slide_tuned_Llama3.2-1B.py:191:36
(EngineCore_DP0 pid=349798) 	max.f32 	%r208, %r208, %r77;
(EngineCore_DP0 pid=349798) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=349798) 	add.s32 	%r209, %r209, 4096;
(EngineCore_DP0 pid=349798) 	setp.lt.s32 	%p6, %r209, %r28;
(EngineCore_DP0 pid=349798) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=349798) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=349798) 	.loc	1 193 32                        // quant_slide_tuned_Llama3.2-1B.py:193:32
(EngineCore_DP0 pid=349798) 	max.f32 	%r210, %r208, 0f2B8CBCCC;
(EngineCore_DP0 pid=349798) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=349798) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=349798) 	mov.b32 	%r79, 0f43E00000;
(EngineCore_DP0 pid=349798) 	.loc	1 194 32                        // quant_slide_tuned_Llama3.2-1B.py:194:32
(EngineCore_DP0 pid=349798) 	div.full.f32 	%r80, %r210, %r79;
(EngineCore_DP0 pid=349798) 	.loc	1 194 41                        // quant_slide_tuned_Llama3.2-1B.py:194:41
(EngineCore_DP0 pid=349798) 	max.f32 	%r78, %r80, 0f36924925;
(EngineCore_DP0 pid=349798) 	.loc	1 196 25                        // quant_slide_tuned_Llama3.2-1B.py:196:25
(EngineCore_DP0 pid=349798) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=349798) 	.loc	1 196 30                        // quant_slide_tuned_Llama3.2-1B.py:196:30
(EngineCore_DP0 pid=349798) 	// begin inline asm
(EngineCore_DP0 pid=349798) 	@%p43 st.global.b32 [ %rd7 + 0 ], { %r78 };
(EngineCore_DP0 pid=349798) 	// end inline asm
(EngineCore_DP0 pid=349798) 	.loc	1 199 29                        // quant_slide_tuned_Llama3.2-1B.py:199:29
(EngineCore_DP0 pid=349798) 	shl.b32 	%r15, %r29, 2;
(EngineCore_DP0 pid=349798) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=349798) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=349798) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=349798) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=349798) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=349798) 	ld.param.b32 	%r33, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=349798) 	shr.s32 	%r34, %r33, 31;
(EngineCore_DP0 pid=349798) 	shr.u32 	%r35, %r34, 30;
(EngineCore_DP0 pid=349798) 	add.s32 	%r36, %r33, %r35;
(EngineCore_DP0 pid=349798) 	shr.s32 	%r37, %r36, 2;
(EngineCore_DP0 pid=349798) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=349798) 	mul.lo.s32 	%r38, %r37, %r1;
(EngineCore_DP0 pid=349798) 	mad.wide.s32 	%rd2, %r38, 4, %rd5;
(EngineCore_DP0 pid=349798) 	div.full.f32 	%r14, %r79, %r210;
(EngineCore_DP0 pid=349798) 	shl.b32 	%r16, %r3, 2;
(EngineCore_DP0 pid=349798) 	mov.b32 	%r211, 0;
(EngineCore_DP0 pid=349798) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=349798)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=349798) 	.loc	1 202 31                        // quant_slide_tuned_Llama3.2-1B.py:202:31
(EngineCore_DP0 pid=349798) 	add.s32 	%r102, %r16, %r211;
(EngineCore_DP0 pid=349798) 	or.b32 	%r103, %r211, 2;
(EngineCore_DP0 pid=349798) 	or.b32 	%r104, %r211, 3;
(EngineCore_DP0 pid=349798) 	.loc	1 203 30                        // quant_slide_tuned_Llama3.2-1B.py:203:30
(EngineCore_DP0 pid=349798) 	setp.lt.s32 	%p25, %r102, %r15;
(EngineCore_DP0 pid=349798) 	.loc	1 206 24                        // quant_slide_tuned_Llama3.2-1B.py:206:24
(EngineCore_DP0 pid=349798) 	shr.s32 	%r105, %r102, 2;
(EngineCore_DP0 pid=349798) 	.loc	1 207 23                        // quant_slide_tuned_Llama3.2-1B.py:207:23
(EngineCore_DP0 pid=349798) 	add.s32 	%r106, %r211, 1;
(EngineCore_DP0 pid=349798) 	shr.s32 	%r107, %r106, 31;
(EngineCore_DP0 pid=349798) 	shr.u32 	%r108, %r107, 30;
(EngineCore_DP0 pid=349798) 	add.s32 	%r109, %r106, %r108;
(EngineCore_DP0 pid=349798) 	and.b32 	%r110, %r109, 2147483644;
(EngineCore_DP0 pid=349798) 	sub.s32 	%r111, %r106, %r110;
(EngineCore_DP0 pid=349798) 	.loc	1 208 30                        // quant_slide_tuned_Llama3.2-1B.py:208:30
(EngineCore_DP0 pid=349798) 	shl.b32 	%r112, %r111, 1;
(EngineCore_DP0 pid=349798) 	.loc	1 208 22                        // quant_slide_tuned_Llama3.2-1B.py:208:22
(EngineCore_DP0 pid=349798) 	mul.lo.s32 	%r113, %r105, 10;
(EngineCore_DP0 pid=349798) 	.loc	1 208 26                        // quant_slide_tuned_Llama3.2-1B.py:208:26
(EngineCore_DP0 pid=349798) 	add.s32 	%r114, %r113, %r112;
(EngineCore_DP0 pid=349798) 	.loc	1 207 23                        // quant_slide_tuned_Llama3.2-1B.py:207:23
(EngineCore_DP0 pid=349798) 	shr.s32 	%r115, %r211, 31;
(EngineCore_DP0 pid=349798) 	shr.u32 	%r116, %r115, 30;
(EngineCore_DP0 pid=349798) 	add.s32 	%r117, %r104, %r116;
(EngineCore_DP0 pid=349798) 	and.b32 	%r118, %r117, 2147483644;
(EngineCore_DP0 pid=349798) 	sub.s32 	%r119, %r104, %r118;
(EngineCore_DP0 pid=349798) 	add.s32 	%r120, %r103, %r116;
(EngineCore_DP0 pid=349798) 	and.b32 	%r121, %r120, 2147483644;
(EngineCore_DP0 pid=349798) 	sub.s32 	%r122, %r103, %r121;
(EngineCore_DP0 pid=349798) 	.loc	1 208 30                        // quant_slide_tuned_Llama3.2-1B.py:208:30
(EngineCore_DP0 pid=349798) 	shl.b32 	%r123, %r122, 1;
(EngineCore_DP0 pid=349798) 	shl.b32 	%r124, %r119, 1;
(EngineCore_DP0 pid=349798) 	.loc	1 208 26                        // quant_slide_tuned_Llama3.2-1B.py:208:26
(EngineCore_DP0 pid=349798) 	add.s32 	%r125, %r113, %r124;
(EngineCore_DP0 pid=349798) 	add.s32 	%r126, %r113, %r123;
(EngineCore_DP0 pid=349798) 	.loc	1 211 53                        // quant_slide_tuned_Llama3.2-1B.py:211:53
(EngineCore_DP0 pid=349798) 	setp.lt.s32 	%p26, %r113, %r27;
(EngineCore_DP0 pid=349798) 	setp.lt.s32 	%p27, %r114, %r27;
(EngineCore_DP0 pid=349798) 	setp.lt.s32 	%p28, %r126, %r27;
(EngineCore_DP0 pid=349798) 	setp.lt.s32 	%p29, %r125, %r27;
(EngineCore_DP0 pid=349798) 	.loc	1 211 37                        // quant_slide_tuned_Llama3.2-1B.py:211:37
(EngineCore_DP0 pid=349798) 	and.pred 	%p9, %p25, %p26;
(EngineCore_DP0 pid=349798) 	and.pred 	%p10, %p25, %p27;
(EngineCore_DP0 pid=349798) 	and.pred 	%p11, %p25, %p28;
(EngineCore_DP0 pid=349798) 	and.pred 	%p12, %p25, %p29;
(EngineCore_DP0 pid=349798) 	.loc	1 210 29                        // quant_slide_tuned_Llama3.2-1B.py:210:29
(EngineCore_DP0 pid=349798) 	mad.wide.s32 	%rd8, %r113, 2, %rd1;
(EngineCore_DP0 pid=349798) 	mad.wide.s32 	%rd9, %r114, 2, %rd1;
(EngineCore_DP0 pid=349798) 	mad.wide.s32 	%rd10, %r126, 2, %rd1;
(EngineCore_DP0 pid=349798) 	mad.wide.s32 	%rd11, %r125, 2, %rd1;
(EngineCore_DP0 pid=349798) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=349798) 	.loc	1 210 21                        // quant_slide_tuned_Llama3.2-1B.py:210:21
(EngineCore_DP0 pid=349798) 	// begin inline asm
(EngineCore_DP0 pid=349798) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=349798) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=349798) 	// end inline asm
(EngineCore_DP0 pid=349798) 	// begin inline asm
(EngineCore_DP0 pid=349798) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=349798) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=349798) 	// end inline asm
(EngineCore_DP0 pid=349798) 	// begin inline asm
(EngineCore_DP0 pid=349798) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=349798) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=349798) 	// end inline asm
(EngineCore_DP0 pid=349798) 	// begin inline asm
(EngineCore_DP0 pid=349798) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=349798) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=349798) 	// end inline asm
(EngineCore_DP0 pid=349798) 	.loc	1 211 79                        // quant_slide_tuned_Llama3.2-1B.py:211:79
(EngineCore_DP0 pid=349798) 	cvt.f32.bf16 	%r127, %rs24;
(EngineCore_DP0 pid=349798) 	cvt.f32.bf16 	%r128, %rs26;
(EngineCore_DP0 pid=349798) 	cvt.f32.bf16 	%r129, %rs28;
(EngineCore_DP0 pid=349798) 	cvt.f32.bf16 	%r130, %rs30;
(EngineCore_DP0 pid=349798) 	.loc	1 213 48                        // quant_slide_tuned_Llama3.2-1B.py:213:48
(EngineCore_DP0 pid=349798) 	or.b32 	%r131, %r113, 1;
(EngineCore_DP0 pid=349798) 	or.b32 	%r132, %r114, 1;
(EngineCore_DP0 pid=349798) 	or.b32 	%r133, %r126, 1;
(EngineCore_DP0 pid=349798) 	or.b32 	%r134, %r125, 1;
(EngineCore_DP0 pid=349798) 	.loc	1 213 53                        // quant_slide_tuned_Llama3.2-1B.py:213:53
(EngineCore_DP0 pid=349798) 	setp.lt.s32 	%p30, %r131, %r27;
(EngineCore_DP0 pid=349798) 	setp.lt.s32 	%p31, %r132, %r27;
(EngineCore_DP0 pid=349798) 	setp.lt.s32 	%p32, %r133, %r27;
(EngineCore_DP0 pid=349798) 	setp.lt.s32 	%p33, %r134, %r27;
(EngineCore_DP0 pid=349798) 	.loc	1 213 37                        // quant_slide_tuned_Llama3.2-1B.py:213:37
(EngineCore_DP0 pid=349798) 	and.pred 	%p13, %p25, %p30;
(EngineCore_DP0 pid=349798) 	and.pred 	%p14, %p25, %p31;
(EngineCore_DP0 pid=349798) 	and.pred 	%p15, %p25, %p32;
(EngineCore_DP0 pid=349798) 	and.pred 	%p16, %p25, %p33;
(EngineCore_DP0 pid=349798) 	.loc	1 212 39                        // quant_slide_tuned_Llama3.2-1B.py:212:39
(EngineCore_DP0 pid=349798) 	add.s64 	%rd12, %rd8, 2;
(EngineCore_DP0 pid=349798) 	add.s64 	%rd13, %rd9, 2;
(EngineCore_DP0 pid=349798) 	add.s64 	%rd14, %rd10, 2;
(EngineCore_DP0 pid=349798) 	add.s64 	%rd15, %rd11, 2;
(EngineCore_DP0 pid=349798) 	.loc	1 212 21                        // quant_slide_tuned_Llama3.2-1B.py:212:21
(EngineCore_DP0 pid=349798) 	// begin inline asm
(EngineCore_DP0 pid=349798) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=349798) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=349798) 	// end inline asm
(EngineCore_DP0 pid=349798) 	// begin inline asm
(EngineCore_DP0 pid=349798) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=349798) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=349798) 	// end inline asm
(EngineCore_DP0 pid=349798) 	// begin inline asm
(EngineCore_DP0 pid=349798) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=349798) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=349798) 	// end inline asm
(EngineCore_DP0 pid=349798) 	// begin inline asm
(EngineCore_DP0 pid=349798) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=349798) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=349798) 	// end inline asm
(EngineCore_DP0 pid=349798) 	.loc	1 213 79                        // quant_slide_tuned_Llama3.2-1B.py:213:79
(EngineCore_DP0 pid=349798) 	cvt.f32.bf16 	%r135, %rs32;
(EngineCore_DP0 pid=349798) 	cvt.f32.bf16 	%r136, %rs34;
(EngineCore_DP0 pid=349798) 	cvt.f32.bf16 	%r137, %rs36;
(EngineCore_DP0 pid=349798) 	cvt.f32.bf16 	%r138, %rs38;
(EngineCore_DP0 pid=349798) 	.loc	1 217 48                        // quant_slide_tuned_Llama3.2-1B.py:217:48
(EngineCore_DP0 pid=349798) 	add.s32 	%r139, %r114, 2;
(EngineCore_DP0 pid=349798) 	add.s32 	%r140, %r126, 2;
(EngineCore_DP0 pid=349798) 	add.s32 	%r141, %r125, 2;
(EngineCore_DP0 pid=349798) 	add.s32 	%r142, %r114, 3;
(EngineCore_DP0 pid=349798) 	add.s32 	%r143, %r126, 3;
(EngineCore_DP0 pid=349798) 	add.s32 	%r144, %r125, 3;
(EngineCore_DP0 pid=349798) 	add.s32 	%r145, %r113, 2;
(EngineCore_DP0 pid=349798) 	add.s32 	%r146, %r113, 3;
(EngineCore_DP0 pid=349798) 	.loc	1 217 53                        // quant_slide_tuned_Llama3.2-1B.py:217:53
(EngineCore_DP0 pid=349798) 	setp.lt.s32 	%p34, %r144, %r27;
(EngineCore_DP0 pid=349798) 	setp.lt.s32 	%p35, %r143, %r27;
(EngineCore_DP0 pid=349798) 	setp.lt.s32 	%p36, %r142, %r27;
(EngineCore_DP0 pid=349798) 	setp.lt.s32 	%p37, %r141, %r27;
(EngineCore_DP0 pid=349798) 	setp.lt.s32 	%p38, %r140, %r27;
(EngineCore_DP0 pid=349798) 	setp.lt.s32 	%p39, %r139, %r27;
(EngineCore_DP0 pid=349798) 	setp.lt.s32 	%p40, %r146, %r27;
(EngineCore_DP0 pid=349798) 	setp.lt.s32 	%p41, %r145, %r27;
(EngineCore_DP0 pid=349798) 	.loc	1 215 37                        // quant_slide_tuned_Llama3.2-1B.py:215:37
(EngineCore_DP0 pid=349798) 	and.pred 	%p17, %p25, %p41;
(EngineCore_DP0 pid=349798) 	and.pred 	%p18, %p25, %p39;
(EngineCore_DP0 pid=349798) 	and.pred 	%p19, %p25, %p38;
(EngineCore_DP0 pid=349798) 	and.pred 	%p20, %p25, %p37;
(EngineCore_DP0 pid=349798) 	.loc	1 214 39                        // quant_slide_tuned_Llama3.2-1B.py:214:39
(EngineCore_DP0 pid=349798) 	add.s64 	%rd16, %rd8, 4;
(EngineCore_DP0 pid=349798) 	add.s64 	%rd17, %rd9, 4;
(EngineCore_DP0 pid=349798) 	add.s64 	%rd18, %rd10, 4;
(EngineCore_DP0 pid=349798) 	add.s64 	%rd19, %rd11, 4;
(EngineCore_DP0 pid=349798) 	.loc	1 214 21                        // quant_slide_tuned_Llama3.2-1B.py:214:21
(EngineCore_DP0 pid=349798) 	// begin inline asm
(EngineCore_DP0 pid=349798) 	mov.u16 %rs40, %rs25;
(EngineCore_DP0 pid=349798) 	@%p17 ld.global.b16 { %rs40 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=349798) 	// end inline asm
(EngineCore_DP0 pid=349798) 	// begin inline asm
(EngineCore_DP0 pid=349798) 	mov.u16 %rs42, %rs25;
(EngineCore_DP0 pid=349798) 	@%p18 ld.global.b16 { %rs42 }, [ %rd17 + 0 ];
(EngineCore_DP0 pid=349798) 	// end inline asm
(EngineCore_DP0 pid=349798) 	// begin inline asm
(EngineCore_DP0 pid=349798) 	mov.u16 %rs44, %rs25;
(EngineCore_DP0 pid=349798) 	@%p19 ld.global.b16 { %rs44 }, [ %rd18 + 0 ];
(EngineCore_DP0 pid=349798) 	// end inline asm
(EngineCore_DP0 pid=349798) 	// begin inline asm
(EngineCore_DP0 pid=349798) 	mov.u16 %rs46, %rs25;
(EngineCore_DP0 pid=349798) 	@%p20 ld.global.b16 { %rs46 }, [ %rd19 + 0 ];
(EngineCore_DP0 pid=349798) 	// end inline asm
(EngineCore_DP0 pid=349798) 	.loc	1 215 79                        // quant_slide_tuned_Llama3.2-1B.py:215:79
(EngineCore_DP0 pid=349798) 	cvt.f32.bf16 	%r147, %rs40;
(EngineCore_DP0 pid=349798) 	cvt.f32.bf16 	%r148, %rs42;
(EngineCore_DP0 pid=349798) 	cvt.f32.bf16 	%r149, %rs44;
(EngineCore_DP0 pid=349798) 	cvt.f32.bf16 	%r150, %rs46;
(EngineCore_DP0 pid=349798) 	.loc	1 217 37                        // quant_slide_tuned_Llama3.2-1B.py:217:37
(EngineCore_DP0 pid=349798) 	and.pred 	%p21, %p25, %p40;
(EngineCore_DP0 pid=349798) 	and.pred 	%p22, %p25, %p36;
(EngineCore_DP0 pid=349798) 	and.pred 	%p23, %p25, %p35;
(EngineCore_DP0 pid=349798) 	and.pred 	%p24, %p25, %p34;
(EngineCore_DP0 pid=349798) 	.loc	1 216 39                        // quant_slide_tuned_Llama3.2-1B.py:216:39
(EngineCore_DP0 pid=349798) 	add.s64 	%rd20, %rd8, 6;
(EngineCore_DP0 pid=349798) 	add.s64 	%rd21, %rd9, 6;
(EngineCore_DP0 pid=349798) 	add.s64 	%rd22, %rd10, 6;
(EngineCore_DP0 pid=349798) 	add.s64 	%rd23, %rd11, 6;
(EngineCore_DP0 pid=349798) 	.loc	1 216 21                        // quant_slide_tuned_Llama3.2-1B.py:216:21
(EngineCore_DP0 pid=349798) 	// begin inline asm
(EngineCore_DP0 pid=349798) 	mov.u16 %rs48, %rs25;
(EngineCore_DP0 pid=349798) 	@%p21 ld.global.b16 { %rs48 }, [ %rd20 + 0 ];
(EngineCore_DP0 pid=349798) 	// end inline asm
(EngineCore_DP0 pid=349798) 	// begin inline asm
(EngineCore_DP0 pid=349798) 	mov.u16 %rs50, %rs25;
(EngineCore_DP0 pid=349798) 	@%p22 ld.global.b16 { %rs50 }, [ %rd21 + 0 ];
(EngineCore_DP0 pid=349798) 	// end inline asm
(EngineCore_DP0 pid=349798) 	// begin inline asm
(EngineCore_DP0 pid=349798) 	mov.u16 %rs52, %rs25;
(EngineCore_DP0 pid=349798) 	@%p23 ld.global.b16 { %rs52 }, [ %rd22 + 0 ];
(EngineCore_DP0 pid=349798) 	// end inline asm
(EngineCore_DP0 pid=349798) 	// begin inline asm
(EngineCore_DP0 pid=349798) 	mov.u16 %rs54, %rs25;
(EngineCore_DP0 pid=349798) 	@%p24 ld.global.b16 { %rs54 }, [ %rd23 + 0 ];
(EngineCore_DP0 pid=349798) 	// end inline asm
(EngineCore_DP0 pid=349798) 	.loc	1 217 79                        // quant_slide_tuned_Llama3.2-1B.py:217:79
(EngineCore_DP0 pid=349798) 	cvt.f32.bf16 	%r151, %rs48;
(EngineCore_DP0 pid=349798) 	cvt.f32.bf16 	%r152, %rs50;
(EngineCore_DP0 pid=349798) 	cvt.f32.bf16 	%r153, %rs52;
(EngineCore_DP0 pid=349798) 	cvt.f32.bf16 	%r154, %rs54;
(EngineCore_DP0 pid=349798) 	.loc	1 219 27                        // quant_slide_tuned_Llama3.2-1B.py:219:27
(EngineCore_DP0 pid=349798) 	mul.f32 	%r155, %r14, %r127;
(EngineCore_DP0 pid=349798) 	mul.f32 	%r156, %r14, %r128;
(EngineCore_DP0 pid=349798) 	mul.f32 	%r157, %r14, %r129;
(EngineCore_DP0 pid=349798) 	mul.f32 	%r158, %r14, %r130;
(EngineCore_DP0 pid=349798) 	mov.b32 	%r159, 0f43E00000;
(EngineCore_DP0 pid=349798) 	.loc	1 219 48                        // quant_slide_tuned_Llama3.2-1B.py:219:48
(EngineCore_DP0 pid=349798) 	min.xorsign.abs.f32 	%r82, %r155, %r159;
(EngineCore_DP0 pid=349798) 	min.xorsign.abs.f32 	%r83, %r156, %r159;
(EngineCore_DP0 pid=349798) 	min.xorsign.abs.f32 	%r84, %r157, %r159;
(EngineCore_DP0 pid=349798) 	min.xorsign.abs.f32 	%r85, %r158, %r159;
(EngineCore_DP0 pid=349798) 	.loc	1 219 60                        // quant_slide_tuned_Llama3.2-1B.py:219:60
(EngineCore_DP0 pid=349798) 	// begin inline asm
(EngineCore_DP0 pid=349798) 	cvt.rn.satfinite.e4m3x2.f32  %rs56, %r83, %r82; 
(EngineCore_DP0 pid=349798) 
(EngineCore_DP0 pid=349798) 	// end inline asm
(EngineCore_DP0 pid=349798) 	shr.u16 	%rs64, %rs56, 8;
(EngineCore_DP0 pid=349798) 	// begin inline asm
(EngineCore_DP0 pid=349798) 	cvt.rn.satfinite.e4m3x2.f32  %rs57, %r85, %r84; 
(EngineCore_DP0 pid=349798) 
(EngineCore_DP0 pid=349798) 	// end inline asm
(EngineCore_DP0 pid=349798) 	shr.u16 	%rs65, %rs57, 8;
(EngineCore_DP0 pid=349798) 	.loc	1 220 27                        // quant_slide_tuned_Llama3.2-1B.py:220:27
(EngineCore_DP0 pid=349798) 	mul.f32 	%r160, %r14, %r135;
(EngineCore_DP0 pid=349798) 	mul.f32 	%r161, %r14, %r136;
(EngineCore_DP0 pid=349798) 	mul.f32 	%r162, %r14, %r137;
(EngineCore_DP0 pid=349798) 	mul.f32 	%r163, %r14, %r138;
(EngineCore_DP0 pid=349798) 	.loc	1 220 48                        // quant_slide_tuned_Llama3.2-1B.py:220:48
(EngineCore_DP0 pid=349798) 	min.xorsign.abs.f32 	%r86, %r160, %r159;
(EngineCore_DP0 pid=349798) 	min.xorsign.abs.f32 	%r87, %r161, %r159;
(EngineCore_DP0 pid=349798) 	min.xorsign.abs.f32 	%r88, %r162, %r159;
(EngineCore_DP0 pid=349798) 	min.xorsign.abs.f32 	%r89, %r163, %r159;
(EngineCore_DP0 pid=349798) 	.loc	1 220 60                        // quant_slide_tuned_Llama3.2-1B.py:220:60
(EngineCore_DP0 pid=349798) 	// begin inline asm
(EngineCore_DP0 pid=349798) 	cvt.rn.satfinite.e4m3x2.f32  %rs58, %r87, %r86; 
(EngineCore_DP0 pid=349798) 
(EngineCore_DP0 pid=349798) 	// end inline asm
(EngineCore_DP0 pid=349798) 	shr.u16 	%rs66, %rs58, 8;
(EngineCore_DP0 pid=349798) 	// begin inline asm
(EngineCore_DP0 pid=349798) 	cvt.rn.satfinite.e4m3x2.f32  %rs59, %r89, %r88; 
(EngineCore_DP0 pid=349798) 
(EngineCore_DP0 pid=349798) 	// end inline asm
(EngineCore_DP0 pid=349798) 	shr.u16 	%rs67, %rs59, 8;
(EngineCore_DP0 pid=349798) 	.loc	1 221 27                        // quant_slide_tuned_Llama3.2-1B.py:221:27
(EngineCore_DP0 pid=349798) 	mul.f32 	%r164, %r14, %r147;
(EngineCore_DP0 pid=349798) 	mul.f32 	%r165, %r14, %r148;
(EngineCore_DP0 pid=349798) 	mul.f32 	%r166, %r14, %r149;
(EngineCore_DP0 pid=349798) 	mul.f32 	%r167, %r14, %r150;
(EngineCore_DP0 pid=349798) 	.loc	1 221 48                        // quant_slide_tuned_Llama3.2-1B.py:221:48
(EngineCore_DP0 pid=349798) 	min.xorsign.abs.f32 	%r90, %r164, %r159;
(EngineCore_DP0 pid=349798) 	min.xorsign.abs.f32 	%r91, %r165, %r159;
(EngineCore_DP0 pid=349798) 	min.xorsign.abs.f32 	%r92, %r166, %r159;
(EngineCore_DP0 pid=349798) 	min.xorsign.abs.f32 	%r93, %r167, %r159;
(EngineCore_DP0 pid=349798) 	.loc	1 221 60                        // quant_slide_tuned_Llama3.2-1B.py:221:60
(EngineCore_DP0 pid=349798) 	// begin inline asm
(EngineCore_DP0 pid=349798) 	cvt.rn.satfinite.e4m3x2.f32  %rs60, %r91, %r90; 
(EngineCore_DP0 pid=349798) 
(EngineCore_DP0 pid=349798) 	// end inline asm
(EngineCore_DP0 pid=349798) 	shr.u16 	%rs68, %rs60, 8;
(EngineCore_DP0 pid=349798) 	// begin inline asm
(EngineCore_DP0 pid=349798) 	cvt.rn.satfinite.e4m3x2.f32  %rs61, %r93, %r92; 
(EngineCore_DP0 pid=349798) 
(EngineCore_DP0 pid=349798) 	// end inline asm
(EngineCore_DP0 pid=349798) 	shr.u16 	%rs69, %rs61, 8;
(EngineCore_DP0 pid=349798) 	.loc	1 222 27                        // quant_slide_tuned_Llama3.2-1B.py:222:27
(EngineCore_DP0 pid=349798) 	mul.f32 	%r168, %r14, %r151;
(EngineCore_DP0 pid=349798) 	mul.f32 	%r169, %r14, %r152;
(EngineCore_DP0 pid=349798) 	mul.f32 	%r170, %r14, %r153;
(EngineCore_DP0 pid=349798) 	mul.f32 	%r171, %r14, %r154;
(EngineCore_DP0 pid=349798) 	.loc	1 222 48                        // quant_slide_tuned_Llama3.2-1B.py:222:48
(EngineCore_DP0 pid=349798) 	min.xorsign.abs.f32 	%r94, %r168, %r159;
(EngineCore_DP0 pid=349798) 	min.xorsign.abs.f32 	%r95, %r169, %r159;
(EngineCore_DP0 pid=349798) 	min.xorsign.abs.f32 	%r96, %r170, %r159;
(EngineCore_DP0 pid=349798) 	min.xorsign.abs.f32 	%r97, %r171, %r159;
(EngineCore_DP0 pid=349798) 	.loc	1 222 60                        // quant_slide_tuned_Llama3.2-1B.py:222:60
(EngineCore_DP0 pid=349798) 	// begin inline asm
(EngineCore_DP0 pid=349798) 	cvt.rn.satfinite.e4m3x2.f32  %rs62, %r95, %r94; 
(EngineCore_DP0 pid=349798) 
(EngineCore_DP0 pid=349798) 	// end inline asm
(EngineCore_DP0 pid=349798) 	shr.u16 	%rs70, %rs62, 8;
(EngineCore_DP0 pid=349798) 	// begin inline asm
(EngineCore_DP0 pid=349798) 	cvt.rn.satfinite.e4m3x2.f32  %rs63, %r97, %r96; 
(EngineCore_DP0 pid=349798) 
(EngineCore_DP0 pid=349798) 	// end inline asm
(EngineCore_DP0 pid=349798) 	shr.u16 	%rs71, %rs63, 8;
(EngineCore_DP0 pid=349798) 	.loc	1 224 45                        // quant_slide_tuned_Llama3.2-1B.py:224:45
(EngineCore_DP0 pid=349798) 	cvt.u32.u16 	%r172, %rs56;
(EngineCore_DP0 pid=349798) 	and.b32 	%r173, %r172, 255;
(EngineCore_DP0 pid=349798) 	cvt.u32.u16 	%r174, %rs64;
(EngineCore_DP0 pid=349798) 	cvt.u32.u16 	%r175, %rs57;
(EngineCore_DP0 pid=349798) 	and.b32 	%r176, %r175, 255;
(EngineCore_DP0 pid=349798) 	cvt.u32.u16 	%r177, %rs65;
(EngineCore_DP0 pid=349798) 	.loc	1 226 45                        // quant_slide_tuned_Llama3.2-1B.py:226:45
(EngineCore_DP0 pid=349798) 	cvt.u32.u16 	%r178, %rs60;
(EngineCore_DP0 pid=349798) 	and.b32 	%r179, %r178, 255;
(EngineCore_DP0 pid=349798) 	cvt.u32.u16 	%r180, %rs68;
(EngineCore_DP0 pid=349798) 	cvt.u32.u16 	%r181, %rs61;
(EngineCore_DP0 pid=349798) 	and.b32 	%r182, %r181, 255;
(EngineCore_DP0 pid=349798) 	cvt.u32.u16 	%r183, %rs69;
(EngineCore_DP0 pid=349798) 	.loc	1 227 45                        // quant_slide_tuned_Llama3.2-1B.py:227:45
(EngineCore_DP0 pid=349798) 	cvt.u32.u16 	%r184, %rs62;
(EngineCore_DP0 pid=349798) 	cvt.u32.u16 	%r185, %rs70;
(EngineCore_DP0 pid=349798) 	cvt.u32.u16 	%r186, %rs63;
(EngineCore_DP0 pid=349798) 	cvt.u32.u16 	%r187, %rs71;
(EngineCore_DP0 pid=349798) 	.loc	1 229 30                        // quant_slide_tuned_Llama3.2-1B.py:229:30
(EngineCore_DP0 pid=349798) 	and.b16 	%rs72, %rs58, 255;
(EngineCore_DP0 pid=349798) 	mul.wide.u16 	%r188, %rs72, 256;
(EngineCore_DP0 pid=349798) 	mul.wide.u16 	%r189, %rs66, 256;
(EngineCore_DP0 pid=349798) 	and.b16 	%rs73, %rs59, 255;
(EngineCore_DP0 pid=349798) 	mul.wide.u16 	%r190, %rs73, 256;
(EngineCore_DP0 pid=349798) 	mul.wide.u16 	%r191, %rs67, 256;
(EngineCore_DP0 pid=349798) 	.loc	1 229 24                        // quant_slide_tuned_Llama3.2-1B.py:229:24
(EngineCore_DP0 pid=349798) 	or.b32 	%r192, %r188, %r173;
(EngineCore_DP0 pid=349798) 	or.b32 	%r193, %r189, %r174;
(EngineCore_DP0 pid=349798) 	or.b32 	%r194, %r190, %r176;
(EngineCore_DP0 pid=349798) 	or.b32 	%r195, %r191, %r177;
(EngineCore_DP0 pid=349798) 	.loc	1 229 42                        // quant_slide_tuned_Llama3.2-1B.py:229:42
(EngineCore_DP0 pid=349798) 	shl.b32 	%r196, %r179, 16;
(EngineCore_DP0 pid=349798) 	shl.b32 	%r197, %r180, 16;
(EngineCore_DP0 pid=349798) 	shl.b32 	%r198, %r182, 16;
(EngineCore_DP0 pid=349798) 	shl.b32 	%r199, %r183, 16;
(EngineCore_DP0 pid=349798) 	.loc	1 229 36                        // quant_slide_tuned_Llama3.2-1B.py:229:36
(EngineCore_DP0 pid=349798) 	or.b32 	%r200, %r196, %r192;
(EngineCore_DP0 pid=349798) 	or.b32 	%r201, %r197, %r193;
(EngineCore_DP0 pid=349798) 	or.b32 	%r202, %r198, %r194;
(EngineCore_DP0 pid=349798) 	or.b32 	%r203, %r199, %r195;
(EngineCore_DP0 pid=349798) 	.loc	1 229 55                        // quant_slide_tuned_Llama3.2-1B.py:229:55
(EngineCore_DP0 pid=349798) 	shl.b32 	%r204, %r184, 24;
(EngineCore_DP0 pid=349798) 	shl.b32 	%r205, %r185, 24;
(EngineCore_DP0 pid=349798) 	shl.b32 	%r206, %r186, 24;
(EngineCore_DP0 pid=349798) 	shl.b32 	%r207, %r187, 24;
(EngineCore_DP0 pid=349798) 	.loc	1 229 49                        // quant_slide_tuned_Llama3.2-1B.py:229:49
(EngineCore_DP0 pid=349798) 	or.b32 	%r98, %r204, %r200;
(EngineCore_DP0 pid=349798) 	or.b32 	%r99, %r205, %r201;
(EngineCore_DP0 pid=349798) 	or.b32 	%r100, %r206, %r202;
(EngineCore_DP0 pid=349798) 	or.b32 	%r101, %r207, %r203;
(EngineCore_DP0 pid=349798) 	.loc	1 230 29                        // quant_slide_tuned_Llama3.2-1B.py:230:29
(EngineCore_DP0 pid=349798) 	mad.wide.s32 	%rd24, %r102, 4, %rd2;
(EngineCore_DP0 pid=349798) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-1B.py:230:39
(EngineCore_DP0 pid=349798) 	// begin inline asm
(EngineCore_DP0 pid=349798) 	@%p25 st.global.v4.b32 [ %rd24 + 0 ], { %r98, %r99, %r100, %r101 };
(EngineCore_DP0 pid=349798) 	// end inline asm
(EngineCore_DP0 pid=349798) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=349798) 	add.s32 	%r211, %r211, 2048;
(EngineCore_DP0 pid=349798) 	setp.lt.s32 	%p42, %r211, %r15;
(EngineCore_DP0 pid=349798) 	@%p42 bra 	$L__BB0_6;
(EngineCore_DP0 pid=349798) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=349798) 	.loc	1 201 4                         // quant_slide_tuned_Llama3.2-1B.py:201:4
(EngineCore_DP0 pid=349798) 	ret;
(EngineCore_DP0 pid=349798) $L__tmp3:
(EngineCore_DP0 pid=349798) $L__func_end0:
(EngineCore_DP0 pid=349798)                                         // -- End function
(EngineCore_DP0 pid=349798) }
(EngineCore_DP0 pid=349798) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=349798) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=349798) 	.section	.debug_abbrev
(EngineCore_DP0 pid=349798) 	{
(EngineCore_DP0 pid=349798) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=349798) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=349798) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=349798) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=349798) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=349798) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=349798) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=349798) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=349798) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=349798) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=349798) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=349798) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=349798) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=349798) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=349798) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=349798) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=349798) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=349798) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=349798) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=349798) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=349798) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=349798) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=349798) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=349798) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=349798) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=349798) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=349798) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=349798) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=349798) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=349798) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=349798) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=349798) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=349798) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=349798) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=349798) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=349798) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=349798) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=349798) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=349798) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=349798) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=349798) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=349798) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=349798) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=349798) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=349798) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=349798) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=349798) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=349798) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=349798) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=349798) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=349798) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=349798) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=349798) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=349798) 	}
(EngineCore_DP0 pid=349798) 	.section	.debug_info
(EngineCore_DP0 pid=349798) 	{
(EngineCore_DP0 pid=349798) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=349798) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=349798) .b8 0
(EngineCore_DP0 pid=349798) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=349798) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=349798) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=349798) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=349798) .b8 114
(EngineCore_DP0 pid=349798) .b8 105
(EngineCore_DP0 pid=349798) .b8 116
(EngineCore_DP0 pid=349798) .b8 111
(EngineCore_DP0 pid=349798) .b8 110
(EngineCore_DP0 pid=349798) .b8 0
(EngineCore_DP0 pid=349798) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=349798) .b8 0
(EngineCore_DP0 pid=349798) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=349798) .b8 117
(EngineCore_DP0 pid=349798) .b8 97
(EngineCore_DP0 pid=349798) .b8 110
(EngineCore_DP0 pid=349798) .b8 116
(EngineCore_DP0 pid=349798) .b8 95
(EngineCore_DP0 pid=349798) .b8 115
(EngineCore_DP0 pid=349798) .b8 108
(EngineCore_DP0 pid=349798) .b8 105
(EngineCore_DP0 pid=349798) .b8 100
(EngineCore_DP0 pid=349798) .b8 101
(EngineCore_DP0 pid=349798) .b8 95
(EngineCore_DP0 pid=349798) .b8 116
(EngineCore_DP0 pid=349798) .b8 117
(EngineCore_DP0 pid=349798) .b8 110
(EngineCore_DP0 pid=349798) .b8 101
(EngineCore_DP0 pid=349798) .b8 100
(EngineCore_DP0 pid=349798) .b8 95
(EngineCore_DP0 pid=349798) .b8 76
(EngineCore_DP0 pid=349798) .b8 108
(EngineCore_DP0 pid=349798) .b8 97
(EngineCore_DP0 pid=349798) .b8 109
(EngineCore_DP0 pid=349798) .b8 97
(EngineCore_DP0 pid=349798) .b8 51
(EngineCore_DP0 pid=349798) .b8 46
(EngineCore_DP0 pid=349798) .b8 50
(EngineCore_DP0 pid=349798) .b8 45
(EngineCore_DP0 pid=349798) .b8 49
(EngineCore_DP0 pid=349798) .b8 66
(EngineCore_DP0 pid=349798) .b8 46
(EngineCore_DP0 pid=349798) .b8 112
(EngineCore_DP0 pid=349798) .b8 121
(EngineCore_DP0 pid=349798) .b8 0
(EngineCore_DP0 pid=349798) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=349798) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=349798) .b8 114
(EngineCore_DP0 pid=349798) .b8 111
(EngineCore_DP0 pid=349798) .b8 111
(EngineCore_DP0 pid=349798) .b8 116
(EngineCore_DP0 pid=349798) .b8 47
(EngineCore_DP0 pid=349798) .b8 118
(EngineCore_DP0 pid=349798) .b8 108
(EngineCore_DP0 pid=349798) .b8 108
(EngineCore_DP0 pid=349798) .b8 109
(EngineCore_DP0 pid=349798) .b8 98
(EngineCore_DP0 pid=349798) .b8 101
(EngineCore_DP0 pid=349798) .b8 110
(EngineCore_DP0 pid=349798) .b8 99
(EngineCore_DP0 pid=349798) .b8 104
(EngineCore_DP0 pid=349798) .b8 47
(EngineCore_DP0 pid=349798) .b8 115
(EngineCore_DP0 pid=349798) .b8 108
(EngineCore_DP0 pid=349798) .b8 105
(EngineCore_DP0 pid=349798) .b8 100
(EngineCore_DP0 pid=349798) .b8 101
(EngineCore_DP0 pid=349798) .b8 115
(EngineCore_DP0 pid=349798) .b8 112
(EngineCore_DP0 pid=349798) .b8 97
(EngineCore_DP0 pid=349798) .b8 114
(EngineCore_DP0 pid=349798) .b8 115
(EngineCore_DP0 pid=349798) .b8 101
(EngineCore_DP0 pid=349798) .b8 47
(EngineCore_DP0 pid=349798) .b8 99
(EngineCore_DP0 pid=349798) .b8 115
(EngineCore_DP0 pid=349798) .b8 114
(EngineCore_DP0 pid=349798) .b8 99
(EngineCore_DP0 pid=349798) .b8 47
(EngineCore_DP0 pid=349798) .b8 102
(EngineCore_DP0 pid=349798) .b8 117
(EngineCore_DP0 pid=349798) .b8 115
(EngineCore_DP0 pid=349798) .b8 101
(EngineCore_DP0 pid=349798) .b8 100
(EngineCore_DP0 pid=349798) .b8 95
(EngineCore_DP0 pid=349798) .b8 113
(EngineCore_DP0 pid=349798) .b8 117
(EngineCore_DP0 pid=349798) .b8 97
(EngineCore_DP0 pid=349798) .b8 110
(EngineCore_DP0 pid=349798) .b8 116
(EngineCore_DP0 pid=349798) .b8 95
(EngineCore_DP0 pid=349798) .b8 115
(EngineCore_DP0 pid=349798) .b8 108
(EngineCore_DP0 pid=349798) .b8 105
(EngineCore_DP0 pid=349798) .b8 100
(EngineCore_DP0 pid=349798) .b8 101
(EngineCore_DP0 pid=349798) .b8 95
(EngineCore_DP0 pid=349798) .b8 116
(EngineCore_DP0 pid=349798) .b8 114
(EngineCore_DP0 pid=349798) .b8 105
(EngineCore_DP0 pid=349798) .b8 116
(EngineCore_DP0 pid=349798) .b8 111
(EngineCore_DP0 pid=349798) .b8 110
(EngineCore_DP0 pid=349798) .b8 47
(EngineCore_DP0 pid=349798) .b8 98
(EngineCore_DP0 pid=349798) .b8 117
(EngineCore_DP0 pid=349798) .b8 105
(EngineCore_DP0 pid=349798) .b8 108
(EngineCore_DP0 pid=349798) .b8 100
(EngineCore_DP0 pid=349798) .b8 47
(EngineCore_DP0 pid=349798) .b8 71
(EngineCore_DP0 pid=349798) .b8 66
(EngineCore_DP0 pid=349798) .b8 49
(EngineCore_DP0 pid=349798) .b8 48
(EngineCore_DP0 pid=349798) .b8 95
(EngineCore_DP0 pid=349798) .b8 99
(EngineCore_DP0 pid=349798) .b8 99
(EngineCore_DP0 pid=349798) .b8 49
(EngineCore_DP0 pid=349798) .b8 50
(EngineCore_DP0 pid=349798) .b8 49
(EngineCore_DP0 pid=349798) .b8 95
(EngineCore_DP0 pid=349798) .b8 112
(EngineCore_DP0 pid=349798) .b8 121
(EngineCore_DP0 pid=349798) .b8 51
(EngineCore_DP0 pid=349798) .b8 49
(EngineCore_DP0 pid=349798) .b8 50
(EngineCore_DP0 pid=349798) .b8 95
(EngineCore_DP0 pid=349798) .b8 99
(EngineCore_DP0 pid=349798) .b8 117
(EngineCore_DP0 pid=349798) .b8 49
(EngineCore_DP0 pid=349798) .b8 50
(EngineCore_DP0 pid=349798) .b8 57
(EngineCore_DP0 pid=349798) .b8 95
(EngineCore_DP0 pid=349798) .b8 97
(EngineCore_DP0 pid=349798) .b8 97
(EngineCore_DP0 pid=349798) .b8 114
(EngineCore_DP0 pid=349798) .b8 99
(EngineCore_DP0 pid=349798) .b8 104
(EngineCore_DP0 pid=349798) .b8 54
(EngineCore_DP0 pid=349798) .b8 52
(EngineCore_DP0 pid=349798) .b8 0
(EngineCore_DP0 pid=349798) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=349798) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=349798) .b8 113
(EngineCore_DP0 pid=349798) .b8 117
(EngineCore_DP0 pid=349798) .b8 97
(EngineCore_DP0 pid=349798) .b8 110
(EngineCore_DP0 pid=349798) .b8 116
(EngineCore_DP0 pid=349798) .b8 95
(EngineCore_DP0 pid=349798) .b8 115
(EngineCore_DP0 pid=349798) .b8 108
(EngineCore_DP0 pid=349798) .b8 105
(EngineCore_DP0 pid=349798) .b8 100
(EngineCore_DP0 pid=349798) .b8 101
(EngineCore_DP0 pid=349798) .b8 95
(EngineCore_DP0 pid=349798) .b8 102
(EngineCore_DP0 pid=349798) .b8 112
(EngineCore_DP0 pid=349798) .b8 56
(EngineCore_DP0 pid=349798) .b8 95
(EngineCore_DP0 pid=349798) .b8 107
(EngineCore_DP0 pid=349798) .b8 101
(EngineCore_DP0 pid=349798) .b8 114
(EngineCore_DP0 pid=349798) .b8 110
(EngineCore_DP0 pid=349798) .b8 101
(EngineCore_DP0 pid=349798) .b8 108
(EngineCore_DP0 pid=349798) .b8 0
(EngineCore_DP0 pid=349798) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=349798) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=349798) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=349798) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=349798) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=349798) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=349798) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=349798) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=349798) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=349798) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=349798) .b8 191                                 // DW_AT_call_line
(EngineCore_DP0 pid=349798) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=349798) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=349798) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=349798) 	}
(EngineCore_DP0 pid=349798) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=349798) 
(EngineCore_DP0 pid=349798) ================================================================
(EngineCore_DP0 pid=349798) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=349798) 
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpgr3ateil.ptx', '-o', '/tmp/tmpgr3ateil.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866] 
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866] 
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866] 
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpgr3ateil.ptx -o /tmp/tmpgr3ateil.ptx.o
(EngineCore_DP0 pid=349798) ERROR 01-25 19:26:43 [core.py:866] 

STDERR:
[2026-01-25 19:26:26] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:26:26] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:26:26] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:26:26] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:26:26] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:26:26] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:26:26] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:26:26] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:26:26] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:26:26] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:26:26] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:26:26] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:26:26] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:26:26] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:26:29] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:26:29] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:26:29] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:26:29] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:26:29] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:26:29] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:26:29] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:26:29] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:26:29] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:26:29] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:26:29] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:26:29] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:26:29] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:26:29] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=349798) [2026-01-25 19:26:30] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=349798) [2026-01-25 19:26:30] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=349798) [2026-01-25 19:26:30] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=349798) [2026-01-25 19:26:30] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=349798) [2026-01-25 19:26:30] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=349798) [2026-01-25 19:26:30] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=349798) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=349798) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:11<00:00, 11.06s/it]
(EngineCore_DP0 pid=349798) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:11<00:00, 11.06s/it]
(EngineCore_DP0 pid=349798) 
(EngineCore_DP0 pid=349798) [2026-01-25 19:26:42] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=349798) [2026-01-25 19:26:42] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6340608 bytes
(EngineCore_DP0 pid=349798) [2026-01-25 19:26:42] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=349798) [2026-01-25 19:26:42] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 4227072 bytes
(EngineCore_DP0 pid=349798) [2026-01-25 19:26:42] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=349798) [2026-01-25 19:26:42] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 33816576 bytes
(EngineCore_DP0 pid=349798) [2026-01-25 19:26:42] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=349798) [2026-01-25 19:26:42] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16809984 bytes
(EngineCore_DP0 pid=349798) Process EngineCore_DP0:
(EngineCore_DP0 pid=349798) Traceback (most recent call last):
(EngineCore_DP0 pid=349798)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=349798)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=349798)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=349798)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=349798) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpgr3ateil.ptx', '-o', '/tmp/tmpgr3ateil.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=349798) 
(EngineCore_DP0 pid=349798) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=349798) 
(EngineCore_DP0 pid=349798) Traceback (most recent call last):
(EngineCore_DP0 pid=349798)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=349798)     self.run()
(EngineCore_DP0 pid=349798)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=349798)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=349798)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=349798)     raise e
(EngineCore_DP0 pid=349798)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=349798)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=349798)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=349798)     super().__init__(
(EngineCore_DP0 pid=349798)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=349798)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=349798)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=349798)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=349798)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=349798)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=349798)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=349798)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=349798)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=349798)     return func(*args, **kwargs)
(EngineCore_DP0 pid=349798)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=349798)     return func(*args, **kwargs)
(EngineCore_DP0 pid=349798)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=349798)     self.model_runner.profile_run()
(EngineCore_DP0 pid=349798)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=349798)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=349798)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=349798)     return func(*args, **kwargs)
(EngineCore_DP0 pid=349798)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=349798)     outputs = self.model(
(EngineCore_DP0 pid=349798)               ^^^^^^^^^^^
(EngineCore_DP0 pid=349798)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=349798)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=349798)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=349798)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=349798)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=349798)     model_output = self.model(
(EngineCore_DP0 pid=349798)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=349798)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=349798)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=349798)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=349798)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=349798)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=349798)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=349798)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=349798)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=349798)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=349798)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=349798)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=349798)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=349798)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=349798)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=349798)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=349798)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=349798)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=349798)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=349798)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=349798)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=349798)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=349798)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=349798)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=349798)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=349798)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=349798)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=349798)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=349798)     return self._linear_fn(
(EngineCore_DP0 pid=349798)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=349798)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=349798)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=349798)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=349798)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=349798)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=349798)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=349798)     return fn(input, L)
(EngineCore_DP0 pid=349798)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=349798)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=349798)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=349798)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=349798)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=349798)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=349798)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=349798)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=349798)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=349798)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=349798)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=349798)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=349798)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=349798)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=349798)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=349798)     raise PTXASError(error)
(EngineCore_DP0 pid=349798) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=349798) `ptxas` stderr:
(EngineCore_DP0 pid=349798) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=349798) 
(EngineCore_DP0 pid=349798) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpgr3ateil.ptx -o /tmp/tmpgr3ateil.ptx.o
(EngineCore_DP0 pid=349798) 
[rank0]:[W125 19:26:43.782159316 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=32768

========== M=65536 ==========
Time: 2026-01-25 19:26:45
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-1B-FP8_M65536.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:27:11 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:27:11 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=350615) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=350615) 
(EngineCore_DP0 pid=350615) 
(EngineCore_DP0 pid=350615) ================================================================
(EngineCore_DP0 pid=350615) Internal Triton PTX codegen error
(EngineCore_DP0 pid=350615) `ptxas` stderr:
(EngineCore_DP0 pid=350615) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=350615) 
(EngineCore_DP0 pid=350615) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp4xtyoaop.ptx -o /tmp/tmp4xtyoaop.ptx.o
(EngineCore_DP0 pid=350615) 
(EngineCore_DP0 pid=350615) 
(EngineCore_DP0 pid=350615) //
(EngineCore_DP0 pid=350615) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=350615) //
(EngineCore_DP0 pid=350615) 
(EngineCore_DP0 pid=350615) .version 8.7
(EngineCore_DP0 pid=350615) .target sm_121a
(EngineCore_DP0 pid=350615) .address_size 64
(EngineCore_DP0 pid=350615) 
(EngineCore_DP0 pid=350615) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=350615) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=350615)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=350615) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=350615) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=350615) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=350615) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=350615) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=350615) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=350615) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=350615) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=350615) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=350615) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=350615) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=350615) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=350615) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=350615) )
(EngineCore_DP0 pid=350615) .reqntid 512
(EngineCore_DP0 pid=350615) {
(EngineCore_DP0 pid=350615) 	.reg .pred 	%p<44>;
(EngineCore_DP0 pid=350615) 	.reg .b16 	%rs<74>;
(EngineCore_DP0 pid=350615) 	.reg .b32 	%r<212>;
(EngineCore_DP0 pid=350615) 	.reg .b64 	%rd<25>;
(EngineCore_DP0 pid=350615) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=350615) $L__func_begin0:
(EngineCore_DP0 pid=350615) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=350615) 
(EngineCore_DP0 pid=350615) // %bb.0:
(EngineCore_DP0 pid=350615) 	ld.param.b32 	%r29, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=350615) 	ld.param.b32 	%r28, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=350615) 	ld.param.b32 	%r27, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=350615) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=350615) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=350615) $L__tmp0:
(EngineCore_DP0 pid=350615) 	.loc	1 177 24                        // quant_slide_tuned_Llama3.2-1B.py:177:24
(EngineCore_DP0 pid=350615) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=350615) 	ld.param.b32 	%r31, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=350615) 	.loc	1 182 26                        // quant_slide_tuned_Llama3.2-1B.py:182:26
(EngineCore_DP0 pid=350615) 	mul.lo.s32 	%r32, %r31, %r1;
(EngineCore_DP0 pid=350615) 	.loc	1 182 20                        // quant_slide_tuned_Llama3.2-1B.py:182:20
(EngineCore_DP0 pid=350615) 	mad.wide.s32 	%rd1, %r32, 2, %rd4;
(EngineCore_DP0 pid=350615) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=350615) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=350615) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=350615) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=350615) 	setp.lt.s32 	%p1, %r28, 1;
(EngineCore_DP0 pid=350615) 	mov.b32 	%r210, 0f2B8CBCCC;
(EngineCore_DP0 pid=350615) 	setp.eq.b32 	%p43, %r2, 0;
(EngineCore_DP0 pid=350615) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=350615) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=350615) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=350615) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=350615) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=350615) 	shr.u32 	%r41, %r2, 3;
(EngineCore_DP0 pid=350615) 	and.b32 	%r42, %r41, 60;
(EngineCore_DP0 pid=350615) 	mov.b32 	%r43, global_smem;
(EngineCore_DP0 pid=350615) 	add.s32 	%r53, %r43, %r42;
(EngineCore_DP0 pid=350615) 	shl.b32 	%r44, %r2, 2;
(EngineCore_DP0 pid=350615) 	add.s32 	%r56, %r43, %r44;
(EngineCore_DP0 pid=350615) 	mov.b32 	%r49, 0;
(EngineCore_DP0 pid=350615) 	mov.b32 	%r208, 0f00000000;
(EngineCore_DP0 pid=350615) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=350615) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=350615) 	mov.b32 	%r209, %r49;
(EngineCore_DP0 pid=350615) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=350615) 	.loc	1 189 22                        // quant_slide_tuned_Llama3.2-1B.py:189:22
(EngineCore_DP0 pid=350615) 	add.s32 	%r59, %r4, %r209;
(EngineCore_DP0 pid=350615) 	setp.lt.s32 	%p2, %r59, %r27;
(EngineCore_DP0 pid=350615) 	.loc	1 190 29                        // quant_slide_tuned_Llama3.2-1B.py:190:29
(EngineCore_DP0 pid=350615) 	mad.wide.s32 	%rd6, %r59, 2, %rd1;
(EngineCore_DP0 pid=350615) 	.loc	1 190 21                        // quant_slide_tuned_Llama3.2-1B.py:190:21
(EngineCore_DP0 pid=350615) 	// begin inline asm
(EngineCore_DP0 pid=350615) 	mov.u32 %r45, %r49;
(EngineCore_DP0 pid=350615) 	mov.u32 %r46, %r49;
(EngineCore_DP0 pid=350615) 	mov.u32 %r47, %r49;
(EngineCore_DP0 pid=350615) 	mov.u32 %r48, %r49;
(EngineCore_DP0 pid=350615) 	@%p2 ld.global.v4.b32 { %r45, %r46, %r47, %r48 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=350615) 	// end inline asm
(EngineCore_DP0 pid=350615) 	mov.b32 	{%rs1, %rs2}, %r45;
(EngineCore_DP0 pid=350615) 	mov.b32 	{%rs3, %rs4}, %r46;
(EngineCore_DP0 pid=350615) 	mov.b32 	{%rs5, %rs6}, %r47;
(EngineCore_DP0 pid=350615) 	mov.b32 	{%rs7, %rs8}, %r48;
(EngineCore_DP0 pid=350615) 	.loc	1 191 50                        // quant_slide_tuned_Llama3.2-1B.py:191:50
(EngineCore_DP0 pid=350615) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=350615) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=350615) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=350615) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=350615) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=350615) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=350615) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=350615) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=350615) $L__tmp1:
(EngineCore_DP0 pid=350615) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=350615) 	bar.sync 	0;
(EngineCore_DP0 pid=350615) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=350615) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=350615) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=350615) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=350615) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=350615) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=350615) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=350615) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=350615) 	cvt.f32.bf16 	%r60, %rs23;
(EngineCore_DP0 pid=350615) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=350615) 	shfl.sync.bfly.b32 	%r61, %r60, 16, 31, -1;
(EngineCore_DP0 pid=350615) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=350615) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=350615) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=350615) 	shfl.sync.bfly.b32 	%r63, %r62, 8, 31, -1;
(EngineCore_DP0 pid=350615) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=350615) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=350615) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=350615) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=350615) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=350615) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=350615) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=350615) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=350615) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=350615) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=350615) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=350615) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=350615) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=350615) 	max.f32 	%r54, %r68, %r69;
(EngineCore_DP0 pid=350615) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=350615) 	// begin inline asm
(EngineCore_DP0 pid=350615) 	@%p3 st.shared.b32 [ %r53 + 0 ], %r54;
(EngineCore_DP0 pid=350615) 	// end inline asm
(EngineCore_DP0 pid=350615) 	bar.sync 	0;
(EngineCore_DP0 pid=350615) 	// begin inline asm
(EngineCore_DP0 pid=350615) 	@%p4 ld.shared.b32 %r55, [ %r56 + 0 ];
(EngineCore_DP0 pid=350615) 	// end inline asm
(EngineCore_DP0 pid=350615) 	shfl.sync.bfly.b32 	%r70, %r55, 8, 31, -1;
(EngineCore_DP0 pid=350615) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=350615) 	max.f32 	%r71, %r55, %r70;
(EngineCore_DP0 pid=350615) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=350615) 	shfl.sync.bfly.b32 	%r72, %r71, 4, 31, -1;
(EngineCore_DP0 pid=350615) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=350615) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=350615) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=350615) 	shfl.sync.bfly.b32 	%r74, %r73, 2, 31, -1;
(EngineCore_DP0 pid=350615) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=350615) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=350615) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=350615) 	shfl.sync.bfly.b32 	%r76, %r75, 1, 31, -1;
(EngineCore_DP0 pid=350615) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=350615) 	max.f32 	%r58, %r75, %r76;
(EngineCore_DP0 pid=350615) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=350615) 	// begin inline asm
(EngineCore_DP0 pid=350615) 	@%p43 st.shared.b32 [ %r56 + 0 ], %r58;
(EngineCore_DP0 pid=350615) 	// end inline asm
(EngineCore_DP0 pid=350615) 	bar.sync 	0;
(EngineCore_DP0 pid=350615) 	ld.shared.b32 	%r77, [global_smem];
(EngineCore_DP0 pid=350615) $L__tmp2:
(EngineCore_DP0 pid=350615) 	.loc	1 191 36                        // quant_slide_tuned_Llama3.2-1B.py:191:36
(EngineCore_DP0 pid=350615) 	max.f32 	%r208, %r208, %r77;
(EngineCore_DP0 pid=350615) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=350615) 	add.s32 	%r209, %r209, 4096;
(EngineCore_DP0 pid=350615) 	setp.lt.s32 	%p6, %r209, %r28;
(EngineCore_DP0 pid=350615) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=350615) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=350615) 	.loc	1 193 32                        // quant_slide_tuned_Llama3.2-1B.py:193:32
(EngineCore_DP0 pid=350615) 	max.f32 	%r210, %r208, 0f2B8CBCCC;
(EngineCore_DP0 pid=350615) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=350615) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=350615) 	mov.b32 	%r79, 0f43E00000;
(EngineCore_DP0 pid=350615) 	.loc	1 194 32                        // quant_slide_tuned_Llama3.2-1B.py:194:32
(EngineCore_DP0 pid=350615) 	div.full.f32 	%r80, %r210, %r79;
(EngineCore_DP0 pid=350615) 	.loc	1 194 41                        // quant_slide_tuned_Llama3.2-1B.py:194:41
(EngineCore_DP0 pid=350615) 	max.f32 	%r78, %r80, 0f36924925;
(EngineCore_DP0 pid=350615) 	.loc	1 196 25                        // quant_slide_tuned_Llama3.2-1B.py:196:25
(EngineCore_DP0 pid=350615) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=350615) 	.loc	1 196 30                        // quant_slide_tuned_Llama3.2-1B.py:196:30
(EngineCore_DP0 pid=350615) 	// begin inline asm
(EngineCore_DP0 pid=350615) 	@%p43 st.global.b32 [ %rd7 + 0 ], { %r78 };
(EngineCore_DP0 pid=350615) 	// end inline asm
(EngineCore_DP0 pid=350615) 	.loc	1 199 29                        // quant_slide_tuned_Llama3.2-1B.py:199:29
(EngineCore_DP0 pid=350615) 	shl.b32 	%r15, %r29, 2;
(EngineCore_DP0 pid=350615) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=350615) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=350615) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=350615) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=350615) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=350615) 	ld.param.b32 	%r33, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=350615) 	shr.s32 	%r34, %r33, 31;
(EngineCore_DP0 pid=350615) 	shr.u32 	%r35, %r34, 30;
(EngineCore_DP0 pid=350615) 	add.s32 	%r36, %r33, %r35;
(EngineCore_DP0 pid=350615) 	shr.s32 	%r37, %r36, 2;
(EngineCore_DP0 pid=350615) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=350615) 	mul.lo.s32 	%r38, %r37, %r1;
(EngineCore_DP0 pid=350615) 	mad.wide.s32 	%rd2, %r38, 4, %rd5;
(EngineCore_DP0 pid=350615) 	div.full.f32 	%r14, %r79, %r210;
(EngineCore_DP0 pid=350615) 	shl.b32 	%r16, %r3, 2;
(EngineCore_DP0 pid=350615) 	mov.b32 	%r211, 0;
(EngineCore_DP0 pid=350615) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=350615)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=350615) 	.loc	1 202 31                        // quant_slide_tuned_Llama3.2-1B.py:202:31
(EngineCore_DP0 pid=350615) 	add.s32 	%r102, %r16, %r211;
(EngineCore_DP0 pid=350615) 	or.b32 	%r103, %r211, 2;
(EngineCore_DP0 pid=350615) 	or.b32 	%r104, %r211, 3;
(EngineCore_DP0 pid=350615) 	.loc	1 203 30                        // quant_slide_tuned_Llama3.2-1B.py:203:30
(EngineCore_DP0 pid=350615) 	setp.lt.s32 	%p25, %r102, %r15;
(EngineCore_DP0 pid=350615) 	.loc	1 206 24                        // quant_slide_tuned_Llama3.2-1B.py:206:24
(EngineCore_DP0 pid=350615) 	shr.s32 	%r105, %r102, 2;
(EngineCore_DP0 pid=350615) 	.loc	1 207 23                        // quant_slide_tuned_Llama3.2-1B.py:207:23
(EngineCore_DP0 pid=350615) 	add.s32 	%r106, %r211, 1;
(EngineCore_DP0 pid=350615) 	shr.s32 	%r107, %r106, 31;
(EngineCore_DP0 pid=350615) 	shr.u32 	%r108, %r107, 30;
(EngineCore_DP0 pid=350615) 	add.s32 	%r109, %r106, %r108;
(EngineCore_DP0 pid=350615) 	and.b32 	%r110, %r109, 2147483644;
(EngineCore_DP0 pid=350615) 	sub.s32 	%r111, %r106, %r110;
(EngineCore_DP0 pid=350615) 	.loc	1 208 30                        // quant_slide_tuned_Llama3.2-1B.py:208:30
(EngineCore_DP0 pid=350615) 	shl.b32 	%r112, %r111, 1;
(EngineCore_DP0 pid=350615) 	.loc	1 208 22                        // quant_slide_tuned_Llama3.2-1B.py:208:22
(EngineCore_DP0 pid=350615) 	mul.lo.s32 	%r113, %r105, 10;
(EngineCore_DP0 pid=350615) 	.loc	1 208 26                        // quant_slide_tuned_Llama3.2-1B.py:208:26
(EngineCore_DP0 pid=350615) 	add.s32 	%r114, %r113, %r112;
(EngineCore_DP0 pid=350615) 	.loc	1 207 23                        // quant_slide_tuned_Llama3.2-1B.py:207:23
(EngineCore_DP0 pid=350615) 	shr.s32 	%r115, %r211, 31;
(EngineCore_DP0 pid=350615) 	shr.u32 	%r116, %r115, 30;
(EngineCore_DP0 pid=350615) 	add.s32 	%r117, %r104, %r116;
(EngineCore_DP0 pid=350615) 	and.b32 	%r118, %r117, 2147483644;
(EngineCore_DP0 pid=350615) 	sub.s32 	%r119, %r104, %r118;
(EngineCore_DP0 pid=350615) 	add.s32 	%r120, %r103, %r116;
(EngineCore_DP0 pid=350615) 	and.b32 	%r121, %r120, 2147483644;
(EngineCore_DP0 pid=350615) 	sub.s32 	%r122, %r103, %r121;
(EngineCore_DP0 pid=350615) 	.loc	1 208 30                        // quant_slide_tuned_Llama3.2-1B.py:208:30
(EngineCore_DP0 pid=350615) 	shl.b32 	%r123, %r122, 1;
(EngineCore_DP0 pid=350615) 	shl.b32 	%r124, %r119, 1;
(EngineCore_DP0 pid=350615) 	.loc	1 208 26                        // quant_slide_tuned_Llama3.2-1B.py:208:26
(EngineCore_DP0 pid=350615) 	add.s32 	%r125, %r113, %r124;
(EngineCore_DP0 pid=350615) 	add.s32 	%r126, %r113, %r123;
(EngineCore_DP0 pid=350615) 	.loc	1 211 53                        // quant_slide_tuned_Llama3.2-1B.py:211:53
(EngineCore_DP0 pid=350615) 	setp.lt.s32 	%p26, %r113, %r27;
(EngineCore_DP0 pid=350615) 	setp.lt.s32 	%p27, %r114, %r27;
(EngineCore_DP0 pid=350615) 	setp.lt.s32 	%p28, %r126, %r27;
(EngineCore_DP0 pid=350615) 	setp.lt.s32 	%p29, %r125, %r27;
(EngineCore_DP0 pid=350615) 	.loc	1 211 37                        // quant_slide_tuned_Llama3.2-1B.py:211:37
(EngineCore_DP0 pid=350615) 	and.pred 	%p9, %p25, %p26;
(EngineCore_DP0 pid=350615) 	and.pred 	%p10, %p25, %p27;
(EngineCore_DP0 pid=350615) 	and.pred 	%p11, %p25, %p28;
(EngineCore_DP0 pid=350615) 	and.pred 	%p12, %p25, %p29;
(EngineCore_DP0 pid=350615) 	.loc	1 210 29                        // quant_slide_tuned_Llama3.2-1B.py:210:29
(EngineCore_DP0 pid=350615) 	mad.wide.s32 	%rd8, %r113, 2, %rd1;
(EngineCore_DP0 pid=350615) 	mad.wide.s32 	%rd9, %r114, 2, %rd1;
(EngineCore_DP0 pid=350615) 	mad.wide.s32 	%rd10, %r126, 2, %rd1;
(EngineCore_DP0 pid=350615) 	mad.wide.s32 	%rd11, %r125, 2, %rd1;
(EngineCore_DP0 pid=350615) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=350615) 	.loc	1 210 21                        // quant_slide_tuned_Llama3.2-1B.py:210:21
(EngineCore_DP0 pid=350615) 	// begin inline asm
(EngineCore_DP0 pid=350615) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=350615) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=350615) 	// end inline asm
(EngineCore_DP0 pid=350615) 	// begin inline asm
(EngineCore_DP0 pid=350615) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=350615) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=350615) 	// end inline asm
(EngineCore_DP0 pid=350615) 	// begin inline asm
(EngineCore_DP0 pid=350615) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=350615) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=350615) 	// end inline asm
(EngineCore_DP0 pid=350615) 	// begin inline asm
(EngineCore_DP0 pid=350615) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=350615) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=350615) 	// end inline asm
(EngineCore_DP0 pid=350615) 	.loc	1 211 79                        // quant_slide_tuned_Llama3.2-1B.py:211:79
(EngineCore_DP0 pid=350615) 	cvt.f32.bf16 	%r127, %rs24;
(EngineCore_DP0 pid=350615) 	cvt.f32.bf16 	%r128, %rs26;
(EngineCore_DP0 pid=350615) 	cvt.f32.bf16 	%r129, %rs28;
(EngineCore_DP0 pid=350615) 	cvt.f32.bf16 	%r130, %rs30;
(EngineCore_DP0 pid=350615) 	.loc	1 213 48                        // quant_slide_tuned_Llama3.2-1B.py:213:48
(EngineCore_DP0 pid=350615) 	or.b32 	%r131, %r113, 1;
(EngineCore_DP0 pid=350615) 	or.b32 	%r132, %r114, 1;
(EngineCore_DP0 pid=350615) 	or.b32 	%r133, %r126, 1;
(EngineCore_DP0 pid=350615) 	or.b32 	%r134, %r125, 1;
(EngineCore_DP0 pid=350615) 	.loc	1 213 53                        // quant_slide_tuned_Llama3.2-1B.py:213:53
(EngineCore_DP0 pid=350615) 	setp.lt.s32 	%p30, %r131, %r27;
(EngineCore_DP0 pid=350615) 	setp.lt.s32 	%p31, %r132, %r27;
(EngineCore_DP0 pid=350615) 	setp.lt.s32 	%p32, %r133, %r27;
(EngineCore_DP0 pid=350615) 	setp.lt.s32 	%p33, %r134, %r27;
(EngineCore_DP0 pid=350615) 	.loc	1 213 37                        // quant_slide_tuned_Llama3.2-1B.py:213:37
(EngineCore_DP0 pid=350615) 	and.pred 	%p13, %p25, %p30;
(EngineCore_DP0 pid=350615) 	and.pred 	%p14, %p25, %p31;
(EngineCore_DP0 pid=350615) 	and.pred 	%p15, %p25, %p32;
(EngineCore_DP0 pid=350615) 	and.pred 	%p16, %p25, %p33;
(EngineCore_DP0 pid=350615) 	.loc	1 212 39                        // quant_slide_tuned_Llama3.2-1B.py:212:39
(EngineCore_DP0 pid=350615) 	add.s64 	%rd12, %rd8, 2;
(EngineCore_DP0 pid=350615) 	add.s64 	%rd13, %rd9, 2;
(EngineCore_DP0 pid=350615) 	add.s64 	%rd14, %rd10, 2;
(EngineCore_DP0 pid=350615) 	add.s64 	%rd15, %rd11, 2;
(EngineCore_DP0 pid=350615) 	.loc	1 212 21                        // quant_slide_tuned_Llama3.2-1B.py:212:21
(EngineCore_DP0 pid=350615) 	// begin inline asm
(EngineCore_DP0 pid=350615) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=350615) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=350615) 	// end inline asm
(EngineCore_DP0 pid=350615) 	// begin inline asm
(EngineCore_DP0 pid=350615) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=350615) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=350615) 	// end inline asm
(EngineCore_DP0 pid=350615) 	// begin inline asm
(EngineCore_DP0 pid=350615) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=350615) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=350615) 	// end inline asm
(EngineCore_DP0 pid=350615) 	// begin inline asm
(EngineCore_DP0 pid=350615) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=350615) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=350615) 	// end inline asm
(EngineCore_DP0 pid=350615) 	.loc	1 213 79                        // quant_slide_tuned_Llama3.2-1B.py:213:79
(EngineCore_DP0 pid=350615) 	cvt.f32.bf16 	%r135, %rs32;
(EngineCore_DP0 pid=350615) 	cvt.f32.bf16 	%r136, %rs34;
(EngineCore_DP0 pid=350615) 	cvt.f32.bf16 	%r137, %rs36;
(EngineCore_DP0 pid=350615) 	cvt.f32.bf16 	%r138, %rs38;
(EngineCore_DP0 pid=350615) 	.loc	1 217 48                        // quant_slide_tuned_Llama3.2-1B.py:217:48
(EngineCore_DP0 pid=350615) 	add.s32 	%r139, %r114, 2;
(EngineCore_DP0 pid=350615) 	add.s32 	%r140, %r126, 2;
(EngineCore_DP0 pid=350615) 	add.s32 	%r141, %r125, 2;
(EngineCore_DP0 pid=350615) 	add.s32 	%r142, %r114, 3;
(EngineCore_DP0 pid=350615) 	add.s32 	%r143, %r126, 3;
(EngineCore_DP0 pid=350615) 	add.s32 	%r144, %r125, 3;
(EngineCore_DP0 pid=350615) 	add.s32 	%r145, %r113, 2;
(EngineCore_DP0 pid=350615) 	add.s32 	%r146, %r113, 3;
(EngineCore_DP0 pid=350615) 	.loc	1 217 53                        // quant_slide_tuned_Llama3.2-1B.py:217:53
(EngineCore_DP0 pid=350615) 	setp.lt.s32 	%p34, %r144, %r27;
(EngineCore_DP0 pid=350615) 	setp.lt.s32 	%p35, %r143, %r27;
(EngineCore_DP0 pid=350615) 	setp.lt.s32 	%p36, %r142, %r27;
(EngineCore_DP0 pid=350615) 	setp.lt.s32 	%p37, %r141, %r27;
(EngineCore_DP0 pid=350615) 	setp.lt.s32 	%p38, %r140, %r27;
(EngineCore_DP0 pid=350615) 	setp.lt.s32 	%p39, %r139, %r27;
(EngineCore_DP0 pid=350615) 	setp.lt.s32 	%p40, %r146, %r27;
(EngineCore_DP0 pid=350615) 	setp.lt.s32 	%p41, %r145, %r27;
(EngineCore_DP0 pid=350615) 	.loc	1 215 37                        // quant_slide_tuned_Llama3.2-1B.py:215:37
(EngineCore_DP0 pid=350615) 	and.pred 	%p17, %p25, %p41;
(EngineCore_DP0 pid=350615) 	and.pred 	%p18, %p25, %p39;
(EngineCore_DP0 pid=350615) 	and.pred 	%p19, %p25, %p38;
(EngineCore_DP0 pid=350615) 	and.pred 	%p20, %p25, %p37;
(EngineCore_DP0 pid=350615) 	.loc	1 214 39                        // quant_slide_tuned_Llama3.2-1B.py:214:39
(EngineCore_DP0 pid=350615) 	add.s64 	%rd16, %rd8, 4;
(EngineCore_DP0 pid=350615) 	add.s64 	%rd17, %rd9, 4;
(EngineCore_DP0 pid=350615) 	add.s64 	%rd18, %rd10, 4;
(EngineCore_DP0 pid=350615) 	add.s64 	%rd19, %rd11, 4;
(EngineCore_DP0 pid=350615) 	.loc	1 214 21                        // quant_slide_tuned_Llama3.2-1B.py:214:21
(EngineCore_DP0 pid=350615) 	// begin inline asm
(EngineCore_DP0 pid=350615) 	mov.u16 %rs40, %rs25;
(EngineCore_DP0 pid=350615) 	@%p17 ld.global.b16 { %rs40 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=350615) 	// end inline asm
(EngineCore_DP0 pid=350615) 	// begin inline asm
(EngineCore_DP0 pid=350615) 	mov.u16 %rs42, %rs25;
(EngineCore_DP0 pid=350615) 	@%p18 ld.global.b16 { %rs42 }, [ %rd17 + 0 ];
(EngineCore_DP0 pid=350615) 	// end inline asm
(EngineCore_DP0 pid=350615) 	// begin inline asm
(EngineCore_DP0 pid=350615) 	mov.u16 %rs44, %rs25;
(EngineCore_DP0 pid=350615) 	@%p19 ld.global.b16 { %rs44 }, [ %rd18 + 0 ];
(EngineCore_DP0 pid=350615) 	// end inline asm
(EngineCore_DP0 pid=350615) 	// begin inline asm
(EngineCore_DP0 pid=350615) 	mov.u16 %rs46, %rs25;
(EngineCore_DP0 pid=350615) 	@%p20 ld.global.b16 { %rs46 }, [ %rd19 + 0 ];
(EngineCore_DP0 pid=350615) 	// end inline asm
(EngineCore_DP0 pid=350615) 	.loc	1 215 79                        // quant_slide_tuned_Llama3.2-1B.py:215:79
(EngineCore_DP0 pid=350615) 	cvt.f32.bf16 	%r147, %rs40;
(EngineCore_DP0 pid=350615) 	cvt.f32.bf16 	%r148, %rs42;
(EngineCore_DP0 pid=350615) 	cvt.f32.bf16 	%r149, %rs44;
(EngineCore_DP0 pid=350615) 	cvt.f32.bf16 	%r150, %rs46;
(EngineCore_DP0 pid=350615) 	.loc	1 217 37                        // quant_slide_tuned_Llama3.2-1B.py:217:37
(EngineCore_DP0 pid=350615) 	and.pred 	%p21, %p25, %p40;
(EngineCore_DP0 pid=350615) 	and.pred 	%p22, %p25, %p36;
(EngineCore_DP0 pid=350615) 	and.pred 	%p23, %p25, %p35;
(EngineCore_DP0 pid=350615) 	and.pred 	%p24, %p25, %p34;
(EngineCore_DP0 pid=350615) 	.loc	1 216 39                        // quant_slide_tuned_Llama3.2-1B.py:216:39
(EngineCore_DP0 pid=350615) 	add.s64 	%rd20, %rd8, 6;
(EngineCore_DP0 pid=350615) 	add.s64 	%rd21, %rd9, 6;
(EngineCore_DP0 pid=350615) 	add.s64 	%rd22, %rd10, 6;
(EngineCore_DP0 pid=350615) 	add.s64 	%rd23, %rd11, 6;
(EngineCore_DP0 pid=350615) 	.loc	1 216 21                        // quant_slide_tuned_Llama3.2-1B.py:216:21
(EngineCore_DP0 pid=350615) 	// begin inline asm
(EngineCore_DP0 pid=350615) 	mov.u16 %rs48, %rs25;
(EngineCore_DP0 pid=350615) 	@%p21 ld.global.b16 { %rs48 }, [ %rd20 + 0 ];
(EngineCore_DP0 pid=350615) 	// end inline asm
(EngineCore_DP0 pid=350615) 	// begin inline asm
(EngineCore_DP0 pid=350615) 	mov.u16 %rs50, %rs25;
(EngineCore_DP0 pid=350615) 	@%p22 ld.global.b16 { %rs50 }, [ %rd21 + 0 ];
(EngineCore_DP0 pid=350615) 	// end inline asm
(EngineCore_DP0 pid=350615) 	// begin inline asm
(EngineCore_DP0 pid=350615) 	mov.u16 %rs52, %rs25;
(EngineCore_DP0 pid=350615) 	@%p23 ld.global.b16 { %rs52 }, [ %rd22 + 0 ];
(EngineCore_DP0 pid=350615) 	// end inline asm
(EngineCore_DP0 pid=350615) 	// begin inline asm
(EngineCore_DP0 pid=350615) 	mov.u16 %rs54, %rs25;
(EngineCore_DP0 pid=350615) 	@%p24 ld.global.b16 { %rs54 }, [ %rd23 + 0 ];
(EngineCore_DP0 pid=350615) 	// end inline asm
(EngineCore_DP0 pid=350615) 	.loc	1 217 79                        // quant_slide_tuned_Llama3.2-1B.py:217:79
(EngineCore_DP0 pid=350615) 	cvt.f32.bf16 	%r151, %rs48;
(EngineCore_DP0 pid=350615) 	cvt.f32.bf16 	%r152, %rs50;
(EngineCore_DP0 pid=350615) 	cvt.f32.bf16 	%r153, %rs52;
(EngineCore_DP0 pid=350615) 	cvt.f32.bf16 	%r154, %rs54;
(EngineCore_DP0 pid=350615) 	.loc	1 219 27                        // quant_slide_tuned_Llama3.2-1B.py:219:27
(EngineCore_DP0 pid=350615) 	mul.f32 	%r155, %r14, %r127;
(EngineCore_DP0 pid=350615) 	mul.f32 	%r156, %r14, %r128;
(EngineCore_DP0 pid=350615) 	mul.f32 	%r157, %r14, %r129;
(EngineCore_DP0 pid=350615) 	mul.f32 	%r158, %r14, %r130;
(EngineCore_DP0 pid=350615) 	mov.b32 	%r159, 0f43E00000;
(EngineCore_DP0 pid=350615) 	.loc	1 219 48                        // quant_slide_tuned_Llama3.2-1B.py:219:48
(EngineCore_DP0 pid=350615) 	min.xorsign.abs.f32 	%r82, %r155, %r159;
(EngineCore_DP0 pid=350615) 	min.xorsign.abs.f32 	%r83, %r156, %r159;
(EngineCore_DP0 pid=350615) 	min.xorsign.abs.f32 	%r84, %r157, %r159;
(EngineCore_DP0 pid=350615) 	min.xorsign.abs.f32 	%r85, %r158, %r159;
(EngineCore_DP0 pid=350615) 	.loc	1 219 60                        // quant_slide_tuned_Llama3.2-1B.py:219:60
(EngineCore_DP0 pid=350615) 	// begin inline asm
(EngineCore_DP0 pid=350615) 	cvt.rn.satfinite.e4m3x2.f32  %rs56, %r83, %r82; 
(EngineCore_DP0 pid=350615) 
(EngineCore_DP0 pid=350615) 	// end inline asm
(EngineCore_DP0 pid=350615) 	shr.u16 	%rs64, %rs56, 8;
(EngineCore_DP0 pid=350615) 	// begin inline asm
(EngineCore_DP0 pid=350615) 	cvt.rn.satfinite.e4m3x2.f32  %rs57, %r85, %r84; 
(EngineCore_DP0 pid=350615) 
(EngineCore_DP0 pid=350615) 	// end inline asm
(EngineCore_DP0 pid=350615) 	shr.u16 	%rs65, %rs57, 8;
(EngineCore_DP0 pid=350615) 	.loc	1 220 27                        // quant_slide_tuned_Llama3.2-1B.py:220:27
(EngineCore_DP0 pid=350615) 	mul.f32 	%r160, %r14, %r135;
(EngineCore_DP0 pid=350615) 	mul.f32 	%r161, %r14, %r136;
(EngineCore_DP0 pid=350615) 	mul.f32 	%r162, %r14, %r137;
(EngineCore_DP0 pid=350615) 	mul.f32 	%r163, %r14, %r138;
(EngineCore_DP0 pid=350615) 	.loc	1 220 48                        // quant_slide_tuned_Llama3.2-1B.py:220:48
(EngineCore_DP0 pid=350615) 	min.xorsign.abs.f32 	%r86, %r160, %r159;
(EngineCore_DP0 pid=350615) 	min.xorsign.abs.f32 	%r87, %r161, %r159;
(EngineCore_DP0 pid=350615) 	min.xorsign.abs.f32 	%r88, %r162, %r159;
(EngineCore_DP0 pid=350615) 	min.xorsign.abs.f32 	%r89, %r163, %r159;
(EngineCore_DP0 pid=350615) 	.loc	1 220 60                        // quant_slide_tuned_Llama3.2-1B.py:220:60
(EngineCore_DP0 pid=350615) 	// begin inline asm
(EngineCore_DP0 pid=350615) 	cvt.rn.satfinite.e4m3x2.f32  %rs58, %r87, %r86; 
(EngineCore_DP0 pid=350615) 
(EngineCore_DP0 pid=350615) 	// end inline asm
(EngineCore_DP0 pid=350615) 	shr.u16 	%rs66, %rs58, 8;
(EngineCore_DP0 pid=350615) 	// begin inline asm
(EngineCore_DP0 pid=350615) 	cvt.rn.satfinite.e4m3x2.f32  %rs59, %r89, %r88; 
(EngineCore_DP0 pid=350615) 
(EngineCore_DP0 pid=350615) 	// end inline asm
(EngineCore_DP0 pid=350615) 	shr.u16 	%rs67, %rs59, 8;
(EngineCore_DP0 pid=350615) 	.loc	1 221 27                        // quant_slide_tuned_Llama3.2-1B.py:221:27
(EngineCore_DP0 pid=350615) 	mul.f32 	%r164, %r14, %r147;
(EngineCore_DP0 pid=350615) 	mul.f32 	%r165, %r14, %r148;
(EngineCore_DP0 pid=350615) 	mul.f32 	%r166, %r14, %r149;
(EngineCore_DP0 pid=350615) 	mul.f32 	%r167, %r14, %r150;
(EngineCore_DP0 pid=350615) 	.loc	1 221 48                        // quant_slide_tuned_Llama3.2-1B.py:221:48
(EngineCore_DP0 pid=350615) 	min.xorsign.abs.f32 	%r90, %r164, %r159;
(EngineCore_DP0 pid=350615) 	min.xorsign.abs.f32 	%r91, %r165, %r159;
(EngineCore_DP0 pid=350615) 	min.xorsign.abs.f32 	%r92, %r166, %r159;
(EngineCore_DP0 pid=350615) 	min.xorsign.abs.f32 	%r93, %r167, %r159;
(EngineCore_DP0 pid=350615) 	.loc	1 221 60                        // quant_slide_tuned_Llama3.2-1B.py:221:60
(EngineCore_DP0 pid=350615) 	// begin inline asm
(EngineCore_DP0 pid=350615) 	cvt.rn.satfinite.e4m3x2.f32  %rs60, %r91, %r90; 
(EngineCore_DP0 pid=350615) 
(EngineCore_DP0 pid=350615) 	// end inline asm
(EngineCore_DP0 pid=350615) 	shr.u16 	%rs68, %rs60, 8;
(EngineCore_DP0 pid=350615) 	// begin inline asm
(EngineCore_DP0 pid=350615) 	cvt.rn.satfinite.e4m3x2.f32  %rs61, %r93, %r92; 
(EngineCore_DP0 pid=350615) 
(EngineCore_DP0 pid=350615) 	// end inline asm
(EngineCore_DP0 pid=350615) 	shr.u16 	%rs69, %rs61, 8;
(EngineCore_DP0 pid=350615) 	.loc	1 222 27                        // quant_slide_tuned_Llama3.2-1B.py:222:27
(EngineCore_DP0 pid=350615) 	mul.f32 	%r168, %r14, %r151;
(EngineCore_DP0 pid=350615) 	mul.f32 	%r169, %r14, %r152;
(EngineCore_DP0 pid=350615) 	mul.f32 	%r170, %r14, %r153;
(EngineCore_DP0 pid=350615) 	mul.f32 	%r171, %r14, %r154;
(EngineCore_DP0 pid=350615) 	.loc	1 222 48                        // quant_slide_tuned_Llama3.2-1B.py:222:48
(EngineCore_DP0 pid=350615) 	min.xorsign.abs.f32 	%r94, %r168, %r159;
(EngineCore_DP0 pid=350615) 	min.xorsign.abs.f32 	%r95, %r169, %r159;
(EngineCore_DP0 pid=350615) 	min.xorsign.abs.f32 	%r96, %r170, %r159;
(EngineCore_DP0 pid=350615) 	min.xorsign.abs.f32 	%r97, %r171, %r159;
(EngineCore_DP0 pid=350615) 	.loc	1 222 60                        // quant_slide_tuned_Llama3.2-1B.py:222:60
(EngineCore_DP0 pid=350615) 	// begin inline asm
(EngineCore_DP0 pid=350615) 	cvt.rn.satfinite.e4m3x2.f32  %rs62, %r95, %r94; 
(EngineCore_DP0 pid=350615) 
(EngineCore_DP0 pid=350615) 	// end inline asm
(EngineCore_DP0 pid=350615) 	shr.u16 	%rs70, %rs62, 8;
(EngineCore_DP0 pid=350615) 	// begin inline asm
(EngineCore_DP0 pid=350615) 	cvt.rn.satfinite.e4m3x2.f32  %rs63, %r97, %r96; 
(EngineCore_DP0 pid=350615) 
(EngineCore_DP0 pid=350615) 	// end inline asm
(EngineCore_DP0 pid=350615) 	shr.u16 	%rs71, %rs63, 8;
(EngineCore_DP0 pid=350615) 	.loc	1 224 45                        // quant_slide_tuned_Llama3.2-1B.py:224:45
(EngineCore_DP0 pid=350615) 	cvt.u32.u16 	%r172, %rs56;
(EngineCore_DP0 pid=350615) 	and.b32 	%r173, %r172, 255;
(EngineCore_DP0 pid=350615) 	cvt.u32.u16 	%r174, %rs64;
(EngineCore_DP0 pid=350615) 	cvt.u32.u16 	%r175, %rs57;
(EngineCore_DP0 pid=350615) 	and.b32 	%r176, %r175, 255;
(EngineCore_DP0 pid=350615) 	cvt.u32.u16 	%r177, %rs65;
(EngineCore_DP0 pid=350615) 	.loc	1 226 45                        // quant_slide_tuned_Llama3.2-1B.py:226:45
(EngineCore_DP0 pid=350615) 	cvt.u32.u16 	%r178, %rs60;
(EngineCore_DP0 pid=350615) 	and.b32 	%r179, %r178, 255;
(EngineCore_DP0 pid=350615) 	cvt.u32.u16 	%r180, %rs68;
(EngineCore_DP0 pid=350615) 	cvt.u32.u16 	%r181, %rs61;
(EngineCore_DP0 pid=350615) 	and.b32 	%r182, %r181, 255;
(EngineCore_DP0 pid=350615) 	cvt.u32.u16 	%r183, %rs69;
(EngineCore_DP0 pid=350615) 	.loc	1 227 45                        // quant_slide_tuned_Llama3.2-1B.py:227:45
(EngineCore_DP0 pid=350615) 	cvt.u32.u16 	%r184, %rs62;
(EngineCore_DP0 pid=350615) 	cvt.u32.u16 	%r185, %rs70;
(EngineCore_DP0 pid=350615) 	cvt.u32.u16 	%r186, %rs63;
(EngineCore_DP0 pid=350615) 	cvt.u32.u16 	%r187, %rs71;
(EngineCore_DP0 pid=350615) 	.loc	1 229 30                        // quant_slide_tuned_Llama3.2-1B.py:229:30
(EngineCore_DP0 pid=350615) 	and.b16 	%rs72, %rs58, 255;
(EngineCore_DP0 pid=350615) 	mul.wide.u16 	%r188, %rs72, 256;
(EngineCore_DP0 pid=350615) 	mul.wide.u16 	%r189, %rs66, 256;
(EngineCore_DP0 pid=350615) 	and.b16 	%rs73, %rs59, 255;
(EngineCore_DP0 pid=350615) 	mul.wide.u16 	%r190, %rs73, 256;
(EngineCore_DP0 pid=350615) 	mul.wide.u16 	%r191, %rs67, 256;
(EngineCore_DP0 pid=350615) 	.loc	1 229 24                        // quant_slide_tuned_Llama3.2-1B.py:229:24
(EngineCore_DP0 pid=350615) 	or.b32 	%r192, %r188, %r173;
(EngineCore_DP0 pid=350615) 	or.b32 	%r193, %r189, %r174;
(EngineCore_DP0 pid=350615) 	or.b32 	%r194, %r190, %r176;
(EngineCore_DP0 pid=350615) 	or.b32 	%r195, %r191, %r177;
(EngineCore_DP0 pid=350615) 	.loc	1 229 42                        // quant_slide_tuned_Llama3.2-1B.py:229:42
(EngineCore_DP0 pid=350615) 	shl.b32 	%r196, %r179, 16;
(EngineCore_DP0 pid=350615) 	shl.b32 	%r197, %r180, 16;
(EngineCore_DP0 pid=350615) 	shl.b32 	%r198, %r182, 16;
(EngineCore_DP0 pid=350615) 	shl.b32 	%r199, %r183, 16;
(EngineCore_DP0 pid=350615) 	.loc	1 229 36                        // quant_slide_tuned_Llama3.2-1B.py:229:36
(EngineCore_DP0 pid=350615) 	or.b32 	%r200, %r196, %r192;
(EngineCore_DP0 pid=350615) 	or.b32 	%r201, %r197, %r193;
(EngineCore_DP0 pid=350615) 	or.b32 	%r202, %r198, %r194;
(EngineCore_DP0 pid=350615) 	or.b32 	%r203, %r199, %r195;
(EngineCore_DP0 pid=350615) 	.loc	1 229 55                        // quant_slide_tuned_Llama3.2-1B.py:229:55
(EngineCore_DP0 pid=350615) 	shl.b32 	%r204, %r184, 24;
(EngineCore_DP0 pid=350615) 	shl.b32 	%r205, %r185, 24;
(EngineCore_DP0 pid=350615) 	shl.b32 	%r206, %r186, 24;
(EngineCore_DP0 pid=350615) 	shl.b32 	%r207, %r187, 24;
(EngineCore_DP0 pid=350615) 	.loc	1 229 49                        // quant_slide_tuned_Llama3.2-1B.py:229:49
(EngineCore_DP0 pid=350615) 	or.b32 	%r98, %r204, %r200;
(EngineCore_DP0 pid=350615) 	or.b32 	%r99, %r205, %r201;
(EngineCore_DP0 pid=350615) 	or.b32 	%r100, %r206, %r202;
(EngineCore_DP0 pid=350615) 	or.b32 	%r101, %r207, %r203;
(EngineCore_DP0 pid=350615) 	.loc	1 230 29                        // quant_slide_tuned_Llama3.2-1B.py:230:29
(EngineCore_DP0 pid=350615) 	mad.wide.s32 	%rd24, %r102, 4, %rd2;
(EngineCore_DP0 pid=350615) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-1B.py:230:39
(EngineCore_DP0 pid=350615) 	// begin inline asm
(EngineCore_DP0 pid=350615) 	@%p25 st.global.v4.b32 [ %rd24 + 0 ], { %r98, %r99, %r100, %r101 };
(EngineCore_DP0 pid=350615) 	// end inline asm
(EngineCore_DP0 pid=350615) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=350615) 	add.s32 	%r211, %r211, 2048;
(EngineCore_DP0 pid=350615) 	setp.lt.s32 	%p42, %r211, %r15;
(EngineCore_DP0 pid=350615) 	@%p42 bra 	$L__BB0_6;
(EngineCore_DP0 pid=350615) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=350615) 	.loc	1 201 4                         // quant_slide_tuned_Llama3.2-1B.py:201:4
(EngineCore_DP0 pid=350615) 	ret;
(EngineCore_DP0 pid=350615) $L__tmp3:
(EngineCore_DP0 pid=350615) $L__func_end0:
(EngineCore_DP0 pid=350615)                                         // -- End function
(EngineCore_DP0 pid=350615) }
(EngineCore_DP0 pid=350615) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=350615) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=350615) 	.section	.debug_abbrev
(EngineCore_DP0 pid=350615) 	{
(EngineCore_DP0 pid=350615) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=350615) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=350615) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=350615) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=350615) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=350615) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=350615) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=350615) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=350615) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=350615) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=350615) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=350615) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=350615) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=350615) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=350615) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=350615) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=350615) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=350615) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=350615) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=350615) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=350615) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=350615) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=350615) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=350615) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=350615) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=350615) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=350615) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=350615) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=350615) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=350615) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=350615) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=350615) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=350615) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=350615) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=350615) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=350615) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=350615) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=350615) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=350615) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=350615) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=350615) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=350615) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=350615) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=350615) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=350615) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=350615) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=350615) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=350615) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=350615) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=350615) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=350615) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=350615) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=350615) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=350615) 	}
(EngineCore_DP0 pid=350615) 	.section	.debug_info
(EngineCore_DP0 pid=350615) 	{
(EngineCore_DP0 pid=350615) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=350615) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=350615) .b8 0
(EngineCore_DP0 pid=350615) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=350615) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=350615) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=350615) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=350615) .b8 114
(EngineCore_DP0 pid=350615) .b8 105
(EngineCore_DP0 pid=350615) .b8 116
(EngineCore_DP0 pid=350615) .b8 111
(EngineCore_DP0 pid=350615) .b8 110
(EngineCore_DP0 pid=350615) .b8 0
(EngineCore_DP0 pid=350615) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=350615) .b8 0
(EngineCore_DP0 pid=350615) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=350615) .b8 117
(EngineCore_DP0 pid=350615) .b8 97
(EngineCore_DP0 pid=350615) .b8 110
(EngineCore_DP0 pid=350615) .b8 116
(EngineCore_DP0 pid=350615) .b8 95
(EngineCore_DP0 pid=350615) .b8 115
(EngineCore_DP0 pid=350615) .b8 108
(EngineCore_DP0 pid=350615) .b8 105
(EngineCore_DP0 pid=350615) .b8 100
(EngineCore_DP0 pid=350615) .b8 101
(EngineCore_DP0 pid=350615) .b8 95
(EngineCore_DP0 pid=350615) .b8 116
(EngineCore_DP0 pid=350615) .b8 117
(EngineCore_DP0 pid=350615) .b8 110
(EngineCore_DP0 pid=350615) .b8 101
(EngineCore_DP0 pid=350615) .b8 100
(EngineCore_DP0 pid=350615) .b8 95
(EngineCore_DP0 pid=350615) .b8 76
(EngineCore_DP0 pid=350615) .b8 108
(EngineCore_DP0 pid=350615) .b8 97
(EngineCore_DP0 pid=350615) .b8 109
(EngineCore_DP0 pid=350615) .b8 97
(EngineCore_DP0 pid=350615) .b8 51
(EngineCore_DP0 pid=350615) .b8 46
(EngineCore_DP0 pid=350615) .b8 50
(EngineCore_DP0 pid=350615) .b8 45
(EngineCore_DP0 pid=350615) .b8 49
(EngineCore_DP0 pid=350615) .b8 66
(EngineCore_DP0 pid=350615) .b8 46
(EngineCore_DP0 pid=350615) .b8 112
(EngineCore_DP0 pid=350615) .b8 121
(EngineCore_DP0 pid=350615) .b8 0
(EngineCore_DP0 pid=350615) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=350615) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=350615) .b8 114
(EngineCore_DP0 pid=350615) .b8 111
(EngineCore_DP0 pid=350615) .b8 111
(EngineCore_DP0 pid=350615) .b8 116
(EngineCore_DP0 pid=350615) .b8 47
(EngineCore_DP0 pid=350615) .b8 118
(EngineCore_DP0 pid=350615) .b8 108
(EngineCore_DP0 pid=350615) .b8 108
(EngineCore_DP0 pid=350615) .b8 109
(EngineCore_DP0 pid=350615) .b8 98
(EngineCore_DP0 pid=350615) .b8 101
(EngineCore_DP0 pid=350615) .b8 110
(EngineCore_DP0 pid=350615) .b8 99
(EngineCore_DP0 pid=350615) .b8 104
(EngineCore_DP0 pid=350615) .b8 47
(EngineCore_DP0 pid=350615) .b8 115
(EngineCore_DP0 pid=350615) .b8 108
(EngineCore_DP0 pid=350615) .b8 105
(EngineCore_DP0 pid=350615) .b8 100
(EngineCore_DP0 pid=350615) .b8 101
(EngineCore_DP0 pid=350615) .b8 115
(EngineCore_DP0 pid=350615) .b8 112
(EngineCore_DP0 pid=350615) .b8 97
(EngineCore_DP0 pid=350615) .b8 114
(EngineCore_DP0 pid=350615) .b8 115
(EngineCore_DP0 pid=350615) .b8 101
(EngineCore_DP0 pid=350615) .b8 47
(EngineCore_DP0 pid=350615) .b8 99
(EngineCore_DP0 pid=350615) .b8 115
(EngineCore_DP0 pid=350615) .b8 114
(EngineCore_DP0 pid=350615) .b8 99
(EngineCore_DP0 pid=350615) .b8 47
(EngineCore_DP0 pid=350615) .b8 102
(EngineCore_DP0 pid=350615) .b8 117
(EngineCore_DP0 pid=350615) .b8 115
(EngineCore_DP0 pid=350615) .b8 101
(EngineCore_DP0 pid=350615) .b8 100
(EngineCore_DP0 pid=350615) .b8 95
(EngineCore_DP0 pid=350615) .b8 113
(EngineCore_DP0 pid=350615) .b8 117
(EngineCore_DP0 pid=350615) .b8 97
(EngineCore_DP0 pid=350615) .b8 110
(EngineCore_DP0 pid=350615) .b8 116
(EngineCore_DP0 pid=350615) .b8 95
(EngineCore_DP0 pid=350615) .b8 115
(EngineCore_DP0 pid=350615) .b8 108
(EngineCore_DP0 pid=350615) .b8 105
(EngineCore_DP0 pid=350615) .b8 100
(EngineCore_DP0 pid=350615) .b8 101
(EngineCore_DP0 pid=350615) .b8 95
(EngineCore_DP0 pid=350615) .b8 116
(EngineCore_DP0 pid=350615) .b8 114
(EngineCore_DP0 pid=350615) .b8 105
(EngineCore_DP0 pid=350615) .b8 116
(EngineCore_DP0 pid=350615) .b8 111
(EngineCore_DP0 pid=350615) .b8 110
(EngineCore_DP0 pid=350615) .b8 47
(EngineCore_DP0 pid=350615) .b8 98
(EngineCore_DP0 pid=350615) .b8 117
(EngineCore_DP0 pid=350615) .b8 105
(EngineCore_DP0 pid=350615) .b8 108
(EngineCore_DP0 pid=350615) .b8 100
(EngineCore_DP0 pid=350615) .b8 47
(EngineCore_DP0 pid=350615) .b8 71
(EngineCore_DP0 pid=350615) .b8 66
(EngineCore_DP0 pid=350615) .b8 49
(EngineCore_DP0 pid=350615) .b8 48
(EngineCore_DP0 pid=350615) .b8 95
(EngineCore_DP0 pid=350615) .b8 99
(EngineCore_DP0 pid=350615) .b8 99
(EngineCore_DP0 pid=350615) .b8 49
(EngineCore_DP0 pid=350615) .b8 50
(EngineCore_DP0 pid=350615) .b8 49
(EngineCore_DP0 pid=350615) .b8 95
(EngineCore_DP0 pid=350615) .b8 112
(EngineCore_DP0 pid=350615) .b8 121
(EngineCore_DP0 pid=350615) .b8 51
(EngineCore_DP0 pid=350615) .b8 49
(EngineCore_DP0 pid=350615) .b8 50
(EngineCore_DP0 pid=350615) .b8 95
(EngineCore_DP0 pid=350615) .b8 99
(EngineCore_DP0 pid=350615) .b8 117
(EngineCore_DP0 pid=350615) .b8 49
(EngineCore_DP0 pid=350615) .b8 50
(EngineCore_DP0 pid=350615) .b8 57
(EngineCore_DP0 pid=350615) .b8 95
(EngineCore_DP0 pid=350615) .b8 97
(EngineCore_DP0 pid=350615) .b8 97
(EngineCore_DP0 pid=350615) .b8 114
(EngineCore_DP0 pid=350615) .b8 99
(EngineCore_DP0 pid=350615) .b8 104
(EngineCore_DP0 pid=350615) .b8 54
(EngineCore_DP0 pid=350615) .b8 52
(EngineCore_DP0 pid=350615) .b8 0
(EngineCore_DP0 pid=350615) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=350615) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=350615) .b8 113
(EngineCore_DP0 pid=350615) .b8 117
(EngineCore_DP0 pid=350615) .b8 97
(EngineCore_DP0 pid=350615) .b8 110
(EngineCore_DP0 pid=350615) .b8 116
(EngineCore_DP0 pid=350615) .b8 95
(EngineCore_DP0 pid=350615) .b8 115
(EngineCore_DP0 pid=350615) .b8 108
(EngineCore_DP0 pid=350615) .b8 105
(EngineCore_DP0 pid=350615) .b8 100
(EngineCore_DP0 pid=350615) .b8 101
(EngineCore_DP0 pid=350615) .b8 95
(EngineCore_DP0 pid=350615) .b8 102
(EngineCore_DP0 pid=350615) .b8 112
(EngineCore_DP0 pid=350615) .b8 56
(EngineCore_DP0 pid=350615) .b8 95
(EngineCore_DP0 pid=350615) .b8 107
(EngineCore_DP0 pid=350615) .b8 101
(EngineCore_DP0 pid=350615) .b8 114
(EngineCore_DP0 pid=350615) .b8 110
(EngineCore_DP0 pid=350615) .b8 101
(EngineCore_DP0 pid=350615) .b8 108
(EngineCore_DP0 pid=350615) .b8 0
(EngineCore_DP0 pid=350615) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=350615) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=350615) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=350615) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=350615) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=350615) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=350615) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=350615) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=350615) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=350615) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=350615) .b8 191                                 // DW_AT_call_line
(EngineCore_DP0 pid=350615) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=350615) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=350615) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=350615) 	}
(EngineCore_DP0 pid=350615) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=350615) 
(EngineCore_DP0 pid=350615) ================================================================
(EngineCore_DP0 pid=350615) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=350615) 
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp4xtyoaop.ptx', '-o', '/tmp/tmp4xtyoaop.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866] 
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866] 
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866] 
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp4xtyoaop.ptx -o /tmp/tmp4xtyoaop.ptx.o
(EngineCore_DP0 pid=350615) ERROR 01-25 19:27:28 [core.py:866] 

STDERR:
[2026-01-25 19:27:11] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:27:11] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:27:11] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:27:11] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:27:11] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:27:11] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:27:11] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:27:11] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:27:11] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:27:11] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:27:11] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:27:11] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:27:11] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:27:11] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:27:15] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:27:15] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:27:15] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:27:15] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:27:15] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:27:15] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:27:15] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:27:15] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:27:15] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:27:15] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:27:15] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:27:15] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:27:15] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:27:15] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=350615) [2026-01-25 19:27:16] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=350615) [2026-01-25 19:27:16] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=350615) [2026-01-25 19:27:16] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=350615) [2026-01-25 19:27:16] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=350615) [2026-01-25 19:27:16] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=350615) [2026-01-25 19:27:16] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=350615) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=350615) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.88s/it]
(EngineCore_DP0 pid=350615) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.88s/it]
(EngineCore_DP0 pid=350615) 
(EngineCore_DP0 pid=350615) [2026-01-25 19:27:27] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=350615) [2026-01-25 19:27:27] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6340608 bytes
(EngineCore_DP0 pid=350615) [2026-01-25 19:27:27] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=350615) [2026-01-25 19:27:27] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 4227072 bytes
(EngineCore_DP0 pid=350615) [2026-01-25 19:27:27] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=350615) [2026-01-25 19:27:27] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 33816576 bytes
(EngineCore_DP0 pid=350615) [2026-01-25 19:27:27] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=350615) [2026-01-25 19:27:27] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16809984 bytes
(EngineCore_DP0 pid=350615) Process EngineCore_DP0:
(EngineCore_DP0 pid=350615) Traceback (most recent call last):
(EngineCore_DP0 pid=350615)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=350615)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=350615)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=350615)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=350615) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp4xtyoaop.ptx', '-o', '/tmp/tmp4xtyoaop.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=350615) 
(EngineCore_DP0 pid=350615) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=350615) 
(EngineCore_DP0 pid=350615) Traceback (most recent call last):
(EngineCore_DP0 pid=350615)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=350615)     self.run()
(EngineCore_DP0 pid=350615)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=350615)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=350615)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=350615)     raise e
(EngineCore_DP0 pid=350615)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=350615)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=350615)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=350615)     super().__init__(
(EngineCore_DP0 pid=350615)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=350615)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=350615)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=350615)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=350615)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=350615)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=350615)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=350615)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=350615)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=350615)     return func(*args, **kwargs)
(EngineCore_DP0 pid=350615)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=350615)     return func(*args, **kwargs)
(EngineCore_DP0 pid=350615)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=350615)     self.model_runner.profile_run()
(EngineCore_DP0 pid=350615)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=350615)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=350615)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=350615)     return func(*args, **kwargs)
(EngineCore_DP0 pid=350615)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=350615)     outputs = self.model(
(EngineCore_DP0 pid=350615)               ^^^^^^^^^^^
(EngineCore_DP0 pid=350615)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=350615)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=350615)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=350615)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=350615)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=350615)     model_output = self.model(
(EngineCore_DP0 pid=350615)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=350615)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=350615)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=350615)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=350615)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=350615)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=350615)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=350615)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=350615)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=350615)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=350615)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=350615)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=350615)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=350615)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=350615)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=350615)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=350615)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=350615)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=350615)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=350615)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=350615)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=350615)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=350615)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=350615)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=350615)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=350615)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=350615)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=350615)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=350615)     return self._linear_fn(
(EngineCore_DP0 pid=350615)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=350615)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=350615)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=350615)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=350615)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=350615)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=350615)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=350615)     return fn(input, L)
(EngineCore_DP0 pid=350615)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=350615)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=350615)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=350615)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=350615)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=350615)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=350615)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=350615)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=350615)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=350615)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=350615)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=350615)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=350615)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=350615)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=350615)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=350615)     raise PTXASError(error)
(EngineCore_DP0 pid=350615) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=350615) `ptxas` stderr:
(EngineCore_DP0 pid=350615) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=350615) 
(EngineCore_DP0 pid=350615) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp4xtyoaop.ptx -o /tmp/tmp4xtyoaop.ptx.o
(EngineCore_DP0 pid=350615) 
[rank0]:[W125 19:27:28.895857106 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=65536

========== M=512 ==========
Time: 2026-01-25 20:14:52
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-3B-FP8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:14:56 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 20:14:56 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=404230) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=404230) 
(EngineCore_DP0 pid=404230) 
(EngineCore_DP0 pid=404230) ================================================================
(EngineCore_DP0 pid=404230) Internal Triton PTX codegen error
(EngineCore_DP0 pid=404230) `ptxas` stderr:
(EngineCore_DP0 pid=404230) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=404230) 
(EngineCore_DP0 pid=404230) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpel5la5du.ptx -o /tmp/tmpel5la5du.ptx.o
(EngineCore_DP0 pid=404230) 
(EngineCore_DP0 pid=404230) 
(EngineCore_DP0 pid=404230) //
(EngineCore_DP0 pid=404230) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=404230) //
(EngineCore_DP0 pid=404230) 
(EngineCore_DP0 pid=404230) .version 8.7
(EngineCore_DP0 pid=404230) .target sm_121a
(EngineCore_DP0 pid=404230) .address_size 64
(EngineCore_DP0 pid=404230) 
(EngineCore_DP0 pid=404230) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=404230) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=404230)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=404230) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=404230) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=404230) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=404230) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=404230) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=404230) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=404230) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=404230) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=404230) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=404230) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=404230) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=404230) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=404230) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=404230) )
(EngineCore_DP0 pid=404230) .reqntid 1024
(EngineCore_DP0 pid=404230) {
(EngineCore_DP0 pid=404230) 	.reg .pred 	%p<20>;
(EngineCore_DP0 pid=404230) 	.reg .b16 	%rs<25>;
(EngineCore_DP0 pid=404230) 	.reg .b32 	%r<115>;
(EngineCore_DP0 pid=404230) 	.reg .b64 	%rd<13>;
(EngineCore_DP0 pid=404230) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=404230) $L__func_begin0:
(EngineCore_DP0 pid=404230) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=404230) 
(EngineCore_DP0 pid=404230) // %bb.0:
(EngineCore_DP0 pid=404230) 	ld.param.b32 	%r19, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=404230) 	ld.param.b32 	%r18, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=404230) 	ld.param.b32 	%r17, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=404230) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=404230) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=404230) $L__tmp0:
(EngineCore_DP0 pid=404230) 	.loc	1 191 24                        // quant_slide_tuned_Llama3.2-3B.py:191:24
(EngineCore_DP0 pid=404230) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=404230) 	ld.param.b32 	%r21, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=404230) 	.loc	1 196 26                        // quant_slide_tuned_Llama3.2-3B.py:196:26
(EngineCore_DP0 pid=404230) 	mul.lo.s32 	%r22, %r21, %r1;
(EngineCore_DP0 pid=404230) 	.loc	1 196 20                        // quant_slide_tuned_Llama3.2-3B.py:196:20
(EngineCore_DP0 pid=404230) 	mad.wide.s32 	%rd1, %r22, 2, %rd4;
(EngineCore_DP0 pid=404230) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=404230) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=404230) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=404230) 	setp.lt.s32 	%p1, %r18, 1;
(EngineCore_DP0 pid=404230) 	mov.b32 	%r113, 0f2B8CBCCC;
(EngineCore_DP0 pid=404230) 	setp.eq.b32 	%p19, %r2, 0;
(EngineCore_DP0 pid=404230) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=404230) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=404230) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=404230) 	shl.b32 	%r3, %r2, 2;
(EngineCore_DP0 pid=404230) 	and.b32 	%r4, %r2, 31;
(EngineCore_DP0 pid=404230) 	shr.u32 	%r31, %r2, 3;
(EngineCore_DP0 pid=404230) 	and.b32 	%r32, %r31, 124;
(EngineCore_DP0 pid=404230) 	mov.b32 	%r33, global_smem;
(EngineCore_DP0 pid=404230) 	add.s32 	%r39, %r33, %r32;
(EngineCore_DP0 pid=404230) 	add.s32 	%r42, %r33, %r3;
(EngineCore_DP0 pid=404230) 	mov.b32 	%r37, 0;
(EngineCore_DP0 pid=404230) 	mov.b32 	%r111, 0f00000000;
(EngineCore_DP0 pid=404230) 	setp.lt.u32 	%p4, %r2, 32;
(EngineCore_DP0 pid=404230) 	setp.eq.b32 	%p3, %r4, 0;
(EngineCore_DP0 pid=404230) 	mov.b32 	%r112, %r37;
(EngineCore_DP0 pid=404230) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=404230) 	.loc	1 203 22                        // quant_slide_tuned_Llama3.2-3B.py:203:22
(EngineCore_DP0 pid=404230) 	add.s32 	%r45, %r3, %r112;
(EngineCore_DP0 pid=404230) 	setp.lt.s32 	%p2, %r45, %r17;
(EngineCore_DP0 pid=404230) 	.loc	1 204 29                        // quant_slide_tuned_Llama3.2-3B.py:204:29
(EngineCore_DP0 pid=404230) 	mad.wide.s32 	%rd6, %r45, 2, %rd1;
(EngineCore_DP0 pid=404230) 	.loc	1 204 21                        // quant_slide_tuned_Llama3.2-3B.py:204:21
(EngineCore_DP0 pid=404230) 	// begin inline asm
(EngineCore_DP0 pid=404230) 	mov.u32 %r35, %r37;
(EngineCore_DP0 pid=404230) 	mov.u32 %r36, %r37;
(EngineCore_DP0 pid=404230) 	@%p2 ld.global.v2.b32 { %r35, %r36 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=404230) 	// end inline asm
(EngineCore_DP0 pid=404230) 	mov.b32 	{%rs1, %rs2}, %r35;
(EngineCore_DP0 pid=404230) 	mov.b32 	{%rs3, %rs4}, %r36;
(EngineCore_DP0 pid=404230) 	.loc	1 205 50                        // quant_slide_tuned_Llama3.2-3B.py:205:50
(EngineCore_DP0 pid=404230) 	abs.bf16 	%rs5, %rs1;
(EngineCore_DP0 pid=404230) 	abs.bf16 	%rs6, %rs2;
(EngineCore_DP0 pid=404230) 	abs.bf16 	%rs7, %rs3;
(EngineCore_DP0 pid=404230) 	abs.bf16 	%rs8, %rs4;
(EngineCore_DP0 pid=404230) $L__tmp1:
(EngineCore_DP0 pid=404230) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=404230) 	bar.sync 	0;
(EngineCore_DP0 pid=404230) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=404230) 	max.bf16 	%rs9, %rs5, %rs6;
(EngineCore_DP0 pid=404230) 	max.bf16 	%rs10, %rs9, %rs7;
(EngineCore_DP0 pid=404230) 	max.bf16 	%rs11, %rs10, %rs8;
(EngineCore_DP0 pid=404230) 	cvt.f32.bf16 	%r46, %rs11;
(EngineCore_DP0 pid=404230) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=404230) 	shfl.sync.bfly.b32 	%r47, %r46, 16, 31, -1;
(EngineCore_DP0 pid=404230) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=404230) 	max.f32 	%r48, %r46, %r47;
(EngineCore_DP0 pid=404230) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=404230) 	shfl.sync.bfly.b32 	%r49, %r48, 8, 31, -1;
(EngineCore_DP0 pid=404230) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=404230) 	max.f32 	%r50, %r48, %r49;
(EngineCore_DP0 pid=404230) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=404230) 	shfl.sync.bfly.b32 	%r51, %r50, 4, 31, -1;
(EngineCore_DP0 pid=404230) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=404230) 	max.f32 	%r52, %r50, %r51;
(EngineCore_DP0 pid=404230) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=404230) 	shfl.sync.bfly.b32 	%r53, %r52, 2, 31, -1;
(EngineCore_DP0 pid=404230) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=404230) 	max.f32 	%r54, %r52, %r53;
(EngineCore_DP0 pid=404230) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=404230) 	shfl.sync.bfly.b32 	%r55, %r54, 1, 31, -1;
(EngineCore_DP0 pid=404230) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=404230) 	max.f32 	%r40, %r54, %r55;
(EngineCore_DP0 pid=404230) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=404230) 	// begin inline asm
(EngineCore_DP0 pid=404230) 	@%p3 st.shared.b32 [ %r39 + 0 ], %r40;
(EngineCore_DP0 pid=404230) 	// end inline asm
(EngineCore_DP0 pid=404230) 	bar.sync 	0;
(EngineCore_DP0 pid=404230) 	// begin inline asm
(EngineCore_DP0 pid=404230) 	@%p4 ld.shared.b32 %r41, [ %r42 + 0 ];
(EngineCore_DP0 pid=404230) 	// end inline asm
(EngineCore_DP0 pid=404230) 	shfl.sync.bfly.b32 	%r56, %r41, 16, 31, -1;
(EngineCore_DP0 pid=404230) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=404230) 	max.f32 	%r57, %r41, %r56;
(EngineCore_DP0 pid=404230) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=404230) 	shfl.sync.bfly.b32 	%r58, %r57, 8, 31, -1;
(EngineCore_DP0 pid=404230) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=404230) 	max.f32 	%r59, %r57, %r58;
(EngineCore_DP0 pid=404230) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=404230) 	shfl.sync.bfly.b32 	%r60, %r59, 4, 31, -1;
(EngineCore_DP0 pid=404230) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=404230) 	max.f32 	%r61, %r59, %r60;
(EngineCore_DP0 pid=404230) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=404230) 	shfl.sync.bfly.b32 	%r62, %r61, 2, 31, -1;
(EngineCore_DP0 pid=404230) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=404230) 	max.f32 	%r63, %r61, %r62;
(EngineCore_DP0 pid=404230) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=404230) 	shfl.sync.bfly.b32 	%r64, %r63, 1, 31, -1;
(EngineCore_DP0 pid=404230) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=404230) 	max.f32 	%r44, %r63, %r64;
(EngineCore_DP0 pid=404230) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=404230) 	// begin inline asm
(EngineCore_DP0 pid=404230) 	@%p19 st.shared.b32 [ %r42 + 0 ], %r44;
(EngineCore_DP0 pid=404230) 	// end inline asm
(EngineCore_DP0 pid=404230) 	bar.sync 	0;
(EngineCore_DP0 pid=404230) 	ld.shared.b32 	%r65, [global_smem];
(EngineCore_DP0 pid=404230) $L__tmp2:
(EngineCore_DP0 pid=404230) 	.loc	1 205 36                        // quant_slide_tuned_Llama3.2-3B.py:205:36
(EngineCore_DP0 pid=404230) 	max.f32 	%r111, %r111, %r65;
(EngineCore_DP0 pid=404230) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=404230) 	add.s32 	%r112, %r112, 4096;
(EngineCore_DP0 pid=404230) 	setp.lt.s32 	%p6, %r112, %r18;
(EngineCore_DP0 pid=404230) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=404230) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=404230) 	.loc	1 207 32                        // quant_slide_tuned_Llama3.2-3B.py:207:32
(EngineCore_DP0 pid=404230) 	max.f32 	%r113, %r111, 0f2B8CBCCC;
(EngineCore_DP0 pid=404230) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=404230) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-3B.py:0:32
(EngineCore_DP0 pid=404230) 	mov.b32 	%r67, 0f43E00000;
(EngineCore_DP0 pid=404230) 	.loc	1 208 32                        // quant_slide_tuned_Llama3.2-3B.py:208:32
(EngineCore_DP0 pid=404230) 	div.full.f32 	%r68, %r113, %r67;
(EngineCore_DP0 pid=404230) 	.loc	1 208 41                        // quant_slide_tuned_Llama3.2-3B.py:208:41
(EngineCore_DP0 pid=404230) 	max.f32 	%r66, %r68, 0f36924925;
(EngineCore_DP0 pid=404230) 	.loc	1 210 25                        // quant_slide_tuned_Llama3.2-3B.py:210:25
(EngineCore_DP0 pid=404230) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=404230) 	.loc	1 210 30                        // quant_slide_tuned_Llama3.2-3B.py:210:30
(EngineCore_DP0 pid=404230) 	// begin inline asm
(EngineCore_DP0 pid=404230) 	@%p19 st.global.b32 [ %rd7 + 0 ], { %r66 };
(EngineCore_DP0 pid=404230) 	// end inline asm
(EngineCore_DP0 pid=404230) 	.loc	1 213 29                        // quant_slide_tuned_Llama3.2-3B.py:213:29
(EngineCore_DP0 pid=404230) 	shl.b32 	%r14, %r19, 2;
(EngineCore_DP0 pid=404230) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=404230) 	setp.lt.s32 	%p8, %r14, 1;
(EngineCore_DP0 pid=404230) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=404230) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=404230) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-3B.py:0:41
(EngineCore_DP0 pid=404230) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=404230) 	shr.s32 	%r24, %r23, 31;
(EngineCore_DP0 pid=404230) 	shr.u32 	%r25, %r24, 30;
(EngineCore_DP0 pid=404230) 	add.s32 	%r26, %r23, %r25;
(EngineCore_DP0 pid=404230) 	shr.s32 	%r27, %r26, 2;
(EngineCore_DP0 pid=404230) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=404230) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=404230) 	mad.wide.s32 	%rd2, %r28, 4, %rd5;
(EngineCore_DP0 pid=404230) 	div.full.f32 	%r13, %r67, %r113;
(EngineCore_DP0 pid=404230) 	mov.b32 	%r114, 0;
(EngineCore_DP0 pid=404230) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=404230)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=404230) 	.loc	1 217 30                        // quant_slide_tuned_Llama3.2-3B.py:217:30
(EngineCore_DP0 pid=404230) 	add.s32 	%r80, %r2, %r114;
(EngineCore_DP0 pid=404230) 	setp.lt.s32 	%p13, %r80, %r14;
(EngineCore_DP0 pid=404230) 	.loc	1 220 24                        // quant_slide_tuned_Llama3.2-3B.py:220:24
(EngineCore_DP0 pid=404230) 	shr.s32 	%r81, %r80, 31;
(EngineCore_DP0 pid=404230) 	shr.u32 	%r82, %r81, 30;
(EngineCore_DP0 pid=404230) 	add.s32 	%r83, %r80, %r82;
(EngineCore_DP0 pid=404230) 	shr.s32 	%r84, %r83, 2;
(EngineCore_DP0 pid=404230) 	.loc	1 221 23                        // quant_slide_tuned_Llama3.2-3B.py:221:23
(EngineCore_DP0 pid=404230) 	and.b32 	%r85, %r83, 2147483644;
(EngineCore_DP0 pid=404230) 	sub.s32 	%r86, %r80, %r85;
(EngineCore_DP0 pid=404230) 	.loc	1 222 30                        // quant_slide_tuned_Llama3.2-3B.py:222:30
(EngineCore_DP0 pid=404230) 	shl.b32 	%r87, %r86, 1;
(EngineCore_DP0 pid=404230) 	.loc	1 222 26                        // quant_slide_tuned_Llama3.2-3B.py:222:26
(EngineCore_DP0 pid=404230) 	mad.lo.s32 	%r88, %r84, 10, %r87;
(EngineCore_DP0 pid=404230) 	.loc	1 225 53                        // quant_slide_tuned_Llama3.2-3B.py:225:53
(EngineCore_DP0 pid=404230) 	setp.lt.s32 	%p14, %r88, %r17;
(EngineCore_DP0 pid=404230) 	.loc	1 225 37                        // quant_slide_tuned_Llama3.2-3B.py:225:37
(EngineCore_DP0 pid=404230) 	and.pred 	%p9, %p13, %p14;
(EngineCore_DP0 pid=404230) 	.loc	1 224 29                        // quant_slide_tuned_Llama3.2-3B.py:224:29
(EngineCore_DP0 pid=404230) 	mad.wide.s32 	%rd8, %r88, 2, %rd1;
(EngineCore_DP0 pid=404230) 	mov.b16 	%rs13, 0;
(EngineCore_DP0 pid=404230) 	.loc	1 224 21                        // quant_slide_tuned_Llama3.2-3B.py:224:21
(EngineCore_DP0 pid=404230) 	// begin inline asm
(EngineCore_DP0 pid=404230) 	mov.u16 %rs12, %rs13;
(EngineCore_DP0 pid=404230) 	@%p9 ld.global.b16 { %rs12 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=404230) 	// end inline asm
(EngineCore_DP0 pid=404230) 	.loc	1 225 79                        // quant_slide_tuned_Llama3.2-3B.py:225:79
(EngineCore_DP0 pid=404230) 	cvt.f32.bf16 	%r89, %rs12;
(EngineCore_DP0 pid=404230) 	.loc	1 227 48                        // quant_slide_tuned_Llama3.2-3B.py:227:48
(EngineCore_DP0 pid=404230) 	or.b32 	%r90, %r88, 1;
(EngineCore_DP0 pid=404230) 	.loc	1 227 53                        // quant_slide_tuned_Llama3.2-3B.py:227:53
(EngineCore_DP0 pid=404230) 	setp.lt.s32 	%p15, %r90, %r17;
(EngineCore_DP0 pid=404230) 	.loc	1 227 37                        // quant_slide_tuned_Llama3.2-3B.py:227:37
(EngineCore_DP0 pid=404230) 	and.pred 	%p10, %p13, %p15;
(EngineCore_DP0 pid=404230) 	.loc	1 226 39                        // quant_slide_tuned_Llama3.2-3B.py:226:39
(EngineCore_DP0 pid=404230) 	add.s64 	%rd9, %rd8, 2;
(EngineCore_DP0 pid=404230) 	.loc	1 226 21                        // quant_slide_tuned_Llama3.2-3B.py:226:21
(EngineCore_DP0 pid=404230) 	// begin inline asm
(EngineCore_DP0 pid=404230) 	mov.u16 %rs14, %rs13;
(EngineCore_DP0 pid=404230) 	@%p10 ld.global.b16 { %rs14 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=404230) 	// end inline asm
(EngineCore_DP0 pid=404230) 	.loc	1 227 79                        // quant_slide_tuned_Llama3.2-3B.py:227:79
(EngineCore_DP0 pid=404230) 	cvt.f32.bf16 	%r91, %rs14;
(EngineCore_DP0 pid=404230) 	.loc	1 229 48                        // quant_slide_tuned_Llama3.2-3B.py:229:48
(EngineCore_DP0 pid=404230) 	add.s32 	%r92, %r88, 2;
(EngineCore_DP0 pid=404230) 	.loc	1 229 53                        // quant_slide_tuned_Llama3.2-3B.py:229:53
(EngineCore_DP0 pid=404230) 	setp.lt.s32 	%p16, %r92, %r17;
(EngineCore_DP0 pid=404230) 	.loc	1 229 37                        // quant_slide_tuned_Llama3.2-3B.py:229:37
(EngineCore_DP0 pid=404230) 	and.pred 	%p11, %p13, %p16;
(EngineCore_DP0 pid=404230) 	.loc	1 228 39                        // quant_slide_tuned_Llama3.2-3B.py:228:39
(EngineCore_DP0 pid=404230) 	add.s64 	%rd10, %rd8, 4;
(EngineCore_DP0 pid=404230) 	.loc	1 228 21                        // quant_slide_tuned_Llama3.2-3B.py:228:21
(EngineCore_DP0 pid=404230) 	// begin inline asm
(EngineCore_DP0 pid=404230) 	mov.u16 %rs16, %rs13;
(EngineCore_DP0 pid=404230) 	@%p11 ld.global.b16 { %rs16 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=404230) 	// end inline asm
(EngineCore_DP0 pid=404230) 	.loc	1 229 79                        // quant_slide_tuned_Llama3.2-3B.py:229:79
(EngineCore_DP0 pid=404230) 	cvt.f32.bf16 	%r93, %rs16;
(EngineCore_DP0 pid=404230) 	.loc	1 231 48                        // quant_slide_tuned_Llama3.2-3B.py:231:48
(EngineCore_DP0 pid=404230) 	add.s32 	%r94, %r88, 3;
(EngineCore_DP0 pid=404230) 	.loc	1 231 53                        // quant_slide_tuned_Llama3.2-3B.py:231:53
(EngineCore_DP0 pid=404230) 	setp.lt.s32 	%p17, %r94, %r17;
(EngineCore_DP0 pid=404230) 	.loc	1 231 37                        // quant_slide_tuned_Llama3.2-3B.py:231:37
(EngineCore_DP0 pid=404230) 	and.pred 	%p12, %p13, %p17;
(EngineCore_DP0 pid=404230) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-3B.py:230:39
(EngineCore_DP0 pid=404230) 	add.s64 	%rd11, %rd8, 6;
(EngineCore_DP0 pid=404230) 	.loc	1 230 21                        // quant_slide_tuned_Llama3.2-3B.py:230:21
(EngineCore_DP0 pid=404230) 	// begin inline asm
(EngineCore_DP0 pid=404230) 	mov.u16 %rs18, %rs13;
(EngineCore_DP0 pid=404230) 	@%p12 ld.global.b16 { %rs18 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=404230) 	// end inline asm
(EngineCore_DP0 pid=404230) 	.loc	1 231 79                        // quant_slide_tuned_Llama3.2-3B.py:231:79
(EngineCore_DP0 pid=404230) 	cvt.f32.bf16 	%r95, %rs18;
(EngineCore_DP0 pid=404230) 	.loc	1 233 27                        // quant_slide_tuned_Llama3.2-3B.py:233:27
(EngineCore_DP0 pid=404230) 	mul.f32 	%r96, %r13, %r89;
(EngineCore_DP0 pid=404230) 	mov.b32 	%r97, 0f43E00000;
(EngineCore_DP0 pid=404230) 	.loc	1 233 48                        // quant_slide_tuned_Llama3.2-3B.py:233:48
(EngineCore_DP0 pid=404230) 	min.xorsign.abs.f32 	%r70, %r96, %r97;
(EngineCore_DP0 pid=404230) 	.loc	1 233 60                        // quant_slide_tuned_Llama3.2-3B.py:233:60
(EngineCore_DP0 pid=404230) 	// begin inline asm
(EngineCore_DP0 pid=404230) 	cvt.rn.satfinite.e4m3x2.f32  %rs20, %r71, %r70; 
(EngineCore_DP0 pid=404230) 
(EngineCore_DP0 pid=404230) 	// end inline asm
(EngineCore_DP0 pid=404230) 	.loc	1 234 27                        // quant_slide_tuned_Llama3.2-3B.py:234:27
(EngineCore_DP0 pid=404230) 	mul.f32 	%r98, %r13, %r91;
(EngineCore_DP0 pid=404230) 	.loc	1 234 48                        // quant_slide_tuned_Llama3.2-3B.py:234:48
(EngineCore_DP0 pid=404230) 	min.xorsign.abs.f32 	%r72, %r98, %r97;
(EngineCore_DP0 pid=404230) 	.loc	1 234 60                        // quant_slide_tuned_Llama3.2-3B.py:234:60
(EngineCore_DP0 pid=404230) 	// begin inline asm
(EngineCore_DP0 pid=404230) 	cvt.rn.satfinite.e4m3x2.f32  %rs21, %r73, %r72; 
(EngineCore_DP0 pid=404230) 
(EngineCore_DP0 pid=404230) 	// end inline asm
(EngineCore_DP0 pid=404230) 	.loc	1 235 27                        // quant_slide_tuned_Llama3.2-3B.py:235:27
(EngineCore_DP0 pid=404230) 	mul.f32 	%r99, %r13, %r93;
(EngineCore_DP0 pid=404230) 	.loc	1 235 48                        // quant_slide_tuned_Llama3.2-3B.py:235:48
(EngineCore_DP0 pid=404230) 	min.xorsign.abs.f32 	%r74, %r99, %r97;
(EngineCore_DP0 pid=404230) 	.loc	1 235 60                        // quant_slide_tuned_Llama3.2-3B.py:235:60
(EngineCore_DP0 pid=404230) 	// begin inline asm
(EngineCore_DP0 pid=404230) 	cvt.rn.satfinite.e4m3x2.f32  %rs22, %r75, %r74; 
(EngineCore_DP0 pid=404230) 
(EngineCore_DP0 pid=404230) 	// end inline asm
(EngineCore_DP0 pid=404230) 	.loc	1 236 27                        // quant_slide_tuned_Llama3.2-3B.py:236:27
(EngineCore_DP0 pid=404230) 	mul.f32 	%r100, %r13, %r95;
(EngineCore_DP0 pid=404230) 	.loc	1 236 48                        // quant_slide_tuned_Llama3.2-3B.py:236:48
(EngineCore_DP0 pid=404230) 	min.xorsign.abs.f32 	%r76, %r100, %r97;
(EngineCore_DP0 pid=404230) 	.loc	1 236 60                        // quant_slide_tuned_Llama3.2-3B.py:236:60
(EngineCore_DP0 pid=404230) 	// begin inline asm
(EngineCore_DP0 pid=404230) 	cvt.rn.satfinite.e4m3x2.f32  %rs23, %r77, %r76; 
(EngineCore_DP0 pid=404230) 
(EngineCore_DP0 pid=404230) 	// end inline asm
(EngineCore_DP0 pid=404230) 	.loc	1 238 45                        // quant_slide_tuned_Llama3.2-3B.py:238:45
(EngineCore_DP0 pid=404230) 	cvt.u32.u16 	%r101, %rs20;
(EngineCore_DP0 pid=404230) 	and.b32 	%r102, %r101, 255;
(EngineCore_DP0 pid=404230) 	.loc	1 240 45                        // quant_slide_tuned_Llama3.2-3B.py:240:45
(EngineCore_DP0 pid=404230) 	cvt.u32.u16 	%r103, %rs22;
(EngineCore_DP0 pid=404230) 	and.b32 	%r104, %r103, 255;
(EngineCore_DP0 pid=404230) 	.loc	1 241 45                        // quant_slide_tuned_Llama3.2-3B.py:241:45
(EngineCore_DP0 pid=404230) 	cvt.u32.u16 	%r105, %rs23;
(EngineCore_DP0 pid=404230) 	.loc	1 243 30                        // quant_slide_tuned_Llama3.2-3B.py:243:30
(EngineCore_DP0 pid=404230) 	and.b16 	%rs24, %rs21, 255;
(EngineCore_DP0 pid=404230) 	mul.wide.u16 	%r106, %rs24, 256;
(EngineCore_DP0 pid=404230) 	.loc	1 243 24                        // quant_slide_tuned_Llama3.2-3B.py:243:24
(EngineCore_DP0 pid=404230) 	or.b32 	%r107, %r106, %r102;
(EngineCore_DP0 pid=404230) 	.loc	1 243 42                        // quant_slide_tuned_Llama3.2-3B.py:243:42
(EngineCore_DP0 pid=404230) 	shl.b32 	%r108, %r104, 16;
(EngineCore_DP0 pid=404230) 	.loc	1 243 36                        // quant_slide_tuned_Llama3.2-3B.py:243:36
(EngineCore_DP0 pid=404230) 	or.b32 	%r109, %r107, %r108;
(EngineCore_DP0 pid=404230) 	.loc	1 243 55                        // quant_slide_tuned_Llama3.2-3B.py:243:55
(EngineCore_DP0 pid=404230) 	shl.b32 	%r110, %r105, 24;
(EngineCore_DP0 pid=404230) 	.loc	1 243 49                        // quant_slide_tuned_Llama3.2-3B.py:243:49
(EngineCore_DP0 pid=404230) 	or.b32 	%r78, %r109, %r110;
(EngineCore_DP0 pid=404230) 	.loc	1 244 29                        // quant_slide_tuned_Llama3.2-3B.py:244:29
(EngineCore_DP0 pid=404230) 	mad.wide.s32 	%rd12, %r80, 4, %rd2;
(EngineCore_DP0 pid=404230) 	.loc	1 244 39                        // quant_slide_tuned_Llama3.2-3B.py:244:39
(EngineCore_DP0 pid=404230) 	// begin inline asm
(EngineCore_DP0 pid=404230) 	@%p13 st.global.b32 [ %rd12 + 0 ], { %r78 };
(EngineCore_DP0 pid=404230) 	// end inline asm
(EngineCore_DP0 pid=404230) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=404230) 	add.s32 	%r114, %r114, 1024;
(EngineCore_DP0 pid=404230) 	setp.lt.s32 	%p18, %r114, %r14;
(EngineCore_DP0 pid=404230) 	@%p18 bra 	$L__BB0_6;
(EngineCore_DP0 pid=404230) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=404230) 	.loc	1 215 4                         // quant_slide_tuned_Llama3.2-3B.py:215:4
(EngineCore_DP0 pid=404230) 	ret;
(EngineCore_DP0 pid=404230) $L__tmp3:
(EngineCore_DP0 pid=404230) $L__func_end0:
(EngineCore_DP0 pid=404230)                                         // -- End function
(EngineCore_DP0 pid=404230) }
(EngineCore_DP0 pid=404230) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py"
(EngineCore_DP0 pid=404230) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=404230) 	.section	.debug_abbrev
(EngineCore_DP0 pid=404230) 	{
(EngineCore_DP0 pid=404230) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=404230) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=404230) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=404230) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=404230) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=404230) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=404230) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=404230) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=404230) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=404230) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=404230) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=404230) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=404230) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=404230) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=404230) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=404230) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=404230) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=404230) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=404230) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=404230) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=404230) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=404230) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=404230) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=404230) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=404230) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=404230) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=404230) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=404230) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=404230) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=404230) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=404230) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=404230) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=404230) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=404230) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=404230) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=404230) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=404230) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=404230) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=404230) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=404230) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=404230) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=404230) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=404230) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=404230) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=404230) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=404230) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=404230) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=404230) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=404230) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=404230) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=404230) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=404230) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=404230) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=404230) 	}
(EngineCore_DP0 pid=404230) 	.section	.debug_info
(EngineCore_DP0 pid=404230) 	{
(EngineCore_DP0 pid=404230) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=404230) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=404230) .b8 0
(EngineCore_DP0 pid=404230) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=404230) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=404230) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=404230) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=404230) .b8 114
(EngineCore_DP0 pid=404230) .b8 105
(EngineCore_DP0 pid=404230) .b8 116
(EngineCore_DP0 pid=404230) .b8 111
(EngineCore_DP0 pid=404230) .b8 110
(EngineCore_DP0 pid=404230) .b8 0
(EngineCore_DP0 pid=404230) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=404230) .b8 0
(EngineCore_DP0 pid=404230) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=404230) .b8 117
(EngineCore_DP0 pid=404230) .b8 97
(EngineCore_DP0 pid=404230) .b8 110
(EngineCore_DP0 pid=404230) .b8 116
(EngineCore_DP0 pid=404230) .b8 95
(EngineCore_DP0 pid=404230) .b8 115
(EngineCore_DP0 pid=404230) .b8 108
(EngineCore_DP0 pid=404230) .b8 105
(EngineCore_DP0 pid=404230) .b8 100
(EngineCore_DP0 pid=404230) .b8 101
(EngineCore_DP0 pid=404230) .b8 95
(EngineCore_DP0 pid=404230) .b8 116
(EngineCore_DP0 pid=404230) .b8 117
(EngineCore_DP0 pid=404230) .b8 110
(EngineCore_DP0 pid=404230) .b8 101
(EngineCore_DP0 pid=404230) .b8 100
(EngineCore_DP0 pid=404230) .b8 95
(EngineCore_DP0 pid=404230) .b8 76
(EngineCore_DP0 pid=404230) .b8 108
(EngineCore_DP0 pid=404230) .b8 97
(EngineCore_DP0 pid=404230) .b8 109
(EngineCore_DP0 pid=404230) .b8 97
(EngineCore_DP0 pid=404230) .b8 51
(EngineCore_DP0 pid=404230) .b8 46
(EngineCore_DP0 pid=404230) .b8 50
(EngineCore_DP0 pid=404230) .b8 45
(EngineCore_DP0 pid=404230) .b8 51
(EngineCore_DP0 pid=404230) .b8 66
(EngineCore_DP0 pid=404230) .b8 46
(EngineCore_DP0 pid=404230) .b8 112
(EngineCore_DP0 pid=404230) .b8 121
(EngineCore_DP0 pid=404230) .b8 0
(EngineCore_DP0 pid=404230) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=404230) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=404230) .b8 114
(EngineCore_DP0 pid=404230) .b8 111
(EngineCore_DP0 pid=404230) .b8 111
(EngineCore_DP0 pid=404230) .b8 116
(EngineCore_DP0 pid=404230) .b8 47
(EngineCore_DP0 pid=404230) .b8 118
(EngineCore_DP0 pid=404230) .b8 108
(EngineCore_DP0 pid=404230) .b8 108
(EngineCore_DP0 pid=404230) .b8 109
(EngineCore_DP0 pid=404230) .b8 98
(EngineCore_DP0 pid=404230) .b8 101
(EngineCore_DP0 pid=404230) .b8 110
(EngineCore_DP0 pid=404230) .b8 99
(EngineCore_DP0 pid=404230) .b8 104
(EngineCore_DP0 pid=404230) .b8 47
(EngineCore_DP0 pid=404230) .b8 115
(EngineCore_DP0 pid=404230) .b8 108
(EngineCore_DP0 pid=404230) .b8 105
(EngineCore_DP0 pid=404230) .b8 100
(EngineCore_DP0 pid=404230) .b8 101
(EngineCore_DP0 pid=404230) .b8 115
(EngineCore_DP0 pid=404230) .b8 112
(EngineCore_DP0 pid=404230) .b8 97
(EngineCore_DP0 pid=404230) .b8 114
(EngineCore_DP0 pid=404230) .b8 115
(EngineCore_DP0 pid=404230) .b8 101
(EngineCore_DP0 pid=404230) .b8 47
(EngineCore_DP0 pid=404230) .b8 99
(EngineCore_DP0 pid=404230) .b8 115
(EngineCore_DP0 pid=404230) .b8 114
(EngineCore_DP0 pid=404230) .b8 99
(EngineCore_DP0 pid=404230) .b8 47
(EngineCore_DP0 pid=404230) .b8 102
(EngineCore_DP0 pid=404230) .b8 117
(EngineCore_DP0 pid=404230) .b8 115
(EngineCore_DP0 pid=404230) .b8 101
(EngineCore_DP0 pid=404230) .b8 100
(EngineCore_DP0 pid=404230) .b8 95
(EngineCore_DP0 pid=404230) .b8 113
(EngineCore_DP0 pid=404230) .b8 117
(EngineCore_DP0 pid=404230) .b8 97
(EngineCore_DP0 pid=404230) .b8 110
(EngineCore_DP0 pid=404230) .b8 116
(EngineCore_DP0 pid=404230) .b8 95
(EngineCore_DP0 pid=404230) .b8 115
(EngineCore_DP0 pid=404230) .b8 108
(EngineCore_DP0 pid=404230) .b8 105
(EngineCore_DP0 pid=404230) .b8 100
(EngineCore_DP0 pid=404230) .b8 101
(EngineCore_DP0 pid=404230) .b8 95
(EngineCore_DP0 pid=404230) .b8 116
(EngineCore_DP0 pid=404230) .b8 114
(EngineCore_DP0 pid=404230) .b8 105
(EngineCore_DP0 pid=404230) .b8 116
(EngineCore_DP0 pid=404230) .b8 111
(EngineCore_DP0 pid=404230) .b8 110
(EngineCore_DP0 pid=404230) .b8 47
(EngineCore_DP0 pid=404230) .b8 98
(EngineCore_DP0 pid=404230) .b8 117
(EngineCore_DP0 pid=404230) .b8 105
(EngineCore_DP0 pid=404230) .b8 108
(EngineCore_DP0 pid=404230) .b8 100
(EngineCore_DP0 pid=404230) .b8 47
(EngineCore_DP0 pid=404230) .b8 71
(EngineCore_DP0 pid=404230) .b8 66
(EngineCore_DP0 pid=404230) .b8 49
(EngineCore_DP0 pid=404230) .b8 48
(EngineCore_DP0 pid=404230) .b8 95
(EngineCore_DP0 pid=404230) .b8 99
(EngineCore_DP0 pid=404230) .b8 99
(EngineCore_DP0 pid=404230) .b8 49
(EngineCore_DP0 pid=404230) .b8 50
(EngineCore_DP0 pid=404230) .b8 49
(EngineCore_DP0 pid=404230) .b8 95
(EngineCore_DP0 pid=404230) .b8 112
(EngineCore_DP0 pid=404230) .b8 121
(EngineCore_DP0 pid=404230) .b8 51
(EngineCore_DP0 pid=404230) .b8 49
(EngineCore_DP0 pid=404230) .b8 50
(EngineCore_DP0 pid=404230) .b8 95
(EngineCore_DP0 pid=404230) .b8 99
(EngineCore_DP0 pid=404230) .b8 117
(EngineCore_DP0 pid=404230) .b8 49
(EngineCore_DP0 pid=404230) .b8 50
(EngineCore_DP0 pid=404230) .b8 57
(EngineCore_DP0 pid=404230) .b8 95
(EngineCore_DP0 pid=404230) .b8 97
(EngineCore_DP0 pid=404230) .b8 97
(EngineCore_DP0 pid=404230) .b8 114
(EngineCore_DP0 pid=404230) .b8 99
(EngineCore_DP0 pid=404230) .b8 104
(EngineCore_DP0 pid=404230) .b8 54
(EngineCore_DP0 pid=404230) .b8 52
(EngineCore_DP0 pid=404230) .b8 0
(EngineCore_DP0 pid=404230) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=404230) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=404230) .b8 113
(EngineCore_DP0 pid=404230) .b8 117
(EngineCore_DP0 pid=404230) .b8 97
(EngineCore_DP0 pid=404230) .b8 110
(EngineCore_DP0 pid=404230) .b8 116
(EngineCore_DP0 pid=404230) .b8 95
(EngineCore_DP0 pid=404230) .b8 115
(EngineCore_DP0 pid=404230) .b8 108
(EngineCore_DP0 pid=404230) .b8 105
(EngineCore_DP0 pid=404230) .b8 100
(EngineCore_DP0 pid=404230) .b8 101
(EngineCore_DP0 pid=404230) .b8 95
(EngineCore_DP0 pid=404230) .b8 102
(EngineCore_DP0 pid=404230) .b8 112
(EngineCore_DP0 pid=404230) .b8 56
(EngineCore_DP0 pid=404230) .b8 95
(EngineCore_DP0 pid=404230) .b8 107
(EngineCore_DP0 pid=404230) .b8 101
(EngineCore_DP0 pid=404230) .b8 114
(EngineCore_DP0 pid=404230) .b8 110
(EngineCore_DP0 pid=404230) .b8 101
(EngineCore_DP0 pid=404230) .b8 108
(EngineCore_DP0 pid=404230) .b8 0
(EngineCore_DP0 pid=404230) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=404230) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=404230) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=404230) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=404230) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=404230) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=404230) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=404230) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=404230) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=404230) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=404230) .b8 205                                 // DW_AT_call_line
(EngineCore_DP0 pid=404230) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=404230) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=404230) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=404230) 	}
(EngineCore_DP0 pid=404230) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=404230) 
(EngineCore_DP0 pid=404230) ================================================================
(EngineCore_DP0 pid=404230) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=404230) 
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpel5la5du.ptx', '-o', '/tmp/tmpel5la5du.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866] 
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866] 
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866] 
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpel5la5du.ptx -o /tmp/tmpel5la5du.ptx.o
(EngineCore_DP0 pid=404230) ERROR 01-25 20:15:28 [core.py:866] 

STDERR:
[2026-01-25 20:14:56] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:14:56] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:14:56] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:14:56] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:14:56] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:14:56] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:14:56] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:14:56] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:14:56] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:14:56] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:14:56] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:14:56] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:14:56] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:14:56] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:14:59] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:14:59] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:14:59] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:14:59] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:14:59] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:14:59] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:14:59] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:14:59] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:14:59] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:14:59] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:14:59] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:14:59] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:14:59] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:14:59] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=404230) [2026-01-25 20:15:00] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=404230) [2026-01-25 20:15:00] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=404230) [2026-01-25 20:15:00] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=404230) [2026-01-25 20:15:00] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=404230) [2026-01-25 20:15:00] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=404230) [2026-01-25 20:15:00] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=404230) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=404230) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:25<00:00, 25.87s/it]
(EngineCore_DP0 pid=404230) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:25<00:00, 25.87s/it]
(EngineCore_DP0 pid=404230) 
(EngineCore_DP0 pid=404230) [2026-01-25 20:15:27] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4928] -> 1D uint8
(EngineCore_DP0 pid=404230) [2026-01-25 20:15:27] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15810560 bytes
(EngineCore_DP0 pid=404230) [2026-01-25 20:15:27] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4928] -> 1D uint8
(EngineCore_DP0 pid=404230) [2026-01-25 20:15:27] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9486336 bytes
(EngineCore_DP0 pid=404230) [2026-01-25 20:15:27] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4928] -> 1D uint8
(EngineCore_DP0 pid=404230) [2026-01-25 20:15:27] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 50593792 bytes
(EngineCore_DP0 pid=404230) [2026-01-25 20:15:27] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 13120] -> 1D uint8
(EngineCore_DP0 pid=404230) [2026-01-25 20:15:27] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 25214976 bytes
(EngineCore_DP0 pid=404230) Process EngineCore_DP0:
(EngineCore_DP0 pid=404230) Traceback (most recent call last):
(EngineCore_DP0 pid=404230)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=404230)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=404230)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=404230)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=404230) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpel5la5du.ptx', '-o', '/tmp/tmpel5la5du.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=404230) 
(EngineCore_DP0 pid=404230) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=404230) 
(EngineCore_DP0 pid=404230) Traceback (most recent call last):
(EngineCore_DP0 pid=404230)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=404230)     self.run()
(EngineCore_DP0 pid=404230)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=404230)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=404230)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=404230)     raise e
(EngineCore_DP0 pid=404230)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=404230)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=404230)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=404230)     super().__init__(
(EngineCore_DP0 pid=404230)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=404230)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=404230)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=404230)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=404230)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=404230)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=404230)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=404230)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=404230)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=404230)     return func(*args, **kwargs)
(EngineCore_DP0 pid=404230)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=404230)     return func(*args, **kwargs)
(EngineCore_DP0 pid=404230)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=404230)     self.model_runner.profile_run()
(EngineCore_DP0 pid=404230)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=404230)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=404230)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=404230)     return func(*args, **kwargs)
(EngineCore_DP0 pid=404230)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=404230)     outputs = self.model(
(EngineCore_DP0 pid=404230)               ^^^^^^^^^^^
(EngineCore_DP0 pid=404230)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=404230)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=404230)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=404230)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=404230)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=404230)     model_output = self.model(
(EngineCore_DP0 pid=404230)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=404230)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=404230)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=404230)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=404230)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=404230)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=404230)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=404230)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=404230)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=404230)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=404230)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=404230)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=404230)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=404230)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=404230)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=404230)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=404230)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=404230)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=404230)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=404230)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=404230)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=404230)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=404230)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=404230)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=404230)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=404230)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=404230)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=404230)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=404230)     return self._linear_fn(
(EngineCore_DP0 pid=404230)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=404230)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=404230)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=404230)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=404230)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=404230)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=404230)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=404230)     return fn(input, L)
(EngineCore_DP0 pid=404230)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=404230)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=404230)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=404230)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=404230)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=404230)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=404230)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=404230)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=404230)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=404230)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=404230)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=404230)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=404230)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=404230)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404230)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=404230)     raise PTXASError(error)
(EngineCore_DP0 pid=404230) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=404230) `ptxas` stderr:
(EngineCore_DP0 pid=404230) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=404230) 
(EngineCore_DP0 pid=404230) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpel5la5du.ptx -o /tmp/tmpel5la5du.ptx.o
(EngineCore_DP0 pid=404230) 
[rank0]:[W125 20:15:28.116109339 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=512

========== M=1024 ==========
Time: 2026-01-25 20:15:30
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-3B-FP8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:15:34 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 20:15:34 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=404937) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=404937) 
(EngineCore_DP0 pid=404937) 
(EngineCore_DP0 pid=404937) ================================================================
(EngineCore_DP0 pid=404937) Internal Triton PTX codegen error
(EngineCore_DP0 pid=404937) `ptxas` stderr:
(EngineCore_DP0 pid=404937) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=404937) 
(EngineCore_DP0 pid=404937) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpr22_ug4k.ptx -o /tmp/tmpr22_ug4k.ptx.o
(EngineCore_DP0 pid=404937) 
(EngineCore_DP0 pid=404937) 
(EngineCore_DP0 pid=404937) //
(EngineCore_DP0 pid=404937) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=404937) //
(EngineCore_DP0 pid=404937) 
(EngineCore_DP0 pid=404937) .version 8.7
(EngineCore_DP0 pid=404937) .target sm_121a
(EngineCore_DP0 pid=404937) .address_size 64
(EngineCore_DP0 pid=404937) 
(EngineCore_DP0 pid=404937) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=404937) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=404937)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=404937) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=404937) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=404937) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=404937) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=404937) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=404937) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=404937) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=404937) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=404937) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=404937) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=404937) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=404937) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=404937) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=404937) )
(EngineCore_DP0 pid=404937) .reqntid 512
(EngineCore_DP0 pid=404937) {
(EngineCore_DP0 pid=404937) 	.reg .pred 	%p<20>;
(EngineCore_DP0 pid=404937) 	.reg .b16 	%rs<37>;
(EngineCore_DP0 pid=404937) 	.reg .b32 	%r<118>;
(EngineCore_DP0 pid=404937) 	.reg .b64 	%rd<13>;
(EngineCore_DP0 pid=404937) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=404937) $L__func_begin0:
(EngineCore_DP0 pid=404937) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=404937) 
(EngineCore_DP0 pid=404937) // %bb.0:
(EngineCore_DP0 pid=404937) 	ld.param.b32 	%r20, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=404937) 	ld.param.b32 	%r19, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=404937) 	ld.param.b32 	%r18, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=404937) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=404937) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=404937) $L__tmp0:
(EngineCore_DP0 pid=404937) 	.loc	1 191 24                        // quant_slide_tuned_Llama3.2-3B.py:191:24
(EngineCore_DP0 pid=404937) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=404937) 	ld.param.b32 	%r22, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=404937) 	.loc	1 196 26                        // quant_slide_tuned_Llama3.2-3B.py:196:26
(EngineCore_DP0 pid=404937) 	mul.lo.s32 	%r23, %r22, %r1;
(EngineCore_DP0 pid=404937) 	.loc	1 196 20                        // quant_slide_tuned_Llama3.2-3B.py:196:20
(EngineCore_DP0 pid=404937) 	mad.wide.s32 	%rd1, %r23, 2, %rd4;
(EngineCore_DP0 pid=404937) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=404937) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=404937) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=404937) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=404937) 	setp.lt.s32 	%p1, %r19, 1;
(EngineCore_DP0 pid=404937) 	mov.b32 	%r116, 0f2B8CBCCC;
(EngineCore_DP0 pid=404937) 	setp.eq.b32 	%p19, %r2, 0;
(EngineCore_DP0 pid=404937) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=404937) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=404937) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=404937) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=404937) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=404937) 	shr.u32 	%r32, %r2, 3;
(EngineCore_DP0 pid=404937) 	and.b32 	%r33, %r32, 60;
(EngineCore_DP0 pid=404937) 	mov.b32 	%r34, global_smem;
(EngineCore_DP0 pid=404937) 	add.s32 	%r44, %r34, %r33;
(EngineCore_DP0 pid=404937) 	shl.b32 	%r35, %r2, 2;
(EngineCore_DP0 pid=404937) 	add.s32 	%r47, %r34, %r35;
(EngineCore_DP0 pid=404937) 	mov.b32 	%r40, 0;
(EngineCore_DP0 pid=404937) 	mov.b32 	%r114, 0f00000000;
(EngineCore_DP0 pid=404937) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=404937) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=404937) 	mov.b32 	%r115, %r40;
(EngineCore_DP0 pid=404937) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=404937) 	.loc	1 203 22                        // quant_slide_tuned_Llama3.2-3B.py:203:22
(EngineCore_DP0 pid=404937) 	add.s32 	%r50, %r4, %r115;
(EngineCore_DP0 pid=404937) 	setp.lt.s32 	%p2, %r50, %r18;
(EngineCore_DP0 pid=404937) 	.loc	1 204 29                        // quant_slide_tuned_Llama3.2-3B.py:204:29
(EngineCore_DP0 pid=404937) 	mad.wide.s32 	%rd6, %r50, 2, %rd1;
(EngineCore_DP0 pid=404937) 	.loc	1 204 21                        // quant_slide_tuned_Llama3.2-3B.py:204:21
(EngineCore_DP0 pid=404937) 	// begin inline asm
(EngineCore_DP0 pid=404937) 	mov.u32 %r36, %r40;
(EngineCore_DP0 pid=404937) 	mov.u32 %r37, %r40;
(EngineCore_DP0 pid=404937) 	mov.u32 %r38, %r40;
(EngineCore_DP0 pid=404937) 	mov.u32 %r39, %r40;
(EngineCore_DP0 pid=404937) 	@%p2 ld.global.v4.b32 { %r36, %r37, %r38, %r39 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=404937) 	// end inline asm
(EngineCore_DP0 pid=404937) 	mov.b32 	{%rs1, %rs2}, %r36;
(EngineCore_DP0 pid=404937) 	mov.b32 	{%rs3, %rs4}, %r37;
(EngineCore_DP0 pid=404937) 	mov.b32 	{%rs5, %rs6}, %r38;
(EngineCore_DP0 pid=404937) 	mov.b32 	{%rs7, %rs8}, %r39;
(EngineCore_DP0 pid=404937) 	.loc	1 205 50                        // quant_slide_tuned_Llama3.2-3B.py:205:50
(EngineCore_DP0 pid=404937) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=404937) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=404937) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=404937) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=404937) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=404937) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=404937) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=404937) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=404937) $L__tmp1:
(EngineCore_DP0 pid=404937) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=404937) 	bar.sync 	0;
(EngineCore_DP0 pid=404937) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=404937) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=404937) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=404937) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=404937) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=404937) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=404937) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=404937) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=404937) 	cvt.f32.bf16 	%r51, %rs23;
(EngineCore_DP0 pid=404937) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=404937) 	shfl.sync.bfly.b32 	%r52, %r51, 16, 31, -1;
(EngineCore_DP0 pid=404937) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=404937) 	max.f32 	%r53, %r51, %r52;
(EngineCore_DP0 pid=404937) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=404937) 	shfl.sync.bfly.b32 	%r54, %r53, 8, 31, -1;
(EngineCore_DP0 pid=404937) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=404937) 	max.f32 	%r55, %r53, %r54;
(EngineCore_DP0 pid=404937) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=404937) 	shfl.sync.bfly.b32 	%r56, %r55, 4, 31, -1;
(EngineCore_DP0 pid=404937) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=404937) 	max.f32 	%r57, %r55, %r56;
(EngineCore_DP0 pid=404937) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=404937) 	shfl.sync.bfly.b32 	%r58, %r57, 2, 31, -1;
(EngineCore_DP0 pid=404937) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=404937) 	max.f32 	%r59, %r57, %r58;
(EngineCore_DP0 pid=404937) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=404937) 	shfl.sync.bfly.b32 	%r60, %r59, 1, 31, -1;
(EngineCore_DP0 pid=404937) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=404937) 	max.f32 	%r45, %r59, %r60;
(EngineCore_DP0 pid=404937) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=404937) 	// begin inline asm
(EngineCore_DP0 pid=404937) 	@%p3 st.shared.b32 [ %r44 + 0 ], %r45;
(EngineCore_DP0 pid=404937) 	// end inline asm
(EngineCore_DP0 pid=404937) 	bar.sync 	0;
(EngineCore_DP0 pid=404937) 	// begin inline asm
(EngineCore_DP0 pid=404937) 	@%p4 ld.shared.b32 %r46, [ %r47 + 0 ];
(EngineCore_DP0 pid=404937) 	// end inline asm
(EngineCore_DP0 pid=404937) 	shfl.sync.bfly.b32 	%r61, %r46, 8, 31, -1;
(EngineCore_DP0 pid=404937) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=404937) 	max.f32 	%r62, %r46, %r61;
(EngineCore_DP0 pid=404937) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=404937) 	shfl.sync.bfly.b32 	%r63, %r62, 4, 31, -1;
(EngineCore_DP0 pid=404937) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=404937) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=404937) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=404937) 	shfl.sync.bfly.b32 	%r65, %r64, 2, 31, -1;
(EngineCore_DP0 pid=404937) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=404937) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=404937) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=404937) 	shfl.sync.bfly.b32 	%r67, %r66, 1, 31, -1;
(EngineCore_DP0 pid=404937) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=404937) 	max.f32 	%r49, %r66, %r67;
(EngineCore_DP0 pid=404937) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=404937) 	// begin inline asm
(EngineCore_DP0 pid=404937) 	@%p19 st.shared.b32 [ %r47 + 0 ], %r49;
(EngineCore_DP0 pid=404937) 	// end inline asm
(EngineCore_DP0 pid=404937) 	bar.sync 	0;
(EngineCore_DP0 pid=404937) 	ld.shared.b32 	%r68, [global_smem];
(EngineCore_DP0 pid=404937) $L__tmp2:
(EngineCore_DP0 pid=404937) 	.loc	1 205 36                        // quant_slide_tuned_Llama3.2-3B.py:205:36
(EngineCore_DP0 pid=404937) 	max.f32 	%r114, %r114, %r68;
(EngineCore_DP0 pid=404937) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=404937) 	add.s32 	%r115, %r115, 4096;
(EngineCore_DP0 pid=404937) 	setp.lt.s32 	%p6, %r115, %r19;
(EngineCore_DP0 pid=404937) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=404937) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=404937) 	.loc	1 207 32                        // quant_slide_tuned_Llama3.2-3B.py:207:32
(EngineCore_DP0 pid=404937) 	max.f32 	%r116, %r114, 0f2B8CBCCC;
(EngineCore_DP0 pid=404937) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=404937) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-3B.py:0:32
(EngineCore_DP0 pid=404937) 	mov.b32 	%r70, 0f43E00000;
(EngineCore_DP0 pid=404937) 	.loc	1 208 32                        // quant_slide_tuned_Llama3.2-3B.py:208:32
(EngineCore_DP0 pid=404937) 	div.full.f32 	%r71, %r116, %r70;
(EngineCore_DP0 pid=404937) 	.loc	1 208 41                        // quant_slide_tuned_Llama3.2-3B.py:208:41
(EngineCore_DP0 pid=404937) 	max.f32 	%r69, %r71, 0f36924925;
(EngineCore_DP0 pid=404937) 	.loc	1 210 25                        // quant_slide_tuned_Llama3.2-3B.py:210:25
(EngineCore_DP0 pid=404937) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=404937) 	.loc	1 210 30                        // quant_slide_tuned_Llama3.2-3B.py:210:30
(EngineCore_DP0 pid=404937) 	// begin inline asm
(EngineCore_DP0 pid=404937) 	@%p19 st.global.b32 [ %rd7 + 0 ], { %r69 };
(EngineCore_DP0 pid=404937) 	// end inline asm
(EngineCore_DP0 pid=404937) 	.loc	1 213 29                        // quant_slide_tuned_Llama3.2-3B.py:213:29
(EngineCore_DP0 pid=404937) 	shl.b32 	%r15, %r20, 2;
(EngineCore_DP0 pid=404937) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=404937) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=404937) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=404937) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=404937) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-3B.py:0:41
(EngineCore_DP0 pid=404937) 	ld.param.b32 	%r24, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=404937) 	shr.s32 	%r25, %r24, 31;
(EngineCore_DP0 pid=404937) 	shr.u32 	%r26, %r25, 30;
(EngineCore_DP0 pid=404937) 	add.s32 	%r27, %r24, %r26;
(EngineCore_DP0 pid=404937) 	shr.s32 	%r28, %r27, 2;
(EngineCore_DP0 pid=404937) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=404937) 	mul.lo.s32 	%r29, %r28, %r1;
(EngineCore_DP0 pid=404937) 	mad.wide.s32 	%rd2, %r29, 4, %rd5;
(EngineCore_DP0 pid=404937) 	div.full.f32 	%r14, %r70, %r116;
(EngineCore_DP0 pid=404937) 	mov.b32 	%r117, 0;
(EngineCore_DP0 pid=404937) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=404937)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=404937) 	.loc	1 217 30                        // quant_slide_tuned_Llama3.2-3B.py:217:30
(EngineCore_DP0 pid=404937) 	add.s32 	%r83, %r3, %r117;
(EngineCore_DP0 pid=404937) 	setp.lt.s32 	%p13, %r83, %r15;
(EngineCore_DP0 pid=404937) 	.loc	1 220 24                        // quant_slide_tuned_Llama3.2-3B.py:220:24
(EngineCore_DP0 pid=404937) 	shr.s32 	%r84, %r83, 31;
(EngineCore_DP0 pid=404937) 	shr.u32 	%r85, %r84, 30;
(EngineCore_DP0 pid=404937) 	add.s32 	%r86, %r83, %r85;
(EngineCore_DP0 pid=404937) 	shr.s32 	%r87, %r86, 2;
(EngineCore_DP0 pid=404937) 	.loc	1 221 23                        // quant_slide_tuned_Llama3.2-3B.py:221:23
(EngineCore_DP0 pid=404937) 	and.b32 	%r88, %r86, 2147483644;
(EngineCore_DP0 pid=404937) 	sub.s32 	%r89, %r83, %r88;
(EngineCore_DP0 pid=404937) 	.loc	1 222 30                        // quant_slide_tuned_Llama3.2-3B.py:222:30
(EngineCore_DP0 pid=404937) 	shl.b32 	%r90, %r89, 1;
(EngineCore_DP0 pid=404937) 	.loc	1 222 26                        // quant_slide_tuned_Llama3.2-3B.py:222:26
(EngineCore_DP0 pid=404937) 	mad.lo.s32 	%r91, %r87, 10, %r90;
(EngineCore_DP0 pid=404937) 	.loc	1 225 53                        // quant_slide_tuned_Llama3.2-3B.py:225:53
(EngineCore_DP0 pid=404937) 	setp.lt.s32 	%p14, %r91, %r18;
(EngineCore_DP0 pid=404937) 	.loc	1 225 37                        // quant_slide_tuned_Llama3.2-3B.py:225:37
(EngineCore_DP0 pid=404937) 	and.pred 	%p9, %p13, %p14;
(EngineCore_DP0 pid=404937) 	.loc	1 224 29                        // quant_slide_tuned_Llama3.2-3B.py:224:29
(EngineCore_DP0 pid=404937) 	mad.wide.s32 	%rd8, %r91, 2, %rd1;
(EngineCore_DP0 pid=404937) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=404937) 	.loc	1 224 21                        // quant_slide_tuned_Llama3.2-3B.py:224:21
(EngineCore_DP0 pid=404937) 	// begin inline asm
(EngineCore_DP0 pid=404937) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=404937) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=404937) 	// end inline asm
(EngineCore_DP0 pid=404937) 	.loc	1 225 79                        // quant_slide_tuned_Llama3.2-3B.py:225:79
(EngineCore_DP0 pid=404937) 	cvt.f32.bf16 	%r92, %rs24;
(EngineCore_DP0 pid=404937) 	.loc	1 227 48                        // quant_slide_tuned_Llama3.2-3B.py:227:48
(EngineCore_DP0 pid=404937) 	or.b32 	%r93, %r91, 1;
(EngineCore_DP0 pid=404937) 	.loc	1 227 53                        // quant_slide_tuned_Llama3.2-3B.py:227:53
(EngineCore_DP0 pid=404937) 	setp.lt.s32 	%p15, %r93, %r18;
(EngineCore_DP0 pid=404937) 	.loc	1 227 37                        // quant_slide_tuned_Llama3.2-3B.py:227:37
(EngineCore_DP0 pid=404937) 	and.pred 	%p10, %p13, %p15;
(EngineCore_DP0 pid=404937) 	.loc	1 226 39                        // quant_slide_tuned_Llama3.2-3B.py:226:39
(EngineCore_DP0 pid=404937) 	add.s64 	%rd9, %rd8, 2;
(EngineCore_DP0 pid=404937) 	.loc	1 226 21                        // quant_slide_tuned_Llama3.2-3B.py:226:21
(EngineCore_DP0 pid=404937) 	// begin inline asm
(EngineCore_DP0 pid=404937) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=404937) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=404937) 	// end inline asm
(EngineCore_DP0 pid=404937) 	.loc	1 227 79                        // quant_slide_tuned_Llama3.2-3B.py:227:79
(EngineCore_DP0 pid=404937) 	cvt.f32.bf16 	%r94, %rs26;
(EngineCore_DP0 pid=404937) 	.loc	1 229 48                        // quant_slide_tuned_Llama3.2-3B.py:229:48
(EngineCore_DP0 pid=404937) 	add.s32 	%r95, %r91, 2;
(EngineCore_DP0 pid=404937) 	.loc	1 229 53                        // quant_slide_tuned_Llama3.2-3B.py:229:53
(EngineCore_DP0 pid=404937) 	setp.lt.s32 	%p16, %r95, %r18;
(EngineCore_DP0 pid=404937) 	.loc	1 229 37                        // quant_slide_tuned_Llama3.2-3B.py:229:37
(EngineCore_DP0 pid=404937) 	and.pred 	%p11, %p13, %p16;
(EngineCore_DP0 pid=404937) 	.loc	1 228 39                        // quant_slide_tuned_Llama3.2-3B.py:228:39
(EngineCore_DP0 pid=404937) 	add.s64 	%rd10, %rd8, 4;
(EngineCore_DP0 pid=404937) 	.loc	1 228 21                        // quant_slide_tuned_Llama3.2-3B.py:228:21
(EngineCore_DP0 pid=404937) 	// begin inline asm
(EngineCore_DP0 pid=404937) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=404937) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=404937) 	// end inline asm
(EngineCore_DP0 pid=404937) 	.loc	1 229 79                        // quant_slide_tuned_Llama3.2-3B.py:229:79
(EngineCore_DP0 pid=404937) 	cvt.f32.bf16 	%r96, %rs28;
(EngineCore_DP0 pid=404937) 	.loc	1 231 48                        // quant_slide_tuned_Llama3.2-3B.py:231:48
(EngineCore_DP0 pid=404937) 	add.s32 	%r97, %r91, 3;
(EngineCore_DP0 pid=404937) 	.loc	1 231 53                        // quant_slide_tuned_Llama3.2-3B.py:231:53
(EngineCore_DP0 pid=404937) 	setp.lt.s32 	%p17, %r97, %r18;
(EngineCore_DP0 pid=404937) 	.loc	1 231 37                        // quant_slide_tuned_Llama3.2-3B.py:231:37
(EngineCore_DP0 pid=404937) 	and.pred 	%p12, %p13, %p17;
(EngineCore_DP0 pid=404937) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-3B.py:230:39
(EngineCore_DP0 pid=404937) 	add.s64 	%rd11, %rd8, 6;
(EngineCore_DP0 pid=404937) 	.loc	1 230 21                        // quant_slide_tuned_Llama3.2-3B.py:230:21
(EngineCore_DP0 pid=404937) 	// begin inline asm
(EngineCore_DP0 pid=404937) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=404937) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=404937) 	// end inline asm
(EngineCore_DP0 pid=404937) 	.loc	1 231 79                        // quant_slide_tuned_Llama3.2-3B.py:231:79
(EngineCore_DP0 pid=404937) 	cvt.f32.bf16 	%r98, %rs30;
(EngineCore_DP0 pid=404937) 	.loc	1 233 27                        // quant_slide_tuned_Llama3.2-3B.py:233:27
(EngineCore_DP0 pid=404937) 	mul.f32 	%r99, %r14, %r92;
(EngineCore_DP0 pid=404937) 	mov.b32 	%r100, 0f43E00000;
(EngineCore_DP0 pid=404937) 	.loc	1 233 48                        // quant_slide_tuned_Llama3.2-3B.py:233:48
(EngineCore_DP0 pid=404937) 	min.xorsign.abs.f32 	%r73, %r99, %r100;
(EngineCore_DP0 pid=404937) 	.loc	1 233 60                        // quant_slide_tuned_Llama3.2-3B.py:233:60
(EngineCore_DP0 pid=404937) 	// begin inline asm
(EngineCore_DP0 pid=404937) 	cvt.rn.satfinite.e4m3x2.f32  %rs32, %r74, %r73; 
(EngineCore_DP0 pid=404937) 
(EngineCore_DP0 pid=404937) 	// end inline asm
(EngineCore_DP0 pid=404937) 	.loc	1 234 27                        // quant_slide_tuned_Llama3.2-3B.py:234:27
(EngineCore_DP0 pid=404937) 	mul.f32 	%r101, %r14, %r94;
(EngineCore_DP0 pid=404937) 	.loc	1 234 48                        // quant_slide_tuned_Llama3.2-3B.py:234:48
(EngineCore_DP0 pid=404937) 	min.xorsign.abs.f32 	%r75, %r101, %r100;
(EngineCore_DP0 pid=404937) 	.loc	1 234 60                        // quant_slide_tuned_Llama3.2-3B.py:234:60
(EngineCore_DP0 pid=404937) 	// begin inline asm
(EngineCore_DP0 pid=404937) 	cvt.rn.satfinite.e4m3x2.f32  %rs33, %r76, %r75; 
(EngineCore_DP0 pid=404937) 
(EngineCore_DP0 pid=404937) 	// end inline asm
(EngineCore_DP0 pid=404937) 	.loc	1 235 27                        // quant_slide_tuned_Llama3.2-3B.py:235:27
(EngineCore_DP0 pid=404937) 	mul.f32 	%r102, %r14, %r96;
(EngineCore_DP0 pid=404937) 	.loc	1 235 48                        // quant_slide_tuned_Llama3.2-3B.py:235:48
(EngineCore_DP0 pid=404937) 	min.xorsign.abs.f32 	%r77, %r102, %r100;
(EngineCore_DP0 pid=404937) 	.loc	1 235 60                        // quant_slide_tuned_Llama3.2-3B.py:235:60
(EngineCore_DP0 pid=404937) 	// begin inline asm
(EngineCore_DP0 pid=404937) 	cvt.rn.satfinite.e4m3x2.f32  %rs34, %r78, %r77; 
(EngineCore_DP0 pid=404937) 
(EngineCore_DP0 pid=404937) 	// end inline asm
(EngineCore_DP0 pid=404937) 	.loc	1 236 27                        // quant_slide_tuned_Llama3.2-3B.py:236:27
(EngineCore_DP0 pid=404937) 	mul.f32 	%r103, %r14, %r98;
(EngineCore_DP0 pid=404937) 	.loc	1 236 48                        // quant_slide_tuned_Llama3.2-3B.py:236:48
(EngineCore_DP0 pid=404937) 	min.xorsign.abs.f32 	%r79, %r103, %r100;
(EngineCore_DP0 pid=404937) 	.loc	1 236 60                        // quant_slide_tuned_Llama3.2-3B.py:236:60
(EngineCore_DP0 pid=404937) 	// begin inline asm
(EngineCore_DP0 pid=404937) 	cvt.rn.satfinite.e4m3x2.f32  %rs35, %r80, %r79; 
(EngineCore_DP0 pid=404937) 
(EngineCore_DP0 pid=404937) 	// end inline asm
(EngineCore_DP0 pid=404937) 	.loc	1 238 45                        // quant_slide_tuned_Llama3.2-3B.py:238:45
(EngineCore_DP0 pid=404937) 	cvt.u32.u16 	%r104, %rs32;
(EngineCore_DP0 pid=404937) 	and.b32 	%r105, %r104, 255;
(EngineCore_DP0 pid=404937) 	.loc	1 240 45                        // quant_slide_tuned_Llama3.2-3B.py:240:45
(EngineCore_DP0 pid=404937) 	cvt.u32.u16 	%r106, %rs34;
(EngineCore_DP0 pid=404937) 	and.b32 	%r107, %r106, 255;
(EngineCore_DP0 pid=404937) 	.loc	1 241 45                        // quant_slide_tuned_Llama3.2-3B.py:241:45
(EngineCore_DP0 pid=404937) 	cvt.u32.u16 	%r108, %rs35;
(EngineCore_DP0 pid=404937) 	.loc	1 243 30                        // quant_slide_tuned_Llama3.2-3B.py:243:30
(EngineCore_DP0 pid=404937) 	and.b16 	%rs36, %rs33, 255;
(EngineCore_DP0 pid=404937) 	mul.wide.u16 	%r109, %rs36, 256;
(EngineCore_DP0 pid=404937) 	.loc	1 243 24                        // quant_slide_tuned_Llama3.2-3B.py:243:24
(EngineCore_DP0 pid=404937) 	or.b32 	%r110, %r109, %r105;
(EngineCore_DP0 pid=404937) 	.loc	1 243 42                        // quant_slide_tuned_Llama3.2-3B.py:243:42
(EngineCore_DP0 pid=404937) 	shl.b32 	%r111, %r107, 16;
(EngineCore_DP0 pid=404937) 	.loc	1 243 36                        // quant_slide_tuned_Llama3.2-3B.py:243:36
(EngineCore_DP0 pid=404937) 	or.b32 	%r112, %r110, %r111;
(EngineCore_DP0 pid=404937) 	.loc	1 243 55                        // quant_slide_tuned_Llama3.2-3B.py:243:55
(EngineCore_DP0 pid=404937) 	shl.b32 	%r113, %r108, 24;
(EngineCore_DP0 pid=404937) 	.loc	1 243 49                        // quant_slide_tuned_Llama3.2-3B.py:243:49
(EngineCore_DP0 pid=404937) 	or.b32 	%r81, %r112, %r113;
(EngineCore_DP0 pid=404937) 	.loc	1 244 29                        // quant_slide_tuned_Llama3.2-3B.py:244:29
(EngineCore_DP0 pid=404937) 	mad.wide.s32 	%rd12, %r83, 4, %rd2;
(EngineCore_DP0 pid=404937) 	.loc	1 244 39                        // quant_slide_tuned_Llama3.2-3B.py:244:39
(EngineCore_DP0 pid=404937) 	// begin inline asm
(EngineCore_DP0 pid=404937) 	@%p13 st.global.b32 [ %rd12 + 0 ], { %r81 };
(EngineCore_DP0 pid=404937) 	// end inline asm
(EngineCore_DP0 pid=404937) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=404937) 	add.s32 	%r117, %r117, 512;
(EngineCore_DP0 pid=404937) 	setp.lt.s32 	%p18, %r117, %r15;
(EngineCore_DP0 pid=404937) 	@%p18 bra 	$L__BB0_6;
(EngineCore_DP0 pid=404937) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=404937) 	.loc	1 215 4                         // quant_slide_tuned_Llama3.2-3B.py:215:4
(EngineCore_DP0 pid=404937) 	ret;
(EngineCore_DP0 pid=404937) $L__tmp3:
(EngineCore_DP0 pid=404937) $L__func_end0:
(EngineCore_DP0 pid=404937)                                         // -- End function
(EngineCore_DP0 pid=404937) }
(EngineCore_DP0 pid=404937) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py"
(EngineCore_DP0 pid=404937) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=404937) 	.section	.debug_abbrev
(EngineCore_DP0 pid=404937) 	{
(EngineCore_DP0 pid=404937) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=404937) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=404937) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=404937) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=404937) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=404937) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=404937) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=404937) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=404937) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=404937) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=404937) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=404937) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=404937) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=404937) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=404937) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=404937) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=404937) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=404937) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=404937) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=404937) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=404937) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=404937) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=404937) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=404937) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=404937) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=404937) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=404937) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=404937) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=404937) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=404937) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=404937) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=404937) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=404937) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=404937) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=404937) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=404937) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=404937) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=404937) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=404937) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=404937) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=404937) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=404937) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=404937) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=404937) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=404937) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=404937) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=404937) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=404937) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=404937) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=404937) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=404937) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=404937) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=404937) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=404937) 	}
(EngineCore_DP0 pid=404937) 	.section	.debug_info
(EngineCore_DP0 pid=404937) 	{
(EngineCore_DP0 pid=404937) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=404937) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=404937) .b8 0
(EngineCore_DP0 pid=404937) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=404937) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=404937) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=404937) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=404937) .b8 114
(EngineCore_DP0 pid=404937) .b8 105
(EngineCore_DP0 pid=404937) .b8 116
(EngineCore_DP0 pid=404937) .b8 111
(EngineCore_DP0 pid=404937) .b8 110
(EngineCore_DP0 pid=404937) .b8 0
(EngineCore_DP0 pid=404937) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=404937) .b8 0
(EngineCore_DP0 pid=404937) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=404937) .b8 117
(EngineCore_DP0 pid=404937) .b8 97
(EngineCore_DP0 pid=404937) .b8 110
(EngineCore_DP0 pid=404937) .b8 116
(EngineCore_DP0 pid=404937) .b8 95
(EngineCore_DP0 pid=404937) .b8 115
(EngineCore_DP0 pid=404937) .b8 108
(EngineCore_DP0 pid=404937) .b8 105
(EngineCore_DP0 pid=404937) .b8 100
(EngineCore_DP0 pid=404937) .b8 101
(EngineCore_DP0 pid=404937) .b8 95
(EngineCore_DP0 pid=404937) .b8 116
(EngineCore_DP0 pid=404937) .b8 117
(EngineCore_DP0 pid=404937) .b8 110
(EngineCore_DP0 pid=404937) .b8 101
(EngineCore_DP0 pid=404937) .b8 100
(EngineCore_DP0 pid=404937) .b8 95
(EngineCore_DP0 pid=404937) .b8 76
(EngineCore_DP0 pid=404937) .b8 108
(EngineCore_DP0 pid=404937) .b8 97
(EngineCore_DP0 pid=404937) .b8 109
(EngineCore_DP0 pid=404937) .b8 97
(EngineCore_DP0 pid=404937) .b8 51
(EngineCore_DP0 pid=404937) .b8 46
(EngineCore_DP0 pid=404937) .b8 50
(EngineCore_DP0 pid=404937) .b8 45
(EngineCore_DP0 pid=404937) .b8 51
(EngineCore_DP0 pid=404937) .b8 66
(EngineCore_DP0 pid=404937) .b8 46
(EngineCore_DP0 pid=404937) .b8 112
(EngineCore_DP0 pid=404937) .b8 121
(EngineCore_DP0 pid=404937) .b8 0
(EngineCore_DP0 pid=404937) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=404937) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=404937) .b8 114
(EngineCore_DP0 pid=404937) .b8 111
(EngineCore_DP0 pid=404937) .b8 111
(EngineCore_DP0 pid=404937) .b8 116
(EngineCore_DP0 pid=404937) .b8 47
(EngineCore_DP0 pid=404937) .b8 118
(EngineCore_DP0 pid=404937) .b8 108
(EngineCore_DP0 pid=404937) .b8 108
(EngineCore_DP0 pid=404937) .b8 109
(EngineCore_DP0 pid=404937) .b8 98
(EngineCore_DP0 pid=404937) .b8 101
(EngineCore_DP0 pid=404937) .b8 110
(EngineCore_DP0 pid=404937) .b8 99
(EngineCore_DP0 pid=404937) .b8 104
(EngineCore_DP0 pid=404937) .b8 47
(EngineCore_DP0 pid=404937) .b8 115
(EngineCore_DP0 pid=404937) .b8 108
(EngineCore_DP0 pid=404937) .b8 105
(EngineCore_DP0 pid=404937) .b8 100
(EngineCore_DP0 pid=404937) .b8 101
(EngineCore_DP0 pid=404937) .b8 115
(EngineCore_DP0 pid=404937) .b8 112
(EngineCore_DP0 pid=404937) .b8 97
(EngineCore_DP0 pid=404937) .b8 114
(EngineCore_DP0 pid=404937) .b8 115
(EngineCore_DP0 pid=404937) .b8 101
(EngineCore_DP0 pid=404937) .b8 47
(EngineCore_DP0 pid=404937) .b8 99
(EngineCore_DP0 pid=404937) .b8 115
(EngineCore_DP0 pid=404937) .b8 114
(EngineCore_DP0 pid=404937) .b8 99
(EngineCore_DP0 pid=404937) .b8 47
(EngineCore_DP0 pid=404937) .b8 102
(EngineCore_DP0 pid=404937) .b8 117
(EngineCore_DP0 pid=404937) .b8 115
(EngineCore_DP0 pid=404937) .b8 101
(EngineCore_DP0 pid=404937) .b8 100
(EngineCore_DP0 pid=404937) .b8 95
(EngineCore_DP0 pid=404937) .b8 113
(EngineCore_DP0 pid=404937) .b8 117
(EngineCore_DP0 pid=404937) .b8 97
(EngineCore_DP0 pid=404937) .b8 110
(EngineCore_DP0 pid=404937) .b8 116
(EngineCore_DP0 pid=404937) .b8 95
(EngineCore_DP0 pid=404937) .b8 115
(EngineCore_DP0 pid=404937) .b8 108
(EngineCore_DP0 pid=404937) .b8 105
(EngineCore_DP0 pid=404937) .b8 100
(EngineCore_DP0 pid=404937) .b8 101
(EngineCore_DP0 pid=404937) .b8 95
(EngineCore_DP0 pid=404937) .b8 116
(EngineCore_DP0 pid=404937) .b8 114
(EngineCore_DP0 pid=404937) .b8 105
(EngineCore_DP0 pid=404937) .b8 116
(EngineCore_DP0 pid=404937) .b8 111
(EngineCore_DP0 pid=404937) .b8 110
(EngineCore_DP0 pid=404937) .b8 47
(EngineCore_DP0 pid=404937) .b8 98
(EngineCore_DP0 pid=404937) .b8 117
(EngineCore_DP0 pid=404937) .b8 105
(EngineCore_DP0 pid=404937) .b8 108
(EngineCore_DP0 pid=404937) .b8 100
(EngineCore_DP0 pid=404937) .b8 47
(EngineCore_DP0 pid=404937) .b8 71
(EngineCore_DP0 pid=404937) .b8 66
(EngineCore_DP0 pid=404937) .b8 49
(EngineCore_DP0 pid=404937) .b8 48
(EngineCore_DP0 pid=404937) .b8 95
(EngineCore_DP0 pid=404937) .b8 99
(EngineCore_DP0 pid=404937) .b8 99
(EngineCore_DP0 pid=404937) .b8 49
(EngineCore_DP0 pid=404937) .b8 50
(EngineCore_DP0 pid=404937) .b8 49
(EngineCore_DP0 pid=404937) .b8 95
(EngineCore_DP0 pid=404937) .b8 112
(EngineCore_DP0 pid=404937) .b8 121
(EngineCore_DP0 pid=404937) .b8 51
(EngineCore_DP0 pid=404937) .b8 49
(EngineCore_DP0 pid=404937) .b8 50
(EngineCore_DP0 pid=404937) .b8 95
(EngineCore_DP0 pid=404937) .b8 99
(EngineCore_DP0 pid=404937) .b8 117
(EngineCore_DP0 pid=404937) .b8 49
(EngineCore_DP0 pid=404937) .b8 50
(EngineCore_DP0 pid=404937) .b8 57
(EngineCore_DP0 pid=404937) .b8 95
(EngineCore_DP0 pid=404937) .b8 97
(EngineCore_DP0 pid=404937) .b8 97
(EngineCore_DP0 pid=404937) .b8 114
(EngineCore_DP0 pid=404937) .b8 99
(EngineCore_DP0 pid=404937) .b8 104
(EngineCore_DP0 pid=404937) .b8 54
(EngineCore_DP0 pid=404937) .b8 52
(EngineCore_DP0 pid=404937) .b8 0
(EngineCore_DP0 pid=404937) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=404937) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=404937) .b8 113
(EngineCore_DP0 pid=404937) .b8 117
(EngineCore_DP0 pid=404937) .b8 97
(EngineCore_DP0 pid=404937) .b8 110
(EngineCore_DP0 pid=404937) .b8 116
(EngineCore_DP0 pid=404937) .b8 95
(EngineCore_DP0 pid=404937) .b8 115
(EngineCore_DP0 pid=404937) .b8 108
(EngineCore_DP0 pid=404937) .b8 105
(EngineCore_DP0 pid=404937) .b8 100
(EngineCore_DP0 pid=404937) .b8 101
(EngineCore_DP0 pid=404937) .b8 95
(EngineCore_DP0 pid=404937) .b8 102
(EngineCore_DP0 pid=404937) .b8 112
(EngineCore_DP0 pid=404937) .b8 56
(EngineCore_DP0 pid=404937) .b8 95
(EngineCore_DP0 pid=404937) .b8 107
(EngineCore_DP0 pid=404937) .b8 101
(EngineCore_DP0 pid=404937) .b8 114
(EngineCore_DP0 pid=404937) .b8 110
(EngineCore_DP0 pid=404937) .b8 101
(EngineCore_DP0 pid=404937) .b8 108
(EngineCore_DP0 pid=404937) .b8 0
(EngineCore_DP0 pid=404937) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=404937) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=404937) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=404937) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=404937) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=404937) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=404937) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=404937) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=404937) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=404937) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=404937) .b8 205                                 // DW_AT_call_line
(EngineCore_DP0 pid=404937) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=404937) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=404937) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=404937) 	}
(EngineCore_DP0 pid=404937) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=404937) 
(EngineCore_DP0 pid=404937) ================================================================
(EngineCore_DP0 pid=404937) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=404937) 
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpr22_ug4k.ptx', '-o', '/tmp/tmpr22_ug4k.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866] 
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866] 
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866] 
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpr22_ug4k.ptx -o /tmp/tmpr22_ug4k.ptx.o
(EngineCore_DP0 pid=404937) ERROR 01-25 20:16:05 [core.py:866] 

STDERR:
[2026-01-25 20:15:34] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:15:34] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:15:34] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:15:34] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:15:34] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:15:34] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:15:34] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:15:34] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:15:34] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:15:34] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:15:34] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:15:34] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:15:34] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:15:34] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:15:37] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:15:37] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:15:37] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:15:37] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:15:37] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:15:37] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:15:37] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:15:37] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:15:37] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:15:37] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:15:37] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:15:37] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:15:37] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:15:37] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=404937) [2026-01-25 20:15:38] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=404937) [2026-01-25 20:15:38] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=404937) [2026-01-25 20:15:38] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=404937) [2026-01-25 20:15:38] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=404937) [2026-01-25 20:15:38] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=404937) [2026-01-25 20:15:38] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=404937) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=404937) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:24<00:00, 24.97s/it]
(EngineCore_DP0 pid=404937) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:24<00:00, 24.97s/it]
(EngineCore_DP0 pid=404937) 
(EngineCore_DP0 pid=404937) [2026-01-25 20:16:04] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4928] -> 1D uint8
(EngineCore_DP0 pid=404937) [2026-01-25 20:16:04] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15810560 bytes
(EngineCore_DP0 pid=404937) [2026-01-25 20:16:04] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4928] -> 1D uint8
(EngineCore_DP0 pid=404937) [2026-01-25 20:16:04] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9486336 bytes
(EngineCore_DP0 pid=404937) [2026-01-25 20:16:04] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4928] -> 1D uint8
(EngineCore_DP0 pid=404937) [2026-01-25 20:16:04] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 50593792 bytes
(EngineCore_DP0 pid=404937) [2026-01-25 20:16:04] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 13120] -> 1D uint8
(EngineCore_DP0 pid=404937) [2026-01-25 20:16:04] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 25214976 bytes
(EngineCore_DP0 pid=404937) Process EngineCore_DP0:
(EngineCore_DP0 pid=404937) Traceback (most recent call last):
(EngineCore_DP0 pid=404937)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=404937)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=404937)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=404937)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=404937) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpr22_ug4k.ptx', '-o', '/tmp/tmpr22_ug4k.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=404937) 
(EngineCore_DP0 pid=404937) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=404937) 
(EngineCore_DP0 pid=404937) Traceback (most recent call last):
(EngineCore_DP0 pid=404937)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=404937)     self.run()
(EngineCore_DP0 pid=404937)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=404937)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=404937)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=404937)     raise e
(EngineCore_DP0 pid=404937)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=404937)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=404937)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=404937)     super().__init__(
(EngineCore_DP0 pid=404937)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=404937)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=404937)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=404937)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=404937)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=404937)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=404937)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=404937)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=404937)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=404937)     return func(*args, **kwargs)
(EngineCore_DP0 pid=404937)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=404937)     return func(*args, **kwargs)
(EngineCore_DP0 pid=404937)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=404937)     self.model_runner.profile_run()
(EngineCore_DP0 pid=404937)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=404937)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=404937)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=404937)     return func(*args, **kwargs)
(EngineCore_DP0 pid=404937)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=404937)     outputs = self.model(
(EngineCore_DP0 pid=404937)               ^^^^^^^^^^^
(EngineCore_DP0 pid=404937)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=404937)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=404937)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=404937)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=404937)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=404937)     model_output = self.model(
(EngineCore_DP0 pid=404937)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=404937)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=404937)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=404937)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=404937)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=404937)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=404937)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=404937)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=404937)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=404937)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=404937)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=404937)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=404937)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=404937)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=404937)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=404937)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=404937)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=404937)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=404937)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=404937)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=404937)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=404937)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=404937)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=404937)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=404937)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=404937)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=404937)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=404937)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=404937)     return self._linear_fn(
(EngineCore_DP0 pid=404937)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=404937)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=404937)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=404937)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=404937)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=404937)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=404937)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=404937)     return fn(input, L)
(EngineCore_DP0 pid=404937)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=404937)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=404937)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=404937)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=404937)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=404937)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=404937)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=404937)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=404937)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=404937)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=404937)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=404937)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=404937)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=404937)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=404937)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=404937)     raise PTXASError(error)
(EngineCore_DP0 pid=404937) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=404937) `ptxas` stderr:
(EngineCore_DP0 pid=404937) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=404937) 
(EngineCore_DP0 pid=404937) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpr22_ug4k.ptx -o /tmp/tmpr22_ug4k.ptx.o
(EngineCore_DP0 pid=404937) 
[rank0]:[W125 20:16:06.269655780 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=1024

========== M=2048 ==========
Time: 2026-01-25 20:16:07
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-3B-FP8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:16:11 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 20:16:12 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=405659) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=405659) 
(EngineCore_DP0 pid=405659) 
(EngineCore_DP0 pid=405659) ================================================================
(EngineCore_DP0 pid=405659) Internal Triton PTX codegen error
(EngineCore_DP0 pid=405659) `ptxas` stderr:
(EngineCore_DP0 pid=405659) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=405659) 
(EngineCore_DP0 pid=405659) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpdldsdswe.ptx -o /tmp/tmpdldsdswe.ptx.o
(EngineCore_DP0 pid=405659) 
(EngineCore_DP0 pid=405659) 
(EngineCore_DP0 pid=405659) //
(EngineCore_DP0 pid=405659) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=405659) //
(EngineCore_DP0 pid=405659) 
(EngineCore_DP0 pid=405659) .version 8.7
(EngineCore_DP0 pid=405659) .target sm_121a
(EngineCore_DP0 pid=405659) .address_size 64
(EngineCore_DP0 pid=405659) 
(EngineCore_DP0 pid=405659) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=405659) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=405659)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=405659) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=405659) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=405659) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=405659) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=405659) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=405659) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=405659) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=405659) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=405659) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=405659) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=405659) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=405659) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=405659) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=405659) )
(EngineCore_DP0 pid=405659) .reqntid 512
(EngineCore_DP0 pid=405659) {
(EngineCore_DP0 pid=405659) 	.reg .pred 	%p<20>;
(EngineCore_DP0 pid=405659) 	.reg .b16 	%rs<37>;
(EngineCore_DP0 pid=405659) 	.reg .b32 	%r<118>;
(EngineCore_DP0 pid=405659) 	.reg .b64 	%rd<13>;
(EngineCore_DP0 pid=405659) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=405659) $L__func_begin0:
(EngineCore_DP0 pid=405659) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=405659) 
(EngineCore_DP0 pid=405659) // %bb.0:
(EngineCore_DP0 pid=405659) 	ld.param.b32 	%r20, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=405659) 	ld.param.b32 	%r19, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=405659) 	ld.param.b32 	%r18, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=405659) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=405659) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=405659) $L__tmp0:
(EngineCore_DP0 pid=405659) 	.loc	1 191 24                        // quant_slide_tuned_Llama3.2-3B.py:191:24
(EngineCore_DP0 pid=405659) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=405659) 	ld.param.b32 	%r22, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=405659) 	.loc	1 196 26                        // quant_slide_tuned_Llama3.2-3B.py:196:26
(EngineCore_DP0 pid=405659) 	mul.lo.s32 	%r23, %r22, %r1;
(EngineCore_DP0 pid=405659) 	.loc	1 196 20                        // quant_slide_tuned_Llama3.2-3B.py:196:20
(EngineCore_DP0 pid=405659) 	mad.wide.s32 	%rd1, %r23, 2, %rd4;
(EngineCore_DP0 pid=405659) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=405659) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=405659) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=405659) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=405659) 	setp.lt.s32 	%p1, %r19, 1;
(EngineCore_DP0 pid=405659) 	mov.b32 	%r116, 0f2B8CBCCC;
(EngineCore_DP0 pid=405659) 	setp.eq.b32 	%p19, %r2, 0;
(EngineCore_DP0 pid=405659) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=405659) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=405659) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=405659) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=405659) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=405659) 	shr.u32 	%r32, %r2, 3;
(EngineCore_DP0 pid=405659) 	and.b32 	%r33, %r32, 60;
(EngineCore_DP0 pid=405659) 	mov.b32 	%r34, global_smem;
(EngineCore_DP0 pid=405659) 	add.s32 	%r44, %r34, %r33;
(EngineCore_DP0 pid=405659) 	shl.b32 	%r35, %r2, 2;
(EngineCore_DP0 pid=405659) 	add.s32 	%r47, %r34, %r35;
(EngineCore_DP0 pid=405659) 	mov.b32 	%r40, 0;
(EngineCore_DP0 pid=405659) 	mov.b32 	%r114, 0f00000000;
(EngineCore_DP0 pid=405659) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=405659) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=405659) 	mov.b32 	%r115, %r40;
(EngineCore_DP0 pid=405659) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=405659) 	.loc	1 203 22                        // quant_slide_tuned_Llama3.2-3B.py:203:22
(EngineCore_DP0 pid=405659) 	add.s32 	%r50, %r4, %r115;
(EngineCore_DP0 pid=405659) 	setp.lt.s32 	%p2, %r50, %r18;
(EngineCore_DP0 pid=405659) 	.loc	1 204 29                        // quant_slide_tuned_Llama3.2-3B.py:204:29
(EngineCore_DP0 pid=405659) 	mad.wide.s32 	%rd6, %r50, 2, %rd1;
(EngineCore_DP0 pid=405659) 	.loc	1 204 21                        // quant_slide_tuned_Llama3.2-3B.py:204:21
(EngineCore_DP0 pid=405659) 	// begin inline asm
(EngineCore_DP0 pid=405659) 	mov.u32 %r36, %r40;
(EngineCore_DP0 pid=405659) 	mov.u32 %r37, %r40;
(EngineCore_DP0 pid=405659) 	mov.u32 %r38, %r40;
(EngineCore_DP0 pid=405659) 	mov.u32 %r39, %r40;
(EngineCore_DP0 pid=405659) 	@%p2 ld.global.v4.b32 { %r36, %r37, %r38, %r39 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=405659) 	// end inline asm
(EngineCore_DP0 pid=405659) 	mov.b32 	{%rs1, %rs2}, %r36;
(EngineCore_DP0 pid=405659) 	mov.b32 	{%rs3, %rs4}, %r37;
(EngineCore_DP0 pid=405659) 	mov.b32 	{%rs5, %rs6}, %r38;
(EngineCore_DP0 pid=405659) 	mov.b32 	{%rs7, %rs8}, %r39;
(EngineCore_DP0 pid=405659) 	.loc	1 205 50                        // quant_slide_tuned_Llama3.2-3B.py:205:50
(EngineCore_DP0 pid=405659) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=405659) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=405659) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=405659) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=405659) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=405659) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=405659) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=405659) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=405659) $L__tmp1:
(EngineCore_DP0 pid=405659) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=405659) 	bar.sync 	0;
(EngineCore_DP0 pid=405659) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=405659) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=405659) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=405659) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=405659) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=405659) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=405659) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=405659) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=405659) 	cvt.f32.bf16 	%r51, %rs23;
(EngineCore_DP0 pid=405659) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=405659) 	shfl.sync.bfly.b32 	%r52, %r51, 16, 31, -1;
(EngineCore_DP0 pid=405659) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=405659) 	max.f32 	%r53, %r51, %r52;
(EngineCore_DP0 pid=405659) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=405659) 	shfl.sync.bfly.b32 	%r54, %r53, 8, 31, -1;
(EngineCore_DP0 pid=405659) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=405659) 	max.f32 	%r55, %r53, %r54;
(EngineCore_DP0 pid=405659) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=405659) 	shfl.sync.bfly.b32 	%r56, %r55, 4, 31, -1;
(EngineCore_DP0 pid=405659) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=405659) 	max.f32 	%r57, %r55, %r56;
(EngineCore_DP0 pid=405659) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=405659) 	shfl.sync.bfly.b32 	%r58, %r57, 2, 31, -1;
(EngineCore_DP0 pid=405659) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=405659) 	max.f32 	%r59, %r57, %r58;
(EngineCore_DP0 pid=405659) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=405659) 	shfl.sync.bfly.b32 	%r60, %r59, 1, 31, -1;
(EngineCore_DP0 pid=405659) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=405659) 	max.f32 	%r45, %r59, %r60;
(EngineCore_DP0 pid=405659) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=405659) 	// begin inline asm
(EngineCore_DP0 pid=405659) 	@%p3 st.shared.b32 [ %r44 + 0 ], %r45;
(EngineCore_DP0 pid=405659) 	// end inline asm
(EngineCore_DP0 pid=405659) 	bar.sync 	0;
(EngineCore_DP0 pid=405659) 	// begin inline asm
(EngineCore_DP0 pid=405659) 	@%p4 ld.shared.b32 %r46, [ %r47 + 0 ];
(EngineCore_DP0 pid=405659) 	// end inline asm
(EngineCore_DP0 pid=405659) 	shfl.sync.bfly.b32 	%r61, %r46, 8, 31, -1;
(EngineCore_DP0 pid=405659) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=405659) 	max.f32 	%r62, %r46, %r61;
(EngineCore_DP0 pid=405659) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=405659) 	shfl.sync.bfly.b32 	%r63, %r62, 4, 31, -1;
(EngineCore_DP0 pid=405659) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=405659) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=405659) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=405659) 	shfl.sync.bfly.b32 	%r65, %r64, 2, 31, -1;
(EngineCore_DP0 pid=405659) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=405659) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=405659) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=405659) 	shfl.sync.bfly.b32 	%r67, %r66, 1, 31, -1;
(EngineCore_DP0 pid=405659) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=405659) 	max.f32 	%r49, %r66, %r67;
(EngineCore_DP0 pid=405659) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=405659) 	// begin inline asm
(EngineCore_DP0 pid=405659) 	@%p19 st.shared.b32 [ %r47 + 0 ], %r49;
(EngineCore_DP0 pid=405659) 	// end inline asm
(EngineCore_DP0 pid=405659) 	bar.sync 	0;
(EngineCore_DP0 pid=405659) 	ld.shared.b32 	%r68, [global_smem];
(EngineCore_DP0 pid=405659) $L__tmp2:
(EngineCore_DP0 pid=405659) 	.loc	1 205 36                        // quant_slide_tuned_Llama3.2-3B.py:205:36
(EngineCore_DP0 pid=405659) 	max.f32 	%r114, %r114, %r68;
(EngineCore_DP0 pid=405659) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=405659) 	add.s32 	%r115, %r115, 4096;
(EngineCore_DP0 pid=405659) 	setp.lt.s32 	%p6, %r115, %r19;
(EngineCore_DP0 pid=405659) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=405659) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=405659) 	.loc	1 207 32                        // quant_slide_tuned_Llama3.2-3B.py:207:32
(EngineCore_DP0 pid=405659) 	max.f32 	%r116, %r114, 0f2B8CBCCC;
(EngineCore_DP0 pid=405659) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=405659) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-3B.py:0:32
(EngineCore_DP0 pid=405659) 	mov.b32 	%r70, 0f43E00000;
(EngineCore_DP0 pid=405659) 	.loc	1 208 32                        // quant_slide_tuned_Llama3.2-3B.py:208:32
(EngineCore_DP0 pid=405659) 	div.full.f32 	%r71, %r116, %r70;
(EngineCore_DP0 pid=405659) 	.loc	1 208 41                        // quant_slide_tuned_Llama3.2-3B.py:208:41
(EngineCore_DP0 pid=405659) 	max.f32 	%r69, %r71, 0f36924925;
(EngineCore_DP0 pid=405659) 	.loc	1 210 25                        // quant_slide_tuned_Llama3.2-3B.py:210:25
(EngineCore_DP0 pid=405659) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=405659) 	.loc	1 210 30                        // quant_slide_tuned_Llama3.2-3B.py:210:30
(EngineCore_DP0 pid=405659) 	// begin inline asm
(EngineCore_DP0 pid=405659) 	@%p19 st.global.b32 [ %rd7 + 0 ], { %r69 };
(EngineCore_DP0 pid=405659) 	// end inline asm
(EngineCore_DP0 pid=405659) 	.loc	1 213 29                        // quant_slide_tuned_Llama3.2-3B.py:213:29
(EngineCore_DP0 pid=405659) 	shl.b32 	%r15, %r20, 2;
(EngineCore_DP0 pid=405659) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=405659) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=405659) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=405659) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=405659) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-3B.py:0:41
(EngineCore_DP0 pid=405659) 	ld.param.b32 	%r24, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=405659) 	shr.s32 	%r25, %r24, 31;
(EngineCore_DP0 pid=405659) 	shr.u32 	%r26, %r25, 30;
(EngineCore_DP0 pid=405659) 	add.s32 	%r27, %r24, %r26;
(EngineCore_DP0 pid=405659) 	shr.s32 	%r28, %r27, 2;
(EngineCore_DP0 pid=405659) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=405659) 	mul.lo.s32 	%r29, %r28, %r1;
(EngineCore_DP0 pid=405659) 	mad.wide.s32 	%rd2, %r29, 4, %rd5;
(EngineCore_DP0 pid=405659) 	div.full.f32 	%r14, %r70, %r116;
(EngineCore_DP0 pid=405659) 	mov.b32 	%r117, 0;
(EngineCore_DP0 pid=405659) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=405659)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=405659) 	.loc	1 217 30                        // quant_slide_tuned_Llama3.2-3B.py:217:30
(EngineCore_DP0 pid=405659) 	add.s32 	%r83, %r3, %r117;
(EngineCore_DP0 pid=405659) 	setp.lt.s32 	%p13, %r83, %r15;
(EngineCore_DP0 pid=405659) 	.loc	1 220 24                        // quant_slide_tuned_Llama3.2-3B.py:220:24
(EngineCore_DP0 pid=405659) 	shr.s32 	%r84, %r83, 31;
(EngineCore_DP0 pid=405659) 	shr.u32 	%r85, %r84, 30;
(EngineCore_DP0 pid=405659) 	add.s32 	%r86, %r83, %r85;
(EngineCore_DP0 pid=405659) 	shr.s32 	%r87, %r86, 2;
(EngineCore_DP0 pid=405659) 	.loc	1 221 23                        // quant_slide_tuned_Llama3.2-3B.py:221:23
(EngineCore_DP0 pid=405659) 	and.b32 	%r88, %r86, 2147483644;
(EngineCore_DP0 pid=405659) 	sub.s32 	%r89, %r83, %r88;
(EngineCore_DP0 pid=405659) 	.loc	1 222 30                        // quant_slide_tuned_Llama3.2-3B.py:222:30
(EngineCore_DP0 pid=405659) 	shl.b32 	%r90, %r89, 1;
(EngineCore_DP0 pid=405659) 	.loc	1 222 26                        // quant_slide_tuned_Llama3.2-3B.py:222:26
(EngineCore_DP0 pid=405659) 	mad.lo.s32 	%r91, %r87, 10, %r90;
(EngineCore_DP0 pid=405659) 	.loc	1 225 53                        // quant_slide_tuned_Llama3.2-3B.py:225:53
(EngineCore_DP0 pid=405659) 	setp.lt.s32 	%p14, %r91, %r18;
(EngineCore_DP0 pid=405659) 	.loc	1 225 37                        // quant_slide_tuned_Llama3.2-3B.py:225:37
(EngineCore_DP0 pid=405659) 	and.pred 	%p9, %p13, %p14;
(EngineCore_DP0 pid=405659) 	.loc	1 224 29                        // quant_slide_tuned_Llama3.2-3B.py:224:29
(EngineCore_DP0 pid=405659) 	mad.wide.s32 	%rd8, %r91, 2, %rd1;
(EngineCore_DP0 pid=405659) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=405659) 	.loc	1 224 21                        // quant_slide_tuned_Llama3.2-3B.py:224:21
(EngineCore_DP0 pid=405659) 	// begin inline asm
(EngineCore_DP0 pid=405659) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=405659) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=405659) 	// end inline asm
(EngineCore_DP0 pid=405659) 	.loc	1 225 79                        // quant_slide_tuned_Llama3.2-3B.py:225:79
(EngineCore_DP0 pid=405659) 	cvt.f32.bf16 	%r92, %rs24;
(EngineCore_DP0 pid=405659) 	.loc	1 227 48                        // quant_slide_tuned_Llama3.2-3B.py:227:48
(EngineCore_DP0 pid=405659) 	or.b32 	%r93, %r91, 1;
(EngineCore_DP0 pid=405659) 	.loc	1 227 53                        // quant_slide_tuned_Llama3.2-3B.py:227:53
(EngineCore_DP0 pid=405659) 	setp.lt.s32 	%p15, %r93, %r18;
(EngineCore_DP0 pid=405659) 	.loc	1 227 37                        // quant_slide_tuned_Llama3.2-3B.py:227:37
(EngineCore_DP0 pid=405659) 	and.pred 	%p10, %p13, %p15;
(EngineCore_DP0 pid=405659) 	.loc	1 226 39                        // quant_slide_tuned_Llama3.2-3B.py:226:39
(EngineCore_DP0 pid=405659) 	add.s64 	%rd9, %rd8, 2;
(EngineCore_DP0 pid=405659) 	.loc	1 226 21                        // quant_slide_tuned_Llama3.2-3B.py:226:21
(EngineCore_DP0 pid=405659) 	// begin inline asm
(EngineCore_DP0 pid=405659) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=405659) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=405659) 	// end inline asm
(EngineCore_DP0 pid=405659) 	.loc	1 227 79                        // quant_slide_tuned_Llama3.2-3B.py:227:79
(EngineCore_DP0 pid=405659) 	cvt.f32.bf16 	%r94, %rs26;
(EngineCore_DP0 pid=405659) 	.loc	1 229 48                        // quant_slide_tuned_Llama3.2-3B.py:229:48
(EngineCore_DP0 pid=405659) 	add.s32 	%r95, %r91, 2;
(EngineCore_DP0 pid=405659) 	.loc	1 229 53                        // quant_slide_tuned_Llama3.2-3B.py:229:53
(EngineCore_DP0 pid=405659) 	setp.lt.s32 	%p16, %r95, %r18;
(EngineCore_DP0 pid=405659) 	.loc	1 229 37                        // quant_slide_tuned_Llama3.2-3B.py:229:37
(EngineCore_DP0 pid=405659) 	and.pred 	%p11, %p13, %p16;
(EngineCore_DP0 pid=405659) 	.loc	1 228 39                        // quant_slide_tuned_Llama3.2-3B.py:228:39
(EngineCore_DP0 pid=405659) 	add.s64 	%rd10, %rd8, 4;
(EngineCore_DP0 pid=405659) 	.loc	1 228 21                        // quant_slide_tuned_Llama3.2-3B.py:228:21
(EngineCore_DP0 pid=405659) 	// begin inline asm
(EngineCore_DP0 pid=405659) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=405659) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=405659) 	// end inline asm
(EngineCore_DP0 pid=405659) 	.loc	1 229 79                        // quant_slide_tuned_Llama3.2-3B.py:229:79
(EngineCore_DP0 pid=405659) 	cvt.f32.bf16 	%r96, %rs28;
(EngineCore_DP0 pid=405659) 	.loc	1 231 48                        // quant_slide_tuned_Llama3.2-3B.py:231:48
(EngineCore_DP0 pid=405659) 	add.s32 	%r97, %r91, 3;
(EngineCore_DP0 pid=405659) 	.loc	1 231 53                        // quant_slide_tuned_Llama3.2-3B.py:231:53
(EngineCore_DP0 pid=405659) 	setp.lt.s32 	%p17, %r97, %r18;
(EngineCore_DP0 pid=405659) 	.loc	1 231 37                        // quant_slide_tuned_Llama3.2-3B.py:231:37
(EngineCore_DP0 pid=405659) 	and.pred 	%p12, %p13, %p17;
(EngineCore_DP0 pid=405659) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-3B.py:230:39
(EngineCore_DP0 pid=405659) 	add.s64 	%rd11, %rd8, 6;
(EngineCore_DP0 pid=405659) 	.loc	1 230 21                        // quant_slide_tuned_Llama3.2-3B.py:230:21
(EngineCore_DP0 pid=405659) 	// begin inline asm
(EngineCore_DP0 pid=405659) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=405659) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=405659) 	// end inline asm
(EngineCore_DP0 pid=405659) 	.loc	1 231 79                        // quant_slide_tuned_Llama3.2-3B.py:231:79
(EngineCore_DP0 pid=405659) 	cvt.f32.bf16 	%r98, %rs30;
(EngineCore_DP0 pid=405659) 	.loc	1 233 27                        // quant_slide_tuned_Llama3.2-3B.py:233:27
(EngineCore_DP0 pid=405659) 	mul.f32 	%r99, %r14, %r92;
(EngineCore_DP0 pid=405659) 	mov.b32 	%r100, 0f43E00000;
(EngineCore_DP0 pid=405659) 	.loc	1 233 48                        // quant_slide_tuned_Llama3.2-3B.py:233:48
(EngineCore_DP0 pid=405659) 	min.xorsign.abs.f32 	%r73, %r99, %r100;
(EngineCore_DP0 pid=405659) 	.loc	1 233 60                        // quant_slide_tuned_Llama3.2-3B.py:233:60
(EngineCore_DP0 pid=405659) 	// begin inline asm
(EngineCore_DP0 pid=405659) 	cvt.rn.satfinite.e4m3x2.f32  %rs32, %r74, %r73; 
(EngineCore_DP0 pid=405659) 
(EngineCore_DP0 pid=405659) 	// end inline asm
(EngineCore_DP0 pid=405659) 	.loc	1 234 27                        // quant_slide_tuned_Llama3.2-3B.py:234:27
(EngineCore_DP0 pid=405659) 	mul.f32 	%r101, %r14, %r94;
(EngineCore_DP0 pid=405659) 	.loc	1 234 48                        // quant_slide_tuned_Llama3.2-3B.py:234:48
(EngineCore_DP0 pid=405659) 	min.xorsign.abs.f32 	%r75, %r101, %r100;
(EngineCore_DP0 pid=405659) 	.loc	1 234 60                        // quant_slide_tuned_Llama3.2-3B.py:234:60
(EngineCore_DP0 pid=405659) 	// begin inline asm
(EngineCore_DP0 pid=405659) 	cvt.rn.satfinite.e4m3x2.f32  %rs33, %r76, %r75; 
(EngineCore_DP0 pid=405659) 
(EngineCore_DP0 pid=405659) 	// end inline asm
(EngineCore_DP0 pid=405659) 	.loc	1 235 27                        // quant_slide_tuned_Llama3.2-3B.py:235:27
(EngineCore_DP0 pid=405659) 	mul.f32 	%r102, %r14, %r96;
(EngineCore_DP0 pid=405659) 	.loc	1 235 48                        // quant_slide_tuned_Llama3.2-3B.py:235:48
(EngineCore_DP0 pid=405659) 	min.xorsign.abs.f32 	%r77, %r102, %r100;
(EngineCore_DP0 pid=405659) 	.loc	1 235 60                        // quant_slide_tuned_Llama3.2-3B.py:235:60
(EngineCore_DP0 pid=405659) 	// begin inline asm
(EngineCore_DP0 pid=405659) 	cvt.rn.satfinite.e4m3x2.f32  %rs34, %r78, %r77; 
(EngineCore_DP0 pid=405659) 
(EngineCore_DP0 pid=405659) 	// end inline asm
(EngineCore_DP0 pid=405659) 	.loc	1 236 27                        // quant_slide_tuned_Llama3.2-3B.py:236:27
(EngineCore_DP0 pid=405659) 	mul.f32 	%r103, %r14, %r98;
(EngineCore_DP0 pid=405659) 	.loc	1 236 48                        // quant_slide_tuned_Llama3.2-3B.py:236:48
(EngineCore_DP0 pid=405659) 	min.xorsign.abs.f32 	%r79, %r103, %r100;
(EngineCore_DP0 pid=405659) 	.loc	1 236 60                        // quant_slide_tuned_Llama3.2-3B.py:236:60
(EngineCore_DP0 pid=405659) 	// begin inline asm
(EngineCore_DP0 pid=405659) 	cvt.rn.satfinite.e4m3x2.f32  %rs35, %r80, %r79; 
(EngineCore_DP0 pid=405659) 
(EngineCore_DP0 pid=405659) 	// end inline asm
(EngineCore_DP0 pid=405659) 	.loc	1 238 45                        // quant_slide_tuned_Llama3.2-3B.py:238:45
(EngineCore_DP0 pid=405659) 	cvt.u32.u16 	%r104, %rs32;
(EngineCore_DP0 pid=405659) 	and.b32 	%r105, %r104, 255;
(EngineCore_DP0 pid=405659) 	.loc	1 240 45                        // quant_slide_tuned_Llama3.2-3B.py:240:45
(EngineCore_DP0 pid=405659) 	cvt.u32.u16 	%r106, %rs34;
(EngineCore_DP0 pid=405659) 	and.b32 	%r107, %r106, 255;
(EngineCore_DP0 pid=405659) 	.loc	1 241 45                        // quant_slide_tuned_Llama3.2-3B.py:241:45
(EngineCore_DP0 pid=405659) 	cvt.u32.u16 	%r108, %rs35;
(EngineCore_DP0 pid=405659) 	.loc	1 243 30                        // quant_slide_tuned_Llama3.2-3B.py:243:30
(EngineCore_DP0 pid=405659) 	and.b16 	%rs36, %rs33, 255;
(EngineCore_DP0 pid=405659) 	mul.wide.u16 	%r109, %rs36, 256;
(EngineCore_DP0 pid=405659) 	.loc	1 243 24                        // quant_slide_tuned_Llama3.2-3B.py:243:24
(EngineCore_DP0 pid=405659) 	or.b32 	%r110, %r109, %r105;
(EngineCore_DP0 pid=405659) 	.loc	1 243 42                        // quant_slide_tuned_Llama3.2-3B.py:243:42
(EngineCore_DP0 pid=405659) 	shl.b32 	%r111, %r107, 16;
(EngineCore_DP0 pid=405659) 	.loc	1 243 36                        // quant_slide_tuned_Llama3.2-3B.py:243:36
(EngineCore_DP0 pid=405659) 	or.b32 	%r112, %r110, %r111;
(EngineCore_DP0 pid=405659) 	.loc	1 243 55                        // quant_slide_tuned_Llama3.2-3B.py:243:55
(EngineCore_DP0 pid=405659) 	shl.b32 	%r113, %r108, 24;
(EngineCore_DP0 pid=405659) 	.loc	1 243 49                        // quant_slide_tuned_Llama3.2-3B.py:243:49
(EngineCore_DP0 pid=405659) 	or.b32 	%r81, %r112, %r113;
(EngineCore_DP0 pid=405659) 	.loc	1 244 29                        // quant_slide_tuned_Llama3.2-3B.py:244:29
(EngineCore_DP0 pid=405659) 	mad.wide.s32 	%rd12, %r83, 4, %rd2;
(EngineCore_DP0 pid=405659) 	.loc	1 244 39                        // quant_slide_tuned_Llama3.2-3B.py:244:39
(EngineCore_DP0 pid=405659) 	// begin inline asm
(EngineCore_DP0 pid=405659) 	@%p13 st.global.b32 [ %rd12 + 0 ], { %r81 };
(EngineCore_DP0 pid=405659) 	// end inline asm
(EngineCore_DP0 pid=405659) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=405659) 	add.s32 	%r117, %r117, 512;
(EngineCore_DP0 pid=405659) 	setp.lt.s32 	%p18, %r117, %r15;
(EngineCore_DP0 pid=405659) 	@%p18 bra 	$L__BB0_6;
(EngineCore_DP0 pid=405659) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=405659) 	.loc	1 215 4                         // quant_slide_tuned_Llama3.2-3B.py:215:4
(EngineCore_DP0 pid=405659) 	ret;
(EngineCore_DP0 pid=405659) $L__tmp3:
(EngineCore_DP0 pid=405659) $L__func_end0:
(EngineCore_DP0 pid=405659)                                         // -- End function
(EngineCore_DP0 pid=405659) }
(EngineCore_DP0 pid=405659) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py"
(EngineCore_DP0 pid=405659) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=405659) 	.section	.debug_abbrev
(EngineCore_DP0 pid=405659) 	{
(EngineCore_DP0 pid=405659) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=405659) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=405659) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=405659) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=405659) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=405659) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=405659) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=405659) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=405659) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=405659) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=405659) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=405659) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=405659) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=405659) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=405659) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=405659) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=405659) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=405659) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=405659) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=405659) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=405659) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=405659) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=405659) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=405659) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=405659) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=405659) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=405659) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=405659) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=405659) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=405659) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=405659) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=405659) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=405659) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=405659) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=405659) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=405659) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=405659) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=405659) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=405659) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=405659) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=405659) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=405659) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=405659) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=405659) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=405659) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=405659) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=405659) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=405659) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=405659) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=405659) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=405659) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=405659) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=405659) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=405659) 	}
(EngineCore_DP0 pid=405659) 	.section	.debug_info
(EngineCore_DP0 pid=405659) 	{
(EngineCore_DP0 pid=405659) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=405659) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=405659) .b8 0
(EngineCore_DP0 pid=405659) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=405659) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=405659) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=405659) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=405659) .b8 114
(EngineCore_DP0 pid=405659) .b8 105
(EngineCore_DP0 pid=405659) .b8 116
(EngineCore_DP0 pid=405659) .b8 111
(EngineCore_DP0 pid=405659) .b8 110
(EngineCore_DP0 pid=405659) .b8 0
(EngineCore_DP0 pid=405659) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=405659) .b8 0
(EngineCore_DP0 pid=405659) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=405659) .b8 117
(EngineCore_DP0 pid=405659) .b8 97
(EngineCore_DP0 pid=405659) .b8 110
(EngineCore_DP0 pid=405659) .b8 116
(EngineCore_DP0 pid=405659) .b8 95
(EngineCore_DP0 pid=405659) .b8 115
(EngineCore_DP0 pid=405659) .b8 108
(EngineCore_DP0 pid=405659) .b8 105
(EngineCore_DP0 pid=405659) .b8 100
(EngineCore_DP0 pid=405659) .b8 101
(EngineCore_DP0 pid=405659) .b8 95
(EngineCore_DP0 pid=405659) .b8 116
(EngineCore_DP0 pid=405659) .b8 117
(EngineCore_DP0 pid=405659) .b8 110
(EngineCore_DP0 pid=405659) .b8 101
(EngineCore_DP0 pid=405659) .b8 100
(EngineCore_DP0 pid=405659) .b8 95
(EngineCore_DP0 pid=405659) .b8 76
(EngineCore_DP0 pid=405659) .b8 108
(EngineCore_DP0 pid=405659) .b8 97
(EngineCore_DP0 pid=405659) .b8 109
(EngineCore_DP0 pid=405659) .b8 97
(EngineCore_DP0 pid=405659) .b8 51
(EngineCore_DP0 pid=405659) .b8 46
(EngineCore_DP0 pid=405659) .b8 50
(EngineCore_DP0 pid=405659) .b8 45
(EngineCore_DP0 pid=405659) .b8 51
(EngineCore_DP0 pid=405659) .b8 66
(EngineCore_DP0 pid=405659) .b8 46
(EngineCore_DP0 pid=405659) .b8 112
(EngineCore_DP0 pid=405659) .b8 121
(EngineCore_DP0 pid=405659) .b8 0
(EngineCore_DP0 pid=405659) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=405659) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=405659) .b8 114
(EngineCore_DP0 pid=405659) .b8 111
(EngineCore_DP0 pid=405659) .b8 111
(EngineCore_DP0 pid=405659) .b8 116
(EngineCore_DP0 pid=405659) .b8 47
(EngineCore_DP0 pid=405659) .b8 118
(EngineCore_DP0 pid=405659) .b8 108
(EngineCore_DP0 pid=405659) .b8 108
(EngineCore_DP0 pid=405659) .b8 109
(EngineCore_DP0 pid=405659) .b8 98
(EngineCore_DP0 pid=405659) .b8 101
(EngineCore_DP0 pid=405659) .b8 110
(EngineCore_DP0 pid=405659) .b8 99
(EngineCore_DP0 pid=405659) .b8 104
(EngineCore_DP0 pid=405659) .b8 47
(EngineCore_DP0 pid=405659) .b8 115
(EngineCore_DP0 pid=405659) .b8 108
(EngineCore_DP0 pid=405659) .b8 105
(EngineCore_DP0 pid=405659) .b8 100
(EngineCore_DP0 pid=405659) .b8 101
(EngineCore_DP0 pid=405659) .b8 115
(EngineCore_DP0 pid=405659) .b8 112
(EngineCore_DP0 pid=405659) .b8 97
(EngineCore_DP0 pid=405659) .b8 114
(EngineCore_DP0 pid=405659) .b8 115
(EngineCore_DP0 pid=405659) .b8 101
(EngineCore_DP0 pid=405659) .b8 47
(EngineCore_DP0 pid=405659) .b8 99
(EngineCore_DP0 pid=405659) .b8 115
(EngineCore_DP0 pid=405659) .b8 114
(EngineCore_DP0 pid=405659) .b8 99
(EngineCore_DP0 pid=405659) .b8 47
(EngineCore_DP0 pid=405659) .b8 102
(EngineCore_DP0 pid=405659) .b8 117
(EngineCore_DP0 pid=405659) .b8 115
(EngineCore_DP0 pid=405659) .b8 101
(EngineCore_DP0 pid=405659) .b8 100
(EngineCore_DP0 pid=405659) .b8 95
(EngineCore_DP0 pid=405659) .b8 113
(EngineCore_DP0 pid=405659) .b8 117
(EngineCore_DP0 pid=405659) .b8 97
(EngineCore_DP0 pid=405659) .b8 110
(EngineCore_DP0 pid=405659) .b8 116
(EngineCore_DP0 pid=405659) .b8 95
(EngineCore_DP0 pid=405659) .b8 115
(EngineCore_DP0 pid=405659) .b8 108
(EngineCore_DP0 pid=405659) .b8 105
(EngineCore_DP0 pid=405659) .b8 100
(EngineCore_DP0 pid=405659) .b8 101
(EngineCore_DP0 pid=405659) .b8 95
(EngineCore_DP0 pid=405659) .b8 116
(EngineCore_DP0 pid=405659) .b8 114
(EngineCore_DP0 pid=405659) .b8 105
(EngineCore_DP0 pid=405659) .b8 116
(EngineCore_DP0 pid=405659) .b8 111
(EngineCore_DP0 pid=405659) .b8 110
(EngineCore_DP0 pid=405659) .b8 47
(EngineCore_DP0 pid=405659) .b8 98
(EngineCore_DP0 pid=405659) .b8 117
(EngineCore_DP0 pid=405659) .b8 105
(EngineCore_DP0 pid=405659) .b8 108
(EngineCore_DP0 pid=405659) .b8 100
(EngineCore_DP0 pid=405659) .b8 47
(EngineCore_DP0 pid=405659) .b8 71
(EngineCore_DP0 pid=405659) .b8 66
(EngineCore_DP0 pid=405659) .b8 49
(EngineCore_DP0 pid=405659) .b8 48
(EngineCore_DP0 pid=405659) .b8 95
(EngineCore_DP0 pid=405659) .b8 99
(EngineCore_DP0 pid=405659) .b8 99
(EngineCore_DP0 pid=405659) .b8 49
(EngineCore_DP0 pid=405659) .b8 50
(EngineCore_DP0 pid=405659) .b8 49
(EngineCore_DP0 pid=405659) .b8 95
(EngineCore_DP0 pid=405659) .b8 112
(EngineCore_DP0 pid=405659) .b8 121
(EngineCore_DP0 pid=405659) .b8 51
(EngineCore_DP0 pid=405659) .b8 49
(EngineCore_DP0 pid=405659) .b8 50
(EngineCore_DP0 pid=405659) .b8 95
(EngineCore_DP0 pid=405659) .b8 99
(EngineCore_DP0 pid=405659) .b8 117
(EngineCore_DP0 pid=405659) .b8 49
(EngineCore_DP0 pid=405659) .b8 50
(EngineCore_DP0 pid=405659) .b8 57
(EngineCore_DP0 pid=405659) .b8 95
(EngineCore_DP0 pid=405659) .b8 97
(EngineCore_DP0 pid=405659) .b8 97
(EngineCore_DP0 pid=405659) .b8 114
(EngineCore_DP0 pid=405659) .b8 99
(EngineCore_DP0 pid=405659) .b8 104
(EngineCore_DP0 pid=405659) .b8 54
(EngineCore_DP0 pid=405659) .b8 52
(EngineCore_DP0 pid=405659) .b8 0
(EngineCore_DP0 pid=405659) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=405659) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=405659) .b8 113
(EngineCore_DP0 pid=405659) .b8 117
(EngineCore_DP0 pid=405659) .b8 97
(EngineCore_DP0 pid=405659) .b8 110
(EngineCore_DP0 pid=405659) .b8 116
(EngineCore_DP0 pid=405659) .b8 95
(EngineCore_DP0 pid=405659) .b8 115
(EngineCore_DP0 pid=405659) .b8 108
(EngineCore_DP0 pid=405659) .b8 105
(EngineCore_DP0 pid=405659) .b8 100
(EngineCore_DP0 pid=405659) .b8 101
(EngineCore_DP0 pid=405659) .b8 95
(EngineCore_DP0 pid=405659) .b8 102
(EngineCore_DP0 pid=405659) .b8 112
(EngineCore_DP0 pid=405659) .b8 56
(EngineCore_DP0 pid=405659) .b8 95
(EngineCore_DP0 pid=405659) .b8 107
(EngineCore_DP0 pid=405659) .b8 101
(EngineCore_DP0 pid=405659) .b8 114
(EngineCore_DP0 pid=405659) .b8 110
(EngineCore_DP0 pid=405659) .b8 101
(EngineCore_DP0 pid=405659) .b8 108
(EngineCore_DP0 pid=405659) .b8 0
(EngineCore_DP0 pid=405659) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=405659) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=405659) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=405659) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=405659) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=405659) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=405659) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=405659) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=405659) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=405659) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=405659) .b8 205                                 // DW_AT_call_line
(EngineCore_DP0 pid=405659) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=405659) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=405659) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=405659) 	}
(EngineCore_DP0 pid=405659) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=405659) 
(EngineCore_DP0 pid=405659) ================================================================
(EngineCore_DP0 pid=405659) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=405659) 
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpdldsdswe.ptx', '-o', '/tmp/tmpdldsdswe.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866] 
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866] 
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866] 
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpdldsdswe.ptx -o /tmp/tmpdldsdswe.ptx.o
(EngineCore_DP0 pid=405659) ERROR 01-25 20:16:43 [core.py:866] 

STDERR:
[2026-01-25 20:16:11] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:16:11] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:16:11] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:16:11] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:16:11] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:16:11] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:16:11] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:16:11] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:16:11] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:16:11] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:16:11] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:16:11] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:16:11] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:16:11] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:16:15] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:16:15] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:16:15] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:16:15] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:16:15] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:16:15] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:16:15] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:16:15] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:16:15] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:16:15] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:16:15] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:16:15] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:16:15] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:16:15] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=405659) [2026-01-25 20:16:16] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=405659) [2026-01-25 20:16:16] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=405659) [2026-01-25 20:16:16] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=405659) [2026-01-25 20:16:16] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=405659) [2026-01-25 20:16:16] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=405659) [2026-01-25 20:16:16] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=405659) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=405659) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:24<00:00, 24.73s/it]
(EngineCore_DP0 pid=405659) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:24<00:00, 24.73s/it]
(EngineCore_DP0 pid=405659) 
(EngineCore_DP0 pid=405659) [2026-01-25 20:16:42] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4928] -> 1D uint8
(EngineCore_DP0 pid=405659) [2026-01-25 20:16:42] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15810560 bytes
(EngineCore_DP0 pid=405659) [2026-01-25 20:16:42] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4928] -> 1D uint8
(EngineCore_DP0 pid=405659) [2026-01-25 20:16:42] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9486336 bytes
(EngineCore_DP0 pid=405659) [2026-01-25 20:16:42] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4928] -> 1D uint8
(EngineCore_DP0 pid=405659) [2026-01-25 20:16:42] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 50593792 bytes
(EngineCore_DP0 pid=405659) [2026-01-25 20:16:42] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 13120] -> 1D uint8
(EngineCore_DP0 pid=405659) [2026-01-25 20:16:42] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 25214976 bytes
(EngineCore_DP0 pid=405659) Process EngineCore_DP0:
(EngineCore_DP0 pid=405659) Traceback (most recent call last):
(EngineCore_DP0 pid=405659)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=405659)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=405659)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=405659)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=405659) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpdldsdswe.ptx', '-o', '/tmp/tmpdldsdswe.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=405659) 
(EngineCore_DP0 pid=405659) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=405659) 
(EngineCore_DP0 pid=405659) Traceback (most recent call last):
(EngineCore_DP0 pid=405659)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=405659)     self.run()
(EngineCore_DP0 pid=405659)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=405659)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=405659)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=405659)     raise e
(EngineCore_DP0 pid=405659)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=405659)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=405659)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=405659)     super().__init__(
(EngineCore_DP0 pid=405659)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=405659)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=405659)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=405659)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=405659)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=405659)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=405659)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=405659)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=405659)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=405659)     return func(*args, **kwargs)
(EngineCore_DP0 pid=405659)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=405659)     return func(*args, **kwargs)
(EngineCore_DP0 pid=405659)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=405659)     self.model_runner.profile_run()
(EngineCore_DP0 pid=405659)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=405659)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=405659)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=405659)     return func(*args, **kwargs)
(EngineCore_DP0 pid=405659)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=405659)     outputs = self.model(
(EngineCore_DP0 pid=405659)               ^^^^^^^^^^^
(EngineCore_DP0 pid=405659)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=405659)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=405659)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=405659)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=405659)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=405659)     model_output = self.model(
(EngineCore_DP0 pid=405659)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=405659)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=405659)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=405659)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=405659)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=405659)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=405659)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=405659)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=405659)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=405659)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=405659)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=405659)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=405659)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=405659)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=405659)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=405659)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=405659)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=405659)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=405659)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=405659)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=405659)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=405659)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=405659)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=405659)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=405659)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=405659)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=405659)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=405659)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=405659)     return self._linear_fn(
(EngineCore_DP0 pid=405659)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=405659)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=405659)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=405659)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=405659)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=405659)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=405659)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=405659)     return fn(input, L)
(EngineCore_DP0 pid=405659)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=405659)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=405659)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=405659)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=405659)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=405659)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=405659)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=405659)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=405659)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=405659)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=405659)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=405659)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=405659)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=405659)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=405659)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=405659)     raise PTXASError(error)
(EngineCore_DP0 pid=405659) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=405659) `ptxas` stderr:
(EngineCore_DP0 pid=405659) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=405659) 
(EngineCore_DP0 pid=405659) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpdldsdswe.ptx -o /tmp/tmpdldsdswe.ptx.o
(EngineCore_DP0 pid=405659) 
[rank0]:[W125 20:16:43.521732775 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=2048

========== M=4096 ==========
Time: 2026-01-25 20:16:44
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-3B-FP8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:16:49 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 20:16:50 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=406356) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=406356) 
(EngineCore_DP0 pid=406356) 
(EngineCore_DP0 pid=406356) ================================================================
(EngineCore_DP0 pid=406356) Internal Triton PTX codegen error
(EngineCore_DP0 pid=406356) `ptxas` stderr:
(EngineCore_DP0 pid=406356) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=406356) 
(EngineCore_DP0 pid=406356) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpk_jgf5ld.ptx -o /tmp/tmpk_jgf5ld.ptx.o
(EngineCore_DP0 pid=406356) 
(EngineCore_DP0 pid=406356) 
(EngineCore_DP0 pid=406356) //
(EngineCore_DP0 pid=406356) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=406356) //
(EngineCore_DP0 pid=406356) 
(EngineCore_DP0 pid=406356) .version 8.7
(EngineCore_DP0 pid=406356) .target sm_121a
(EngineCore_DP0 pid=406356) .address_size 64
(EngineCore_DP0 pid=406356) 
(EngineCore_DP0 pid=406356) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=406356) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=406356)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=406356) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=406356) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=406356) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=406356) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=406356) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=406356) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=406356) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=406356) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=406356) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=406356) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=406356) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=406356) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=406356) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=406356) )
(EngineCore_DP0 pid=406356) .reqntid 512
(EngineCore_DP0 pid=406356) {
(EngineCore_DP0 pid=406356) 	.reg .pred 	%p<28>;
(EngineCore_DP0 pid=406356) 	.reg .b16 	%rs<49>;
(EngineCore_DP0 pid=406356) 	.reg .b32 	%r<151>;
(EngineCore_DP0 pid=406356) 	.reg .b64 	%rd<17>;
(EngineCore_DP0 pid=406356) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=406356) $L__func_begin0:
(EngineCore_DP0 pid=406356) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=406356) 
(EngineCore_DP0 pid=406356) // %bb.0:
(EngineCore_DP0 pid=406356) 	ld.param.b32 	%r25, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=406356) 	ld.param.b32 	%r24, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=406356) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=406356) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=406356) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=406356) $L__tmp0:
(EngineCore_DP0 pid=406356) 	.loc	1 191 24                        // quant_slide_tuned_Llama3.2-3B.py:191:24
(EngineCore_DP0 pid=406356) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=406356) 	ld.param.b32 	%r27, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=406356) 	.loc	1 196 26                        // quant_slide_tuned_Llama3.2-3B.py:196:26
(EngineCore_DP0 pid=406356) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=406356) 	.loc	1 196 20                        // quant_slide_tuned_Llama3.2-3B.py:196:20
(EngineCore_DP0 pid=406356) 	mad.wide.s32 	%rd1, %r28, 2, %rd4;
(EngineCore_DP0 pid=406356) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=406356) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=406356) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=406356) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=406356) 	setp.lt.s32 	%p1, %r24, 1;
(EngineCore_DP0 pid=406356) 	mov.b32 	%r149, 0f2B8CBCCC;
(EngineCore_DP0 pid=406356) 	setp.eq.b32 	%p27, %r2, 0;
(EngineCore_DP0 pid=406356) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=406356) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=406356) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=406356) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=406356) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=406356) 	shr.u32 	%r37, %r2, 3;
(EngineCore_DP0 pid=406356) 	and.b32 	%r38, %r37, 60;
(EngineCore_DP0 pid=406356) 	mov.b32 	%r39, global_smem;
(EngineCore_DP0 pid=406356) 	add.s32 	%r49, %r39, %r38;
(EngineCore_DP0 pid=406356) 	shl.b32 	%r40, %r2, 2;
(EngineCore_DP0 pid=406356) 	add.s32 	%r52, %r39, %r40;
(EngineCore_DP0 pid=406356) 	mov.b32 	%r45, 0;
(EngineCore_DP0 pid=406356) 	mov.b32 	%r147, 0f00000000;
(EngineCore_DP0 pid=406356) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=406356) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=406356) 	mov.b32 	%r148, %r45;
(EngineCore_DP0 pid=406356) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=406356) 	.loc	1 203 22                        // quant_slide_tuned_Llama3.2-3B.py:203:22
(EngineCore_DP0 pid=406356) 	add.s32 	%r55, %r4, %r148;
(EngineCore_DP0 pid=406356) 	setp.lt.s32 	%p2, %r55, %r23;
(EngineCore_DP0 pid=406356) 	.loc	1 204 29                        // quant_slide_tuned_Llama3.2-3B.py:204:29
(EngineCore_DP0 pid=406356) 	mad.wide.s32 	%rd6, %r55, 2, %rd1;
(EngineCore_DP0 pid=406356) 	.loc	1 204 21                        // quant_slide_tuned_Llama3.2-3B.py:204:21
(EngineCore_DP0 pid=406356) 	// begin inline asm
(EngineCore_DP0 pid=406356) 	mov.u32 %r41, %r45;
(EngineCore_DP0 pid=406356) 	mov.u32 %r42, %r45;
(EngineCore_DP0 pid=406356) 	mov.u32 %r43, %r45;
(EngineCore_DP0 pid=406356) 	mov.u32 %r44, %r45;
(EngineCore_DP0 pid=406356) 	@%p2 ld.global.v4.b32 { %r41, %r42, %r43, %r44 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=406356) 	// end inline asm
(EngineCore_DP0 pid=406356) 	mov.b32 	{%rs1, %rs2}, %r41;
(EngineCore_DP0 pid=406356) 	mov.b32 	{%rs3, %rs4}, %r42;
(EngineCore_DP0 pid=406356) 	mov.b32 	{%rs5, %rs6}, %r43;
(EngineCore_DP0 pid=406356) 	mov.b32 	{%rs7, %rs8}, %r44;
(EngineCore_DP0 pid=406356) 	.loc	1 205 50                        // quant_slide_tuned_Llama3.2-3B.py:205:50
(EngineCore_DP0 pid=406356) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=406356) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=406356) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=406356) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=406356) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=406356) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=406356) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=406356) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=406356) $L__tmp1:
(EngineCore_DP0 pid=406356) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=406356) 	bar.sync 	0;
(EngineCore_DP0 pid=406356) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=406356) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=406356) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=406356) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=406356) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=406356) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=406356) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=406356) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=406356) 	cvt.f32.bf16 	%r56, %rs23;
(EngineCore_DP0 pid=406356) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=406356) 	shfl.sync.bfly.b32 	%r57, %r56, 16, 31, -1;
(EngineCore_DP0 pid=406356) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=406356) 	max.f32 	%r58, %r56, %r57;
(EngineCore_DP0 pid=406356) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=406356) 	shfl.sync.bfly.b32 	%r59, %r58, 8, 31, -1;
(EngineCore_DP0 pid=406356) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=406356) 	max.f32 	%r60, %r58, %r59;
(EngineCore_DP0 pid=406356) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=406356) 	shfl.sync.bfly.b32 	%r61, %r60, 4, 31, -1;
(EngineCore_DP0 pid=406356) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=406356) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=406356) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=406356) 	shfl.sync.bfly.b32 	%r63, %r62, 2, 31, -1;
(EngineCore_DP0 pid=406356) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=406356) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=406356) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=406356) 	shfl.sync.bfly.b32 	%r65, %r64, 1, 31, -1;
(EngineCore_DP0 pid=406356) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=406356) 	max.f32 	%r50, %r64, %r65;
(EngineCore_DP0 pid=406356) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=406356) 	// begin inline asm
(EngineCore_DP0 pid=406356) 	@%p3 st.shared.b32 [ %r49 + 0 ], %r50;
(EngineCore_DP0 pid=406356) 	// end inline asm
(EngineCore_DP0 pid=406356) 	bar.sync 	0;
(EngineCore_DP0 pid=406356) 	// begin inline asm
(EngineCore_DP0 pid=406356) 	@%p4 ld.shared.b32 %r51, [ %r52 + 0 ];
(EngineCore_DP0 pid=406356) 	// end inline asm
(EngineCore_DP0 pid=406356) 	shfl.sync.bfly.b32 	%r66, %r51, 8, 31, -1;
(EngineCore_DP0 pid=406356) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=406356) 	max.f32 	%r67, %r51, %r66;
(EngineCore_DP0 pid=406356) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=406356) 	shfl.sync.bfly.b32 	%r68, %r67, 4, 31, -1;
(EngineCore_DP0 pid=406356) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=406356) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=406356) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=406356) 	shfl.sync.bfly.b32 	%r70, %r69, 2, 31, -1;
(EngineCore_DP0 pid=406356) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=406356) 	max.f32 	%r71, %r69, %r70;
(EngineCore_DP0 pid=406356) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=406356) 	shfl.sync.bfly.b32 	%r72, %r71, 1, 31, -1;
(EngineCore_DP0 pid=406356) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=406356) 	max.f32 	%r54, %r71, %r72;
(EngineCore_DP0 pid=406356) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=406356) 	// begin inline asm
(EngineCore_DP0 pid=406356) 	@%p27 st.shared.b32 [ %r52 + 0 ], %r54;
(EngineCore_DP0 pid=406356) 	// end inline asm
(EngineCore_DP0 pid=406356) 	bar.sync 	0;
(EngineCore_DP0 pid=406356) 	ld.shared.b32 	%r73, [global_smem];
(EngineCore_DP0 pid=406356) $L__tmp2:
(EngineCore_DP0 pid=406356) 	.loc	1 205 36                        // quant_slide_tuned_Llama3.2-3B.py:205:36
(EngineCore_DP0 pid=406356) 	max.f32 	%r147, %r147, %r73;
(EngineCore_DP0 pid=406356) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=406356) 	add.s32 	%r148, %r148, 4096;
(EngineCore_DP0 pid=406356) 	setp.lt.s32 	%p6, %r148, %r24;
(EngineCore_DP0 pid=406356) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=406356) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=406356) 	.loc	1 207 32                        // quant_slide_tuned_Llama3.2-3B.py:207:32
(EngineCore_DP0 pid=406356) 	max.f32 	%r149, %r147, 0f2B8CBCCC;
(EngineCore_DP0 pid=406356) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=406356) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-3B.py:0:32
(EngineCore_DP0 pid=406356) 	mov.b32 	%r75, 0f43E00000;
(EngineCore_DP0 pid=406356) 	.loc	1 208 32                        // quant_slide_tuned_Llama3.2-3B.py:208:32
(EngineCore_DP0 pid=406356) 	div.full.f32 	%r76, %r149, %r75;
(EngineCore_DP0 pid=406356) 	.loc	1 208 41                        // quant_slide_tuned_Llama3.2-3B.py:208:41
(EngineCore_DP0 pid=406356) 	max.f32 	%r74, %r76, 0f36924925;
(EngineCore_DP0 pid=406356) 	.loc	1 210 25                        // quant_slide_tuned_Llama3.2-3B.py:210:25
(EngineCore_DP0 pid=406356) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=406356) 	.loc	1 210 30                        // quant_slide_tuned_Llama3.2-3B.py:210:30
(EngineCore_DP0 pid=406356) 	// begin inline asm
(EngineCore_DP0 pid=406356) 	@%p27 st.global.b32 [ %rd7 + 0 ], { %r74 };
(EngineCore_DP0 pid=406356) 	// end inline asm
(EngineCore_DP0 pid=406356) 	.loc	1 213 29                        // quant_slide_tuned_Llama3.2-3B.py:213:29
(EngineCore_DP0 pid=406356) 	shl.b32 	%r15, %r25, 2;
(EngineCore_DP0 pid=406356) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=406356) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=406356) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=406356) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=406356) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-3B.py:0:41
(EngineCore_DP0 pid=406356) 	ld.param.b32 	%r29, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=406356) 	shr.s32 	%r30, %r29, 31;
(EngineCore_DP0 pid=406356) 	shr.u32 	%r31, %r30, 30;
(EngineCore_DP0 pid=406356) 	add.s32 	%r32, %r29, %r31;
(EngineCore_DP0 pid=406356) 	shr.s32 	%r33, %r32, 2;
(EngineCore_DP0 pid=406356) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=406356) 	mul.lo.s32 	%r34, %r33, %r1;
(EngineCore_DP0 pid=406356) 	mad.wide.s32 	%rd2, %r34, 4, %rd5;
(EngineCore_DP0 pid=406356) 	div.full.f32 	%r14, %r75, %r149;
(EngineCore_DP0 pid=406356) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=406356) 	mov.b32 	%r150, 0;
(EngineCore_DP0 pid=406356) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=406356)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=406356) 	.loc	1 216 31                        // quant_slide_tuned_Llama3.2-3B.py:216:31
(EngineCore_DP0 pid=406356) 	add.s32 	%r88, %r16, %r150;
(EngineCore_DP0 pid=406356) 	.loc	1 217 30                        // quant_slide_tuned_Llama3.2-3B.py:217:30
(EngineCore_DP0 pid=406356) 	add.s32 	%r89, %r88, 1;
(EngineCore_DP0 pid=406356) 	setp.lt.s32 	%p17, %r88, %r15;
(EngineCore_DP0 pid=406356) 	.loc	1 220 24                        // quant_slide_tuned_Llama3.2-3B.py:220:24
(EngineCore_DP0 pid=406356) 	shr.s32 	%r90, %r88, 31;
(EngineCore_DP0 pid=406356) 	shr.u32 	%r91, %r90, 30;
(EngineCore_DP0 pid=406356) 	add.s32 	%r92, %r88, %r91;
(EngineCore_DP0 pid=406356) 	shr.s32 	%r93, %r92, 2;
(EngineCore_DP0 pid=406356) 	.loc	1 221 23                        // quant_slide_tuned_Llama3.2-3B.py:221:23
(EngineCore_DP0 pid=406356) 	shr.s32 	%r94, %r89, 31;
(EngineCore_DP0 pid=406356) 	shr.u32 	%r95, %r94, 30;
(EngineCore_DP0 pid=406356) 	add.s32 	%r96, %r89, %r95;
(EngineCore_DP0 pid=406356) 	and.b32 	%r97, %r96, 2147483644;
(EngineCore_DP0 pid=406356) 	sub.s32 	%r98, %r89, %r97;
(EngineCore_DP0 pid=406356) 	and.b32 	%r99, %r92, 2147483644;
(EngineCore_DP0 pid=406356) 	sub.s32 	%r100, %r88, %r99;
(EngineCore_DP0 pid=406356) 	.loc	1 222 22                        // quant_slide_tuned_Llama3.2-3B.py:222:22
(EngineCore_DP0 pid=406356) 	mul.lo.s32 	%r101, %r93, 10;
(EngineCore_DP0 pid=406356) 	.loc	1 222 30                        // quant_slide_tuned_Llama3.2-3B.py:222:30
(EngineCore_DP0 pid=406356) 	shl.b32 	%r102, %r100, 1;
(EngineCore_DP0 pid=406356) 	shl.b32 	%r103, %r98, 1;
(EngineCore_DP0 pid=406356) 	.loc	1 222 26                        // quant_slide_tuned_Llama3.2-3B.py:222:26
(EngineCore_DP0 pid=406356) 	add.s32 	%r104, %r101, %r103;
(EngineCore_DP0 pid=406356) 	add.s32 	%r105, %r101, %r102;
(EngineCore_DP0 pid=406356) 	.loc	1 225 53                        // quant_slide_tuned_Llama3.2-3B.py:225:53
(EngineCore_DP0 pid=406356) 	setp.lt.s32 	%p18, %r105, %r23;
(EngineCore_DP0 pid=406356) 	setp.lt.s32 	%p19, %r104, %r23;
(EngineCore_DP0 pid=406356) 	.loc	1 225 37                        // quant_slide_tuned_Llama3.2-3B.py:225:37
(EngineCore_DP0 pid=406356) 	and.pred 	%p9, %p17, %p18;
(EngineCore_DP0 pid=406356) 	and.pred 	%p10, %p17, %p19;
(EngineCore_DP0 pid=406356) 	.loc	1 224 29                        // quant_slide_tuned_Llama3.2-3B.py:224:29
(EngineCore_DP0 pid=406356) 	mad.wide.s32 	%rd8, %r105, 2, %rd1;
(EngineCore_DP0 pid=406356) 	mad.wide.s32 	%rd9, %r104, 2, %rd1;
(EngineCore_DP0 pid=406356) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=406356) 	.loc	1 224 21                        // quant_slide_tuned_Llama3.2-3B.py:224:21
(EngineCore_DP0 pid=406356) 	// begin inline asm
(EngineCore_DP0 pid=406356) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=406356) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=406356) 	// end inline asm
(EngineCore_DP0 pid=406356) 	// begin inline asm
(EngineCore_DP0 pid=406356) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=406356) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=406356) 	// end inline asm
(EngineCore_DP0 pid=406356) 	.loc	1 225 79                        // quant_slide_tuned_Llama3.2-3B.py:225:79
(EngineCore_DP0 pid=406356) 	cvt.f32.bf16 	%r106, %rs24;
(EngineCore_DP0 pid=406356) 	cvt.f32.bf16 	%r107, %rs26;
(EngineCore_DP0 pid=406356) 	.loc	1 227 48                        // quant_slide_tuned_Llama3.2-3B.py:227:48
(EngineCore_DP0 pid=406356) 	or.b32 	%r108, %r105, 1;
(EngineCore_DP0 pid=406356) 	or.b32 	%r109, %r104, 1;
(EngineCore_DP0 pid=406356) 	.loc	1 227 53                        // quant_slide_tuned_Llama3.2-3B.py:227:53
(EngineCore_DP0 pid=406356) 	setp.lt.s32 	%p20, %r108, %r23;
(EngineCore_DP0 pid=406356) 	setp.lt.s32 	%p21, %r109, %r23;
(EngineCore_DP0 pid=406356) 	.loc	1 227 37                        // quant_slide_tuned_Llama3.2-3B.py:227:37
(EngineCore_DP0 pid=406356) 	and.pred 	%p11, %p17, %p20;
(EngineCore_DP0 pid=406356) 	and.pred 	%p12, %p17, %p21;
(EngineCore_DP0 pid=406356) 	.loc	1 226 39                        // quant_slide_tuned_Llama3.2-3B.py:226:39
(EngineCore_DP0 pid=406356) 	add.s64 	%rd10, %rd8, 2;
(EngineCore_DP0 pid=406356) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=406356) 	.loc	1 226 21                        // quant_slide_tuned_Llama3.2-3B.py:226:21
(EngineCore_DP0 pid=406356) 	// begin inline asm
(EngineCore_DP0 pid=406356) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=406356) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=406356) 	// end inline asm
(EngineCore_DP0 pid=406356) 	// begin inline asm
(EngineCore_DP0 pid=406356) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=406356) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=406356) 	// end inline asm
(EngineCore_DP0 pid=406356) 	.loc	1 227 79                        // quant_slide_tuned_Llama3.2-3B.py:227:79
(EngineCore_DP0 pid=406356) 	cvt.f32.bf16 	%r110, %rs28;
(EngineCore_DP0 pid=406356) 	cvt.f32.bf16 	%r111, %rs30;
(EngineCore_DP0 pid=406356) 	.loc	1 231 48                        // quant_slide_tuned_Llama3.2-3B.py:231:48
(EngineCore_DP0 pid=406356) 	add.s32 	%r112, %r105, 2;
(EngineCore_DP0 pid=406356) 	add.s32 	%r113, %r104, 2;
(EngineCore_DP0 pid=406356) 	add.s32 	%r114, %r105, 3;
(EngineCore_DP0 pid=406356) 	add.s32 	%r115, %r104, 3;
(EngineCore_DP0 pid=406356) 	.loc	1 231 53                        // quant_slide_tuned_Llama3.2-3B.py:231:53
(EngineCore_DP0 pid=406356) 	setp.lt.s32 	%p22, %r115, %r23;
(EngineCore_DP0 pid=406356) 	setp.lt.s32 	%p23, %r114, %r23;
(EngineCore_DP0 pid=406356) 	setp.lt.s32 	%p24, %r113, %r23;
(EngineCore_DP0 pid=406356) 	setp.lt.s32 	%p25, %r112, %r23;
(EngineCore_DP0 pid=406356) 	.loc	1 229 37                        // quant_slide_tuned_Llama3.2-3B.py:229:37
(EngineCore_DP0 pid=406356) 	and.pred 	%p13, %p17, %p25;
(EngineCore_DP0 pid=406356) 	and.pred 	%p14, %p17, %p24;
(EngineCore_DP0 pid=406356) 	.loc	1 228 39                        // quant_slide_tuned_Llama3.2-3B.py:228:39
(EngineCore_DP0 pid=406356) 	add.s64 	%rd12, %rd8, 4;
(EngineCore_DP0 pid=406356) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=406356) 	.loc	1 228 21                        // quant_slide_tuned_Llama3.2-3B.py:228:21
(EngineCore_DP0 pid=406356) 	// begin inline asm
(EngineCore_DP0 pid=406356) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=406356) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=406356) 	// end inline asm
(EngineCore_DP0 pid=406356) 	// begin inline asm
(EngineCore_DP0 pid=406356) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=406356) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=406356) 	// end inline asm
(EngineCore_DP0 pid=406356) 	.loc	1 229 79                        // quant_slide_tuned_Llama3.2-3B.py:229:79
(EngineCore_DP0 pid=406356) 	cvt.f32.bf16 	%r116, %rs32;
(EngineCore_DP0 pid=406356) 	cvt.f32.bf16 	%r117, %rs34;
(EngineCore_DP0 pid=406356) 	.loc	1 231 37                        // quant_slide_tuned_Llama3.2-3B.py:231:37
(EngineCore_DP0 pid=406356) 	and.pred 	%p15, %p17, %p23;
(EngineCore_DP0 pid=406356) 	and.pred 	%p16, %p17, %p22;
(EngineCore_DP0 pid=406356) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-3B.py:230:39
(EngineCore_DP0 pid=406356) 	add.s64 	%rd14, %rd8, 6;
(EngineCore_DP0 pid=406356) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=406356) 	.loc	1 230 21                        // quant_slide_tuned_Llama3.2-3B.py:230:21
(EngineCore_DP0 pid=406356) 	// begin inline asm
(EngineCore_DP0 pid=406356) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=406356) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=406356) 	// end inline asm
(EngineCore_DP0 pid=406356) 	// begin inline asm
(EngineCore_DP0 pid=406356) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=406356) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=406356) 	// end inline asm
(EngineCore_DP0 pid=406356) 	.loc	1 231 79                        // quant_slide_tuned_Llama3.2-3B.py:231:79
(EngineCore_DP0 pid=406356) 	cvt.f32.bf16 	%r118, %rs36;
(EngineCore_DP0 pid=406356) 	cvt.f32.bf16 	%r119, %rs38;
(EngineCore_DP0 pid=406356) 	.loc	1 233 27                        // quant_slide_tuned_Llama3.2-3B.py:233:27
(EngineCore_DP0 pid=406356) 	mul.f32 	%r120, %r14, %r106;
(EngineCore_DP0 pid=406356) 	mul.f32 	%r121, %r14, %r107;
(EngineCore_DP0 pid=406356) 	mov.b32 	%r122, 0f43E00000;
(EngineCore_DP0 pid=406356) 	.loc	1 233 48                        // quant_slide_tuned_Llama3.2-3B.py:233:48
(EngineCore_DP0 pid=406356) 	min.xorsign.abs.f32 	%r78, %r120, %r122;
(EngineCore_DP0 pid=406356) 	min.xorsign.abs.f32 	%r79, %r121, %r122;
(EngineCore_DP0 pid=406356) 	.loc	1 233 60                        // quant_slide_tuned_Llama3.2-3B.py:233:60
(EngineCore_DP0 pid=406356) 	// begin inline asm
(EngineCore_DP0 pid=406356) 	cvt.rn.satfinite.e4m3x2.f32  %rs40, %r79, %r78; 
(EngineCore_DP0 pid=406356) 
(EngineCore_DP0 pid=406356) 	// end inline asm
(EngineCore_DP0 pid=406356) 	shr.u16 	%rs44, %rs40, 8;
(EngineCore_DP0 pid=406356) 	.loc	1 234 27                        // quant_slide_tuned_Llama3.2-3B.py:234:27
(EngineCore_DP0 pid=406356) 	mul.f32 	%r123, %r14, %r110;
(EngineCore_DP0 pid=406356) 	mul.f32 	%r124, %r14, %r111;
(EngineCore_DP0 pid=406356) 	.loc	1 234 48                        // quant_slide_tuned_Llama3.2-3B.py:234:48
(EngineCore_DP0 pid=406356) 	min.xorsign.abs.f32 	%r80, %r123, %r122;
(EngineCore_DP0 pid=406356) 	min.xorsign.abs.f32 	%r81, %r124, %r122;
(EngineCore_DP0 pid=406356) 	.loc	1 234 60                        // quant_slide_tuned_Llama3.2-3B.py:234:60
(EngineCore_DP0 pid=406356) 	// begin inline asm
(EngineCore_DP0 pid=406356) 	cvt.rn.satfinite.e4m3x2.f32  %rs41, %r81, %r80; 
(EngineCore_DP0 pid=406356) 
(EngineCore_DP0 pid=406356) 	// end inline asm
(EngineCore_DP0 pid=406356) 	shr.u16 	%rs45, %rs41, 8;
(EngineCore_DP0 pid=406356) 	.loc	1 235 27                        // quant_slide_tuned_Llama3.2-3B.py:235:27
(EngineCore_DP0 pid=406356) 	mul.f32 	%r125, %r14, %r116;
(EngineCore_DP0 pid=406356) 	mul.f32 	%r126, %r14, %r117;
(EngineCore_DP0 pid=406356) 	.loc	1 235 48                        // quant_slide_tuned_Llama3.2-3B.py:235:48
(EngineCore_DP0 pid=406356) 	min.xorsign.abs.f32 	%r82, %r125, %r122;
(EngineCore_DP0 pid=406356) 	min.xorsign.abs.f32 	%r83, %r126, %r122;
(EngineCore_DP0 pid=406356) 	.loc	1 235 60                        // quant_slide_tuned_Llama3.2-3B.py:235:60
(EngineCore_DP0 pid=406356) 	// begin inline asm
(EngineCore_DP0 pid=406356) 	cvt.rn.satfinite.e4m3x2.f32  %rs42, %r83, %r82; 
(EngineCore_DP0 pid=406356) 
(EngineCore_DP0 pid=406356) 	// end inline asm
(EngineCore_DP0 pid=406356) 	shr.u16 	%rs46, %rs42, 8;
(EngineCore_DP0 pid=406356) 	.loc	1 236 27                        // quant_slide_tuned_Llama3.2-3B.py:236:27
(EngineCore_DP0 pid=406356) 	mul.f32 	%r127, %r14, %r118;
(EngineCore_DP0 pid=406356) 	mul.f32 	%r128, %r14, %r119;
(EngineCore_DP0 pid=406356) 	.loc	1 236 48                        // quant_slide_tuned_Llama3.2-3B.py:236:48
(EngineCore_DP0 pid=406356) 	min.xorsign.abs.f32 	%r84, %r127, %r122;
(EngineCore_DP0 pid=406356) 	min.xorsign.abs.f32 	%r85, %r128, %r122;
(EngineCore_DP0 pid=406356) 	.loc	1 236 60                        // quant_slide_tuned_Llama3.2-3B.py:236:60
(EngineCore_DP0 pid=406356) 	// begin inline asm
(EngineCore_DP0 pid=406356) 	cvt.rn.satfinite.e4m3x2.f32  %rs43, %r85, %r84; 
(EngineCore_DP0 pid=406356) 
(EngineCore_DP0 pid=406356) 	// end inline asm
(EngineCore_DP0 pid=406356) 	shr.u16 	%rs47, %rs43, 8;
(EngineCore_DP0 pid=406356) 	.loc	1 238 45                        // quant_slide_tuned_Llama3.2-3B.py:238:45
(EngineCore_DP0 pid=406356) 	cvt.u32.u16 	%r129, %rs40;
(EngineCore_DP0 pid=406356) 	and.b32 	%r130, %r129, 255;
(EngineCore_DP0 pid=406356) 	cvt.u32.u16 	%r131, %rs44;
(EngineCore_DP0 pid=406356) 	.loc	1 240 45                        // quant_slide_tuned_Llama3.2-3B.py:240:45
(EngineCore_DP0 pid=406356) 	cvt.u32.u16 	%r132, %rs42;
(EngineCore_DP0 pid=406356) 	and.b32 	%r133, %r132, 255;
(EngineCore_DP0 pid=406356) 	cvt.u32.u16 	%r134, %rs46;
(EngineCore_DP0 pid=406356) 	.loc	1 241 45                        // quant_slide_tuned_Llama3.2-3B.py:241:45
(EngineCore_DP0 pid=406356) 	cvt.u32.u16 	%r135, %rs43;
(EngineCore_DP0 pid=406356) 	cvt.u32.u16 	%r136, %rs47;
(EngineCore_DP0 pid=406356) 	.loc	1 243 30                        // quant_slide_tuned_Llama3.2-3B.py:243:30
(EngineCore_DP0 pid=406356) 	and.b16 	%rs48, %rs41, 255;
(EngineCore_DP0 pid=406356) 	mul.wide.u16 	%r137, %rs48, 256;
(EngineCore_DP0 pid=406356) 	mul.wide.u16 	%r138, %rs45, 256;
(EngineCore_DP0 pid=406356) 	.loc	1 243 24                        // quant_slide_tuned_Llama3.2-3B.py:243:24
(EngineCore_DP0 pid=406356) 	or.b32 	%r139, %r137, %r130;
(EngineCore_DP0 pid=406356) 	or.b32 	%r140, %r138, %r131;
(EngineCore_DP0 pid=406356) 	.loc	1 243 42                        // quant_slide_tuned_Llama3.2-3B.py:243:42
(EngineCore_DP0 pid=406356) 	shl.b32 	%r141, %r133, 16;
(EngineCore_DP0 pid=406356) 	shl.b32 	%r142, %r134, 16;
(EngineCore_DP0 pid=406356) 	.loc	1 243 36                        // quant_slide_tuned_Llama3.2-3B.py:243:36
(EngineCore_DP0 pid=406356) 	or.b32 	%r143, %r139, %r141;
(EngineCore_DP0 pid=406356) 	or.b32 	%r144, %r140, %r142;
(EngineCore_DP0 pid=406356) 	.loc	1 243 55                        // quant_slide_tuned_Llama3.2-3B.py:243:55
(EngineCore_DP0 pid=406356) 	shl.b32 	%r145, %r135, 24;
(EngineCore_DP0 pid=406356) 	shl.b32 	%r146, %r136, 24;
(EngineCore_DP0 pid=406356) 	.loc	1 243 49                        // quant_slide_tuned_Llama3.2-3B.py:243:49
(EngineCore_DP0 pid=406356) 	or.b32 	%r86, %r143, %r145;
(EngineCore_DP0 pid=406356) 	or.b32 	%r87, %r144, %r146;
(EngineCore_DP0 pid=406356) 	.loc	1 244 29                        // quant_slide_tuned_Llama3.2-3B.py:244:29
(EngineCore_DP0 pid=406356) 	mad.wide.s32 	%rd16, %r88, 4, %rd2;
(EngineCore_DP0 pid=406356) 	.loc	1 244 39                        // quant_slide_tuned_Llama3.2-3B.py:244:39
(EngineCore_DP0 pid=406356) 	// begin inline asm
(EngineCore_DP0 pid=406356) 	@%p17 st.global.v2.b32 [ %rd16 + 0 ], { %r86, %r87 };
(EngineCore_DP0 pid=406356) 	// end inline asm
(EngineCore_DP0 pid=406356) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=406356) 	add.s32 	%r150, %r150, 1024;
(EngineCore_DP0 pid=406356) 	setp.lt.s32 	%p26, %r150, %r15;
(EngineCore_DP0 pid=406356) 	@%p26 bra 	$L__BB0_6;
(EngineCore_DP0 pid=406356) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=406356) 	.loc	1 215 4                         // quant_slide_tuned_Llama3.2-3B.py:215:4
(EngineCore_DP0 pid=406356) 	ret;
(EngineCore_DP0 pid=406356) $L__tmp3:
(EngineCore_DP0 pid=406356) $L__func_end0:
(EngineCore_DP0 pid=406356)                                         // -- End function
(EngineCore_DP0 pid=406356) }
(EngineCore_DP0 pid=406356) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py"
(EngineCore_DP0 pid=406356) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=406356) 	.section	.debug_abbrev
(EngineCore_DP0 pid=406356) 	{
(EngineCore_DP0 pid=406356) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=406356) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=406356) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=406356) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=406356) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=406356) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=406356) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=406356) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=406356) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=406356) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=406356) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=406356) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=406356) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=406356) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=406356) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=406356) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=406356) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=406356) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=406356) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=406356) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=406356) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=406356) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=406356) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=406356) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=406356) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=406356) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=406356) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=406356) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=406356) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=406356) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=406356) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=406356) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=406356) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=406356) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=406356) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=406356) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=406356) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=406356) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=406356) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=406356) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=406356) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=406356) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=406356) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=406356) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=406356) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=406356) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=406356) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=406356) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=406356) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=406356) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=406356) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=406356) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=406356) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=406356) 	}
(EngineCore_DP0 pid=406356) 	.section	.debug_info
(EngineCore_DP0 pid=406356) 	{
(EngineCore_DP0 pid=406356) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=406356) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=406356) .b8 0
(EngineCore_DP0 pid=406356) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=406356) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=406356) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=406356) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=406356) .b8 114
(EngineCore_DP0 pid=406356) .b8 105
(EngineCore_DP0 pid=406356) .b8 116
(EngineCore_DP0 pid=406356) .b8 111
(EngineCore_DP0 pid=406356) .b8 110
(EngineCore_DP0 pid=406356) .b8 0
(EngineCore_DP0 pid=406356) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=406356) .b8 0
(EngineCore_DP0 pid=406356) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=406356) .b8 117
(EngineCore_DP0 pid=406356) .b8 97
(EngineCore_DP0 pid=406356) .b8 110
(EngineCore_DP0 pid=406356) .b8 116
(EngineCore_DP0 pid=406356) .b8 95
(EngineCore_DP0 pid=406356) .b8 115
(EngineCore_DP0 pid=406356) .b8 108
(EngineCore_DP0 pid=406356) .b8 105
(EngineCore_DP0 pid=406356) .b8 100
(EngineCore_DP0 pid=406356) .b8 101
(EngineCore_DP0 pid=406356) .b8 95
(EngineCore_DP0 pid=406356) .b8 116
(EngineCore_DP0 pid=406356) .b8 117
(EngineCore_DP0 pid=406356) .b8 110
(EngineCore_DP0 pid=406356) .b8 101
(EngineCore_DP0 pid=406356) .b8 100
(EngineCore_DP0 pid=406356) .b8 95
(EngineCore_DP0 pid=406356) .b8 76
(EngineCore_DP0 pid=406356) .b8 108
(EngineCore_DP0 pid=406356) .b8 97
(EngineCore_DP0 pid=406356) .b8 109
(EngineCore_DP0 pid=406356) .b8 97
(EngineCore_DP0 pid=406356) .b8 51
(EngineCore_DP0 pid=406356) .b8 46
(EngineCore_DP0 pid=406356) .b8 50
(EngineCore_DP0 pid=406356) .b8 45
(EngineCore_DP0 pid=406356) .b8 51
(EngineCore_DP0 pid=406356) .b8 66
(EngineCore_DP0 pid=406356) .b8 46
(EngineCore_DP0 pid=406356) .b8 112
(EngineCore_DP0 pid=406356) .b8 121
(EngineCore_DP0 pid=406356) .b8 0
(EngineCore_DP0 pid=406356) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=406356) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=406356) .b8 114
(EngineCore_DP0 pid=406356) .b8 111
(EngineCore_DP0 pid=406356) .b8 111
(EngineCore_DP0 pid=406356) .b8 116
(EngineCore_DP0 pid=406356) .b8 47
(EngineCore_DP0 pid=406356) .b8 118
(EngineCore_DP0 pid=406356) .b8 108
(EngineCore_DP0 pid=406356) .b8 108
(EngineCore_DP0 pid=406356) .b8 109
(EngineCore_DP0 pid=406356) .b8 98
(EngineCore_DP0 pid=406356) .b8 101
(EngineCore_DP0 pid=406356) .b8 110
(EngineCore_DP0 pid=406356) .b8 99
(EngineCore_DP0 pid=406356) .b8 104
(EngineCore_DP0 pid=406356) .b8 47
(EngineCore_DP0 pid=406356) .b8 115
(EngineCore_DP0 pid=406356) .b8 108
(EngineCore_DP0 pid=406356) .b8 105
(EngineCore_DP0 pid=406356) .b8 100
(EngineCore_DP0 pid=406356) .b8 101
(EngineCore_DP0 pid=406356) .b8 115
(EngineCore_DP0 pid=406356) .b8 112
(EngineCore_DP0 pid=406356) .b8 97
(EngineCore_DP0 pid=406356) .b8 114
(EngineCore_DP0 pid=406356) .b8 115
(EngineCore_DP0 pid=406356) .b8 101
(EngineCore_DP0 pid=406356) .b8 47
(EngineCore_DP0 pid=406356) .b8 99
(EngineCore_DP0 pid=406356) .b8 115
(EngineCore_DP0 pid=406356) .b8 114
(EngineCore_DP0 pid=406356) .b8 99
(EngineCore_DP0 pid=406356) .b8 47
(EngineCore_DP0 pid=406356) .b8 102
(EngineCore_DP0 pid=406356) .b8 117
(EngineCore_DP0 pid=406356) .b8 115
(EngineCore_DP0 pid=406356) .b8 101
(EngineCore_DP0 pid=406356) .b8 100
(EngineCore_DP0 pid=406356) .b8 95
(EngineCore_DP0 pid=406356) .b8 113
(EngineCore_DP0 pid=406356) .b8 117
(EngineCore_DP0 pid=406356) .b8 97
(EngineCore_DP0 pid=406356) .b8 110
(EngineCore_DP0 pid=406356) .b8 116
(EngineCore_DP0 pid=406356) .b8 95
(EngineCore_DP0 pid=406356) .b8 115
(EngineCore_DP0 pid=406356) .b8 108
(EngineCore_DP0 pid=406356) .b8 105
(EngineCore_DP0 pid=406356) .b8 100
(EngineCore_DP0 pid=406356) .b8 101
(EngineCore_DP0 pid=406356) .b8 95
(EngineCore_DP0 pid=406356) .b8 116
(EngineCore_DP0 pid=406356) .b8 114
(EngineCore_DP0 pid=406356) .b8 105
(EngineCore_DP0 pid=406356) .b8 116
(EngineCore_DP0 pid=406356) .b8 111
(EngineCore_DP0 pid=406356) .b8 110
(EngineCore_DP0 pid=406356) .b8 47
(EngineCore_DP0 pid=406356) .b8 98
(EngineCore_DP0 pid=406356) .b8 117
(EngineCore_DP0 pid=406356) .b8 105
(EngineCore_DP0 pid=406356) .b8 108
(EngineCore_DP0 pid=406356) .b8 100
(EngineCore_DP0 pid=406356) .b8 47
(EngineCore_DP0 pid=406356) .b8 71
(EngineCore_DP0 pid=406356) .b8 66
(EngineCore_DP0 pid=406356) .b8 49
(EngineCore_DP0 pid=406356) .b8 48
(EngineCore_DP0 pid=406356) .b8 95
(EngineCore_DP0 pid=406356) .b8 99
(EngineCore_DP0 pid=406356) .b8 99
(EngineCore_DP0 pid=406356) .b8 49
(EngineCore_DP0 pid=406356) .b8 50
(EngineCore_DP0 pid=406356) .b8 49
(EngineCore_DP0 pid=406356) .b8 95
(EngineCore_DP0 pid=406356) .b8 112
(EngineCore_DP0 pid=406356) .b8 121
(EngineCore_DP0 pid=406356) .b8 51
(EngineCore_DP0 pid=406356) .b8 49
(EngineCore_DP0 pid=406356) .b8 50
(EngineCore_DP0 pid=406356) .b8 95
(EngineCore_DP0 pid=406356) .b8 99
(EngineCore_DP0 pid=406356) .b8 117
(EngineCore_DP0 pid=406356) .b8 49
(EngineCore_DP0 pid=406356) .b8 50
(EngineCore_DP0 pid=406356) .b8 57
(EngineCore_DP0 pid=406356) .b8 95
(EngineCore_DP0 pid=406356) .b8 97
(EngineCore_DP0 pid=406356) .b8 97
(EngineCore_DP0 pid=406356) .b8 114
(EngineCore_DP0 pid=406356) .b8 99
(EngineCore_DP0 pid=406356) .b8 104
(EngineCore_DP0 pid=406356) .b8 54
(EngineCore_DP0 pid=406356) .b8 52
(EngineCore_DP0 pid=406356) .b8 0
(EngineCore_DP0 pid=406356) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=406356) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=406356) .b8 113
(EngineCore_DP0 pid=406356) .b8 117
(EngineCore_DP0 pid=406356) .b8 97
(EngineCore_DP0 pid=406356) .b8 110
(EngineCore_DP0 pid=406356) .b8 116
(EngineCore_DP0 pid=406356) .b8 95
(EngineCore_DP0 pid=406356) .b8 115
(EngineCore_DP0 pid=406356) .b8 108
(EngineCore_DP0 pid=406356) .b8 105
(EngineCore_DP0 pid=406356) .b8 100
(EngineCore_DP0 pid=406356) .b8 101
(EngineCore_DP0 pid=406356) .b8 95
(EngineCore_DP0 pid=406356) .b8 102
(EngineCore_DP0 pid=406356) .b8 112
(EngineCore_DP0 pid=406356) .b8 56
(EngineCore_DP0 pid=406356) .b8 95
(EngineCore_DP0 pid=406356) .b8 107
(EngineCore_DP0 pid=406356) .b8 101
(EngineCore_DP0 pid=406356) .b8 114
(EngineCore_DP0 pid=406356) .b8 110
(EngineCore_DP0 pid=406356) .b8 101
(EngineCore_DP0 pid=406356) .b8 108
(EngineCore_DP0 pid=406356) .b8 0
(EngineCore_DP0 pid=406356) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=406356) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=406356) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=406356) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=406356) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=406356) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=406356) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=406356) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=406356) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=406356) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=406356) .b8 205                                 // DW_AT_call_line
(EngineCore_DP0 pid=406356) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=406356) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=406356) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=406356) 	}
(EngineCore_DP0 pid=406356) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=406356) 
(EngineCore_DP0 pid=406356) ================================================================
(EngineCore_DP0 pid=406356) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=406356) 
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpk_jgf5ld.ptx', '-o', '/tmp/tmpk_jgf5ld.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866] 
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866] 
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866] 
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpk_jgf5ld.ptx -o /tmp/tmpk_jgf5ld.ptx.o
(EngineCore_DP0 pid=406356) ERROR 01-25 20:17:20 [core.py:866] 

STDERR:
[2026-01-25 20:16:49] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:16:49] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:16:49] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:16:49] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:16:49] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:16:49] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:16:49] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:16:49] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:16:49] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:16:49] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:16:49] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:16:49] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:16:49] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:16:49] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:16:53] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:16:53] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:16:53] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:16:53] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:16:53] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:16:53] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:16:53] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:16:53] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:16:53] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:16:53] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:16:53] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:16:53] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:16:53] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:16:53] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=406356) [2026-01-25 20:16:54] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=406356) [2026-01-25 20:16:54] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=406356) [2026-01-25 20:16:54] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=406356) [2026-01-25 20:16:54] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=406356) [2026-01-25 20:16:54] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=406356) [2026-01-25 20:16:54] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=406356) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=406356) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:24<00:00, 24.77s/it]
(EngineCore_DP0 pid=406356) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:24<00:00, 24.77s/it]
(EngineCore_DP0 pid=406356) 
(EngineCore_DP0 pid=406356) [2026-01-25 20:17:19] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4928] -> 1D uint8
(EngineCore_DP0 pid=406356) [2026-01-25 20:17:19] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15810560 bytes
(EngineCore_DP0 pid=406356) [2026-01-25 20:17:19] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4928] -> 1D uint8
(EngineCore_DP0 pid=406356) [2026-01-25 20:17:19] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9486336 bytes
(EngineCore_DP0 pid=406356) [2026-01-25 20:17:19] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4928] -> 1D uint8
(EngineCore_DP0 pid=406356) [2026-01-25 20:17:19] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 50593792 bytes
(EngineCore_DP0 pid=406356) [2026-01-25 20:17:19] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 13120] -> 1D uint8
(EngineCore_DP0 pid=406356) [2026-01-25 20:17:19] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 25214976 bytes
(EngineCore_DP0 pid=406356) Process EngineCore_DP0:
(EngineCore_DP0 pid=406356) Traceback (most recent call last):
(EngineCore_DP0 pid=406356)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=406356)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=406356)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=406356)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=406356) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpk_jgf5ld.ptx', '-o', '/tmp/tmpk_jgf5ld.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=406356) 
(EngineCore_DP0 pid=406356) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=406356) 
(EngineCore_DP0 pid=406356) Traceback (most recent call last):
(EngineCore_DP0 pid=406356)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=406356)     self.run()
(EngineCore_DP0 pid=406356)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=406356)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=406356)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=406356)     raise e
(EngineCore_DP0 pid=406356)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=406356)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=406356)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=406356)     super().__init__(
(EngineCore_DP0 pid=406356)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=406356)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=406356)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=406356)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=406356)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=406356)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=406356)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=406356)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=406356)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=406356)     return func(*args, **kwargs)
(EngineCore_DP0 pid=406356)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=406356)     return func(*args, **kwargs)
(EngineCore_DP0 pid=406356)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=406356)     self.model_runner.profile_run()
(EngineCore_DP0 pid=406356)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=406356)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=406356)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=406356)     return func(*args, **kwargs)
(EngineCore_DP0 pid=406356)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=406356)     outputs = self.model(
(EngineCore_DP0 pid=406356)               ^^^^^^^^^^^
(EngineCore_DP0 pid=406356)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=406356)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=406356)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=406356)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=406356)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=406356)     model_output = self.model(
(EngineCore_DP0 pid=406356)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=406356)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=406356)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=406356)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=406356)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=406356)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=406356)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=406356)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=406356)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=406356)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=406356)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=406356)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=406356)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=406356)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=406356)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=406356)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=406356)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=406356)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=406356)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=406356)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=406356)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=406356)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=406356)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=406356)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=406356)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=406356)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=406356)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=406356)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=406356)     return self._linear_fn(
(EngineCore_DP0 pid=406356)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=406356)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=406356)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=406356)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=406356)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=406356)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=406356)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=406356)     return fn(input, L)
(EngineCore_DP0 pid=406356)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=406356)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=406356)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=406356)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=406356)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=406356)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=406356)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=406356)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=406356)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=406356)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=406356)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=406356)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=406356)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=406356)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=406356)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=406356)     raise PTXASError(error)
(EngineCore_DP0 pid=406356) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=406356) `ptxas` stderr:
(EngineCore_DP0 pid=406356) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=406356) 
(EngineCore_DP0 pid=406356) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpk_jgf5ld.ptx -o /tmp/tmpk_jgf5ld.ptx.o
(EngineCore_DP0 pid=406356) 
[rank0]:[W125 20:17:21.292835499 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=4096

========== M=8192 ==========
Time: 2026-01-25 20:17:22
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-3B-FP8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:17:29 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 20:17:29 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=407093) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=407093) 
(EngineCore_DP0 pid=407093) 
(EngineCore_DP0 pid=407093) ================================================================
(EngineCore_DP0 pid=407093) Internal Triton PTX codegen error
(EngineCore_DP0 pid=407093) `ptxas` stderr:
(EngineCore_DP0 pid=407093) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=407093) 
(EngineCore_DP0 pid=407093) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpr46b1zuq.ptx -o /tmp/tmpr46b1zuq.ptx.o
(EngineCore_DP0 pid=407093) 
(EngineCore_DP0 pid=407093) 
(EngineCore_DP0 pid=407093) //
(EngineCore_DP0 pid=407093) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=407093) //
(EngineCore_DP0 pid=407093) 
(EngineCore_DP0 pid=407093) .version 8.7
(EngineCore_DP0 pid=407093) .target sm_121a
(EngineCore_DP0 pid=407093) .address_size 64
(EngineCore_DP0 pid=407093) 
(EngineCore_DP0 pid=407093) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=407093) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=407093)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=407093) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=407093) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=407093) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=407093) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=407093) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=407093) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=407093) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=407093) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=407093) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=407093) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=407093) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=407093) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=407093) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=407093) )
(EngineCore_DP0 pid=407093) .reqntid 512
(EngineCore_DP0 pid=407093) {
(EngineCore_DP0 pid=407093) 	.reg .pred 	%p<29>;
(EngineCore_DP0 pid=407093) 	.reg .b16 	%rs<73>;
(EngineCore_DP0 pid=407093) 	.reg .b32 	%r<160>;
(EngineCore_DP0 pid=407093) 	.reg .b64 	%rd<18>;
(EngineCore_DP0 pid=407093) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=407093) $L__func_begin0:
(EngineCore_DP0 pid=407093) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=407093) 
(EngineCore_DP0 pid=407093) // %bb.0:
(EngineCore_DP0 pid=407093) 	ld.param.b32 	%r25, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=407093) 	ld.param.b32 	%r24, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=407093) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=407093) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=407093) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=407093) $L__tmp0:
(EngineCore_DP0 pid=407093) 	.loc	1 191 24                        // quant_slide_tuned_Llama3.2-3B.py:191:24
(EngineCore_DP0 pid=407093) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=407093) 	ld.param.b32 	%r27, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=407093) 	.loc	1 196 26                        // quant_slide_tuned_Llama3.2-3B.py:196:26
(EngineCore_DP0 pid=407093) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=407093) 	.loc	1 196 20                        // quant_slide_tuned_Llama3.2-3B.py:196:20
(EngineCore_DP0 pid=407093) 	mad.wide.s32 	%rd1, %r28, 2, %rd4;
(EngineCore_DP0 pid=407093) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=407093) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=407093) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=407093) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=407093) 	setp.lt.s32 	%p1, %r24, 1;
(EngineCore_DP0 pid=407093) 	mov.b32 	%r158, 0f2B8CBCCC;
(EngineCore_DP0 pid=407093) 	setp.eq.b32 	%p28, %r2, 0;
(EngineCore_DP0 pid=407093) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=407093) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=407093) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=407093) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=407093) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=407093) 	shr.u32 	%r37, %r2, 3;
(EngineCore_DP0 pid=407093) 	and.b32 	%r38, %r37, 60;
(EngineCore_DP0 pid=407093) 	mov.b32 	%r39, global_smem;
(EngineCore_DP0 pid=407093) 	add.s32 	%r57, %r39, %r38;
(EngineCore_DP0 pid=407093) 	shl.b32 	%r40, %r2, 2;
(EngineCore_DP0 pid=407093) 	add.s32 	%r60, %r39, %r40;
(EngineCore_DP0 pid=407093) 	mov.b32 	%r45, 0;
(EngineCore_DP0 pid=407093) 	mov.b32 	%r156, 0f00000000;
(EngineCore_DP0 pid=407093) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=407093) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=407093) 	mov.b32 	%r157, %r45;
(EngineCore_DP0 pid=407093) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=407093) 	.loc	1 202 19                        // quant_slide_tuned_Llama3.2-3B.py:202:19
(EngineCore_DP0 pid=407093) 	add.s32 	%r63, %r4, %r157;
(EngineCore_DP0 pid=407093) 	.loc	1 203 22                        // quant_slide_tuned_Llama3.2-3B.py:203:22
(EngineCore_DP0 pid=407093) 	add.s32 	%r64, %r63, 4096;
(EngineCore_DP0 pid=407093) 	setp.lt.s32 	%p2, %r63, %r23;
(EngineCore_DP0 pid=407093) 	setp.lt.s32 	%p3, %r64, %r23;
(EngineCore_DP0 pid=407093) 	.loc	1 204 29                        // quant_slide_tuned_Llama3.2-3B.py:204:29
(EngineCore_DP0 pid=407093) 	mad.wide.s32 	%rd6, %r63, 2, %rd1;
(EngineCore_DP0 pid=407093) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=407093) 	.loc	1 204 21                        // quant_slide_tuned_Llama3.2-3B.py:204:21
(EngineCore_DP0 pid=407093) 	// begin inline asm
(EngineCore_DP0 pid=407093) 	mov.u32 %r41, %r45;
(EngineCore_DP0 pid=407093) 	mov.u32 %r42, %r45;
(EngineCore_DP0 pid=407093) 	mov.u32 %r43, %r45;
(EngineCore_DP0 pid=407093) 	mov.u32 %r44, %r45;
(EngineCore_DP0 pid=407093) 	@%p2 ld.global.v4.b32 { %r41, %r42, %r43, %r44 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=407093) 	// end inline asm
(EngineCore_DP0 pid=407093) 	mov.b32 	{%rs1, %rs2}, %r41;
(EngineCore_DP0 pid=407093) 	mov.b32 	{%rs3, %rs4}, %r42;
(EngineCore_DP0 pid=407093) 	mov.b32 	{%rs5, %rs6}, %r43;
(EngineCore_DP0 pid=407093) 	mov.b32 	{%rs7, %rs8}, %r44;
(EngineCore_DP0 pid=407093) 	// begin inline asm
(EngineCore_DP0 pid=407093) 	mov.u32 %r49, %r45;
(EngineCore_DP0 pid=407093) 	mov.u32 %r50, %r45;
(EngineCore_DP0 pid=407093) 	mov.u32 %r51, %r45;
(EngineCore_DP0 pid=407093) 	mov.u32 %r52, %r45;
(EngineCore_DP0 pid=407093) 	@%p3 ld.global.v4.b32 { %r49, %r50, %r51, %r52 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=407093) 	// end inline asm
(EngineCore_DP0 pid=407093) 	mov.b32 	{%rs9, %rs10}, %r49;
(EngineCore_DP0 pid=407093) 	mov.b32 	{%rs11, %rs12}, %r50;
(EngineCore_DP0 pid=407093) 	mov.b32 	{%rs13, %rs14}, %r51;
(EngineCore_DP0 pid=407093) 	mov.b32 	{%rs15, %rs16}, %r52;
(EngineCore_DP0 pid=407093) 	.loc	1 205 50                        // quant_slide_tuned_Llama3.2-3B.py:205:50
(EngineCore_DP0 pid=407093) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=407093) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=407093) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=407093) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=407093) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=407093) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=407093) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=407093) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=407093) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=407093) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=407093) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=407093) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=407093) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=407093) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=407093) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=407093) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=407093) $L__tmp1:
(EngineCore_DP0 pid=407093) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=407093) 	bar.sync 	0;
(EngineCore_DP0 pid=407093) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=407093) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=407093) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=407093) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=407093) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=407093) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=407093) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=407093) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=407093) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=407093) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=407093) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=407093) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=407093) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=407093) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=407093) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=407093) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=407093) 	cvt.f32.bf16 	%r65, %rs47;
(EngineCore_DP0 pid=407093) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=407093) 	shfl.sync.bfly.b32 	%r66, %r65, 16, 31, -1;
(EngineCore_DP0 pid=407093) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=407093) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=407093) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=407093) 	shfl.sync.bfly.b32 	%r68, %r67, 8, 31, -1;
(EngineCore_DP0 pid=407093) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=407093) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=407093) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=407093) 	shfl.sync.bfly.b32 	%r70, %r69, 4, 31, -1;
(EngineCore_DP0 pid=407093) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=407093) 	max.f32 	%r71, %r69, %r70;
(EngineCore_DP0 pid=407093) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=407093) 	shfl.sync.bfly.b32 	%r72, %r71, 2, 31, -1;
(EngineCore_DP0 pid=407093) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=407093) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=407093) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=407093) 	shfl.sync.bfly.b32 	%r74, %r73, 1, 31, -1;
(EngineCore_DP0 pid=407093) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=407093) 	max.f32 	%r58, %r73, %r74;
(EngineCore_DP0 pid=407093) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=407093) 	// begin inline asm
(EngineCore_DP0 pid=407093) 	@%p4 st.shared.b32 [ %r57 + 0 ], %r58;
(EngineCore_DP0 pid=407093) 	// end inline asm
(EngineCore_DP0 pid=407093) 	bar.sync 	0;
(EngineCore_DP0 pid=407093) 	// begin inline asm
(EngineCore_DP0 pid=407093) 	@%p5 ld.shared.b32 %r59, [ %r60 + 0 ];
(EngineCore_DP0 pid=407093) 	// end inline asm
(EngineCore_DP0 pid=407093) 	shfl.sync.bfly.b32 	%r75, %r59, 8, 31, -1;
(EngineCore_DP0 pid=407093) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=407093) 	max.f32 	%r76, %r59, %r75;
(EngineCore_DP0 pid=407093) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=407093) 	shfl.sync.bfly.b32 	%r77, %r76, 4, 31, -1;
(EngineCore_DP0 pid=407093) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=407093) 	max.f32 	%r78, %r76, %r77;
(EngineCore_DP0 pid=407093) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=407093) 	shfl.sync.bfly.b32 	%r79, %r78, 2, 31, -1;
(EngineCore_DP0 pid=407093) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=407093) 	max.f32 	%r80, %r78, %r79;
(EngineCore_DP0 pid=407093) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=407093) 	shfl.sync.bfly.b32 	%r81, %r80, 1, 31, -1;
(EngineCore_DP0 pid=407093) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=407093) 	max.f32 	%r62, %r80, %r81;
(EngineCore_DP0 pid=407093) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=407093) 	// begin inline asm
(EngineCore_DP0 pid=407093) 	@%p28 st.shared.b32 [ %r60 + 0 ], %r62;
(EngineCore_DP0 pid=407093) 	// end inline asm
(EngineCore_DP0 pid=407093) 	bar.sync 	0;
(EngineCore_DP0 pid=407093) 	ld.shared.b32 	%r82, [global_smem];
(EngineCore_DP0 pid=407093) $L__tmp2:
(EngineCore_DP0 pid=407093) 	.loc	1 205 36                        // quant_slide_tuned_Llama3.2-3B.py:205:36
(EngineCore_DP0 pid=407093) 	max.f32 	%r156, %r156, %r82;
(EngineCore_DP0 pid=407093) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=407093) 	add.s32 	%r157, %r157, 8192;
(EngineCore_DP0 pid=407093) 	setp.lt.s32 	%p7, %r157, %r24;
(EngineCore_DP0 pid=407093) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=407093) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=407093) 	.loc	1 207 32                        // quant_slide_tuned_Llama3.2-3B.py:207:32
(EngineCore_DP0 pid=407093) 	max.f32 	%r158, %r156, 0f2B8CBCCC;
(EngineCore_DP0 pid=407093) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=407093) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-3B.py:0:32
(EngineCore_DP0 pid=407093) 	mov.b32 	%r84, 0f43E00000;
(EngineCore_DP0 pid=407093) 	.loc	1 208 32                        // quant_slide_tuned_Llama3.2-3B.py:208:32
(EngineCore_DP0 pid=407093) 	div.full.f32 	%r85, %r158, %r84;
(EngineCore_DP0 pid=407093) 	.loc	1 208 41                        // quant_slide_tuned_Llama3.2-3B.py:208:41
(EngineCore_DP0 pid=407093) 	max.f32 	%r83, %r85, 0f36924925;
(EngineCore_DP0 pid=407093) 	.loc	1 210 25                        // quant_slide_tuned_Llama3.2-3B.py:210:25
(EngineCore_DP0 pid=407093) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=407093) 	.loc	1 210 30                        // quant_slide_tuned_Llama3.2-3B.py:210:30
(EngineCore_DP0 pid=407093) 	// begin inline asm
(EngineCore_DP0 pid=407093) 	@%p28 st.global.b32 [ %rd8 + 0 ], { %r83 };
(EngineCore_DP0 pid=407093) 	// end inline asm
(EngineCore_DP0 pid=407093) 	.loc	1 213 29                        // quant_slide_tuned_Llama3.2-3B.py:213:29
(EngineCore_DP0 pid=407093) 	shl.b32 	%r15, %r25, 2;
(EngineCore_DP0 pid=407093) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=407093) 	setp.lt.s32 	%p9, %r15, 1;
(EngineCore_DP0 pid=407093) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=407093) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=407093) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-3B.py:0:41
(EngineCore_DP0 pid=407093) 	ld.param.b32 	%r29, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=407093) 	shr.s32 	%r30, %r29, 31;
(EngineCore_DP0 pid=407093) 	shr.u32 	%r31, %r30, 30;
(EngineCore_DP0 pid=407093) 	add.s32 	%r32, %r29, %r31;
(EngineCore_DP0 pid=407093) 	shr.s32 	%r33, %r32, 2;
(EngineCore_DP0 pid=407093) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=407093) 	mul.lo.s32 	%r34, %r33, %r1;
(EngineCore_DP0 pid=407093) 	mad.wide.s32 	%rd2, %r34, 4, %rd5;
(EngineCore_DP0 pid=407093) 	div.full.f32 	%r14, %r84, %r158;
(EngineCore_DP0 pid=407093) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=407093) 	mov.b32 	%r159, 0;
(EngineCore_DP0 pid=407093) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=407093)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=407093) 	.loc	1 216 31                        // quant_slide_tuned_Llama3.2-3B.py:216:31
(EngineCore_DP0 pid=407093) 	add.s32 	%r97, %r16, %r159;
(EngineCore_DP0 pid=407093) 	.loc	1 217 30                        // quant_slide_tuned_Llama3.2-3B.py:217:30
(EngineCore_DP0 pid=407093) 	add.s32 	%r98, %r97, 1;
(EngineCore_DP0 pid=407093) 	setp.lt.s32 	%p18, %r97, %r15;
(EngineCore_DP0 pid=407093) 	.loc	1 220 24                        // quant_slide_tuned_Llama3.2-3B.py:220:24
(EngineCore_DP0 pid=407093) 	shr.s32 	%r99, %r97, 31;
(EngineCore_DP0 pid=407093) 	shr.u32 	%r100, %r99, 30;
(EngineCore_DP0 pid=407093) 	add.s32 	%r101, %r97, %r100;
(EngineCore_DP0 pid=407093) 	shr.s32 	%r102, %r101, 2;
(EngineCore_DP0 pid=407093) 	.loc	1 221 23                        // quant_slide_tuned_Llama3.2-3B.py:221:23
(EngineCore_DP0 pid=407093) 	shr.s32 	%r103, %r98, 31;
(EngineCore_DP0 pid=407093) 	shr.u32 	%r104, %r103, 30;
(EngineCore_DP0 pid=407093) 	add.s32 	%r105, %r98, %r104;
(EngineCore_DP0 pid=407093) 	and.b32 	%r106, %r105, 2147483644;
(EngineCore_DP0 pid=407093) 	sub.s32 	%r107, %r98, %r106;
(EngineCore_DP0 pid=407093) 	and.b32 	%r108, %r101, 2147483644;
(EngineCore_DP0 pid=407093) 	sub.s32 	%r109, %r97, %r108;
(EngineCore_DP0 pid=407093) 	.loc	1 222 22                        // quant_slide_tuned_Llama3.2-3B.py:222:22
(EngineCore_DP0 pid=407093) 	mul.lo.s32 	%r110, %r102, 10;
(EngineCore_DP0 pid=407093) 	.loc	1 222 30                        // quant_slide_tuned_Llama3.2-3B.py:222:30
(EngineCore_DP0 pid=407093) 	shl.b32 	%r111, %r109, 1;
(EngineCore_DP0 pid=407093) 	shl.b32 	%r112, %r107, 1;
(EngineCore_DP0 pid=407093) 	.loc	1 222 26                        // quant_slide_tuned_Llama3.2-3B.py:222:26
(EngineCore_DP0 pid=407093) 	add.s32 	%r113, %r110, %r112;
(EngineCore_DP0 pid=407093) 	add.s32 	%r114, %r110, %r111;
(EngineCore_DP0 pid=407093) 	.loc	1 225 53                        // quant_slide_tuned_Llama3.2-3B.py:225:53
(EngineCore_DP0 pid=407093) 	setp.lt.s32 	%p19, %r114, %r23;
(EngineCore_DP0 pid=407093) 	setp.lt.s32 	%p20, %r113, %r23;
(EngineCore_DP0 pid=407093) 	.loc	1 225 37                        // quant_slide_tuned_Llama3.2-3B.py:225:37
(EngineCore_DP0 pid=407093) 	and.pred 	%p10, %p18, %p19;
(EngineCore_DP0 pid=407093) 	and.pred 	%p11, %p18, %p20;
(EngineCore_DP0 pid=407093) 	.loc	1 224 29                        // quant_slide_tuned_Llama3.2-3B.py:224:29
(EngineCore_DP0 pid=407093) 	mad.wide.s32 	%rd9, %r114, 2, %rd1;
(EngineCore_DP0 pid=407093) 	mad.wide.s32 	%rd10, %r113, 2, %rd1;
(EngineCore_DP0 pid=407093) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=407093) 	.loc	1 224 21                        // quant_slide_tuned_Llama3.2-3B.py:224:21
(EngineCore_DP0 pid=407093) 	// begin inline asm
(EngineCore_DP0 pid=407093) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=407093) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=407093) 	// end inline asm
(EngineCore_DP0 pid=407093) 	// begin inline asm
(EngineCore_DP0 pid=407093) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=407093) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=407093) 	// end inline asm
(EngineCore_DP0 pid=407093) 	.loc	1 225 79                        // quant_slide_tuned_Llama3.2-3B.py:225:79
(EngineCore_DP0 pid=407093) 	cvt.f32.bf16 	%r115, %rs48;
(EngineCore_DP0 pid=407093) 	cvt.f32.bf16 	%r116, %rs50;
(EngineCore_DP0 pid=407093) 	.loc	1 227 48                        // quant_slide_tuned_Llama3.2-3B.py:227:48
(EngineCore_DP0 pid=407093) 	or.b32 	%r117, %r114, 1;
(EngineCore_DP0 pid=407093) 	or.b32 	%r118, %r113, 1;
(EngineCore_DP0 pid=407093) 	.loc	1 227 53                        // quant_slide_tuned_Llama3.2-3B.py:227:53
(EngineCore_DP0 pid=407093) 	setp.lt.s32 	%p21, %r117, %r23;
(EngineCore_DP0 pid=407093) 	setp.lt.s32 	%p22, %r118, %r23;
(EngineCore_DP0 pid=407093) 	.loc	1 227 37                        // quant_slide_tuned_Llama3.2-3B.py:227:37
(EngineCore_DP0 pid=407093) 	and.pred 	%p12, %p18, %p21;
(EngineCore_DP0 pid=407093) 	and.pred 	%p13, %p18, %p22;
(EngineCore_DP0 pid=407093) 	.loc	1 226 39                        // quant_slide_tuned_Llama3.2-3B.py:226:39
(EngineCore_DP0 pid=407093) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=407093) 	add.s64 	%rd12, %rd10, 2;
(EngineCore_DP0 pid=407093) 	.loc	1 226 21                        // quant_slide_tuned_Llama3.2-3B.py:226:21
(EngineCore_DP0 pid=407093) 	// begin inline asm
(EngineCore_DP0 pid=407093) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=407093) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=407093) 	// end inline asm
(EngineCore_DP0 pid=407093) 	// begin inline asm
(EngineCore_DP0 pid=407093) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=407093) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=407093) 	// end inline asm
(EngineCore_DP0 pid=407093) 	.loc	1 227 79                        // quant_slide_tuned_Llama3.2-3B.py:227:79
(EngineCore_DP0 pid=407093) 	cvt.f32.bf16 	%r119, %rs52;
(EngineCore_DP0 pid=407093) 	cvt.f32.bf16 	%r120, %rs54;
(EngineCore_DP0 pid=407093) 	.loc	1 231 48                        // quant_slide_tuned_Llama3.2-3B.py:231:48
(EngineCore_DP0 pid=407093) 	add.s32 	%r121, %r114, 2;
(EngineCore_DP0 pid=407093) 	add.s32 	%r122, %r113, 2;
(EngineCore_DP0 pid=407093) 	add.s32 	%r123, %r114, 3;
(EngineCore_DP0 pid=407093) 	add.s32 	%r124, %r113, 3;
(EngineCore_DP0 pid=407093) 	.loc	1 231 53                        // quant_slide_tuned_Llama3.2-3B.py:231:53
(EngineCore_DP0 pid=407093) 	setp.lt.s32 	%p23, %r124, %r23;
(EngineCore_DP0 pid=407093) 	setp.lt.s32 	%p24, %r123, %r23;
(EngineCore_DP0 pid=407093) 	setp.lt.s32 	%p25, %r122, %r23;
(EngineCore_DP0 pid=407093) 	setp.lt.s32 	%p26, %r121, %r23;
(EngineCore_DP0 pid=407093) 	.loc	1 229 37                        // quant_slide_tuned_Llama3.2-3B.py:229:37
(EngineCore_DP0 pid=407093) 	and.pred 	%p14, %p18, %p26;
(EngineCore_DP0 pid=407093) 	and.pred 	%p15, %p18, %p25;
(EngineCore_DP0 pid=407093) 	.loc	1 228 39                        // quant_slide_tuned_Llama3.2-3B.py:228:39
(EngineCore_DP0 pid=407093) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=407093) 	add.s64 	%rd14, %rd10, 4;
(EngineCore_DP0 pid=407093) 	.loc	1 228 21                        // quant_slide_tuned_Llama3.2-3B.py:228:21
(EngineCore_DP0 pid=407093) 	// begin inline asm
(EngineCore_DP0 pid=407093) 	mov.u16 %rs56, %rs49;
(EngineCore_DP0 pid=407093) 	@%p14 ld.global.b16 { %rs56 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=407093) 	// end inline asm
(EngineCore_DP0 pid=407093) 	// begin inline asm
(EngineCore_DP0 pid=407093) 	mov.u16 %rs58, %rs49;
(EngineCore_DP0 pid=407093) 	@%p15 ld.global.b16 { %rs58 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=407093) 	// end inline asm
(EngineCore_DP0 pid=407093) 	.loc	1 229 79                        // quant_slide_tuned_Llama3.2-3B.py:229:79
(EngineCore_DP0 pid=407093) 	cvt.f32.bf16 	%r125, %rs56;
(EngineCore_DP0 pid=407093) 	cvt.f32.bf16 	%r126, %rs58;
(EngineCore_DP0 pid=407093) 	.loc	1 231 37                        // quant_slide_tuned_Llama3.2-3B.py:231:37
(EngineCore_DP0 pid=407093) 	and.pred 	%p16, %p18, %p24;
(EngineCore_DP0 pid=407093) 	and.pred 	%p17, %p18, %p23;
(EngineCore_DP0 pid=407093) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-3B.py:230:39
(EngineCore_DP0 pid=407093) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=407093) 	add.s64 	%rd16, %rd10, 6;
(EngineCore_DP0 pid=407093) 	.loc	1 230 21                        // quant_slide_tuned_Llama3.2-3B.py:230:21
(EngineCore_DP0 pid=407093) 	// begin inline asm
(EngineCore_DP0 pid=407093) 	mov.u16 %rs60, %rs49;
(EngineCore_DP0 pid=407093) 	@%p16 ld.global.b16 { %rs60 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=407093) 	// end inline asm
(EngineCore_DP0 pid=407093) 	// begin inline asm
(EngineCore_DP0 pid=407093) 	mov.u16 %rs62, %rs49;
(EngineCore_DP0 pid=407093) 	@%p17 ld.global.b16 { %rs62 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=407093) 	// end inline asm
(EngineCore_DP0 pid=407093) 	.loc	1 231 79                        // quant_slide_tuned_Llama3.2-3B.py:231:79
(EngineCore_DP0 pid=407093) 	cvt.f32.bf16 	%r127, %rs60;
(EngineCore_DP0 pid=407093) 	cvt.f32.bf16 	%r128, %rs62;
(EngineCore_DP0 pid=407093) 	.loc	1 233 27                        // quant_slide_tuned_Llama3.2-3B.py:233:27
(EngineCore_DP0 pid=407093) 	mul.f32 	%r129, %r14, %r115;
(EngineCore_DP0 pid=407093) 	mul.f32 	%r130, %r14, %r116;
(EngineCore_DP0 pid=407093) 	mov.b32 	%r131, 0f43E00000;
(EngineCore_DP0 pid=407093) 	.loc	1 233 48                        // quant_slide_tuned_Llama3.2-3B.py:233:48
(EngineCore_DP0 pid=407093) 	min.xorsign.abs.f32 	%r87, %r129, %r131;
(EngineCore_DP0 pid=407093) 	min.xorsign.abs.f32 	%r88, %r130, %r131;
(EngineCore_DP0 pid=407093) 	.loc	1 233 60                        // quant_slide_tuned_Llama3.2-3B.py:233:60
(EngineCore_DP0 pid=407093) 	// begin inline asm
(EngineCore_DP0 pid=407093) 	cvt.rn.satfinite.e4m3x2.f32  %rs64, %r88, %r87; 
(EngineCore_DP0 pid=407093) 
(EngineCore_DP0 pid=407093) 	// end inline asm
(EngineCore_DP0 pid=407093) 	shr.u16 	%rs68, %rs64, 8;
(EngineCore_DP0 pid=407093) 	.loc	1 234 27                        // quant_slide_tuned_Llama3.2-3B.py:234:27
(EngineCore_DP0 pid=407093) 	mul.f32 	%r132, %r14, %r119;
(EngineCore_DP0 pid=407093) 	mul.f32 	%r133, %r14, %r120;
(EngineCore_DP0 pid=407093) 	.loc	1 234 48                        // quant_slide_tuned_Llama3.2-3B.py:234:48
(EngineCore_DP0 pid=407093) 	min.xorsign.abs.f32 	%r89, %r132, %r131;
(EngineCore_DP0 pid=407093) 	min.xorsign.abs.f32 	%r90, %r133, %r131;
(EngineCore_DP0 pid=407093) 	.loc	1 234 60                        // quant_slide_tuned_Llama3.2-3B.py:234:60
(EngineCore_DP0 pid=407093) 	// begin inline asm
(EngineCore_DP0 pid=407093) 	cvt.rn.satfinite.e4m3x2.f32  %rs65, %r90, %r89; 
(EngineCore_DP0 pid=407093) 
(EngineCore_DP0 pid=407093) 	// end inline asm
(EngineCore_DP0 pid=407093) 	shr.u16 	%rs69, %rs65, 8;
(EngineCore_DP0 pid=407093) 	.loc	1 235 27                        // quant_slide_tuned_Llama3.2-3B.py:235:27
(EngineCore_DP0 pid=407093) 	mul.f32 	%r134, %r14, %r125;
(EngineCore_DP0 pid=407093) 	mul.f32 	%r135, %r14, %r126;
(EngineCore_DP0 pid=407093) 	.loc	1 235 48                        // quant_slide_tuned_Llama3.2-3B.py:235:48
(EngineCore_DP0 pid=407093) 	min.xorsign.abs.f32 	%r91, %r134, %r131;
(EngineCore_DP0 pid=407093) 	min.xorsign.abs.f32 	%r92, %r135, %r131;
(EngineCore_DP0 pid=407093) 	.loc	1 235 60                        // quant_slide_tuned_Llama3.2-3B.py:235:60
(EngineCore_DP0 pid=407093) 	// begin inline asm
(EngineCore_DP0 pid=407093) 	cvt.rn.satfinite.e4m3x2.f32  %rs66, %r92, %r91; 
(EngineCore_DP0 pid=407093) 
(EngineCore_DP0 pid=407093) 	// end inline asm
(EngineCore_DP0 pid=407093) 	shr.u16 	%rs70, %rs66, 8;
(EngineCore_DP0 pid=407093) 	.loc	1 236 27                        // quant_slide_tuned_Llama3.2-3B.py:236:27
(EngineCore_DP0 pid=407093) 	mul.f32 	%r136, %r14, %r127;
(EngineCore_DP0 pid=407093) 	mul.f32 	%r137, %r14, %r128;
(EngineCore_DP0 pid=407093) 	.loc	1 236 48                        // quant_slide_tuned_Llama3.2-3B.py:236:48
(EngineCore_DP0 pid=407093) 	min.xorsign.abs.f32 	%r93, %r136, %r131;
(EngineCore_DP0 pid=407093) 	min.xorsign.abs.f32 	%r94, %r137, %r131;
(EngineCore_DP0 pid=407093) 	.loc	1 236 60                        // quant_slide_tuned_Llama3.2-3B.py:236:60
(EngineCore_DP0 pid=407093) 	// begin inline asm
(EngineCore_DP0 pid=407093) 	cvt.rn.satfinite.e4m3x2.f32  %rs67, %r94, %r93; 
(EngineCore_DP0 pid=407093) 
(EngineCore_DP0 pid=407093) 	// end inline asm
(EngineCore_DP0 pid=407093) 	shr.u16 	%rs71, %rs67, 8;
(EngineCore_DP0 pid=407093) 	.loc	1 238 45                        // quant_slide_tuned_Llama3.2-3B.py:238:45
(EngineCore_DP0 pid=407093) 	cvt.u32.u16 	%r138, %rs64;
(EngineCore_DP0 pid=407093) 	and.b32 	%r139, %r138, 255;
(EngineCore_DP0 pid=407093) 	cvt.u32.u16 	%r140, %rs68;
(EngineCore_DP0 pid=407093) 	.loc	1 240 45                        // quant_slide_tuned_Llama3.2-3B.py:240:45
(EngineCore_DP0 pid=407093) 	cvt.u32.u16 	%r141, %rs66;
(EngineCore_DP0 pid=407093) 	and.b32 	%r142, %r141, 255;
(EngineCore_DP0 pid=407093) 	cvt.u32.u16 	%r143, %rs70;
(EngineCore_DP0 pid=407093) 	.loc	1 241 45                        // quant_slide_tuned_Llama3.2-3B.py:241:45
(EngineCore_DP0 pid=407093) 	cvt.u32.u16 	%r144, %rs67;
(EngineCore_DP0 pid=407093) 	cvt.u32.u16 	%r145, %rs71;
(EngineCore_DP0 pid=407093) 	.loc	1 243 30                        // quant_slide_tuned_Llama3.2-3B.py:243:30
(EngineCore_DP0 pid=407093) 	and.b16 	%rs72, %rs65, 255;
(EngineCore_DP0 pid=407093) 	mul.wide.u16 	%r146, %rs72, 256;
(EngineCore_DP0 pid=407093) 	mul.wide.u16 	%r147, %rs69, 256;
(EngineCore_DP0 pid=407093) 	.loc	1 243 24                        // quant_slide_tuned_Llama3.2-3B.py:243:24
(EngineCore_DP0 pid=407093) 	or.b32 	%r148, %r146, %r139;
(EngineCore_DP0 pid=407093) 	or.b32 	%r149, %r147, %r140;
(EngineCore_DP0 pid=407093) 	.loc	1 243 42                        // quant_slide_tuned_Llama3.2-3B.py:243:42
(EngineCore_DP0 pid=407093) 	shl.b32 	%r150, %r142, 16;
(EngineCore_DP0 pid=407093) 	shl.b32 	%r151, %r143, 16;
(EngineCore_DP0 pid=407093) 	.loc	1 243 36                        // quant_slide_tuned_Llama3.2-3B.py:243:36
(EngineCore_DP0 pid=407093) 	or.b32 	%r152, %r148, %r150;
(EngineCore_DP0 pid=407093) 	or.b32 	%r153, %r149, %r151;
(EngineCore_DP0 pid=407093) 	.loc	1 243 55                        // quant_slide_tuned_Llama3.2-3B.py:243:55
(EngineCore_DP0 pid=407093) 	shl.b32 	%r154, %r144, 24;
(EngineCore_DP0 pid=407093) 	shl.b32 	%r155, %r145, 24;
(EngineCore_DP0 pid=407093) 	.loc	1 243 49                        // quant_slide_tuned_Llama3.2-3B.py:243:49
(EngineCore_DP0 pid=407093) 	or.b32 	%r95, %r152, %r154;
(EngineCore_DP0 pid=407093) 	or.b32 	%r96, %r153, %r155;
(EngineCore_DP0 pid=407093) 	.loc	1 244 29                        // quant_slide_tuned_Llama3.2-3B.py:244:29
(EngineCore_DP0 pid=407093) 	mad.wide.s32 	%rd17, %r97, 4, %rd2;
(EngineCore_DP0 pid=407093) 	.loc	1 244 39                        // quant_slide_tuned_Llama3.2-3B.py:244:39
(EngineCore_DP0 pid=407093) 	// begin inline asm
(EngineCore_DP0 pid=407093) 	@%p18 st.global.v2.b32 [ %rd17 + 0 ], { %r95, %r96 };
(EngineCore_DP0 pid=407093) 	// end inline asm
(EngineCore_DP0 pid=407093) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=407093) 	add.s32 	%r159, %r159, 1024;
(EngineCore_DP0 pid=407093) 	setp.lt.s32 	%p27, %r159, %r15;
(EngineCore_DP0 pid=407093) 	@%p27 bra 	$L__BB0_6;
(EngineCore_DP0 pid=407093) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=407093) 	.loc	1 215 4                         // quant_slide_tuned_Llama3.2-3B.py:215:4
(EngineCore_DP0 pid=407093) 	ret;
(EngineCore_DP0 pid=407093) $L__tmp3:
(EngineCore_DP0 pid=407093) $L__func_end0:
(EngineCore_DP0 pid=407093)                                         // -- End function
(EngineCore_DP0 pid=407093) }
(EngineCore_DP0 pid=407093) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py"
(EngineCore_DP0 pid=407093) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=407093) 	.section	.debug_abbrev
(EngineCore_DP0 pid=407093) 	{
(EngineCore_DP0 pid=407093) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=407093) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=407093) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=407093) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=407093) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=407093) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=407093) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=407093) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=407093) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=407093) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=407093) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=407093) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=407093) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=407093) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=407093) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=407093) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=407093) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=407093) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=407093) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=407093) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=407093) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=407093) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=407093) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=407093) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=407093) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=407093) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=407093) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=407093) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=407093) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=407093) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=407093) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=407093) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=407093) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=407093) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=407093) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=407093) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=407093) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=407093) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=407093) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=407093) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=407093) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=407093) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=407093) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=407093) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=407093) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=407093) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=407093) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=407093) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=407093) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=407093) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=407093) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=407093) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=407093) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=407093) 	}
(EngineCore_DP0 pid=407093) 	.section	.debug_info
(EngineCore_DP0 pid=407093) 	{
(EngineCore_DP0 pid=407093) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=407093) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=407093) .b8 0
(EngineCore_DP0 pid=407093) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=407093) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=407093) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=407093) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=407093) .b8 114
(EngineCore_DP0 pid=407093) .b8 105
(EngineCore_DP0 pid=407093) .b8 116
(EngineCore_DP0 pid=407093) .b8 111
(EngineCore_DP0 pid=407093) .b8 110
(EngineCore_DP0 pid=407093) .b8 0
(EngineCore_DP0 pid=407093) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=407093) .b8 0
(EngineCore_DP0 pid=407093) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=407093) .b8 117
(EngineCore_DP0 pid=407093) .b8 97
(EngineCore_DP0 pid=407093) .b8 110
(EngineCore_DP0 pid=407093) .b8 116
(EngineCore_DP0 pid=407093) .b8 95
(EngineCore_DP0 pid=407093) .b8 115
(EngineCore_DP0 pid=407093) .b8 108
(EngineCore_DP0 pid=407093) .b8 105
(EngineCore_DP0 pid=407093) .b8 100
(EngineCore_DP0 pid=407093) .b8 101
(EngineCore_DP0 pid=407093) .b8 95
(EngineCore_DP0 pid=407093) .b8 116
(EngineCore_DP0 pid=407093) .b8 117
(EngineCore_DP0 pid=407093) .b8 110
(EngineCore_DP0 pid=407093) .b8 101
(EngineCore_DP0 pid=407093) .b8 100
(EngineCore_DP0 pid=407093) .b8 95
(EngineCore_DP0 pid=407093) .b8 76
(EngineCore_DP0 pid=407093) .b8 108
(EngineCore_DP0 pid=407093) .b8 97
(EngineCore_DP0 pid=407093) .b8 109
(EngineCore_DP0 pid=407093) .b8 97
(EngineCore_DP0 pid=407093) .b8 51
(EngineCore_DP0 pid=407093) .b8 46
(EngineCore_DP0 pid=407093) .b8 50
(EngineCore_DP0 pid=407093) .b8 45
(EngineCore_DP0 pid=407093) .b8 51
(EngineCore_DP0 pid=407093) .b8 66
(EngineCore_DP0 pid=407093) .b8 46
(EngineCore_DP0 pid=407093) .b8 112
(EngineCore_DP0 pid=407093) .b8 121
(EngineCore_DP0 pid=407093) .b8 0
(EngineCore_DP0 pid=407093) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=407093) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=407093) .b8 114
(EngineCore_DP0 pid=407093) .b8 111
(EngineCore_DP0 pid=407093) .b8 111
(EngineCore_DP0 pid=407093) .b8 116
(EngineCore_DP0 pid=407093) .b8 47
(EngineCore_DP0 pid=407093) .b8 118
(EngineCore_DP0 pid=407093) .b8 108
(EngineCore_DP0 pid=407093) .b8 108
(EngineCore_DP0 pid=407093) .b8 109
(EngineCore_DP0 pid=407093) .b8 98
(EngineCore_DP0 pid=407093) .b8 101
(EngineCore_DP0 pid=407093) .b8 110
(EngineCore_DP0 pid=407093) .b8 99
(EngineCore_DP0 pid=407093) .b8 104
(EngineCore_DP0 pid=407093) .b8 47
(EngineCore_DP0 pid=407093) .b8 115
(EngineCore_DP0 pid=407093) .b8 108
(EngineCore_DP0 pid=407093) .b8 105
(EngineCore_DP0 pid=407093) .b8 100
(EngineCore_DP0 pid=407093) .b8 101
(EngineCore_DP0 pid=407093) .b8 115
(EngineCore_DP0 pid=407093) .b8 112
(EngineCore_DP0 pid=407093) .b8 97
(EngineCore_DP0 pid=407093) .b8 114
(EngineCore_DP0 pid=407093) .b8 115
(EngineCore_DP0 pid=407093) .b8 101
(EngineCore_DP0 pid=407093) .b8 47
(EngineCore_DP0 pid=407093) .b8 99
(EngineCore_DP0 pid=407093) .b8 115
(EngineCore_DP0 pid=407093) .b8 114
(EngineCore_DP0 pid=407093) .b8 99
(EngineCore_DP0 pid=407093) .b8 47
(EngineCore_DP0 pid=407093) .b8 102
(EngineCore_DP0 pid=407093) .b8 117
(EngineCore_DP0 pid=407093) .b8 115
(EngineCore_DP0 pid=407093) .b8 101
(EngineCore_DP0 pid=407093) .b8 100
(EngineCore_DP0 pid=407093) .b8 95
(EngineCore_DP0 pid=407093) .b8 113
(EngineCore_DP0 pid=407093) .b8 117
(EngineCore_DP0 pid=407093) .b8 97
(EngineCore_DP0 pid=407093) .b8 110
(EngineCore_DP0 pid=407093) .b8 116
(EngineCore_DP0 pid=407093) .b8 95
(EngineCore_DP0 pid=407093) .b8 115
(EngineCore_DP0 pid=407093) .b8 108
(EngineCore_DP0 pid=407093) .b8 105
(EngineCore_DP0 pid=407093) .b8 100
(EngineCore_DP0 pid=407093) .b8 101
(EngineCore_DP0 pid=407093) .b8 95
(EngineCore_DP0 pid=407093) .b8 116
(EngineCore_DP0 pid=407093) .b8 114
(EngineCore_DP0 pid=407093) .b8 105
(EngineCore_DP0 pid=407093) .b8 116
(EngineCore_DP0 pid=407093) .b8 111
(EngineCore_DP0 pid=407093) .b8 110
(EngineCore_DP0 pid=407093) .b8 47
(EngineCore_DP0 pid=407093) .b8 98
(EngineCore_DP0 pid=407093) .b8 117
(EngineCore_DP0 pid=407093) .b8 105
(EngineCore_DP0 pid=407093) .b8 108
(EngineCore_DP0 pid=407093) .b8 100
(EngineCore_DP0 pid=407093) .b8 47
(EngineCore_DP0 pid=407093) .b8 71
(EngineCore_DP0 pid=407093) .b8 66
(EngineCore_DP0 pid=407093) .b8 49
(EngineCore_DP0 pid=407093) .b8 48
(EngineCore_DP0 pid=407093) .b8 95
(EngineCore_DP0 pid=407093) .b8 99
(EngineCore_DP0 pid=407093) .b8 99
(EngineCore_DP0 pid=407093) .b8 49
(EngineCore_DP0 pid=407093) .b8 50
(EngineCore_DP0 pid=407093) .b8 49
(EngineCore_DP0 pid=407093) .b8 95
(EngineCore_DP0 pid=407093) .b8 112
(EngineCore_DP0 pid=407093) .b8 121
(EngineCore_DP0 pid=407093) .b8 51
(EngineCore_DP0 pid=407093) .b8 49
(EngineCore_DP0 pid=407093) .b8 50
(EngineCore_DP0 pid=407093) .b8 95
(EngineCore_DP0 pid=407093) .b8 99
(EngineCore_DP0 pid=407093) .b8 117
(EngineCore_DP0 pid=407093) .b8 49
(EngineCore_DP0 pid=407093) .b8 50
(EngineCore_DP0 pid=407093) .b8 57
(EngineCore_DP0 pid=407093) .b8 95
(EngineCore_DP0 pid=407093) .b8 97
(EngineCore_DP0 pid=407093) .b8 97
(EngineCore_DP0 pid=407093) .b8 114
(EngineCore_DP0 pid=407093) .b8 99
(EngineCore_DP0 pid=407093) .b8 104
(EngineCore_DP0 pid=407093) .b8 54
(EngineCore_DP0 pid=407093) .b8 52
(EngineCore_DP0 pid=407093) .b8 0
(EngineCore_DP0 pid=407093) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=407093) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=407093) .b8 113
(EngineCore_DP0 pid=407093) .b8 117
(EngineCore_DP0 pid=407093) .b8 97
(EngineCore_DP0 pid=407093) .b8 110
(EngineCore_DP0 pid=407093) .b8 116
(EngineCore_DP0 pid=407093) .b8 95
(EngineCore_DP0 pid=407093) .b8 115
(EngineCore_DP0 pid=407093) .b8 108
(EngineCore_DP0 pid=407093) .b8 105
(EngineCore_DP0 pid=407093) .b8 100
(EngineCore_DP0 pid=407093) .b8 101
(EngineCore_DP0 pid=407093) .b8 95
(EngineCore_DP0 pid=407093) .b8 102
(EngineCore_DP0 pid=407093) .b8 112
(EngineCore_DP0 pid=407093) .b8 56
(EngineCore_DP0 pid=407093) .b8 95
(EngineCore_DP0 pid=407093) .b8 107
(EngineCore_DP0 pid=407093) .b8 101
(EngineCore_DP0 pid=407093) .b8 114
(EngineCore_DP0 pid=407093) .b8 110
(EngineCore_DP0 pid=407093) .b8 101
(EngineCore_DP0 pid=407093) .b8 108
(EngineCore_DP0 pid=407093) .b8 0
(EngineCore_DP0 pid=407093) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=407093) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=407093) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=407093) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=407093) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=407093) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=407093) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=407093) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=407093) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=407093) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=407093) .b8 205                                 // DW_AT_call_line
(EngineCore_DP0 pid=407093) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=407093) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=407093) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=407093) 	}
(EngineCore_DP0 pid=407093) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=407093) 
(EngineCore_DP0 pid=407093) ================================================================
(EngineCore_DP0 pid=407093) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=407093) 
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpr46b1zuq.ptx', '-o', '/tmp/tmpr46b1zuq.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866] 
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866] 
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866] 
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpr46b1zuq.ptx -o /tmp/tmpr46b1zuq.ptx.o
(EngineCore_DP0 pid=407093) ERROR 01-25 20:18:00 [core.py:866] 

STDERR:
[2026-01-25 20:17:29] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:17:29] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:17:29] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:17:29] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:17:29] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:17:29] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:17:29] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:17:29] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:17:29] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:17:29] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:17:29] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:17:29] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:17:29] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:17:29] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:17:32] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:17:32] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:17:32] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:17:32] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:17:32] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:17:32] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:17:32] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:17:32] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:17:32] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:17:32] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:17:32] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:17:32] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:17:32] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:17:32] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=407093) [2026-01-25 20:17:33] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=407093) [2026-01-25 20:17:33] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=407093) [2026-01-25 20:17:33] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=407093) [2026-01-25 20:17:33] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=407093) [2026-01-25 20:17:33] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=407093) [2026-01-25 20:17:33] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=407093) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=407093) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:25<00:00, 25.10s/it]
(EngineCore_DP0 pid=407093) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:25<00:00, 25.10s/it]
(EngineCore_DP0 pid=407093) 
(EngineCore_DP0 pid=407093) [2026-01-25 20:17:59] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4928] -> 1D uint8
(EngineCore_DP0 pid=407093) [2026-01-25 20:17:59] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15810560 bytes
(EngineCore_DP0 pid=407093) [2026-01-25 20:17:59] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4928] -> 1D uint8
(EngineCore_DP0 pid=407093) [2026-01-25 20:17:59] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9486336 bytes
(EngineCore_DP0 pid=407093) [2026-01-25 20:17:59] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4928] -> 1D uint8
(EngineCore_DP0 pid=407093) [2026-01-25 20:17:59] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 50593792 bytes
(EngineCore_DP0 pid=407093) [2026-01-25 20:17:59] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 13120] -> 1D uint8
(EngineCore_DP0 pid=407093) [2026-01-25 20:17:59] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 25214976 bytes
(EngineCore_DP0 pid=407093) Process EngineCore_DP0:
(EngineCore_DP0 pid=407093) Traceback (most recent call last):
(EngineCore_DP0 pid=407093)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=407093)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=407093)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=407093)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=407093) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpr46b1zuq.ptx', '-o', '/tmp/tmpr46b1zuq.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=407093) 
(EngineCore_DP0 pid=407093) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=407093) 
(EngineCore_DP0 pid=407093) Traceback (most recent call last):
(EngineCore_DP0 pid=407093)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=407093)     self.run()
(EngineCore_DP0 pid=407093)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=407093)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=407093)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=407093)     raise e
(EngineCore_DP0 pid=407093)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=407093)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=407093)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=407093)     super().__init__(
(EngineCore_DP0 pid=407093)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=407093)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=407093)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=407093)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=407093)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=407093)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=407093)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=407093)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=407093)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=407093)     return func(*args, **kwargs)
(EngineCore_DP0 pid=407093)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=407093)     return func(*args, **kwargs)
(EngineCore_DP0 pid=407093)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=407093)     self.model_runner.profile_run()
(EngineCore_DP0 pid=407093)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=407093)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=407093)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=407093)     return func(*args, **kwargs)
(EngineCore_DP0 pid=407093)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=407093)     outputs = self.model(
(EngineCore_DP0 pid=407093)               ^^^^^^^^^^^
(EngineCore_DP0 pid=407093)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=407093)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=407093)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=407093)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=407093)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=407093)     model_output = self.model(
(EngineCore_DP0 pid=407093)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=407093)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=407093)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=407093)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=407093)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=407093)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=407093)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=407093)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=407093)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=407093)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=407093)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=407093)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=407093)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=407093)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=407093)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=407093)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=407093)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=407093)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=407093)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=407093)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=407093)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=407093)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=407093)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=407093)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=407093)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=407093)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=407093)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=407093)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=407093)     return self._linear_fn(
(EngineCore_DP0 pid=407093)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=407093)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=407093)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=407093)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=407093)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=407093)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=407093)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=407093)     return fn(input, L)
(EngineCore_DP0 pid=407093)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=407093)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=407093)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=407093)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=407093)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=407093)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=407093)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=407093)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=407093)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=407093)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=407093)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=407093)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=407093)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=407093)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407093)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=407093)     raise PTXASError(error)
(EngineCore_DP0 pid=407093) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=407093) `ptxas` stderr:
(EngineCore_DP0 pid=407093) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=407093) 
(EngineCore_DP0 pid=407093) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpr46b1zuq.ptx -o /tmp/tmpr46b1zuq.ptx.o
(EngineCore_DP0 pid=407093) 
[rank0]:[W125 20:18:00.044989813 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=8192

========== M=16384 ==========
Time: 2026-01-25 20:18:02
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-3B-FP8_M16384.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:18:11 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 20:18:11 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=407880) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=407880) 
(EngineCore_DP0 pid=407880) 
(EngineCore_DP0 pid=407880) ================================================================
(EngineCore_DP0 pid=407880) Internal Triton PTX codegen error
(EngineCore_DP0 pid=407880) `ptxas` stderr:
(EngineCore_DP0 pid=407880) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=407880) 
(EngineCore_DP0 pid=407880) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpui6uhxil.ptx -o /tmp/tmpui6uhxil.ptx.o
(EngineCore_DP0 pid=407880) 
(EngineCore_DP0 pid=407880) 
(EngineCore_DP0 pid=407880) //
(EngineCore_DP0 pid=407880) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=407880) //
(EngineCore_DP0 pid=407880) 
(EngineCore_DP0 pid=407880) .version 8.7
(EngineCore_DP0 pid=407880) .target sm_121a
(EngineCore_DP0 pid=407880) .address_size 64
(EngineCore_DP0 pid=407880) 
(EngineCore_DP0 pid=407880) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=407880) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=407880)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=407880) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=407880) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=407880) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=407880) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=407880) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=407880) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=407880) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=407880) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=407880) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=407880) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=407880) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=407880) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=407880) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=407880) )
(EngineCore_DP0 pid=407880) .reqntid 512
(EngineCore_DP0 pid=407880) {
(EngineCore_DP0 pid=407880) 	.reg .pred 	%p<29>;
(EngineCore_DP0 pid=407880) 	.reg .b16 	%rs<73>;
(EngineCore_DP0 pid=407880) 	.reg .b32 	%r<160>;
(EngineCore_DP0 pid=407880) 	.reg .b64 	%rd<18>;
(EngineCore_DP0 pid=407880) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=407880) $L__func_begin0:
(EngineCore_DP0 pid=407880) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=407880) 
(EngineCore_DP0 pid=407880) // %bb.0:
(EngineCore_DP0 pid=407880) 	ld.param.b32 	%r25, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=407880) 	ld.param.b32 	%r24, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=407880) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=407880) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=407880) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=407880) $L__tmp0:
(EngineCore_DP0 pid=407880) 	.loc	1 191 24                        // quant_slide_tuned_Llama3.2-3B.py:191:24
(EngineCore_DP0 pid=407880) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=407880) 	ld.param.b32 	%r27, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=407880) 	.loc	1 196 26                        // quant_slide_tuned_Llama3.2-3B.py:196:26
(EngineCore_DP0 pid=407880) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=407880) 	.loc	1 196 20                        // quant_slide_tuned_Llama3.2-3B.py:196:20
(EngineCore_DP0 pid=407880) 	mad.wide.s32 	%rd1, %r28, 2, %rd4;
(EngineCore_DP0 pid=407880) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=407880) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=407880) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=407880) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=407880) 	setp.lt.s32 	%p1, %r24, 1;
(EngineCore_DP0 pid=407880) 	mov.b32 	%r158, 0f2B8CBCCC;
(EngineCore_DP0 pid=407880) 	setp.eq.b32 	%p28, %r2, 0;
(EngineCore_DP0 pid=407880) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=407880) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=407880) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=407880) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=407880) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=407880) 	shr.u32 	%r37, %r2, 3;
(EngineCore_DP0 pid=407880) 	and.b32 	%r38, %r37, 60;
(EngineCore_DP0 pid=407880) 	mov.b32 	%r39, global_smem;
(EngineCore_DP0 pid=407880) 	add.s32 	%r57, %r39, %r38;
(EngineCore_DP0 pid=407880) 	shl.b32 	%r40, %r2, 2;
(EngineCore_DP0 pid=407880) 	add.s32 	%r60, %r39, %r40;
(EngineCore_DP0 pid=407880) 	mov.b32 	%r45, 0;
(EngineCore_DP0 pid=407880) 	mov.b32 	%r156, 0f00000000;
(EngineCore_DP0 pid=407880) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=407880) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=407880) 	mov.b32 	%r157, %r45;
(EngineCore_DP0 pid=407880) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=407880) 	.loc	1 202 19                        // quant_slide_tuned_Llama3.2-3B.py:202:19
(EngineCore_DP0 pid=407880) 	add.s32 	%r63, %r4, %r157;
(EngineCore_DP0 pid=407880) 	.loc	1 203 22                        // quant_slide_tuned_Llama3.2-3B.py:203:22
(EngineCore_DP0 pid=407880) 	add.s32 	%r64, %r63, 4096;
(EngineCore_DP0 pid=407880) 	setp.lt.s32 	%p2, %r63, %r23;
(EngineCore_DP0 pid=407880) 	setp.lt.s32 	%p3, %r64, %r23;
(EngineCore_DP0 pid=407880) 	.loc	1 204 29                        // quant_slide_tuned_Llama3.2-3B.py:204:29
(EngineCore_DP0 pid=407880) 	mad.wide.s32 	%rd6, %r63, 2, %rd1;
(EngineCore_DP0 pid=407880) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=407880) 	.loc	1 204 21                        // quant_slide_tuned_Llama3.2-3B.py:204:21
(EngineCore_DP0 pid=407880) 	// begin inline asm
(EngineCore_DP0 pid=407880) 	mov.u32 %r41, %r45;
(EngineCore_DP0 pid=407880) 	mov.u32 %r42, %r45;
(EngineCore_DP0 pid=407880) 	mov.u32 %r43, %r45;
(EngineCore_DP0 pid=407880) 	mov.u32 %r44, %r45;
(EngineCore_DP0 pid=407880) 	@%p2 ld.global.v4.b32 { %r41, %r42, %r43, %r44 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=407880) 	// end inline asm
(EngineCore_DP0 pid=407880) 	mov.b32 	{%rs1, %rs2}, %r41;
(EngineCore_DP0 pid=407880) 	mov.b32 	{%rs3, %rs4}, %r42;
(EngineCore_DP0 pid=407880) 	mov.b32 	{%rs5, %rs6}, %r43;
(EngineCore_DP0 pid=407880) 	mov.b32 	{%rs7, %rs8}, %r44;
(EngineCore_DP0 pid=407880) 	// begin inline asm
(EngineCore_DP0 pid=407880) 	mov.u32 %r49, %r45;
(EngineCore_DP0 pid=407880) 	mov.u32 %r50, %r45;
(EngineCore_DP0 pid=407880) 	mov.u32 %r51, %r45;
(EngineCore_DP0 pid=407880) 	mov.u32 %r52, %r45;
(EngineCore_DP0 pid=407880) 	@%p3 ld.global.v4.b32 { %r49, %r50, %r51, %r52 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=407880) 	// end inline asm
(EngineCore_DP0 pid=407880) 	mov.b32 	{%rs9, %rs10}, %r49;
(EngineCore_DP0 pid=407880) 	mov.b32 	{%rs11, %rs12}, %r50;
(EngineCore_DP0 pid=407880) 	mov.b32 	{%rs13, %rs14}, %r51;
(EngineCore_DP0 pid=407880) 	mov.b32 	{%rs15, %rs16}, %r52;
(EngineCore_DP0 pid=407880) 	.loc	1 205 50                        // quant_slide_tuned_Llama3.2-3B.py:205:50
(EngineCore_DP0 pid=407880) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=407880) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=407880) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=407880) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=407880) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=407880) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=407880) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=407880) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=407880) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=407880) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=407880) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=407880) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=407880) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=407880) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=407880) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=407880) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=407880) $L__tmp1:
(EngineCore_DP0 pid=407880) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=407880) 	bar.sync 	0;
(EngineCore_DP0 pid=407880) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=407880) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=407880) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=407880) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=407880) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=407880) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=407880) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=407880) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=407880) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=407880) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=407880) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=407880) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=407880) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=407880) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=407880) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=407880) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=407880) 	cvt.f32.bf16 	%r65, %rs47;
(EngineCore_DP0 pid=407880) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=407880) 	shfl.sync.bfly.b32 	%r66, %r65, 16, 31, -1;
(EngineCore_DP0 pid=407880) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=407880) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=407880) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=407880) 	shfl.sync.bfly.b32 	%r68, %r67, 8, 31, -1;
(EngineCore_DP0 pid=407880) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=407880) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=407880) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=407880) 	shfl.sync.bfly.b32 	%r70, %r69, 4, 31, -1;
(EngineCore_DP0 pid=407880) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=407880) 	max.f32 	%r71, %r69, %r70;
(EngineCore_DP0 pid=407880) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=407880) 	shfl.sync.bfly.b32 	%r72, %r71, 2, 31, -1;
(EngineCore_DP0 pid=407880) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=407880) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=407880) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=407880) 	shfl.sync.bfly.b32 	%r74, %r73, 1, 31, -1;
(EngineCore_DP0 pid=407880) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=407880) 	max.f32 	%r58, %r73, %r74;
(EngineCore_DP0 pid=407880) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=407880) 	// begin inline asm
(EngineCore_DP0 pid=407880) 	@%p4 st.shared.b32 [ %r57 + 0 ], %r58;
(EngineCore_DP0 pid=407880) 	// end inline asm
(EngineCore_DP0 pid=407880) 	bar.sync 	0;
(EngineCore_DP0 pid=407880) 	// begin inline asm
(EngineCore_DP0 pid=407880) 	@%p5 ld.shared.b32 %r59, [ %r60 + 0 ];
(EngineCore_DP0 pid=407880) 	// end inline asm
(EngineCore_DP0 pid=407880) 	shfl.sync.bfly.b32 	%r75, %r59, 8, 31, -1;
(EngineCore_DP0 pid=407880) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=407880) 	max.f32 	%r76, %r59, %r75;
(EngineCore_DP0 pid=407880) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=407880) 	shfl.sync.bfly.b32 	%r77, %r76, 4, 31, -1;
(EngineCore_DP0 pid=407880) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=407880) 	max.f32 	%r78, %r76, %r77;
(EngineCore_DP0 pid=407880) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=407880) 	shfl.sync.bfly.b32 	%r79, %r78, 2, 31, -1;
(EngineCore_DP0 pid=407880) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=407880) 	max.f32 	%r80, %r78, %r79;
(EngineCore_DP0 pid=407880) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=407880) 	shfl.sync.bfly.b32 	%r81, %r80, 1, 31, -1;
(EngineCore_DP0 pid=407880) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=407880) 	max.f32 	%r62, %r80, %r81;
(EngineCore_DP0 pid=407880) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=407880) 	// begin inline asm
(EngineCore_DP0 pid=407880) 	@%p28 st.shared.b32 [ %r60 + 0 ], %r62;
(EngineCore_DP0 pid=407880) 	// end inline asm
(EngineCore_DP0 pid=407880) 	bar.sync 	0;
(EngineCore_DP0 pid=407880) 	ld.shared.b32 	%r82, [global_smem];
(EngineCore_DP0 pid=407880) $L__tmp2:
(EngineCore_DP0 pid=407880) 	.loc	1 205 36                        // quant_slide_tuned_Llama3.2-3B.py:205:36
(EngineCore_DP0 pid=407880) 	max.f32 	%r156, %r156, %r82;
(EngineCore_DP0 pid=407880) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=407880) 	add.s32 	%r157, %r157, 8192;
(EngineCore_DP0 pid=407880) 	setp.lt.s32 	%p7, %r157, %r24;
(EngineCore_DP0 pid=407880) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=407880) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=407880) 	.loc	1 207 32                        // quant_slide_tuned_Llama3.2-3B.py:207:32
(EngineCore_DP0 pid=407880) 	max.f32 	%r158, %r156, 0f2B8CBCCC;
(EngineCore_DP0 pid=407880) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=407880) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-3B.py:0:32
(EngineCore_DP0 pid=407880) 	mov.b32 	%r84, 0f43E00000;
(EngineCore_DP0 pid=407880) 	.loc	1 208 32                        // quant_slide_tuned_Llama3.2-3B.py:208:32
(EngineCore_DP0 pid=407880) 	div.full.f32 	%r85, %r158, %r84;
(EngineCore_DP0 pid=407880) 	.loc	1 208 41                        // quant_slide_tuned_Llama3.2-3B.py:208:41
(EngineCore_DP0 pid=407880) 	max.f32 	%r83, %r85, 0f36924925;
(EngineCore_DP0 pid=407880) 	.loc	1 210 25                        // quant_slide_tuned_Llama3.2-3B.py:210:25
(EngineCore_DP0 pid=407880) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=407880) 	.loc	1 210 30                        // quant_slide_tuned_Llama3.2-3B.py:210:30
(EngineCore_DP0 pid=407880) 	// begin inline asm
(EngineCore_DP0 pid=407880) 	@%p28 st.global.b32 [ %rd8 + 0 ], { %r83 };
(EngineCore_DP0 pid=407880) 	// end inline asm
(EngineCore_DP0 pid=407880) 	.loc	1 213 29                        // quant_slide_tuned_Llama3.2-3B.py:213:29
(EngineCore_DP0 pid=407880) 	shl.b32 	%r15, %r25, 2;
(EngineCore_DP0 pid=407880) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=407880) 	setp.lt.s32 	%p9, %r15, 1;
(EngineCore_DP0 pid=407880) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=407880) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=407880) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-3B.py:0:41
(EngineCore_DP0 pid=407880) 	ld.param.b32 	%r29, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=407880) 	shr.s32 	%r30, %r29, 31;
(EngineCore_DP0 pid=407880) 	shr.u32 	%r31, %r30, 30;
(EngineCore_DP0 pid=407880) 	add.s32 	%r32, %r29, %r31;
(EngineCore_DP0 pid=407880) 	shr.s32 	%r33, %r32, 2;
(EngineCore_DP0 pid=407880) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=407880) 	mul.lo.s32 	%r34, %r33, %r1;
(EngineCore_DP0 pid=407880) 	mad.wide.s32 	%rd2, %r34, 4, %rd5;
(EngineCore_DP0 pid=407880) 	div.full.f32 	%r14, %r84, %r158;
(EngineCore_DP0 pid=407880) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=407880) 	mov.b32 	%r159, 0;
(EngineCore_DP0 pid=407880) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=407880)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=407880) 	.loc	1 216 31                        // quant_slide_tuned_Llama3.2-3B.py:216:31
(EngineCore_DP0 pid=407880) 	add.s32 	%r97, %r16, %r159;
(EngineCore_DP0 pid=407880) 	.loc	1 217 30                        // quant_slide_tuned_Llama3.2-3B.py:217:30
(EngineCore_DP0 pid=407880) 	add.s32 	%r98, %r97, 1;
(EngineCore_DP0 pid=407880) 	setp.lt.s32 	%p18, %r97, %r15;
(EngineCore_DP0 pid=407880) 	.loc	1 220 24                        // quant_slide_tuned_Llama3.2-3B.py:220:24
(EngineCore_DP0 pid=407880) 	shr.s32 	%r99, %r97, 31;
(EngineCore_DP0 pid=407880) 	shr.u32 	%r100, %r99, 30;
(EngineCore_DP0 pid=407880) 	add.s32 	%r101, %r97, %r100;
(EngineCore_DP0 pid=407880) 	shr.s32 	%r102, %r101, 2;
(EngineCore_DP0 pid=407880) 	.loc	1 221 23                        // quant_slide_tuned_Llama3.2-3B.py:221:23
(EngineCore_DP0 pid=407880) 	shr.s32 	%r103, %r98, 31;
(EngineCore_DP0 pid=407880) 	shr.u32 	%r104, %r103, 30;
(EngineCore_DP0 pid=407880) 	add.s32 	%r105, %r98, %r104;
(EngineCore_DP0 pid=407880) 	and.b32 	%r106, %r105, 2147483644;
(EngineCore_DP0 pid=407880) 	sub.s32 	%r107, %r98, %r106;
(EngineCore_DP0 pid=407880) 	and.b32 	%r108, %r101, 2147483644;
(EngineCore_DP0 pid=407880) 	sub.s32 	%r109, %r97, %r108;
(EngineCore_DP0 pid=407880) 	.loc	1 222 22                        // quant_slide_tuned_Llama3.2-3B.py:222:22
(EngineCore_DP0 pid=407880) 	mul.lo.s32 	%r110, %r102, 10;
(EngineCore_DP0 pid=407880) 	.loc	1 222 30                        // quant_slide_tuned_Llama3.2-3B.py:222:30
(EngineCore_DP0 pid=407880) 	shl.b32 	%r111, %r109, 1;
(EngineCore_DP0 pid=407880) 	shl.b32 	%r112, %r107, 1;
(EngineCore_DP0 pid=407880) 	.loc	1 222 26                        // quant_slide_tuned_Llama3.2-3B.py:222:26
(EngineCore_DP0 pid=407880) 	add.s32 	%r113, %r110, %r112;
(EngineCore_DP0 pid=407880) 	add.s32 	%r114, %r110, %r111;
(EngineCore_DP0 pid=407880) 	.loc	1 225 53                        // quant_slide_tuned_Llama3.2-3B.py:225:53
(EngineCore_DP0 pid=407880) 	setp.lt.s32 	%p19, %r114, %r23;
(EngineCore_DP0 pid=407880) 	setp.lt.s32 	%p20, %r113, %r23;
(EngineCore_DP0 pid=407880) 	.loc	1 225 37                        // quant_slide_tuned_Llama3.2-3B.py:225:37
(EngineCore_DP0 pid=407880) 	and.pred 	%p10, %p18, %p19;
(EngineCore_DP0 pid=407880) 	and.pred 	%p11, %p18, %p20;
(EngineCore_DP0 pid=407880) 	.loc	1 224 29                        // quant_slide_tuned_Llama3.2-3B.py:224:29
(EngineCore_DP0 pid=407880) 	mad.wide.s32 	%rd9, %r114, 2, %rd1;
(EngineCore_DP0 pid=407880) 	mad.wide.s32 	%rd10, %r113, 2, %rd1;
(EngineCore_DP0 pid=407880) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=407880) 	.loc	1 224 21                        // quant_slide_tuned_Llama3.2-3B.py:224:21
(EngineCore_DP0 pid=407880) 	// begin inline asm
(EngineCore_DP0 pid=407880) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=407880) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=407880) 	// end inline asm
(EngineCore_DP0 pid=407880) 	// begin inline asm
(EngineCore_DP0 pid=407880) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=407880) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=407880) 	// end inline asm
(EngineCore_DP0 pid=407880) 	.loc	1 225 79                        // quant_slide_tuned_Llama3.2-3B.py:225:79
(EngineCore_DP0 pid=407880) 	cvt.f32.bf16 	%r115, %rs48;
(EngineCore_DP0 pid=407880) 	cvt.f32.bf16 	%r116, %rs50;
(EngineCore_DP0 pid=407880) 	.loc	1 227 48                        // quant_slide_tuned_Llama3.2-3B.py:227:48
(EngineCore_DP0 pid=407880) 	or.b32 	%r117, %r114, 1;
(EngineCore_DP0 pid=407880) 	or.b32 	%r118, %r113, 1;
(EngineCore_DP0 pid=407880) 	.loc	1 227 53                        // quant_slide_tuned_Llama3.2-3B.py:227:53
(EngineCore_DP0 pid=407880) 	setp.lt.s32 	%p21, %r117, %r23;
(EngineCore_DP0 pid=407880) 	setp.lt.s32 	%p22, %r118, %r23;
(EngineCore_DP0 pid=407880) 	.loc	1 227 37                        // quant_slide_tuned_Llama3.2-3B.py:227:37
(EngineCore_DP0 pid=407880) 	and.pred 	%p12, %p18, %p21;
(EngineCore_DP0 pid=407880) 	and.pred 	%p13, %p18, %p22;
(EngineCore_DP0 pid=407880) 	.loc	1 226 39                        // quant_slide_tuned_Llama3.2-3B.py:226:39
(EngineCore_DP0 pid=407880) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=407880) 	add.s64 	%rd12, %rd10, 2;
(EngineCore_DP0 pid=407880) 	.loc	1 226 21                        // quant_slide_tuned_Llama3.2-3B.py:226:21
(EngineCore_DP0 pid=407880) 	// begin inline asm
(EngineCore_DP0 pid=407880) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=407880) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=407880) 	// end inline asm
(EngineCore_DP0 pid=407880) 	// begin inline asm
(EngineCore_DP0 pid=407880) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=407880) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=407880) 	// end inline asm
(EngineCore_DP0 pid=407880) 	.loc	1 227 79                        // quant_slide_tuned_Llama3.2-3B.py:227:79
(EngineCore_DP0 pid=407880) 	cvt.f32.bf16 	%r119, %rs52;
(EngineCore_DP0 pid=407880) 	cvt.f32.bf16 	%r120, %rs54;
(EngineCore_DP0 pid=407880) 	.loc	1 231 48                        // quant_slide_tuned_Llama3.2-3B.py:231:48
(EngineCore_DP0 pid=407880) 	add.s32 	%r121, %r114, 2;
(EngineCore_DP0 pid=407880) 	add.s32 	%r122, %r113, 2;
(EngineCore_DP0 pid=407880) 	add.s32 	%r123, %r114, 3;
(EngineCore_DP0 pid=407880) 	add.s32 	%r124, %r113, 3;
(EngineCore_DP0 pid=407880) 	.loc	1 231 53                        // quant_slide_tuned_Llama3.2-3B.py:231:53
(EngineCore_DP0 pid=407880) 	setp.lt.s32 	%p23, %r124, %r23;
(EngineCore_DP0 pid=407880) 	setp.lt.s32 	%p24, %r123, %r23;
(EngineCore_DP0 pid=407880) 	setp.lt.s32 	%p25, %r122, %r23;
(EngineCore_DP0 pid=407880) 	setp.lt.s32 	%p26, %r121, %r23;
(EngineCore_DP0 pid=407880) 	.loc	1 229 37                        // quant_slide_tuned_Llama3.2-3B.py:229:37
(EngineCore_DP0 pid=407880) 	and.pred 	%p14, %p18, %p26;
(EngineCore_DP0 pid=407880) 	and.pred 	%p15, %p18, %p25;
(EngineCore_DP0 pid=407880) 	.loc	1 228 39                        // quant_slide_tuned_Llama3.2-3B.py:228:39
(EngineCore_DP0 pid=407880) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=407880) 	add.s64 	%rd14, %rd10, 4;
(EngineCore_DP0 pid=407880) 	.loc	1 228 21                        // quant_slide_tuned_Llama3.2-3B.py:228:21
(EngineCore_DP0 pid=407880) 	// begin inline asm
(EngineCore_DP0 pid=407880) 	mov.u16 %rs56, %rs49;
(EngineCore_DP0 pid=407880) 	@%p14 ld.global.b16 { %rs56 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=407880) 	// end inline asm
(EngineCore_DP0 pid=407880) 	// begin inline asm
(EngineCore_DP0 pid=407880) 	mov.u16 %rs58, %rs49;
(EngineCore_DP0 pid=407880) 	@%p15 ld.global.b16 { %rs58 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=407880) 	// end inline asm
(EngineCore_DP0 pid=407880) 	.loc	1 229 79                        // quant_slide_tuned_Llama3.2-3B.py:229:79
(EngineCore_DP0 pid=407880) 	cvt.f32.bf16 	%r125, %rs56;
(EngineCore_DP0 pid=407880) 	cvt.f32.bf16 	%r126, %rs58;
(EngineCore_DP0 pid=407880) 	.loc	1 231 37                        // quant_slide_tuned_Llama3.2-3B.py:231:37
(EngineCore_DP0 pid=407880) 	and.pred 	%p16, %p18, %p24;
(EngineCore_DP0 pid=407880) 	and.pred 	%p17, %p18, %p23;
(EngineCore_DP0 pid=407880) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-3B.py:230:39
(EngineCore_DP0 pid=407880) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=407880) 	add.s64 	%rd16, %rd10, 6;
(EngineCore_DP0 pid=407880) 	.loc	1 230 21                        // quant_slide_tuned_Llama3.2-3B.py:230:21
(EngineCore_DP0 pid=407880) 	// begin inline asm
(EngineCore_DP0 pid=407880) 	mov.u16 %rs60, %rs49;
(EngineCore_DP0 pid=407880) 	@%p16 ld.global.b16 { %rs60 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=407880) 	// end inline asm
(EngineCore_DP0 pid=407880) 	// begin inline asm
(EngineCore_DP0 pid=407880) 	mov.u16 %rs62, %rs49;
(EngineCore_DP0 pid=407880) 	@%p17 ld.global.b16 { %rs62 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=407880) 	// end inline asm
(EngineCore_DP0 pid=407880) 	.loc	1 231 79                        // quant_slide_tuned_Llama3.2-3B.py:231:79
(EngineCore_DP0 pid=407880) 	cvt.f32.bf16 	%r127, %rs60;
(EngineCore_DP0 pid=407880) 	cvt.f32.bf16 	%r128, %rs62;
(EngineCore_DP0 pid=407880) 	.loc	1 233 27                        // quant_slide_tuned_Llama3.2-3B.py:233:27
(EngineCore_DP0 pid=407880) 	mul.f32 	%r129, %r14, %r115;
(EngineCore_DP0 pid=407880) 	mul.f32 	%r130, %r14, %r116;
(EngineCore_DP0 pid=407880) 	mov.b32 	%r131, 0f43E00000;
(EngineCore_DP0 pid=407880) 	.loc	1 233 48                        // quant_slide_tuned_Llama3.2-3B.py:233:48
(EngineCore_DP0 pid=407880) 	min.xorsign.abs.f32 	%r87, %r129, %r131;
(EngineCore_DP0 pid=407880) 	min.xorsign.abs.f32 	%r88, %r130, %r131;
(EngineCore_DP0 pid=407880) 	.loc	1 233 60                        // quant_slide_tuned_Llama3.2-3B.py:233:60
(EngineCore_DP0 pid=407880) 	// begin inline asm
(EngineCore_DP0 pid=407880) 	cvt.rn.satfinite.e4m3x2.f32  %rs64, %r88, %r87; 
(EngineCore_DP0 pid=407880) 
(EngineCore_DP0 pid=407880) 	// end inline asm
(EngineCore_DP0 pid=407880) 	shr.u16 	%rs68, %rs64, 8;
(EngineCore_DP0 pid=407880) 	.loc	1 234 27                        // quant_slide_tuned_Llama3.2-3B.py:234:27
(EngineCore_DP0 pid=407880) 	mul.f32 	%r132, %r14, %r119;
(EngineCore_DP0 pid=407880) 	mul.f32 	%r133, %r14, %r120;
(EngineCore_DP0 pid=407880) 	.loc	1 234 48                        // quant_slide_tuned_Llama3.2-3B.py:234:48
(EngineCore_DP0 pid=407880) 	min.xorsign.abs.f32 	%r89, %r132, %r131;
(EngineCore_DP0 pid=407880) 	min.xorsign.abs.f32 	%r90, %r133, %r131;
(EngineCore_DP0 pid=407880) 	.loc	1 234 60                        // quant_slide_tuned_Llama3.2-3B.py:234:60
(EngineCore_DP0 pid=407880) 	// begin inline asm
(EngineCore_DP0 pid=407880) 	cvt.rn.satfinite.e4m3x2.f32  %rs65, %r90, %r89; 
(EngineCore_DP0 pid=407880) 
(EngineCore_DP0 pid=407880) 	// end inline asm
(EngineCore_DP0 pid=407880) 	shr.u16 	%rs69, %rs65, 8;
(EngineCore_DP0 pid=407880) 	.loc	1 235 27                        // quant_slide_tuned_Llama3.2-3B.py:235:27
(EngineCore_DP0 pid=407880) 	mul.f32 	%r134, %r14, %r125;
(EngineCore_DP0 pid=407880) 	mul.f32 	%r135, %r14, %r126;
(EngineCore_DP0 pid=407880) 	.loc	1 235 48                        // quant_slide_tuned_Llama3.2-3B.py:235:48
(EngineCore_DP0 pid=407880) 	min.xorsign.abs.f32 	%r91, %r134, %r131;
(EngineCore_DP0 pid=407880) 	min.xorsign.abs.f32 	%r92, %r135, %r131;
(EngineCore_DP0 pid=407880) 	.loc	1 235 60                        // quant_slide_tuned_Llama3.2-3B.py:235:60
(EngineCore_DP0 pid=407880) 	// begin inline asm
(EngineCore_DP0 pid=407880) 	cvt.rn.satfinite.e4m3x2.f32  %rs66, %r92, %r91; 
(EngineCore_DP0 pid=407880) 
(EngineCore_DP0 pid=407880) 	// end inline asm
(EngineCore_DP0 pid=407880) 	shr.u16 	%rs70, %rs66, 8;
(EngineCore_DP0 pid=407880) 	.loc	1 236 27                        // quant_slide_tuned_Llama3.2-3B.py:236:27
(EngineCore_DP0 pid=407880) 	mul.f32 	%r136, %r14, %r127;
(EngineCore_DP0 pid=407880) 	mul.f32 	%r137, %r14, %r128;
(EngineCore_DP0 pid=407880) 	.loc	1 236 48                        // quant_slide_tuned_Llama3.2-3B.py:236:48
(EngineCore_DP0 pid=407880) 	min.xorsign.abs.f32 	%r93, %r136, %r131;
(EngineCore_DP0 pid=407880) 	min.xorsign.abs.f32 	%r94, %r137, %r131;
(EngineCore_DP0 pid=407880) 	.loc	1 236 60                        // quant_slide_tuned_Llama3.2-3B.py:236:60
(EngineCore_DP0 pid=407880) 	// begin inline asm
(EngineCore_DP0 pid=407880) 	cvt.rn.satfinite.e4m3x2.f32  %rs67, %r94, %r93; 
(EngineCore_DP0 pid=407880) 
(EngineCore_DP0 pid=407880) 	// end inline asm
(EngineCore_DP0 pid=407880) 	shr.u16 	%rs71, %rs67, 8;
(EngineCore_DP0 pid=407880) 	.loc	1 238 45                        // quant_slide_tuned_Llama3.2-3B.py:238:45
(EngineCore_DP0 pid=407880) 	cvt.u32.u16 	%r138, %rs64;
(EngineCore_DP0 pid=407880) 	and.b32 	%r139, %r138, 255;
(EngineCore_DP0 pid=407880) 	cvt.u32.u16 	%r140, %rs68;
(EngineCore_DP0 pid=407880) 	.loc	1 240 45                        // quant_slide_tuned_Llama3.2-3B.py:240:45
(EngineCore_DP0 pid=407880) 	cvt.u32.u16 	%r141, %rs66;
(EngineCore_DP0 pid=407880) 	and.b32 	%r142, %r141, 255;
(EngineCore_DP0 pid=407880) 	cvt.u32.u16 	%r143, %rs70;
(EngineCore_DP0 pid=407880) 	.loc	1 241 45                        // quant_slide_tuned_Llama3.2-3B.py:241:45
(EngineCore_DP0 pid=407880) 	cvt.u32.u16 	%r144, %rs67;
(EngineCore_DP0 pid=407880) 	cvt.u32.u16 	%r145, %rs71;
(EngineCore_DP0 pid=407880) 	.loc	1 243 30                        // quant_slide_tuned_Llama3.2-3B.py:243:30
(EngineCore_DP0 pid=407880) 	and.b16 	%rs72, %rs65, 255;
(EngineCore_DP0 pid=407880) 	mul.wide.u16 	%r146, %rs72, 256;
(EngineCore_DP0 pid=407880) 	mul.wide.u16 	%r147, %rs69, 256;
(EngineCore_DP0 pid=407880) 	.loc	1 243 24                        // quant_slide_tuned_Llama3.2-3B.py:243:24
(EngineCore_DP0 pid=407880) 	or.b32 	%r148, %r146, %r139;
(EngineCore_DP0 pid=407880) 	or.b32 	%r149, %r147, %r140;
(EngineCore_DP0 pid=407880) 	.loc	1 243 42                        // quant_slide_tuned_Llama3.2-3B.py:243:42
(EngineCore_DP0 pid=407880) 	shl.b32 	%r150, %r142, 16;
(EngineCore_DP0 pid=407880) 	shl.b32 	%r151, %r143, 16;
(EngineCore_DP0 pid=407880) 	.loc	1 243 36                        // quant_slide_tuned_Llama3.2-3B.py:243:36
(EngineCore_DP0 pid=407880) 	or.b32 	%r152, %r148, %r150;
(EngineCore_DP0 pid=407880) 	or.b32 	%r153, %r149, %r151;
(EngineCore_DP0 pid=407880) 	.loc	1 243 55                        // quant_slide_tuned_Llama3.2-3B.py:243:55
(EngineCore_DP0 pid=407880) 	shl.b32 	%r154, %r144, 24;
(EngineCore_DP0 pid=407880) 	shl.b32 	%r155, %r145, 24;
(EngineCore_DP0 pid=407880) 	.loc	1 243 49                        // quant_slide_tuned_Llama3.2-3B.py:243:49
(EngineCore_DP0 pid=407880) 	or.b32 	%r95, %r152, %r154;
(EngineCore_DP0 pid=407880) 	or.b32 	%r96, %r153, %r155;
(EngineCore_DP0 pid=407880) 	.loc	1 244 29                        // quant_slide_tuned_Llama3.2-3B.py:244:29
(EngineCore_DP0 pid=407880) 	mad.wide.s32 	%rd17, %r97, 4, %rd2;
(EngineCore_DP0 pid=407880) 	.loc	1 244 39                        // quant_slide_tuned_Llama3.2-3B.py:244:39
(EngineCore_DP0 pid=407880) 	// begin inline asm
(EngineCore_DP0 pid=407880) 	@%p18 st.global.v2.b32 [ %rd17 + 0 ], { %r95, %r96 };
(EngineCore_DP0 pid=407880) 	// end inline asm
(EngineCore_DP0 pid=407880) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=407880) 	add.s32 	%r159, %r159, 1024;
(EngineCore_DP0 pid=407880) 	setp.lt.s32 	%p27, %r159, %r15;
(EngineCore_DP0 pid=407880) 	@%p27 bra 	$L__BB0_6;
(EngineCore_DP0 pid=407880) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=407880) 	.loc	1 215 4                         // quant_slide_tuned_Llama3.2-3B.py:215:4
(EngineCore_DP0 pid=407880) 	ret;
(EngineCore_DP0 pid=407880) $L__tmp3:
(EngineCore_DP0 pid=407880) $L__func_end0:
(EngineCore_DP0 pid=407880)                                         // -- End function
(EngineCore_DP0 pid=407880) }
(EngineCore_DP0 pid=407880) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py"
(EngineCore_DP0 pid=407880) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=407880) 	.section	.debug_abbrev
(EngineCore_DP0 pid=407880) 	{
(EngineCore_DP0 pid=407880) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=407880) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=407880) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=407880) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=407880) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=407880) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=407880) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=407880) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=407880) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=407880) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=407880) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=407880) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=407880) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=407880) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=407880) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=407880) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=407880) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=407880) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=407880) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=407880) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=407880) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=407880) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=407880) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=407880) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=407880) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=407880) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=407880) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=407880) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=407880) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=407880) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=407880) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=407880) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=407880) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=407880) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=407880) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=407880) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=407880) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=407880) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=407880) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=407880) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=407880) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=407880) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=407880) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=407880) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=407880) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=407880) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=407880) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=407880) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=407880) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=407880) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=407880) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=407880) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=407880) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=407880) 	}
(EngineCore_DP0 pid=407880) 	.section	.debug_info
(EngineCore_DP0 pid=407880) 	{
(EngineCore_DP0 pid=407880) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=407880) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=407880) .b8 0
(EngineCore_DP0 pid=407880) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=407880) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=407880) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=407880) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=407880) .b8 114
(EngineCore_DP0 pid=407880) .b8 105
(EngineCore_DP0 pid=407880) .b8 116
(EngineCore_DP0 pid=407880) .b8 111
(EngineCore_DP0 pid=407880) .b8 110
(EngineCore_DP0 pid=407880) .b8 0
(EngineCore_DP0 pid=407880) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=407880) .b8 0
(EngineCore_DP0 pid=407880) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=407880) .b8 117
(EngineCore_DP0 pid=407880) .b8 97
(EngineCore_DP0 pid=407880) .b8 110
(EngineCore_DP0 pid=407880) .b8 116
(EngineCore_DP0 pid=407880) .b8 95
(EngineCore_DP0 pid=407880) .b8 115
(EngineCore_DP0 pid=407880) .b8 108
(EngineCore_DP0 pid=407880) .b8 105
(EngineCore_DP0 pid=407880) .b8 100
(EngineCore_DP0 pid=407880) .b8 101
(EngineCore_DP0 pid=407880) .b8 95
(EngineCore_DP0 pid=407880) .b8 116
(EngineCore_DP0 pid=407880) .b8 117
(EngineCore_DP0 pid=407880) .b8 110
(EngineCore_DP0 pid=407880) .b8 101
(EngineCore_DP0 pid=407880) .b8 100
(EngineCore_DP0 pid=407880) .b8 95
(EngineCore_DP0 pid=407880) .b8 76
(EngineCore_DP0 pid=407880) .b8 108
(EngineCore_DP0 pid=407880) .b8 97
(EngineCore_DP0 pid=407880) .b8 109
(EngineCore_DP0 pid=407880) .b8 97
(EngineCore_DP0 pid=407880) .b8 51
(EngineCore_DP0 pid=407880) .b8 46
(EngineCore_DP0 pid=407880) .b8 50
(EngineCore_DP0 pid=407880) .b8 45
(EngineCore_DP0 pid=407880) .b8 51
(EngineCore_DP0 pid=407880) .b8 66
(EngineCore_DP0 pid=407880) .b8 46
(EngineCore_DP0 pid=407880) .b8 112
(EngineCore_DP0 pid=407880) .b8 121
(EngineCore_DP0 pid=407880) .b8 0
(EngineCore_DP0 pid=407880) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=407880) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=407880) .b8 114
(EngineCore_DP0 pid=407880) .b8 111
(EngineCore_DP0 pid=407880) .b8 111
(EngineCore_DP0 pid=407880) .b8 116
(EngineCore_DP0 pid=407880) .b8 47
(EngineCore_DP0 pid=407880) .b8 118
(EngineCore_DP0 pid=407880) .b8 108
(EngineCore_DP0 pid=407880) .b8 108
(EngineCore_DP0 pid=407880) .b8 109
(EngineCore_DP0 pid=407880) .b8 98
(EngineCore_DP0 pid=407880) .b8 101
(EngineCore_DP0 pid=407880) .b8 110
(EngineCore_DP0 pid=407880) .b8 99
(EngineCore_DP0 pid=407880) .b8 104
(EngineCore_DP0 pid=407880) .b8 47
(EngineCore_DP0 pid=407880) .b8 115
(EngineCore_DP0 pid=407880) .b8 108
(EngineCore_DP0 pid=407880) .b8 105
(EngineCore_DP0 pid=407880) .b8 100
(EngineCore_DP0 pid=407880) .b8 101
(EngineCore_DP0 pid=407880) .b8 115
(EngineCore_DP0 pid=407880) .b8 112
(EngineCore_DP0 pid=407880) .b8 97
(EngineCore_DP0 pid=407880) .b8 114
(EngineCore_DP0 pid=407880) .b8 115
(EngineCore_DP0 pid=407880) .b8 101
(EngineCore_DP0 pid=407880) .b8 47
(EngineCore_DP0 pid=407880) .b8 99
(EngineCore_DP0 pid=407880) .b8 115
(EngineCore_DP0 pid=407880) .b8 114
(EngineCore_DP0 pid=407880) .b8 99
(EngineCore_DP0 pid=407880) .b8 47
(EngineCore_DP0 pid=407880) .b8 102
(EngineCore_DP0 pid=407880) .b8 117
(EngineCore_DP0 pid=407880) .b8 115
(EngineCore_DP0 pid=407880) .b8 101
(EngineCore_DP0 pid=407880) .b8 100
(EngineCore_DP0 pid=407880) .b8 95
(EngineCore_DP0 pid=407880) .b8 113
(EngineCore_DP0 pid=407880) .b8 117
(EngineCore_DP0 pid=407880) .b8 97
(EngineCore_DP0 pid=407880) .b8 110
(EngineCore_DP0 pid=407880) .b8 116
(EngineCore_DP0 pid=407880) .b8 95
(EngineCore_DP0 pid=407880) .b8 115
(EngineCore_DP0 pid=407880) .b8 108
(EngineCore_DP0 pid=407880) .b8 105
(EngineCore_DP0 pid=407880) .b8 100
(EngineCore_DP0 pid=407880) .b8 101
(EngineCore_DP0 pid=407880) .b8 95
(EngineCore_DP0 pid=407880) .b8 116
(EngineCore_DP0 pid=407880) .b8 114
(EngineCore_DP0 pid=407880) .b8 105
(EngineCore_DP0 pid=407880) .b8 116
(EngineCore_DP0 pid=407880) .b8 111
(EngineCore_DP0 pid=407880) .b8 110
(EngineCore_DP0 pid=407880) .b8 47
(EngineCore_DP0 pid=407880) .b8 98
(EngineCore_DP0 pid=407880) .b8 117
(EngineCore_DP0 pid=407880) .b8 105
(EngineCore_DP0 pid=407880) .b8 108
(EngineCore_DP0 pid=407880) .b8 100
(EngineCore_DP0 pid=407880) .b8 47
(EngineCore_DP0 pid=407880) .b8 71
(EngineCore_DP0 pid=407880) .b8 66
(EngineCore_DP0 pid=407880) .b8 49
(EngineCore_DP0 pid=407880) .b8 48
(EngineCore_DP0 pid=407880) .b8 95
(EngineCore_DP0 pid=407880) .b8 99
(EngineCore_DP0 pid=407880) .b8 99
(EngineCore_DP0 pid=407880) .b8 49
(EngineCore_DP0 pid=407880) .b8 50
(EngineCore_DP0 pid=407880) .b8 49
(EngineCore_DP0 pid=407880) .b8 95
(EngineCore_DP0 pid=407880) .b8 112
(EngineCore_DP0 pid=407880) .b8 121
(EngineCore_DP0 pid=407880) .b8 51
(EngineCore_DP0 pid=407880) .b8 49
(EngineCore_DP0 pid=407880) .b8 50
(EngineCore_DP0 pid=407880) .b8 95
(EngineCore_DP0 pid=407880) .b8 99
(EngineCore_DP0 pid=407880) .b8 117
(EngineCore_DP0 pid=407880) .b8 49
(EngineCore_DP0 pid=407880) .b8 50
(EngineCore_DP0 pid=407880) .b8 57
(EngineCore_DP0 pid=407880) .b8 95
(EngineCore_DP0 pid=407880) .b8 97
(EngineCore_DP0 pid=407880) .b8 97
(EngineCore_DP0 pid=407880) .b8 114
(EngineCore_DP0 pid=407880) .b8 99
(EngineCore_DP0 pid=407880) .b8 104
(EngineCore_DP0 pid=407880) .b8 54
(EngineCore_DP0 pid=407880) .b8 52
(EngineCore_DP0 pid=407880) .b8 0
(EngineCore_DP0 pid=407880) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=407880) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=407880) .b8 113
(EngineCore_DP0 pid=407880) .b8 117
(EngineCore_DP0 pid=407880) .b8 97
(EngineCore_DP0 pid=407880) .b8 110
(EngineCore_DP0 pid=407880) .b8 116
(EngineCore_DP0 pid=407880) .b8 95
(EngineCore_DP0 pid=407880) .b8 115
(EngineCore_DP0 pid=407880) .b8 108
(EngineCore_DP0 pid=407880) .b8 105
(EngineCore_DP0 pid=407880) .b8 100
(EngineCore_DP0 pid=407880) .b8 101
(EngineCore_DP0 pid=407880) .b8 95
(EngineCore_DP0 pid=407880) .b8 102
(EngineCore_DP0 pid=407880) .b8 112
(EngineCore_DP0 pid=407880) .b8 56
(EngineCore_DP0 pid=407880) .b8 95
(EngineCore_DP0 pid=407880) .b8 107
(EngineCore_DP0 pid=407880) .b8 101
(EngineCore_DP0 pid=407880) .b8 114
(EngineCore_DP0 pid=407880) .b8 110
(EngineCore_DP0 pid=407880) .b8 101
(EngineCore_DP0 pid=407880) .b8 108
(EngineCore_DP0 pid=407880) .b8 0
(EngineCore_DP0 pid=407880) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=407880) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=407880) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=407880) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=407880) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=407880) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=407880) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=407880) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=407880) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=407880) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=407880) .b8 205                                 // DW_AT_call_line
(EngineCore_DP0 pid=407880) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=407880) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=407880) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=407880) 	}
(EngineCore_DP0 pid=407880) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=407880) 
(EngineCore_DP0 pid=407880) ================================================================
(EngineCore_DP0 pid=407880) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=407880) 
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpui6uhxil.ptx', '-o', '/tmp/tmpui6uhxil.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866] 
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866] 
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866] 
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpui6uhxil.ptx -o /tmp/tmpui6uhxil.ptx.o
(EngineCore_DP0 pid=407880) ERROR 01-25 20:18:43 [core.py:866] 

STDERR:
[2026-01-25 20:18:11] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:18:11] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:18:11] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:18:11] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:18:11] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:18:11] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:18:11] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:18:11] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:18:11] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:18:11] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:18:11] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:18:11] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:18:11] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:18:11] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:18:15] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:18:15] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:18:15] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:18:15] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:18:15] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:18:15] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:18:15] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:18:15] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:18:15] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:18:15] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:18:15] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:18:15] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:18:15] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:18:15] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=407880) [2026-01-25 20:18:16] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=407880) [2026-01-25 20:18:16] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=407880) [2026-01-25 20:18:16] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=407880) [2026-01-25 20:18:16] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=407880) [2026-01-25 20:18:16] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=407880) [2026-01-25 20:18:16] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=407880) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=407880) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:25<00:00, 25.13s/it]
(EngineCore_DP0 pid=407880) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:25<00:00, 25.13s/it]
(EngineCore_DP0 pid=407880) 
(EngineCore_DP0 pid=407880) [2026-01-25 20:18:42] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4928] -> 1D uint8
(EngineCore_DP0 pid=407880) [2026-01-25 20:18:42] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15810560 bytes
(EngineCore_DP0 pid=407880) [2026-01-25 20:18:42] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4928] -> 1D uint8
(EngineCore_DP0 pid=407880) [2026-01-25 20:18:42] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9486336 bytes
(EngineCore_DP0 pid=407880) [2026-01-25 20:18:42] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4928] -> 1D uint8
(EngineCore_DP0 pid=407880) [2026-01-25 20:18:42] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 50593792 bytes
(EngineCore_DP0 pid=407880) [2026-01-25 20:18:42] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 13120] -> 1D uint8
(EngineCore_DP0 pid=407880) [2026-01-25 20:18:42] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 25214976 bytes
(EngineCore_DP0 pid=407880) Process EngineCore_DP0:
(EngineCore_DP0 pid=407880) Traceback (most recent call last):
(EngineCore_DP0 pid=407880)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=407880)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=407880)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=407880)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=407880) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpui6uhxil.ptx', '-o', '/tmp/tmpui6uhxil.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=407880) 
(EngineCore_DP0 pid=407880) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=407880) 
(EngineCore_DP0 pid=407880) Traceback (most recent call last):
(EngineCore_DP0 pid=407880)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=407880)     self.run()
(EngineCore_DP0 pid=407880)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=407880)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=407880)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=407880)     raise e
(EngineCore_DP0 pid=407880)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=407880)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=407880)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=407880)     super().__init__(
(EngineCore_DP0 pid=407880)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=407880)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=407880)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=407880)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=407880)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=407880)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=407880)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=407880)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=407880)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=407880)     return func(*args, **kwargs)
(EngineCore_DP0 pid=407880)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=407880)     return func(*args, **kwargs)
(EngineCore_DP0 pid=407880)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=407880)     self.model_runner.profile_run()
(EngineCore_DP0 pid=407880)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=407880)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=407880)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=407880)     return func(*args, **kwargs)
(EngineCore_DP0 pid=407880)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=407880)     outputs = self.model(
(EngineCore_DP0 pid=407880)               ^^^^^^^^^^^
(EngineCore_DP0 pid=407880)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=407880)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=407880)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=407880)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=407880)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=407880)     model_output = self.model(
(EngineCore_DP0 pid=407880)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=407880)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=407880)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=407880)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=407880)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=407880)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=407880)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=407880)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=407880)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=407880)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=407880)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=407880)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=407880)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=407880)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=407880)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=407880)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=407880)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=407880)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=407880)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=407880)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=407880)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=407880)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=407880)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=407880)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=407880)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=407880)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=407880)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=407880)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=407880)     return self._linear_fn(
(EngineCore_DP0 pid=407880)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=407880)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=407880)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=407880)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=407880)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=407880)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=407880)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=407880)     return fn(input, L)
(EngineCore_DP0 pid=407880)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=407880)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=407880)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=407880)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=407880)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=407880)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=407880)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=407880)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=407880)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=407880)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=407880)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=407880)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=407880)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=407880)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=407880)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=407880)     raise PTXASError(error)
(EngineCore_DP0 pid=407880) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=407880) `ptxas` stderr:
(EngineCore_DP0 pid=407880) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=407880) 
(EngineCore_DP0 pid=407880) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpui6uhxil.ptx -o /tmp/tmpui6uhxil.ptx.o
(EngineCore_DP0 pid=407880) 
[rank0]:[W125 20:18:43.713884840 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=16384

========== M=32768 ==========
Time: 2026-01-25 20:18:45
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-3B-FP8_M32768.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:19:00 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 20:19:00 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=408724) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=408724) 
(EngineCore_DP0 pid=408724) 
(EngineCore_DP0 pid=408724) ================================================================
(EngineCore_DP0 pid=408724) Internal Triton PTX codegen error
(EngineCore_DP0 pid=408724) `ptxas` stderr:
(EngineCore_DP0 pid=408724) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=408724) 
(EngineCore_DP0 pid=408724) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpqwm097ao.ptx -o /tmp/tmpqwm097ao.ptx.o
(EngineCore_DP0 pid=408724) 
(EngineCore_DP0 pid=408724) 
(EngineCore_DP0 pid=408724) //
(EngineCore_DP0 pid=408724) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=408724) //
(EngineCore_DP0 pid=408724) 
(EngineCore_DP0 pid=408724) .version 8.7
(EngineCore_DP0 pid=408724) .target sm_121a
(EngineCore_DP0 pid=408724) .address_size 64
(EngineCore_DP0 pid=408724) 
(EngineCore_DP0 pid=408724) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=408724) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=408724)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=408724) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=408724) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=408724) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=408724) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=408724) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=408724) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=408724) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=408724) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=408724) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=408724) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=408724) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=408724) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=408724) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=408724) )
(EngineCore_DP0 pid=408724) .reqntid 512
(EngineCore_DP0 pid=408724) {
(EngineCore_DP0 pid=408724) 	.reg .pred 	%p<44>;
(EngineCore_DP0 pid=408724) 	.reg .b16 	%rs<74>;
(EngineCore_DP0 pid=408724) 	.reg .b32 	%r<212>;
(EngineCore_DP0 pid=408724) 	.reg .b64 	%rd<25>;
(EngineCore_DP0 pid=408724) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=408724) $L__func_begin0:
(EngineCore_DP0 pid=408724) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=408724) 
(EngineCore_DP0 pid=408724) // %bb.0:
(EngineCore_DP0 pid=408724) 	ld.param.b32 	%r29, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=408724) 	ld.param.b32 	%r28, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=408724) 	ld.param.b32 	%r27, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=408724) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=408724) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=408724) $L__tmp0:
(EngineCore_DP0 pid=408724) 	.loc	1 191 24                        // quant_slide_tuned_Llama3.2-3B.py:191:24
(EngineCore_DP0 pid=408724) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=408724) 	ld.param.b32 	%r31, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=408724) 	.loc	1 196 26                        // quant_slide_tuned_Llama3.2-3B.py:196:26
(EngineCore_DP0 pid=408724) 	mul.lo.s32 	%r32, %r31, %r1;
(EngineCore_DP0 pid=408724) 	.loc	1 196 20                        // quant_slide_tuned_Llama3.2-3B.py:196:20
(EngineCore_DP0 pid=408724) 	mad.wide.s32 	%rd1, %r32, 2, %rd4;
(EngineCore_DP0 pid=408724) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=408724) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=408724) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=408724) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=408724) 	setp.lt.s32 	%p1, %r28, 1;
(EngineCore_DP0 pid=408724) 	mov.b32 	%r210, 0f2B8CBCCC;
(EngineCore_DP0 pid=408724) 	setp.eq.b32 	%p43, %r2, 0;
(EngineCore_DP0 pid=408724) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=408724) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=408724) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=408724) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=408724) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=408724) 	shr.u32 	%r41, %r2, 3;
(EngineCore_DP0 pid=408724) 	and.b32 	%r42, %r41, 60;
(EngineCore_DP0 pid=408724) 	mov.b32 	%r43, global_smem;
(EngineCore_DP0 pid=408724) 	add.s32 	%r53, %r43, %r42;
(EngineCore_DP0 pid=408724) 	shl.b32 	%r44, %r2, 2;
(EngineCore_DP0 pid=408724) 	add.s32 	%r56, %r43, %r44;
(EngineCore_DP0 pid=408724) 	mov.b32 	%r49, 0;
(EngineCore_DP0 pid=408724) 	mov.b32 	%r208, 0f00000000;
(EngineCore_DP0 pid=408724) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=408724) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=408724) 	mov.b32 	%r209, %r49;
(EngineCore_DP0 pid=408724) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=408724) 	.loc	1 203 22                        // quant_slide_tuned_Llama3.2-3B.py:203:22
(EngineCore_DP0 pid=408724) 	add.s32 	%r59, %r4, %r209;
(EngineCore_DP0 pid=408724) 	setp.lt.s32 	%p2, %r59, %r27;
(EngineCore_DP0 pid=408724) 	.loc	1 204 29                        // quant_slide_tuned_Llama3.2-3B.py:204:29
(EngineCore_DP0 pid=408724) 	mad.wide.s32 	%rd6, %r59, 2, %rd1;
(EngineCore_DP0 pid=408724) 	.loc	1 204 21                        // quant_slide_tuned_Llama3.2-3B.py:204:21
(EngineCore_DP0 pid=408724) 	// begin inline asm
(EngineCore_DP0 pid=408724) 	mov.u32 %r45, %r49;
(EngineCore_DP0 pid=408724) 	mov.u32 %r46, %r49;
(EngineCore_DP0 pid=408724) 	mov.u32 %r47, %r49;
(EngineCore_DP0 pid=408724) 	mov.u32 %r48, %r49;
(EngineCore_DP0 pid=408724) 	@%p2 ld.global.v4.b32 { %r45, %r46, %r47, %r48 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=408724) 	// end inline asm
(EngineCore_DP0 pid=408724) 	mov.b32 	{%rs1, %rs2}, %r45;
(EngineCore_DP0 pid=408724) 	mov.b32 	{%rs3, %rs4}, %r46;
(EngineCore_DP0 pid=408724) 	mov.b32 	{%rs5, %rs6}, %r47;
(EngineCore_DP0 pid=408724) 	mov.b32 	{%rs7, %rs8}, %r48;
(EngineCore_DP0 pid=408724) 	.loc	1 205 50                        // quant_slide_tuned_Llama3.2-3B.py:205:50
(EngineCore_DP0 pid=408724) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=408724) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=408724) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=408724) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=408724) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=408724) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=408724) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=408724) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=408724) $L__tmp1:
(EngineCore_DP0 pid=408724) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=408724) 	bar.sync 	0;
(EngineCore_DP0 pid=408724) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=408724) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=408724) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=408724) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=408724) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=408724) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=408724) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=408724) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=408724) 	cvt.f32.bf16 	%r60, %rs23;
(EngineCore_DP0 pid=408724) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=408724) 	shfl.sync.bfly.b32 	%r61, %r60, 16, 31, -1;
(EngineCore_DP0 pid=408724) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=408724) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=408724) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=408724) 	shfl.sync.bfly.b32 	%r63, %r62, 8, 31, -1;
(EngineCore_DP0 pid=408724) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=408724) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=408724) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=408724) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=408724) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=408724) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=408724) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=408724) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=408724) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=408724) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=408724) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=408724) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=408724) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=408724) 	max.f32 	%r54, %r68, %r69;
(EngineCore_DP0 pid=408724) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=408724) 	// begin inline asm
(EngineCore_DP0 pid=408724) 	@%p3 st.shared.b32 [ %r53 + 0 ], %r54;
(EngineCore_DP0 pid=408724) 	// end inline asm
(EngineCore_DP0 pid=408724) 	bar.sync 	0;
(EngineCore_DP0 pid=408724) 	// begin inline asm
(EngineCore_DP0 pid=408724) 	@%p4 ld.shared.b32 %r55, [ %r56 + 0 ];
(EngineCore_DP0 pid=408724) 	// end inline asm
(EngineCore_DP0 pid=408724) 	shfl.sync.bfly.b32 	%r70, %r55, 8, 31, -1;
(EngineCore_DP0 pid=408724) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=408724) 	max.f32 	%r71, %r55, %r70;
(EngineCore_DP0 pid=408724) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=408724) 	shfl.sync.bfly.b32 	%r72, %r71, 4, 31, -1;
(EngineCore_DP0 pid=408724) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=408724) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=408724) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=408724) 	shfl.sync.bfly.b32 	%r74, %r73, 2, 31, -1;
(EngineCore_DP0 pid=408724) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=408724) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=408724) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=408724) 	shfl.sync.bfly.b32 	%r76, %r75, 1, 31, -1;
(EngineCore_DP0 pid=408724) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=408724) 	max.f32 	%r58, %r75, %r76;
(EngineCore_DP0 pid=408724) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=408724) 	// begin inline asm
(EngineCore_DP0 pid=408724) 	@%p43 st.shared.b32 [ %r56 + 0 ], %r58;
(EngineCore_DP0 pid=408724) 	// end inline asm
(EngineCore_DP0 pid=408724) 	bar.sync 	0;
(EngineCore_DP0 pid=408724) 	ld.shared.b32 	%r77, [global_smem];
(EngineCore_DP0 pid=408724) $L__tmp2:
(EngineCore_DP0 pid=408724) 	.loc	1 205 36                        // quant_slide_tuned_Llama3.2-3B.py:205:36
(EngineCore_DP0 pid=408724) 	max.f32 	%r208, %r208, %r77;
(EngineCore_DP0 pid=408724) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=408724) 	add.s32 	%r209, %r209, 4096;
(EngineCore_DP0 pid=408724) 	setp.lt.s32 	%p6, %r209, %r28;
(EngineCore_DP0 pid=408724) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=408724) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=408724) 	.loc	1 207 32                        // quant_slide_tuned_Llama3.2-3B.py:207:32
(EngineCore_DP0 pid=408724) 	max.f32 	%r210, %r208, 0f2B8CBCCC;
(EngineCore_DP0 pid=408724) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=408724) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-3B.py:0:32
(EngineCore_DP0 pid=408724) 	mov.b32 	%r79, 0f43E00000;
(EngineCore_DP0 pid=408724) 	.loc	1 208 32                        // quant_slide_tuned_Llama3.2-3B.py:208:32
(EngineCore_DP0 pid=408724) 	div.full.f32 	%r80, %r210, %r79;
(EngineCore_DP0 pid=408724) 	.loc	1 208 41                        // quant_slide_tuned_Llama3.2-3B.py:208:41
(EngineCore_DP0 pid=408724) 	max.f32 	%r78, %r80, 0f36924925;
(EngineCore_DP0 pid=408724) 	.loc	1 210 25                        // quant_slide_tuned_Llama3.2-3B.py:210:25
(EngineCore_DP0 pid=408724) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=408724) 	.loc	1 210 30                        // quant_slide_tuned_Llama3.2-3B.py:210:30
(EngineCore_DP0 pid=408724) 	// begin inline asm
(EngineCore_DP0 pid=408724) 	@%p43 st.global.b32 [ %rd7 + 0 ], { %r78 };
(EngineCore_DP0 pid=408724) 	// end inline asm
(EngineCore_DP0 pid=408724) 	.loc	1 213 29                        // quant_slide_tuned_Llama3.2-3B.py:213:29
(EngineCore_DP0 pid=408724) 	shl.b32 	%r15, %r29, 2;
(EngineCore_DP0 pid=408724) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=408724) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=408724) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=408724) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=408724) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-3B.py:0:41
(EngineCore_DP0 pid=408724) 	ld.param.b32 	%r33, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=408724) 	shr.s32 	%r34, %r33, 31;
(EngineCore_DP0 pid=408724) 	shr.u32 	%r35, %r34, 30;
(EngineCore_DP0 pid=408724) 	add.s32 	%r36, %r33, %r35;
(EngineCore_DP0 pid=408724) 	shr.s32 	%r37, %r36, 2;
(EngineCore_DP0 pid=408724) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=408724) 	mul.lo.s32 	%r38, %r37, %r1;
(EngineCore_DP0 pid=408724) 	mad.wide.s32 	%rd2, %r38, 4, %rd5;
(EngineCore_DP0 pid=408724) 	div.full.f32 	%r14, %r79, %r210;
(EngineCore_DP0 pid=408724) 	shl.b32 	%r16, %r3, 2;
(EngineCore_DP0 pid=408724) 	mov.b32 	%r211, 0;
(EngineCore_DP0 pid=408724) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=408724)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=408724) 	.loc	1 216 31                        // quant_slide_tuned_Llama3.2-3B.py:216:31
(EngineCore_DP0 pid=408724) 	add.s32 	%r102, %r16, %r211;
(EngineCore_DP0 pid=408724) 	or.b32 	%r103, %r211, 2;
(EngineCore_DP0 pid=408724) 	or.b32 	%r104, %r211, 3;
(EngineCore_DP0 pid=408724) 	.loc	1 217 30                        // quant_slide_tuned_Llama3.2-3B.py:217:30
(EngineCore_DP0 pid=408724) 	setp.lt.s32 	%p25, %r102, %r15;
(EngineCore_DP0 pid=408724) 	.loc	1 220 24                        // quant_slide_tuned_Llama3.2-3B.py:220:24
(EngineCore_DP0 pid=408724) 	shr.s32 	%r105, %r102, 2;
(EngineCore_DP0 pid=408724) 	.loc	1 221 23                        // quant_slide_tuned_Llama3.2-3B.py:221:23
(EngineCore_DP0 pid=408724) 	add.s32 	%r106, %r211, 1;
(EngineCore_DP0 pid=408724) 	shr.s32 	%r107, %r106, 31;
(EngineCore_DP0 pid=408724) 	shr.u32 	%r108, %r107, 30;
(EngineCore_DP0 pid=408724) 	add.s32 	%r109, %r106, %r108;
(EngineCore_DP0 pid=408724) 	and.b32 	%r110, %r109, 2147483644;
(EngineCore_DP0 pid=408724) 	sub.s32 	%r111, %r106, %r110;
(EngineCore_DP0 pid=408724) 	.loc	1 222 30                        // quant_slide_tuned_Llama3.2-3B.py:222:30
(EngineCore_DP0 pid=408724) 	shl.b32 	%r112, %r111, 1;
(EngineCore_DP0 pid=408724) 	.loc	1 222 22                        // quant_slide_tuned_Llama3.2-3B.py:222:22
(EngineCore_DP0 pid=408724) 	mul.lo.s32 	%r113, %r105, 10;
(EngineCore_DP0 pid=408724) 	.loc	1 222 26                        // quant_slide_tuned_Llama3.2-3B.py:222:26
(EngineCore_DP0 pid=408724) 	add.s32 	%r114, %r113, %r112;
(EngineCore_DP0 pid=408724) 	.loc	1 221 23                        // quant_slide_tuned_Llama3.2-3B.py:221:23
(EngineCore_DP0 pid=408724) 	shr.s32 	%r115, %r211, 31;
(EngineCore_DP0 pid=408724) 	shr.u32 	%r116, %r115, 30;
(EngineCore_DP0 pid=408724) 	add.s32 	%r117, %r104, %r116;
(EngineCore_DP0 pid=408724) 	and.b32 	%r118, %r117, 2147483644;
(EngineCore_DP0 pid=408724) 	sub.s32 	%r119, %r104, %r118;
(EngineCore_DP0 pid=408724) 	add.s32 	%r120, %r103, %r116;
(EngineCore_DP0 pid=408724) 	and.b32 	%r121, %r120, 2147483644;
(EngineCore_DP0 pid=408724) 	sub.s32 	%r122, %r103, %r121;
(EngineCore_DP0 pid=408724) 	.loc	1 222 30                        // quant_slide_tuned_Llama3.2-3B.py:222:30
(EngineCore_DP0 pid=408724) 	shl.b32 	%r123, %r122, 1;
(EngineCore_DP0 pid=408724) 	shl.b32 	%r124, %r119, 1;
(EngineCore_DP0 pid=408724) 	.loc	1 222 26                        // quant_slide_tuned_Llama3.2-3B.py:222:26
(EngineCore_DP0 pid=408724) 	add.s32 	%r125, %r113, %r124;
(EngineCore_DP0 pid=408724) 	add.s32 	%r126, %r113, %r123;
(EngineCore_DP0 pid=408724) 	.loc	1 225 53                        // quant_slide_tuned_Llama3.2-3B.py:225:53
(EngineCore_DP0 pid=408724) 	setp.lt.s32 	%p26, %r113, %r27;
(EngineCore_DP0 pid=408724) 	setp.lt.s32 	%p27, %r114, %r27;
(EngineCore_DP0 pid=408724) 	setp.lt.s32 	%p28, %r126, %r27;
(EngineCore_DP0 pid=408724) 	setp.lt.s32 	%p29, %r125, %r27;
(EngineCore_DP0 pid=408724) 	.loc	1 225 37                        // quant_slide_tuned_Llama3.2-3B.py:225:37
(EngineCore_DP0 pid=408724) 	and.pred 	%p9, %p25, %p26;
(EngineCore_DP0 pid=408724) 	and.pred 	%p10, %p25, %p27;
(EngineCore_DP0 pid=408724) 	and.pred 	%p11, %p25, %p28;
(EngineCore_DP0 pid=408724) 	and.pred 	%p12, %p25, %p29;
(EngineCore_DP0 pid=408724) 	.loc	1 224 29                        // quant_slide_tuned_Llama3.2-3B.py:224:29
(EngineCore_DP0 pid=408724) 	mad.wide.s32 	%rd8, %r113, 2, %rd1;
(EngineCore_DP0 pid=408724) 	mad.wide.s32 	%rd9, %r114, 2, %rd1;
(EngineCore_DP0 pid=408724) 	mad.wide.s32 	%rd10, %r126, 2, %rd1;
(EngineCore_DP0 pid=408724) 	mad.wide.s32 	%rd11, %r125, 2, %rd1;
(EngineCore_DP0 pid=408724) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=408724) 	.loc	1 224 21                        // quant_slide_tuned_Llama3.2-3B.py:224:21
(EngineCore_DP0 pid=408724) 	// begin inline asm
(EngineCore_DP0 pid=408724) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=408724) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=408724) 	// end inline asm
(EngineCore_DP0 pid=408724) 	// begin inline asm
(EngineCore_DP0 pid=408724) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=408724) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=408724) 	// end inline asm
(EngineCore_DP0 pid=408724) 	// begin inline asm
(EngineCore_DP0 pid=408724) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=408724) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=408724) 	// end inline asm
(EngineCore_DP0 pid=408724) 	// begin inline asm
(EngineCore_DP0 pid=408724) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=408724) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=408724) 	// end inline asm
(EngineCore_DP0 pid=408724) 	.loc	1 225 79                        // quant_slide_tuned_Llama3.2-3B.py:225:79
(EngineCore_DP0 pid=408724) 	cvt.f32.bf16 	%r127, %rs24;
(EngineCore_DP0 pid=408724) 	cvt.f32.bf16 	%r128, %rs26;
(EngineCore_DP0 pid=408724) 	cvt.f32.bf16 	%r129, %rs28;
(EngineCore_DP0 pid=408724) 	cvt.f32.bf16 	%r130, %rs30;
(EngineCore_DP0 pid=408724) 	.loc	1 227 48                        // quant_slide_tuned_Llama3.2-3B.py:227:48
(EngineCore_DP0 pid=408724) 	or.b32 	%r131, %r113, 1;
(EngineCore_DP0 pid=408724) 	or.b32 	%r132, %r114, 1;
(EngineCore_DP0 pid=408724) 	or.b32 	%r133, %r126, 1;
(EngineCore_DP0 pid=408724) 	or.b32 	%r134, %r125, 1;
(EngineCore_DP0 pid=408724) 	.loc	1 227 53                        // quant_slide_tuned_Llama3.2-3B.py:227:53
(EngineCore_DP0 pid=408724) 	setp.lt.s32 	%p30, %r131, %r27;
(EngineCore_DP0 pid=408724) 	setp.lt.s32 	%p31, %r132, %r27;
(EngineCore_DP0 pid=408724) 	setp.lt.s32 	%p32, %r133, %r27;
(EngineCore_DP0 pid=408724) 	setp.lt.s32 	%p33, %r134, %r27;
(EngineCore_DP0 pid=408724) 	.loc	1 227 37                        // quant_slide_tuned_Llama3.2-3B.py:227:37
(EngineCore_DP0 pid=408724) 	and.pred 	%p13, %p25, %p30;
(EngineCore_DP0 pid=408724) 	and.pred 	%p14, %p25, %p31;
(EngineCore_DP0 pid=408724) 	and.pred 	%p15, %p25, %p32;
(EngineCore_DP0 pid=408724) 	and.pred 	%p16, %p25, %p33;
(EngineCore_DP0 pid=408724) 	.loc	1 226 39                        // quant_slide_tuned_Llama3.2-3B.py:226:39
(EngineCore_DP0 pid=408724) 	add.s64 	%rd12, %rd8, 2;
(EngineCore_DP0 pid=408724) 	add.s64 	%rd13, %rd9, 2;
(EngineCore_DP0 pid=408724) 	add.s64 	%rd14, %rd10, 2;
(EngineCore_DP0 pid=408724) 	add.s64 	%rd15, %rd11, 2;
(EngineCore_DP0 pid=408724) 	.loc	1 226 21                        // quant_slide_tuned_Llama3.2-3B.py:226:21
(EngineCore_DP0 pid=408724) 	// begin inline asm
(EngineCore_DP0 pid=408724) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=408724) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=408724) 	// end inline asm
(EngineCore_DP0 pid=408724) 	// begin inline asm
(EngineCore_DP0 pid=408724) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=408724) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=408724) 	// end inline asm
(EngineCore_DP0 pid=408724) 	// begin inline asm
(EngineCore_DP0 pid=408724) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=408724) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=408724) 	// end inline asm
(EngineCore_DP0 pid=408724) 	// begin inline asm
(EngineCore_DP0 pid=408724) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=408724) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=408724) 	// end inline asm
(EngineCore_DP0 pid=408724) 	.loc	1 227 79                        // quant_slide_tuned_Llama3.2-3B.py:227:79
(EngineCore_DP0 pid=408724) 	cvt.f32.bf16 	%r135, %rs32;
(EngineCore_DP0 pid=408724) 	cvt.f32.bf16 	%r136, %rs34;
(EngineCore_DP0 pid=408724) 	cvt.f32.bf16 	%r137, %rs36;
(EngineCore_DP0 pid=408724) 	cvt.f32.bf16 	%r138, %rs38;
(EngineCore_DP0 pid=408724) 	.loc	1 231 48                        // quant_slide_tuned_Llama3.2-3B.py:231:48
(EngineCore_DP0 pid=408724) 	add.s32 	%r139, %r114, 2;
(EngineCore_DP0 pid=408724) 	add.s32 	%r140, %r126, 2;
(EngineCore_DP0 pid=408724) 	add.s32 	%r141, %r125, 2;
(EngineCore_DP0 pid=408724) 	add.s32 	%r142, %r114, 3;
(EngineCore_DP0 pid=408724) 	add.s32 	%r143, %r126, 3;
(EngineCore_DP0 pid=408724) 	add.s32 	%r144, %r125, 3;
(EngineCore_DP0 pid=408724) 	add.s32 	%r145, %r113, 2;
(EngineCore_DP0 pid=408724) 	add.s32 	%r146, %r113, 3;
(EngineCore_DP0 pid=408724) 	.loc	1 231 53                        // quant_slide_tuned_Llama3.2-3B.py:231:53
(EngineCore_DP0 pid=408724) 	setp.lt.s32 	%p34, %r144, %r27;
(EngineCore_DP0 pid=408724) 	setp.lt.s32 	%p35, %r143, %r27;
(EngineCore_DP0 pid=408724) 	setp.lt.s32 	%p36, %r142, %r27;
(EngineCore_DP0 pid=408724) 	setp.lt.s32 	%p37, %r141, %r27;
(EngineCore_DP0 pid=408724) 	setp.lt.s32 	%p38, %r140, %r27;
(EngineCore_DP0 pid=408724) 	setp.lt.s32 	%p39, %r139, %r27;
(EngineCore_DP0 pid=408724) 	setp.lt.s32 	%p40, %r146, %r27;
(EngineCore_DP0 pid=408724) 	setp.lt.s32 	%p41, %r145, %r27;
(EngineCore_DP0 pid=408724) 	.loc	1 229 37                        // quant_slide_tuned_Llama3.2-3B.py:229:37
(EngineCore_DP0 pid=408724) 	and.pred 	%p17, %p25, %p41;
(EngineCore_DP0 pid=408724) 	and.pred 	%p18, %p25, %p39;
(EngineCore_DP0 pid=408724) 	and.pred 	%p19, %p25, %p38;
(EngineCore_DP0 pid=408724) 	and.pred 	%p20, %p25, %p37;
(EngineCore_DP0 pid=408724) 	.loc	1 228 39                        // quant_slide_tuned_Llama3.2-3B.py:228:39
(EngineCore_DP0 pid=408724) 	add.s64 	%rd16, %rd8, 4;
(EngineCore_DP0 pid=408724) 	add.s64 	%rd17, %rd9, 4;
(EngineCore_DP0 pid=408724) 	add.s64 	%rd18, %rd10, 4;
(EngineCore_DP0 pid=408724) 	add.s64 	%rd19, %rd11, 4;
(EngineCore_DP0 pid=408724) 	.loc	1 228 21                        // quant_slide_tuned_Llama3.2-3B.py:228:21
(EngineCore_DP0 pid=408724) 	// begin inline asm
(EngineCore_DP0 pid=408724) 	mov.u16 %rs40, %rs25;
(EngineCore_DP0 pid=408724) 	@%p17 ld.global.b16 { %rs40 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=408724) 	// end inline asm
(EngineCore_DP0 pid=408724) 	// begin inline asm
(EngineCore_DP0 pid=408724) 	mov.u16 %rs42, %rs25;
(EngineCore_DP0 pid=408724) 	@%p18 ld.global.b16 { %rs42 }, [ %rd17 + 0 ];
(EngineCore_DP0 pid=408724) 	// end inline asm
(EngineCore_DP0 pid=408724) 	// begin inline asm
(EngineCore_DP0 pid=408724) 	mov.u16 %rs44, %rs25;
(EngineCore_DP0 pid=408724) 	@%p19 ld.global.b16 { %rs44 }, [ %rd18 + 0 ];
(EngineCore_DP0 pid=408724) 	// end inline asm
(EngineCore_DP0 pid=408724) 	// begin inline asm
(EngineCore_DP0 pid=408724) 	mov.u16 %rs46, %rs25;
(EngineCore_DP0 pid=408724) 	@%p20 ld.global.b16 { %rs46 }, [ %rd19 + 0 ];
(EngineCore_DP0 pid=408724) 	// end inline asm
(EngineCore_DP0 pid=408724) 	.loc	1 229 79                        // quant_slide_tuned_Llama3.2-3B.py:229:79
(EngineCore_DP0 pid=408724) 	cvt.f32.bf16 	%r147, %rs40;
(EngineCore_DP0 pid=408724) 	cvt.f32.bf16 	%r148, %rs42;
(EngineCore_DP0 pid=408724) 	cvt.f32.bf16 	%r149, %rs44;
(EngineCore_DP0 pid=408724) 	cvt.f32.bf16 	%r150, %rs46;
(EngineCore_DP0 pid=408724) 	.loc	1 231 37                        // quant_slide_tuned_Llama3.2-3B.py:231:37
(EngineCore_DP0 pid=408724) 	and.pred 	%p21, %p25, %p40;
(EngineCore_DP0 pid=408724) 	and.pred 	%p22, %p25, %p36;
(EngineCore_DP0 pid=408724) 	and.pred 	%p23, %p25, %p35;
(EngineCore_DP0 pid=408724) 	and.pred 	%p24, %p25, %p34;
(EngineCore_DP0 pid=408724) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-3B.py:230:39
(EngineCore_DP0 pid=408724) 	add.s64 	%rd20, %rd8, 6;
(EngineCore_DP0 pid=408724) 	add.s64 	%rd21, %rd9, 6;
(EngineCore_DP0 pid=408724) 	add.s64 	%rd22, %rd10, 6;
(EngineCore_DP0 pid=408724) 	add.s64 	%rd23, %rd11, 6;
(EngineCore_DP0 pid=408724) 	.loc	1 230 21                        // quant_slide_tuned_Llama3.2-3B.py:230:21
(EngineCore_DP0 pid=408724) 	// begin inline asm
(EngineCore_DP0 pid=408724) 	mov.u16 %rs48, %rs25;
(EngineCore_DP0 pid=408724) 	@%p21 ld.global.b16 { %rs48 }, [ %rd20 + 0 ];
(EngineCore_DP0 pid=408724) 	// end inline asm
(EngineCore_DP0 pid=408724) 	// begin inline asm
(EngineCore_DP0 pid=408724) 	mov.u16 %rs50, %rs25;
(EngineCore_DP0 pid=408724) 	@%p22 ld.global.b16 { %rs50 }, [ %rd21 + 0 ];
(EngineCore_DP0 pid=408724) 	// end inline asm
(EngineCore_DP0 pid=408724) 	// begin inline asm
(EngineCore_DP0 pid=408724) 	mov.u16 %rs52, %rs25;
(EngineCore_DP0 pid=408724) 	@%p23 ld.global.b16 { %rs52 }, [ %rd22 + 0 ];
(EngineCore_DP0 pid=408724) 	// end inline asm
(EngineCore_DP0 pid=408724) 	// begin inline asm
(EngineCore_DP0 pid=408724) 	mov.u16 %rs54, %rs25;
(EngineCore_DP0 pid=408724) 	@%p24 ld.global.b16 { %rs54 }, [ %rd23 + 0 ];
(EngineCore_DP0 pid=408724) 	// end inline asm
(EngineCore_DP0 pid=408724) 	.loc	1 231 79                        // quant_slide_tuned_Llama3.2-3B.py:231:79
(EngineCore_DP0 pid=408724) 	cvt.f32.bf16 	%r151, %rs48;
(EngineCore_DP0 pid=408724) 	cvt.f32.bf16 	%r152, %rs50;
(EngineCore_DP0 pid=408724) 	cvt.f32.bf16 	%r153, %rs52;
(EngineCore_DP0 pid=408724) 	cvt.f32.bf16 	%r154, %rs54;
(EngineCore_DP0 pid=408724) 	.loc	1 233 27                        // quant_slide_tuned_Llama3.2-3B.py:233:27
(EngineCore_DP0 pid=408724) 	mul.f32 	%r155, %r14, %r127;
(EngineCore_DP0 pid=408724) 	mul.f32 	%r156, %r14, %r128;
(EngineCore_DP0 pid=408724) 	mul.f32 	%r157, %r14, %r129;
(EngineCore_DP0 pid=408724) 	mul.f32 	%r158, %r14, %r130;
(EngineCore_DP0 pid=408724) 	mov.b32 	%r159, 0f43E00000;
(EngineCore_DP0 pid=408724) 	.loc	1 233 48                        // quant_slide_tuned_Llama3.2-3B.py:233:48
(EngineCore_DP0 pid=408724) 	min.xorsign.abs.f32 	%r82, %r155, %r159;
(EngineCore_DP0 pid=408724) 	min.xorsign.abs.f32 	%r83, %r156, %r159;
(EngineCore_DP0 pid=408724) 	min.xorsign.abs.f32 	%r84, %r157, %r159;
(EngineCore_DP0 pid=408724) 	min.xorsign.abs.f32 	%r85, %r158, %r159;
(EngineCore_DP0 pid=408724) 	.loc	1 233 60                        // quant_slide_tuned_Llama3.2-3B.py:233:60
(EngineCore_DP0 pid=408724) 	// begin inline asm
(EngineCore_DP0 pid=408724) 	cvt.rn.satfinite.e4m3x2.f32  %rs56, %r83, %r82; 
(EngineCore_DP0 pid=408724) 
(EngineCore_DP0 pid=408724) 	// end inline asm
(EngineCore_DP0 pid=408724) 	shr.u16 	%rs64, %rs56, 8;
(EngineCore_DP0 pid=408724) 	// begin inline asm
(EngineCore_DP0 pid=408724) 	cvt.rn.satfinite.e4m3x2.f32  %rs57, %r85, %r84; 
(EngineCore_DP0 pid=408724) 
(EngineCore_DP0 pid=408724) 	// end inline asm
(EngineCore_DP0 pid=408724) 	shr.u16 	%rs65, %rs57, 8;
(EngineCore_DP0 pid=408724) 	.loc	1 234 27                        // quant_slide_tuned_Llama3.2-3B.py:234:27
(EngineCore_DP0 pid=408724) 	mul.f32 	%r160, %r14, %r135;
(EngineCore_DP0 pid=408724) 	mul.f32 	%r161, %r14, %r136;
(EngineCore_DP0 pid=408724) 	mul.f32 	%r162, %r14, %r137;
(EngineCore_DP0 pid=408724) 	mul.f32 	%r163, %r14, %r138;
(EngineCore_DP0 pid=408724) 	.loc	1 234 48                        // quant_slide_tuned_Llama3.2-3B.py:234:48
(EngineCore_DP0 pid=408724) 	min.xorsign.abs.f32 	%r86, %r160, %r159;
(EngineCore_DP0 pid=408724) 	min.xorsign.abs.f32 	%r87, %r161, %r159;
(EngineCore_DP0 pid=408724) 	min.xorsign.abs.f32 	%r88, %r162, %r159;
(EngineCore_DP0 pid=408724) 	min.xorsign.abs.f32 	%r89, %r163, %r159;
(EngineCore_DP0 pid=408724) 	.loc	1 234 60                        // quant_slide_tuned_Llama3.2-3B.py:234:60
(EngineCore_DP0 pid=408724) 	// begin inline asm
(EngineCore_DP0 pid=408724) 	cvt.rn.satfinite.e4m3x2.f32  %rs58, %r87, %r86; 
(EngineCore_DP0 pid=408724) 
(EngineCore_DP0 pid=408724) 	// end inline asm
(EngineCore_DP0 pid=408724) 	shr.u16 	%rs66, %rs58, 8;
(EngineCore_DP0 pid=408724) 	// begin inline asm
(EngineCore_DP0 pid=408724) 	cvt.rn.satfinite.e4m3x2.f32  %rs59, %r89, %r88; 
(EngineCore_DP0 pid=408724) 
(EngineCore_DP0 pid=408724) 	// end inline asm
(EngineCore_DP0 pid=408724) 	shr.u16 	%rs67, %rs59, 8;
(EngineCore_DP0 pid=408724) 	.loc	1 235 27                        // quant_slide_tuned_Llama3.2-3B.py:235:27
(EngineCore_DP0 pid=408724) 	mul.f32 	%r164, %r14, %r147;
(EngineCore_DP0 pid=408724) 	mul.f32 	%r165, %r14, %r148;
(EngineCore_DP0 pid=408724) 	mul.f32 	%r166, %r14, %r149;
(EngineCore_DP0 pid=408724) 	mul.f32 	%r167, %r14, %r150;
(EngineCore_DP0 pid=408724) 	.loc	1 235 48                        // quant_slide_tuned_Llama3.2-3B.py:235:48
(EngineCore_DP0 pid=408724) 	min.xorsign.abs.f32 	%r90, %r164, %r159;
(EngineCore_DP0 pid=408724) 	min.xorsign.abs.f32 	%r91, %r165, %r159;
(EngineCore_DP0 pid=408724) 	min.xorsign.abs.f32 	%r92, %r166, %r159;
(EngineCore_DP0 pid=408724) 	min.xorsign.abs.f32 	%r93, %r167, %r159;
(EngineCore_DP0 pid=408724) 	.loc	1 235 60                        // quant_slide_tuned_Llama3.2-3B.py:235:60
(EngineCore_DP0 pid=408724) 	// begin inline asm
(EngineCore_DP0 pid=408724) 	cvt.rn.satfinite.e4m3x2.f32  %rs60, %r91, %r90; 
(EngineCore_DP0 pid=408724) 
(EngineCore_DP0 pid=408724) 	// end inline asm
(EngineCore_DP0 pid=408724) 	shr.u16 	%rs68, %rs60, 8;
(EngineCore_DP0 pid=408724) 	// begin inline asm
(EngineCore_DP0 pid=408724) 	cvt.rn.satfinite.e4m3x2.f32  %rs61, %r93, %r92; 
(EngineCore_DP0 pid=408724) 
(EngineCore_DP0 pid=408724) 	// end inline asm
(EngineCore_DP0 pid=408724) 	shr.u16 	%rs69, %rs61, 8;
(EngineCore_DP0 pid=408724) 	.loc	1 236 27                        // quant_slide_tuned_Llama3.2-3B.py:236:27
(EngineCore_DP0 pid=408724) 	mul.f32 	%r168, %r14, %r151;
(EngineCore_DP0 pid=408724) 	mul.f32 	%r169, %r14, %r152;
(EngineCore_DP0 pid=408724) 	mul.f32 	%r170, %r14, %r153;
(EngineCore_DP0 pid=408724) 	mul.f32 	%r171, %r14, %r154;
(EngineCore_DP0 pid=408724) 	.loc	1 236 48                        // quant_slide_tuned_Llama3.2-3B.py:236:48
(EngineCore_DP0 pid=408724) 	min.xorsign.abs.f32 	%r94, %r168, %r159;
(EngineCore_DP0 pid=408724) 	min.xorsign.abs.f32 	%r95, %r169, %r159;
(EngineCore_DP0 pid=408724) 	min.xorsign.abs.f32 	%r96, %r170, %r159;
(EngineCore_DP0 pid=408724) 	min.xorsign.abs.f32 	%r97, %r171, %r159;
(EngineCore_DP0 pid=408724) 	.loc	1 236 60                        // quant_slide_tuned_Llama3.2-3B.py:236:60
(EngineCore_DP0 pid=408724) 	// begin inline asm
(EngineCore_DP0 pid=408724) 	cvt.rn.satfinite.e4m3x2.f32  %rs62, %r95, %r94; 
(EngineCore_DP0 pid=408724) 
(EngineCore_DP0 pid=408724) 	// end inline asm
(EngineCore_DP0 pid=408724) 	shr.u16 	%rs70, %rs62, 8;
(EngineCore_DP0 pid=408724) 	// begin inline asm
(EngineCore_DP0 pid=408724) 	cvt.rn.satfinite.e4m3x2.f32  %rs63, %r97, %r96; 
(EngineCore_DP0 pid=408724) 
(EngineCore_DP0 pid=408724) 	// end inline asm
(EngineCore_DP0 pid=408724) 	shr.u16 	%rs71, %rs63, 8;
(EngineCore_DP0 pid=408724) 	.loc	1 238 45                        // quant_slide_tuned_Llama3.2-3B.py:238:45
(EngineCore_DP0 pid=408724) 	cvt.u32.u16 	%r172, %rs56;
(EngineCore_DP0 pid=408724) 	and.b32 	%r173, %r172, 255;
(EngineCore_DP0 pid=408724) 	cvt.u32.u16 	%r174, %rs64;
(EngineCore_DP0 pid=408724) 	cvt.u32.u16 	%r175, %rs57;
(EngineCore_DP0 pid=408724) 	and.b32 	%r176, %r175, 255;
(EngineCore_DP0 pid=408724) 	cvt.u32.u16 	%r177, %rs65;
(EngineCore_DP0 pid=408724) 	.loc	1 240 45                        // quant_slide_tuned_Llama3.2-3B.py:240:45
(EngineCore_DP0 pid=408724) 	cvt.u32.u16 	%r178, %rs60;
(EngineCore_DP0 pid=408724) 	and.b32 	%r179, %r178, 255;
(EngineCore_DP0 pid=408724) 	cvt.u32.u16 	%r180, %rs68;
(EngineCore_DP0 pid=408724) 	cvt.u32.u16 	%r181, %rs61;
(EngineCore_DP0 pid=408724) 	and.b32 	%r182, %r181, 255;
(EngineCore_DP0 pid=408724) 	cvt.u32.u16 	%r183, %rs69;
(EngineCore_DP0 pid=408724) 	.loc	1 241 45                        // quant_slide_tuned_Llama3.2-3B.py:241:45
(EngineCore_DP0 pid=408724) 	cvt.u32.u16 	%r184, %rs62;
(EngineCore_DP0 pid=408724) 	cvt.u32.u16 	%r185, %rs70;
(EngineCore_DP0 pid=408724) 	cvt.u32.u16 	%r186, %rs63;
(EngineCore_DP0 pid=408724) 	cvt.u32.u16 	%r187, %rs71;
(EngineCore_DP0 pid=408724) 	.loc	1 243 30                        // quant_slide_tuned_Llama3.2-3B.py:243:30
(EngineCore_DP0 pid=408724) 	and.b16 	%rs72, %rs58, 255;
(EngineCore_DP0 pid=408724) 	mul.wide.u16 	%r188, %rs72, 256;
(EngineCore_DP0 pid=408724) 	mul.wide.u16 	%r189, %rs66, 256;
(EngineCore_DP0 pid=408724) 	and.b16 	%rs73, %rs59, 255;
(EngineCore_DP0 pid=408724) 	mul.wide.u16 	%r190, %rs73, 256;
(EngineCore_DP0 pid=408724) 	mul.wide.u16 	%r191, %rs67, 256;
(EngineCore_DP0 pid=408724) 	.loc	1 243 24                        // quant_slide_tuned_Llama3.2-3B.py:243:24
(EngineCore_DP0 pid=408724) 	or.b32 	%r192, %r188, %r173;
(EngineCore_DP0 pid=408724) 	or.b32 	%r193, %r189, %r174;
(EngineCore_DP0 pid=408724) 	or.b32 	%r194, %r190, %r176;
(EngineCore_DP0 pid=408724) 	or.b32 	%r195, %r191, %r177;
(EngineCore_DP0 pid=408724) 	.loc	1 243 42                        // quant_slide_tuned_Llama3.2-3B.py:243:42
(EngineCore_DP0 pid=408724) 	shl.b32 	%r196, %r179, 16;
(EngineCore_DP0 pid=408724) 	shl.b32 	%r197, %r180, 16;
(EngineCore_DP0 pid=408724) 	shl.b32 	%r198, %r182, 16;
(EngineCore_DP0 pid=408724) 	shl.b32 	%r199, %r183, 16;
(EngineCore_DP0 pid=408724) 	.loc	1 243 36                        // quant_slide_tuned_Llama3.2-3B.py:243:36
(EngineCore_DP0 pid=408724) 	or.b32 	%r200, %r196, %r192;
(EngineCore_DP0 pid=408724) 	or.b32 	%r201, %r197, %r193;
(EngineCore_DP0 pid=408724) 	or.b32 	%r202, %r198, %r194;
(EngineCore_DP0 pid=408724) 	or.b32 	%r203, %r199, %r195;
(EngineCore_DP0 pid=408724) 	.loc	1 243 55                        // quant_slide_tuned_Llama3.2-3B.py:243:55
(EngineCore_DP0 pid=408724) 	shl.b32 	%r204, %r184, 24;
(EngineCore_DP0 pid=408724) 	shl.b32 	%r205, %r185, 24;
(EngineCore_DP0 pid=408724) 	shl.b32 	%r206, %r186, 24;
(EngineCore_DP0 pid=408724) 	shl.b32 	%r207, %r187, 24;
(EngineCore_DP0 pid=408724) 	.loc	1 243 49                        // quant_slide_tuned_Llama3.2-3B.py:243:49
(EngineCore_DP0 pid=408724) 	or.b32 	%r98, %r204, %r200;
(EngineCore_DP0 pid=408724) 	or.b32 	%r99, %r205, %r201;
(EngineCore_DP0 pid=408724) 	or.b32 	%r100, %r206, %r202;
(EngineCore_DP0 pid=408724) 	or.b32 	%r101, %r207, %r203;
(EngineCore_DP0 pid=408724) 	.loc	1 244 29                        // quant_slide_tuned_Llama3.2-3B.py:244:29
(EngineCore_DP0 pid=408724) 	mad.wide.s32 	%rd24, %r102, 4, %rd2;
(EngineCore_DP0 pid=408724) 	.loc	1 244 39                        // quant_slide_tuned_Llama3.2-3B.py:244:39
(EngineCore_DP0 pid=408724) 	// begin inline asm
(EngineCore_DP0 pid=408724) 	@%p25 st.global.v4.b32 [ %rd24 + 0 ], { %r98, %r99, %r100, %r101 };
(EngineCore_DP0 pid=408724) 	// end inline asm
(EngineCore_DP0 pid=408724) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=408724) 	add.s32 	%r211, %r211, 2048;
(EngineCore_DP0 pid=408724) 	setp.lt.s32 	%p42, %r211, %r15;
(EngineCore_DP0 pid=408724) 	@%p42 bra 	$L__BB0_6;
(EngineCore_DP0 pid=408724) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=408724) 	.loc	1 215 4                         // quant_slide_tuned_Llama3.2-3B.py:215:4
(EngineCore_DP0 pid=408724) 	ret;
(EngineCore_DP0 pid=408724) $L__tmp3:
(EngineCore_DP0 pid=408724) $L__func_end0:
(EngineCore_DP0 pid=408724)                                         // -- End function
(EngineCore_DP0 pid=408724) }
(EngineCore_DP0 pid=408724) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py"
(EngineCore_DP0 pid=408724) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=408724) 	.section	.debug_abbrev
(EngineCore_DP0 pid=408724) 	{
(EngineCore_DP0 pid=408724) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=408724) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=408724) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=408724) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=408724) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=408724) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=408724) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=408724) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=408724) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=408724) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=408724) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=408724) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=408724) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=408724) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=408724) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=408724) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=408724) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=408724) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=408724) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=408724) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=408724) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=408724) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=408724) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=408724) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=408724) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=408724) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=408724) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=408724) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=408724) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=408724) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=408724) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=408724) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=408724) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=408724) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=408724) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=408724) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=408724) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=408724) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=408724) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=408724) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=408724) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=408724) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=408724) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=408724) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=408724) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=408724) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=408724) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=408724) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=408724) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=408724) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=408724) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=408724) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=408724) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=408724) 	}
(EngineCore_DP0 pid=408724) 	.section	.debug_info
(EngineCore_DP0 pid=408724) 	{
(EngineCore_DP0 pid=408724) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=408724) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=408724) .b8 0
(EngineCore_DP0 pid=408724) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=408724) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=408724) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=408724) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=408724) .b8 114
(EngineCore_DP0 pid=408724) .b8 105
(EngineCore_DP0 pid=408724) .b8 116
(EngineCore_DP0 pid=408724) .b8 111
(EngineCore_DP0 pid=408724) .b8 110
(EngineCore_DP0 pid=408724) .b8 0
(EngineCore_DP0 pid=408724) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=408724) .b8 0
(EngineCore_DP0 pid=408724) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=408724) .b8 117
(EngineCore_DP0 pid=408724) .b8 97
(EngineCore_DP0 pid=408724) .b8 110
(EngineCore_DP0 pid=408724) .b8 116
(EngineCore_DP0 pid=408724) .b8 95
(EngineCore_DP0 pid=408724) .b8 115
(EngineCore_DP0 pid=408724) .b8 108
(EngineCore_DP0 pid=408724) .b8 105
(EngineCore_DP0 pid=408724) .b8 100
(EngineCore_DP0 pid=408724) .b8 101
(EngineCore_DP0 pid=408724) .b8 95
(EngineCore_DP0 pid=408724) .b8 116
(EngineCore_DP0 pid=408724) .b8 117
(EngineCore_DP0 pid=408724) .b8 110
(EngineCore_DP0 pid=408724) .b8 101
(EngineCore_DP0 pid=408724) .b8 100
(EngineCore_DP0 pid=408724) .b8 95
(EngineCore_DP0 pid=408724) .b8 76
(EngineCore_DP0 pid=408724) .b8 108
(EngineCore_DP0 pid=408724) .b8 97
(EngineCore_DP0 pid=408724) .b8 109
(EngineCore_DP0 pid=408724) .b8 97
(EngineCore_DP0 pid=408724) .b8 51
(EngineCore_DP0 pid=408724) .b8 46
(EngineCore_DP0 pid=408724) .b8 50
(EngineCore_DP0 pid=408724) .b8 45
(EngineCore_DP0 pid=408724) .b8 51
(EngineCore_DP0 pid=408724) .b8 66
(EngineCore_DP0 pid=408724) .b8 46
(EngineCore_DP0 pid=408724) .b8 112
(EngineCore_DP0 pid=408724) .b8 121
(EngineCore_DP0 pid=408724) .b8 0
(EngineCore_DP0 pid=408724) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=408724) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=408724) .b8 114
(EngineCore_DP0 pid=408724) .b8 111
(EngineCore_DP0 pid=408724) .b8 111
(EngineCore_DP0 pid=408724) .b8 116
(EngineCore_DP0 pid=408724) .b8 47
(EngineCore_DP0 pid=408724) .b8 118
(EngineCore_DP0 pid=408724) .b8 108
(EngineCore_DP0 pid=408724) .b8 108
(EngineCore_DP0 pid=408724) .b8 109
(EngineCore_DP0 pid=408724) .b8 98
(EngineCore_DP0 pid=408724) .b8 101
(EngineCore_DP0 pid=408724) .b8 110
(EngineCore_DP0 pid=408724) .b8 99
(EngineCore_DP0 pid=408724) .b8 104
(EngineCore_DP0 pid=408724) .b8 47
(EngineCore_DP0 pid=408724) .b8 115
(EngineCore_DP0 pid=408724) .b8 108
(EngineCore_DP0 pid=408724) .b8 105
(EngineCore_DP0 pid=408724) .b8 100
(EngineCore_DP0 pid=408724) .b8 101
(EngineCore_DP0 pid=408724) .b8 115
(EngineCore_DP0 pid=408724) .b8 112
(EngineCore_DP0 pid=408724) .b8 97
(EngineCore_DP0 pid=408724) .b8 114
(EngineCore_DP0 pid=408724) .b8 115
(EngineCore_DP0 pid=408724) .b8 101
(EngineCore_DP0 pid=408724) .b8 47
(EngineCore_DP0 pid=408724) .b8 99
(EngineCore_DP0 pid=408724) .b8 115
(EngineCore_DP0 pid=408724) .b8 114
(EngineCore_DP0 pid=408724) .b8 99
(EngineCore_DP0 pid=408724) .b8 47
(EngineCore_DP0 pid=408724) .b8 102
(EngineCore_DP0 pid=408724) .b8 117
(EngineCore_DP0 pid=408724) .b8 115
(EngineCore_DP0 pid=408724) .b8 101
(EngineCore_DP0 pid=408724) .b8 100
(EngineCore_DP0 pid=408724) .b8 95
(EngineCore_DP0 pid=408724) .b8 113
(EngineCore_DP0 pid=408724) .b8 117
(EngineCore_DP0 pid=408724) .b8 97
(EngineCore_DP0 pid=408724) .b8 110
(EngineCore_DP0 pid=408724) .b8 116
(EngineCore_DP0 pid=408724) .b8 95
(EngineCore_DP0 pid=408724) .b8 115
(EngineCore_DP0 pid=408724) .b8 108
(EngineCore_DP0 pid=408724) .b8 105
(EngineCore_DP0 pid=408724) .b8 100
(EngineCore_DP0 pid=408724) .b8 101
(EngineCore_DP0 pid=408724) .b8 95
(EngineCore_DP0 pid=408724) .b8 116
(EngineCore_DP0 pid=408724) .b8 114
(EngineCore_DP0 pid=408724) .b8 105
(EngineCore_DP0 pid=408724) .b8 116
(EngineCore_DP0 pid=408724) .b8 111
(EngineCore_DP0 pid=408724) .b8 110
(EngineCore_DP0 pid=408724) .b8 47
(EngineCore_DP0 pid=408724) .b8 98
(EngineCore_DP0 pid=408724) .b8 117
(EngineCore_DP0 pid=408724) .b8 105
(EngineCore_DP0 pid=408724) .b8 108
(EngineCore_DP0 pid=408724) .b8 100
(EngineCore_DP0 pid=408724) .b8 47
(EngineCore_DP0 pid=408724) .b8 71
(EngineCore_DP0 pid=408724) .b8 66
(EngineCore_DP0 pid=408724) .b8 49
(EngineCore_DP0 pid=408724) .b8 48
(EngineCore_DP0 pid=408724) .b8 95
(EngineCore_DP0 pid=408724) .b8 99
(EngineCore_DP0 pid=408724) .b8 99
(EngineCore_DP0 pid=408724) .b8 49
(EngineCore_DP0 pid=408724) .b8 50
(EngineCore_DP0 pid=408724) .b8 49
(EngineCore_DP0 pid=408724) .b8 95
(EngineCore_DP0 pid=408724) .b8 112
(EngineCore_DP0 pid=408724) .b8 121
(EngineCore_DP0 pid=408724) .b8 51
(EngineCore_DP0 pid=408724) .b8 49
(EngineCore_DP0 pid=408724) .b8 50
(EngineCore_DP0 pid=408724) .b8 95
(EngineCore_DP0 pid=408724) .b8 99
(EngineCore_DP0 pid=408724) .b8 117
(EngineCore_DP0 pid=408724) .b8 49
(EngineCore_DP0 pid=408724) .b8 50
(EngineCore_DP0 pid=408724) .b8 57
(EngineCore_DP0 pid=408724) .b8 95
(EngineCore_DP0 pid=408724) .b8 97
(EngineCore_DP0 pid=408724) .b8 97
(EngineCore_DP0 pid=408724) .b8 114
(EngineCore_DP0 pid=408724) .b8 99
(EngineCore_DP0 pid=408724) .b8 104
(EngineCore_DP0 pid=408724) .b8 54
(EngineCore_DP0 pid=408724) .b8 52
(EngineCore_DP0 pid=408724) .b8 0
(EngineCore_DP0 pid=408724) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=408724) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=408724) .b8 113
(EngineCore_DP0 pid=408724) .b8 117
(EngineCore_DP0 pid=408724) .b8 97
(EngineCore_DP0 pid=408724) .b8 110
(EngineCore_DP0 pid=408724) .b8 116
(EngineCore_DP0 pid=408724) .b8 95
(EngineCore_DP0 pid=408724) .b8 115
(EngineCore_DP0 pid=408724) .b8 108
(EngineCore_DP0 pid=408724) .b8 105
(EngineCore_DP0 pid=408724) .b8 100
(EngineCore_DP0 pid=408724) .b8 101
(EngineCore_DP0 pid=408724) .b8 95
(EngineCore_DP0 pid=408724) .b8 102
(EngineCore_DP0 pid=408724) .b8 112
(EngineCore_DP0 pid=408724) .b8 56
(EngineCore_DP0 pid=408724) .b8 95
(EngineCore_DP0 pid=408724) .b8 107
(EngineCore_DP0 pid=408724) .b8 101
(EngineCore_DP0 pid=408724) .b8 114
(EngineCore_DP0 pid=408724) .b8 110
(EngineCore_DP0 pid=408724) .b8 101
(EngineCore_DP0 pid=408724) .b8 108
(EngineCore_DP0 pid=408724) .b8 0
(EngineCore_DP0 pid=408724) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=408724) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=408724) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=408724) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=408724) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=408724) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=408724) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=408724) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=408724) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=408724) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=408724) .b8 205                                 // DW_AT_call_line
(EngineCore_DP0 pid=408724) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=408724) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=408724) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=408724) 	}
(EngineCore_DP0 pid=408724) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=408724) 
(EngineCore_DP0 pid=408724) ================================================================
(EngineCore_DP0 pid=408724) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=408724) 
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpqwm097ao.ptx', '-o', '/tmp/tmpqwm097ao.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866] 
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866] 
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866] 
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpqwm097ao.ptx -o /tmp/tmpqwm097ao.ptx.o
(EngineCore_DP0 pid=408724) ERROR 01-25 20:19:31 [core.py:866] 

STDERR:
[2026-01-25 20:19:00] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:19:00] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:19:00] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:19:00] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:19:00] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:19:00] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:19:00] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:19:00] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:19:00] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:19:00] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:19:00] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:19:00] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:19:00] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:19:00] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:19:03] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:19:03] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:19:03] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:19:03] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:19:03] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:19:03] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:19:03] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:19:03] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:19:03] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:19:03] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:19:03] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:19:03] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:19:03] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:19:03] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=408724) [2026-01-25 20:19:04] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=408724) [2026-01-25 20:19:04] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=408724) [2026-01-25 20:19:04] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=408724) [2026-01-25 20:19:04] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=408724) [2026-01-25 20:19:04] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=408724) [2026-01-25 20:19:04] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=408724) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=408724) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:24<00:00, 25.00s/it]
(EngineCore_DP0 pid=408724) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:24<00:00, 25.00s/it]
(EngineCore_DP0 pid=408724) 
(EngineCore_DP0 pid=408724) [2026-01-25 20:19:30] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4928] -> 1D uint8
(EngineCore_DP0 pid=408724) [2026-01-25 20:19:30] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15810560 bytes
(EngineCore_DP0 pid=408724) [2026-01-25 20:19:30] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4928] -> 1D uint8
(EngineCore_DP0 pid=408724) [2026-01-25 20:19:30] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9486336 bytes
(EngineCore_DP0 pid=408724) [2026-01-25 20:19:30] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4928] -> 1D uint8
(EngineCore_DP0 pid=408724) [2026-01-25 20:19:30] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 50593792 bytes
(EngineCore_DP0 pid=408724) [2026-01-25 20:19:30] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 13120] -> 1D uint8
(EngineCore_DP0 pid=408724) [2026-01-25 20:19:30] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 25214976 bytes
(EngineCore_DP0 pid=408724) Process EngineCore_DP0:
(EngineCore_DP0 pid=408724) Traceback (most recent call last):
(EngineCore_DP0 pid=408724)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=408724)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=408724)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=408724)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=408724) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpqwm097ao.ptx', '-o', '/tmp/tmpqwm097ao.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=408724) 
(EngineCore_DP0 pid=408724) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=408724) 
(EngineCore_DP0 pid=408724) Traceback (most recent call last):
(EngineCore_DP0 pid=408724)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=408724)     self.run()
(EngineCore_DP0 pid=408724)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=408724)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=408724)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=408724)     raise e
(EngineCore_DP0 pid=408724)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=408724)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=408724)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=408724)     super().__init__(
(EngineCore_DP0 pid=408724)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=408724)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=408724)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=408724)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=408724)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=408724)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=408724)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=408724)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=408724)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=408724)     return func(*args, **kwargs)
(EngineCore_DP0 pid=408724)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=408724)     return func(*args, **kwargs)
(EngineCore_DP0 pid=408724)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=408724)     self.model_runner.profile_run()
(EngineCore_DP0 pid=408724)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=408724)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=408724)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=408724)     return func(*args, **kwargs)
(EngineCore_DP0 pid=408724)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=408724)     outputs = self.model(
(EngineCore_DP0 pid=408724)               ^^^^^^^^^^^
(EngineCore_DP0 pid=408724)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=408724)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=408724)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=408724)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=408724)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=408724)     model_output = self.model(
(EngineCore_DP0 pid=408724)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=408724)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=408724)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=408724)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=408724)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=408724)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=408724)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=408724)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=408724)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=408724)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=408724)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=408724)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=408724)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=408724)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=408724)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=408724)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=408724)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=408724)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=408724)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=408724)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=408724)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=408724)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=408724)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=408724)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=408724)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=408724)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=408724)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=408724)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=408724)     return self._linear_fn(
(EngineCore_DP0 pid=408724)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=408724)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=408724)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=408724)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=408724)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=408724)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=408724)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=408724)     return fn(input, L)
(EngineCore_DP0 pid=408724)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=408724)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=408724)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=408724)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=408724)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=408724)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=408724)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=408724)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=408724)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=408724)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=408724)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=408724)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=408724)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=408724)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=408724)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=408724)     raise PTXASError(error)
(EngineCore_DP0 pid=408724) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=408724) `ptxas` stderr:
(EngineCore_DP0 pid=408724) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=408724) 
(EngineCore_DP0 pid=408724) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpqwm097ao.ptx -o /tmp/tmpqwm097ao.ptx.o
(EngineCore_DP0 pid=408724) 
[rank0]:[W125 20:19:31.065831096 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=32768

========== M=65536 ==========
Time: 2026-01-25 20:19:33
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-3B-FP8_M65536.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:19:59 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 20:19:59 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=409742) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=409742) 
(EngineCore_DP0 pid=409742) 
(EngineCore_DP0 pid=409742) ================================================================
(EngineCore_DP0 pid=409742) Internal Triton PTX codegen error
(EngineCore_DP0 pid=409742) `ptxas` stderr:
(EngineCore_DP0 pid=409742) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=409742) 
(EngineCore_DP0 pid=409742) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpw7gi1ndv.ptx -o /tmp/tmpw7gi1ndv.ptx.o
(EngineCore_DP0 pid=409742) 
(EngineCore_DP0 pid=409742) 
(EngineCore_DP0 pid=409742) //
(EngineCore_DP0 pid=409742) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=409742) //
(EngineCore_DP0 pid=409742) 
(EngineCore_DP0 pid=409742) .version 8.7
(EngineCore_DP0 pid=409742) .target sm_121a
(EngineCore_DP0 pid=409742) .address_size 64
(EngineCore_DP0 pid=409742) 
(EngineCore_DP0 pid=409742) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=409742) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=409742)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=409742) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=409742) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=409742) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=409742) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=409742) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=409742) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=409742) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=409742) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=409742) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=409742) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=409742) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=409742) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=409742) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=409742) )
(EngineCore_DP0 pid=409742) .reqntid 512
(EngineCore_DP0 pid=409742) {
(EngineCore_DP0 pid=409742) 	.reg .pred 	%p<28>;
(EngineCore_DP0 pid=409742) 	.reg .b16 	%rs<49>;
(EngineCore_DP0 pid=409742) 	.reg .b32 	%r<151>;
(EngineCore_DP0 pid=409742) 	.reg .b64 	%rd<17>;
(EngineCore_DP0 pid=409742) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=409742) $L__func_begin0:
(EngineCore_DP0 pid=409742) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=409742) 
(EngineCore_DP0 pid=409742) // %bb.0:
(EngineCore_DP0 pid=409742) 	ld.param.b32 	%r25, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=409742) 	ld.param.b32 	%r24, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=409742) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=409742) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=409742) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=409742) $L__tmp0:
(EngineCore_DP0 pid=409742) 	.loc	1 191 24                        // quant_slide_tuned_Llama3.2-3B.py:191:24
(EngineCore_DP0 pid=409742) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=409742) 	ld.param.b32 	%r27, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=409742) 	.loc	1 196 26                        // quant_slide_tuned_Llama3.2-3B.py:196:26
(EngineCore_DP0 pid=409742) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=409742) 	.loc	1 196 20                        // quant_slide_tuned_Llama3.2-3B.py:196:20
(EngineCore_DP0 pid=409742) 	mad.wide.s32 	%rd1, %r28, 2, %rd4;
(EngineCore_DP0 pid=409742) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=409742) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=409742) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=409742) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=409742) 	setp.lt.s32 	%p1, %r24, 1;
(EngineCore_DP0 pid=409742) 	mov.b32 	%r149, 0f2B8CBCCC;
(EngineCore_DP0 pid=409742) 	setp.eq.b32 	%p27, %r2, 0;
(EngineCore_DP0 pid=409742) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=409742) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=409742) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=409742) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=409742) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=409742) 	shr.u32 	%r37, %r2, 3;
(EngineCore_DP0 pid=409742) 	and.b32 	%r38, %r37, 60;
(EngineCore_DP0 pid=409742) 	mov.b32 	%r39, global_smem;
(EngineCore_DP0 pid=409742) 	add.s32 	%r49, %r39, %r38;
(EngineCore_DP0 pid=409742) 	shl.b32 	%r40, %r2, 2;
(EngineCore_DP0 pid=409742) 	add.s32 	%r52, %r39, %r40;
(EngineCore_DP0 pid=409742) 	mov.b32 	%r45, 0;
(EngineCore_DP0 pid=409742) 	mov.b32 	%r147, 0f00000000;
(EngineCore_DP0 pid=409742) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=409742) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=409742) 	mov.b32 	%r148, %r45;
(EngineCore_DP0 pid=409742) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=409742) 	.loc	1 203 22                        // quant_slide_tuned_Llama3.2-3B.py:203:22
(EngineCore_DP0 pid=409742) 	add.s32 	%r55, %r4, %r148;
(EngineCore_DP0 pid=409742) 	setp.lt.s32 	%p2, %r55, %r23;
(EngineCore_DP0 pid=409742) 	.loc	1 204 29                        // quant_slide_tuned_Llama3.2-3B.py:204:29
(EngineCore_DP0 pid=409742) 	mad.wide.s32 	%rd6, %r55, 2, %rd1;
(EngineCore_DP0 pid=409742) 	.loc	1 204 21                        // quant_slide_tuned_Llama3.2-3B.py:204:21
(EngineCore_DP0 pid=409742) 	// begin inline asm
(EngineCore_DP0 pid=409742) 	mov.u32 %r41, %r45;
(EngineCore_DP0 pid=409742) 	mov.u32 %r42, %r45;
(EngineCore_DP0 pid=409742) 	mov.u32 %r43, %r45;
(EngineCore_DP0 pid=409742) 	mov.u32 %r44, %r45;
(EngineCore_DP0 pid=409742) 	@%p2 ld.global.v4.b32 { %r41, %r42, %r43, %r44 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=409742) 	// end inline asm
(EngineCore_DP0 pid=409742) 	mov.b32 	{%rs1, %rs2}, %r41;
(EngineCore_DP0 pid=409742) 	mov.b32 	{%rs3, %rs4}, %r42;
(EngineCore_DP0 pid=409742) 	mov.b32 	{%rs5, %rs6}, %r43;
(EngineCore_DP0 pid=409742) 	mov.b32 	{%rs7, %rs8}, %r44;
(EngineCore_DP0 pid=409742) 	.loc	1 205 50                        // quant_slide_tuned_Llama3.2-3B.py:205:50
(EngineCore_DP0 pid=409742) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=409742) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=409742) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=409742) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=409742) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=409742) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=409742) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=409742) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=409742) $L__tmp1:
(EngineCore_DP0 pid=409742) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=409742) 	bar.sync 	0;
(EngineCore_DP0 pid=409742) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=409742) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=409742) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=409742) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=409742) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=409742) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=409742) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=409742) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=409742) 	cvt.f32.bf16 	%r56, %rs23;
(EngineCore_DP0 pid=409742) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=409742) 	shfl.sync.bfly.b32 	%r57, %r56, 16, 31, -1;
(EngineCore_DP0 pid=409742) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=409742) 	max.f32 	%r58, %r56, %r57;
(EngineCore_DP0 pid=409742) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=409742) 	shfl.sync.bfly.b32 	%r59, %r58, 8, 31, -1;
(EngineCore_DP0 pid=409742) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=409742) 	max.f32 	%r60, %r58, %r59;
(EngineCore_DP0 pid=409742) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=409742) 	shfl.sync.bfly.b32 	%r61, %r60, 4, 31, -1;
(EngineCore_DP0 pid=409742) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=409742) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=409742) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=409742) 	shfl.sync.bfly.b32 	%r63, %r62, 2, 31, -1;
(EngineCore_DP0 pid=409742) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=409742) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=409742) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=409742) 	shfl.sync.bfly.b32 	%r65, %r64, 1, 31, -1;
(EngineCore_DP0 pid=409742) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=409742) 	max.f32 	%r50, %r64, %r65;
(EngineCore_DP0 pid=409742) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=409742) 	// begin inline asm
(EngineCore_DP0 pid=409742) 	@%p3 st.shared.b32 [ %r49 + 0 ], %r50;
(EngineCore_DP0 pid=409742) 	// end inline asm
(EngineCore_DP0 pid=409742) 	bar.sync 	0;
(EngineCore_DP0 pid=409742) 	// begin inline asm
(EngineCore_DP0 pid=409742) 	@%p4 ld.shared.b32 %r51, [ %r52 + 0 ];
(EngineCore_DP0 pid=409742) 	// end inline asm
(EngineCore_DP0 pid=409742) 	shfl.sync.bfly.b32 	%r66, %r51, 8, 31, -1;
(EngineCore_DP0 pid=409742) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=409742) 	max.f32 	%r67, %r51, %r66;
(EngineCore_DP0 pid=409742) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=409742) 	shfl.sync.bfly.b32 	%r68, %r67, 4, 31, -1;
(EngineCore_DP0 pid=409742) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=409742) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=409742) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=409742) 	shfl.sync.bfly.b32 	%r70, %r69, 2, 31, -1;
(EngineCore_DP0 pid=409742) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=409742) 	max.f32 	%r71, %r69, %r70;
(EngineCore_DP0 pid=409742) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=409742) 	shfl.sync.bfly.b32 	%r72, %r71, 1, 31, -1;
(EngineCore_DP0 pid=409742) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=409742) 	max.f32 	%r54, %r71, %r72;
(EngineCore_DP0 pid=409742) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=409742) 	// begin inline asm
(EngineCore_DP0 pid=409742) 	@%p27 st.shared.b32 [ %r52 + 0 ], %r54;
(EngineCore_DP0 pid=409742) 	// end inline asm
(EngineCore_DP0 pid=409742) 	bar.sync 	0;
(EngineCore_DP0 pid=409742) 	ld.shared.b32 	%r73, [global_smem];
(EngineCore_DP0 pid=409742) $L__tmp2:
(EngineCore_DP0 pid=409742) 	.loc	1 205 36                        // quant_slide_tuned_Llama3.2-3B.py:205:36
(EngineCore_DP0 pid=409742) 	max.f32 	%r147, %r147, %r73;
(EngineCore_DP0 pid=409742) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=409742) 	add.s32 	%r148, %r148, 4096;
(EngineCore_DP0 pid=409742) 	setp.lt.s32 	%p6, %r148, %r24;
(EngineCore_DP0 pid=409742) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=409742) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=409742) 	.loc	1 207 32                        // quant_slide_tuned_Llama3.2-3B.py:207:32
(EngineCore_DP0 pid=409742) 	max.f32 	%r149, %r147, 0f2B8CBCCC;
(EngineCore_DP0 pid=409742) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=409742) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-3B.py:0:32
(EngineCore_DP0 pid=409742) 	mov.b32 	%r75, 0f43E00000;
(EngineCore_DP0 pid=409742) 	.loc	1 208 32                        // quant_slide_tuned_Llama3.2-3B.py:208:32
(EngineCore_DP0 pid=409742) 	div.full.f32 	%r76, %r149, %r75;
(EngineCore_DP0 pid=409742) 	.loc	1 208 41                        // quant_slide_tuned_Llama3.2-3B.py:208:41
(EngineCore_DP0 pid=409742) 	max.f32 	%r74, %r76, 0f36924925;
(EngineCore_DP0 pid=409742) 	.loc	1 210 25                        // quant_slide_tuned_Llama3.2-3B.py:210:25
(EngineCore_DP0 pid=409742) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=409742) 	.loc	1 210 30                        // quant_slide_tuned_Llama3.2-3B.py:210:30
(EngineCore_DP0 pid=409742) 	// begin inline asm
(EngineCore_DP0 pid=409742) 	@%p27 st.global.b32 [ %rd7 + 0 ], { %r74 };
(EngineCore_DP0 pid=409742) 	// end inline asm
(EngineCore_DP0 pid=409742) 	.loc	1 213 29                        // quant_slide_tuned_Llama3.2-3B.py:213:29
(EngineCore_DP0 pid=409742) 	shl.b32 	%r15, %r25, 2;
(EngineCore_DP0 pid=409742) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=409742) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=409742) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=409742) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=409742) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-3B.py:0:41
(EngineCore_DP0 pid=409742) 	ld.param.b32 	%r29, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=409742) 	shr.s32 	%r30, %r29, 31;
(EngineCore_DP0 pid=409742) 	shr.u32 	%r31, %r30, 30;
(EngineCore_DP0 pid=409742) 	add.s32 	%r32, %r29, %r31;
(EngineCore_DP0 pid=409742) 	shr.s32 	%r33, %r32, 2;
(EngineCore_DP0 pid=409742) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=409742) 	mul.lo.s32 	%r34, %r33, %r1;
(EngineCore_DP0 pid=409742) 	mad.wide.s32 	%rd2, %r34, 4, %rd5;
(EngineCore_DP0 pid=409742) 	div.full.f32 	%r14, %r75, %r149;
(EngineCore_DP0 pid=409742) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=409742) 	mov.b32 	%r150, 0;
(EngineCore_DP0 pid=409742) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=409742)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=409742) 	.loc	1 216 31                        // quant_slide_tuned_Llama3.2-3B.py:216:31
(EngineCore_DP0 pid=409742) 	add.s32 	%r88, %r16, %r150;
(EngineCore_DP0 pid=409742) 	.loc	1 217 30                        // quant_slide_tuned_Llama3.2-3B.py:217:30
(EngineCore_DP0 pid=409742) 	add.s32 	%r89, %r88, 1;
(EngineCore_DP0 pid=409742) 	setp.lt.s32 	%p17, %r88, %r15;
(EngineCore_DP0 pid=409742) 	.loc	1 220 24                        // quant_slide_tuned_Llama3.2-3B.py:220:24
(EngineCore_DP0 pid=409742) 	shr.s32 	%r90, %r88, 31;
(EngineCore_DP0 pid=409742) 	shr.u32 	%r91, %r90, 30;
(EngineCore_DP0 pid=409742) 	add.s32 	%r92, %r88, %r91;
(EngineCore_DP0 pid=409742) 	shr.s32 	%r93, %r92, 2;
(EngineCore_DP0 pid=409742) 	.loc	1 221 23                        // quant_slide_tuned_Llama3.2-3B.py:221:23
(EngineCore_DP0 pid=409742) 	shr.s32 	%r94, %r89, 31;
(EngineCore_DP0 pid=409742) 	shr.u32 	%r95, %r94, 30;
(EngineCore_DP0 pid=409742) 	add.s32 	%r96, %r89, %r95;
(EngineCore_DP0 pid=409742) 	and.b32 	%r97, %r96, 2147483644;
(EngineCore_DP0 pid=409742) 	sub.s32 	%r98, %r89, %r97;
(EngineCore_DP0 pid=409742) 	and.b32 	%r99, %r92, 2147483644;
(EngineCore_DP0 pid=409742) 	sub.s32 	%r100, %r88, %r99;
(EngineCore_DP0 pid=409742) 	.loc	1 222 22                        // quant_slide_tuned_Llama3.2-3B.py:222:22
(EngineCore_DP0 pid=409742) 	mul.lo.s32 	%r101, %r93, 10;
(EngineCore_DP0 pid=409742) 	.loc	1 222 30                        // quant_slide_tuned_Llama3.2-3B.py:222:30
(EngineCore_DP0 pid=409742) 	shl.b32 	%r102, %r100, 1;
(EngineCore_DP0 pid=409742) 	shl.b32 	%r103, %r98, 1;
(EngineCore_DP0 pid=409742) 	.loc	1 222 26                        // quant_slide_tuned_Llama3.2-3B.py:222:26
(EngineCore_DP0 pid=409742) 	add.s32 	%r104, %r101, %r103;
(EngineCore_DP0 pid=409742) 	add.s32 	%r105, %r101, %r102;
(EngineCore_DP0 pid=409742) 	.loc	1 225 53                        // quant_slide_tuned_Llama3.2-3B.py:225:53
(EngineCore_DP0 pid=409742) 	setp.lt.s32 	%p18, %r105, %r23;
(EngineCore_DP0 pid=409742) 	setp.lt.s32 	%p19, %r104, %r23;
(EngineCore_DP0 pid=409742) 	.loc	1 225 37                        // quant_slide_tuned_Llama3.2-3B.py:225:37
(EngineCore_DP0 pid=409742) 	and.pred 	%p9, %p17, %p18;
(EngineCore_DP0 pid=409742) 	and.pred 	%p10, %p17, %p19;
(EngineCore_DP0 pid=409742) 	.loc	1 224 29                        // quant_slide_tuned_Llama3.2-3B.py:224:29
(EngineCore_DP0 pid=409742) 	mad.wide.s32 	%rd8, %r105, 2, %rd1;
(EngineCore_DP0 pid=409742) 	mad.wide.s32 	%rd9, %r104, 2, %rd1;
(EngineCore_DP0 pid=409742) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=409742) 	.loc	1 224 21                        // quant_slide_tuned_Llama3.2-3B.py:224:21
(EngineCore_DP0 pid=409742) 	// begin inline asm
(EngineCore_DP0 pid=409742) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=409742) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=409742) 	// end inline asm
(EngineCore_DP0 pid=409742) 	// begin inline asm
(EngineCore_DP0 pid=409742) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=409742) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=409742) 	// end inline asm
(EngineCore_DP0 pid=409742) 	.loc	1 225 79                        // quant_slide_tuned_Llama3.2-3B.py:225:79
(EngineCore_DP0 pid=409742) 	cvt.f32.bf16 	%r106, %rs24;
(EngineCore_DP0 pid=409742) 	cvt.f32.bf16 	%r107, %rs26;
(EngineCore_DP0 pid=409742) 	.loc	1 227 48                        // quant_slide_tuned_Llama3.2-3B.py:227:48
(EngineCore_DP0 pid=409742) 	or.b32 	%r108, %r105, 1;
(EngineCore_DP0 pid=409742) 	or.b32 	%r109, %r104, 1;
(EngineCore_DP0 pid=409742) 	.loc	1 227 53                        // quant_slide_tuned_Llama3.2-3B.py:227:53
(EngineCore_DP0 pid=409742) 	setp.lt.s32 	%p20, %r108, %r23;
(EngineCore_DP0 pid=409742) 	setp.lt.s32 	%p21, %r109, %r23;
(EngineCore_DP0 pid=409742) 	.loc	1 227 37                        // quant_slide_tuned_Llama3.2-3B.py:227:37
(EngineCore_DP0 pid=409742) 	and.pred 	%p11, %p17, %p20;
(EngineCore_DP0 pid=409742) 	and.pred 	%p12, %p17, %p21;
(EngineCore_DP0 pid=409742) 	.loc	1 226 39                        // quant_slide_tuned_Llama3.2-3B.py:226:39
(EngineCore_DP0 pid=409742) 	add.s64 	%rd10, %rd8, 2;
(EngineCore_DP0 pid=409742) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=409742) 	.loc	1 226 21                        // quant_slide_tuned_Llama3.2-3B.py:226:21
(EngineCore_DP0 pid=409742) 	// begin inline asm
(EngineCore_DP0 pid=409742) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=409742) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=409742) 	// end inline asm
(EngineCore_DP0 pid=409742) 	// begin inline asm
(EngineCore_DP0 pid=409742) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=409742) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=409742) 	// end inline asm
(EngineCore_DP0 pid=409742) 	.loc	1 227 79                        // quant_slide_tuned_Llama3.2-3B.py:227:79
(EngineCore_DP0 pid=409742) 	cvt.f32.bf16 	%r110, %rs28;
(EngineCore_DP0 pid=409742) 	cvt.f32.bf16 	%r111, %rs30;
(EngineCore_DP0 pid=409742) 	.loc	1 231 48                        // quant_slide_tuned_Llama3.2-3B.py:231:48
(EngineCore_DP0 pid=409742) 	add.s32 	%r112, %r105, 2;
(EngineCore_DP0 pid=409742) 	add.s32 	%r113, %r104, 2;
(EngineCore_DP0 pid=409742) 	add.s32 	%r114, %r105, 3;
(EngineCore_DP0 pid=409742) 	add.s32 	%r115, %r104, 3;
(EngineCore_DP0 pid=409742) 	.loc	1 231 53                        // quant_slide_tuned_Llama3.2-3B.py:231:53
(EngineCore_DP0 pid=409742) 	setp.lt.s32 	%p22, %r115, %r23;
(EngineCore_DP0 pid=409742) 	setp.lt.s32 	%p23, %r114, %r23;
(EngineCore_DP0 pid=409742) 	setp.lt.s32 	%p24, %r113, %r23;
(EngineCore_DP0 pid=409742) 	setp.lt.s32 	%p25, %r112, %r23;
(EngineCore_DP0 pid=409742) 	.loc	1 229 37                        // quant_slide_tuned_Llama3.2-3B.py:229:37
(EngineCore_DP0 pid=409742) 	and.pred 	%p13, %p17, %p25;
(EngineCore_DP0 pid=409742) 	and.pred 	%p14, %p17, %p24;
(EngineCore_DP0 pid=409742) 	.loc	1 228 39                        // quant_slide_tuned_Llama3.2-3B.py:228:39
(EngineCore_DP0 pid=409742) 	add.s64 	%rd12, %rd8, 4;
(EngineCore_DP0 pid=409742) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=409742) 	.loc	1 228 21                        // quant_slide_tuned_Llama3.2-3B.py:228:21
(EngineCore_DP0 pid=409742) 	// begin inline asm
(EngineCore_DP0 pid=409742) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=409742) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=409742) 	// end inline asm
(EngineCore_DP0 pid=409742) 	// begin inline asm
(EngineCore_DP0 pid=409742) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=409742) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=409742) 	// end inline asm
(EngineCore_DP0 pid=409742) 	.loc	1 229 79                        // quant_slide_tuned_Llama3.2-3B.py:229:79
(EngineCore_DP0 pid=409742) 	cvt.f32.bf16 	%r116, %rs32;
(EngineCore_DP0 pid=409742) 	cvt.f32.bf16 	%r117, %rs34;
(EngineCore_DP0 pid=409742) 	.loc	1 231 37                        // quant_slide_tuned_Llama3.2-3B.py:231:37
(EngineCore_DP0 pid=409742) 	and.pred 	%p15, %p17, %p23;
(EngineCore_DP0 pid=409742) 	and.pred 	%p16, %p17, %p22;
(EngineCore_DP0 pid=409742) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-3B.py:230:39
(EngineCore_DP0 pid=409742) 	add.s64 	%rd14, %rd8, 6;
(EngineCore_DP0 pid=409742) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=409742) 	.loc	1 230 21                        // quant_slide_tuned_Llama3.2-3B.py:230:21
(EngineCore_DP0 pid=409742) 	// begin inline asm
(EngineCore_DP0 pid=409742) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=409742) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=409742) 	// end inline asm
(EngineCore_DP0 pid=409742) 	// begin inline asm
(EngineCore_DP0 pid=409742) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=409742) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=409742) 	// end inline asm
(EngineCore_DP0 pid=409742) 	.loc	1 231 79                        // quant_slide_tuned_Llama3.2-3B.py:231:79
(EngineCore_DP0 pid=409742) 	cvt.f32.bf16 	%r118, %rs36;
(EngineCore_DP0 pid=409742) 	cvt.f32.bf16 	%r119, %rs38;
(EngineCore_DP0 pid=409742) 	.loc	1 233 27                        // quant_slide_tuned_Llama3.2-3B.py:233:27
(EngineCore_DP0 pid=409742) 	mul.f32 	%r120, %r14, %r106;
(EngineCore_DP0 pid=409742) 	mul.f32 	%r121, %r14, %r107;
(EngineCore_DP0 pid=409742) 	mov.b32 	%r122, 0f43E00000;
(EngineCore_DP0 pid=409742) 	.loc	1 233 48                        // quant_slide_tuned_Llama3.2-3B.py:233:48
(EngineCore_DP0 pid=409742) 	min.xorsign.abs.f32 	%r78, %r120, %r122;
(EngineCore_DP0 pid=409742) 	min.xorsign.abs.f32 	%r79, %r121, %r122;
(EngineCore_DP0 pid=409742) 	.loc	1 233 60                        // quant_slide_tuned_Llama3.2-3B.py:233:60
(EngineCore_DP0 pid=409742) 	// begin inline asm
(EngineCore_DP0 pid=409742) 	cvt.rn.satfinite.e4m3x2.f32  %rs40, %r79, %r78; 
(EngineCore_DP0 pid=409742) 
(EngineCore_DP0 pid=409742) 	// end inline asm
(EngineCore_DP0 pid=409742) 	shr.u16 	%rs44, %rs40, 8;
(EngineCore_DP0 pid=409742) 	.loc	1 234 27                        // quant_slide_tuned_Llama3.2-3B.py:234:27
(EngineCore_DP0 pid=409742) 	mul.f32 	%r123, %r14, %r110;
(EngineCore_DP0 pid=409742) 	mul.f32 	%r124, %r14, %r111;
(EngineCore_DP0 pid=409742) 	.loc	1 234 48                        // quant_slide_tuned_Llama3.2-3B.py:234:48
(EngineCore_DP0 pid=409742) 	min.xorsign.abs.f32 	%r80, %r123, %r122;
(EngineCore_DP0 pid=409742) 	min.xorsign.abs.f32 	%r81, %r124, %r122;
(EngineCore_DP0 pid=409742) 	.loc	1 234 60                        // quant_slide_tuned_Llama3.2-3B.py:234:60
(EngineCore_DP0 pid=409742) 	// begin inline asm
(EngineCore_DP0 pid=409742) 	cvt.rn.satfinite.e4m3x2.f32  %rs41, %r81, %r80; 
(EngineCore_DP0 pid=409742) 
(EngineCore_DP0 pid=409742) 	// end inline asm
(EngineCore_DP0 pid=409742) 	shr.u16 	%rs45, %rs41, 8;
(EngineCore_DP0 pid=409742) 	.loc	1 235 27                        // quant_slide_tuned_Llama3.2-3B.py:235:27
(EngineCore_DP0 pid=409742) 	mul.f32 	%r125, %r14, %r116;
(EngineCore_DP0 pid=409742) 	mul.f32 	%r126, %r14, %r117;
(EngineCore_DP0 pid=409742) 	.loc	1 235 48                        // quant_slide_tuned_Llama3.2-3B.py:235:48
(EngineCore_DP0 pid=409742) 	min.xorsign.abs.f32 	%r82, %r125, %r122;
(EngineCore_DP0 pid=409742) 	min.xorsign.abs.f32 	%r83, %r126, %r122;
(EngineCore_DP0 pid=409742) 	.loc	1 235 60                        // quant_slide_tuned_Llama3.2-3B.py:235:60
(EngineCore_DP0 pid=409742) 	// begin inline asm
(EngineCore_DP0 pid=409742) 	cvt.rn.satfinite.e4m3x2.f32  %rs42, %r83, %r82; 
(EngineCore_DP0 pid=409742) 
(EngineCore_DP0 pid=409742) 	// end inline asm
(EngineCore_DP0 pid=409742) 	shr.u16 	%rs46, %rs42, 8;
(EngineCore_DP0 pid=409742) 	.loc	1 236 27                        // quant_slide_tuned_Llama3.2-3B.py:236:27
(EngineCore_DP0 pid=409742) 	mul.f32 	%r127, %r14, %r118;
(EngineCore_DP0 pid=409742) 	mul.f32 	%r128, %r14, %r119;
(EngineCore_DP0 pid=409742) 	.loc	1 236 48                        // quant_slide_tuned_Llama3.2-3B.py:236:48
(EngineCore_DP0 pid=409742) 	min.xorsign.abs.f32 	%r84, %r127, %r122;
(EngineCore_DP0 pid=409742) 	min.xorsign.abs.f32 	%r85, %r128, %r122;
(EngineCore_DP0 pid=409742) 	.loc	1 236 60                        // quant_slide_tuned_Llama3.2-3B.py:236:60
(EngineCore_DP0 pid=409742) 	// begin inline asm
(EngineCore_DP0 pid=409742) 	cvt.rn.satfinite.e4m3x2.f32  %rs43, %r85, %r84; 
(EngineCore_DP0 pid=409742) 
(EngineCore_DP0 pid=409742) 	// end inline asm
(EngineCore_DP0 pid=409742) 	shr.u16 	%rs47, %rs43, 8;
(EngineCore_DP0 pid=409742) 	.loc	1 238 45                        // quant_slide_tuned_Llama3.2-3B.py:238:45
(EngineCore_DP0 pid=409742) 	cvt.u32.u16 	%r129, %rs40;
(EngineCore_DP0 pid=409742) 	and.b32 	%r130, %r129, 255;
(EngineCore_DP0 pid=409742) 	cvt.u32.u16 	%r131, %rs44;
(EngineCore_DP0 pid=409742) 	.loc	1 240 45                        // quant_slide_tuned_Llama3.2-3B.py:240:45
(EngineCore_DP0 pid=409742) 	cvt.u32.u16 	%r132, %rs42;
(EngineCore_DP0 pid=409742) 	and.b32 	%r133, %r132, 255;
(EngineCore_DP0 pid=409742) 	cvt.u32.u16 	%r134, %rs46;
(EngineCore_DP0 pid=409742) 	.loc	1 241 45                        // quant_slide_tuned_Llama3.2-3B.py:241:45
(EngineCore_DP0 pid=409742) 	cvt.u32.u16 	%r135, %rs43;
(EngineCore_DP0 pid=409742) 	cvt.u32.u16 	%r136, %rs47;
(EngineCore_DP0 pid=409742) 	.loc	1 243 30                        // quant_slide_tuned_Llama3.2-3B.py:243:30
(EngineCore_DP0 pid=409742) 	and.b16 	%rs48, %rs41, 255;
(EngineCore_DP0 pid=409742) 	mul.wide.u16 	%r137, %rs48, 256;
(EngineCore_DP0 pid=409742) 	mul.wide.u16 	%r138, %rs45, 256;
(EngineCore_DP0 pid=409742) 	.loc	1 243 24                        // quant_slide_tuned_Llama3.2-3B.py:243:24
(EngineCore_DP0 pid=409742) 	or.b32 	%r139, %r137, %r130;
(EngineCore_DP0 pid=409742) 	or.b32 	%r140, %r138, %r131;
(EngineCore_DP0 pid=409742) 	.loc	1 243 42                        // quant_slide_tuned_Llama3.2-3B.py:243:42
(EngineCore_DP0 pid=409742) 	shl.b32 	%r141, %r133, 16;
(EngineCore_DP0 pid=409742) 	shl.b32 	%r142, %r134, 16;
(EngineCore_DP0 pid=409742) 	.loc	1 243 36                        // quant_slide_tuned_Llama3.2-3B.py:243:36
(EngineCore_DP0 pid=409742) 	or.b32 	%r143, %r139, %r141;
(EngineCore_DP0 pid=409742) 	or.b32 	%r144, %r140, %r142;
(EngineCore_DP0 pid=409742) 	.loc	1 243 55                        // quant_slide_tuned_Llama3.2-3B.py:243:55
(EngineCore_DP0 pid=409742) 	shl.b32 	%r145, %r135, 24;
(EngineCore_DP0 pid=409742) 	shl.b32 	%r146, %r136, 24;
(EngineCore_DP0 pid=409742) 	.loc	1 243 49                        // quant_slide_tuned_Llama3.2-3B.py:243:49
(EngineCore_DP0 pid=409742) 	or.b32 	%r86, %r143, %r145;
(EngineCore_DP0 pid=409742) 	or.b32 	%r87, %r144, %r146;
(EngineCore_DP0 pid=409742) 	.loc	1 244 29                        // quant_slide_tuned_Llama3.2-3B.py:244:29
(EngineCore_DP0 pid=409742) 	mad.wide.s32 	%rd16, %r88, 4, %rd2;
(EngineCore_DP0 pid=409742) 	.loc	1 244 39                        // quant_slide_tuned_Llama3.2-3B.py:244:39
(EngineCore_DP0 pid=409742) 	// begin inline asm
(EngineCore_DP0 pid=409742) 	@%p17 st.global.v2.b32 [ %rd16 + 0 ], { %r86, %r87 };
(EngineCore_DP0 pid=409742) 	// end inline asm
(EngineCore_DP0 pid=409742) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=409742) 	add.s32 	%r150, %r150, 1024;
(EngineCore_DP0 pid=409742) 	setp.lt.s32 	%p26, %r150, %r15;
(EngineCore_DP0 pid=409742) 	@%p26 bra 	$L__BB0_6;
(EngineCore_DP0 pid=409742) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=409742) 	.loc	1 215 4                         // quant_slide_tuned_Llama3.2-3B.py:215:4
(EngineCore_DP0 pid=409742) 	ret;
(EngineCore_DP0 pid=409742) $L__tmp3:
(EngineCore_DP0 pid=409742) $L__func_end0:
(EngineCore_DP0 pid=409742)                                         // -- End function
(EngineCore_DP0 pid=409742) }
(EngineCore_DP0 pid=409742) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py"
(EngineCore_DP0 pid=409742) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=409742) 	.section	.debug_abbrev
(EngineCore_DP0 pid=409742) 	{
(EngineCore_DP0 pid=409742) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=409742) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=409742) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=409742) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=409742) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=409742) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=409742) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=409742) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=409742) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=409742) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=409742) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=409742) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=409742) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=409742) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=409742) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=409742) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=409742) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=409742) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=409742) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=409742) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=409742) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=409742) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=409742) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=409742) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=409742) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=409742) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=409742) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=409742) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=409742) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=409742) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=409742) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=409742) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=409742) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=409742) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=409742) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=409742) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=409742) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=409742) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=409742) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=409742) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=409742) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=409742) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=409742) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=409742) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=409742) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=409742) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=409742) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=409742) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=409742) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=409742) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=409742) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=409742) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=409742) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=409742) 	}
(EngineCore_DP0 pid=409742) 	.section	.debug_info
(EngineCore_DP0 pid=409742) 	{
(EngineCore_DP0 pid=409742) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=409742) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=409742) .b8 0
(EngineCore_DP0 pid=409742) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=409742) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=409742) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=409742) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=409742) .b8 114
(EngineCore_DP0 pid=409742) .b8 105
(EngineCore_DP0 pid=409742) .b8 116
(EngineCore_DP0 pid=409742) .b8 111
(EngineCore_DP0 pid=409742) .b8 110
(EngineCore_DP0 pid=409742) .b8 0
(EngineCore_DP0 pid=409742) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=409742) .b8 0
(EngineCore_DP0 pid=409742) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=409742) .b8 117
(EngineCore_DP0 pid=409742) .b8 97
(EngineCore_DP0 pid=409742) .b8 110
(EngineCore_DP0 pid=409742) .b8 116
(EngineCore_DP0 pid=409742) .b8 95
(EngineCore_DP0 pid=409742) .b8 115
(EngineCore_DP0 pid=409742) .b8 108
(EngineCore_DP0 pid=409742) .b8 105
(EngineCore_DP0 pid=409742) .b8 100
(EngineCore_DP0 pid=409742) .b8 101
(EngineCore_DP0 pid=409742) .b8 95
(EngineCore_DP0 pid=409742) .b8 116
(EngineCore_DP0 pid=409742) .b8 117
(EngineCore_DP0 pid=409742) .b8 110
(EngineCore_DP0 pid=409742) .b8 101
(EngineCore_DP0 pid=409742) .b8 100
(EngineCore_DP0 pid=409742) .b8 95
(EngineCore_DP0 pid=409742) .b8 76
(EngineCore_DP0 pid=409742) .b8 108
(EngineCore_DP0 pid=409742) .b8 97
(EngineCore_DP0 pid=409742) .b8 109
(EngineCore_DP0 pid=409742) .b8 97
(EngineCore_DP0 pid=409742) .b8 51
(EngineCore_DP0 pid=409742) .b8 46
(EngineCore_DP0 pid=409742) .b8 50
(EngineCore_DP0 pid=409742) .b8 45
(EngineCore_DP0 pid=409742) .b8 51
(EngineCore_DP0 pid=409742) .b8 66
(EngineCore_DP0 pid=409742) .b8 46
(EngineCore_DP0 pid=409742) .b8 112
(EngineCore_DP0 pid=409742) .b8 121
(EngineCore_DP0 pid=409742) .b8 0
(EngineCore_DP0 pid=409742) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=409742) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=409742) .b8 114
(EngineCore_DP0 pid=409742) .b8 111
(EngineCore_DP0 pid=409742) .b8 111
(EngineCore_DP0 pid=409742) .b8 116
(EngineCore_DP0 pid=409742) .b8 47
(EngineCore_DP0 pid=409742) .b8 118
(EngineCore_DP0 pid=409742) .b8 108
(EngineCore_DP0 pid=409742) .b8 108
(EngineCore_DP0 pid=409742) .b8 109
(EngineCore_DP0 pid=409742) .b8 98
(EngineCore_DP0 pid=409742) .b8 101
(EngineCore_DP0 pid=409742) .b8 110
(EngineCore_DP0 pid=409742) .b8 99
(EngineCore_DP0 pid=409742) .b8 104
(EngineCore_DP0 pid=409742) .b8 47
(EngineCore_DP0 pid=409742) .b8 115
(EngineCore_DP0 pid=409742) .b8 108
(EngineCore_DP0 pid=409742) .b8 105
(EngineCore_DP0 pid=409742) .b8 100
(EngineCore_DP0 pid=409742) .b8 101
(EngineCore_DP0 pid=409742) .b8 115
(EngineCore_DP0 pid=409742) .b8 112
(EngineCore_DP0 pid=409742) .b8 97
(EngineCore_DP0 pid=409742) .b8 114
(EngineCore_DP0 pid=409742) .b8 115
(EngineCore_DP0 pid=409742) .b8 101
(EngineCore_DP0 pid=409742) .b8 47
(EngineCore_DP0 pid=409742) .b8 99
(EngineCore_DP0 pid=409742) .b8 115
(EngineCore_DP0 pid=409742) .b8 114
(EngineCore_DP0 pid=409742) .b8 99
(EngineCore_DP0 pid=409742) .b8 47
(EngineCore_DP0 pid=409742) .b8 102
(EngineCore_DP0 pid=409742) .b8 117
(EngineCore_DP0 pid=409742) .b8 115
(EngineCore_DP0 pid=409742) .b8 101
(EngineCore_DP0 pid=409742) .b8 100
(EngineCore_DP0 pid=409742) .b8 95
(EngineCore_DP0 pid=409742) .b8 113
(EngineCore_DP0 pid=409742) .b8 117
(EngineCore_DP0 pid=409742) .b8 97
(EngineCore_DP0 pid=409742) .b8 110
(EngineCore_DP0 pid=409742) .b8 116
(EngineCore_DP0 pid=409742) .b8 95
(EngineCore_DP0 pid=409742) .b8 115
(EngineCore_DP0 pid=409742) .b8 108
(EngineCore_DP0 pid=409742) .b8 105
(EngineCore_DP0 pid=409742) .b8 100
(EngineCore_DP0 pid=409742) .b8 101
(EngineCore_DP0 pid=409742) .b8 95
(EngineCore_DP0 pid=409742) .b8 116
(EngineCore_DP0 pid=409742) .b8 114
(EngineCore_DP0 pid=409742) .b8 105
(EngineCore_DP0 pid=409742) .b8 116
(EngineCore_DP0 pid=409742) .b8 111
(EngineCore_DP0 pid=409742) .b8 110
(EngineCore_DP0 pid=409742) .b8 47
(EngineCore_DP0 pid=409742) .b8 98
(EngineCore_DP0 pid=409742) .b8 117
(EngineCore_DP0 pid=409742) .b8 105
(EngineCore_DP0 pid=409742) .b8 108
(EngineCore_DP0 pid=409742) .b8 100
(EngineCore_DP0 pid=409742) .b8 47
(EngineCore_DP0 pid=409742) .b8 71
(EngineCore_DP0 pid=409742) .b8 66
(EngineCore_DP0 pid=409742) .b8 49
(EngineCore_DP0 pid=409742) .b8 48
(EngineCore_DP0 pid=409742) .b8 95
(EngineCore_DP0 pid=409742) .b8 99
(EngineCore_DP0 pid=409742) .b8 99
(EngineCore_DP0 pid=409742) .b8 49
(EngineCore_DP0 pid=409742) .b8 50
(EngineCore_DP0 pid=409742) .b8 49
(EngineCore_DP0 pid=409742) .b8 95
(EngineCore_DP0 pid=409742) .b8 112
(EngineCore_DP0 pid=409742) .b8 121
(EngineCore_DP0 pid=409742) .b8 51
(EngineCore_DP0 pid=409742) .b8 49
(EngineCore_DP0 pid=409742) .b8 50
(EngineCore_DP0 pid=409742) .b8 95
(EngineCore_DP0 pid=409742) .b8 99
(EngineCore_DP0 pid=409742) .b8 117
(EngineCore_DP0 pid=409742) .b8 49
(EngineCore_DP0 pid=409742) .b8 50
(EngineCore_DP0 pid=409742) .b8 57
(EngineCore_DP0 pid=409742) .b8 95
(EngineCore_DP0 pid=409742) .b8 97
(EngineCore_DP0 pid=409742) .b8 97
(EngineCore_DP0 pid=409742) .b8 114
(EngineCore_DP0 pid=409742) .b8 99
(EngineCore_DP0 pid=409742) .b8 104
(EngineCore_DP0 pid=409742) .b8 54
(EngineCore_DP0 pid=409742) .b8 52
(EngineCore_DP0 pid=409742) .b8 0
(EngineCore_DP0 pid=409742) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=409742) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=409742) .b8 113
(EngineCore_DP0 pid=409742) .b8 117
(EngineCore_DP0 pid=409742) .b8 97
(EngineCore_DP0 pid=409742) .b8 110
(EngineCore_DP0 pid=409742) .b8 116
(EngineCore_DP0 pid=409742) .b8 95
(EngineCore_DP0 pid=409742) .b8 115
(EngineCore_DP0 pid=409742) .b8 108
(EngineCore_DP0 pid=409742) .b8 105
(EngineCore_DP0 pid=409742) .b8 100
(EngineCore_DP0 pid=409742) .b8 101
(EngineCore_DP0 pid=409742) .b8 95
(EngineCore_DP0 pid=409742) .b8 102
(EngineCore_DP0 pid=409742) .b8 112
(EngineCore_DP0 pid=409742) .b8 56
(EngineCore_DP0 pid=409742) .b8 95
(EngineCore_DP0 pid=409742) .b8 107
(EngineCore_DP0 pid=409742) .b8 101
(EngineCore_DP0 pid=409742) .b8 114
(EngineCore_DP0 pid=409742) .b8 110
(EngineCore_DP0 pid=409742) .b8 101
(EngineCore_DP0 pid=409742) .b8 108
(EngineCore_DP0 pid=409742) .b8 0
(EngineCore_DP0 pid=409742) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=409742) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=409742) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=409742) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=409742) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=409742) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=409742) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=409742) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=409742) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=409742) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=409742) .b8 205                                 // DW_AT_call_line
(EngineCore_DP0 pid=409742) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=409742) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=409742) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=409742) 	}
(EngineCore_DP0 pid=409742) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=409742) 
(EngineCore_DP0 pid=409742) ================================================================
(EngineCore_DP0 pid=409742) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=409742) 
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpw7gi1ndv.ptx', '-o', '/tmp/tmpw7gi1ndv.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866] 
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866] 
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866] 
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpw7gi1ndv.ptx -o /tmp/tmpw7gi1ndv.ptx.o
(EngineCore_DP0 pid=409742) ERROR 01-25 20:20:31 [core.py:866] 

STDERR:
[2026-01-25 20:19:59] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:19:59] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:19:59] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:19:59] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:19:59] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:19:59] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:19:59] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:19:59] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:19:59] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:19:59] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:19:59] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:19:59] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:19:59] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:19:59] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:20:03] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:20:03] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:20:03] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:20:03] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:20:03] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:20:03] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:20:03] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:20:03] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:20:03] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:20:03] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:20:03] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:20:03] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:20:03] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:20:03] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=409742) [2026-01-25 20:20:04] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=409742) [2026-01-25 20:20:04] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=409742) [2026-01-25 20:20:04] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=409742) [2026-01-25 20:20:04] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=409742) [2026-01-25 20:20:04] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=409742) [2026-01-25 20:20:04] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=409742) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=409742) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:25<00:00, 25.07s/it]
(EngineCore_DP0 pid=409742) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:25<00:00, 25.07s/it]
(EngineCore_DP0 pid=409742) 
(EngineCore_DP0 pid=409742) [2026-01-25 20:20:30] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4928] -> 1D uint8
(EngineCore_DP0 pid=409742) [2026-01-25 20:20:30] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15810560 bytes
(EngineCore_DP0 pid=409742) [2026-01-25 20:20:30] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4928] -> 1D uint8
(EngineCore_DP0 pid=409742) [2026-01-25 20:20:30] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9486336 bytes
(EngineCore_DP0 pid=409742) [2026-01-25 20:20:30] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4928] -> 1D uint8
(EngineCore_DP0 pid=409742) [2026-01-25 20:20:30] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 50593792 bytes
(EngineCore_DP0 pid=409742) [2026-01-25 20:20:30] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 13120] -> 1D uint8
(EngineCore_DP0 pid=409742) [2026-01-25 20:20:30] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 25214976 bytes
(EngineCore_DP0 pid=409742) Process EngineCore_DP0:
(EngineCore_DP0 pid=409742) Traceback (most recent call last):
(EngineCore_DP0 pid=409742)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=409742)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=409742)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=409742)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=409742) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpw7gi1ndv.ptx', '-o', '/tmp/tmpw7gi1ndv.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=409742) 
(EngineCore_DP0 pid=409742) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=409742) 
(EngineCore_DP0 pid=409742) Traceback (most recent call last):
(EngineCore_DP0 pid=409742)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=409742)     self.run()
(EngineCore_DP0 pid=409742)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=409742)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=409742)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=409742)     raise e
(EngineCore_DP0 pid=409742)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=409742)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=409742)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=409742)     super().__init__(
(EngineCore_DP0 pid=409742)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=409742)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=409742)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=409742)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=409742)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=409742)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=409742)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=409742)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=409742)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=409742)     return func(*args, **kwargs)
(EngineCore_DP0 pid=409742)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=409742)     return func(*args, **kwargs)
(EngineCore_DP0 pid=409742)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=409742)     self.model_runner.profile_run()
(EngineCore_DP0 pid=409742)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=409742)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=409742)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=409742)     return func(*args, **kwargs)
(EngineCore_DP0 pid=409742)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=409742)     outputs = self.model(
(EngineCore_DP0 pid=409742)               ^^^^^^^^^^^
(EngineCore_DP0 pid=409742)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=409742)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=409742)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=409742)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=409742)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=409742)     model_output = self.model(
(EngineCore_DP0 pid=409742)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=409742)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=409742)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=409742)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=409742)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=409742)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=409742)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=409742)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=409742)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=409742)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=409742)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=409742)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=409742)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=409742)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=409742)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=409742)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=409742)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=409742)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=409742)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=409742)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=409742)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=409742)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=409742)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=409742)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=409742)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=409742)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=409742)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=409742)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=409742)     return self._linear_fn(
(EngineCore_DP0 pid=409742)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=409742)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=409742)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=409742)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=409742)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=409742)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=409742)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=409742)     return fn(input, L)
(EngineCore_DP0 pid=409742)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=409742)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=409742)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=409742)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=409742)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=409742)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=409742)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=409742)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=409742)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=409742)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=409742)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=409742)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=409742)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=409742)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=409742)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=409742)     raise PTXASError(error)
(EngineCore_DP0 pid=409742) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=409742) `ptxas` stderr:
(EngineCore_DP0 pid=409742) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=409742) 
(EngineCore_DP0 pid=409742) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpw7gi1ndv.ptx -o /tmp/tmpw7gi1ndv.ptx.o
(EngineCore_DP0 pid=409742) 
[rank0]:[W125 20:20:31.907885223 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=65536

========== M=512 ==========
Time: 2026-01-25 21:45:58
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Qwen2.5-7B-FP8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:46:02 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 21:46:02 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=495248) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=495248) 
(EngineCore_DP0 pid=495248) 
(EngineCore_DP0 pid=495248) ================================================================
(EngineCore_DP0 pid=495248) Internal Triton PTX codegen error
(EngineCore_DP0 pid=495248) `ptxas` stderr:
(EngineCore_DP0 pid=495248) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=495248) 
(EngineCore_DP0 pid=495248) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpvmvykpn2.ptx -o /tmp/tmpvmvykpn2.ptx.o
(EngineCore_DP0 pid=495248) 
(EngineCore_DP0 pid=495248) 
(EngineCore_DP0 pid=495248) //
(EngineCore_DP0 pid=495248) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=495248) //
(EngineCore_DP0 pid=495248) 
(EngineCore_DP0 pid=495248) .version 8.7
(EngineCore_DP0 pid=495248) .target sm_121a
(EngineCore_DP0 pid=495248) .address_size 64
(EngineCore_DP0 pid=495248) 
(EngineCore_DP0 pid=495248) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=495248) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=495248)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=495248) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=495248) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=495248) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=495248) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=495248) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=495248) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=495248) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=495248) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=495248) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=495248) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=495248) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=495248) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=495248) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=495248) )
(EngineCore_DP0 pid=495248) .reqntid 1024
(EngineCore_DP0 pid=495248) {
(EngineCore_DP0 pid=495248) 	.reg .pred 	%p<20>;
(EngineCore_DP0 pid=495248) 	.reg .b16 	%rs<25>;
(EngineCore_DP0 pid=495248) 	.reg .b32 	%r<115>;
(EngineCore_DP0 pid=495248) 	.reg .b64 	%rd<13>;
(EngineCore_DP0 pid=495248) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=495248) $L__func_begin0:
(EngineCore_DP0 pid=495248) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=495248) 
(EngineCore_DP0 pid=495248) // %bb.0:
(EngineCore_DP0 pid=495248) 	ld.param.b32 	%r19, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=495248) 	ld.param.b32 	%r18, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=495248) 	ld.param.b32 	%r17, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=495248) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=495248) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=495248) $L__tmp0:
(EngineCore_DP0 pid=495248) 	.loc	1 143 24                        // quant_slide_tuned_Qwen2.5-7B.py:143:24
(EngineCore_DP0 pid=495248) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=495248) 	ld.param.b32 	%r21, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=495248) 	.loc	1 148 26                        // quant_slide_tuned_Qwen2.5-7B.py:148:26
(EngineCore_DP0 pid=495248) 	mul.lo.s32 	%r22, %r21, %r1;
(EngineCore_DP0 pid=495248) 	.loc	1 148 20                        // quant_slide_tuned_Qwen2.5-7B.py:148:20
(EngineCore_DP0 pid=495248) 	mad.wide.s32 	%rd1, %r22, 2, %rd4;
(EngineCore_DP0 pid=495248) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=495248) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=495248) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=495248) 	setp.lt.s32 	%p1, %r18, 1;
(EngineCore_DP0 pid=495248) 	mov.b32 	%r113, 0f2B8CBCCC;
(EngineCore_DP0 pid=495248) 	setp.eq.b32 	%p19, %r2, 0;
(EngineCore_DP0 pid=495248) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=495248) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=495248) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=495248) 	shl.b32 	%r3, %r2, 2;
(EngineCore_DP0 pid=495248) 	and.b32 	%r4, %r2, 31;
(EngineCore_DP0 pid=495248) 	shr.u32 	%r31, %r2, 3;
(EngineCore_DP0 pid=495248) 	and.b32 	%r32, %r31, 124;
(EngineCore_DP0 pid=495248) 	mov.b32 	%r33, global_smem;
(EngineCore_DP0 pid=495248) 	add.s32 	%r39, %r33, %r32;
(EngineCore_DP0 pid=495248) 	add.s32 	%r42, %r33, %r3;
(EngineCore_DP0 pid=495248) 	mov.b32 	%r37, 0;
(EngineCore_DP0 pid=495248) 	mov.b32 	%r111, 0f00000000;
(EngineCore_DP0 pid=495248) 	setp.lt.u32 	%p4, %r2, 32;
(EngineCore_DP0 pid=495248) 	setp.eq.b32 	%p3, %r4, 0;
(EngineCore_DP0 pid=495248) 	mov.b32 	%r112, %r37;
(EngineCore_DP0 pid=495248) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=495248) 	.loc	1 155 22                        // quant_slide_tuned_Qwen2.5-7B.py:155:22
(EngineCore_DP0 pid=495248) 	add.s32 	%r45, %r3, %r112;
(EngineCore_DP0 pid=495248) 	setp.lt.s32 	%p2, %r45, %r17;
(EngineCore_DP0 pid=495248) 	.loc	1 156 29                        // quant_slide_tuned_Qwen2.5-7B.py:156:29
(EngineCore_DP0 pid=495248) 	mad.wide.s32 	%rd6, %r45, 2, %rd1;
(EngineCore_DP0 pid=495248) 	.loc	1 156 21                        // quant_slide_tuned_Qwen2.5-7B.py:156:21
(EngineCore_DP0 pid=495248) 	// begin inline asm
(EngineCore_DP0 pid=495248) 	mov.u32 %r35, %r37;
(EngineCore_DP0 pid=495248) 	mov.u32 %r36, %r37;
(EngineCore_DP0 pid=495248) 	@%p2 ld.global.v2.b32 { %r35, %r36 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=495248) 	// end inline asm
(EngineCore_DP0 pid=495248) 	mov.b32 	{%rs1, %rs2}, %r35;
(EngineCore_DP0 pid=495248) 	mov.b32 	{%rs3, %rs4}, %r36;
(EngineCore_DP0 pid=495248) 	.loc	1 157 50                        // quant_slide_tuned_Qwen2.5-7B.py:157:50
(EngineCore_DP0 pid=495248) 	abs.bf16 	%rs5, %rs1;
(EngineCore_DP0 pid=495248) 	abs.bf16 	%rs6, %rs2;
(EngineCore_DP0 pid=495248) 	abs.bf16 	%rs7, %rs3;
(EngineCore_DP0 pid=495248) 	abs.bf16 	%rs8, %rs4;
(EngineCore_DP0 pid=495248) $L__tmp1:
(EngineCore_DP0 pid=495248) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=495248) 	bar.sync 	0;
(EngineCore_DP0 pid=495248) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=495248) 	max.bf16 	%rs9, %rs5, %rs6;
(EngineCore_DP0 pid=495248) 	max.bf16 	%rs10, %rs9, %rs7;
(EngineCore_DP0 pid=495248) 	max.bf16 	%rs11, %rs10, %rs8;
(EngineCore_DP0 pid=495248) 	cvt.f32.bf16 	%r46, %rs11;
(EngineCore_DP0 pid=495248) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=495248) 	shfl.sync.bfly.b32 	%r47, %r46, 16, 31, -1;
(EngineCore_DP0 pid=495248) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=495248) 	max.f32 	%r48, %r46, %r47;
(EngineCore_DP0 pid=495248) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=495248) 	shfl.sync.bfly.b32 	%r49, %r48, 8, 31, -1;
(EngineCore_DP0 pid=495248) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=495248) 	max.f32 	%r50, %r48, %r49;
(EngineCore_DP0 pid=495248) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=495248) 	shfl.sync.bfly.b32 	%r51, %r50, 4, 31, -1;
(EngineCore_DP0 pid=495248) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=495248) 	max.f32 	%r52, %r50, %r51;
(EngineCore_DP0 pid=495248) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=495248) 	shfl.sync.bfly.b32 	%r53, %r52, 2, 31, -1;
(EngineCore_DP0 pid=495248) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=495248) 	max.f32 	%r54, %r52, %r53;
(EngineCore_DP0 pid=495248) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=495248) 	shfl.sync.bfly.b32 	%r55, %r54, 1, 31, -1;
(EngineCore_DP0 pid=495248) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=495248) 	max.f32 	%r40, %r54, %r55;
(EngineCore_DP0 pid=495248) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=495248) 	// begin inline asm
(EngineCore_DP0 pid=495248) 	@%p3 st.shared.b32 [ %r39 + 0 ], %r40;
(EngineCore_DP0 pid=495248) 	// end inline asm
(EngineCore_DP0 pid=495248) 	bar.sync 	0;
(EngineCore_DP0 pid=495248) 	// begin inline asm
(EngineCore_DP0 pid=495248) 	@%p4 ld.shared.b32 %r41, [ %r42 + 0 ];
(EngineCore_DP0 pid=495248) 	// end inline asm
(EngineCore_DP0 pid=495248) 	shfl.sync.bfly.b32 	%r56, %r41, 16, 31, -1;
(EngineCore_DP0 pid=495248) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=495248) 	max.f32 	%r57, %r41, %r56;
(EngineCore_DP0 pid=495248) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=495248) 	shfl.sync.bfly.b32 	%r58, %r57, 8, 31, -1;
(EngineCore_DP0 pid=495248) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=495248) 	max.f32 	%r59, %r57, %r58;
(EngineCore_DP0 pid=495248) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=495248) 	shfl.sync.bfly.b32 	%r60, %r59, 4, 31, -1;
(EngineCore_DP0 pid=495248) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=495248) 	max.f32 	%r61, %r59, %r60;
(EngineCore_DP0 pid=495248) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=495248) 	shfl.sync.bfly.b32 	%r62, %r61, 2, 31, -1;
(EngineCore_DP0 pid=495248) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=495248) 	max.f32 	%r63, %r61, %r62;
(EngineCore_DP0 pid=495248) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=495248) 	shfl.sync.bfly.b32 	%r64, %r63, 1, 31, -1;
(EngineCore_DP0 pid=495248) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=495248) 	max.f32 	%r44, %r63, %r64;
(EngineCore_DP0 pid=495248) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=495248) 	// begin inline asm
(EngineCore_DP0 pid=495248) 	@%p19 st.shared.b32 [ %r42 + 0 ], %r44;
(EngineCore_DP0 pid=495248) 	// end inline asm
(EngineCore_DP0 pid=495248) 	bar.sync 	0;
(EngineCore_DP0 pid=495248) 	ld.shared.b32 	%r65, [global_smem];
(EngineCore_DP0 pid=495248) $L__tmp2:
(EngineCore_DP0 pid=495248) 	.loc	1 157 36                        // quant_slide_tuned_Qwen2.5-7B.py:157:36
(EngineCore_DP0 pid=495248) 	max.f32 	%r111, %r111, %r65;
(EngineCore_DP0 pid=495248) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=495248) 	add.s32 	%r112, %r112, 4096;
(EngineCore_DP0 pid=495248) 	setp.lt.s32 	%p6, %r112, %r18;
(EngineCore_DP0 pid=495248) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=495248) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=495248) 	.loc	1 159 32                        // quant_slide_tuned_Qwen2.5-7B.py:159:32
(EngineCore_DP0 pid=495248) 	max.f32 	%r113, %r111, 0f2B8CBCCC;
(EngineCore_DP0 pid=495248) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=495248) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-7B.py:0:32
(EngineCore_DP0 pid=495248) 	mov.b32 	%r67, 0f43E00000;
(EngineCore_DP0 pid=495248) 	.loc	1 160 32                        // quant_slide_tuned_Qwen2.5-7B.py:160:32
(EngineCore_DP0 pid=495248) 	div.full.f32 	%r68, %r113, %r67;
(EngineCore_DP0 pid=495248) 	.loc	1 160 41                        // quant_slide_tuned_Qwen2.5-7B.py:160:41
(EngineCore_DP0 pid=495248) 	max.f32 	%r66, %r68, 0f36924925;
(EngineCore_DP0 pid=495248) 	.loc	1 162 25                        // quant_slide_tuned_Qwen2.5-7B.py:162:25
(EngineCore_DP0 pid=495248) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=495248) 	.loc	1 162 30                        // quant_slide_tuned_Qwen2.5-7B.py:162:30
(EngineCore_DP0 pid=495248) 	// begin inline asm
(EngineCore_DP0 pid=495248) 	@%p19 st.global.b32 [ %rd7 + 0 ], { %r66 };
(EngineCore_DP0 pid=495248) 	// end inline asm
(EngineCore_DP0 pid=495248) 	.loc	1 165 29                        // quant_slide_tuned_Qwen2.5-7B.py:165:29
(EngineCore_DP0 pid=495248) 	shl.b32 	%r14, %r19, 2;
(EngineCore_DP0 pid=495248) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=495248) 	setp.lt.s32 	%p8, %r14, 1;
(EngineCore_DP0 pid=495248) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=495248) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=495248) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-7B.py:0:41
(EngineCore_DP0 pid=495248) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=495248) 	shr.s32 	%r24, %r23, 31;
(EngineCore_DP0 pid=495248) 	shr.u32 	%r25, %r24, 30;
(EngineCore_DP0 pid=495248) 	add.s32 	%r26, %r23, %r25;
(EngineCore_DP0 pid=495248) 	shr.s32 	%r27, %r26, 2;
(EngineCore_DP0 pid=495248) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=495248) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=495248) 	mad.wide.s32 	%rd2, %r28, 4, %rd5;
(EngineCore_DP0 pid=495248) 	div.full.f32 	%r13, %r67, %r113;
(EngineCore_DP0 pid=495248) 	mov.b32 	%r114, 0;
(EngineCore_DP0 pid=495248) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=495248)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=495248) 	.loc	1 169 30                        // quant_slide_tuned_Qwen2.5-7B.py:169:30
(EngineCore_DP0 pid=495248) 	add.s32 	%r80, %r2, %r114;
(EngineCore_DP0 pid=495248) 	setp.lt.s32 	%p13, %r80, %r14;
(EngineCore_DP0 pid=495248) 	.loc	1 172 24                        // quant_slide_tuned_Qwen2.5-7B.py:172:24
(EngineCore_DP0 pid=495248) 	shr.s32 	%r81, %r80, 31;
(EngineCore_DP0 pid=495248) 	shr.u32 	%r82, %r81, 30;
(EngineCore_DP0 pid=495248) 	add.s32 	%r83, %r80, %r82;
(EngineCore_DP0 pid=495248) 	shr.s32 	%r84, %r83, 2;
(EngineCore_DP0 pid=495248) 	.loc	1 173 23                        // quant_slide_tuned_Qwen2.5-7B.py:173:23
(EngineCore_DP0 pid=495248) 	and.b32 	%r85, %r83, 2147483644;
(EngineCore_DP0 pid=495248) 	sub.s32 	%r86, %r80, %r85;
(EngineCore_DP0 pid=495248) 	.loc	1 174 30                        // quant_slide_tuned_Qwen2.5-7B.py:174:30
(EngineCore_DP0 pid=495248) 	shl.b32 	%r87, %r86, 1;
(EngineCore_DP0 pid=495248) 	.loc	1 174 26                        // quant_slide_tuned_Qwen2.5-7B.py:174:26
(EngineCore_DP0 pid=495248) 	mad.lo.s32 	%r88, %r84, 10, %r87;
(EngineCore_DP0 pid=495248) 	.loc	1 177 53                        // quant_slide_tuned_Qwen2.5-7B.py:177:53
(EngineCore_DP0 pid=495248) 	setp.lt.s32 	%p14, %r88, %r17;
(EngineCore_DP0 pid=495248) 	.loc	1 177 37                        // quant_slide_tuned_Qwen2.5-7B.py:177:37
(EngineCore_DP0 pid=495248) 	and.pred 	%p9, %p13, %p14;
(EngineCore_DP0 pid=495248) 	.loc	1 176 29                        // quant_slide_tuned_Qwen2.5-7B.py:176:29
(EngineCore_DP0 pid=495248) 	mad.wide.s32 	%rd8, %r88, 2, %rd1;
(EngineCore_DP0 pid=495248) 	mov.b16 	%rs13, 0;
(EngineCore_DP0 pid=495248) 	.loc	1 176 21                        // quant_slide_tuned_Qwen2.5-7B.py:176:21
(EngineCore_DP0 pid=495248) 	// begin inline asm
(EngineCore_DP0 pid=495248) 	mov.u16 %rs12, %rs13;
(EngineCore_DP0 pid=495248) 	@%p9 ld.global.b16 { %rs12 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=495248) 	// end inline asm
(EngineCore_DP0 pid=495248) 	.loc	1 177 79                        // quant_slide_tuned_Qwen2.5-7B.py:177:79
(EngineCore_DP0 pid=495248) 	cvt.f32.bf16 	%r89, %rs12;
(EngineCore_DP0 pid=495248) 	.loc	1 179 48                        // quant_slide_tuned_Qwen2.5-7B.py:179:48
(EngineCore_DP0 pid=495248) 	or.b32 	%r90, %r88, 1;
(EngineCore_DP0 pid=495248) 	.loc	1 179 53                        // quant_slide_tuned_Qwen2.5-7B.py:179:53
(EngineCore_DP0 pid=495248) 	setp.lt.s32 	%p15, %r90, %r17;
(EngineCore_DP0 pid=495248) 	.loc	1 179 37                        // quant_slide_tuned_Qwen2.5-7B.py:179:37
(EngineCore_DP0 pid=495248) 	and.pred 	%p10, %p13, %p15;
(EngineCore_DP0 pid=495248) 	.loc	1 178 39                        // quant_slide_tuned_Qwen2.5-7B.py:178:39
(EngineCore_DP0 pid=495248) 	add.s64 	%rd9, %rd8, 2;
(EngineCore_DP0 pid=495248) 	.loc	1 178 21                        // quant_slide_tuned_Qwen2.5-7B.py:178:21
(EngineCore_DP0 pid=495248) 	// begin inline asm
(EngineCore_DP0 pid=495248) 	mov.u16 %rs14, %rs13;
(EngineCore_DP0 pid=495248) 	@%p10 ld.global.b16 { %rs14 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=495248) 	// end inline asm
(EngineCore_DP0 pid=495248) 	.loc	1 179 79                        // quant_slide_tuned_Qwen2.5-7B.py:179:79
(EngineCore_DP0 pid=495248) 	cvt.f32.bf16 	%r91, %rs14;
(EngineCore_DP0 pid=495248) 	.loc	1 181 48                        // quant_slide_tuned_Qwen2.5-7B.py:181:48
(EngineCore_DP0 pid=495248) 	add.s32 	%r92, %r88, 2;
(EngineCore_DP0 pid=495248) 	.loc	1 181 53                        // quant_slide_tuned_Qwen2.5-7B.py:181:53
(EngineCore_DP0 pid=495248) 	setp.lt.s32 	%p16, %r92, %r17;
(EngineCore_DP0 pid=495248) 	.loc	1 181 37                        // quant_slide_tuned_Qwen2.5-7B.py:181:37
(EngineCore_DP0 pid=495248) 	and.pred 	%p11, %p13, %p16;
(EngineCore_DP0 pid=495248) 	.loc	1 180 39                        // quant_slide_tuned_Qwen2.5-7B.py:180:39
(EngineCore_DP0 pid=495248) 	add.s64 	%rd10, %rd8, 4;
(EngineCore_DP0 pid=495248) 	.loc	1 180 21                        // quant_slide_tuned_Qwen2.5-7B.py:180:21
(EngineCore_DP0 pid=495248) 	// begin inline asm
(EngineCore_DP0 pid=495248) 	mov.u16 %rs16, %rs13;
(EngineCore_DP0 pid=495248) 	@%p11 ld.global.b16 { %rs16 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=495248) 	// end inline asm
(EngineCore_DP0 pid=495248) 	.loc	1 181 79                        // quant_slide_tuned_Qwen2.5-7B.py:181:79
(EngineCore_DP0 pid=495248) 	cvt.f32.bf16 	%r93, %rs16;
(EngineCore_DP0 pid=495248) 	.loc	1 183 48                        // quant_slide_tuned_Qwen2.5-7B.py:183:48
(EngineCore_DP0 pid=495248) 	add.s32 	%r94, %r88, 3;
(EngineCore_DP0 pid=495248) 	.loc	1 183 53                        // quant_slide_tuned_Qwen2.5-7B.py:183:53
(EngineCore_DP0 pid=495248) 	setp.lt.s32 	%p17, %r94, %r17;
(EngineCore_DP0 pid=495248) 	.loc	1 183 37                        // quant_slide_tuned_Qwen2.5-7B.py:183:37
(EngineCore_DP0 pid=495248) 	and.pred 	%p12, %p13, %p17;
(EngineCore_DP0 pid=495248) 	.loc	1 182 39                        // quant_slide_tuned_Qwen2.5-7B.py:182:39
(EngineCore_DP0 pid=495248) 	add.s64 	%rd11, %rd8, 6;
(EngineCore_DP0 pid=495248) 	.loc	1 182 21                        // quant_slide_tuned_Qwen2.5-7B.py:182:21
(EngineCore_DP0 pid=495248) 	// begin inline asm
(EngineCore_DP0 pid=495248) 	mov.u16 %rs18, %rs13;
(EngineCore_DP0 pid=495248) 	@%p12 ld.global.b16 { %rs18 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=495248) 	// end inline asm
(EngineCore_DP0 pid=495248) 	.loc	1 183 79                        // quant_slide_tuned_Qwen2.5-7B.py:183:79
(EngineCore_DP0 pid=495248) 	cvt.f32.bf16 	%r95, %rs18;
(EngineCore_DP0 pid=495248) 	.loc	1 185 27                        // quant_slide_tuned_Qwen2.5-7B.py:185:27
(EngineCore_DP0 pid=495248) 	mul.f32 	%r96, %r13, %r89;
(EngineCore_DP0 pid=495248) 	mov.b32 	%r97, 0f43E00000;
(EngineCore_DP0 pid=495248) 	.loc	1 185 48                        // quant_slide_tuned_Qwen2.5-7B.py:185:48
(EngineCore_DP0 pid=495248) 	min.xorsign.abs.f32 	%r70, %r96, %r97;
(EngineCore_DP0 pid=495248) 	.loc	1 185 60                        // quant_slide_tuned_Qwen2.5-7B.py:185:60
(EngineCore_DP0 pid=495248) 	// begin inline asm
(EngineCore_DP0 pid=495248) 	cvt.rn.satfinite.e4m3x2.f32  %rs20, %r71, %r70; 
(EngineCore_DP0 pid=495248) 
(EngineCore_DP0 pid=495248) 	// end inline asm
(EngineCore_DP0 pid=495248) 	.loc	1 186 27                        // quant_slide_tuned_Qwen2.5-7B.py:186:27
(EngineCore_DP0 pid=495248) 	mul.f32 	%r98, %r13, %r91;
(EngineCore_DP0 pid=495248) 	.loc	1 186 48                        // quant_slide_tuned_Qwen2.5-7B.py:186:48
(EngineCore_DP0 pid=495248) 	min.xorsign.abs.f32 	%r72, %r98, %r97;
(EngineCore_DP0 pid=495248) 	.loc	1 186 60                        // quant_slide_tuned_Qwen2.5-7B.py:186:60
(EngineCore_DP0 pid=495248) 	// begin inline asm
(EngineCore_DP0 pid=495248) 	cvt.rn.satfinite.e4m3x2.f32  %rs21, %r73, %r72; 
(EngineCore_DP0 pid=495248) 
(EngineCore_DP0 pid=495248) 	// end inline asm
(EngineCore_DP0 pid=495248) 	.loc	1 187 27                        // quant_slide_tuned_Qwen2.5-7B.py:187:27
(EngineCore_DP0 pid=495248) 	mul.f32 	%r99, %r13, %r93;
(EngineCore_DP0 pid=495248) 	.loc	1 187 48                        // quant_slide_tuned_Qwen2.5-7B.py:187:48
(EngineCore_DP0 pid=495248) 	min.xorsign.abs.f32 	%r74, %r99, %r97;
(EngineCore_DP0 pid=495248) 	.loc	1 187 60                        // quant_slide_tuned_Qwen2.5-7B.py:187:60
(EngineCore_DP0 pid=495248) 	// begin inline asm
(EngineCore_DP0 pid=495248) 	cvt.rn.satfinite.e4m3x2.f32  %rs22, %r75, %r74; 
(EngineCore_DP0 pid=495248) 
(EngineCore_DP0 pid=495248) 	// end inline asm
(EngineCore_DP0 pid=495248) 	.loc	1 188 27                        // quant_slide_tuned_Qwen2.5-7B.py:188:27
(EngineCore_DP0 pid=495248) 	mul.f32 	%r100, %r13, %r95;
(EngineCore_DP0 pid=495248) 	.loc	1 188 48                        // quant_slide_tuned_Qwen2.5-7B.py:188:48
(EngineCore_DP0 pid=495248) 	min.xorsign.abs.f32 	%r76, %r100, %r97;
(EngineCore_DP0 pid=495248) 	.loc	1 188 60                        // quant_slide_tuned_Qwen2.5-7B.py:188:60
(EngineCore_DP0 pid=495248) 	// begin inline asm
(EngineCore_DP0 pid=495248) 	cvt.rn.satfinite.e4m3x2.f32  %rs23, %r77, %r76; 
(EngineCore_DP0 pid=495248) 
(EngineCore_DP0 pid=495248) 	// end inline asm
(EngineCore_DP0 pid=495248) 	.loc	1 190 45                        // quant_slide_tuned_Qwen2.5-7B.py:190:45
(EngineCore_DP0 pid=495248) 	cvt.u32.u16 	%r101, %rs20;
(EngineCore_DP0 pid=495248) 	and.b32 	%r102, %r101, 255;
(EngineCore_DP0 pid=495248) 	.loc	1 192 45                        // quant_slide_tuned_Qwen2.5-7B.py:192:45
(EngineCore_DP0 pid=495248) 	cvt.u32.u16 	%r103, %rs22;
(EngineCore_DP0 pid=495248) 	and.b32 	%r104, %r103, 255;
(EngineCore_DP0 pid=495248) 	.loc	1 193 45                        // quant_slide_tuned_Qwen2.5-7B.py:193:45
(EngineCore_DP0 pid=495248) 	cvt.u32.u16 	%r105, %rs23;
(EngineCore_DP0 pid=495248) 	.loc	1 195 30                        // quant_slide_tuned_Qwen2.5-7B.py:195:30
(EngineCore_DP0 pid=495248) 	and.b16 	%rs24, %rs21, 255;
(EngineCore_DP0 pid=495248) 	mul.wide.u16 	%r106, %rs24, 256;
(EngineCore_DP0 pid=495248) 	.loc	1 195 24                        // quant_slide_tuned_Qwen2.5-7B.py:195:24
(EngineCore_DP0 pid=495248) 	or.b32 	%r107, %r106, %r102;
(EngineCore_DP0 pid=495248) 	.loc	1 195 42                        // quant_slide_tuned_Qwen2.5-7B.py:195:42
(EngineCore_DP0 pid=495248) 	shl.b32 	%r108, %r104, 16;
(EngineCore_DP0 pid=495248) 	.loc	1 195 36                        // quant_slide_tuned_Qwen2.5-7B.py:195:36
(EngineCore_DP0 pid=495248) 	or.b32 	%r109, %r107, %r108;
(EngineCore_DP0 pid=495248) 	.loc	1 195 55                        // quant_slide_tuned_Qwen2.5-7B.py:195:55
(EngineCore_DP0 pid=495248) 	shl.b32 	%r110, %r105, 24;
(EngineCore_DP0 pid=495248) 	.loc	1 195 49                        // quant_slide_tuned_Qwen2.5-7B.py:195:49
(EngineCore_DP0 pid=495248) 	or.b32 	%r78, %r109, %r110;
(EngineCore_DP0 pid=495248) 	.loc	1 196 29                        // quant_slide_tuned_Qwen2.5-7B.py:196:29
(EngineCore_DP0 pid=495248) 	mad.wide.s32 	%rd12, %r80, 4, %rd2;
(EngineCore_DP0 pid=495248) 	.loc	1 196 39                        // quant_slide_tuned_Qwen2.5-7B.py:196:39
(EngineCore_DP0 pid=495248) 	// begin inline asm
(EngineCore_DP0 pid=495248) 	@%p13 st.global.b32 [ %rd12 + 0 ], { %r78 };
(EngineCore_DP0 pid=495248) 	// end inline asm
(EngineCore_DP0 pid=495248) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=495248) 	add.s32 	%r114, %r114, 1024;
(EngineCore_DP0 pid=495248) 	setp.lt.s32 	%p18, %r114, %r14;
(EngineCore_DP0 pid=495248) 	@%p18 bra 	$L__BB0_6;
(EngineCore_DP0 pid=495248) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=495248) 	.loc	1 167 4                         // quant_slide_tuned_Qwen2.5-7B.py:167:4
(EngineCore_DP0 pid=495248) 	ret;
(EngineCore_DP0 pid=495248) $L__tmp3:
(EngineCore_DP0 pid=495248) $L__func_end0:
(EngineCore_DP0 pid=495248)                                         // -- End function
(EngineCore_DP0 pid=495248) }
(EngineCore_DP0 pid=495248) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py"
(EngineCore_DP0 pid=495248) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=495248) 	.section	.debug_abbrev
(EngineCore_DP0 pid=495248) 	{
(EngineCore_DP0 pid=495248) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=495248) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=495248) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=495248) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=495248) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=495248) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=495248) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=495248) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=495248) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=495248) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=495248) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=495248) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=495248) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=495248) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=495248) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=495248) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=495248) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=495248) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=495248) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=495248) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=495248) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=495248) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=495248) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=495248) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=495248) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=495248) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=495248) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=495248) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=495248) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=495248) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=495248) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=495248) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=495248) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=495248) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=495248) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=495248) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=495248) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=495248) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=495248) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=495248) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=495248) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=495248) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=495248) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=495248) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=495248) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=495248) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=495248) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=495248) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=495248) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=495248) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=495248) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=495248) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=495248) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=495248) 	}
(EngineCore_DP0 pid=495248) 	.section	.debug_info
(EngineCore_DP0 pid=495248) 	{
(EngineCore_DP0 pid=495248) .b32 221                                // Length of Unit
(EngineCore_DP0 pid=495248) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=495248) .b8 0
(EngineCore_DP0 pid=495248) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=495248) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=495248) .b8 1                                   // Abbrev [1] 0xb:0xd6 DW_TAG_compile_unit
(EngineCore_DP0 pid=495248) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=495248) .b8 114
(EngineCore_DP0 pid=495248) .b8 105
(EngineCore_DP0 pid=495248) .b8 116
(EngineCore_DP0 pid=495248) .b8 111
(EngineCore_DP0 pid=495248) .b8 110
(EngineCore_DP0 pid=495248) .b8 0
(EngineCore_DP0 pid=495248) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=495248) .b8 0
(EngineCore_DP0 pid=495248) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=495248) .b8 117
(EngineCore_DP0 pid=495248) .b8 97
(EngineCore_DP0 pid=495248) .b8 110
(EngineCore_DP0 pid=495248) .b8 116
(EngineCore_DP0 pid=495248) .b8 95
(EngineCore_DP0 pid=495248) .b8 115
(EngineCore_DP0 pid=495248) .b8 108
(EngineCore_DP0 pid=495248) .b8 105
(EngineCore_DP0 pid=495248) .b8 100
(EngineCore_DP0 pid=495248) .b8 101
(EngineCore_DP0 pid=495248) .b8 95
(EngineCore_DP0 pid=495248) .b8 116
(EngineCore_DP0 pid=495248) .b8 117
(EngineCore_DP0 pid=495248) .b8 110
(EngineCore_DP0 pid=495248) .b8 101
(EngineCore_DP0 pid=495248) .b8 100
(EngineCore_DP0 pid=495248) .b8 95
(EngineCore_DP0 pid=495248) .b8 81
(EngineCore_DP0 pid=495248) .b8 119
(EngineCore_DP0 pid=495248) .b8 101
(EngineCore_DP0 pid=495248) .b8 110
(EngineCore_DP0 pid=495248) .b8 50
(EngineCore_DP0 pid=495248) .b8 46
(EngineCore_DP0 pid=495248) .b8 53
(EngineCore_DP0 pid=495248) .b8 45
(EngineCore_DP0 pid=495248) .b8 55
(EngineCore_DP0 pid=495248) .b8 66
(EngineCore_DP0 pid=495248) .b8 46
(EngineCore_DP0 pid=495248) .b8 112
(EngineCore_DP0 pid=495248) .b8 121
(EngineCore_DP0 pid=495248) .b8 0
(EngineCore_DP0 pid=495248) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=495248) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=495248) .b8 114
(EngineCore_DP0 pid=495248) .b8 111
(EngineCore_DP0 pid=495248) .b8 111
(EngineCore_DP0 pid=495248) .b8 116
(EngineCore_DP0 pid=495248) .b8 47
(EngineCore_DP0 pid=495248) .b8 118
(EngineCore_DP0 pid=495248) .b8 108
(EngineCore_DP0 pid=495248) .b8 108
(EngineCore_DP0 pid=495248) .b8 109
(EngineCore_DP0 pid=495248) .b8 98
(EngineCore_DP0 pid=495248) .b8 101
(EngineCore_DP0 pid=495248) .b8 110
(EngineCore_DP0 pid=495248) .b8 99
(EngineCore_DP0 pid=495248) .b8 104
(EngineCore_DP0 pid=495248) .b8 47
(EngineCore_DP0 pid=495248) .b8 115
(EngineCore_DP0 pid=495248) .b8 108
(EngineCore_DP0 pid=495248) .b8 105
(EngineCore_DP0 pid=495248) .b8 100
(EngineCore_DP0 pid=495248) .b8 101
(EngineCore_DP0 pid=495248) .b8 115
(EngineCore_DP0 pid=495248) .b8 112
(EngineCore_DP0 pid=495248) .b8 97
(EngineCore_DP0 pid=495248) .b8 114
(EngineCore_DP0 pid=495248) .b8 115
(EngineCore_DP0 pid=495248) .b8 101
(EngineCore_DP0 pid=495248) .b8 47
(EngineCore_DP0 pid=495248) .b8 99
(EngineCore_DP0 pid=495248) .b8 115
(EngineCore_DP0 pid=495248) .b8 114
(EngineCore_DP0 pid=495248) .b8 99
(EngineCore_DP0 pid=495248) .b8 47
(EngineCore_DP0 pid=495248) .b8 102
(EngineCore_DP0 pid=495248) .b8 117
(EngineCore_DP0 pid=495248) .b8 115
(EngineCore_DP0 pid=495248) .b8 101
(EngineCore_DP0 pid=495248) .b8 100
(EngineCore_DP0 pid=495248) .b8 95
(EngineCore_DP0 pid=495248) .b8 113
(EngineCore_DP0 pid=495248) .b8 117
(EngineCore_DP0 pid=495248) .b8 97
(EngineCore_DP0 pid=495248) .b8 110
(EngineCore_DP0 pid=495248) .b8 116
(EngineCore_DP0 pid=495248) .b8 95
(EngineCore_DP0 pid=495248) .b8 115
(EngineCore_DP0 pid=495248) .b8 108
(EngineCore_DP0 pid=495248) .b8 105
(EngineCore_DP0 pid=495248) .b8 100
(EngineCore_DP0 pid=495248) .b8 101
(EngineCore_DP0 pid=495248) .b8 95
(EngineCore_DP0 pid=495248) .b8 116
(EngineCore_DP0 pid=495248) .b8 114
(EngineCore_DP0 pid=495248) .b8 105
(EngineCore_DP0 pid=495248) .b8 116
(EngineCore_DP0 pid=495248) .b8 111
(EngineCore_DP0 pid=495248) .b8 110
(EngineCore_DP0 pid=495248) .b8 47
(EngineCore_DP0 pid=495248) .b8 98
(EngineCore_DP0 pid=495248) .b8 117
(EngineCore_DP0 pid=495248) .b8 105
(EngineCore_DP0 pid=495248) .b8 108
(EngineCore_DP0 pid=495248) .b8 100
(EngineCore_DP0 pid=495248) .b8 47
(EngineCore_DP0 pid=495248) .b8 71
(EngineCore_DP0 pid=495248) .b8 66
(EngineCore_DP0 pid=495248) .b8 49
(EngineCore_DP0 pid=495248) .b8 48
(EngineCore_DP0 pid=495248) .b8 95
(EngineCore_DP0 pid=495248) .b8 99
(EngineCore_DP0 pid=495248) .b8 99
(EngineCore_DP0 pid=495248) .b8 49
(EngineCore_DP0 pid=495248) .b8 50
(EngineCore_DP0 pid=495248) .b8 49
(EngineCore_DP0 pid=495248) .b8 95
(EngineCore_DP0 pid=495248) .b8 112
(EngineCore_DP0 pid=495248) .b8 121
(EngineCore_DP0 pid=495248) .b8 51
(EngineCore_DP0 pid=495248) .b8 49
(EngineCore_DP0 pid=495248) .b8 50
(EngineCore_DP0 pid=495248) .b8 95
(EngineCore_DP0 pid=495248) .b8 99
(EngineCore_DP0 pid=495248) .b8 117
(EngineCore_DP0 pid=495248) .b8 49
(EngineCore_DP0 pid=495248) .b8 50
(EngineCore_DP0 pid=495248) .b8 57
(EngineCore_DP0 pid=495248) .b8 95
(EngineCore_DP0 pid=495248) .b8 97
(EngineCore_DP0 pid=495248) .b8 97
(EngineCore_DP0 pid=495248) .b8 114
(EngineCore_DP0 pid=495248) .b8 99
(EngineCore_DP0 pid=495248) .b8 104
(EngineCore_DP0 pid=495248) .b8 54
(EngineCore_DP0 pid=495248) .b8 52
(EngineCore_DP0 pid=495248) .b8 0
(EngineCore_DP0 pid=495248) .b8 2                                   // Abbrev [2] 0x98:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=495248) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=495248) .b8 113
(EngineCore_DP0 pid=495248) .b8 117
(EngineCore_DP0 pid=495248) .b8 97
(EngineCore_DP0 pid=495248) .b8 110
(EngineCore_DP0 pid=495248) .b8 116
(EngineCore_DP0 pid=495248) .b8 95
(EngineCore_DP0 pid=495248) .b8 115
(EngineCore_DP0 pid=495248) .b8 108
(EngineCore_DP0 pid=495248) .b8 105
(EngineCore_DP0 pid=495248) .b8 100
(EngineCore_DP0 pid=495248) .b8 101
(EngineCore_DP0 pid=495248) .b8 95
(EngineCore_DP0 pid=495248) .b8 102
(EngineCore_DP0 pid=495248) .b8 112
(EngineCore_DP0 pid=495248) .b8 56
(EngineCore_DP0 pid=495248) .b8 95
(EngineCore_DP0 pid=495248) .b8 107
(EngineCore_DP0 pid=495248) .b8 101
(EngineCore_DP0 pid=495248) .b8 114
(EngineCore_DP0 pid=495248) .b8 110
(EngineCore_DP0 pid=495248) .b8 101
(EngineCore_DP0 pid=495248) .b8 108
(EngineCore_DP0 pid=495248) .b8 0
(EngineCore_DP0 pid=495248) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=495248) .b8 3                                   // Abbrev [3] 0xb2:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=495248) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=495248) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=495248) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=495248) .b8 4                                   // Abbrev [4] 0xc7:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=495248) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=495248) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=495248) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=495248) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=495248) .b8 157                                 // DW_AT_call_line
(EngineCore_DP0 pid=495248) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=495248) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=495248) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=495248) 	}
(EngineCore_DP0 pid=495248) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=495248) 
(EngineCore_DP0 pid=495248) ================================================================
(EngineCore_DP0 pid=495248) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=495248) 
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpvmvykpn2.ptx', '-o', '/tmp/tmpvmvykpn2.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866] 
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866] 
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866] 
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpvmvykpn2.ptx -o /tmp/tmpvmvykpn2.ptx.o
(EngineCore_DP0 pid=495248) ERROR 01-25 21:47:15 [core.py:866] 

STDERR:
[2026-01-25 21:46:02] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:46:02] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:46:02] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:46:02] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:46:02] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:46:02] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:46:02] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:46:02] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:46:02] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:46:02] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:46:02] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:46:02] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:46:02] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:46:02] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:46:05] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:46:05] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:46:05] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:46:05] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:46:05] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:46:05] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:46:05] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:46:05] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:46:05] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:46:05] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:46:05] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:46:05] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:46:05] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:46:05] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=495248) [2026-01-25 21:46:06] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=495248) [2026-01-25 21:46:06] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=495248) [2026-01-25 21:46:06] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=495248) [2026-01-25 21:46:06] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=495248) [2026-01-25 21:46:06] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=495248) [2026-01-25 21:46:06] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=495248) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=495248) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:28<00:28, 28.56s/it]
(EngineCore_DP0 pid=495248) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:06<00:00, 33.91s/it]
(EngineCore_DP0 pid=495248) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:06<00:00, 33.11s/it]
(EngineCore_DP0 pid=495248) 
(EngineCore_DP0 pid=495248) [2026-01-25 21:47:14] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=495248) [2026-01-25 21:47:14] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16588800 bytes
(EngineCore_DP0 pid=495248) [2026-01-25 21:47:14] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=495248) [2026-01-25 21:47:14] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 12902400 bytes
(EngineCore_DP0 pid=495248) [2026-01-25 21:47:14] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=495248) [2026-01-25 21:47:14] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 136396800 bytes
(EngineCore_DP0 pid=495248) [2026-01-25 21:47:14] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=495248) [2026-01-25 21:47:14] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 67952640 bytes
(EngineCore_DP0 pid=495248) Process EngineCore_DP0:
(EngineCore_DP0 pid=495248) Traceback (most recent call last):
(EngineCore_DP0 pid=495248)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=495248)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=495248)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=495248)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=495248) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpvmvykpn2.ptx', '-o', '/tmp/tmpvmvykpn2.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=495248) 
(EngineCore_DP0 pid=495248) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=495248) 
(EngineCore_DP0 pid=495248) Traceback (most recent call last):
(EngineCore_DP0 pid=495248)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=495248)     self.run()
(EngineCore_DP0 pid=495248)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=495248)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=495248)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=495248)     raise e
(EngineCore_DP0 pid=495248)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=495248)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=495248)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=495248)     super().__init__(
(EngineCore_DP0 pid=495248)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=495248)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=495248)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=495248)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=495248)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=495248)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=495248)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=495248)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=495248)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=495248)     return func(*args, **kwargs)
(EngineCore_DP0 pid=495248)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=495248)     return func(*args, **kwargs)
(EngineCore_DP0 pid=495248)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=495248)     self.model_runner.profile_run()
(EngineCore_DP0 pid=495248)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=495248)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=495248)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=495248)     return func(*args, **kwargs)
(EngineCore_DP0 pid=495248)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=495248)     outputs = self.model(
(EngineCore_DP0 pid=495248)               ^^^^^^^^^^^
(EngineCore_DP0 pid=495248)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=495248)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=495248)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=495248)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=495248)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=495248)     hidden_states = self.model(
(EngineCore_DP0 pid=495248)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=495248)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=495248)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=495248)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=495248)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=495248)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=495248)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=495248)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=495248)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=495248)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=495248)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=495248)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=495248)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=495248)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=495248)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=495248)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=495248)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=495248)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=495248)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=495248)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=495248)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=495248)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=495248)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=495248)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=495248)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=495248)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=495248)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=495248)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=495248)     return self._linear_fn(
(EngineCore_DP0 pid=495248)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=495248)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=495248)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=495248)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=495248)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=495248)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=495248)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=495248)     return fn(input, L)
(EngineCore_DP0 pid=495248)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=495248)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=495248)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=495248)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=495248)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=495248)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=495248)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=495248)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=495248)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=495248)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=495248)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=495248)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=495248)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=495248)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=495248)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=495248)     raise PTXASError(error)
(EngineCore_DP0 pid=495248) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=495248) `ptxas` stderr:
(EngineCore_DP0 pid=495248) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=495248) 
(EngineCore_DP0 pid=495248) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpvmvykpn2.ptx -o /tmp/tmpvmvykpn2.ptx.o
(EngineCore_DP0 pid=495248) 
[rank0]:[W125 21:47:15.029359727 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=512

========== M=1024 ==========
Time: 2026-01-25 21:47:17
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Qwen2.5-7B-FP8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:47:21 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 21:47:21 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=496534) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=496534) 
(EngineCore_DP0 pid=496534) 
(EngineCore_DP0 pid=496534) ================================================================
(EngineCore_DP0 pid=496534) Internal Triton PTX codegen error
(EngineCore_DP0 pid=496534) `ptxas` stderr:
(EngineCore_DP0 pid=496534) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=496534) 
(EngineCore_DP0 pid=496534) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpi9frvrnw.ptx -o /tmp/tmpi9frvrnw.ptx.o
(EngineCore_DP0 pid=496534) 
(EngineCore_DP0 pid=496534) 
(EngineCore_DP0 pid=496534) //
(EngineCore_DP0 pid=496534) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=496534) //
(EngineCore_DP0 pid=496534) 
(EngineCore_DP0 pid=496534) .version 8.7
(EngineCore_DP0 pid=496534) .target sm_121a
(EngineCore_DP0 pid=496534) .address_size 64
(EngineCore_DP0 pid=496534) 
(EngineCore_DP0 pid=496534) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=496534) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=496534)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=496534) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=496534) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=496534) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=496534) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=496534) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=496534) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=496534) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=496534) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=496534) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=496534) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=496534) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=496534) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=496534) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=496534) )
(EngineCore_DP0 pid=496534) .reqntid 512
(EngineCore_DP0 pid=496534) {
(EngineCore_DP0 pid=496534) 	.reg .pred 	%p<28>;
(EngineCore_DP0 pid=496534) 	.reg .b16 	%rs<49>;
(EngineCore_DP0 pid=496534) 	.reg .b32 	%r<151>;
(EngineCore_DP0 pid=496534) 	.reg .b64 	%rd<17>;
(EngineCore_DP0 pid=496534) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=496534) $L__func_begin0:
(EngineCore_DP0 pid=496534) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=496534) 
(EngineCore_DP0 pid=496534) // %bb.0:
(EngineCore_DP0 pid=496534) 	ld.param.b32 	%r25, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=496534) 	ld.param.b32 	%r24, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=496534) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=496534) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=496534) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=496534) $L__tmp0:
(EngineCore_DP0 pid=496534) 	.loc	1 143 24                        // quant_slide_tuned_Qwen2.5-7B.py:143:24
(EngineCore_DP0 pid=496534) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=496534) 	ld.param.b32 	%r27, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=496534) 	.loc	1 148 26                        // quant_slide_tuned_Qwen2.5-7B.py:148:26
(EngineCore_DP0 pid=496534) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=496534) 	.loc	1 148 20                        // quant_slide_tuned_Qwen2.5-7B.py:148:20
(EngineCore_DP0 pid=496534) 	mad.wide.s32 	%rd1, %r28, 2, %rd4;
(EngineCore_DP0 pid=496534) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=496534) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=496534) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=496534) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=496534) 	setp.lt.s32 	%p1, %r24, 1;
(EngineCore_DP0 pid=496534) 	mov.b32 	%r149, 0f2B8CBCCC;
(EngineCore_DP0 pid=496534) 	setp.eq.b32 	%p27, %r2, 0;
(EngineCore_DP0 pid=496534) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=496534) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=496534) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=496534) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=496534) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=496534) 	shr.u32 	%r37, %r2, 3;
(EngineCore_DP0 pid=496534) 	and.b32 	%r38, %r37, 60;
(EngineCore_DP0 pid=496534) 	mov.b32 	%r39, global_smem;
(EngineCore_DP0 pid=496534) 	add.s32 	%r49, %r39, %r38;
(EngineCore_DP0 pid=496534) 	shl.b32 	%r40, %r2, 2;
(EngineCore_DP0 pid=496534) 	add.s32 	%r52, %r39, %r40;
(EngineCore_DP0 pid=496534) 	mov.b32 	%r45, 0;
(EngineCore_DP0 pid=496534) 	mov.b32 	%r147, 0f00000000;
(EngineCore_DP0 pid=496534) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=496534) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=496534) 	mov.b32 	%r148, %r45;
(EngineCore_DP0 pid=496534) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=496534) 	.loc	1 155 22                        // quant_slide_tuned_Qwen2.5-7B.py:155:22
(EngineCore_DP0 pid=496534) 	add.s32 	%r55, %r4, %r148;
(EngineCore_DP0 pid=496534) 	setp.lt.s32 	%p2, %r55, %r23;
(EngineCore_DP0 pid=496534) 	.loc	1 156 29                        // quant_slide_tuned_Qwen2.5-7B.py:156:29
(EngineCore_DP0 pid=496534) 	mad.wide.s32 	%rd6, %r55, 2, %rd1;
(EngineCore_DP0 pid=496534) 	.loc	1 156 21                        // quant_slide_tuned_Qwen2.5-7B.py:156:21
(EngineCore_DP0 pid=496534) 	// begin inline asm
(EngineCore_DP0 pid=496534) 	mov.u32 %r41, %r45;
(EngineCore_DP0 pid=496534) 	mov.u32 %r42, %r45;
(EngineCore_DP0 pid=496534) 	mov.u32 %r43, %r45;
(EngineCore_DP0 pid=496534) 	mov.u32 %r44, %r45;
(EngineCore_DP0 pid=496534) 	@%p2 ld.global.v4.b32 { %r41, %r42, %r43, %r44 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=496534) 	// end inline asm
(EngineCore_DP0 pid=496534) 	mov.b32 	{%rs1, %rs2}, %r41;
(EngineCore_DP0 pid=496534) 	mov.b32 	{%rs3, %rs4}, %r42;
(EngineCore_DP0 pid=496534) 	mov.b32 	{%rs5, %rs6}, %r43;
(EngineCore_DP0 pid=496534) 	mov.b32 	{%rs7, %rs8}, %r44;
(EngineCore_DP0 pid=496534) 	.loc	1 157 50                        // quant_slide_tuned_Qwen2.5-7B.py:157:50
(EngineCore_DP0 pid=496534) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=496534) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=496534) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=496534) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=496534) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=496534) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=496534) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=496534) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=496534) $L__tmp1:
(EngineCore_DP0 pid=496534) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=496534) 	bar.sync 	0;
(EngineCore_DP0 pid=496534) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=496534) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=496534) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=496534) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=496534) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=496534) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=496534) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=496534) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=496534) 	cvt.f32.bf16 	%r56, %rs23;
(EngineCore_DP0 pid=496534) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=496534) 	shfl.sync.bfly.b32 	%r57, %r56, 16, 31, -1;
(EngineCore_DP0 pid=496534) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=496534) 	max.f32 	%r58, %r56, %r57;
(EngineCore_DP0 pid=496534) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=496534) 	shfl.sync.bfly.b32 	%r59, %r58, 8, 31, -1;
(EngineCore_DP0 pid=496534) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=496534) 	max.f32 	%r60, %r58, %r59;
(EngineCore_DP0 pid=496534) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=496534) 	shfl.sync.bfly.b32 	%r61, %r60, 4, 31, -1;
(EngineCore_DP0 pid=496534) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=496534) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=496534) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=496534) 	shfl.sync.bfly.b32 	%r63, %r62, 2, 31, -1;
(EngineCore_DP0 pid=496534) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=496534) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=496534) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=496534) 	shfl.sync.bfly.b32 	%r65, %r64, 1, 31, -1;
(EngineCore_DP0 pid=496534) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=496534) 	max.f32 	%r50, %r64, %r65;
(EngineCore_DP0 pid=496534) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=496534) 	// begin inline asm
(EngineCore_DP0 pid=496534) 	@%p3 st.shared.b32 [ %r49 + 0 ], %r50;
(EngineCore_DP0 pid=496534) 	// end inline asm
(EngineCore_DP0 pid=496534) 	bar.sync 	0;
(EngineCore_DP0 pid=496534) 	// begin inline asm
(EngineCore_DP0 pid=496534) 	@%p4 ld.shared.b32 %r51, [ %r52 + 0 ];
(EngineCore_DP0 pid=496534) 	// end inline asm
(EngineCore_DP0 pid=496534) 	shfl.sync.bfly.b32 	%r66, %r51, 8, 31, -1;
(EngineCore_DP0 pid=496534) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=496534) 	max.f32 	%r67, %r51, %r66;
(EngineCore_DP0 pid=496534) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=496534) 	shfl.sync.bfly.b32 	%r68, %r67, 4, 31, -1;
(EngineCore_DP0 pid=496534) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=496534) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=496534) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=496534) 	shfl.sync.bfly.b32 	%r70, %r69, 2, 31, -1;
(EngineCore_DP0 pid=496534) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=496534) 	max.f32 	%r71, %r69, %r70;
(EngineCore_DP0 pid=496534) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=496534) 	shfl.sync.bfly.b32 	%r72, %r71, 1, 31, -1;
(EngineCore_DP0 pid=496534) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=496534) 	max.f32 	%r54, %r71, %r72;
(EngineCore_DP0 pid=496534) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=496534) 	// begin inline asm
(EngineCore_DP0 pid=496534) 	@%p27 st.shared.b32 [ %r52 + 0 ], %r54;
(EngineCore_DP0 pid=496534) 	// end inline asm
(EngineCore_DP0 pid=496534) 	bar.sync 	0;
(EngineCore_DP0 pid=496534) 	ld.shared.b32 	%r73, [global_smem];
(EngineCore_DP0 pid=496534) $L__tmp2:
(EngineCore_DP0 pid=496534) 	.loc	1 157 36                        // quant_slide_tuned_Qwen2.5-7B.py:157:36
(EngineCore_DP0 pid=496534) 	max.f32 	%r147, %r147, %r73;
(EngineCore_DP0 pid=496534) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=496534) 	add.s32 	%r148, %r148, 4096;
(EngineCore_DP0 pid=496534) 	setp.lt.s32 	%p6, %r148, %r24;
(EngineCore_DP0 pid=496534) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=496534) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=496534) 	.loc	1 159 32                        // quant_slide_tuned_Qwen2.5-7B.py:159:32
(EngineCore_DP0 pid=496534) 	max.f32 	%r149, %r147, 0f2B8CBCCC;
(EngineCore_DP0 pid=496534) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=496534) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-7B.py:0:32
(EngineCore_DP0 pid=496534) 	mov.b32 	%r75, 0f43E00000;
(EngineCore_DP0 pid=496534) 	.loc	1 160 32                        // quant_slide_tuned_Qwen2.5-7B.py:160:32
(EngineCore_DP0 pid=496534) 	div.full.f32 	%r76, %r149, %r75;
(EngineCore_DP0 pid=496534) 	.loc	1 160 41                        // quant_slide_tuned_Qwen2.5-7B.py:160:41
(EngineCore_DP0 pid=496534) 	max.f32 	%r74, %r76, 0f36924925;
(EngineCore_DP0 pid=496534) 	.loc	1 162 25                        // quant_slide_tuned_Qwen2.5-7B.py:162:25
(EngineCore_DP0 pid=496534) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=496534) 	.loc	1 162 30                        // quant_slide_tuned_Qwen2.5-7B.py:162:30
(EngineCore_DP0 pid=496534) 	// begin inline asm
(EngineCore_DP0 pid=496534) 	@%p27 st.global.b32 [ %rd7 + 0 ], { %r74 };
(EngineCore_DP0 pid=496534) 	// end inline asm
(EngineCore_DP0 pid=496534) 	.loc	1 165 29                        // quant_slide_tuned_Qwen2.5-7B.py:165:29
(EngineCore_DP0 pid=496534) 	shl.b32 	%r15, %r25, 2;
(EngineCore_DP0 pid=496534) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=496534) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=496534) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=496534) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=496534) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-7B.py:0:41
(EngineCore_DP0 pid=496534) 	ld.param.b32 	%r29, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=496534) 	shr.s32 	%r30, %r29, 31;
(EngineCore_DP0 pid=496534) 	shr.u32 	%r31, %r30, 30;
(EngineCore_DP0 pid=496534) 	add.s32 	%r32, %r29, %r31;
(EngineCore_DP0 pid=496534) 	shr.s32 	%r33, %r32, 2;
(EngineCore_DP0 pid=496534) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=496534) 	mul.lo.s32 	%r34, %r33, %r1;
(EngineCore_DP0 pid=496534) 	mad.wide.s32 	%rd2, %r34, 4, %rd5;
(EngineCore_DP0 pid=496534) 	div.full.f32 	%r14, %r75, %r149;
(EngineCore_DP0 pid=496534) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=496534) 	mov.b32 	%r150, 0;
(EngineCore_DP0 pid=496534) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=496534)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=496534) 	.loc	1 168 31                        // quant_slide_tuned_Qwen2.5-7B.py:168:31
(EngineCore_DP0 pid=496534) 	add.s32 	%r88, %r16, %r150;
(EngineCore_DP0 pid=496534) 	.loc	1 169 30                        // quant_slide_tuned_Qwen2.5-7B.py:169:30
(EngineCore_DP0 pid=496534) 	add.s32 	%r89, %r88, 1;
(EngineCore_DP0 pid=496534) 	setp.lt.s32 	%p17, %r88, %r15;
(EngineCore_DP0 pid=496534) 	.loc	1 172 24                        // quant_slide_tuned_Qwen2.5-7B.py:172:24
(EngineCore_DP0 pid=496534) 	shr.s32 	%r90, %r88, 31;
(EngineCore_DP0 pid=496534) 	shr.u32 	%r91, %r90, 30;
(EngineCore_DP0 pid=496534) 	add.s32 	%r92, %r88, %r91;
(EngineCore_DP0 pid=496534) 	shr.s32 	%r93, %r92, 2;
(EngineCore_DP0 pid=496534) 	.loc	1 173 23                        // quant_slide_tuned_Qwen2.5-7B.py:173:23
(EngineCore_DP0 pid=496534) 	shr.s32 	%r94, %r89, 31;
(EngineCore_DP0 pid=496534) 	shr.u32 	%r95, %r94, 30;
(EngineCore_DP0 pid=496534) 	add.s32 	%r96, %r89, %r95;
(EngineCore_DP0 pid=496534) 	and.b32 	%r97, %r96, 2147483644;
(EngineCore_DP0 pid=496534) 	sub.s32 	%r98, %r89, %r97;
(EngineCore_DP0 pid=496534) 	and.b32 	%r99, %r92, 2147483644;
(EngineCore_DP0 pid=496534) 	sub.s32 	%r100, %r88, %r99;
(EngineCore_DP0 pid=496534) 	.loc	1 174 22                        // quant_slide_tuned_Qwen2.5-7B.py:174:22
(EngineCore_DP0 pid=496534) 	mul.lo.s32 	%r101, %r93, 10;
(EngineCore_DP0 pid=496534) 	.loc	1 174 30                        // quant_slide_tuned_Qwen2.5-7B.py:174:30
(EngineCore_DP0 pid=496534) 	shl.b32 	%r102, %r100, 1;
(EngineCore_DP0 pid=496534) 	shl.b32 	%r103, %r98, 1;
(EngineCore_DP0 pid=496534) 	.loc	1 174 26                        // quant_slide_tuned_Qwen2.5-7B.py:174:26
(EngineCore_DP0 pid=496534) 	add.s32 	%r104, %r101, %r103;
(EngineCore_DP0 pid=496534) 	add.s32 	%r105, %r101, %r102;
(EngineCore_DP0 pid=496534) 	.loc	1 177 53                        // quant_slide_tuned_Qwen2.5-7B.py:177:53
(EngineCore_DP0 pid=496534) 	setp.lt.s32 	%p18, %r105, %r23;
(EngineCore_DP0 pid=496534) 	setp.lt.s32 	%p19, %r104, %r23;
(EngineCore_DP0 pid=496534) 	.loc	1 177 37                        // quant_slide_tuned_Qwen2.5-7B.py:177:37
(EngineCore_DP0 pid=496534) 	and.pred 	%p9, %p17, %p18;
(EngineCore_DP0 pid=496534) 	and.pred 	%p10, %p17, %p19;
(EngineCore_DP0 pid=496534) 	.loc	1 176 29                        // quant_slide_tuned_Qwen2.5-7B.py:176:29
(EngineCore_DP0 pid=496534) 	mad.wide.s32 	%rd8, %r105, 2, %rd1;
(EngineCore_DP0 pid=496534) 	mad.wide.s32 	%rd9, %r104, 2, %rd1;
(EngineCore_DP0 pid=496534) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=496534) 	.loc	1 176 21                        // quant_slide_tuned_Qwen2.5-7B.py:176:21
(EngineCore_DP0 pid=496534) 	// begin inline asm
(EngineCore_DP0 pid=496534) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=496534) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=496534) 	// end inline asm
(EngineCore_DP0 pid=496534) 	// begin inline asm
(EngineCore_DP0 pid=496534) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=496534) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=496534) 	// end inline asm
(EngineCore_DP0 pid=496534) 	.loc	1 177 79                        // quant_slide_tuned_Qwen2.5-7B.py:177:79
(EngineCore_DP0 pid=496534) 	cvt.f32.bf16 	%r106, %rs24;
(EngineCore_DP0 pid=496534) 	cvt.f32.bf16 	%r107, %rs26;
(EngineCore_DP0 pid=496534) 	.loc	1 179 48                        // quant_slide_tuned_Qwen2.5-7B.py:179:48
(EngineCore_DP0 pid=496534) 	or.b32 	%r108, %r105, 1;
(EngineCore_DP0 pid=496534) 	or.b32 	%r109, %r104, 1;
(EngineCore_DP0 pid=496534) 	.loc	1 179 53                        // quant_slide_tuned_Qwen2.5-7B.py:179:53
(EngineCore_DP0 pid=496534) 	setp.lt.s32 	%p20, %r108, %r23;
(EngineCore_DP0 pid=496534) 	setp.lt.s32 	%p21, %r109, %r23;
(EngineCore_DP0 pid=496534) 	.loc	1 179 37                        // quant_slide_tuned_Qwen2.5-7B.py:179:37
(EngineCore_DP0 pid=496534) 	and.pred 	%p11, %p17, %p20;
(EngineCore_DP0 pid=496534) 	and.pred 	%p12, %p17, %p21;
(EngineCore_DP0 pid=496534) 	.loc	1 178 39                        // quant_slide_tuned_Qwen2.5-7B.py:178:39
(EngineCore_DP0 pid=496534) 	add.s64 	%rd10, %rd8, 2;
(EngineCore_DP0 pid=496534) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=496534) 	.loc	1 178 21                        // quant_slide_tuned_Qwen2.5-7B.py:178:21
(EngineCore_DP0 pid=496534) 	// begin inline asm
(EngineCore_DP0 pid=496534) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=496534) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=496534) 	// end inline asm
(EngineCore_DP0 pid=496534) 	// begin inline asm
(EngineCore_DP0 pid=496534) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=496534) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=496534) 	// end inline asm
(EngineCore_DP0 pid=496534) 	.loc	1 179 79                        // quant_slide_tuned_Qwen2.5-7B.py:179:79
(EngineCore_DP0 pid=496534) 	cvt.f32.bf16 	%r110, %rs28;
(EngineCore_DP0 pid=496534) 	cvt.f32.bf16 	%r111, %rs30;
(EngineCore_DP0 pid=496534) 	.loc	1 183 48                        // quant_slide_tuned_Qwen2.5-7B.py:183:48
(EngineCore_DP0 pid=496534) 	add.s32 	%r112, %r105, 2;
(EngineCore_DP0 pid=496534) 	add.s32 	%r113, %r104, 2;
(EngineCore_DP0 pid=496534) 	add.s32 	%r114, %r105, 3;
(EngineCore_DP0 pid=496534) 	add.s32 	%r115, %r104, 3;
(EngineCore_DP0 pid=496534) 	.loc	1 183 53                        // quant_slide_tuned_Qwen2.5-7B.py:183:53
(EngineCore_DP0 pid=496534) 	setp.lt.s32 	%p22, %r115, %r23;
(EngineCore_DP0 pid=496534) 	setp.lt.s32 	%p23, %r114, %r23;
(EngineCore_DP0 pid=496534) 	setp.lt.s32 	%p24, %r113, %r23;
(EngineCore_DP0 pid=496534) 	setp.lt.s32 	%p25, %r112, %r23;
(EngineCore_DP0 pid=496534) 	.loc	1 181 37                        // quant_slide_tuned_Qwen2.5-7B.py:181:37
(EngineCore_DP0 pid=496534) 	and.pred 	%p13, %p17, %p25;
(EngineCore_DP0 pid=496534) 	and.pred 	%p14, %p17, %p24;
(EngineCore_DP0 pid=496534) 	.loc	1 180 39                        // quant_slide_tuned_Qwen2.5-7B.py:180:39
(EngineCore_DP0 pid=496534) 	add.s64 	%rd12, %rd8, 4;
(EngineCore_DP0 pid=496534) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=496534) 	.loc	1 180 21                        // quant_slide_tuned_Qwen2.5-7B.py:180:21
(EngineCore_DP0 pid=496534) 	// begin inline asm
(EngineCore_DP0 pid=496534) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=496534) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=496534) 	// end inline asm
(EngineCore_DP0 pid=496534) 	// begin inline asm
(EngineCore_DP0 pid=496534) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=496534) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=496534) 	// end inline asm
(EngineCore_DP0 pid=496534) 	.loc	1 181 79                        // quant_slide_tuned_Qwen2.5-7B.py:181:79
(EngineCore_DP0 pid=496534) 	cvt.f32.bf16 	%r116, %rs32;
(EngineCore_DP0 pid=496534) 	cvt.f32.bf16 	%r117, %rs34;
(EngineCore_DP0 pid=496534) 	.loc	1 183 37                        // quant_slide_tuned_Qwen2.5-7B.py:183:37
(EngineCore_DP0 pid=496534) 	and.pred 	%p15, %p17, %p23;
(EngineCore_DP0 pid=496534) 	and.pred 	%p16, %p17, %p22;
(EngineCore_DP0 pid=496534) 	.loc	1 182 39                        // quant_slide_tuned_Qwen2.5-7B.py:182:39
(EngineCore_DP0 pid=496534) 	add.s64 	%rd14, %rd8, 6;
(EngineCore_DP0 pid=496534) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=496534) 	.loc	1 182 21                        // quant_slide_tuned_Qwen2.5-7B.py:182:21
(EngineCore_DP0 pid=496534) 	// begin inline asm
(EngineCore_DP0 pid=496534) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=496534) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=496534) 	// end inline asm
(EngineCore_DP0 pid=496534) 	// begin inline asm
(EngineCore_DP0 pid=496534) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=496534) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=496534) 	// end inline asm
(EngineCore_DP0 pid=496534) 	.loc	1 183 79                        // quant_slide_tuned_Qwen2.5-7B.py:183:79
(EngineCore_DP0 pid=496534) 	cvt.f32.bf16 	%r118, %rs36;
(EngineCore_DP0 pid=496534) 	cvt.f32.bf16 	%r119, %rs38;
(EngineCore_DP0 pid=496534) 	.loc	1 185 27                        // quant_slide_tuned_Qwen2.5-7B.py:185:27
(EngineCore_DP0 pid=496534) 	mul.f32 	%r120, %r14, %r106;
(EngineCore_DP0 pid=496534) 	mul.f32 	%r121, %r14, %r107;
(EngineCore_DP0 pid=496534) 	mov.b32 	%r122, 0f43E00000;
(EngineCore_DP0 pid=496534) 	.loc	1 185 48                        // quant_slide_tuned_Qwen2.5-7B.py:185:48
(EngineCore_DP0 pid=496534) 	min.xorsign.abs.f32 	%r78, %r120, %r122;
(EngineCore_DP0 pid=496534) 	min.xorsign.abs.f32 	%r79, %r121, %r122;
(EngineCore_DP0 pid=496534) 	.loc	1 185 60                        // quant_slide_tuned_Qwen2.5-7B.py:185:60
(EngineCore_DP0 pid=496534) 	// begin inline asm
(EngineCore_DP0 pid=496534) 	cvt.rn.satfinite.e4m3x2.f32  %rs40, %r79, %r78; 
(EngineCore_DP0 pid=496534) 
(EngineCore_DP0 pid=496534) 	// end inline asm
(EngineCore_DP0 pid=496534) 	shr.u16 	%rs44, %rs40, 8;
(EngineCore_DP0 pid=496534) 	.loc	1 186 27                        // quant_slide_tuned_Qwen2.5-7B.py:186:27
(EngineCore_DP0 pid=496534) 	mul.f32 	%r123, %r14, %r110;
(EngineCore_DP0 pid=496534) 	mul.f32 	%r124, %r14, %r111;
(EngineCore_DP0 pid=496534) 	.loc	1 186 48                        // quant_slide_tuned_Qwen2.5-7B.py:186:48
(EngineCore_DP0 pid=496534) 	min.xorsign.abs.f32 	%r80, %r123, %r122;
(EngineCore_DP0 pid=496534) 	min.xorsign.abs.f32 	%r81, %r124, %r122;
(EngineCore_DP0 pid=496534) 	.loc	1 186 60                        // quant_slide_tuned_Qwen2.5-7B.py:186:60
(EngineCore_DP0 pid=496534) 	// begin inline asm
(EngineCore_DP0 pid=496534) 	cvt.rn.satfinite.e4m3x2.f32  %rs41, %r81, %r80; 
(EngineCore_DP0 pid=496534) 
(EngineCore_DP0 pid=496534) 	// end inline asm
(EngineCore_DP0 pid=496534) 	shr.u16 	%rs45, %rs41, 8;
(EngineCore_DP0 pid=496534) 	.loc	1 187 27                        // quant_slide_tuned_Qwen2.5-7B.py:187:27
(EngineCore_DP0 pid=496534) 	mul.f32 	%r125, %r14, %r116;
(EngineCore_DP0 pid=496534) 	mul.f32 	%r126, %r14, %r117;
(EngineCore_DP0 pid=496534) 	.loc	1 187 48                        // quant_slide_tuned_Qwen2.5-7B.py:187:48
(EngineCore_DP0 pid=496534) 	min.xorsign.abs.f32 	%r82, %r125, %r122;
(EngineCore_DP0 pid=496534) 	min.xorsign.abs.f32 	%r83, %r126, %r122;
(EngineCore_DP0 pid=496534) 	.loc	1 187 60                        // quant_slide_tuned_Qwen2.5-7B.py:187:60
(EngineCore_DP0 pid=496534) 	// begin inline asm
(EngineCore_DP0 pid=496534) 	cvt.rn.satfinite.e4m3x2.f32  %rs42, %r83, %r82; 
(EngineCore_DP0 pid=496534) 
(EngineCore_DP0 pid=496534) 	// end inline asm
(EngineCore_DP0 pid=496534) 	shr.u16 	%rs46, %rs42, 8;
(EngineCore_DP0 pid=496534) 	.loc	1 188 27                        // quant_slide_tuned_Qwen2.5-7B.py:188:27
(EngineCore_DP0 pid=496534) 	mul.f32 	%r127, %r14, %r118;
(EngineCore_DP0 pid=496534) 	mul.f32 	%r128, %r14, %r119;
(EngineCore_DP0 pid=496534) 	.loc	1 188 48                        // quant_slide_tuned_Qwen2.5-7B.py:188:48
(EngineCore_DP0 pid=496534) 	min.xorsign.abs.f32 	%r84, %r127, %r122;
(EngineCore_DP0 pid=496534) 	min.xorsign.abs.f32 	%r85, %r128, %r122;
(EngineCore_DP0 pid=496534) 	.loc	1 188 60                        // quant_slide_tuned_Qwen2.5-7B.py:188:60
(EngineCore_DP0 pid=496534) 	// begin inline asm
(EngineCore_DP0 pid=496534) 	cvt.rn.satfinite.e4m3x2.f32  %rs43, %r85, %r84; 
(EngineCore_DP0 pid=496534) 
(EngineCore_DP0 pid=496534) 	// end inline asm
(EngineCore_DP0 pid=496534) 	shr.u16 	%rs47, %rs43, 8;
(EngineCore_DP0 pid=496534) 	.loc	1 190 45                        // quant_slide_tuned_Qwen2.5-7B.py:190:45
(EngineCore_DP0 pid=496534) 	cvt.u32.u16 	%r129, %rs40;
(EngineCore_DP0 pid=496534) 	and.b32 	%r130, %r129, 255;
(EngineCore_DP0 pid=496534) 	cvt.u32.u16 	%r131, %rs44;
(EngineCore_DP0 pid=496534) 	.loc	1 192 45                        // quant_slide_tuned_Qwen2.5-7B.py:192:45
(EngineCore_DP0 pid=496534) 	cvt.u32.u16 	%r132, %rs42;
(EngineCore_DP0 pid=496534) 	and.b32 	%r133, %r132, 255;
(EngineCore_DP0 pid=496534) 	cvt.u32.u16 	%r134, %rs46;
(EngineCore_DP0 pid=496534) 	.loc	1 193 45                        // quant_slide_tuned_Qwen2.5-7B.py:193:45
(EngineCore_DP0 pid=496534) 	cvt.u32.u16 	%r135, %rs43;
(EngineCore_DP0 pid=496534) 	cvt.u32.u16 	%r136, %rs47;
(EngineCore_DP0 pid=496534) 	.loc	1 195 30                        // quant_slide_tuned_Qwen2.5-7B.py:195:30
(EngineCore_DP0 pid=496534) 	and.b16 	%rs48, %rs41, 255;
(EngineCore_DP0 pid=496534) 	mul.wide.u16 	%r137, %rs48, 256;
(EngineCore_DP0 pid=496534) 	mul.wide.u16 	%r138, %rs45, 256;
(EngineCore_DP0 pid=496534) 	.loc	1 195 24                        // quant_slide_tuned_Qwen2.5-7B.py:195:24
(EngineCore_DP0 pid=496534) 	or.b32 	%r139, %r137, %r130;
(EngineCore_DP0 pid=496534) 	or.b32 	%r140, %r138, %r131;
(EngineCore_DP0 pid=496534) 	.loc	1 195 42                        // quant_slide_tuned_Qwen2.5-7B.py:195:42
(EngineCore_DP0 pid=496534) 	shl.b32 	%r141, %r133, 16;
(EngineCore_DP0 pid=496534) 	shl.b32 	%r142, %r134, 16;
(EngineCore_DP0 pid=496534) 	.loc	1 195 36                        // quant_slide_tuned_Qwen2.5-7B.py:195:36
(EngineCore_DP0 pid=496534) 	or.b32 	%r143, %r139, %r141;
(EngineCore_DP0 pid=496534) 	or.b32 	%r144, %r140, %r142;
(EngineCore_DP0 pid=496534) 	.loc	1 195 55                        // quant_slide_tuned_Qwen2.5-7B.py:195:55
(EngineCore_DP0 pid=496534) 	shl.b32 	%r145, %r135, 24;
(EngineCore_DP0 pid=496534) 	shl.b32 	%r146, %r136, 24;
(EngineCore_DP0 pid=496534) 	.loc	1 195 49                        // quant_slide_tuned_Qwen2.5-7B.py:195:49
(EngineCore_DP0 pid=496534) 	or.b32 	%r86, %r143, %r145;
(EngineCore_DP0 pid=496534) 	or.b32 	%r87, %r144, %r146;
(EngineCore_DP0 pid=496534) 	.loc	1 196 29                        // quant_slide_tuned_Qwen2.5-7B.py:196:29
(EngineCore_DP0 pid=496534) 	mad.wide.s32 	%rd16, %r88, 4, %rd2;
(EngineCore_DP0 pid=496534) 	.loc	1 196 39                        // quant_slide_tuned_Qwen2.5-7B.py:196:39
(EngineCore_DP0 pid=496534) 	// begin inline asm
(EngineCore_DP0 pid=496534) 	@%p17 st.global.v2.b32 [ %rd16 + 0 ], { %r86, %r87 };
(EngineCore_DP0 pid=496534) 	// end inline asm
(EngineCore_DP0 pid=496534) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=496534) 	add.s32 	%r150, %r150, 1024;
(EngineCore_DP0 pid=496534) 	setp.lt.s32 	%p26, %r150, %r15;
(EngineCore_DP0 pid=496534) 	@%p26 bra 	$L__BB0_6;
(EngineCore_DP0 pid=496534) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=496534) 	.loc	1 167 4                         // quant_slide_tuned_Qwen2.5-7B.py:167:4
(EngineCore_DP0 pid=496534) 	ret;
(EngineCore_DP0 pid=496534) $L__tmp3:
(EngineCore_DP0 pid=496534) $L__func_end0:
(EngineCore_DP0 pid=496534)                                         // -- End function
(EngineCore_DP0 pid=496534) }
(EngineCore_DP0 pid=496534) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py"
(EngineCore_DP0 pid=496534) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=496534) 	.section	.debug_abbrev
(EngineCore_DP0 pid=496534) 	{
(EngineCore_DP0 pid=496534) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=496534) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=496534) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=496534) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=496534) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=496534) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=496534) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=496534) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=496534) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=496534) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=496534) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=496534) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=496534) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=496534) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=496534) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=496534) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=496534) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=496534) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=496534) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=496534) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=496534) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=496534) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=496534) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=496534) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=496534) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=496534) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=496534) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=496534) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=496534) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=496534) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=496534) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=496534) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=496534) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=496534) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=496534) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=496534) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=496534) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=496534) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=496534) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=496534) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=496534) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=496534) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=496534) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=496534) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=496534) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=496534) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=496534) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=496534) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=496534) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=496534) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=496534) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=496534) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=496534) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=496534) 	}
(EngineCore_DP0 pid=496534) 	.section	.debug_info
(EngineCore_DP0 pid=496534) 	{
(EngineCore_DP0 pid=496534) .b32 221                                // Length of Unit
(EngineCore_DP0 pid=496534) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=496534) .b8 0
(EngineCore_DP0 pid=496534) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=496534) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=496534) .b8 1                                   // Abbrev [1] 0xb:0xd6 DW_TAG_compile_unit
(EngineCore_DP0 pid=496534) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=496534) .b8 114
(EngineCore_DP0 pid=496534) .b8 105
(EngineCore_DP0 pid=496534) .b8 116
(EngineCore_DP0 pid=496534) .b8 111
(EngineCore_DP0 pid=496534) .b8 110
(EngineCore_DP0 pid=496534) .b8 0
(EngineCore_DP0 pid=496534) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=496534) .b8 0
(EngineCore_DP0 pid=496534) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=496534) .b8 117
(EngineCore_DP0 pid=496534) .b8 97
(EngineCore_DP0 pid=496534) .b8 110
(EngineCore_DP0 pid=496534) .b8 116
(EngineCore_DP0 pid=496534) .b8 95
(EngineCore_DP0 pid=496534) .b8 115
(EngineCore_DP0 pid=496534) .b8 108
(EngineCore_DP0 pid=496534) .b8 105
(EngineCore_DP0 pid=496534) .b8 100
(EngineCore_DP0 pid=496534) .b8 101
(EngineCore_DP0 pid=496534) .b8 95
(EngineCore_DP0 pid=496534) .b8 116
(EngineCore_DP0 pid=496534) .b8 117
(EngineCore_DP0 pid=496534) .b8 110
(EngineCore_DP0 pid=496534) .b8 101
(EngineCore_DP0 pid=496534) .b8 100
(EngineCore_DP0 pid=496534) .b8 95
(EngineCore_DP0 pid=496534) .b8 81
(EngineCore_DP0 pid=496534) .b8 119
(EngineCore_DP0 pid=496534) .b8 101
(EngineCore_DP0 pid=496534) .b8 110
(EngineCore_DP0 pid=496534) .b8 50
(EngineCore_DP0 pid=496534) .b8 46
(EngineCore_DP0 pid=496534) .b8 53
(EngineCore_DP0 pid=496534) .b8 45
(EngineCore_DP0 pid=496534) .b8 55
(EngineCore_DP0 pid=496534) .b8 66
(EngineCore_DP0 pid=496534) .b8 46
(EngineCore_DP0 pid=496534) .b8 112
(EngineCore_DP0 pid=496534) .b8 121
(EngineCore_DP0 pid=496534) .b8 0
(EngineCore_DP0 pid=496534) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=496534) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=496534) .b8 114
(EngineCore_DP0 pid=496534) .b8 111
(EngineCore_DP0 pid=496534) .b8 111
(EngineCore_DP0 pid=496534) .b8 116
(EngineCore_DP0 pid=496534) .b8 47
(EngineCore_DP0 pid=496534) .b8 118
(EngineCore_DP0 pid=496534) .b8 108
(EngineCore_DP0 pid=496534) .b8 108
(EngineCore_DP0 pid=496534) .b8 109
(EngineCore_DP0 pid=496534) .b8 98
(EngineCore_DP0 pid=496534) .b8 101
(EngineCore_DP0 pid=496534) .b8 110
(EngineCore_DP0 pid=496534) .b8 99
(EngineCore_DP0 pid=496534) .b8 104
(EngineCore_DP0 pid=496534) .b8 47
(EngineCore_DP0 pid=496534) .b8 115
(EngineCore_DP0 pid=496534) .b8 108
(EngineCore_DP0 pid=496534) .b8 105
(EngineCore_DP0 pid=496534) .b8 100
(EngineCore_DP0 pid=496534) .b8 101
(EngineCore_DP0 pid=496534) .b8 115
(EngineCore_DP0 pid=496534) .b8 112
(EngineCore_DP0 pid=496534) .b8 97
(EngineCore_DP0 pid=496534) .b8 114
(EngineCore_DP0 pid=496534) .b8 115
(EngineCore_DP0 pid=496534) .b8 101
(EngineCore_DP0 pid=496534) .b8 47
(EngineCore_DP0 pid=496534) .b8 99
(EngineCore_DP0 pid=496534) .b8 115
(EngineCore_DP0 pid=496534) .b8 114
(EngineCore_DP0 pid=496534) .b8 99
(EngineCore_DP0 pid=496534) .b8 47
(EngineCore_DP0 pid=496534) .b8 102
(EngineCore_DP0 pid=496534) .b8 117
(EngineCore_DP0 pid=496534) .b8 115
(EngineCore_DP0 pid=496534) .b8 101
(EngineCore_DP0 pid=496534) .b8 100
(EngineCore_DP0 pid=496534) .b8 95
(EngineCore_DP0 pid=496534) .b8 113
(EngineCore_DP0 pid=496534) .b8 117
(EngineCore_DP0 pid=496534) .b8 97
(EngineCore_DP0 pid=496534) .b8 110
(EngineCore_DP0 pid=496534) .b8 116
(EngineCore_DP0 pid=496534) .b8 95
(EngineCore_DP0 pid=496534) .b8 115
(EngineCore_DP0 pid=496534) .b8 108
(EngineCore_DP0 pid=496534) .b8 105
(EngineCore_DP0 pid=496534) .b8 100
(EngineCore_DP0 pid=496534) .b8 101
(EngineCore_DP0 pid=496534) .b8 95
(EngineCore_DP0 pid=496534) .b8 116
(EngineCore_DP0 pid=496534) .b8 114
(EngineCore_DP0 pid=496534) .b8 105
(EngineCore_DP0 pid=496534) .b8 116
(EngineCore_DP0 pid=496534) .b8 111
(EngineCore_DP0 pid=496534) .b8 110
(EngineCore_DP0 pid=496534) .b8 47
(EngineCore_DP0 pid=496534) .b8 98
(EngineCore_DP0 pid=496534) .b8 117
(EngineCore_DP0 pid=496534) .b8 105
(EngineCore_DP0 pid=496534) .b8 108
(EngineCore_DP0 pid=496534) .b8 100
(EngineCore_DP0 pid=496534) .b8 47
(EngineCore_DP0 pid=496534) .b8 71
(EngineCore_DP0 pid=496534) .b8 66
(EngineCore_DP0 pid=496534) .b8 49
(EngineCore_DP0 pid=496534) .b8 48
(EngineCore_DP0 pid=496534) .b8 95
(EngineCore_DP0 pid=496534) .b8 99
(EngineCore_DP0 pid=496534) .b8 99
(EngineCore_DP0 pid=496534) .b8 49
(EngineCore_DP0 pid=496534) .b8 50
(EngineCore_DP0 pid=496534) .b8 49
(EngineCore_DP0 pid=496534) .b8 95
(EngineCore_DP0 pid=496534) .b8 112
(EngineCore_DP0 pid=496534) .b8 121
(EngineCore_DP0 pid=496534) .b8 51
(EngineCore_DP0 pid=496534) .b8 49
(EngineCore_DP0 pid=496534) .b8 50
(EngineCore_DP0 pid=496534) .b8 95
(EngineCore_DP0 pid=496534) .b8 99
(EngineCore_DP0 pid=496534) .b8 117
(EngineCore_DP0 pid=496534) .b8 49
(EngineCore_DP0 pid=496534) .b8 50
(EngineCore_DP0 pid=496534) .b8 57
(EngineCore_DP0 pid=496534) .b8 95
(EngineCore_DP0 pid=496534) .b8 97
(EngineCore_DP0 pid=496534) .b8 97
(EngineCore_DP0 pid=496534) .b8 114
(EngineCore_DP0 pid=496534) .b8 99
(EngineCore_DP0 pid=496534) .b8 104
(EngineCore_DP0 pid=496534) .b8 54
(EngineCore_DP0 pid=496534) .b8 52
(EngineCore_DP0 pid=496534) .b8 0
(EngineCore_DP0 pid=496534) .b8 2                                   // Abbrev [2] 0x98:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=496534) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=496534) .b8 113
(EngineCore_DP0 pid=496534) .b8 117
(EngineCore_DP0 pid=496534) .b8 97
(EngineCore_DP0 pid=496534) .b8 110
(EngineCore_DP0 pid=496534) .b8 116
(EngineCore_DP0 pid=496534) .b8 95
(EngineCore_DP0 pid=496534) .b8 115
(EngineCore_DP0 pid=496534) .b8 108
(EngineCore_DP0 pid=496534) .b8 105
(EngineCore_DP0 pid=496534) .b8 100
(EngineCore_DP0 pid=496534) .b8 101
(EngineCore_DP0 pid=496534) .b8 95
(EngineCore_DP0 pid=496534) .b8 102
(EngineCore_DP0 pid=496534) .b8 112
(EngineCore_DP0 pid=496534) .b8 56
(EngineCore_DP0 pid=496534) .b8 95
(EngineCore_DP0 pid=496534) .b8 107
(EngineCore_DP0 pid=496534) .b8 101
(EngineCore_DP0 pid=496534) .b8 114
(EngineCore_DP0 pid=496534) .b8 110
(EngineCore_DP0 pid=496534) .b8 101
(EngineCore_DP0 pid=496534) .b8 108
(EngineCore_DP0 pid=496534) .b8 0
(EngineCore_DP0 pid=496534) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=496534) .b8 3                                   // Abbrev [3] 0xb2:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=496534) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=496534) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=496534) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=496534) .b8 4                                   // Abbrev [4] 0xc7:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=496534) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=496534) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=496534) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=496534) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=496534) .b8 157                                 // DW_AT_call_line
(EngineCore_DP0 pid=496534) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=496534) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=496534) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=496534) 	}
(EngineCore_DP0 pid=496534) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=496534) 
(EngineCore_DP0 pid=496534) ================================================================
(EngineCore_DP0 pid=496534) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=496534) 
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpi9frvrnw.ptx', '-o', '/tmp/tmpi9frvrnw.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866] 
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866] 
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866] 
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpi9frvrnw.ptx -o /tmp/tmpi9frvrnw.ptx.o
(EngineCore_DP0 pid=496534) ERROR 01-25 21:48:32 [core.py:866] 

STDERR:
[2026-01-25 21:47:21] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:47:21] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:47:21] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:47:21] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:47:21] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:47:21] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:47:21] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:47:21] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:47:21] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:47:21] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:47:21] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:47:21] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:47:21] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:47:21] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:47:24] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:47:24] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:47:24] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:47:24] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:47:24] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:47:24] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:47:24] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:47:24] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:47:24] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:47:24] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:47:24] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:47:24] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:47:24] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:47:24] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=496534) [2026-01-25 21:47:25] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=496534) [2026-01-25 21:47:25] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=496534) [2026-01-25 21:47:25] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=496534) [2026-01-25 21:47:25] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=496534) [2026-01-25 21:47:25] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=496534) [2026-01-25 21:47:25] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=496534) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=496534) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:27<00:27, 27.69s/it]
(EngineCore_DP0 pid=496534) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:04<00:00, 32.90s/it]
(EngineCore_DP0 pid=496534) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:04<00:00, 32.12s/it]
(EngineCore_DP0 pid=496534) 
(EngineCore_DP0 pid=496534) [2026-01-25 21:48:31] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=496534) [2026-01-25 21:48:31] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16588800 bytes
(EngineCore_DP0 pid=496534) [2026-01-25 21:48:31] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=496534) [2026-01-25 21:48:31] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 12902400 bytes
(EngineCore_DP0 pid=496534) [2026-01-25 21:48:31] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=496534) [2026-01-25 21:48:31] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 136396800 bytes
(EngineCore_DP0 pid=496534) [2026-01-25 21:48:31] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=496534) [2026-01-25 21:48:31] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 67952640 bytes
(EngineCore_DP0 pid=496534) Process EngineCore_DP0:
(EngineCore_DP0 pid=496534) Traceback (most recent call last):
(EngineCore_DP0 pid=496534)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=496534)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=496534)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=496534)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=496534) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpi9frvrnw.ptx', '-o', '/tmp/tmpi9frvrnw.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=496534) 
(EngineCore_DP0 pid=496534) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=496534) 
(EngineCore_DP0 pid=496534) Traceback (most recent call last):
(EngineCore_DP0 pid=496534)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=496534)     self.run()
(EngineCore_DP0 pid=496534)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=496534)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=496534)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=496534)     raise e
(EngineCore_DP0 pid=496534)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=496534)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=496534)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=496534)     super().__init__(
(EngineCore_DP0 pid=496534)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=496534)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=496534)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=496534)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=496534)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=496534)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=496534)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=496534)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=496534)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=496534)     return func(*args, **kwargs)
(EngineCore_DP0 pid=496534)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=496534)     return func(*args, **kwargs)
(EngineCore_DP0 pid=496534)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=496534)     self.model_runner.profile_run()
(EngineCore_DP0 pid=496534)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=496534)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=496534)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=496534)     return func(*args, **kwargs)
(EngineCore_DP0 pid=496534)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=496534)     outputs = self.model(
(EngineCore_DP0 pid=496534)               ^^^^^^^^^^^
(EngineCore_DP0 pid=496534)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=496534)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=496534)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=496534)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=496534)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=496534)     hidden_states = self.model(
(EngineCore_DP0 pid=496534)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=496534)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=496534)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=496534)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=496534)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=496534)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=496534)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=496534)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=496534)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=496534)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=496534)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=496534)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=496534)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=496534)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=496534)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=496534)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=496534)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=496534)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=496534)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=496534)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=496534)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=496534)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=496534)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=496534)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=496534)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=496534)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=496534)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=496534)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=496534)     return self._linear_fn(
(EngineCore_DP0 pid=496534)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=496534)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=496534)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=496534)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=496534)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=496534)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=496534)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=496534)     return fn(input, L)
(EngineCore_DP0 pid=496534)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=496534)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=496534)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=496534)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=496534)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=496534)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=496534)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=496534)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=496534)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=496534)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=496534)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=496534)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=496534)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=496534)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=496534)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=496534)     raise PTXASError(error)
(EngineCore_DP0 pid=496534) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=496534) `ptxas` stderr:
(EngineCore_DP0 pid=496534) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=496534) 
(EngineCore_DP0 pid=496534) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpi9frvrnw.ptx -o /tmp/tmpi9frvrnw.ptx.o
(EngineCore_DP0 pid=496534) 
[rank0]:[W125 21:48:32.907025312 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=1024

========== M=2048 ==========
Time: 2026-01-25 21:48:34
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Qwen2.5-7B-FP8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:48:38 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 21:48:38 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=497790) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=497790) 
(EngineCore_DP0 pid=497790) 
(EngineCore_DP0 pid=497790) ================================================================
(EngineCore_DP0 pid=497790) Internal Triton PTX codegen error
(EngineCore_DP0 pid=497790) `ptxas` stderr:
(EngineCore_DP0 pid=497790) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=497790) 
(EngineCore_DP0 pid=497790) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpqzqh98x6.ptx -o /tmp/tmpqzqh98x6.ptx.o
(EngineCore_DP0 pid=497790) 
(EngineCore_DP0 pid=497790) 
(EngineCore_DP0 pid=497790) //
(EngineCore_DP0 pid=497790) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=497790) //
(EngineCore_DP0 pid=497790) 
(EngineCore_DP0 pid=497790) .version 8.7
(EngineCore_DP0 pid=497790) .target sm_121a
(EngineCore_DP0 pid=497790) .address_size 64
(EngineCore_DP0 pid=497790) 
(EngineCore_DP0 pid=497790) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=497790) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=497790)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=497790) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=497790) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=497790) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=497790) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=497790) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=497790) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=497790) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=497790) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=497790) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=497790) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=497790) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=497790) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=497790) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=497790) )
(EngineCore_DP0 pid=497790) .reqntid 512
(EngineCore_DP0 pid=497790) {
(EngineCore_DP0 pid=497790) 	.reg .pred 	%p<28>;
(EngineCore_DP0 pid=497790) 	.reg .b16 	%rs<49>;
(EngineCore_DP0 pid=497790) 	.reg .b32 	%r<151>;
(EngineCore_DP0 pid=497790) 	.reg .b64 	%rd<17>;
(EngineCore_DP0 pid=497790) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=497790) $L__func_begin0:
(EngineCore_DP0 pid=497790) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=497790) 
(EngineCore_DP0 pid=497790) // %bb.0:
(EngineCore_DP0 pid=497790) 	ld.param.b32 	%r25, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=497790) 	ld.param.b32 	%r24, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=497790) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=497790) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=497790) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=497790) $L__tmp0:
(EngineCore_DP0 pid=497790) 	.loc	1 143 24                        // quant_slide_tuned_Qwen2.5-7B.py:143:24
(EngineCore_DP0 pid=497790) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=497790) 	ld.param.b32 	%r27, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=497790) 	.loc	1 148 26                        // quant_slide_tuned_Qwen2.5-7B.py:148:26
(EngineCore_DP0 pid=497790) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=497790) 	.loc	1 148 20                        // quant_slide_tuned_Qwen2.5-7B.py:148:20
(EngineCore_DP0 pid=497790) 	mad.wide.s32 	%rd1, %r28, 2, %rd4;
(EngineCore_DP0 pid=497790) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=497790) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=497790) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=497790) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=497790) 	setp.lt.s32 	%p1, %r24, 1;
(EngineCore_DP0 pid=497790) 	mov.b32 	%r149, 0f2B8CBCCC;
(EngineCore_DP0 pid=497790) 	setp.eq.b32 	%p27, %r2, 0;
(EngineCore_DP0 pid=497790) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=497790) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=497790) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=497790) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=497790) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=497790) 	shr.u32 	%r37, %r2, 3;
(EngineCore_DP0 pid=497790) 	and.b32 	%r38, %r37, 60;
(EngineCore_DP0 pid=497790) 	mov.b32 	%r39, global_smem;
(EngineCore_DP0 pid=497790) 	add.s32 	%r49, %r39, %r38;
(EngineCore_DP0 pid=497790) 	shl.b32 	%r40, %r2, 2;
(EngineCore_DP0 pid=497790) 	add.s32 	%r52, %r39, %r40;
(EngineCore_DP0 pid=497790) 	mov.b32 	%r45, 0;
(EngineCore_DP0 pid=497790) 	mov.b32 	%r147, 0f00000000;
(EngineCore_DP0 pid=497790) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=497790) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=497790) 	mov.b32 	%r148, %r45;
(EngineCore_DP0 pid=497790) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=497790) 	.loc	1 155 22                        // quant_slide_tuned_Qwen2.5-7B.py:155:22
(EngineCore_DP0 pid=497790) 	add.s32 	%r55, %r4, %r148;
(EngineCore_DP0 pid=497790) 	setp.lt.s32 	%p2, %r55, %r23;
(EngineCore_DP0 pid=497790) 	.loc	1 156 29                        // quant_slide_tuned_Qwen2.5-7B.py:156:29
(EngineCore_DP0 pid=497790) 	mad.wide.s32 	%rd6, %r55, 2, %rd1;
(EngineCore_DP0 pid=497790) 	.loc	1 156 21                        // quant_slide_tuned_Qwen2.5-7B.py:156:21
(EngineCore_DP0 pid=497790) 	// begin inline asm
(EngineCore_DP0 pid=497790) 	mov.u32 %r41, %r45;
(EngineCore_DP0 pid=497790) 	mov.u32 %r42, %r45;
(EngineCore_DP0 pid=497790) 	mov.u32 %r43, %r45;
(EngineCore_DP0 pid=497790) 	mov.u32 %r44, %r45;
(EngineCore_DP0 pid=497790) 	@%p2 ld.global.v4.b32 { %r41, %r42, %r43, %r44 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=497790) 	// end inline asm
(EngineCore_DP0 pid=497790) 	mov.b32 	{%rs1, %rs2}, %r41;
(EngineCore_DP0 pid=497790) 	mov.b32 	{%rs3, %rs4}, %r42;
(EngineCore_DP0 pid=497790) 	mov.b32 	{%rs5, %rs6}, %r43;
(EngineCore_DP0 pid=497790) 	mov.b32 	{%rs7, %rs8}, %r44;
(EngineCore_DP0 pid=497790) 	.loc	1 157 50                        // quant_slide_tuned_Qwen2.5-7B.py:157:50
(EngineCore_DP0 pid=497790) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=497790) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=497790) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=497790) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=497790) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=497790) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=497790) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=497790) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=497790) $L__tmp1:
(EngineCore_DP0 pid=497790) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=497790) 	bar.sync 	0;
(EngineCore_DP0 pid=497790) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=497790) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=497790) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=497790) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=497790) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=497790) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=497790) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=497790) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=497790) 	cvt.f32.bf16 	%r56, %rs23;
(EngineCore_DP0 pid=497790) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=497790) 	shfl.sync.bfly.b32 	%r57, %r56, 16, 31, -1;
(EngineCore_DP0 pid=497790) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=497790) 	max.f32 	%r58, %r56, %r57;
(EngineCore_DP0 pid=497790) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=497790) 	shfl.sync.bfly.b32 	%r59, %r58, 8, 31, -1;
(EngineCore_DP0 pid=497790) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=497790) 	max.f32 	%r60, %r58, %r59;
(EngineCore_DP0 pid=497790) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=497790) 	shfl.sync.bfly.b32 	%r61, %r60, 4, 31, -1;
(EngineCore_DP0 pid=497790) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=497790) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=497790) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=497790) 	shfl.sync.bfly.b32 	%r63, %r62, 2, 31, -1;
(EngineCore_DP0 pid=497790) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=497790) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=497790) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=497790) 	shfl.sync.bfly.b32 	%r65, %r64, 1, 31, -1;
(EngineCore_DP0 pid=497790) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=497790) 	max.f32 	%r50, %r64, %r65;
(EngineCore_DP0 pid=497790) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=497790) 	// begin inline asm
(EngineCore_DP0 pid=497790) 	@%p3 st.shared.b32 [ %r49 + 0 ], %r50;
(EngineCore_DP0 pid=497790) 	// end inline asm
(EngineCore_DP0 pid=497790) 	bar.sync 	0;
(EngineCore_DP0 pid=497790) 	// begin inline asm
(EngineCore_DP0 pid=497790) 	@%p4 ld.shared.b32 %r51, [ %r52 + 0 ];
(EngineCore_DP0 pid=497790) 	// end inline asm
(EngineCore_DP0 pid=497790) 	shfl.sync.bfly.b32 	%r66, %r51, 8, 31, -1;
(EngineCore_DP0 pid=497790) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=497790) 	max.f32 	%r67, %r51, %r66;
(EngineCore_DP0 pid=497790) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=497790) 	shfl.sync.bfly.b32 	%r68, %r67, 4, 31, -1;
(EngineCore_DP0 pid=497790) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=497790) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=497790) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=497790) 	shfl.sync.bfly.b32 	%r70, %r69, 2, 31, -1;
(EngineCore_DP0 pid=497790) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=497790) 	max.f32 	%r71, %r69, %r70;
(EngineCore_DP0 pid=497790) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=497790) 	shfl.sync.bfly.b32 	%r72, %r71, 1, 31, -1;
(EngineCore_DP0 pid=497790) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=497790) 	max.f32 	%r54, %r71, %r72;
(EngineCore_DP0 pid=497790) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=497790) 	// begin inline asm
(EngineCore_DP0 pid=497790) 	@%p27 st.shared.b32 [ %r52 + 0 ], %r54;
(EngineCore_DP0 pid=497790) 	// end inline asm
(EngineCore_DP0 pid=497790) 	bar.sync 	0;
(EngineCore_DP0 pid=497790) 	ld.shared.b32 	%r73, [global_smem];
(EngineCore_DP0 pid=497790) $L__tmp2:
(EngineCore_DP0 pid=497790) 	.loc	1 157 36                        // quant_slide_tuned_Qwen2.5-7B.py:157:36
(EngineCore_DP0 pid=497790) 	max.f32 	%r147, %r147, %r73;
(EngineCore_DP0 pid=497790) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=497790) 	add.s32 	%r148, %r148, 4096;
(EngineCore_DP0 pid=497790) 	setp.lt.s32 	%p6, %r148, %r24;
(EngineCore_DP0 pid=497790) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=497790) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=497790) 	.loc	1 159 32                        // quant_slide_tuned_Qwen2.5-7B.py:159:32
(EngineCore_DP0 pid=497790) 	max.f32 	%r149, %r147, 0f2B8CBCCC;
(EngineCore_DP0 pid=497790) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=497790) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-7B.py:0:32
(EngineCore_DP0 pid=497790) 	mov.b32 	%r75, 0f43E00000;
(EngineCore_DP0 pid=497790) 	.loc	1 160 32                        // quant_slide_tuned_Qwen2.5-7B.py:160:32
(EngineCore_DP0 pid=497790) 	div.full.f32 	%r76, %r149, %r75;
(EngineCore_DP0 pid=497790) 	.loc	1 160 41                        // quant_slide_tuned_Qwen2.5-7B.py:160:41
(EngineCore_DP0 pid=497790) 	max.f32 	%r74, %r76, 0f36924925;
(EngineCore_DP0 pid=497790) 	.loc	1 162 25                        // quant_slide_tuned_Qwen2.5-7B.py:162:25
(EngineCore_DP0 pid=497790) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=497790) 	.loc	1 162 30                        // quant_slide_tuned_Qwen2.5-7B.py:162:30
(EngineCore_DP0 pid=497790) 	// begin inline asm
(EngineCore_DP0 pid=497790) 	@%p27 st.global.b32 [ %rd7 + 0 ], { %r74 };
(EngineCore_DP0 pid=497790) 	// end inline asm
(EngineCore_DP0 pid=497790) 	.loc	1 165 29                        // quant_slide_tuned_Qwen2.5-7B.py:165:29
(EngineCore_DP0 pid=497790) 	shl.b32 	%r15, %r25, 2;
(EngineCore_DP0 pid=497790) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=497790) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=497790) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=497790) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=497790) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-7B.py:0:41
(EngineCore_DP0 pid=497790) 	ld.param.b32 	%r29, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=497790) 	shr.s32 	%r30, %r29, 31;
(EngineCore_DP0 pid=497790) 	shr.u32 	%r31, %r30, 30;
(EngineCore_DP0 pid=497790) 	add.s32 	%r32, %r29, %r31;
(EngineCore_DP0 pid=497790) 	shr.s32 	%r33, %r32, 2;
(EngineCore_DP0 pid=497790) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=497790) 	mul.lo.s32 	%r34, %r33, %r1;
(EngineCore_DP0 pid=497790) 	mad.wide.s32 	%rd2, %r34, 4, %rd5;
(EngineCore_DP0 pid=497790) 	div.full.f32 	%r14, %r75, %r149;
(EngineCore_DP0 pid=497790) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=497790) 	mov.b32 	%r150, 0;
(EngineCore_DP0 pid=497790) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=497790)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=497790) 	.loc	1 168 31                        // quant_slide_tuned_Qwen2.5-7B.py:168:31
(EngineCore_DP0 pid=497790) 	add.s32 	%r88, %r16, %r150;
(EngineCore_DP0 pid=497790) 	.loc	1 169 30                        // quant_slide_tuned_Qwen2.5-7B.py:169:30
(EngineCore_DP0 pid=497790) 	add.s32 	%r89, %r88, 1;
(EngineCore_DP0 pid=497790) 	setp.lt.s32 	%p17, %r88, %r15;
(EngineCore_DP0 pid=497790) 	.loc	1 172 24                        // quant_slide_tuned_Qwen2.5-7B.py:172:24
(EngineCore_DP0 pid=497790) 	shr.s32 	%r90, %r88, 31;
(EngineCore_DP0 pid=497790) 	shr.u32 	%r91, %r90, 30;
(EngineCore_DP0 pid=497790) 	add.s32 	%r92, %r88, %r91;
(EngineCore_DP0 pid=497790) 	shr.s32 	%r93, %r92, 2;
(EngineCore_DP0 pid=497790) 	.loc	1 173 23                        // quant_slide_tuned_Qwen2.5-7B.py:173:23
(EngineCore_DP0 pid=497790) 	shr.s32 	%r94, %r89, 31;
(EngineCore_DP0 pid=497790) 	shr.u32 	%r95, %r94, 30;
(EngineCore_DP0 pid=497790) 	add.s32 	%r96, %r89, %r95;
(EngineCore_DP0 pid=497790) 	and.b32 	%r97, %r96, 2147483644;
(EngineCore_DP0 pid=497790) 	sub.s32 	%r98, %r89, %r97;
(EngineCore_DP0 pid=497790) 	and.b32 	%r99, %r92, 2147483644;
(EngineCore_DP0 pid=497790) 	sub.s32 	%r100, %r88, %r99;
(EngineCore_DP0 pid=497790) 	.loc	1 174 22                        // quant_slide_tuned_Qwen2.5-7B.py:174:22
(EngineCore_DP0 pid=497790) 	mul.lo.s32 	%r101, %r93, 10;
(EngineCore_DP0 pid=497790) 	.loc	1 174 30                        // quant_slide_tuned_Qwen2.5-7B.py:174:30
(EngineCore_DP0 pid=497790) 	shl.b32 	%r102, %r100, 1;
(EngineCore_DP0 pid=497790) 	shl.b32 	%r103, %r98, 1;
(EngineCore_DP0 pid=497790) 	.loc	1 174 26                        // quant_slide_tuned_Qwen2.5-7B.py:174:26
(EngineCore_DP0 pid=497790) 	add.s32 	%r104, %r101, %r103;
(EngineCore_DP0 pid=497790) 	add.s32 	%r105, %r101, %r102;
(EngineCore_DP0 pid=497790) 	.loc	1 177 53                        // quant_slide_tuned_Qwen2.5-7B.py:177:53
(EngineCore_DP0 pid=497790) 	setp.lt.s32 	%p18, %r105, %r23;
(EngineCore_DP0 pid=497790) 	setp.lt.s32 	%p19, %r104, %r23;
(EngineCore_DP0 pid=497790) 	.loc	1 177 37                        // quant_slide_tuned_Qwen2.5-7B.py:177:37
(EngineCore_DP0 pid=497790) 	and.pred 	%p9, %p17, %p18;
(EngineCore_DP0 pid=497790) 	and.pred 	%p10, %p17, %p19;
(EngineCore_DP0 pid=497790) 	.loc	1 176 29                        // quant_slide_tuned_Qwen2.5-7B.py:176:29
(EngineCore_DP0 pid=497790) 	mad.wide.s32 	%rd8, %r105, 2, %rd1;
(EngineCore_DP0 pid=497790) 	mad.wide.s32 	%rd9, %r104, 2, %rd1;
(EngineCore_DP0 pid=497790) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=497790) 	.loc	1 176 21                        // quant_slide_tuned_Qwen2.5-7B.py:176:21
(EngineCore_DP0 pid=497790) 	// begin inline asm
(EngineCore_DP0 pid=497790) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=497790) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=497790) 	// end inline asm
(EngineCore_DP0 pid=497790) 	// begin inline asm
(EngineCore_DP0 pid=497790) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=497790) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=497790) 	// end inline asm
(EngineCore_DP0 pid=497790) 	.loc	1 177 79                        // quant_slide_tuned_Qwen2.5-7B.py:177:79
(EngineCore_DP0 pid=497790) 	cvt.f32.bf16 	%r106, %rs24;
(EngineCore_DP0 pid=497790) 	cvt.f32.bf16 	%r107, %rs26;
(EngineCore_DP0 pid=497790) 	.loc	1 179 48                        // quant_slide_tuned_Qwen2.5-7B.py:179:48
(EngineCore_DP0 pid=497790) 	or.b32 	%r108, %r105, 1;
(EngineCore_DP0 pid=497790) 	or.b32 	%r109, %r104, 1;
(EngineCore_DP0 pid=497790) 	.loc	1 179 53                        // quant_slide_tuned_Qwen2.5-7B.py:179:53
(EngineCore_DP0 pid=497790) 	setp.lt.s32 	%p20, %r108, %r23;
(EngineCore_DP0 pid=497790) 	setp.lt.s32 	%p21, %r109, %r23;
(EngineCore_DP0 pid=497790) 	.loc	1 179 37                        // quant_slide_tuned_Qwen2.5-7B.py:179:37
(EngineCore_DP0 pid=497790) 	and.pred 	%p11, %p17, %p20;
(EngineCore_DP0 pid=497790) 	and.pred 	%p12, %p17, %p21;
(EngineCore_DP0 pid=497790) 	.loc	1 178 39                        // quant_slide_tuned_Qwen2.5-7B.py:178:39
(EngineCore_DP0 pid=497790) 	add.s64 	%rd10, %rd8, 2;
(EngineCore_DP0 pid=497790) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=497790) 	.loc	1 178 21                        // quant_slide_tuned_Qwen2.5-7B.py:178:21
(EngineCore_DP0 pid=497790) 	// begin inline asm
(EngineCore_DP0 pid=497790) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=497790) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=497790) 	// end inline asm
(EngineCore_DP0 pid=497790) 	// begin inline asm
(EngineCore_DP0 pid=497790) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=497790) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=497790) 	// end inline asm
(EngineCore_DP0 pid=497790) 	.loc	1 179 79                        // quant_slide_tuned_Qwen2.5-7B.py:179:79
(EngineCore_DP0 pid=497790) 	cvt.f32.bf16 	%r110, %rs28;
(EngineCore_DP0 pid=497790) 	cvt.f32.bf16 	%r111, %rs30;
(EngineCore_DP0 pid=497790) 	.loc	1 183 48                        // quant_slide_tuned_Qwen2.5-7B.py:183:48
(EngineCore_DP0 pid=497790) 	add.s32 	%r112, %r105, 2;
(EngineCore_DP0 pid=497790) 	add.s32 	%r113, %r104, 2;
(EngineCore_DP0 pid=497790) 	add.s32 	%r114, %r105, 3;
(EngineCore_DP0 pid=497790) 	add.s32 	%r115, %r104, 3;
(EngineCore_DP0 pid=497790) 	.loc	1 183 53                        // quant_slide_tuned_Qwen2.5-7B.py:183:53
(EngineCore_DP0 pid=497790) 	setp.lt.s32 	%p22, %r115, %r23;
(EngineCore_DP0 pid=497790) 	setp.lt.s32 	%p23, %r114, %r23;
(EngineCore_DP0 pid=497790) 	setp.lt.s32 	%p24, %r113, %r23;
(EngineCore_DP0 pid=497790) 	setp.lt.s32 	%p25, %r112, %r23;
(EngineCore_DP0 pid=497790) 	.loc	1 181 37                        // quant_slide_tuned_Qwen2.5-7B.py:181:37
(EngineCore_DP0 pid=497790) 	and.pred 	%p13, %p17, %p25;
(EngineCore_DP0 pid=497790) 	and.pred 	%p14, %p17, %p24;
(EngineCore_DP0 pid=497790) 	.loc	1 180 39                        // quant_slide_tuned_Qwen2.5-7B.py:180:39
(EngineCore_DP0 pid=497790) 	add.s64 	%rd12, %rd8, 4;
(EngineCore_DP0 pid=497790) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=497790) 	.loc	1 180 21                        // quant_slide_tuned_Qwen2.5-7B.py:180:21
(EngineCore_DP0 pid=497790) 	// begin inline asm
(EngineCore_DP0 pid=497790) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=497790) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=497790) 	// end inline asm
(EngineCore_DP0 pid=497790) 	// begin inline asm
(EngineCore_DP0 pid=497790) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=497790) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=497790) 	// end inline asm
(EngineCore_DP0 pid=497790) 	.loc	1 181 79                        // quant_slide_tuned_Qwen2.5-7B.py:181:79
(EngineCore_DP0 pid=497790) 	cvt.f32.bf16 	%r116, %rs32;
(EngineCore_DP0 pid=497790) 	cvt.f32.bf16 	%r117, %rs34;
(EngineCore_DP0 pid=497790) 	.loc	1 183 37                        // quant_slide_tuned_Qwen2.5-7B.py:183:37
(EngineCore_DP0 pid=497790) 	and.pred 	%p15, %p17, %p23;
(EngineCore_DP0 pid=497790) 	and.pred 	%p16, %p17, %p22;
(EngineCore_DP0 pid=497790) 	.loc	1 182 39                        // quant_slide_tuned_Qwen2.5-7B.py:182:39
(EngineCore_DP0 pid=497790) 	add.s64 	%rd14, %rd8, 6;
(EngineCore_DP0 pid=497790) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=497790) 	.loc	1 182 21                        // quant_slide_tuned_Qwen2.5-7B.py:182:21
(EngineCore_DP0 pid=497790) 	// begin inline asm
(EngineCore_DP0 pid=497790) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=497790) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=497790) 	// end inline asm
(EngineCore_DP0 pid=497790) 	// begin inline asm
(EngineCore_DP0 pid=497790) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=497790) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=497790) 	// end inline asm
(EngineCore_DP0 pid=497790) 	.loc	1 183 79                        // quant_slide_tuned_Qwen2.5-7B.py:183:79
(EngineCore_DP0 pid=497790) 	cvt.f32.bf16 	%r118, %rs36;
(EngineCore_DP0 pid=497790) 	cvt.f32.bf16 	%r119, %rs38;
(EngineCore_DP0 pid=497790) 	.loc	1 185 27                        // quant_slide_tuned_Qwen2.5-7B.py:185:27
(EngineCore_DP0 pid=497790) 	mul.f32 	%r120, %r14, %r106;
(EngineCore_DP0 pid=497790) 	mul.f32 	%r121, %r14, %r107;
(EngineCore_DP0 pid=497790) 	mov.b32 	%r122, 0f43E00000;
(EngineCore_DP0 pid=497790) 	.loc	1 185 48                        // quant_slide_tuned_Qwen2.5-7B.py:185:48
(EngineCore_DP0 pid=497790) 	min.xorsign.abs.f32 	%r78, %r120, %r122;
(EngineCore_DP0 pid=497790) 	min.xorsign.abs.f32 	%r79, %r121, %r122;
(EngineCore_DP0 pid=497790) 	.loc	1 185 60                        // quant_slide_tuned_Qwen2.5-7B.py:185:60
(EngineCore_DP0 pid=497790) 	// begin inline asm
(EngineCore_DP0 pid=497790) 	cvt.rn.satfinite.e4m3x2.f32  %rs40, %r79, %r78; 
(EngineCore_DP0 pid=497790) 
(EngineCore_DP0 pid=497790) 	// end inline asm
(EngineCore_DP0 pid=497790) 	shr.u16 	%rs44, %rs40, 8;
(EngineCore_DP0 pid=497790) 	.loc	1 186 27                        // quant_slide_tuned_Qwen2.5-7B.py:186:27
(EngineCore_DP0 pid=497790) 	mul.f32 	%r123, %r14, %r110;
(EngineCore_DP0 pid=497790) 	mul.f32 	%r124, %r14, %r111;
(EngineCore_DP0 pid=497790) 	.loc	1 186 48                        // quant_slide_tuned_Qwen2.5-7B.py:186:48
(EngineCore_DP0 pid=497790) 	min.xorsign.abs.f32 	%r80, %r123, %r122;
(EngineCore_DP0 pid=497790) 	min.xorsign.abs.f32 	%r81, %r124, %r122;
(EngineCore_DP0 pid=497790) 	.loc	1 186 60                        // quant_slide_tuned_Qwen2.5-7B.py:186:60
(EngineCore_DP0 pid=497790) 	// begin inline asm
(EngineCore_DP0 pid=497790) 	cvt.rn.satfinite.e4m3x2.f32  %rs41, %r81, %r80; 
(EngineCore_DP0 pid=497790) 
(EngineCore_DP0 pid=497790) 	// end inline asm
(EngineCore_DP0 pid=497790) 	shr.u16 	%rs45, %rs41, 8;
(EngineCore_DP0 pid=497790) 	.loc	1 187 27                        // quant_slide_tuned_Qwen2.5-7B.py:187:27
(EngineCore_DP0 pid=497790) 	mul.f32 	%r125, %r14, %r116;
(EngineCore_DP0 pid=497790) 	mul.f32 	%r126, %r14, %r117;
(EngineCore_DP0 pid=497790) 	.loc	1 187 48                        // quant_slide_tuned_Qwen2.5-7B.py:187:48
(EngineCore_DP0 pid=497790) 	min.xorsign.abs.f32 	%r82, %r125, %r122;
(EngineCore_DP0 pid=497790) 	min.xorsign.abs.f32 	%r83, %r126, %r122;
(EngineCore_DP0 pid=497790) 	.loc	1 187 60                        // quant_slide_tuned_Qwen2.5-7B.py:187:60
(EngineCore_DP0 pid=497790) 	// begin inline asm
(EngineCore_DP0 pid=497790) 	cvt.rn.satfinite.e4m3x2.f32  %rs42, %r83, %r82; 
(EngineCore_DP0 pid=497790) 
(EngineCore_DP0 pid=497790) 	// end inline asm
(EngineCore_DP0 pid=497790) 	shr.u16 	%rs46, %rs42, 8;
(EngineCore_DP0 pid=497790) 	.loc	1 188 27                        // quant_slide_tuned_Qwen2.5-7B.py:188:27
(EngineCore_DP0 pid=497790) 	mul.f32 	%r127, %r14, %r118;
(EngineCore_DP0 pid=497790) 	mul.f32 	%r128, %r14, %r119;
(EngineCore_DP0 pid=497790) 	.loc	1 188 48                        // quant_slide_tuned_Qwen2.5-7B.py:188:48
(EngineCore_DP0 pid=497790) 	min.xorsign.abs.f32 	%r84, %r127, %r122;
(EngineCore_DP0 pid=497790) 	min.xorsign.abs.f32 	%r85, %r128, %r122;
(EngineCore_DP0 pid=497790) 	.loc	1 188 60                        // quant_slide_tuned_Qwen2.5-7B.py:188:60
(EngineCore_DP0 pid=497790) 	// begin inline asm
(EngineCore_DP0 pid=497790) 	cvt.rn.satfinite.e4m3x2.f32  %rs43, %r85, %r84; 
(EngineCore_DP0 pid=497790) 
(EngineCore_DP0 pid=497790) 	// end inline asm
(EngineCore_DP0 pid=497790) 	shr.u16 	%rs47, %rs43, 8;
(EngineCore_DP0 pid=497790) 	.loc	1 190 45                        // quant_slide_tuned_Qwen2.5-7B.py:190:45
(EngineCore_DP0 pid=497790) 	cvt.u32.u16 	%r129, %rs40;
(EngineCore_DP0 pid=497790) 	and.b32 	%r130, %r129, 255;
(EngineCore_DP0 pid=497790) 	cvt.u32.u16 	%r131, %rs44;
(EngineCore_DP0 pid=497790) 	.loc	1 192 45                        // quant_slide_tuned_Qwen2.5-7B.py:192:45
(EngineCore_DP0 pid=497790) 	cvt.u32.u16 	%r132, %rs42;
(EngineCore_DP0 pid=497790) 	and.b32 	%r133, %r132, 255;
(EngineCore_DP0 pid=497790) 	cvt.u32.u16 	%r134, %rs46;
(EngineCore_DP0 pid=497790) 	.loc	1 193 45                        // quant_slide_tuned_Qwen2.5-7B.py:193:45
(EngineCore_DP0 pid=497790) 	cvt.u32.u16 	%r135, %rs43;
(EngineCore_DP0 pid=497790) 	cvt.u32.u16 	%r136, %rs47;
(EngineCore_DP0 pid=497790) 	.loc	1 195 30                        // quant_slide_tuned_Qwen2.5-7B.py:195:30
(EngineCore_DP0 pid=497790) 	and.b16 	%rs48, %rs41, 255;
(EngineCore_DP0 pid=497790) 	mul.wide.u16 	%r137, %rs48, 256;
(EngineCore_DP0 pid=497790) 	mul.wide.u16 	%r138, %rs45, 256;
(EngineCore_DP0 pid=497790) 	.loc	1 195 24                        // quant_slide_tuned_Qwen2.5-7B.py:195:24
(EngineCore_DP0 pid=497790) 	or.b32 	%r139, %r137, %r130;
(EngineCore_DP0 pid=497790) 	or.b32 	%r140, %r138, %r131;
(EngineCore_DP0 pid=497790) 	.loc	1 195 42                        // quant_slide_tuned_Qwen2.5-7B.py:195:42
(EngineCore_DP0 pid=497790) 	shl.b32 	%r141, %r133, 16;
(EngineCore_DP0 pid=497790) 	shl.b32 	%r142, %r134, 16;
(EngineCore_DP0 pid=497790) 	.loc	1 195 36                        // quant_slide_tuned_Qwen2.5-7B.py:195:36
(EngineCore_DP0 pid=497790) 	or.b32 	%r143, %r139, %r141;
(EngineCore_DP0 pid=497790) 	or.b32 	%r144, %r140, %r142;
(EngineCore_DP0 pid=497790) 	.loc	1 195 55                        // quant_slide_tuned_Qwen2.5-7B.py:195:55
(EngineCore_DP0 pid=497790) 	shl.b32 	%r145, %r135, 24;
(EngineCore_DP0 pid=497790) 	shl.b32 	%r146, %r136, 24;
(EngineCore_DP0 pid=497790) 	.loc	1 195 49                        // quant_slide_tuned_Qwen2.5-7B.py:195:49
(EngineCore_DP0 pid=497790) 	or.b32 	%r86, %r143, %r145;
(EngineCore_DP0 pid=497790) 	or.b32 	%r87, %r144, %r146;
(EngineCore_DP0 pid=497790) 	.loc	1 196 29                        // quant_slide_tuned_Qwen2.5-7B.py:196:29
(EngineCore_DP0 pid=497790) 	mad.wide.s32 	%rd16, %r88, 4, %rd2;
(EngineCore_DP0 pid=497790) 	.loc	1 196 39                        // quant_slide_tuned_Qwen2.5-7B.py:196:39
(EngineCore_DP0 pid=497790) 	// begin inline asm
(EngineCore_DP0 pid=497790) 	@%p17 st.global.v2.b32 [ %rd16 + 0 ], { %r86, %r87 };
(EngineCore_DP0 pid=497790) 	// end inline asm
(EngineCore_DP0 pid=497790) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=497790) 	add.s32 	%r150, %r150, 1024;
(EngineCore_DP0 pid=497790) 	setp.lt.s32 	%p26, %r150, %r15;
(EngineCore_DP0 pid=497790) 	@%p26 bra 	$L__BB0_6;
(EngineCore_DP0 pid=497790) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=497790) 	.loc	1 167 4                         // quant_slide_tuned_Qwen2.5-7B.py:167:4
(EngineCore_DP0 pid=497790) 	ret;
(EngineCore_DP0 pid=497790) $L__tmp3:
(EngineCore_DP0 pid=497790) $L__func_end0:
(EngineCore_DP0 pid=497790)                                         // -- End function
(EngineCore_DP0 pid=497790) }
(EngineCore_DP0 pid=497790) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py"
(EngineCore_DP0 pid=497790) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=497790) 	.section	.debug_abbrev
(EngineCore_DP0 pid=497790) 	{
(EngineCore_DP0 pid=497790) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=497790) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=497790) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=497790) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=497790) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=497790) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=497790) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=497790) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=497790) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=497790) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=497790) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=497790) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=497790) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=497790) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=497790) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=497790) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=497790) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=497790) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=497790) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=497790) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=497790) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=497790) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=497790) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=497790) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=497790) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=497790) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=497790) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=497790) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=497790) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=497790) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=497790) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=497790) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=497790) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=497790) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=497790) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=497790) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=497790) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=497790) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=497790) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=497790) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=497790) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=497790) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=497790) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=497790) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=497790) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=497790) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=497790) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=497790) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=497790) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=497790) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=497790) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=497790) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=497790) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=497790) 	}
(EngineCore_DP0 pid=497790) 	.section	.debug_info
(EngineCore_DP0 pid=497790) 	{
(EngineCore_DP0 pid=497790) .b32 221                                // Length of Unit
(EngineCore_DP0 pid=497790) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=497790) .b8 0
(EngineCore_DP0 pid=497790) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=497790) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=497790) .b8 1                                   // Abbrev [1] 0xb:0xd6 DW_TAG_compile_unit
(EngineCore_DP0 pid=497790) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=497790) .b8 114
(EngineCore_DP0 pid=497790) .b8 105
(EngineCore_DP0 pid=497790) .b8 116
(EngineCore_DP0 pid=497790) .b8 111
(EngineCore_DP0 pid=497790) .b8 110
(EngineCore_DP0 pid=497790) .b8 0
(EngineCore_DP0 pid=497790) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=497790) .b8 0
(EngineCore_DP0 pid=497790) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=497790) .b8 117
(EngineCore_DP0 pid=497790) .b8 97
(EngineCore_DP0 pid=497790) .b8 110
(EngineCore_DP0 pid=497790) .b8 116
(EngineCore_DP0 pid=497790) .b8 95
(EngineCore_DP0 pid=497790) .b8 115
(EngineCore_DP0 pid=497790) .b8 108
(EngineCore_DP0 pid=497790) .b8 105
(EngineCore_DP0 pid=497790) .b8 100
(EngineCore_DP0 pid=497790) .b8 101
(EngineCore_DP0 pid=497790) .b8 95
(EngineCore_DP0 pid=497790) .b8 116
(EngineCore_DP0 pid=497790) .b8 117
(EngineCore_DP0 pid=497790) .b8 110
(EngineCore_DP0 pid=497790) .b8 101
(EngineCore_DP0 pid=497790) .b8 100
(EngineCore_DP0 pid=497790) .b8 95
(EngineCore_DP0 pid=497790) .b8 81
(EngineCore_DP0 pid=497790) .b8 119
(EngineCore_DP0 pid=497790) .b8 101
(EngineCore_DP0 pid=497790) .b8 110
(EngineCore_DP0 pid=497790) .b8 50
(EngineCore_DP0 pid=497790) .b8 46
(EngineCore_DP0 pid=497790) .b8 53
(EngineCore_DP0 pid=497790) .b8 45
(EngineCore_DP0 pid=497790) .b8 55
(EngineCore_DP0 pid=497790) .b8 66
(EngineCore_DP0 pid=497790) .b8 46
(EngineCore_DP0 pid=497790) .b8 112
(EngineCore_DP0 pid=497790) .b8 121
(EngineCore_DP0 pid=497790) .b8 0
(EngineCore_DP0 pid=497790) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=497790) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=497790) .b8 114
(EngineCore_DP0 pid=497790) .b8 111
(EngineCore_DP0 pid=497790) .b8 111
(EngineCore_DP0 pid=497790) .b8 116
(EngineCore_DP0 pid=497790) .b8 47
(EngineCore_DP0 pid=497790) .b8 118
(EngineCore_DP0 pid=497790) .b8 108
(EngineCore_DP0 pid=497790) .b8 108
(EngineCore_DP0 pid=497790) .b8 109
(EngineCore_DP0 pid=497790) .b8 98
(EngineCore_DP0 pid=497790) .b8 101
(EngineCore_DP0 pid=497790) .b8 110
(EngineCore_DP0 pid=497790) .b8 99
(EngineCore_DP0 pid=497790) .b8 104
(EngineCore_DP0 pid=497790) .b8 47
(EngineCore_DP0 pid=497790) .b8 115
(EngineCore_DP0 pid=497790) .b8 108
(EngineCore_DP0 pid=497790) .b8 105
(EngineCore_DP0 pid=497790) .b8 100
(EngineCore_DP0 pid=497790) .b8 101
(EngineCore_DP0 pid=497790) .b8 115
(EngineCore_DP0 pid=497790) .b8 112
(EngineCore_DP0 pid=497790) .b8 97
(EngineCore_DP0 pid=497790) .b8 114
(EngineCore_DP0 pid=497790) .b8 115
(EngineCore_DP0 pid=497790) .b8 101
(EngineCore_DP0 pid=497790) .b8 47
(EngineCore_DP0 pid=497790) .b8 99
(EngineCore_DP0 pid=497790) .b8 115
(EngineCore_DP0 pid=497790) .b8 114
(EngineCore_DP0 pid=497790) .b8 99
(EngineCore_DP0 pid=497790) .b8 47
(EngineCore_DP0 pid=497790) .b8 102
(EngineCore_DP0 pid=497790) .b8 117
(EngineCore_DP0 pid=497790) .b8 115
(EngineCore_DP0 pid=497790) .b8 101
(EngineCore_DP0 pid=497790) .b8 100
(EngineCore_DP0 pid=497790) .b8 95
(EngineCore_DP0 pid=497790) .b8 113
(EngineCore_DP0 pid=497790) .b8 117
(EngineCore_DP0 pid=497790) .b8 97
(EngineCore_DP0 pid=497790) .b8 110
(EngineCore_DP0 pid=497790) .b8 116
(EngineCore_DP0 pid=497790) .b8 95
(EngineCore_DP0 pid=497790) .b8 115
(EngineCore_DP0 pid=497790) .b8 108
(EngineCore_DP0 pid=497790) .b8 105
(EngineCore_DP0 pid=497790) .b8 100
(EngineCore_DP0 pid=497790) .b8 101
(EngineCore_DP0 pid=497790) .b8 95
(EngineCore_DP0 pid=497790) .b8 116
(EngineCore_DP0 pid=497790) .b8 114
(EngineCore_DP0 pid=497790) .b8 105
(EngineCore_DP0 pid=497790) .b8 116
(EngineCore_DP0 pid=497790) .b8 111
(EngineCore_DP0 pid=497790) .b8 110
(EngineCore_DP0 pid=497790) .b8 47
(EngineCore_DP0 pid=497790) .b8 98
(EngineCore_DP0 pid=497790) .b8 117
(EngineCore_DP0 pid=497790) .b8 105
(EngineCore_DP0 pid=497790) .b8 108
(EngineCore_DP0 pid=497790) .b8 100
(EngineCore_DP0 pid=497790) .b8 47
(EngineCore_DP0 pid=497790) .b8 71
(EngineCore_DP0 pid=497790) .b8 66
(EngineCore_DP0 pid=497790) .b8 49
(EngineCore_DP0 pid=497790) .b8 48
(EngineCore_DP0 pid=497790) .b8 95
(EngineCore_DP0 pid=497790) .b8 99
(EngineCore_DP0 pid=497790) .b8 99
(EngineCore_DP0 pid=497790) .b8 49
(EngineCore_DP0 pid=497790) .b8 50
(EngineCore_DP0 pid=497790) .b8 49
(EngineCore_DP0 pid=497790) .b8 95
(EngineCore_DP0 pid=497790) .b8 112
(EngineCore_DP0 pid=497790) .b8 121
(EngineCore_DP0 pid=497790) .b8 51
(EngineCore_DP0 pid=497790) .b8 49
(EngineCore_DP0 pid=497790) .b8 50
(EngineCore_DP0 pid=497790) .b8 95
(EngineCore_DP0 pid=497790) .b8 99
(EngineCore_DP0 pid=497790) .b8 117
(EngineCore_DP0 pid=497790) .b8 49
(EngineCore_DP0 pid=497790) .b8 50
(EngineCore_DP0 pid=497790) .b8 57
(EngineCore_DP0 pid=497790) .b8 95
(EngineCore_DP0 pid=497790) .b8 97
(EngineCore_DP0 pid=497790) .b8 97
(EngineCore_DP0 pid=497790) .b8 114
(EngineCore_DP0 pid=497790) .b8 99
(EngineCore_DP0 pid=497790) .b8 104
(EngineCore_DP0 pid=497790) .b8 54
(EngineCore_DP0 pid=497790) .b8 52
(EngineCore_DP0 pid=497790) .b8 0
(EngineCore_DP0 pid=497790) .b8 2                                   // Abbrev [2] 0x98:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=497790) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=497790) .b8 113
(EngineCore_DP0 pid=497790) .b8 117
(EngineCore_DP0 pid=497790) .b8 97
(EngineCore_DP0 pid=497790) .b8 110
(EngineCore_DP0 pid=497790) .b8 116
(EngineCore_DP0 pid=497790) .b8 95
(EngineCore_DP0 pid=497790) .b8 115
(EngineCore_DP0 pid=497790) .b8 108
(EngineCore_DP0 pid=497790) .b8 105
(EngineCore_DP0 pid=497790) .b8 100
(EngineCore_DP0 pid=497790) .b8 101
(EngineCore_DP0 pid=497790) .b8 95
(EngineCore_DP0 pid=497790) .b8 102
(EngineCore_DP0 pid=497790) .b8 112
(EngineCore_DP0 pid=497790) .b8 56
(EngineCore_DP0 pid=497790) .b8 95
(EngineCore_DP0 pid=497790) .b8 107
(EngineCore_DP0 pid=497790) .b8 101
(EngineCore_DP0 pid=497790) .b8 114
(EngineCore_DP0 pid=497790) .b8 110
(EngineCore_DP0 pid=497790) .b8 101
(EngineCore_DP0 pid=497790) .b8 108
(EngineCore_DP0 pid=497790) .b8 0
(EngineCore_DP0 pid=497790) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=497790) .b8 3                                   // Abbrev [3] 0xb2:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=497790) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=497790) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=497790) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=497790) .b8 4                                   // Abbrev [4] 0xc7:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=497790) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=497790) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=497790) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=497790) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=497790) .b8 157                                 // DW_AT_call_line
(EngineCore_DP0 pid=497790) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=497790) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=497790) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=497790) 	}
(EngineCore_DP0 pid=497790) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=497790) 
(EngineCore_DP0 pid=497790) ================================================================
(EngineCore_DP0 pid=497790) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=497790) 
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpqzqh98x6.ptx', '-o', '/tmp/tmpqzqh98x6.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866] 
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866] 
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866] 
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpqzqh98x6.ptx -o /tmp/tmpqzqh98x6.ptx.o
(EngineCore_DP0 pid=497790) ERROR 01-25 21:49:49 [core.py:866] 

STDERR:
[2026-01-25 21:48:38] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:48:38] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:48:38] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:48:38] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:48:38] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:48:38] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:48:38] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:48:38] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:48:38] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:48:38] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:48:38] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:48:38] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:48:38] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:48:38] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:48:42] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:48:42] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:48:42] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:48:42] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:48:42] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:48:42] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:48:42] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:48:42] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:48:42] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:48:42] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:48:42] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:48:42] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:48:42] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:48:42] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=497790) [2026-01-25 21:48:43] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=497790) [2026-01-25 21:48:43] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=497790) [2026-01-25 21:48:43] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=497790) [2026-01-25 21:48:43] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=497790) [2026-01-25 21:48:43] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=497790) [2026-01-25 21:48:43] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=497790) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=497790) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:27<00:27, 27.40s/it]
(EngineCore_DP0 pid=497790) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:04<00:00, 32.83s/it]
(EngineCore_DP0 pid=497790) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:04<00:00, 32.01s/it]
(EngineCore_DP0 pid=497790) 
(EngineCore_DP0 pid=497790) [2026-01-25 21:49:48] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=497790) [2026-01-25 21:49:48] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16588800 bytes
(EngineCore_DP0 pid=497790) [2026-01-25 21:49:48] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=497790) [2026-01-25 21:49:48] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 12902400 bytes
(EngineCore_DP0 pid=497790) [2026-01-25 21:49:48] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=497790) [2026-01-25 21:49:48] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 136396800 bytes
(EngineCore_DP0 pid=497790) [2026-01-25 21:49:48] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=497790) [2026-01-25 21:49:48] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 67952640 bytes
(EngineCore_DP0 pid=497790) Process EngineCore_DP0:
(EngineCore_DP0 pid=497790) Traceback (most recent call last):
(EngineCore_DP0 pid=497790)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=497790)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=497790)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=497790)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=497790) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpqzqh98x6.ptx', '-o', '/tmp/tmpqzqh98x6.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=497790) 
(EngineCore_DP0 pid=497790) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=497790) 
(EngineCore_DP0 pid=497790) Traceback (most recent call last):
(EngineCore_DP0 pid=497790)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=497790)     self.run()
(EngineCore_DP0 pid=497790)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=497790)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=497790)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=497790)     raise e
(EngineCore_DP0 pid=497790)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=497790)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=497790)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=497790)     super().__init__(
(EngineCore_DP0 pid=497790)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=497790)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=497790)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=497790)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=497790)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=497790)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=497790)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=497790)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=497790)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=497790)     return func(*args, **kwargs)
(EngineCore_DP0 pid=497790)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=497790)     return func(*args, **kwargs)
(EngineCore_DP0 pid=497790)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=497790)     self.model_runner.profile_run()
(EngineCore_DP0 pid=497790)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=497790)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=497790)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=497790)     return func(*args, **kwargs)
(EngineCore_DP0 pid=497790)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=497790)     outputs = self.model(
(EngineCore_DP0 pid=497790)               ^^^^^^^^^^^
(EngineCore_DP0 pid=497790)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=497790)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=497790)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=497790)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=497790)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=497790)     hidden_states = self.model(
(EngineCore_DP0 pid=497790)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=497790)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=497790)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=497790)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=497790)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=497790)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=497790)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=497790)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=497790)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=497790)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=497790)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=497790)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=497790)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=497790)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=497790)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=497790)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=497790)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=497790)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=497790)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=497790)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=497790)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=497790)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=497790)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=497790)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=497790)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=497790)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=497790)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=497790)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=497790)     return self._linear_fn(
(EngineCore_DP0 pid=497790)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=497790)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=497790)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=497790)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=497790)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=497790)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=497790)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=497790)     return fn(input, L)
(EngineCore_DP0 pid=497790)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=497790)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=497790)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=497790)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=497790)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=497790)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=497790)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=497790)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=497790)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=497790)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=497790)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=497790)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=497790)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=497790)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=497790)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=497790)     raise PTXASError(error)
(EngineCore_DP0 pid=497790) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=497790) `ptxas` stderr:
(EngineCore_DP0 pid=497790) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=497790) 
(EngineCore_DP0 pid=497790) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpqzqh98x6.ptx -o /tmp/tmpqzqh98x6.ptx.o
(EngineCore_DP0 pid=497790) 
[rank0]:[W125 21:49:49.904796961 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=2048

========== M=4096 ==========
Time: 2026-01-25 21:49:51
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Qwen2.5-7B-FP8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:49:56 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 21:49:56 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=499105) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=499105) 
(EngineCore_DP0 pid=499105) 
(EngineCore_DP0 pid=499105) ================================================================
(EngineCore_DP0 pid=499105) Internal Triton PTX codegen error
(EngineCore_DP0 pid=499105) `ptxas` stderr:
(EngineCore_DP0 pid=499105) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=499105) 
(EngineCore_DP0 pid=499105) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp0ef_4zyh.ptx -o /tmp/tmp0ef_4zyh.ptx.o
(EngineCore_DP0 pid=499105) 
(EngineCore_DP0 pid=499105) 
(EngineCore_DP0 pid=499105) //
(EngineCore_DP0 pid=499105) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=499105) //
(EngineCore_DP0 pid=499105) 
(EngineCore_DP0 pid=499105) .version 8.7
(EngineCore_DP0 pid=499105) .target sm_121a
(EngineCore_DP0 pid=499105) .address_size 64
(EngineCore_DP0 pid=499105) 
(EngineCore_DP0 pid=499105) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=499105) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=499105)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=499105) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=499105) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=499105) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=499105) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=499105) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=499105) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=499105) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=499105) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=499105) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=499105) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=499105) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=499105) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=499105) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=499105) )
(EngineCore_DP0 pid=499105) .reqntid 512
(EngineCore_DP0 pid=499105) {
(EngineCore_DP0 pid=499105) 	.reg .pred 	%p<28>;
(EngineCore_DP0 pid=499105) 	.reg .b16 	%rs<49>;
(EngineCore_DP0 pid=499105) 	.reg .b32 	%r<151>;
(EngineCore_DP0 pid=499105) 	.reg .b64 	%rd<17>;
(EngineCore_DP0 pid=499105) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=499105) $L__func_begin0:
(EngineCore_DP0 pid=499105) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=499105) 
(EngineCore_DP0 pid=499105) // %bb.0:
(EngineCore_DP0 pid=499105) 	ld.param.b32 	%r25, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=499105) 	ld.param.b32 	%r24, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=499105) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=499105) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=499105) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=499105) $L__tmp0:
(EngineCore_DP0 pid=499105) 	.loc	1 143 24                        // quant_slide_tuned_Qwen2.5-7B.py:143:24
(EngineCore_DP0 pid=499105) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=499105) 	ld.param.b32 	%r27, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=499105) 	.loc	1 148 26                        // quant_slide_tuned_Qwen2.5-7B.py:148:26
(EngineCore_DP0 pid=499105) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=499105) 	.loc	1 148 20                        // quant_slide_tuned_Qwen2.5-7B.py:148:20
(EngineCore_DP0 pid=499105) 	mad.wide.s32 	%rd1, %r28, 2, %rd4;
(EngineCore_DP0 pid=499105) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=499105) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=499105) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=499105) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=499105) 	setp.lt.s32 	%p1, %r24, 1;
(EngineCore_DP0 pid=499105) 	mov.b32 	%r149, 0f2B8CBCCC;
(EngineCore_DP0 pid=499105) 	setp.eq.b32 	%p27, %r2, 0;
(EngineCore_DP0 pid=499105) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=499105) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=499105) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=499105) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=499105) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=499105) 	shr.u32 	%r37, %r2, 3;
(EngineCore_DP0 pid=499105) 	and.b32 	%r38, %r37, 60;
(EngineCore_DP0 pid=499105) 	mov.b32 	%r39, global_smem;
(EngineCore_DP0 pid=499105) 	add.s32 	%r49, %r39, %r38;
(EngineCore_DP0 pid=499105) 	shl.b32 	%r40, %r2, 2;
(EngineCore_DP0 pid=499105) 	add.s32 	%r52, %r39, %r40;
(EngineCore_DP0 pid=499105) 	mov.b32 	%r45, 0;
(EngineCore_DP0 pid=499105) 	mov.b32 	%r147, 0f00000000;
(EngineCore_DP0 pid=499105) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=499105) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=499105) 	mov.b32 	%r148, %r45;
(EngineCore_DP0 pid=499105) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=499105) 	.loc	1 155 22                        // quant_slide_tuned_Qwen2.5-7B.py:155:22
(EngineCore_DP0 pid=499105) 	add.s32 	%r55, %r4, %r148;
(EngineCore_DP0 pid=499105) 	setp.lt.s32 	%p2, %r55, %r23;
(EngineCore_DP0 pid=499105) 	.loc	1 156 29                        // quant_slide_tuned_Qwen2.5-7B.py:156:29
(EngineCore_DP0 pid=499105) 	mad.wide.s32 	%rd6, %r55, 2, %rd1;
(EngineCore_DP0 pid=499105) 	.loc	1 156 21                        // quant_slide_tuned_Qwen2.5-7B.py:156:21
(EngineCore_DP0 pid=499105) 	// begin inline asm
(EngineCore_DP0 pid=499105) 	mov.u32 %r41, %r45;
(EngineCore_DP0 pid=499105) 	mov.u32 %r42, %r45;
(EngineCore_DP0 pid=499105) 	mov.u32 %r43, %r45;
(EngineCore_DP0 pid=499105) 	mov.u32 %r44, %r45;
(EngineCore_DP0 pid=499105) 	@%p2 ld.global.v4.b32 { %r41, %r42, %r43, %r44 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=499105) 	// end inline asm
(EngineCore_DP0 pid=499105) 	mov.b32 	{%rs1, %rs2}, %r41;
(EngineCore_DP0 pid=499105) 	mov.b32 	{%rs3, %rs4}, %r42;
(EngineCore_DP0 pid=499105) 	mov.b32 	{%rs5, %rs6}, %r43;
(EngineCore_DP0 pid=499105) 	mov.b32 	{%rs7, %rs8}, %r44;
(EngineCore_DP0 pid=499105) 	.loc	1 157 50                        // quant_slide_tuned_Qwen2.5-7B.py:157:50
(EngineCore_DP0 pid=499105) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=499105) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=499105) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=499105) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=499105) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=499105) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=499105) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=499105) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=499105) $L__tmp1:
(EngineCore_DP0 pid=499105) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=499105) 	bar.sync 	0;
(EngineCore_DP0 pid=499105) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=499105) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=499105) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=499105) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=499105) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=499105) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=499105) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=499105) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=499105) 	cvt.f32.bf16 	%r56, %rs23;
(EngineCore_DP0 pid=499105) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=499105) 	shfl.sync.bfly.b32 	%r57, %r56, 16, 31, -1;
(EngineCore_DP0 pid=499105) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=499105) 	max.f32 	%r58, %r56, %r57;
(EngineCore_DP0 pid=499105) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=499105) 	shfl.sync.bfly.b32 	%r59, %r58, 8, 31, -1;
(EngineCore_DP0 pid=499105) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=499105) 	max.f32 	%r60, %r58, %r59;
(EngineCore_DP0 pid=499105) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=499105) 	shfl.sync.bfly.b32 	%r61, %r60, 4, 31, -1;
(EngineCore_DP0 pid=499105) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=499105) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=499105) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=499105) 	shfl.sync.bfly.b32 	%r63, %r62, 2, 31, -1;
(EngineCore_DP0 pid=499105) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=499105) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=499105) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=499105) 	shfl.sync.bfly.b32 	%r65, %r64, 1, 31, -1;
(EngineCore_DP0 pid=499105) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=499105) 	max.f32 	%r50, %r64, %r65;
(EngineCore_DP0 pid=499105) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=499105) 	// begin inline asm
(EngineCore_DP0 pid=499105) 	@%p3 st.shared.b32 [ %r49 + 0 ], %r50;
(EngineCore_DP0 pid=499105) 	// end inline asm
(EngineCore_DP0 pid=499105) 	bar.sync 	0;
(EngineCore_DP0 pid=499105) 	// begin inline asm
(EngineCore_DP0 pid=499105) 	@%p4 ld.shared.b32 %r51, [ %r52 + 0 ];
(EngineCore_DP0 pid=499105) 	// end inline asm
(EngineCore_DP0 pid=499105) 	shfl.sync.bfly.b32 	%r66, %r51, 8, 31, -1;
(EngineCore_DP0 pid=499105) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=499105) 	max.f32 	%r67, %r51, %r66;
(EngineCore_DP0 pid=499105) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=499105) 	shfl.sync.bfly.b32 	%r68, %r67, 4, 31, -1;
(EngineCore_DP0 pid=499105) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=499105) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=499105) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=499105) 	shfl.sync.bfly.b32 	%r70, %r69, 2, 31, -1;
(EngineCore_DP0 pid=499105) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=499105) 	max.f32 	%r71, %r69, %r70;
(EngineCore_DP0 pid=499105) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=499105) 	shfl.sync.bfly.b32 	%r72, %r71, 1, 31, -1;
(EngineCore_DP0 pid=499105) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=499105) 	max.f32 	%r54, %r71, %r72;
(EngineCore_DP0 pid=499105) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=499105) 	// begin inline asm
(EngineCore_DP0 pid=499105) 	@%p27 st.shared.b32 [ %r52 + 0 ], %r54;
(EngineCore_DP0 pid=499105) 	// end inline asm
(EngineCore_DP0 pid=499105) 	bar.sync 	0;
(EngineCore_DP0 pid=499105) 	ld.shared.b32 	%r73, [global_smem];
(EngineCore_DP0 pid=499105) $L__tmp2:
(EngineCore_DP0 pid=499105) 	.loc	1 157 36                        // quant_slide_tuned_Qwen2.5-7B.py:157:36
(EngineCore_DP0 pid=499105) 	max.f32 	%r147, %r147, %r73;
(EngineCore_DP0 pid=499105) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=499105) 	add.s32 	%r148, %r148, 4096;
(EngineCore_DP0 pid=499105) 	setp.lt.s32 	%p6, %r148, %r24;
(EngineCore_DP0 pid=499105) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=499105) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=499105) 	.loc	1 159 32                        // quant_slide_tuned_Qwen2.5-7B.py:159:32
(EngineCore_DP0 pid=499105) 	max.f32 	%r149, %r147, 0f2B8CBCCC;
(EngineCore_DP0 pid=499105) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=499105) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-7B.py:0:32
(EngineCore_DP0 pid=499105) 	mov.b32 	%r75, 0f43E00000;
(EngineCore_DP0 pid=499105) 	.loc	1 160 32                        // quant_slide_tuned_Qwen2.5-7B.py:160:32
(EngineCore_DP0 pid=499105) 	div.full.f32 	%r76, %r149, %r75;
(EngineCore_DP0 pid=499105) 	.loc	1 160 41                        // quant_slide_tuned_Qwen2.5-7B.py:160:41
(EngineCore_DP0 pid=499105) 	max.f32 	%r74, %r76, 0f36924925;
(EngineCore_DP0 pid=499105) 	.loc	1 162 25                        // quant_slide_tuned_Qwen2.5-7B.py:162:25
(EngineCore_DP0 pid=499105) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=499105) 	.loc	1 162 30                        // quant_slide_tuned_Qwen2.5-7B.py:162:30
(EngineCore_DP0 pid=499105) 	// begin inline asm
(EngineCore_DP0 pid=499105) 	@%p27 st.global.b32 [ %rd7 + 0 ], { %r74 };
(EngineCore_DP0 pid=499105) 	// end inline asm
(EngineCore_DP0 pid=499105) 	.loc	1 165 29                        // quant_slide_tuned_Qwen2.5-7B.py:165:29
(EngineCore_DP0 pid=499105) 	shl.b32 	%r15, %r25, 2;
(EngineCore_DP0 pid=499105) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=499105) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=499105) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=499105) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=499105) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-7B.py:0:41
(EngineCore_DP0 pid=499105) 	ld.param.b32 	%r29, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=499105) 	shr.s32 	%r30, %r29, 31;
(EngineCore_DP0 pid=499105) 	shr.u32 	%r31, %r30, 30;
(EngineCore_DP0 pid=499105) 	add.s32 	%r32, %r29, %r31;
(EngineCore_DP0 pid=499105) 	shr.s32 	%r33, %r32, 2;
(EngineCore_DP0 pid=499105) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=499105) 	mul.lo.s32 	%r34, %r33, %r1;
(EngineCore_DP0 pid=499105) 	mad.wide.s32 	%rd2, %r34, 4, %rd5;
(EngineCore_DP0 pid=499105) 	div.full.f32 	%r14, %r75, %r149;
(EngineCore_DP0 pid=499105) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=499105) 	mov.b32 	%r150, 0;
(EngineCore_DP0 pid=499105) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=499105)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=499105) 	.loc	1 168 31                        // quant_slide_tuned_Qwen2.5-7B.py:168:31
(EngineCore_DP0 pid=499105) 	add.s32 	%r88, %r16, %r150;
(EngineCore_DP0 pid=499105) 	.loc	1 169 30                        // quant_slide_tuned_Qwen2.5-7B.py:169:30
(EngineCore_DP0 pid=499105) 	add.s32 	%r89, %r88, 1;
(EngineCore_DP0 pid=499105) 	setp.lt.s32 	%p17, %r88, %r15;
(EngineCore_DP0 pid=499105) 	.loc	1 172 24                        // quant_slide_tuned_Qwen2.5-7B.py:172:24
(EngineCore_DP0 pid=499105) 	shr.s32 	%r90, %r88, 31;
(EngineCore_DP0 pid=499105) 	shr.u32 	%r91, %r90, 30;
(EngineCore_DP0 pid=499105) 	add.s32 	%r92, %r88, %r91;
(EngineCore_DP0 pid=499105) 	shr.s32 	%r93, %r92, 2;
(EngineCore_DP0 pid=499105) 	.loc	1 173 23                        // quant_slide_tuned_Qwen2.5-7B.py:173:23
(EngineCore_DP0 pid=499105) 	shr.s32 	%r94, %r89, 31;
(EngineCore_DP0 pid=499105) 	shr.u32 	%r95, %r94, 30;
(EngineCore_DP0 pid=499105) 	add.s32 	%r96, %r89, %r95;
(EngineCore_DP0 pid=499105) 	and.b32 	%r97, %r96, 2147483644;
(EngineCore_DP0 pid=499105) 	sub.s32 	%r98, %r89, %r97;
(EngineCore_DP0 pid=499105) 	and.b32 	%r99, %r92, 2147483644;
(EngineCore_DP0 pid=499105) 	sub.s32 	%r100, %r88, %r99;
(EngineCore_DP0 pid=499105) 	.loc	1 174 22                        // quant_slide_tuned_Qwen2.5-7B.py:174:22
(EngineCore_DP0 pid=499105) 	mul.lo.s32 	%r101, %r93, 10;
(EngineCore_DP0 pid=499105) 	.loc	1 174 30                        // quant_slide_tuned_Qwen2.5-7B.py:174:30
(EngineCore_DP0 pid=499105) 	shl.b32 	%r102, %r100, 1;
(EngineCore_DP0 pid=499105) 	shl.b32 	%r103, %r98, 1;
(EngineCore_DP0 pid=499105) 	.loc	1 174 26                        // quant_slide_tuned_Qwen2.5-7B.py:174:26
(EngineCore_DP0 pid=499105) 	add.s32 	%r104, %r101, %r103;
(EngineCore_DP0 pid=499105) 	add.s32 	%r105, %r101, %r102;
(EngineCore_DP0 pid=499105) 	.loc	1 177 53                        // quant_slide_tuned_Qwen2.5-7B.py:177:53
(EngineCore_DP0 pid=499105) 	setp.lt.s32 	%p18, %r105, %r23;
(EngineCore_DP0 pid=499105) 	setp.lt.s32 	%p19, %r104, %r23;
(EngineCore_DP0 pid=499105) 	.loc	1 177 37                        // quant_slide_tuned_Qwen2.5-7B.py:177:37
(EngineCore_DP0 pid=499105) 	and.pred 	%p9, %p17, %p18;
(EngineCore_DP0 pid=499105) 	and.pred 	%p10, %p17, %p19;
(EngineCore_DP0 pid=499105) 	.loc	1 176 29                        // quant_slide_tuned_Qwen2.5-7B.py:176:29
(EngineCore_DP0 pid=499105) 	mad.wide.s32 	%rd8, %r105, 2, %rd1;
(EngineCore_DP0 pid=499105) 	mad.wide.s32 	%rd9, %r104, 2, %rd1;
(EngineCore_DP0 pid=499105) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=499105) 	.loc	1 176 21                        // quant_slide_tuned_Qwen2.5-7B.py:176:21
(EngineCore_DP0 pid=499105) 	// begin inline asm
(EngineCore_DP0 pid=499105) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=499105) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=499105) 	// end inline asm
(EngineCore_DP0 pid=499105) 	// begin inline asm
(EngineCore_DP0 pid=499105) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=499105) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=499105) 	// end inline asm
(EngineCore_DP0 pid=499105) 	.loc	1 177 79                        // quant_slide_tuned_Qwen2.5-7B.py:177:79
(EngineCore_DP0 pid=499105) 	cvt.f32.bf16 	%r106, %rs24;
(EngineCore_DP0 pid=499105) 	cvt.f32.bf16 	%r107, %rs26;
(EngineCore_DP0 pid=499105) 	.loc	1 179 48                        // quant_slide_tuned_Qwen2.5-7B.py:179:48
(EngineCore_DP0 pid=499105) 	or.b32 	%r108, %r105, 1;
(EngineCore_DP0 pid=499105) 	or.b32 	%r109, %r104, 1;
(EngineCore_DP0 pid=499105) 	.loc	1 179 53                        // quant_slide_tuned_Qwen2.5-7B.py:179:53
(EngineCore_DP0 pid=499105) 	setp.lt.s32 	%p20, %r108, %r23;
(EngineCore_DP0 pid=499105) 	setp.lt.s32 	%p21, %r109, %r23;
(EngineCore_DP0 pid=499105) 	.loc	1 179 37                        // quant_slide_tuned_Qwen2.5-7B.py:179:37
(EngineCore_DP0 pid=499105) 	and.pred 	%p11, %p17, %p20;
(EngineCore_DP0 pid=499105) 	and.pred 	%p12, %p17, %p21;
(EngineCore_DP0 pid=499105) 	.loc	1 178 39                        // quant_slide_tuned_Qwen2.5-7B.py:178:39
(EngineCore_DP0 pid=499105) 	add.s64 	%rd10, %rd8, 2;
(EngineCore_DP0 pid=499105) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=499105) 	.loc	1 178 21                        // quant_slide_tuned_Qwen2.5-7B.py:178:21
(EngineCore_DP0 pid=499105) 	// begin inline asm
(EngineCore_DP0 pid=499105) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=499105) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=499105) 	// end inline asm
(EngineCore_DP0 pid=499105) 	// begin inline asm
(EngineCore_DP0 pid=499105) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=499105) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=499105) 	// end inline asm
(EngineCore_DP0 pid=499105) 	.loc	1 179 79                        // quant_slide_tuned_Qwen2.5-7B.py:179:79
(EngineCore_DP0 pid=499105) 	cvt.f32.bf16 	%r110, %rs28;
(EngineCore_DP0 pid=499105) 	cvt.f32.bf16 	%r111, %rs30;
(EngineCore_DP0 pid=499105) 	.loc	1 183 48                        // quant_slide_tuned_Qwen2.5-7B.py:183:48
(EngineCore_DP0 pid=499105) 	add.s32 	%r112, %r105, 2;
(EngineCore_DP0 pid=499105) 	add.s32 	%r113, %r104, 2;
(EngineCore_DP0 pid=499105) 	add.s32 	%r114, %r105, 3;
(EngineCore_DP0 pid=499105) 	add.s32 	%r115, %r104, 3;
(EngineCore_DP0 pid=499105) 	.loc	1 183 53                        // quant_slide_tuned_Qwen2.5-7B.py:183:53
(EngineCore_DP0 pid=499105) 	setp.lt.s32 	%p22, %r115, %r23;
(EngineCore_DP0 pid=499105) 	setp.lt.s32 	%p23, %r114, %r23;
(EngineCore_DP0 pid=499105) 	setp.lt.s32 	%p24, %r113, %r23;
(EngineCore_DP0 pid=499105) 	setp.lt.s32 	%p25, %r112, %r23;
(EngineCore_DP0 pid=499105) 	.loc	1 181 37                        // quant_slide_tuned_Qwen2.5-7B.py:181:37
(EngineCore_DP0 pid=499105) 	and.pred 	%p13, %p17, %p25;
(EngineCore_DP0 pid=499105) 	and.pred 	%p14, %p17, %p24;
(EngineCore_DP0 pid=499105) 	.loc	1 180 39                        // quant_slide_tuned_Qwen2.5-7B.py:180:39
(EngineCore_DP0 pid=499105) 	add.s64 	%rd12, %rd8, 4;
(EngineCore_DP0 pid=499105) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=499105) 	.loc	1 180 21                        // quant_slide_tuned_Qwen2.5-7B.py:180:21
(EngineCore_DP0 pid=499105) 	// begin inline asm
(EngineCore_DP0 pid=499105) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=499105) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=499105) 	// end inline asm
(EngineCore_DP0 pid=499105) 	// begin inline asm
(EngineCore_DP0 pid=499105) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=499105) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=499105) 	// end inline asm
(EngineCore_DP0 pid=499105) 	.loc	1 181 79                        // quant_slide_tuned_Qwen2.5-7B.py:181:79
(EngineCore_DP0 pid=499105) 	cvt.f32.bf16 	%r116, %rs32;
(EngineCore_DP0 pid=499105) 	cvt.f32.bf16 	%r117, %rs34;
(EngineCore_DP0 pid=499105) 	.loc	1 183 37                        // quant_slide_tuned_Qwen2.5-7B.py:183:37
(EngineCore_DP0 pid=499105) 	and.pred 	%p15, %p17, %p23;
(EngineCore_DP0 pid=499105) 	and.pred 	%p16, %p17, %p22;
(EngineCore_DP0 pid=499105) 	.loc	1 182 39                        // quant_slide_tuned_Qwen2.5-7B.py:182:39
(EngineCore_DP0 pid=499105) 	add.s64 	%rd14, %rd8, 6;
(EngineCore_DP0 pid=499105) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=499105) 	.loc	1 182 21                        // quant_slide_tuned_Qwen2.5-7B.py:182:21
(EngineCore_DP0 pid=499105) 	// begin inline asm
(EngineCore_DP0 pid=499105) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=499105) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=499105) 	// end inline asm
(EngineCore_DP0 pid=499105) 	// begin inline asm
(EngineCore_DP0 pid=499105) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=499105) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=499105) 	// end inline asm
(EngineCore_DP0 pid=499105) 	.loc	1 183 79                        // quant_slide_tuned_Qwen2.5-7B.py:183:79
(EngineCore_DP0 pid=499105) 	cvt.f32.bf16 	%r118, %rs36;
(EngineCore_DP0 pid=499105) 	cvt.f32.bf16 	%r119, %rs38;
(EngineCore_DP0 pid=499105) 	.loc	1 185 27                        // quant_slide_tuned_Qwen2.5-7B.py:185:27
(EngineCore_DP0 pid=499105) 	mul.f32 	%r120, %r14, %r106;
(EngineCore_DP0 pid=499105) 	mul.f32 	%r121, %r14, %r107;
(EngineCore_DP0 pid=499105) 	mov.b32 	%r122, 0f43E00000;
(EngineCore_DP0 pid=499105) 	.loc	1 185 48                        // quant_slide_tuned_Qwen2.5-7B.py:185:48
(EngineCore_DP0 pid=499105) 	min.xorsign.abs.f32 	%r78, %r120, %r122;
(EngineCore_DP0 pid=499105) 	min.xorsign.abs.f32 	%r79, %r121, %r122;
(EngineCore_DP0 pid=499105) 	.loc	1 185 60                        // quant_slide_tuned_Qwen2.5-7B.py:185:60
(EngineCore_DP0 pid=499105) 	// begin inline asm
(EngineCore_DP0 pid=499105) 	cvt.rn.satfinite.e4m3x2.f32  %rs40, %r79, %r78; 
(EngineCore_DP0 pid=499105) 
(EngineCore_DP0 pid=499105) 	// end inline asm
(EngineCore_DP0 pid=499105) 	shr.u16 	%rs44, %rs40, 8;
(EngineCore_DP0 pid=499105) 	.loc	1 186 27                        // quant_slide_tuned_Qwen2.5-7B.py:186:27
(EngineCore_DP0 pid=499105) 	mul.f32 	%r123, %r14, %r110;
(EngineCore_DP0 pid=499105) 	mul.f32 	%r124, %r14, %r111;
(EngineCore_DP0 pid=499105) 	.loc	1 186 48                        // quant_slide_tuned_Qwen2.5-7B.py:186:48
(EngineCore_DP0 pid=499105) 	min.xorsign.abs.f32 	%r80, %r123, %r122;
(EngineCore_DP0 pid=499105) 	min.xorsign.abs.f32 	%r81, %r124, %r122;
(EngineCore_DP0 pid=499105) 	.loc	1 186 60                        // quant_slide_tuned_Qwen2.5-7B.py:186:60
(EngineCore_DP0 pid=499105) 	// begin inline asm
(EngineCore_DP0 pid=499105) 	cvt.rn.satfinite.e4m3x2.f32  %rs41, %r81, %r80; 
(EngineCore_DP0 pid=499105) 
(EngineCore_DP0 pid=499105) 	// end inline asm
(EngineCore_DP0 pid=499105) 	shr.u16 	%rs45, %rs41, 8;
(EngineCore_DP0 pid=499105) 	.loc	1 187 27                        // quant_slide_tuned_Qwen2.5-7B.py:187:27
(EngineCore_DP0 pid=499105) 	mul.f32 	%r125, %r14, %r116;
(EngineCore_DP0 pid=499105) 	mul.f32 	%r126, %r14, %r117;
(EngineCore_DP0 pid=499105) 	.loc	1 187 48                        // quant_slide_tuned_Qwen2.5-7B.py:187:48
(EngineCore_DP0 pid=499105) 	min.xorsign.abs.f32 	%r82, %r125, %r122;
(EngineCore_DP0 pid=499105) 	min.xorsign.abs.f32 	%r83, %r126, %r122;
(EngineCore_DP0 pid=499105) 	.loc	1 187 60                        // quant_slide_tuned_Qwen2.5-7B.py:187:60
(EngineCore_DP0 pid=499105) 	// begin inline asm
(EngineCore_DP0 pid=499105) 	cvt.rn.satfinite.e4m3x2.f32  %rs42, %r83, %r82; 
(EngineCore_DP0 pid=499105) 
(EngineCore_DP0 pid=499105) 	// end inline asm
(EngineCore_DP0 pid=499105) 	shr.u16 	%rs46, %rs42, 8;
(EngineCore_DP0 pid=499105) 	.loc	1 188 27                        // quant_slide_tuned_Qwen2.5-7B.py:188:27
(EngineCore_DP0 pid=499105) 	mul.f32 	%r127, %r14, %r118;
(EngineCore_DP0 pid=499105) 	mul.f32 	%r128, %r14, %r119;
(EngineCore_DP0 pid=499105) 	.loc	1 188 48                        // quant_slide_tuned_Qwen2.5-7B.py:188:48
(EngineCore_DP0 pid=499105) 	min.xorsign.abs.f32 	%r84, %r127, %r122;
(EngineCore_DP0 pid=499105) 	min.xorsign.abs.f32 	%r85, %r128, %r122;
(EngineCore_DP0 pid=499105) 	.loc	1 188 60                        // quant_slide_tuned_Qwen2.5-7B.py:188:60
(EngineCore_DP0 pid=499105) 	// begin inline asm
(EngineCore_DP0 pid=499105) 	cvt.rn.satfinite.e4m3x2.f32  %rs43, %r85, %r84; 
(EngineCore_DP0 pid=499105) 
(EngineCore_DP0 pid=499105) 	// end inline asm
(EngineCore_DP0 pid=499105) 	shr.u16 	%rs47, %rs43, 8;
(EngineCore_DP0 pid=499105) 	.loc	1 190 45                        // quant_slide_tuned_Qwen2.5-7B.py:190:45
(EngineCore_DP0 pid=499105) 	cvt.u32.u16 	%r129, %rs40;
(EngineCore_DP0 pid=499105) 	and.b32 	%r130, %r129, 255;
(EngineCore_DP0 pid=499105) 	cvt.u32.u16 	%r131, %rs44;
(EngineCore_DP0 pid=499105) 	.loc	1 192 45                        // quant_slide_tuned_Qwen2.5-7B.py:192:45
(EngineCore_DP0 pid=499105) 	cvt.u32.u16 	%r132, %rs42;
(EngineCore_DP0 pid=499105) 	and.b32 	%r133, %r132, 255;
(EngineCore_DP0 pid=499105) 	cvt.u32.u16 	%r134, %rs46;
(EngineCore_DP0 pid=499105) 	.loc	1 193 45                        // quant_slide_tuned_Qwen2.5-7B.py:193:45
(EngineCore_DP0 pid=499105) 	cvt.u32.u16 	%r135, %rs43;
(EngineCore_DP0 pid=499105) 	cvt.u32.u16 	%r136, %rs47;
(EngineCore_DP0 pid=499105) 	.loc	1 195 30                        // quant_slide_tuned_Qwen2.5-7B.py:195:30
(EngineCore_DP0 pid=499105) 	and.b16 	%rs48, %rs41, 255;
(EngineCore_DP0 pid=499105) 	mul.wide.u16 	%r137, %rs48, 256;
(EngineCore_DP0 pid=499105) 	mul.wide.u16 	%r138, %rs45, 256;
(EngineCore_DP0 pid=499105) 	.loc	1 195 24                        // quant_slide_tuned_Qwen2.5-7B.py:195:24
(EngineCore_DP0 pid=499105) 	or.b32 	%r139, %r137, %r130;
(EngineCore_DP0 pid=499105) 	or.b32 	%r140, %r138, %r131;
(EngineCore_DP0 pid=499105) 	.loc	1 195 42                        // quant_slide_tuned_Qwen2.5-7B.py:195:42
(EngineCore_DP0 pid=499105) 	shl.b32 	%r141, %r133, 16;
(EngineCore_DP0 pid=499105) 	shl.b32 	%r142, %r134, 16;
(EngineCore_DP0 pid=499105) 	.loc	1 195 36                        // quant_slide_tuned_Qwen2.5-7B.py:195:36
(EngineCore_DP0 pid=499105) 	or.b32 	%r143, %r139, %r141;
(EngineCore_DP0 pid=499105) 	or.b32 	%r144, %r140, %r142;
(EngineCore_DP0 pid=499105) 	.loc	1 195 55                        // quant_slide_tuned_Qwen2.5-7B.py:195:55
(EngineCore_DP0 pid=499105) 	shl.b32 	%r145, %r135, 24;
(EngineCore_DP0 pid=499105) 	shl.b32 	%r146, %r136, 24;
(EngineCore_DP0 pid=499105) 	.loc	1 195 49                        // quant_slide_tuned_Qwen2.5-7B.py:195:49
(EngineCore_DP0 pid=499105) 	or.b32 	%r86, %r143, %r145;
(EngineCore_DP0 pid=499105) 	or.b32 	%r87, %r144, %r146;
(EngineCore_DP0 pid=499105) 	.loc	1 196 29                        // quant_slide_tuned_Qwen2.5-7B.py:196:29
(EngineCore_DP0 pid=499105) 	mad.wide.s32 	%rd16, %r88, 4, %rd2;
(EngineCore_DP0 pid=499105) 	.loc	1 196 39                        // quant_slide_tuned_Qwen2.5-7B.py:196:39
(EngineCore_DP0 pid=499105) 	// begin inline asm
(EngineCore_DP0 pid=499105) 	@%p17 st.global.v2.b32 [ %rd16 + 0 ], { %r86, %r87 };
(EngineCore_DP0 pid=499105) 	// end inline asm
(EngineCore_DP0 pid=499105) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=499105) 	add.s32 	%r150, %r150, 1024;
(EngineCore_DP0 pid=499105) 	setp.lt.s32 	%p26, %r150, %r15;
(EngineCore_DP0 pid=499105) 	@%p26 bra 	$L__BB0_6;
(EngineCore_DP0 pid=499105) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=499105) 	.loc	1 167 4                         // quant_slide_tuned_Qwen2.5-7B.py:167:4
(EngineCore_DP0 pid=499105) 	ret;
(EngineCore_DP0 pid=499105) $L__tmp3:
(EngineCore_DP0 pid=499105) $L__func_end0:
(EngineCore_DP0 pid=499105)                                         // -- End function
(EngineCore_DP0 pid=499105) }
(EngineCore_DP0 pid=499105) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py"
(EngineCore_DP0 pid=499105) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=499105) 	.section	.debug_abbrev
(EngineCore_DP0 pid=499105) 	{
(EngineCore_DP0 pid=499105) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=499105) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=499105) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=499105) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=499105) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=499105) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=499105) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=499105) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=499105) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=499105) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=499105) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=499105) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=499105) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=499105) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=499105) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=499105) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=499105) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=499105) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=499105) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=499105) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=499105) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=499105) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=499105) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=499105) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=499105) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=499105) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=499105) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=499105) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=499105) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=499105) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=499105) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=499105) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=499105) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=499105) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=499105) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=499105) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=499105) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=499105) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=499105) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=499105) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=499105) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=499105) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=499105) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=499105) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=499105) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=499105) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=499105) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=499105) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=499105) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=499105) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=499105) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=499105) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=499105) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=499105) 	}
(EngineCore_DP0 pid=499105) 	.section	.debug_info
(EngineCore_DP0 pid=499105) 	{
(EngineCore_DP0 pid=499105) .b32 221                                // Length of Unit
(EngineCore_DP0 pid=499105) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=499105) .b8 0
(EngineCore_DP0 pid=499105) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=499105) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=499105) .b8 1                                   // Abbrev [1] 0xb:0xd6 DW_TAG_compile_unit
(EngineCore_DP0 pid=499105) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=499105) .b8 114
(EngineCore_DP0 pid=499105) .b8 105
(EngineCore_DP0 pid=499105) .b8 116
(EngineCore_DP0 pid=499105) .b8 111
(EngineCore_DP0 pid=499105) .b8 110
(EngineCore_DP0 pid=499105) .b8 0
(EngineCore_DP0 pid=499105) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=499105) .b8 0
(EngineCore_DP0 pid=499105) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=499105) .b8 117
(EngineCore_DP0 pid=499105) .b8 97
(EngineCore_DP0 pid=499105) .b8 110
(EngineCore_DP0 pid=499105) .b8 116
(EngineCore_DP0 pid=499105) .b8 95
(EngineCore_DP0 pid=499105) .b8 115
(EngineCore_DP0 pid=499105) .b8 108
(EngineCore_DP0 pid=499105) .b8 105
(EngineCore_DP0 pid=499105) .b8 100
(EngineCore_DP0 pid=499105) .b8 101
(EngineCore_DP0 pid=499105) .b8 95
(EngineCore_DP0 pid=499105) .b8 116
(EngineCore_DP0 pid=499105) .b8 117
(EngineCore_DP0 pid=499105) .b8 110
(EngineCore_DP0 pid=499105) .b8 101
(EngineCore_DP0 pid=499105) .b8 100
(EngineCore_DP0 pid=499105) .b8 95
(EngineCore_DP0 pid=499105) .b8 81
(EngineCore_DP0 pid=499105) .b8 119
(EngineCore_DP0 pid=499105) .b8 101
(EngineCore_DP0 pid=499105) .b8 110
(EngineCore_DP0 pid=499105) .b8 50
(EngineCore_DP0 pid=499105) .b8 46
(EngineCore_DP0 pid=499105) .b8 53
(EngineCore_DP0 pid=499105) .b8 45
(EngineCore_DP0 pid=499105) .b8 55
(EngineCore_DP0 pid=499105) .b8 66
(EngineCore_DP0 pid=499105) .b8 46
(EngineCore_DP0 pid=499105) .b8 112
(EngineCore_DP0 pid=499105) .b8 121
(EngineCore_DP0 pid=499105) .b8 0
(EngineCore_DP0 pid=499105) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=499105) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=499105) .b8 114
(EngineCore_DP0 pid=499105) .b8 111
(EngineCore_DP0 pid=499105) .b8 111
(EngineCore_DP0 pid=499105) .b8 116
(EngineCore_DP0 pid=499105) .b8 47
(EngineCore_DP0 pid=499105) .b8 118
(EngineCore_DP0 pid=499105) .b8 108
(EngineCore_DP0 pid=499105) .b8 108
(EngineCore_DP0 pid=499105) .b8 109
(EngineCore_DP0 pid=499105) .b8 98
(EngineCore_DP0 pid=499105) .b8 101
(EngineCore_DP0 pid=499105) .b8 110
(EngineCore_DP0 pid=499105) .b8 99
(EngineCore_DP0 pid=499105) .b8 104
(EngineCore_DP0 pid=499105) .b8 47
(EngineCore_DP0 pid=499105) .b8 115
(EngineCore_DP0 pid=499105) .b8 108
(EngineCore_DP0 pid=499105) .b8 105
(EngineCore_DP0 pid=499105) .b8 100
(EngineCore_DP0 pid=499105) .b8 101
(EngineCore_DP0 pid=499105) .b8 115
(EngineCore_DP0 pid=499105) .b8 112
(EngineCore_DP0 pid=499105) .b8 97
(EngineCore_DP0 pid=499105) .b8 114
(EngineCore_DP0 pid=499105) .b8 115
(EngineCore_DP0 pid=499105) .b8 101
(EngineCore_DP0 pid=499105) .b8 47
(EngineCore_DP0 pid=499105) .b8 99
(EngineCore_DP0 pid=499105) .b8 115
(EngineCore_DP0 pid=499105) .b8 114
(EngineCore_DP0 pid=499105) .b8 99
(EngineCore_DP0 pid=499105) .b8 47
(EngineCore_DP0 pid=499105) .b8 102
(EngineCore_DP0 pid=499105) .b8 117
(EngineCore_DP0 pid=499105) .b8 115
(EngineCore_DP0 pid=499105) .b8 101
(EngineCore_DP0 pid=499105) .b8 100
(EngineCore_DP0 pid=499105) .b8 95
(EngineCore_DP0 pid=499105) .b8 113
(EngineCore_DP0 pid=499105) .b8 117
(EngineCore_DP0 pid=499105) .b8 97
(EngineCore_DP0 pid=499105) .b8 110
(EngineCore_DP0 pid=499105) .b8 116
(EngineCore_DP0 pid=499105) .b8 95
(EngineCore_DP0 pid=499105) .b8 115
(EngineCore_DP0 pid=499105) .b8 108
(EngineCore_DP0 pid=499105) .b8 105
(EngineCore_DP0 pid=499105) .b8 100
(EngineCore_DP0 pid=499105) .b8 101
(EngineCore_DP0 pid=499105) .b8 95
(EngineCore_DP0 pid=499105) .b8 116
(EngineCore_DP0 pid=499105) .b8 114
(EngineCore_DP0 pid=499105) .b8 105
(EngineCore_DP0 pid=499105) .b8 116
(EngineCore_DP0 pid=499105) .b8 111
(EngineCore_DP0 pid=499105) .b8 110
(EngineCore_DP0 pid=499105) .b8 47
(EngineCore_DP0 pid=499105) .b8 98
(EngineCore_DP0 pid=499105) .b8 117
(EngineCore_DP0 pid=499105) .b8 105
(EngineCore_DP0 pid=499105) .b8 108
(EngineCore_DP0 pid=499105) .b8 100
(EngineCore_DP0 pid=499105) .b8 47
(EngineCore_DP0 pid=499105) .b8 71
(EngineCore_DP0 pid=499105) .b8 66
(EngineCore_DP0 pid=499105) .b8 49
(EngineCore_DP0 pid=499105) .b8 48
(EngineCore_DP0 pid=499105) .b8 95
(EngineCore_DP0 pid=499105) .b8 99
(EngineCore_DP0 pid=499105) .b8 99
(EngineCore_DP0 pid=499105) .b8 49
(EngineCore_DP0 pid=499105) .b8 50
(EngineCore_DP0 pid=499105) .b8 49
(EngineCore_DP0 pid=499105) .b8 95
(EngineCore_DP0 pid=499105) .b8 112
(EngineCore_DP0 pid=499105) .b8 121
(EngineCore_DP0 pid=499105) .b8 51
(EngineCore_DP0 pid=499105) .b8 49
(EngineCore_DP0 pid=499105) .b8 50
(EngineCore_DP0 pid=499105) .b8 95
(EngineCore_DP0 pid=499105) .b8 99
(EngineCore_DP0 pid=499105) .b8 117
(EngineCore_DP0 pid=499105) .b8 49
(EngineCore_DP0 pid=499105) .b8 50
(EngineCore_DP0 pid=499105) .b8 57
(EngineCore_DP0 pid=499105) .b8 95
(EngineCore_DP0 pid=499105) .b8 97
(EngineCore_DP0 pid=499105) .b8 97
(EngineCore_DP0 pid=499105) .b8 114
(EngineCore_DP0 pid=499105) .b8 99
(EngineCore_DP0 pid=499105) .b8 104
(EngineCore_DP0 pid=499105) .b8 54
(EngineCore_DP0 pid=499105) .b8 52
(EngineCore_DP0 pid=499105) .b8 0
(EngineCore_DP0 pid=499105) .b8 2                                   // Abbrev [2] 0x98:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=499105) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=499105) .b8 113
(EngineCore_DP0 pid=499105) .b8 117
(EngineCore_DP0 pid=499105) .b8 97
(EngineCore_DP0 pid=499105) .b8 110
(EngineCore_DP0 pid=499105) .b8 116
(EngineCore_DP0 pid=499105) .b8 95
(EngineCore_DP0 pid=499105) .b8 115
(EngineCore_DP0 pid=499105) .b8 108
(EngineCore_DP0 pid=499105) .b8 105
(EngineCore_DP0 pid=499105) .b8 100
(EngineCore_DP0 pid=499105) .b8 101
(EngineCore_DP0 pid=499105) .b8 95
(EngineCore_DP0 pid=499105) .b8 102
(EngineCore_DP0 pid=499105) .b8 112
(EngineCore_DP0 pid=499105) .b8 56
(EngineCore_DP0 pid=499105) .b8 95
(EngineCore_DP0 pid=499105) .b8 107
(EngineCore_DP0 pid=499105) .b8 101
(EngineCore_DP0 pid=499105) .b8 114
(EngineCore_DP0 pid=499105) .b8 110
(EngineCore_DP0 pid=499105) .b8 101
(EngineCore_DP0 pid=499105) .b8 108
(EngineCore_DP0 pid=499105) .b8 0
(EngineCore_DP0 pid=499105) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=499105) .b8 3                                   // Abbrev [3] 0xb2:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=499105) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=499105) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=499105) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=499105) .b8 4                                   // Abbrev [4] 0xc7:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=499105) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=499105) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=499105) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=499105) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=499105) .b8 157                                 // DW_AT_call_line
(EngineCore_DP0 pid=499105) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=499105) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=499105) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=499105) 	}
(EngineCore_DP0 pid=499105) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=499105) 
(EngineCore_DP0 pid=499105) ================================================================
(EngineCore_DP0 pid=499105) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=499105) 
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp0ef_4zyh.ptx', '-o', '/tmp/tmp0ef_4zyh.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866] 
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866] 
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866] 
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp0ef_4zyh.ptx -o /tmp/tmp0ef_4zyh.ptx.o
(EngineCore_DP0 pid=499105) ERROR 01-25 21:51:08 [core.py:866] 

STDERR:
[2026-01-25 21:49:56] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:49:56] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:49:56] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:49:56] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:49:56] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:49:56] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:49:56] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:49:56] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:49:56] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:49:56] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:49:56] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:49:56] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:49:56] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:49:56] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:49:59] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:50:00] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:50:00] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:50:00] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:50:00] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:50:00] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:50:00] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:50:00] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:50:00] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:50:00] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:50:00] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:50:00] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:50:00] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:50:00] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=499105) [2026-01-25 21:50:00] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=499105) [2026-01-25 21:50:00] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=499105) [2026-01-25 21:50:00] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=499105) [2026-01-25 21:50:00] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=499105) [2026-01-25 21:50:00] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=499105) [2026-01-25 21:50:00] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=499105) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=499105) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:28<00:28, 28.09s/it]
(EngineCore_DP0 pid=499105) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:05<00:00, 33.36s/it]
(EngineCore_DP0 pid=499105) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:05<00:00, 32.57s/it]
(EngineCore_DP0 pid=499105) 
(EngineCore_DP0 pid=499105) [2026-01-25 21:51:07] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=499105) [2026-01-25 21:51:07] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16588800 bytes
(EngineCore_DP0 pid=499105) [2026-01-25 21:51:07] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=499105) [2026-01-25 21:51:07] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 12902400 bytes
(EngineCore_DP0 pid=499105) [2026-01-25 21:51:07] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=499105) [2026-01-25 21:51:07] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 136396800 bytes
(EngineCore_DP0 pid=499105) [2026-01-25 21:51:07] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=499105) [2026-01-25 21:51:07] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 67952640 bytes
(EngineCore_DP0 pid=499105) Process EngineCore_DP0:
(EngineCore_DP0 pid=499105) Traceback (most recent call last):
(EngineCore_DP0 pid=499105)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=499105)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=499105)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=499105)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=499105) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp0ef_4zyh.ptx', '-o', '/tmp/tmp0ef_4zyh.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=499105) 
(EngineCore_DP0 pid=499105) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=499105) 
(EngineCore_DP0 pid=499105) Traceback (most recent call last):
(EngineCore_DP0 pid=499105)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=499105)     self.run()
(EngineCore_DP0 pid=499105)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=499105)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=499105)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=499105)     raise e
(EngineCore_DP0 pid=499105)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=499105)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=499105)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=499105)     super().__init__(
(EngineCore_DP0 pid=499105)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=499105)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=499105)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=499105)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=499105)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=499105)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=499105)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=499105)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=499105)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=499105)     return func(*args, **kwargs)
(EngineCore_DP0 pid=499105)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=499105)     return func(*args, **kwargs)
(EngineCore_DP0 pid=499105)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=499105)     self.model_runner.profile_run()
(EngineCore_DP0 pid=499105)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=499105)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=499105)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=499105)     return func(*args, **kwargs)
(EngineCore_DP0 pid=499105)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=499105)     outputs = self.model(
(EngineCore_DP0 pid=499105)               ^^^^^^^^^^^
(EngineCore_DP0 pid=499105)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=499105)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=499105)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=499105)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=499105)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=499105)     hidden_states = self.model(
(EngineCore_DP0 pid=499105)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=499105)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=499105)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=499105)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=499105)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=499105)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=499105)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=499105)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=499105)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=499105)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=499105)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=499105)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=499105)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=499105)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=499105)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=499105)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=499105)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=499105)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=499105)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=499105)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=499105)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=499105)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=499105)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=499105)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=499105)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=499105)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=499105)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=499105)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=499105)     return self._linear_fn(
(EngineCore_DP0 pid=499105)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=499105)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=499105)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=499105)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=499105)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=499105)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=499105)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=499105)     return fn(input, L)
(EngineCore_DP0 pid=499105)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=499105)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=499105)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=499105)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=499105)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=499105)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=499105)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=499105)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=499105)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=499105)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=499105)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=499105)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=499105)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=499105)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=499105)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=499105)     raise PTXASError(error)
(EngineCore_DP0 pid=499105) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=499105) `ptxas` stderr:
(EngineCore_DP0 pid=499105) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=499105) 
(EngineCore_DP0 pid=499105) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp0ef_4zyh.ptx -o /tmp/tmp0ef_4zyh.ptx.o
(EngineCore_DP0 pid=499105) 
[rank0]:[W125 21:51:08.849735250 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=4096

========== M=8192 ==========
Time: 2026-01-25 21:51:10
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Qwen2.5-7B-FP8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:51:17 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 21:51:17 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=500415) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=500415) 
(EngineCore_DP0 pid=500415) 
(EngineCore_DP0 pid=500415) ================================================================
(EngineCore_DP0 pid=500415) Internal Triton PTX codegen error
(EngineCore_DP0 pid=500415) `ptxas` stderr:
(EngineCore_DP0 pid=500415) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=500415) 
(EngineCore_DP0 pid=500415) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpyn1c0t49.ptx -o /tmp/tmpyn1c0t49.ptx.o
(EngineCore_DP0 pid=500415) 
(EngineCore_DP0 pid=500415) 
(EngineCore_DP0 pid=500415) //
(EngineCore_DP0 pid=500415) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=500415) //
(EngineCore_DP0 pid=500415) 
(EngineCore_DP0 pid=500415) .version 8.7
(EngineCore_DP0 pid=500415) .target sm_121a
(EngineCore_DP0 pid=500415) .address_size 64
(EngineCore_DP0 pid=500415) 
(EngineCore_DP0 pid=500415) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=500415) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=500415)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=500415) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=500415) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=500415) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=500415) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=500415) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=500415) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=500415) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=500415) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=500415) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=500415) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=500415) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=500415) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=500415) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=500415) )
(EngineCore_DP0 pid=500415) .reqntid 512
(EngineCore_DP0 pid=500415) {
(EngineCore_DP0 pid=500415) 	.reg .pred 	%p<29>;
(EngineCore_DP0 pid=500415) 	.reg .b16 	%rs<73>;
(EngineCore_DP0 pid=500415) 	.reg .b32 	%r<160>;
(EngineCore_DP0 pid=500415) 	.reg .b64 	%rd<18>;
(EngineCore_DP0 pid=500415) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=500415) $L__func_begin0:
(EngineCore_DP0 pid=500415) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=500415) 
(EngineCore_DP0 pid=500415) // %bb.0:
(EngineCore_DP0 pid=500415) 	ld.param.b32 	%r25, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=500415) 	ld.param.b32 	%r24, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=500415) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=500415) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=500415) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=500415) $L__tmp0:
(EngineCore_DP0 pid=500415) 	.loc	1 143 24                        // quant_slide_tuned_Qwen2.5-7B.py:143:24
(EngineCore_DP0 pid=500415) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=500415) 	ld.param.b32 	%r27, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=500415) 	.loc	1 148 26                        // quant_slide_tuned_Qwen2.5-7B.py:148:26
(EngineCore_DP0 pid=500415) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=500415) 	.loc	1 148 20                        // quant_slide_tuned_Qwen2.5-7B.py:148:20
(EngineCore_DP0 pid=500415) 	mad.wide.s32 	%rd1, %r28, 2, %rd4;
(EngineCore_DP0 pid=500415) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=500415) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=500415) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=500415) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=500415) 	setp.lt.s32 	%p1, %r24, 1;
(EngineCore_DP0 pid=500415) 	mov.b32 	%r158, 0f2B8CBCCC;
(EngineCore_DP0 pid=500415) 	setp.eq.b32 	%p28, %r2, 0;
(EngineCore_DP0 pid=500415) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=500415) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=500415) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=500415) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=500415) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=500415) 	shr.u32 	%r37, %r2, 3;
(EngineCore_DP0 pid=500415) 	and.b32 	%r38, %r37, 60;
(EngineCore_DP0 pid=500415) 	mov.b32 	%r39, global_smem;
(EngineCore_DP0 pid=500415) 	add.s32 	%r57, %r39, %r38;
(EngineCore_DP0 pid=500415) 	shl.b32 	%r40, %r2, 2;
(EngineCore_DP0 pid=500415) 	add.s32 	%r60, %r39, %r40;
(EngineCore_DP0 pid=500415) 	mov.b32 	%r45, 0;
(EngineCore_DP0 pid=500415) 	mov.b32 	%r156, 0f00000000;
(EngineCore_DP0 pid=500415) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=500415) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=500415) 	mov.b32 	%r157, %r45;
(EngineCore_DP0 pid=500415) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=500415) 	.loc	1 154 19                        // quant_slide_tuned_Qwen2.5-7B.py:154:19
(EngineCore_DP0 pid=500415) 	add.s32 	%r63, %r4, %r157;
(EngineCore_DP0 pid=500415) 	.loc	1 155 22                        // quant_slide_tuned_Qwen2.5-7B.py:155:22
(EngineCore_DP0 pid=500415) 	add.s32 	%r64, %r63, 4096;
(EngineCore_DP0 pid=500415) 	setp.lt.s32 	%p2, %r63, %r23;
(EngineCore_DP0 pid=500415) 	setp.lt.s32 	%p3, %r64, %r23;
(EngineCore_DP0 pid=500415) 	.loc	1 156 29                        // quant_slide_tuned_Qwen2.5-7B.py:156:29
(EngineCore_DP0 pid=500415) 	mad.wide.s32 	%rd6, %r63, 2, %rd1;
(EngineCore_DP0 pid=500415) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=500415) 	.loc	1 156 21                        // quant_slide_tuned_Qwen2.5-7B.py:156:21
(EngineCore_DP0 pid=500415) 	// begin inline asm
(EngineCore_DP0 pid=500415) 	mov.u32 %r41, %r45;
(EngineCore_DP0 pid=500415) 	mov.u32 %r42, %r45;
(EngineCore_DP0 pid=500415) 	mov.u32 %r43, %r45;
(EngineCore_DP0 pid=500415) 	mov.u32 %r44, %r45;
(EngineCore_DP0 pid=500415) 	@%p2 ld.global.v4.b32 { %r41, %r42, %r43, %r44 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=500415) 	// end inline asm
(EngineCore_DP0 pid=500415) 	mov.b32 	{%rs1, %rs2}, %r41;
(EngineCore_DP0 pid=500415) 	mov.b32 	{%rs3, %rs4}, %r42;
(EngineCore_DP0 pid=500415) 	mov.b32 	{%rs5, %rs6}, %r43;
(EngineCore_DP0 pid=500415) 	mov.b32 	{%rs7, %rs8}, %r44;
(EngineCore_DP0 pid=500415) 	// begin inline asm
(EngineCore_DP0 pid=500415) 	mov.u32 %r49, %r45;
(EngineCore_DP0 pid=500415) 	mov.u32 %r50, %r45;
(EngineCore_DP0 pid=500415) 	mov.u32 %r51, %r45;
(EngineCore_DP0 pid=500415) 	mov.u32 %r52, %r45;
(EngineCore_DP0 pid=500415) 	@%p3 ld.global.v4.b32 { %r49, %r50, %r51, %r52 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=500415) 	// end inline asm
(EngineCore_DP0 pid=500415) 	mov.b32 	{%rs9, %rs10}, %r49;
(EngineCore_DP0 pid=500415) 	mov.b32 	{%rs11, %rs12}, %r50;
(EngineCore_DP0 pid=500415) 	mov.b32 	{%rs13, %rs14}, %r51;
(EngineCore_DP0 pid=500415) 	mov.b32 	{%rs15, %rs16}, %r52;
(EngineCore_DP0 pid=500415) 	.loc	1 157 50                        // quant_slide_tuned_Qwen2.5-7B.py:157:50
(EngineCore_DP0 pid=500415) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=500415) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=500415) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=500415) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=500415) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=500415) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=500415) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=500415) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=500415) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=500415) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=500415) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=500415) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=500415) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=500415) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=500415) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=500415) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=500415) $L__tmp1:
(EngineCore_DP0 pid=500415) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=500415) 	bar.sync 	0;
(EngineCore_DP0 pid=500415) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=500415) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=500415) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=500415) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=500415) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=500415) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=500415) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=500415) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=500415) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=500415) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=500415) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=500415) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=500415) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=500415) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=500415) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=500415) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=500415) 	cvt.f32.bf16 	%r65, %rs47;
(EngineCore_DP0 pid=500415) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=500415) 	shfl.sync.bfly.b32 	%r66, %r65, 16, 31, -1;
(EngineCore_DP0 pid=500415) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=500415) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=500415) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=500415) 	shfl.sync.bfly.b32 	%r68, %r67, 8, 31, -1;
(EngineCore_DP0 pid=500415) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=500415) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=500415) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=500415) 	shfl.sync.bfly.b32 	%r70, %r69, 4, 31, -1;
(EngineCore_DP0 pid=500415) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=500415) 	max.f32 	%r71, %r69, %r70;
(EngineCore_DP0 pid=500415) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=500415) 	shfl.sync.bfly.b32 	%r72, %r71, 2, 31, -1;
(EngineCore_DP0 pid=500415) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=500415) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=500415) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=500415) 	shfl.sync.bfly.b32 	%r74, %r73, 1, 31, -1;
(EngineCore_DP0 pid=500415) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=500415) 	max.f32 	%r58, %r73, %r74;
(EngineCore_DP0 pid=500415) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=500415) 	// begin inline asm
(EngineCore_DP0 pid=500415) 	@%p4 st.shared.b32 [ %r57 + 0 ], %r58;
(EngineCore_DP0 pid=500415) 	// end inline asm
(EngineCore_DP0 pid=500415) 	bar.sync 	0;
(EngineCore_DP0 pid=500415) 	// begin inline asm
(EngineCore_DP0 pid=500415) 	@%p5 ld.shared.b32 %r59, [ %r60 + 0 ];
(EngineCore_DP0 pid=500415) 	// end inline asm
(EngineCore_DP0 pid=500415) 	shfl.sync.bfly.b32 	%r75, %r59, 8, 31, -1;
(EngineCore_DP0 pid=500415) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=500415) 	max.f32 	%r76, %r59, %r75;
(EngineCore_DP0 pid=500415) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=500415) 	shfl.sync.bfly.b32 	%r77, %r76, 4, 31, -1;
(EngineCore_DP0 pid=500415) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=500415) 	max.f32 	%r78, %r76, %r77;
(EngineCore_DP0 pid=500415) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=500415) 	shfl.sync.bfly.b32 	%r79, %r78, 2, 31, -1;
(EngineCore_DP0 pid=500415) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=500415) 	max.f32 	%r80, %r78, %r79;
(EngineCore_DP0 pid=500415) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=500415) 	shfl.sync.bfly.b32 	%r81, %r80, 1, 31, -1;
(EngineCore_DP0 pid=500415) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=500415) 	max.f32 	%r62, %r80, %r81;
(EngineCore_DP0 pid=500415) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=500415) 	// begin inline asm
(EngineCore_DP0 pid=500415) 	@%p28 st.shared.b32 [ %r60 + 0 ], %r62;
(EngineCore_DP0 pid=500415) 	// end inline asm
(EngineCore_DP0 pid=500415) 	bar.sync 	0;
(EngineCore_DP0 pid=500415) 	ld.shared.b32 	%r82, [global_smem];
(EngineCore_DP0 pid=500415) $L__tmp2:
(EngineCore_DP0 pid=500415) 	.loc	1 157 36                        // quant_slide_tuned_Qwen2.5-7B.py:157:36
(EngineCore_DP0 pid=500415) 	max.f32 	%r156, %r156, %r82;
(EngineCore_DP0 pid=500415) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=500415) 	add.s32 	%r157, %r157, 8192;
(EngineCore_DP0 pid=500415) 	setp.lt.s32 	%p7, %r157, %r24;
(EngineCore_DP0 pid=500415) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=500415) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=500415) 	.loc	1 159 32                        // quant_slide_tuned_Qwen2.5-7B.py:159:32
(EngineCore_DP0 pid=500415) 	max.f32 	%r158, %r156, 0f2B8CBCCC;
(EngineCore_DP0 pid=500415) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=500415) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-7B.py:0:32
(EngineCore_DP0 pid=500415) 	mov.b32 	%r84, 0f43E00000;
(EngineCore_DP0 pid=500415) 	.loc	1 160 32                        // quant_slide_tuned_Qwen2.5-7B.py:160:32
(EngineCore_DP0 pid=500415) 	div.full.f32 	%r85, %r158, %r84;
(EngineCore_DP0 pid=500415) 	.loc	1 160 41                        // quant_slide_tuned_Qwen2.5-7B.py:160:41
(EngineCore_DP0 pid=500415) 	max.f32 	%r83, %r85, 0f36924925;
(EngineCore_DP0 pid=500415) 	.loc	1 162 25                        // quant_slide_tuned_Qwen2.5-7B.py:162:25
(EngineCore_DP0 pid=500415) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=500415) 	.loc	1 162 30                        // quant_slide_tuned_Qwen2.5-7B.py:162:30
(EngineCore_DP0 pid=500415) 	// begin inline asm
(EngineCore_DP0 pid=500415) 	@%p28 st.global.b32 [ %rd8 + 0 ], { %r83 };
(EngineCore_DP0 pid=500415) 	// end inline asm
(EngineCore_DP0 pid=500415) 	.loc	1 165 29                        // quant_slide_tuned_Qwen2.5-7B.py:165:29
(EngineCore_DP0 pid=500415) 	shl.b32 	%r15, %r25, 2;
(EngineCore_DP0 pid=500415) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=500415) 	setp.lt.s32 	%p9, %r15, 1;
(EngineCore_DP0 pid=500415) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=500415) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=500415) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-7B.py:0:41
(EngineCore_DP0 pid=500415) 	ld.param.b32 	%r29, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=500415) 	shr.s32 	%r30, %r29, 31;
(EngineCore_DP0 pid=500415) 	shr.u32 	%r31, %r30, 30;
(EngineCore_DP0 pid=500415) 	add.s32 	%r32, %r29, %r31;
(EngineCore_DP0 pid=500415) 	shr.s32 	%r33, %r32, 2;
(EngineCore_DP0 pid=500415) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=500415) 	mul.lo.s32 	%r34, %r33, %r1;
(EngineCore_DP0 pid=500415) 	mad.wide.s32 	%rd2, %r34, 4, %rd5;
(EngineCore_DP0 pid=500415) 	div.full.f32 	%r14, %r84, %r158;
(EngineCore_DP0 pid=500415) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=500415) 	mov.b32 	%r159, 0;
(EngineCore_DP0 pid=500415) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=500415)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=500415) 	.loc	1 168 31                        // quant_slide_tuned_Qwen2.5-7B.py:168:31
(EngineCore_DP0 pid=500415) 	add.s32 	%r97, %r16, %r159;
(EngineCore_DP0 pid=500415) 	.loc	1 169 30                        // quant_slide_tuned_Qwen2.5-7B.py:169:30
(EngineCore_DP0 pid=500415) 	add.s32 	%r98, %r97, 1;
(EngineCore_DP0 pid=500415) 	setp.lt.s32 	%p18, %r97, %r15;
(EngineCore_DP0 pid=500415) 	.loc	1 172 24                        // quant_slide_tuned_Qwen2.5-7B.py:172:24
(EngineCore_DP0 pid=500415) 	shr.s32 	%r99, %r97, 31;
(EngineCore_DP0 pid=500415) 	shr.u32 	%r100, %r99, 30;
(EngineCore_DP0 pid=500415) 	add.s32 	%r101, %r97, %r100;
(EngineCore_DP0 pid=500415) 	shr.s32 	%r102, %r101, 2;
(EngineCore_DP0 pid=500415) 	.loc	1 173 23                        // quant_slide_tuned_Qwen2.5-7B.py:173:23
(EngineCore_DP0 pid=500415) 	shr.s32 	%r103, %r98, 31;
(EngineCore_DP0 pid=500415) 	shr.u32 	%r104, %r103, 30;
(EngineCore_DP0 pid=500415) 	add.s32 	%r105, %r98, %r104;
(EngineCore_DP0 pid=500415) 	and.b32 	%r106, %r105, 2147483644;
(EngineCore_DP0 pid=500415) 	sub.s32 	%r107, %r98, %r106;
(EngineCore_DP0 pid=500415) 	and.b32 	%r108, %r101, 2147483644;
(EngineCore_DP0 pid=500415) 	sub.s32 	%r109, %r97, %r108;
(EngineCore_DP0 pid=500415) 	.loc	1 174 22                        // quant_slide_tuned_Qwen2.5-7B.py:174:22
(EngineCore_DP0 pid=500415) 	mul.lo.s32 	%r110, %r102, 10;
(EngineCore_DP0 pid=500415) 	.loc	1 174 30                        // quant_slide_tuned_Qwen2.5-7B.py:174:30
(EngineCore_DP0 pid=500415) 	shl.b32 	%r111, %r109, 1;
(EngineCore_DP0 pid=500415) 	shl.b32 	%r112, %r107, 1;
(EngineCore_DP0 pid=500415) 	.loc	1 174 26                        // quant_slide_tuned_Qwen2.5-7B.py:174:26
(EngineCore_DP0 pid=500415) 	add.s32 	%r113, %r110, %r112;
(EngineCore_DP0 pid=500415) 	add.s32 	%r114, %r110, %r111;
(EngineCore_DP0 pid=500415) 	.loc	1 177 53                        // quant_slide_tuned_Qwen2.5-7B.py:177:53
(EngineCore_DP0 pid=500415) 	setp.lt.s32 	%p19, %r114, %r23;
(EngineCore_DP0 pid=500415) 	setp.lt.s32 	%p20, %r113, %r23;
(EngineCore_DP0 pid=500415) 	.loc	1 177 37                        // quant_slide_tuned_Qwen2.5-7B.py:177:37
(EngineCore_DP0 pid=500415) 	and.pred 	%p10, %p18, %p19;
(EngineCore_DP0 pid=500415) 	and.pred 	%p11, %p18, %p20;
(EngineCore_DP0 pid=500415) 	.loc	1 176 29                        // quant_slide_tuned_Qwen2.5-7B.py:176:29
(EngineCore_DP0 pid=500415) 	mad.wide.s32 	%rd9, %r114, 2, %rd1;
(EngineCore_DP0 pid=500415) 	mad.wide.s32 	%rd10, %r113, 2, %rd1;
(EngineCore_DP0 pid=500415) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=500415) 	.loc	1 176 21                        // quant_slide_tuned_Qwen2.5-7B.py:176:21
(EngineCore_DP0 pid=500415) 	// begin inline asm
(EngineCore_DP0 pid=500415) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=500415) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=500415) 	// end inline asm
(EngineCore_DP0 pid=500415) 	// begin inline asm
(EngineCore_DP0 pid=500415) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=500415) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=500415) 	// end inline asm
(EngineCore_DP0 pid=500415) 	.loc	1 177 79                        // quant_slide_tuned_Qwen2.5-7B.py:177:79
(EngineCore_DP0 pid=500415) 	cvt.f32.bf16 	%r115, %rs48;
(EngineCore_DP0 pid=500415) 	cvt.f32.bf16 	%r116, %rs50;
(EngineCore_DP0 pid=500415) 	.loc	1 179 48                        // quant_slide_tuned_Qwen2.5-7B.py:179:48
(EngineCore_DP0 pid=500415) 	or.b32 	%r117, %r114, 1;
(EngineCore_DP0 pid=500415) 	or.b32 	%r118, %r113, 1;
(EngineCore_DP0 pid=500415) 	.loc	1 179 53                        // quant_slide_tuned_Qwen2.5-7B.py:179:53
(EngineCore_DP0 pid=500415) 	setp.lt.s32 	%p21, %r117, %r23;
(EngineCore_DP0 pid=500415) 	setp.lt.s32 	%p22, %r118, %r23;
(EngineCore_DP0 pid=500415) 	.loc	1 179 37                        // quant_slide_tuned_Qwen2.5-7B.py:179:37
(EngineCore_DP0 pid=500415) 	and.pred 	%p12, %p18, %p21;
(EngineCore_DP0 pid=500415) 	and.pred 	%p13, %p18, %p22;
(EngineCore_DP0 pid=500415) 	.loc	1 178 39                        // quant_slide_tuned_Qwen2.5-7B.py:178:39
(EngineCore_DP0 pid=500415) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=500415) 	add.s64 	%rd12, %rd10, 2;
(EngineCore_DP0 pid=500415) 	.loc	1 178 21                        // quant_slide_tuned_Qwen2.5-7B.py:178:21
(EngineCore_DP0 pid=500415) 	// begin inline asm
(EngineCore_DP0 pid=500415) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=500415) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=500415) 	// end inline asm
(EngineCore_DP0 pid=500415) 	// begin inline asm
(EngineCore_DP0 pid=500415) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=500415) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=500415) 	// end inline asm
(EngineCore_DP0 pid=500415) 	.loc	1 179 79                        // quant_slide_tuned_Qwen2.5-7B.py:179:79
(EngineCore_DP0 pid=500415) 	cvt.f32.bf16 	%r119, %rs52;
(EngineCore_DP0 pid=500415) 	cvt.f32.bf16 	%r120, %rs54;
(EngineCore_DP0 pid=500415) 	.loc	1 183 48                        // quant_slide_tuned_Qwen2.5-7B.py:183:48
(EngineCore_DP0 pid=500415) 	add.s32 	%r121, %r114, 2;
(EngineCore_DP0 pid=500415) 	add.s32 	%r122, %r113, 2;
(EngineCore_DP0 pid=500415) 	add.s32 	%r123, %r114, 3;
(EngineCore_DP0 pid=500415) 	add.s32 	%r124, %r113, 3;
(EngineCore_DP0 pid=500415) 	.loc	1 183 53                        // quant_slide_tuned_Qwen2.5-7B.py:183:53
(EngineCore_DP0 pid=500415) 	setp.lt.s32 	%p23, %r124, %r23;
(EngineCore_DP0 pid=500415) 	setp.lt.s32 	%p24, %r123, %r23;
(EngineCore_DP0 pid=500415) 	setp.lt.s32 	%p25, %r122, %r23;
(EngineCore_DP0 pid=500415) 	setp.lt.s32 	%p26, %r121, %r23;
(EngineCore_DP0 pid=500415) 	.loc	1 181 37                        // quant_slide_tuned_Qwen2.5-7B.py:181:37
(EngineCore_DP0 pid=500415) 	and.pred 	%p14, %p18, %p26;
(EngineCore_DP0 pid=500415) 	and.pred 	%p15, %p18, %p25;
(EngineCore_DP0 pid=500415) 	.loc	1 180 39                        // quant_slide_tuned_Qwen2.5-7B.py:180:39
(EngineCore_DP0 pid=500415) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=500415) 	add.s64 	%rd14, %rd10, 4;
(EngineCore_DP0 pid=500415) 	.loc	1 180 21                        // quant_slide_tuned_Qwen2.5-7B.py:180:21
(EngineCore_DP0 pid=500415) 	// begin inline asm
(EngineCore_DP0 pid=500415) 	mov.u16 %rs56, %rs49;
(EngineCore_DP0 pid=500415) 	@%p14 ld.global.b16 { %rs56 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=500415) 	// end inline asm
(EngineCore_DP0 pid=500415) 	// begin inline asm
(EngineCore_DP0 pid=500415) 	mov.u16 %rs58, %rs49;
(EngineCore_DP0 pid=500415) 	@%p15 ld.global.b16 { %rs58 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=500415) 	// end inline asm
(EngineCore_DP0 pid=500415) 	.loc	1 181 79                        // quant_slide_tuned_Qwen2.5-7B.py:181:79
(EngineCore_DP0 pid=500415) 	cvt.f32.bf16 	%r125, %rs56;
(EngineCore_DP0 pid=500415) 	cvt.f32.bf16 	%r126, %rs58;
(EngineCore_DP0 pid=500415) 	.loc	1 183 37                        // quant_slide_tuned_Qwen2.5-7B.py:183:37
(EngineCore_DP0 pid=500415) 	and.pred 	%p16, %p18, %p24;
(EngineCore_DP0 pid=500415) 	and.pred 	%p17, %p18, %p23;
(EngineCore_DP0 pid=500415) 	.loc	1 182 39                        // quant_slide_tuned_Qwen2.5-7B.py:182:39
(EngineCore_DP0 pid=500415) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=500415) 	add.s64 	%rd16, %rd10, 6;
(EngineCore_DP0 pid=500415) 	.loc	1 182 21                        // quant_slide_tuned_Qwen2.5-7B.py:182:21
(EngineCore_DP0 pid=500415) 	// begin inline asm
(EngineCore_DP0 pid=500415) 	mov.u16 %rs60, %rs49;
(EngineCore_DP0 pid=500415) 	@%p16 ld.global.b16 { %rs60 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=500415) 	// end inline asm
(EngineCore_DP0 pid=500415) 	// begin inline asm
(EngineCore_DP0 pid=500415) 	mov.u16 %rs62, %rs49;
(EngineCore_DP0 pid=500415) 	@%p17 ld.global.b16 { %rs62 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=500415) 	// end inline asm
(EngineCore_DP0 pid=500415) 	.loc	1 183 79                        // quant_slide_tuned_Qwen2.5-7B.py:183:79
(EngineCore_DP0 pid=500415) 	cvt.f32.bf16 	%r127, %rs60;
(EngineCore_DP0 pid=500415) 	cvt.f32.bf16 	%r128, %rs62;
(EngineCore_DP0 pid=500415) 	.loc	1 185 27                        // quant_slide_tuned_Qwen2.5-7B.py:185:27
(EngineCore_DP0 pid=500415) 	mul.f32 	%r129, %r14, %r115;
(EngineCore_DP0 pid=500415) 	mul.f32 	%r130, %r14, %r116;
(EngineCore_DP0 pid=500415) 	mov.b32 	%r131, 0f43E00000;
(EngineCore_DP0 pid=500415) 	.loc	1 185 48                        // quant_slide_tuned_Qwen2.5-7B.py:185:48
(EngineCore_DP0 pid=500415) 	min.xorsign.abs.f32 	%r87, %r129, %r131;
(EngineCore_DP0 pid=500415) 	min.xorsign.abs.f32 	%r88, %r130, %r131;
(EngineCore_DP0 pid=500415) 	.loc	1 185 60                        // quant_slide_tuned_Qwen2.5-7B.py:185:60
(EngineCore_DP0 pid=500415) 	// begin inline asm
(EngineCore_DP0 pid=500415) 	cvt.rn.satfinite.e4m3x2.f32  %rs64, %r88, %r87; 
(EngineCore_DP0 pid=500415) 
(EngineCore_DP0 pid=500415) 	// end inline asm
(EngineCore_DP0 pid=500415) 	shr.u16 	%rs68, %rs64, 8;
(EngineCore_DP0 pid=500415) 	.loc	1 186 27                        // quant_slide_tuned_Qwen2.5-7B.py:186:27
(EngineCore_DP0 pid=500415) 	mul.f32 	%r132, %r14, %r119;
(EngineCore_DP0 pid=500415) 	mul.f32 	%r133, %r14, %r120;
(EngineCore_DP0 pid=500415) 	.loc	1 186 48                        // quant_slide_tuned_Qwen2.5-7B.py:186:48
(EngineCore_DP0 pid=500415) 	min.xorsign.abs.f32 	%r89, %r132, %r131;
(EngineCore_DP0 pid=500415) 	min.xorsign.abs.f32 	%r90, %r133, %r131;
(EngineCore_DP0 pid=500415) 	.loc	1 186 60                        // quant_slide_tuned_Qwen2.5-7B.py:186:60
(EngineCore_DP0 pid=500415) 	// begin inline asm
(EngineCore_DP0 pid=500415) 	cvt.rn.satfinite.e4m3x2.f32  %rs65, %r90, %r89; 
(EngineCore_DP0 pid=500415) 
(EngineCore_DP0 pid=500415) 	// end inline asm
(EngineCore_DP0 pid=500415) 	shr.u16 	%rs69, %rs65, 8;
(EngineCore_DP0 pid=500415) 	.loc	1 187 27                        // quant_slide_tuned_Qwen2.5-7B.py:187:27
(EngineCore_DP0 pid=500415) 	mul.f32 	%r134, %r14, %r125;
(EngineCore_DP0 pid=500415) 	mul.f32 	%r135, %r14, %r126;
(EngineCore_DP0 pid=500415) 	.loc	1 187 48                        // quant_slide_tuned_Qwen2.5-7B.py:187:48
(EngineCore_DP0 pid=500415) 	min.xorsign.abs.f32 	%r91, %r134, %r131;
(EngineCore_DP0 pid=500415) 	min.xorsign.abs.f32 	%r92, %r135, %r131;
(EngineCore_DP0 pid=500415) 	.loc	1 187 60                        // quant_slide_tuned_Qwen2.5-7B.py:187:60
(EngineCore_DP0 pid=500415) 	// begin inline asm
(EngineCore_DP0 pid=500415) 	cvt.rn.satfinite.e4m3x2.f32  %rs66, %r92, %r91; 
(EngineCore_DP0 pid=500415) 
(EngineCore_DP0 pid=500415) 	// end inline asm
(EngineCore_DP0 pid=500415) 	shr.u16 	%rs70, %rs66, 8;
(EngineCore_DP0 pid=500415) 	.loc	1 188 27                        // quant_slide_tuned_Qwen2.5-7B.py:188:27
(EngineCore_DP0 pid=500415) 	mul.f32 	%r136, %r14, %r127;
(EngineCore_DP0 pid=500415) 	mul.f32 	%r137, %r14, %r128;
(EngineCore_DP0 pid=500415) 	.loc	1 188 48                        // quant_slide_tuned_Qwen2.5-7B.py:188:48
(EngineCore_DP0 pid=500415) 	min.xorsign.abs.f32 	%r93, %r136, %r131;
(EngineCore_DP0 pid=500415) 	min.xorsign.abs.f32 	%r94, %r137, %r131;
(EngineCore_DP0 pid=500415) 	.loc	1 188 60                        // quant_slide_tuned_Qwen2.5-7B.py:188:60
(EngineCore_DP0 pid=500415) 	// begin inline asm
(EngineCore_DP0 pid=500415) 	cvt.rn.satfinite.e4m3x2.f32  %rs67, %r94, %r93; 
(EngineCore_DP0 pid=500415) 
(EngineCore_DP0 pid=500415) 	// end inline asm
(EngineCore_DP0 pid=500415) 	shr.u16 	%rs71, %rs67, 8;
(EngineCore_DP0 pid=500415) 	.loc	1 190 45                        // quant_slide_tuned_Qwen2.5-7B.py:190:45
(EngineCore_DP0 pid=500415) 	cvt.u32.u16 	%r138, %rs64;
(EngineCore_DP0 pid=500415) 	and.b32 	%r139, %r138, 255;
(EngineCore_DP0 pid=500415) 	cvt.u32.u16 	%r140, %rs68;
(EngineCore_DP0 pid=500415) 	.loc	1 192 45                        // quant_slide_tuned_Qwen2.5-7B.py:192:45
(EngineCore_DP0 pid=500415) 	cvt.u32.u16 	%r141, %rs66;
(EngineCore_DP0 pid=500415) 	and.b32 	%r142, %r141, 255;
(EngineCore_DP0 pid=500415) 	cvt.u32.u16 	%r143, %rs70;
(EngineCore_DP0 pid=500415) 	.loc	1 193 45                        // quant_slide_tuned_Qwen2.5-7B.py:193:45
(EngineCore_DP0 pid=500415) 	cvt.u32.u16 	%r144, %rs67;
(EngineCore_DP0 pid=500415) 	cvt.u32.u16 	%r145, %rs71;
(EngineCore_DP0 pid=500415) 	.loc	1 195 30                        // quant_slide_tuned_Qwen2.5-7B.py:195:30
(EngineCore_DP0 pid=500415) 	and.b16 	%rs72, %rs65, 255;
(EngineCore_DP0 pid=500415) 	mul.wide.u16 	%r146, %rs72, 256;
(EngineCore_DP0 pid=500415) 	mul.wide.u16 	%r147, %rs69, 256;
(EngineCore_DP0 pid=500415) 	.loc	1 195 24                        // quant_slide_tuned_Qwen2.5-7B.py:195:24
(EngineCore_DP0 pid=500415) 	or.b32 	%r148, %r146, %r139;
(EngineCore_DP0 pid=500415) 	or.b32 	%r149, %r147, %r140;
(EngineCore_DP0 pid=500415) 	.loc	1 195 42                        // quant_slide_tuned_Qwen2.5-7B.py:195:42
(EngineCore_DP0 pid=500415) 	shl.b32 	%r150, %r142, 16;
(EngineCore_DP0 pid=500415) 	shl.b32 	%r151, %r143, 16;
(EngineCore_DP0 pid=500415) 	.loc	1 195 36                        // quant_slide_tuned_Qwen2.5-7B.py:195:36
(EngineCore_DP0 pid=500415) 	or.b32 	%r152, %r148, %r150;
(EngineCore_DP0 pid=500415) 	or.b32 	%r153, %r149, %r151;
(EngineCore_DP0 pid=500415) 	.loc	1 195 55                        // quant_slide_tuned_Qwen2.5-7B.py:195:55
(EngineCore_DP0 pid=500415) 	shl.b32 	%r154, %r144, 24;
(EngineCore_DP0 pid=500415) 	shl.b32 	%r155, %r145, 24;
(EngineCore_DP0 pid=500415) 	.loc	1 195 49                        // quant_slide_tuned_Qwen2.5-7B.py:195:49
(EngineCore_DP0 pid=500415) 	or.b32 	%r95, %r152, %r154;
(EngineCore_DP0 pid=500415) 	or.b32 	%r96, %r153, %r155;
(EngineCore_DP0 pid=500415) 	.loc	1 196 29                        // quant_slide_tuned_Qwen2.5-7B.py:196:29
(EngineCore_DP0 pid=500415) 	mad.wide.s32 	%rd17, %r97, 4, %rd2;
(EngineCore_DP0 pid=500415) 	.loc	1 196 39                        // quant_slide_tuned_Qwen2.5-7B.py:196:39
(EngineCore_DP0 pid=500415) 	// begin inline asm
(EngineCore_DP0 pid=500415) 	@%p18 st.global.v2.b32 [ %rd17 + 0 ], { %r95, %r96 };
(EngineCore_DP0 pid=500415) 	// end inline asm
(EngineCore_DP0 pid=500415) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=500415) 	add.s32 	%r159, %r159, 1024;
(EngineCore_DP0 pid=500415) 	setp.lt.s32 	%p27, %r159, %r15;
(EngineCore_DP0 pid=500415) 	@%p27 bra 	$L__BB0_6;
(EngineCore_DP0 pid=500415) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=500415) 	.loc	1 167 4                         // quant_slide_tuned_Qwen2.5-7B.py:167:4
(EngineCore_DP0 pid=500415) 	ret;
(EngineCore_DP0 pid=500415) $L__tmp3:
(EngineCore_DP0 pid=500415) $L__func_end0:
(EngineCore_DP0 pid=500415)                                         // -- End function
(EngineCore_DP0 pid=500415) }
(EngineCore_DP0 pid=500415) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py"
(EngineCore_DP0 pid=500415) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=500415) 	.section	.debug_abbrev
(EngineCore_DP0 pid=500415) 	{
(EngineCore_DP0 pid=500415) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=500415) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=500415) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=500415) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=500415) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=500415) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=500415) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=500415) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=500415) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=500415) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=500415) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=500415) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=500415) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=500415) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=500415) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=500415) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=500415) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=500415) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=500415) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=500415) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=500415) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=500415) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=500415) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=500415) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=500415) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=500415) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=500415) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=500415) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=500415) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=500415) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=500415) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=500415) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=500415) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=500415) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=500415) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=500415) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=500415) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=500415) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=500415) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=500415) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=500415) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=500415) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=500415) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=500415) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=500415) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=500415) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=500415) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=500415) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=500415) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=500415) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=500415) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=500415) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=500415) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=500415) 	}
(EngineCore_DP0 pid=500415) 	.section	.debug_info
(EngineCore_DP0 pid=500415) 	{
(EngineCore_DP0 pid=500415) .b32 221                                // Length of Unit
(EngineCore_DP0 pid=500415) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=500415) .b8 0
(EngineCore_DP0 pid=500415) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=500415) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=500415) .b8 1                                   // Abbrev [1] 0xb:0xd6 DW_TAG_compile_unit
(EngineCore_DP0 pid=500415) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=500415) .b8 114
(EngineCore_DP0 pid=500415) .b8 105
(EngineCore_DP0 pid=500415) .b8 116
(EngineCore_DP0 pid=500415) .b8 111
(EngineCore_DP0 pid=500415) .b8 110
(EngineCore_DP0 pid=500415) .b8 0
(EngineCore_DP0 pid=500415) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=500415) .b8 0
(EngineCore_DP0 pid=500415) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=500415) .b8 117
(EngineCore_DP0 pid=500415) .b8 97
(EngineCore_DP0 pid=500415) .b8 110
(EngineCore_DP0 pid=500415) .b8 116
(EngineCore_DP0 pid=500415) .b8 95
(EngineCore_DP0 pid=500415) .b8 115
(EngineCore_DP0 pid=500415) .b8 108
(EngineCore_DP0 pid=500415) .b8 105
(EngineCore_DP0 pid=500415) .b8 100
(EngineCore_DP0 pid=500415) .b8 101
(EngineCore_DP0 pid=500415) .b8 95
(EngineCore_DP0 pid=500415) .b8 116
(EngineCore_DP0 pid=500415) .b8 117
(EngineCore_DP0 pid=500415) .b8 110
(EngineCore_DP0 pid=500415) .b8 101
(EngineCore_DP0 pid=500415) .b8 100
(EngineCore_DP0 pid=500415) .b8 95
(EngineCore_DP0 pid=500415) .b8 81
(EngineCore_DP0 pid=500415) .b8 119
(EngineCore_DP0 pid=500415) .b8 101
(EngineCore_DP0 pid=500415) .b8 110
(EngineCore_DP0 pid=500415) .b8 50
(EngineCore_DP0 pid=500415) .b8 46
(EngineCore_DP0 pid=500415) .b8 53
(EngineCore_DP0 pid=500415) .b8 45
(EngineCore_DP0 pid=500415) .b8 55
(EngineCore_DP0 pid=500415) .b8 66
(EngineCore_DP0 pid=500415) .b8 46
(EngineCore_DP0 pid=500415) .b8 112
(EngineCore_DP0 pid=500415) .b8 121
(EngineCore_DP0 pid=500415) .b8 0
(EngineCore_DP0 pid=500415) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=500415) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=500415) .b8 114
(EngineCore_DP0 pid=500415) .b8 111
(EngineCore_DP0 pid=500415) .b8 111
(EngineCore_DP0 pid=500415) .b8 116
(EngineCore_DP0 pid=500415) .b8 47
(EngineCore_DP0 pid=500415) .b8 118
(EngineCore_DP0 pid=500415) .b8 108
(EngineCore_DP0 pid=500415) .b8 108
(EngineCore_DP0 pid=500415) .b8 109
(EngineCore_DP0 pid=500415) .b8 98
(EngineCore_DP0 pid=500415) .b8 101
(EngineCore_DP0 pid=500415) .b8 110
(EngineCore_DP0 pid=500415) .b8 99
(EngineCore_DP0 pid=500415) .b8 104
(EngineCore_DP0 pid=500415) .b8 47
(EngineCore_DP0 pid=500415) .b8 115
(EngineCore_DP0 pid=500415) .b8 108
(EngineCore_DP0 pid=500415) .b8 105
(EngineCore_DP0 pid=500415) .b8 100
(EngineCore_DP0 pid=500415) .b8 101
(EngineCore_DP0 pid=500415) .b8 115
(EngineCore_DP0 pid=500415) .b8 112
(EngineCore_DP0 pid=500415) .b8 97
(EngineCore_DP0 pid=500415) .b8 114
(EngineCore_DP0 pid=500415) .b8 115
(EngineCore_DP0 pid=500415) .b8 101
(EngineCore_DP0 pid=500415) .b8 47
(EngineCore_DP0 pid=500415) .b8 99
(EngineCore_DP0 pid=500415) .b8 115
(EngineCore_DP0 pid=500415) .b8 114
(EngineCore_DP0 pid=500415) .b8 99
(EngineCore_DP0 pid=500415) .b8 47
(EngineCore_DP0 pid=500415) .b8 102
(EngineCore_DP0 pid=500415) .b8 117
(EngineCore_DP0 pid=500415) .b8 115
(EngineCore_DP0 pid=500415) .b8 101
(EngineCore_DP0 pid=500415) .b8 100
(EngineCore_DP0 pid=500415) .b8 95
(EngineCore_DP0 pid=500415) .b8 113
(EngineCore_DP0 pid=500415) .b8 117
(EngineCore_DP0 pid=500415) .b8 97
(EngineCore_DP0 pid=500415) .b8 110
(EngineCore_DP0 pid=500415) .b8 116
(EngineCore_DP0 pid=500415) .b8 95
(EngineCore_DP0 pid=500415) .b8 115
(EngineCore_DP0 pid=500415) .b8 108
(EngineCore_DP0 pid=500415) .b8 105
(EngineCore_DP0 pid=500415) .b8 100
(EngineCore_DP0 pid=500415) .b8 101
(EngineCore_DP0 pid=500415) .b8 95
(EngineCore_DP0 pid=500415) .b8 116
(EngineCore_DP0 pid=500415) .b8 114
(EngineCore_DP0 pid=500415) .b8 105
(EngineCore_DP0 pid=500415) .b8 116
(EngineCore_DP0 pid=500415) .b8 111
(EngineCore_DP0 pid=500415) .b8 110
(EngineCore_DP0 pid=500415) .b8 47
(EngineCore_DP0 pid=500415) .b8 98
(EngineCore_DP0 pid=500415) .b8 117
(EngineCore_DP0 pid=500415) .b8 105
(EngineCore_DP0 pid=500415) .b8 108
(EngineCore_DP0 pid=500415) .b8 100
(EngineCore_DP0 pid=500415) .b8 47
(EngineCore_DP0 pid=500415) .b8 71
(EngineCore_DP0 pid=500415) .b8 66
(EngineCore_DP0 pid=500415) .b8 49
(EngineCore_DP0 pid=500415) .b8 48
(EngineCore_DP0 pid=500415) .b8 95
(EngineCore_DP0 pid=500415) .b8 99
(EngineCore_DP0 pid=500415) .b8 99
(EngineCore_DP0 pid=500415) .b8 49
(EngineCore_DP0 pid=500415) .b8 50
(EngineCore_DP0 pid=500415) .b8 49
(EngineCore_DP0 pid=500415) .b8 95
(EngineCore_DP0 pid=500415) .b8 112
(EngineCore_DP0 pid=500415) .b8 121
(EngineCore_DP0 pid=500415) .b8 51
(EngineCore_DP0 pid=500415) .b8 49
(EngineCore_DP0 pid=500415) .b8 50
(EngineCore_DP0 pid=500415) .b8 95
(EngineCore_DP0 pid=500415) .b8 99
(EngineCore_DP0 pid=500415) .b8 117
(EngineCore_DP0 pid=500415) .b8 49
(EngineCore_DP0 pid=500415) .b8 50
(EngineCore_DP0 pid=500415) .b8 57
(EngineCore_DP0 pid=500415) .b8 95
(EngineCore_DP0 pid=500415) .b8 97
(EngineCore_DP0 pid=500415) .b8 97
(EngineCore_DP0 pid=500415) .b8 114
(EngineCore_DP0 pid=500415) .b8 99
(EngineCore_DP0 pid=500415) .b8 104
(EngineCore_DP0 pid=500415) .b8 54
(EngineCore_DP0 pid=500415) .b8 52
(EngineCore_DP0 pid=500415) .b8 0
(EngineCore_DP0 pid=500415) .b8 2                                   // Abbrev [2] 0x98:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=500415) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=500415) .b8 113
(EngineCore_DP0 pid=500415) .b8 117
(EngineCore_DP0 pid=500415) .b8 97
(EngineCore_DP0 pid=500415) .b8 110
(EngineCore_DP0 pid=500415) .b8 116
(EngineCore_DP0 pid=500415) .b8 95
(EngineCore_DP0 pid=500415) .b8 115
(EngineCore_DP0 pid=500415) .b8 108
(EngineCore_DP0 pid=500415) .b8 105
(EngineCore_DP0 pid=500415) .b8 100
(EngineCore_DP0 pid=500415) .b8 101
(EngineCore_DP0 pid=500415) .b8 95
(EngineCore_DP0 pid=500415) .b8 102
(EngineCore_DP0 pid=500415) .b8 112
(EngineCore_DP0 pid=500415) .b8 56
(EngineCore_DP0 pid=500415) .b8 95
(EngineCore_DP0 pid=500415) .b8 107
(EngineCore_DP0 pid=500415) .b8 101
(EngineCore_DP0 pid=500415) .b8 114
(EngineCore_DP0 pid=500415) .b8 110
(EngineCore_DP0 pid=500415) .b8 101
(EngineCore_DP0 pid=500415) .b8 108
(EngineCore_DP0 pid=500415) .b8 0
(EngineCore_DP0 pid=500415) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=500415) .b8 3                                   // Abbrev [3] 0xb2:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=500415) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=500415) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=500415) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=500415) .b8 4                                   // Abbrev [4] 0xc7:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=500415) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=500415) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=500415) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=500415) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=500415) .b8 157                                 // DW_AT_call_line
(EngineCore_DP0 pid=500415) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=500415) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=500415) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=500415) 	}
(EngineCore_DP0 pid=500415) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=500415) 
(EngineCore_DP0 pid=500415) ================================================================
(EngineCore_DP0 pid=500415) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=500415) 
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpyn1c0t49.ptx', '-o', '/tmp/tmpyn1c0t49.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866] 
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866] 
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866] 
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpyn1c0t49.ptx -o /tmp/tmpyn1c0t49.ptx.o
(EngineCore_DP0 pid=500415) ERROR 01-25 21:52:28 [core.py:866] 

STDERR:
[2026-01-25 21:51:17] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:51:17] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:51:17] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:51:17] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:51:17] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:51:17] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:51:17] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:51:17] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:51:17] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:51:17] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:51:17] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:51:17] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:51:17] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:51:17] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:51:20] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:51:20] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:51:20] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:51:20] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:51:20] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:51:20] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:51:20] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:51:20] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:51:20] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:51:20] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:51:20] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:51:20] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:51:20] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:51:20] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=500415) [2026-01-25 21:51:21] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=500415) [2026-01-25 21:51:21] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=500415) [2026-01-25 21:51:21] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=500415) [2026-01-25 21:51:21] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=500415) [2026-01-25 21:51:21] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=500415) [2026-01-25 21:51:21] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=500415) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=500415) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:28<00:28, 28.00s/it]
(EngineCore_DP0 pid=500415) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:04<00:00, 33.14s/it]
(EngineCore_DP0 pid=500415) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:04<00:00, 32.37s/it]
(EngineCore_DP0 pid=500415) 
(EngineCore_DP0 pid=500415) [2026-01-25 21:52:27] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=500415) [2026-01-25 21:52:27] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16588800 bytes
(EngineCore_DP0 pid=500415) [2026-01-25 21:52:27] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=500415) [2026-01-25 21:52:27] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 12902400 bytes
(EngineCore_DP0 pid=500415) [2026-01-25 21:52:27] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=500415) [2026-01-25 21:52:27] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 136396800 bytes
(EngineCore_DP0 pid=500415) [2026-01-25 21:52:27] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=500415) [2026-01-25 21:52:27] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 67952640 bytes
(EngineCore_DP0 pid=500415) Process EngineCore_DP0:
(EngineCore_DP0 pid=500415) Traceback (most recent call last):
(EngineCore_DP0 pid=500415)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=500415)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=500415)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=500415)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=500415) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpyn1c0t49.ptx', '-o', '/tmp/tmpyn1c0t49.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=500415) 
(EngineCore_DP0 pid=500415) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=500415) 
(EngineCore_DP0 pid=500415) Traceback (most recent call last):
(EngineCore_DP0 pid=500415)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=500415)     self.run()
(EngineCore_DP0 pid=500415)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=500415)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=500415)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=500415)     raise e
(EngineCore_DP0 pid=500415)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=500415)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=500415)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=500415)     super().__init__(
(EngineCore_DP0 pid=500415)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=500415)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=500415)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=500415)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=500415)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=500415)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=500415)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=500415)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=500415)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=500415)     return func(*args, **kwargs)
(EngineCore_DP0 pid=500415)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=500415)     return func(*args, **kwargs)
(EngineCore_DP0 pid=500415)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=500415)     self.model_runner.profile_run()
(EngineCore_DP0 pid=500415)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=500415)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=500415)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=500415)     return func(*args, **kwargs)
(EngineCore_DP0 pid=500415)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=500415)     outputs = self.model(
(EngineCore_DP0 pid=500415)               ^^^^^^^^^^^
(EngineCore_DP0 pid=500415)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=500415)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=500415)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=500415)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=500415)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=500415)     hidden_states = self.model(
(EngineCore_DP0 pid=500415)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=500415)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=500415)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=500415)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=500415)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=500415)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=500415)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=500415)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=500415)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=500415)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=500415)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=500415)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=500415)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=500415)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=500415)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=500415)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=500415)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=500415)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=500415)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=500415)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=500415)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=500415)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=500415)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=500415)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=500415)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=500415)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=500415)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=500415)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=500415)     return self._linear_fn(
(EngineCore_DP0 pid=500415)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=500415)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=500415)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=500415)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=500415)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=500415)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=500415)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=500415)     return fn(input, L)
(EngineCore_DP0 pid=500415)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=500415)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=500415)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=500415)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=500415)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=500415)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=500415)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=500415)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=500415)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=500415)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=500415)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=500415)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=500415)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=500415)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=500415)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=500415)     raise PTXASError(error)
(EngineCore_DP0 pid=500415) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=500415) `ptxas` stderr:
(EngineCore_DP0 pid=500415) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=500415) 
(EngineCore_DP0 pid=500415) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpyn1c0t49.ptx -o /tmp/tmpyn1c0t49.ptx.o
(EngineCore_DP0 pid=500415) 
[rank0]:[W125 21:52:29.279715837 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=8192

========== M=16384 ==========
Time: 2026-01-25 21:52:30
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Qwen2.5-7B-FP8_M16384.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:52:41 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 21:52:41 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=501801) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=501801) 
(EngineCore_DP0 pid=501801) 
(EngineCore_DP0 pid=501801) ================================================================
(EngineCore_DP0 pid=501801) Internal Triton PTX codegen error
(EngineCore_DP0 pid=501801) `ptxas` stderr:
(EngineCore_DP0 pid=501801) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=501801) 
(EngineCore_DP0 pid=501801) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp_mkoqus6.ptx -o /tmp/tmp_mkoqus6.ptx.o
(EngineCore_DP0 pid=501801) 
(EngineCore_DP0 pid=501801) 
(EngineCore_DP0 pid=501801) //
(EngineCore_DP0 pid=501801) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=501801) //
(EngineCore_DP0 pid=501801) 
(EngineCore_DP0 pid=501801) .version 8.7
(EngineCore_DP0 pid=501801) .target sm_121a
(EngineCore_DP0 pid=501801) .address_size 64
(EngineCore_DP0 pid=501801) 
(EngineCore_DP0 pid=501801) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=501801) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=501801)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=501801) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=501801) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=501801) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=501801) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=501801) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=501801) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=501801) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=501801) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=501801) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=501801) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=501801) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=501801) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=501801) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=501801) )
(EngineCore_DP0 pid=501801) .reqntid 512
(EngineCore_DP0 pid=501801) {
(EngineCore_DP0 pid=501801) 	.reg .pred 	%p<29>;
(EngineCore_DP0 pid=501801) 	.reg .b16 	%rs<73>;
(EngineCore_DP0 pid=501801) 	.reg .b32 	%r<160>;
(EngineCore_DP0 pid=501801) 	.reg .b64 	%rd<18>;
(EngineCore_DP0 pid=501801) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=501801) $L__func_begin0:
(EngineCore_DP0 pid=501801) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=501801) 
(EngineCore_DP0 pid=501801) // %bb.0:
(EngineCore_DP0 pid=501801) 	ld.param.b32 	%r25, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=501801) 	ld.param.b32 	%r24, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=501801) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=501801) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=501801) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=501801) $L__tmp0:
(EngineCore_DP0 pid=501801) 	.loc	1 143 24                        // quant_slide_tuned_Qwen2.5-7B.py:143:24
(EngineCore_DP0 pid=501801) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=501801) 	ld.param.b32 	%r27, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=501801) 	.loc	1 148 26                        // quant_slide_tuned_Qwen2.5-7B.py:148:26
(EngineCore_DP0 pid=501801) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=501801) 	.loc	1 148 20                        // quant_slide_tuned_Qwen2.5-7B.py:148:20
(EngineCore_DP0 pid=501801) 	mad.wide.s32 	%rd1, %r28, 2, %rd4;
(EngineCore_DP0 pid=501801) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=501801) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=501801) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=501801) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=501801) 	setp.lt.s32 	%p1, %r24, 1;
(EngineCore_DP0 pid=501801) 	mov.b32 	%r158, 0f2B8CBCCC;
(EngineCore_DP0 pid=501801) 	setp.eq.b32 	%p28, %r2, 0;
(EngineCore_DP0 pid=501801) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=501801) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=501801) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=501801) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=501801) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=501801) 	shr.u32 	%r37, %r2, 3;
(EngineCore_DP0 pid=501801) 	and.b32 	%r38, %r37, 60;
(EngineCore_DP0 pid=501801) 	mov.b32 	%r39, global_smem;
(EngineCore_DP0 pid=501801) 	add.s32 	%r57, %r39, %r38;
(EngineCore_DP0 pid=501801) 	shl.b32 	%r40, %r2, 2;
(EngineCore_DP0 pid=501801) 	add.s32 	%r60, %r39, %r40;
(EngineCore_DP0 pid=501801) 	mov.b32 	%r45, 0;
(EngineCore_DP0 pid=501801) 	mov.b32 	%r156, 0f00000000;
(EngineCore_DP0 pid=501801) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=501801) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=501801) 	mov.b32 	%r157, %r45;
(EngineCore_DP0 pid=501801) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=501801) 	.loc	1 154 19                        // quant_slide_tuned_Qwen2.5-7B.py:154:19
(EngineCore_DP0 pid=501801) 	add.s32 	%r63, %r4, %r157;
(EngineCore_DP0 pid=501801) 	.loc	1 155 22                        // quant_slide_tuned_Qwen2.5-7B.py:155:22
(EngineCore_DP0 pid=501801) 	add.s32 	%r64, %r63, 4096;
(EngineCore_DP0 pid=501801) 	setp.lt.s32 	%p2, %r63, %r23;
(EngineCore_DP0 pid=501801) 	setp.lt.s32 	%p3, %r64, %r23;
(EngineCore_DP0 pid=501801) 	.loc	1 156 29                        // quant_slide_tuned_Qwen2.5-7B.py:156:29
(EngineCore_DP0 pid=501801) 	mad.wide.s32 	%rd6, %r63, 2, %rd1;
(EngineCore_DP0 pid=501801) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=501801) 	.loc	1 156 21                        // quant_slide_tuned_Qwen2.5-7B.py:156:21
(EngineCore_DP0 pid=501801) 	// begin inline asm
(EngineCore_DP0 pid=501801) 	mov.u32 %r41, %r45;
(EngineCore_DP0 pid=501801) 	mov.u32 %r42, %r45;
(EngineCore_DP0 pid=501801) 	mov.u32 %r43, %r45;
(EngineCore_DP0 pid=501801) 	mov.u32 %r44, %r45;
(EngineCore_DP0 pid=501801) 	@%p2 ld.global.v4.b32 { %r41, %r42, %r43, %r44 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=501801) 	// end inline asm
(EngineCore_DP0 pid=501801) 	mov.b32 	{%rs1, %rs2}, %r41;
(EngineCore_DP0 pid=501801) 	mov.b32 	{%rs3, %rs4}, %r42;
(EngineCore_DP0 pid=501801) 	mov.b32 	{%rs5, %rs6}, %r43;
(EngineCore_DP0 pid=501801) 	mov.b32 	{%rs7, %rs8}, %r44;
(EngineCore_DP0 pid=501801) 	// begin inline asm
(EngineCore_DP0 pid=501801) 	mov.u32 %r49, %r45;
(EngineCore_DP0 pid=501801) 	mov.u32 %r50, %r45;
(EngineCore_DP0 pid=501801) 	mov.u32 %r51, %r45;
(EngineCore_DP0 pid=501801) 	mov.u32 %r52, %r45;
(EngineCore_DP0 pid=501801) 	@%p3 ld.global.v4.b32 { %r49, %r50, %r51, %r52 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=501801) 	// end inline asm
(EngineCore_DP0 pid=501801) 	mov.b32 	{%rs9, %rs10}, %r49;
(EngineCore_DP0 pid=501801) 	mov.b32 	{%rs11, %rs12}, %r50;
(EngineCore_DP0 pid=501801) 	mov.b32 	{%rs13, %rs14}, %r51;
(EngineCore_DP0 pid=501801) 	mov.b32 	{%rs15, %rs16}, %r52;
(EngineCore_DP0 pid=501801) 	.loc	1 157 50                        // quant_slide_tuned_Qwen2.5-7B.py:157:50
(EngineCore_DP0 pid=501801) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=501801) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=501801) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=501801) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=501801) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=501801) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=501801) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=501801) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=501801) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=501801) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=501801) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=501801) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=501801) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=501801) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=501801) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=501801) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=501801) $L__tmp1:
(EngineCore_DP0 pid=501801) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=501801) 	bar.sync 	0;
(EngineCore_DP0 pid=501801) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=501801) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=501801) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=501801) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=501801) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=501801) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=501801) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=501801) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=501801) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=501801) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=501801) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=501801) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=501801) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=501801) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=501801) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=501801) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=501801) 	cvt.f32.bf16 	%r65, %rs47;
(EngineCore_DP0 pid=501801) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=501801) 	shfl.sync.bfly.b32 	%r66, %r65, 16, 31, -1;
(EngineCore_DP0 pid=501801) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=501801) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=501801) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=501801) 	shfl.sync.bfly.b32 	%r68, %r67, 8, 31, -1;
(EngineCore_DP0 pid=501801) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=501801) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=501801) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=501801) 	shfl.sync.bfly.b32 	%r70, %r69, 4, 31, -1;
(EngineCore_DP0 pid=501801) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=501801) 	max.f32 	%r71, %r69, %r70;
(EngineCore_DP0 pid=501801) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=501801) 	shfl.sync.bfly.b32 	%r72, %r71, 2, 31, -1;
(EngineCore_DP0 pid=501801) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=501801) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=501801) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=501801) 	shfl.sync.bfly.b32 	%r74, %r73, 1, 31, -1;
(EngineCore_DP0 pid=501801) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=501801) 	max.f32 	%r58, %r73, %r74;
(EngineCore_DP0 pid=501801) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=501801) 	// begin inline asm
(EngineCore_DP0 pid=501801) 	@%p4 st.shared.b32 [ %r57 + 0 ], %r58;
(EngineCore_DP0 pid=501801) 	// end inline asm
(EngineCore_DP0 pid=501801) 	bar.sync 	0;
(EngineCore_DP0 pid=501801) 	// begin inline asm
(EngineCore_DP0 pid=501801) 	@%p5 ld.shared.b32 %r59, [ %r60 + 0 ];
(EngineCore_DP0 pid=501801) 	// end inline asm
(EngineCore_DP0 pid=501801) 	shfl.sync.bfly.b32 	%r75, %r59, 8, 31, -1;
(EngineCore_DP0 pid=501801) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=501801) 	max.f32 	%r76, %r59, %r75;
(EngineCore_DP0 pid=501801) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=501801) 	shfl.sync.bfly.b32 	%r77, %r76, 4, 31, -1;
(EngineCore_DP0 pid=501801) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=501801) 	max.f32 	%r78, %r76, %r77;
(EngineCore_DP0 pid=501801) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=501801) 	shfl.sync.bfly.b32 	%r79, %r78, 2, 31, -1;
(EngineCore_DP0 pid=501801) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=501801) 	max.f32 	%r80, %r78, %r79;
(EngineCore_DP0 pid=501801) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=501801) 	shfl.sync.bfly.b32 	%r81, %r80, 1, 31, -1;
(EngineCore_DP0 pid=501801) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=501801) 	max.f32 	%r62, %r80, %r81;
(EngineCore_DP0 pid=501801) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=501801) 	// begin inline asm
(EngineCore_DP0 pid=501801) 	@%p28 st.shared.b32 [ %r60 + 0 ], %r62;
(EngineCore_DP0 pid=501801) 	// end inline asm
(EngineCore_DP0 pid=501801) 	bar.sync 	0;
(EngineCore_DP0 pid=501801) 	ld.shared.b32 	%r82, [global_smem];
(EngineCore_DP0 pid=501801) $L__tmp2:
(EngineCore_DP0 pid=501801) 	.loc	1 157 36                        // quant_slide_tuned_Qwen2.5-7B.py:157:36
(EngineCore_DP0 pid=501801) 	max.f32 	%r156, %r156, %r82;
(EngineCore_DP0 pid=501801) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=501801) 	add.s32 	%r157, %r157, 8192;
(EngineCore_DP0 pid=501801) 	setp.lt.s32 	%p7, %r157, %r24;
(EngineCore_DP0 pid=501801) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=501801) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=501801) 	.loc	1 159 32                        // quant_slide_tuned_Qwen2.5-7B.py:159:32
(EngineCore_DP0 pid=501801) 	max.f32 	%r158, %r156, 0f2B8CBCCC;
(EngineCore_DP0 pid=501801) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=501801) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-7B.py:0:32
(EngineCore_DP0 pid=501801) 	mov.b32 	%r84, 0f43E00000;
(EngineCore_DP0 pid=501801) 	.loc	1 160 32                        // quant_slide_tuned_Qwen2.5-7B.py:160:32
(EngineCore_DP0 pid=501801) 	div.full.f32 	%r85, %r158, %r84;
(EngineCore_DP0 pid=501801) 	.loc	1 160 41                        // quant_slide_tuned_Qwen2.5-7B.py:160:41
(EngineCore_DP0 pid=501801) 	max.f32 	%r83, %r85, 0f36924925;
(EngineCore_DP0 pid=501801) 	.loc	1 162 25                        // quant_slide_tuned_Qwen2.5-7B.py:162:25
(EngineCore_DP0 pid=501801) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=501801) 	.loc	1 162 30                        // quant_slide_tuned_Qwen2.5-7B.py:162:30
(EngineCore_DP0 pid=501801) 	// begin inline asm
(EngineCore_DP0 pid=501801) 	@%p28 st.global.b32 [ %rd8 + 0 ], { %r83 };
(EngineCore_DP0 pid=501801) 	// end inline asm
(EngineCore_DP0 pid=501801) 	.loc	1 165 29                        // quant_slide_tuned_Qwen2.5-7B.py:165:29
(EngineCore_DP0 pid=501801) 	shl.b32 	%r15, %r25, 2;
(EngineCore_DP0 pid=501801) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=501801) 	setp.lt.s32 	%p9, %r15, 1;
(EngineCore_DP0 pid=501801) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=501801) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=501801) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-7B.py:0:41
(EngineCore_DP0 pid=501801) 	ld.param.b32 	%r29, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=501801) 	shr.s32 	%r30, %r29, 31;
(EngineCore_DP0 pid=501801) 	shr.u32 	%r31, %r30, 30;
(EngineCore_DP0 pid=501801) 	add.s32 	%r32, %r29, %r31;
(EngineCore_DP0 pid=501801) 	shr.s32 	%r33, %r32, 2;
(EngineCore_DP0 pid=501801) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=501801) 	mul.lo.s32 	%r34, %r33, %r1;
(EngineCore_DP0 pid=501801) 	mad.wide.s32 	%rd2, %r34, 4, %rd5;
(EngineCore_DP0 pid=501801) 	div.full.f32 	%r14, %r84, %r158;
(EngineCore_DP0 pid=501801) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=501801) 	mov.b32 	%r159, 0;
(EngineCore_DP0 pid=501801) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=501801)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=501801) 	.loc	1 168 31                        // quant_slide_tuned_Qwen2.5-7B.py:168:31
(EngineCore_DP0 pid=501801) 	add.s32 	%r97, %r16, %r159;
(EngineCore_DP0 pid=501801) 	.loc	1 169 30                        // quant_slide_tuned_Qwen2.5-7B.py:169:30
(EngineCore_DP0 pid=501801) 	add.s32 	%r98, %r97, 1;
(EngineCore_DP0 pid=501801) 	setp.lt.s32 	%p18, %r97, %r15;
(EngineCore_DP0 pid=501801) 	.loc	1 172 24                        // quant_slide_tuned_Qwen2.5-7B.py:172:24
(EngineCore_DP0 pid=501801) 	shr.s32 	%r99, %r97, 31;
(EngineCore_DP0 pid=501801) 	shr.u32 	%r100, %r99, 30;
(EngineCore_DP0 pid=501801) 	add.s32 	%r101, %r97, %r100;
(EngineCore_DP0 pid=501801) 	shr.s32 	%r102, %r101, 2;
(EngineCore_DP0 pid=501801) 	.loc	1 173 23                        // quant_slide_tuned_Qwen2.5-7B.py:173:23
(EngineCore_DP0 pid=501801) 	shr.s32 	%r103, %r98, 31;
(EngineCore_DP0 pid=501801) 	shr.u32 	%r104, %r103, 30;
(EngineCore_DP0 pid=501801) 	add.s32 	%r105, %r98, %r104;
(EngineCore_DP0 pid=501801) 	and.b32 	%r106, %r105, 2147483644;
(EngineCore_DP0 pid=501801) 	sub.s32 	%r107, %r98, %r106;
(EngineCore_DP0 pid=501801) 	and.b32 	%r108, %r101, 2147483644;
(EngineCore_DP0 pid=501801) 	sub.s32 	%r109, %r97, %r108;
(EngineCore_DP0 pid=501801) 	.loc	1 174 22                        // quant_slide_tuned_Qwen2.5-7B.py:174:22
(EngineCore_DP0 pid=501801) 	mul.lo.s32 	%r110, %r102, 10;
(EngineCore_DP0 pid=501801) 	.loc	1 174 30                        // quant_slide_tuned_Qwen2.5-7B.py:174:30
(EngineCore_DP0 pid=501801) 	shl.b32 	%r111, %r109, 1;
(EngineCore_DP0 pid=501801) 	shl.b32 	%r112, %r107, 1;
(EngineCore_DP0 pid=501801) 	.loc	1 174 26                        // quant_slide_tuned_Qwen2.5-7B.py:174:26
(EngineCore_DP0 pid=501801) 	add.s32 	%r113, %r110, %r112;
(EngineCore_DP0 pid=501801) 	add.s32 	%r114, %r110, %r111;
(EngineCore_DP0 pid=501801) 	.loc	1 177 53                        // quant_slide_tuned_Qwen2.5-7B.py:177:53
(EngineCore_DP0 pid=501801) 	setp.lt.s32 	%p19, %r114, %r23;
(EngineCore_DP0 pid=501801) 	setp.lt.s32 	%p20, %r113, %r23;
(EngineCore_DP0 pid=501801) 	.loc	1 177 37                        // quant_slide_tuned_Qwen2.5-7B.py:177:37
(EngineCore_DP0 pid=501801) 	and.pred 	%p10, %p18, %p19;
(EngineCore_DP0 pid=501801) 	and.pred 	%p11, %p18, %p20;
(EngineCore_DP0 pid=501801) 	.loc	1 176 29                        // quant_slide_tuned_Qwen2.5-7B.py:176:29
(EngineCore_DP0 pid=501801) 	mad.wide.s32 	%rd9, %r114, 2, %rd1;
(EngineCore_DP0 pid=501801) 	mad.wide.s32 	%rd10, %r113, 2, %rd1;
(EngineCore_DP0 pid=501801) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=501801) 	.loc	1 176 21                        // quant_slide_tuned_Qwen2.5-7B.py:176:21
(EngineCore_DP0 pid=501801) 	// begin inline asm
(EngineCore_DP0 pid=501801) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=501801) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=501801) 	// end inline asm
(EngineCore_DP0 pid=501801) 	// begin inline asm
(EngineCore_DP0 pid=501801) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=501801) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=501801) 	// end inline asm
(EngineCore_DP0 pid=501801) 	.loc	1 177 79                        // quant_slide_tuned_Qwen2.5-7B.py:177:79
(EngineCore_DP0 pid=501801) 	cvt.f32.bf16 	%r115, %rs48;
(EngineCore_DP0 pid=501801) 	cvt.f32.bf16 	%r116, %rs50;
(EngineCore_DP0 pid=501801) 	.loc	1 179 48                        // quant_slide_tuned_Qwen2.5-7B.py:179:48
(EngineCore_DP0 pid=501801) 	or.b32 	%r117, %r114, 1;
(EngineCore_DP0 pid=501801) 	or.b32 	%r118, %r113, 1;
(EngineCore_DP0 pid=501801) 	.loc	1 179 53                        // quant_slide_tuned_Qwen2.5-7B.py:179:53
(EngineCore_DP0 pid=501801) 	setp.lt.s32 	%p21, %r117, %r23;
(EngineCore_DP0 pid=501801) 	setp.lt.s32 	%p22, %r118, %r23;
(EngineCore_DP0 pid=501801) 	.loc	1 179 37                        // quant_slide_tuned_Qwen2.5-7B.py:179:37
(EngineCore_DP0 pid=501801) 	and.pred 	%p12, %p18, %p21;
(EngineCore_DP0 pid=501801) 	and.pred 	%p13, %p18, %p22;
(EngineCore_DP0 pid=501801) 	.loc	1 178 39                        // quant_slide_tuned_Qwen2.5-7B.py:178:39
(EngineCore_DP0 pid=501801) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=501801) 	add.s64 	%rd12, %rd10, 2;
(EngineCore_DP0 pid=501801) 	.loc	1 178 21                        // quant_slide_tuned_Qwen2.5-7B.py:178:21
(EngineCore_DP0 pid=501801) 	// begin inline asm
(EngineCore_DP0 pid=501801) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=501801) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=501801) 	// end inline asm
(EngineCore_DP0 pid=501801) 	// begin inline asm
(EngineCore_DP0 pid=501801) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=501801) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=501801) 	// end inline asm
(EngineCore_DP0 pid=501801) 	.loc	1 179 79                        // quant_slide_tuned_Qwen2.5-7B.py:179:79
(EngineCore_DP0 pid=501801) 	cvt.f32.bf16 	%r119, %rs52;
(EngineCore_DP0 pid=501801) 	cvt.f32.bf16 	%r120, %rs54;
(EngineCore_DP0 pid=501801) 	.loc	1 183 48                        // quant_slide_tuned_Qwen2.5-7B.py:183:48
(EngineCore_DP0 pid=501801) 	add.s32 	%r121, %r114, 2;
(EngineCore_DP0 pid=501801) 	add.s32 	%r122, %r113, 2;
(EngineCore_DP0 pid=501801) 	add.s32 	%r123, %r114, 3;
(EngineCore_DP0 pid=501801) 	add.s32 	%r124, %r113, 3;
(EngineCore_DP0 pid=501801) 	.loc	1 183 53                        // quant_slide_tuned_Qwen2.5-7B.py:183:53
(EngineCore_DP0 pid=501801) 	setp.lt.s32 	%p23, %r124, %r23;
(EngineCore_DP0 pid=501801) 	setp.lt.s32 	%p24, %r123, %r23;
(EngineCore_DP0 pid=501801) 	setp.lt.s32 	%p25, %r122, %r23;
(EngineCore_DP0 pid=501801) 	setp.lt.s32 	%p26, %r121, %r23;
(EngineCore_DP0 pid=501801) 	.loc	1 181 37                        // quant_slide_tuned_Qwen2.5-7B.py:181:37
(EngineCore_DP0 pid=501801) 	and.pred 	%p14, %p18, %p26;
(EngineCore_DP0 pid=501801) 	and.pred 	%p15, %p18, %p25;
(EngineCore_DP0 pid=501801) 	.loc	1 180 39                        // quant_slide_tuned_Qwen2.5-7B.py:180:39
(EngineCore_DP0 pid=501801) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=501801) 	add.s64 	%rd14, %rd10, 4;
(EngineCore_DP0 pid=501801) 	.loc	1 180 21                        // quant_slide_tuned_Qwen2.5-7B.py:180:21
(EngineCore_DP0 pid=501801) 	// begin inline asm
(EngineCore_DP0 pid=501801) 	mov.u16 %rs56, %rs49;
(EngineCore_DP0 pid=501801) 	@%p14 ld.global.b16 { %rs56 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=501801) 	// end inline asm
(EngineCore_DP0 pid=501801) 	// begin inline asm
(EngineCore_DP0 pid=501801) 	mov.u16 %rs58, %rs49;
(EngineCore_DP0 pid=501801) 	@%p15 ld.global.b16 { %rs58 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=501801) 	// end inline asm
(EngineCore_DP0 pid=501801) 	.loc	1 181 79                        // quant_slide_tuned_Qwen2.5-7B.py:181:79
(EngineCore_DP0 pid=501801) 	cvt.f32.bf16 	%r125, %rs56;
(EngineCore_DP0 pid=501801) 	cvt.f32.bf16 	%r126, %rs58;
(EngineCore_DP0 pid=501801) 	.loc	1 183 37                        // quant_slide_tuned_Qwen2.5-7B.py:183:37
(EngineCore_DP0 pid=501801) 	and.pred 	%p16, %p18, %p24;
(EngineCore_DP0 pid=501801) 	and.pred 	%p17, %p18, %p23;
(EngineCore_DP0 pid=501801) 	.loc	1 182 39                        // quant_slide_tuned_Qwen2.5-7B.py:182:39
(EngineCore_DP0 pid=501801) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=501801) 	add.s64 	%rd16, %rd10, 6;
(EngineCore_DP0 pid=501801) 	.loc	1 182 21                        // quant_slide_tuned_Qwen2.5-7B.py:182:21
(EngineCore_DP0 pid=501801) 	// begin inline asm
(EngineCore_DP0 pid=501801) 	mov.u16 %rs60, %rs49;
(EngineCore_DP0 pid=501801) 	@%p16 ld.global.b16 { %rs60 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=501801) 	// end inline asm
(EngineCore_DP0 pid=501801) 	// begin inline asm
(EngineCore_DP0 pid=501801) 	mov.u16 %rs62, %rs49;
(EngineCore_DP0 pid=501801) 	@%p17 ld.global.b16 { %rs62 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=501801) 	// end inline asm
(EngineCore_DP0 pid=501801) 	.loc	1 183 79                        // quant_slide_tuned_Qwen2.5-7B.py:183:79
(EngineCore_DP0 pid=501801) 	cvt.f32.bf16 	%r127, %rs60;
(EngineCore_DP0 pid=501801) 	cvt.f32.bf16 	%r128, %rs62;
(EngineCore_DP0 pid=501801) 	.loc	1 185 27                        // quant_slide_tuned_Qwen2.5-7B.py:185:27
(EngineCore_DP0 pid=501801) 	mul.f32 	%r129, %r14, %r115;
(EngineCore_DP0 pid=501801) 	mul.f32 	%r130, %r14, %r116;
(EngineCore_DP0 pid=501801) 	mov.b32 	%r131, 0f43E00000;
(EngineCore_DP0 pid=501801) 	.loc	1 185 48                        // quant_slide_tuned_Qwen2.5-7B.py:185:48
(EngineCore_DP0 pid=501801) 	min.xorsign.abs.f32 	%r87, %r129, %r131;
(EngineCore_DP0 pid=501801) 	min.xorsign.abs.f32 	%r88, %r130, %r131;
(EngineCore_DP0 pid=501801) 	.loc	1 185 60                        // quant_slide_tuned_Qwen2.5-7B.py:185:60
(EngineCore_DP0 pid=501801) 	// begin inline asm
(EngineCore_DP0 pid=501801) 	cvt.rn.satfinite.e4m3x2.f32  %rs64, %r88, %r87; 
(EngineCore_DP0 pid=501801) 
(EngineCore_DP0 pid=501801) 	// end inline asm
(EngineCore_DP0 pid=501801) 	shr.u16 	%rs68, %rs64, 8;
(EngineCore_DP0 pid=501801) 	.loc	1 186 27                        // quant_slide_tuned_Qwen2.5-7B.py:186:27
(EngineCore_DP0 pid=501801) 	mul.f32 	%r132, %r14, %r119;
(EngineCore_DP0 pid=501801) 	mul.f32 	%r133, %r14, %r120;
(EngineCore_DP0 pid=501801) 	.loc	1 186 48                        // quant_slide_tuned_Qwen2.5-7B.py:186:48
(EngineCore_DP0 pid=501801) 	min.xorsign.abs.f32 	%r89, %r132, %r131;
(EngineCore_DP0 pid=501801) 	min.xorsign.abs.f32 	%r90, %r133, %r131;
(EngineCore_DP0 pid=501801) 	.loc	1 186 60                        // quant_slide_tuned_Qwen2.5-7B.py:186:60
(EngineCore_DP0 pid=501801) 	// begin inline asm
(EngineCore_DP0 pid=501801) 	cvt.rn.satfinite.e4m3x2.f32  %rs65, %r90, %r89; 
(EngineCore_DP0 pid=501801) 
(EngineCore_DP0 pid=501801) 	// end inline asm
(EngineCore_DP0 pid=501801) 	shr.u16 	%rs69, %rs65, 8;
(EngineCore_DP0 pid=501801) 	.loc	1 187 27                        // quant_slide_tuned_Qwen2.5-7B.py:187:27
(EngineCore_DP0 pid=501801) 	mul.f32 	%r134, %r14, %r125;
(EngineCore_DP0 pid=501801) 	mul.f32 	%r135, %r14, %r126;
(EngineCore_DP0 pid=501801) 	.loc	1 187 48                        // quant_slide_tuned_Qwen2.5-7B.py:187:48
(EngineCore_DP0 pid=501801) 	min.xorsign.abs.f32 	%r91, %r134, %r131;
(EngineCore_DP0 pid=501801) 	min.xorsign.abs.f32 	%r92, %r135, %r131;
(EngineCore_DP0 pid=501801) 	.loc	1 187 60                        // quant_slide_tuned_Qwen2.5-7B.py:187:60
(EngineCore_DP0 pid=501801) 	// begin inline asm
(EngineCore_DP0 pid=501801) 	cvt.rn.satfinite.e4m3x2.f32  %rs66, %r92, %r91; 
(EngineCore_DP0 pid=501801) 
(EngineCore_DP0 pid=501801) 	// end inline asm
(EngineCore_DP0 pid=501801) 	shr.u16 	%rs70, %rs66, 8;
(EngineCore_DP0 pid=501801) 	.loc	1 188 27                        // quant_slide_tuned_Qwen2.5-7B.py:188:27
(EngineCore_DP0 pid=501801) 	mul.f32 	%r136, %r14, %r127;
(EngineCore_DP0 pid=501801) 	mul.f32 	%r137, %r14, %r128;
(EngineCore_DP0 pid=501801) 	.loc	1 188 48                        // quant_slide_tuned_Qwen2.5-7B.py:188:48
(EngineCore_DP0 pid=501801) 	min.xorsign.abs.f32 	%r93, %r136, %r131;
(EngineCore_DP0 pid=501801) 	min.xorsign.abs.f32 	%r94, %r137, %r131;
(EngineCore_DP0 pid=501801) 	.loc	1 188 60                        // quant_slide_tuned_Qwen2.5-7B.py:188:60
(EngineCore_DP0 pid=501801) 	// begin inline asm
(EngineCore_DP0 pid=501801) 	cvt.rn.satfinite.e4m3x2.f32  %rs67, %r94, %r93; 
(EngineCore_DP0 pid=501801) 
(EngineCore_DP0 pid=501801) 	// end inline asm
(EngineCore_DP0 pid=501801) 	shr.u16 	%rs71, %rs67, 8;
(EngineCore_DP0 pid=501801) 	.loc	1 190 45                        // quant_slide_tuned_Qwen2.5-7B.py:190:45
(EngineCore_DP0 pid=501801) 	cvt.u32.u16 	%r138, %rs64;
(EngineCore_DP0 pid=501801) 	and.b32 	%r139, %r138, 255;
(EngineCore_DP0 pid=501801) 	cvt.u32.u16 	%r140, %rs68;
(EngineCore_DP0 pid=501801) 	.loc	1 192 45                        // quant_slide_tuned_Qwen2.5-7B.py:192:45
(EngineCore_DP0 pid=501801) 	cvt.u32.u16 	%r141, %rs66;
(EngineCore_DP0 pid=501801) 	and.b32 	%r142, %r141, 255;
(EngineCore_DP0 pid=501801) 	cvt.u32.u16 	%r143, %rs70;
(EngineCore_DP0 pid=501801) 	.loc	1 193 45                        // quant_slide_tuned_Qwen2.5-7B.py:193:45
(EngineCore_DP0 pid=501801) 	cvt.u32.u16 	%r144, %rs67;
(EngineCore_DP0 pid=501801) 	cvt.u32.u16 	%r145, %rs71;
(EngineCore_DP0 pid=501801) 	.loc	1 195 30                        // quant_slide_tuned_Qwen2.5-7B.py:195:30
(EngineCore_DP0 pid=501801) 	and.b16 	%rs72, %rs65, 255;
(EngineCore_DP0 pid=501801) 	mul.wide.u16 	%r146, %rs72, 256;
(EngineCore_DP0 pid=501801) 	mul.wide.u16 	%r147, %rs69, 256;
(EngineCore_DP0 pid=501801) 	.loc	1 195 24                        // quant_slide_tuned_Qwen2.5-7B.py:195:24
(EngineCore_DP0 pid=501801) 	or.b32 	%r148, %r146, %r139;
(EngineCore_DP0 pid=501801) 	or.b32 	%r149, %r147, %r140;
(EngineCore_DP0 pid=501801) 	.loc	1 195 42                        // quant_slide_tuned_Qwen2.5-7B.py:195:42
(EngineCore_DP0 pid=501801) 	shl.b32 	%r150, %r142, 16;
(EngineCore_DP0 pid=501801) 	shl.b32 	%r151, %r143, 16;
(EngineCore_DP0 pid=501801) 	.loc	1 195 36                        // quant_slide_tuned_Qwen2.5-7B.py:195:36
(EngineCore_DP0 pid=501801) 	or.b32 	%r152, %r148, %r150;
(EngineCore_DP0 pid=501801) 	or.b32 	%r153, %r149, %r151;
(EngineCore_DP0 pid=501801) 	.loc	1 195 55                        // quant_slide_tuned_Qwen2.5-7B.py:195:55
(EngineCore_DP0 pid=501801) 	shl.b32 	%r154, %r144, 24;
(EngineCore_DP0 pid=501801) 	shl.b32 	%r155, %r145, 24;
(EngineCore_DP0 pid=501801) 	.loc	1 195 49                        // quant_slide_tuned_Qwen2.5-7B.py:195:49
(EngineCore_DP0 pid=501801) 	or.b32 	%r95, %r152, %r154;
(EngineCore_DP0 pid=501801) 	or.b32 	%r96, %r153, %r155;
(EngineCore_DP0 pid=501801) 	.loc	1 196 29                        // quant_slide_tuned_Qwen2.5-7B.py:196:29
(EngineCore_DP0 pid=501801) 	mad.wide.s32 	%rd17, %r97, 4, %rd2;
(EngineCore_DP0 pid=501801) 	.loc	1 196 39                        // quant_slide_tuned_Qwen2.5-7B.py:196:39
(EngineCore_DP0 pid=501801) 	// begin inline asm
(EngineCore_DP0 pid=501801) 	@%p18 st.global.v2.b32 [ %rd17 + 0 ], { %r95, %r96 };
(EngineCore_DP0 pid=501801) 	// end inline asm
(EngineCore_DP0 pid=501801) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=501801) 	add.s32 	%r159, %r159, 1024;
(EngineCore_DP0 pid=501801) 	setp.lt.s32 	%p27, %r159, %r15;
(EngineCore_DP0 pid=501801) 	@%p27 bra 	$L__BB0_6;
(EngineCore_DP0 pid=501801) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=501801) 	.loc	1 167 4                         // quant_slide_tuned_Qwen2.5-7B.py:167:4
(EngineCore_DP0 pid=501801) 	ret;
(EngineCore_DP0 pid=501801) $L__tmp3:
(EngineCore_DP0 pid=501801) $L__func_end0:
(EngineCore_DP0 pid=501801)                                         // -- End function
(EngineCore_DP0 pid=501801) }
(EngineCore_DP0 pid=501801) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py"
(EngineCore_DP0 pid=501801) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=501801) 	.section	.debug_abbrev
(EngineCore_DP0 pid=501801) 	{
(EngineCore_DP0 pid=501801) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=501801) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=501801) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=501801) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=501801) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=501801) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=501801) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=501801) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=501801) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=501801) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=501801) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=501801) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=501801) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=501801) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=501801) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=501801) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=501801) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=501801) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=501801) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=501801) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=501801) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=501801) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=501801) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=501801) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=501801) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=501801) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=501801) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=501801) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=501801) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=501801) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=501801) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=501801) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=501801) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=501801) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=501801) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=501801) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=501801) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=501801) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=501801) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=501801) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=501801) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=501801) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=501801) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=501801) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=501801) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=501801) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=501801) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=501801) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=501801) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=501801) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=501801) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=501801) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=501801) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=501801) 	}
(EngineCore_DP0 pid=501801) 	.section	.debug_info
(EngineCore_DP0 pid=501801) 	{
(EngineCore_DP0 pid=501801) .b32 221                                // Length of Unit
(EngineCore_DP0 pid=501801) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=501801) .b8 0
(EngineCore_DP0 pid=501801) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=501801) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=501801) .b8 1                                   // Abbrev [1] 0xb:0xd6 DW_TAG_compile_unit
(EngineCore_DP0 pid=501801) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=501801) .b8 114
(EngineCore_DP0 pid=501801) .b8 105
(EngineCore_DP0 pid=501801) .b8 116
(EngineCore_DP0 pid=501801) .b8 111
(EngineCore_DP0 pid=501801) .b8 110
(EngineCore_DP0 pid=501801) .b8 0
(EngineCore_DP0 pid=501801) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=501801) .b8 0
(EngineCore_DP0 pid=501801) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=501801) .b8 117
(EngineCore_DP0 pid=501801) .b8 97
(EngineCore_DP0 pid=501801) .b8 110
(EngineCore_DP0 pid=501801) .b8 116
(EngineCore_DP0 pid=501801) .b8 95
(EngineCore_DP0 pid=501801) .b8 115
(EngineCore_DP0 pid=501801) .b8 108
(EngineCore_DP0 pid=501801) .b8 105
(EngineCore_DP0 pid=501801) .b8 100
(EngineCore_DP0 pid=501801) .b8 101
(EngineCore_DP0 pid=501801) .b8 95
(EngineCore_DP0 pid=501801) .b8 116
(EngineCore_DP0 pid=501801) .b8 117
(EngineCore_DP0 pid=501801) .b8 110
(EngineCore_DP0 pid=501801) .b8 101
(EngineCore_DP0 pid=501801) .b8 100
(EngineCore_DP0 pid=501801) .b8 95
(EngineCore_DP0 pid=501801) .b8 81
(EngineCore_DP0 pid=501801) .b8 119
(EngineCore_DP0 pid=501801) .b8 101
(EngineCore_DP0 pid=501801) .b8 110
(EngineCore_DP0 pid=501801) .b8 50
(EngineCore_DP0 pid=501801) .b8 46
(EngineCore_DP0 pid=501801) .b8 53
(EngineCore_DP0 pid=501801) .b8 45
(EngineCore_DP0 pid=501801) .b8 55
(EngineCore_DP0 pid=501801) .b8 66
(EngineCore_DP0 pid=501801) .b8 46
(EngineCore_DP0 pid=501801) .b8 112
(EngineCore_DP0 pid=501801) .b8 121
(EngineCore_DP0 pid=501801) .b8 0
(EngineCore_DP0 pid=501801) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=501801) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=501801) .b8 114
(EngineCore_DP0 pid=501801) .b8 111
(EngineCore_DP0 pid=501801) .b8 111
(EngineCore_DP0 pid=501801) .b8 116
(EngineCore_DP0 pid=501801) .b8 47
(EngineCore_DP0 pid=501801) .b8 118
(EngineCore_DP0 pid=501801) .b8 108
(EngineCore_DP0 pid=501801) .b8 108
(EngineCore_DP0 pid=501801) .b8 109
(EngineCore_DP0 pid=501801) .b8 98
(EngineCore_DP0 pid=501801) .b8 101
(EngineCore_DP0 pid=501801) .b8 110
(EngineCore_DP0 pid=501801) .b8 99
(EngineCore_DP0 pid=501801) .b8 104
(EngineCore_DP0 pid=501801) .b8 47
(EngineCore_DP0 pid=501801) .b8 115
(EngineCore_DP0 pid=501801) .b8 108
(EngineCore_DP0 pid=501801) .b8 105
(EngineCore_DP0 pid=501801) .b8 100
(EngineCore_DP0 pid=501801) .b8 101
(EngineCore_DP0 pid=501801) .b8 115
(EngineCore_DP0 pid=501801) .b8 112
(EngineCore_DP0 pid=501801) .b8 97
(EngineCore_DP0 pid=501801) .b8 114
(EngineCore_DP0 pid=501801) .b8 115
(EngineCore_DP0 pid=501801) .b8 101
(EngineCore_DP0 pid=501801) .b8 47
(EngineCore_DP0 pid=501801) .b8 99
(EngineCore_DP0 pid=501801) .b8 115
(EngineCore_DP0 pid=501801) .b8 114
(EngineCore_DP0 pid=501801) .b8 99
(EngineCore_DP0 pid=501801) .b8 47
(EngineCore_DP0 pid=501801) .b8 102
(EngineCore_DP0 pid=501801) .b8 117
(EngineCore_DP0 pid=501801) .b8 115
(EngineCore_DP0 pid=501801) .b8 101
(EngineCore_DP0 pid=501801) .b8 100
(EngineCore_DP0 pid=501801) .b8 95
(EngineCore_DP0 pid=501801) .b8 113
(EngineCore_DP0 pid=501801) .b8 117
(EngineCore_DP0 pid=501801) .b8 97
(EngineCore_DP0 pid=501801) .b8 110
(EngineCore_DP0 pid=501801) .b8 116
(EngineCore_DP0 pid=501801) .b8 95
(EngineCore_DP0 pid=501801) .b8 115
(EngineCore_DP0 pid=501801) .b8 108
(EngineCore_DP0 pid=501801) .b8 105
(EngineCore_DP0 pid=501801) .b8 100
(EngineCore_DP0 pid=501801) .b8 101
(EngineCore_DP0 pid=501801) .b8 95
(EngineCore_DP0 pid=501801) .b8 116
(EngineCore_DP0 pid=501801) .b8 114
(EngineCore_DP0 pid=501801) .b8 105
(EngineCore_DP0 pid=501801) .b8 116
(EngineCore_DP0 pid=501801) .b8 111
(EngineCore_DP0 pid=501801) .b8 110
(EngineCore_DP0 pid=501801) .b8 47
(EngineCore_DP0 pid=501801) .b8 98
(EngineCore_DP0 pid=501801) .b8 117
(EngineCore_DP0 pid=501801) .b8 105
(EngineCore_DP0 pid=501801) .b8 108
(EngineCore_DP0 pid=501801) .b8 100
(EngineCore_DP0 pid=501801) .b8 47
(EngineCore_DP0 pid=501801) .b8 71
(EngineCore_DP0 pid=501801) .b8 66
(EngineCore_DP0 pid=501801) .b8 49
(EngineCore_DP0 pid=501801) .b8 48
(EngineCore_DP0 pid=501801) .b8 95
(EngineCore_DP0 pid=501801) .b8 99
(EngineCore_DP0 pid=501801) .b8 99
(EngineCore_DP0 pid=501801) .b8 49
(EngineCore_DP0 pid=501801) .b8 50
(EngineCore_DP0 pid=501801) .b8 49
(EngineCore_DP0 pid=501801) .b8 95
(EngineCore_DP0 pid=501801) .b8 112
(EngineCore_DP0 pid=501801) .b8 121
(EngineCore_DP0 pid=501801) .b8 51
(EngineCore_DP0 pid=501801) .b8 49
(EngineCore_DP0 pid=501801) .b8 50
(EngineCore_DP0 pid=501801) .b8 95
(EngineCore_DP0 pid=501801) .b8 99
(EngineCore_DP0 pid=501801) .b8 117
(EngineCore_DP0 pid=501801) .b8 49
(EngineCore_DP0 pid=501801) .b8 50
(EngineCore_DP0 pid=501801) .b8 57
(EngineCore_DP0 pid=501801) .b8 95
(EngineCore_DP0 pid=501801) .b8 97
(EngineCore_DP0 pid=501801) .b8 97
(EngineCore_DP0 pid=501801) .b8 114
(EngineCore_DP0 pid=501801) .b8 99
(EngineCore_DP0 pid=501801) .b8 104
(EngineCore_DP0 pid=501801) .b8 54
(EngineCore_DP0 pid=501801) .b8 52
(EngineCore_DP0 pid=501801) .b8 0
(EngineCore_DP0 pid=501801) .b8 2                                   // Abbrev [2] 0x98:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=501801) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=501801) .b8 113
(EngineCore_DP0 pid=501801) .b8 117
(EngineCore_DP0 pid=501801) .b8 97
(EngineCore_DP0 pid=501801) .b8 110
(EngineCore_DP0 pid=501801) .b8 116
(EngineCore_DP0 pid=501801) .b8 95
(EngineCore_DP0 pid=501801) .b8 115
(EngineCore_DP0 pid=501801) .b8 108
(EngineCore_DP0 pid=501801) .b8 105
(EngineCore_DP0 pid=501801) .b8 100
(EngineCore_DP0 pid=501801) .b8 101
(EngineCore_DP0 pid=501801) .b8 95
(EngineCore_DP0 pid=501801) .b8 102
(EngineCore_DP0 pid=501801) .b8 112
(EngineCore_DP0 pid=501801) .b8 56
(EngineCore_DP0 pid=501801) .b8 95
(EngineCore_DP0 pid=501801) .b8 107
(EngineCore_DP0 pid=501801) .b8 101
(EngineCore_DP0 pid=501801) .b8 114
(EngineCore_DP0 pid=501801) .b8 110
(EngineCore_DP0 pid=501801) .b8 101
(EngineCore_DP0 pid=501801) .b8 108
(EngineCore_DP0 pid=501801) .b8 0
(EngineCore_DP0 pid=501801) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=501801) .b8 3                                   // Abbrev [3] 0xb2:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=501801) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=501801) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=501801) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=501801) .b8 4                                   // Abbrev [4] 0xc7:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=501801) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=501801) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=501801) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=501801) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=501801) .b8 157                                 // DW_AT_call_line
(EngineCore_DP0 pid=501801) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=501801) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=501801) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=501801) 	}
(EngineCore_DP0 pid=501801) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=501801) 
(EngineCore_DP0 pid=501801) ================================================================
(EngineCore_DP0 pid=501801) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=501801) 
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp_mkoqus6.ptx', '-o', '/tmp/tmp_mkoqus6.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866] 
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866] 
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866] 
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp_mkoqus6.ptx -o /tmp/tmp_mkoqus6.ptx.o
(EngineCore_DP0 pid=501801) ERROR 01-25 21:53:53 [core.py:866] 

STDERR:
[2026-01-25 21:52:41] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:52:41] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:52:41] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:52:41] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:52:41] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:52:41] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:52:41] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:52:41] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:52:41] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:52:41] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:52:41] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:52:41] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:52:41] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:52:41] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:52:44] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:52:44] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:52:44] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:52:44] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:52:44] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:52:44] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:52:44] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:52:44] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:52:44] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:52:44] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:52:44] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:52:44] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:52:44] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:52:44] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=501801) [2026-01-25 21:52:45] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=501801) [2026-01-25 21:52:45] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=501801) [2026-01-25 21:52:45] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=501801) [2026-01-25 21:52:45] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=501801) [2026-01-25 21:52:45] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=501801) [2026-01-25 21:52:45] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=501801) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=501801) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:27<00:27, 27.70s/it]
(EngineCore_DP0 pid=501801) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:04<00:00, 33.29s/it]
(EngineCore_DP0 pid=501801) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:04<00:00, 32.45s/it]
(EngineCore_DP0 pid=501801) 
(EngineCore_DP0 pid=501801) [2026-01-25 21:53:52] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=501801) [2026-01-25 21:53:52] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16588800 bytes
(EngineCore_DP0 pid=501801) [2026-01-25 21:53:52] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=501801) [2026-01-25 21:53:52] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 12902400 bytes
(EngineCore_DP0 pid=501801) [2026-01-25 21:53:52] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=501801) [2026-01-25 21:53:52] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 136396800 bytes
(EngineCore_DP0 pid=501801) [2026-01-25 21:53:52] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=501801) [2026-01-25 21:53:52] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 67952640 bytes
(EngineCore_DP0 pid=501801) Process EngineCore_DP0:
(EngineCore_DP0 pid=501801) Traceback (most recent call last):
(EngineCore_DP0 pid=501801)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=501801)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=501801)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=501801)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=501801) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp_mkoqus6.ptx', '-o', '/tmp/tmp_mkoqus6.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=501801) 
(EngineCore_DP0 pid=501801) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=501801) 
(EngineCore_DP0 pid=501801) Traceback (most recent call last):
(EngineCore_DP0 pid=501801)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=501801)     self.run()
(EngineCore_DP0 pid=501801)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=501801)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=501801)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=501801)     raise e
(EngineCore_DP0 pid=501801)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=501801)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=501801)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=501801)     super().__init__(
(EngineCore_DP0 pid=501801)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=501801)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=501801)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=501801)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=501801)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=501801)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=501801)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=501801)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=501801)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=501801)     return func(*args, **kwargs)
(EngineCore_DP0 pid=501801)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=501801)     return func(*args, **kwargs)
(EngineCore_DP0 pid=501801)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=501801)     self.model_runner.profile_run()
(EngineCore_DP0 pid=501801)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=501801)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=501801)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=501801)     return func(*args, **kwargs)
(EngineCore_DP0 pid=501801)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=501801)     outputs = self.model(
(EngineCore_DP0 pid=501801)               ^^^^^^^^^^^
(EngineCore_DP0 pid=501801)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=501801)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=501801)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=501801)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=501801)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=501801)     hidden_states = self.model(
(EngineCore_DP0 pid=501801)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=501801)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=501801)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=501801)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=501801)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=501801)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=501801)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=501801)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=501801)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=501801)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=501801)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=501801)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=501801)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=501801)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=501801)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=501801)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=501801)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=501801)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=501801)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=501801)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=501801)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=501801)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=501801)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=501801)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=501801)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=501801)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=501801)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=501801)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=501801)     return self._linear_fn(
(EngineCore_DP0 pid=501801)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=501801)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=501801)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=501801)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=501801)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=501801)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=501801)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=501801)     return fn(input, L)
(EngineCore_DP0 pid=501801)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=501801)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=501801)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=501801)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=501801)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=501801)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=501801)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=501801)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=501801)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=501801)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=501801)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=501801)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=501801)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=501801)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=501801)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=501801)     raise PTXASError(error)
(EngineCore_DP0 pid=501801) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=501801) `ptxas` stderr:
(EngineCore_DP0 pid=501801) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=501801) 
(EngineCore_DP0 pid=501801) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp_mkoqus6.ptx -o /tmp/tmp_mkoqus6.ptx.o
(EngineCore_DP0 pid=501801) 
[rank0]:[W125 21:53:53.775314933 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=16384

========== M=32768 ==========
Time: 2026-01-25 21:53:55
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Qwen2.5-7B-FP8_M32768.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:54:13 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 21:54:13 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=503263) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=503263) 
(EngineCore_DP0 pid=503263) 
(EngineCore_DP0 pid=503263) ================================================================
(EngineCore_DP0 pid=503263) Internal Triton PTX codegen error
(EngineCore_DP0 pid=503263) `ptxas` stderr:
(EngineCore_DP0 pid=503263) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=503263) 
(EngineCore_DP0 pid=503263) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpbqwx5tg4.ptx -o /tmp/tmpbqwx5tg4.ptx.o
(EngineCore_DP0 pid=503263) 
(EngineCore_DP0 pid=503263) 
(EngineCore_DP0 pid=503263) //
(EngineCore_DP0 pid=503263) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=503263) //
(EngineCore_DP0 pid=503263) 
(EngineCore_DP0 pid=503263) .version 8.7
(EngineCore_DP0 pid=503263) .target sm_121a
(EngineCore_DP0 pid=503263) .address_size 64
(EngineCore_DP0 pid=503263) 
(EngineCore_DP0 pid=503263) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=503263) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=503263)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=503263) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=503263) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=503263) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=503263) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=503263) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=503263) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=503263) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=503263) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=503263) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=503263) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=503263) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=503263) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=503263) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=503263) )
(EngineCore_DP0 pid=503263) .reqntid 512
(EngineCore_DP0 pid=503263) {
(EngineCore_DP0 pid=503263) 	.reg .pred 	%p<28>;
(EngineCore_DP0 pid=503263) 	.reg .b16 	%rs<49>;
(EngineCore_DP0 pid=503263) 	.reg .b32 	%r<151>;
(EngineCore_DP0 pid=503263) 	.reg .b64 	%rd<17>;
(EngineCore_DP0 pid=503263) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=503263) $L__func_begin0:
(EngineCore_DP0 pid=503263) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=503263) 
(EngineCore_DP0 pid=503263) // %bb.0:
(EngineCore_DP0 pid=503263) 	ld.param.b32 	%r25, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=503263) 	ld.param.b32 	%r24, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=503263) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=503263) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=503263) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=503263) $L__tmp0:
(EngineCore_DP0 pid=503263) 	.loc	1 143 24                        // quant_slide_tuned_Qwen2.5-7B.py:143:24
(EngineCore_DP0 pid=503263) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=503263) 	ld.param.b32 	%r27, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=503263) 	.loc	1 148 26                        // quant_slide_tuned_Qwen2.5-7B.py:148:26
(EngineCore_DP0 pid=503263) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=503263) 	.loc	1 148 20                        // quant_slide_tuned_Qwen2.5-7B.py:148:20
(EngineCore_DP0 pid=503263) 	mad.wide.s32 	%rd1, %r28, 2, %rd4;
(EngineCore_DP0 pid=503263) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=503263) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=503263) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=503263) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=503263) 	setp.lt.s32 	%p1, %r24, 1;
(EngineCore_DP0 pid=503263) 	mov.b32 	%r149, 0f2B8CBCCC;
(EngineCore_DP0 pid=503263) 	setp.eq.b32 	%p27, %r2, 0;
(EngineCore_DP0 pid=503263) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=503263) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=503263) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=503263) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=503263) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=503263) 	shr.u32 	%r37, %r2, 3;
(EngineCore_DP0 pid=503263) 	and.b32 	%r38, %r37, 60;
(EngineCore_DP0 pid=503263) 	mov.b32 	%r39, global_smem;
(EngineCore_DP0 pid=503263) 	add.s32 	%r49, %r39, %r38;
(EngineCore_DP0 pid=503263) 	shl.b32 	%r40, %r2, 2;
(EngineCore_DP0 pid=503263) 	add.s32 	%r52, %r39, %r40;
(EngineCore_DP0 pid=503263) 	mov.b32 	%r45, 0;
(EngineCore_DP0 pid=503263) 	mov.b32 	%r147, 0f00000000;
(EngineCore_DP0 pid=503263) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=503263) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=503263) 	mov.b32 	%r148, %r45;
(EngineCore_DP0 pid=503263) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=503263) 	.loc	1 155 22                        // quant_slide_tuned_Qwen2.5-7B.py:155:22
(EngineCore_DP0 pid=503263) 	add.s32 	%r55, %r4, %r148;
(EngineCore_DP0 pid=503263) 	setp.lt.s32 	%p2, %r55, %r23;
(EngineCore_DP0 pid=503263) 	.loc	1 156 29                        // quant_slide_tuned_Qwen2.5-7B.py:156:29
(EngineCore_DP0 pid=503263) 	mad.wide.s32 	%rd6, %r55, 2, %rd1;
(EngineCore_DP0 pid=503263) 	.loc	1 156 21                        // quant_slide_tuned_Qwen2.5-7B.py:156:21
(EngineCore_DP0 pid=503263) 	// begin inline asm
(EngineCore_DP0 pid=503263) 	mov.u32 %r41, %r45;
(EngineCore_DP0 pid=503263) 	mov.u32 %r42, %r45;
(EngineCore_DP0 pid=503263) 	mov.u32 %r43, %r45;
(EngineCore_DP0 pid=503263) 	mov.u32 %r44, %r45;
(EngineCore_DP0 pid=503263) 	@%p2 ld.global.v4.b32 { %r41, %r42, %r43, %r44 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=503263) 	// end inline asm
(EngineCore_DP0 pid=503263) 	mov.b32 	{%rs1, %rs2}, %r41;
(EngineCore_DP0 pid=503263) 	mov.b32 	{%rs3, %rs4}, %r42;
(EngineCore_DP0 pid=503263) 	mov.b32 	{%rs5, %rs6}, %r43;
(EngineCore_DP0 pid=503263) 	mov.b32 	{%rs7, %rs8}, %r44;
(EngineCore_DP0 pid=503263) 	.loc	1 157 50                        // quant_slide_tuned_Qwen2.5-7B.py:157:50
(EngineCore_DP0 pid=503263) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=503263) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=503263) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=503263) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=503263) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=503263) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=503263) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=503263) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=503263) $L__tmp1:
(EngineCore_DP0 pid=503263) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=503263) 	bar.sync 	0;
(EngineCore_DP0 pid=503263) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=503263) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=503263) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=503263) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=503263) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=503263) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=503263) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=503263) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=503263) 	cvt.f32.bf16 	%r56, %rs23;
(EngineCore_DP0 pid=503263) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=503263) 	shfl.sync.bfly.b32 	%r57, %r56, 16, 31, -1;
(EngineCore_DP0 pid=503263) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=503263) 	max.f32 	%r58, %r56, %r57;
(EngineCore_DP0 pid=503263) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=503263) 	shfl.sync.bfly.b32 	%r59, %r58, 8, 31, -1;
(EngineCore_DP0 pid=503263) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=503263) 	max.f32 	%r60, %r58, %r59;
(EngineCore_DP0 pid=503263) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=503263) 	shfl.sync.bfly.b32 	%r61, %r60, 4, 31, -1;
(EngineCore_DP0 pid=503263) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=503263) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=503263) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=503263) 	shfl.sync.bfly.b32 	%r63, %r62, 2, 31, -1;
(EngineCore_DP0 pid=503263) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=503263) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=503263) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=503263) 	shfl.sync.bfly.b32 	%r65, %r64, 1, 31, -1;
(EngineCore_DP0 pid=503263) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=503263) 	max.f32 	%r50, %r64, %r65;
(EngineCore_DP0 pid=503263) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=503263) 	// begin inline asm
(EngineCore_DP0 pid=503263) 	@%p3 st.shared.b32 [ %r49 + 0 ], %r50;
(EngineCore_DP0 pid=503263) 	// end inline asm
(EngineCore_DP0 pid=503263) 	bar.sync 	0;
(EngineCore_DP0 pid=503263) 	// begin inline asm
(EngineCore_DP0 pid=503263) 	@%p4 ld.shared.b32 %r51, [ %r52 + 0 ];
(EngineCore_DP0 pid=503263) 	// end inline asm
(EngineCore_DP0 pid=503263) 	shfl.sync.bfly.b32 	%r66, %r51, 8, 31, -1;
(EngineCore_DP0 pid=503263) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=503263) 	max.f32 	%r67, %r51, %r66;
(EngineCore_DP0 pid=503263) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=503263) 	shfl.sync.bfly.b32 	%r68, %r67, 4, 31, -1;
(EngineCore_DP0 pid=503263) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=503263) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=503263) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=503263) 	shfl.sync.bfly.b32 	%r70, %r69, 2, 31, -1;
(EngineCore_DP0 pid=503263) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=503263) 	max.f32 	%r71, %r69, %r70;
(EngineCore_DP0 pid=503263) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=503263) 	shfl.sync.bfly.b32 	%r72, %r71, 1, 31, -1;
(EngineCore_DP0 pid=503263) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=503263) 	max.f32 	%r54, %r71, %r72;
(EngineCore_DP0 pid=503263) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=503263) 	// begin inline asm
(EngineCore_DP0 pid=503263) 	@%p27 st.shared.b32 [ %r52 + 0 ], %r54;
(EngineCore_DP0 pid=503263) 	// end inline asm
(EngineCore_DP0 pid=503263) 	bar.sync 	0;
(EngineCore_DP0 pid=503263) 	ld.shared.b32 	%r73, [global_smem];
(EngineCore_DP0 pid=503263) $L__tmp2:
(EngineCore_DP0 pid=503263) 	.loc	1 157 36                        // quant_slide_tuned_Qwen2.5-7B.py:157:36
(EngineCore_DP0 pid=503263) 	max.f32 	%r147, %r147, %r73;
(EngineCore_DP0 pid=503263) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=503263) 	add.s32 	%r148, %r148, 4096;
(EngineCore_DP0 pid=503263) 	setp.lt.s32 	%p6, %r148, %r24;
(EngineCore_DP0 pid=503263) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=503263) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=503263) 	.loc	1 159 32                        // quant_slide_tuned_Qwen2.5-7B.py:159:32
(EngineCore_DP0 pid=503263) 	max.f32 	%r149, %r147, 0f2B8CBCCC;
(EngineCore_DP0 pid=503263) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=503263) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-7B.py:0:32
(EngineCore_DP0 pid=503263) 	mov.b32 	%r75, 0f43E00000;
(EngineCore_DP0 pid=503263) 	.loc	1 160 32                        // quant_slide_tuned_Qwen2.5-7B.py:160:32
(EngineCore_DP0 pid=503263) 	div.full.f32 	%r76, %r149, %r75;
(EngineCore_DP0 pid=503263) 	.loc	1 160 41                        // quant_slide_tuned_Qwen2.5-7B.py:160:41
(EngineCore_DP0 pid=503263) 	max.f32 	%r74, %r76, 0f36924925;
(EngineCore_DP0 pid=503263) 	.loc	1 162 25                        // quant_slide_tuned_Qwen2.5-7B.py:162:25
(EngineCore_DP0 pid=503263) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=503263) 	.loc	1 162 30                        // quant_slide_tuned_Qwen2.5-7B.py:162:30
(EngineCore_DP0 pid=503263) 	// begin inline asm
(EngineCore_DP0 pid=503263) 	@%p27 st.global.b32 [ %rd7 + 0 ], { %r74 };
(EngineCore_DP0 pid=503263) 	// end inline asm
(EngineCore_DP0 pid=503263) 	.loc	1 165 29                        // quant_slide_tuned_Qwen2.5-7B.py:165:29
(EngineCore_DP0 pid=503263) 	shl.b32 	%r15, %r25, 2;
(EngineCore_DP0 pid=503263) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=503263) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=503263) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=503263) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=503263) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-7B.py:0:41
(EngineCore_DP0 pid=503263) 	ld.param.b32 	%r29, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=503263) 	shr.s32 	%r30, %r29, 31;
(EngineCore_DP0 pid=503263) 	shr.u32 	%r31, %r30, 30;
(EngineCore_DP0 pid=503263) 	add.s32 	%r32, %r29, %r31;
(EngineCore_DP0 pid=503263) 	shr.s32 	%r33, %r32, 2;
(EngineCore_DP0 pid=503263) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=503263) 	mul.lo.s32 	%r34, %r33, %r1;
(EngineCore_DP0 pid=503263) 	mad.wide.s32 	%rd2, %r34, 4, %rd5;
(EngineCore_DP0 pid=503263) 	div.full.f32 	%r14, %r75, %r149;
(EngineCore_DP0 pid=503263) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=503263) 	mov.b32 	%r150, 0;
(EngineCore_DP0 pid=503263) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=503263)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=503263) 	.loc	1 168 31                        // quant_slide_tuned_Qwen2.5-7B.py:168:31
(EngineCore_DP0 pid=503263) 	add.s32 	%r88, %r16, %r150;
(EngineCore_DP0 pid=503263) 	.loc	1 169 30                        // quant_slide_tuned_Qwen2.5-7B.py:169:30
(EngineCore_DP0 pid=503263) 	add.s32 	%r89, %r88, 1;
(EngineCore_DP0 pid=503263) 	setp.lt.s32 	%p17, %r88, %r15;
(EngineCore_DP0 pid=503263) 	.loc	1 172 24                        // quant_slide_tuned_Qwen2.5-7B.py:172:24
(EngineCore_DP0 pid=503263) 	shr.s32 	%r90, %r88, 31;
(EngineCore_DP0 pid=503263) 	shr.u32 	%r91, %r90, 30;
(EngineCore_DP0 pid=503263) 	add.s32 	%r92, %r88, %r91;
(EngineCore_DP0 pid=503263) 	shr.s32 	%r93, %r92, 2;
(EngineCore_DP0 pid=503263) 	.loc	1 173 23                        // quant_slide_tuned_Qwen2.5-7B.py:173:23
(EngineCore_DP0 pid=503263) 	shr.s32 	%r94, %r89, 31;
(EngineCore_DP0 pid=503263) 	shr.u32 	%r95, %r94, 30;
(EngineCore_DP0 pid=503263) 	add.s32 	%r96, %r89, %r95;
(EngineCore_DP0 pid=503263) 	and.b32 	%r97, %r96, 2147483644;
(EngineCore_DP0 pid=503263) 	sub.s32 	%r98, %r89, %r97;
(EngineCore_DP0 pid=503263) 	and.b32 	%r99, %r92, 2147483644;
(EngineCore_DP0 pid=503263) 	sub.s32 	%r100, %r88, %r99;
(EngineCore_DP0 pid=503263) 	.loc	1 174 22                        // quant_slide_tuned_Qwen2.5-7B.py:174:22
(EngineCore_DP0 pid=503263) 	mul.lo.s32 	%r101, %r93, 10;
(EngineCore_DP0 pid=503263) 	.loc	1 174 30                        // quant_slide_tuned_Qwen2.5-7B.py:174:30
(EngineCore_DP0 pid=503263) 	shl.b32 	%r102, %r100, 1;
(EngineCore_DP0 pid=503263) 	shl.b32 	%r103, %r98, 1;
(EngineCore_DP0 pid=503263) 	.loc	1 174 26                        // quant_slide_tuned_Qwen2.5-7B.py:174:26
(EngineCore_DP0 pid=503263) 	add.s32 	%r104, %r101, %r103;
(EngineCore_DP0 pid=503263) 	add.s32 	%r105, %r101, %r102;
(EngineCore_DP0 pid=503263) 	.loc	1 177 53                        // quant_slide_tuned_Qwen2.5-7B.py:177:53
(EngineCore_DP0 pid=503263) 	setp.lt.s32 	%p18, %r105, %r23;
(EngineCore_DP0 pid=503263) 	setp.lt.s32 	%p19, %r104, %r23;
(EngineCore_DP0 pid=503263) 	.loc	1 177 37                        // quant_slide_tuned_Qwen2.5-7B.py:177:37
(EngineCore_DP0 pid=503263) 	and.pred 	%p9, %p17, %p18;
(EngineCore_DP0 pid=503263) 	and.pred 	%p10, %p17, %p19;
(EngineCore_DP0 pid=503263) 	.loc	1 176 29                        // quant_slide_tuned_Qwen2.5-7B.py:176:29
(EngineCore_DP0 pid=503263) 	mad.wide.s32 	%rd8, %r105, 2, %rd1;
(EngineCore_DP0 pid=503263) 	mad.wide.s32 	%rd9, %r104, 2, %rd1;
(EngineCore_DP0 pid=503263) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=503263) 	.loc	1 176 21                        // quant_slide_tuned_Qwen2.5-7B.py:176:21
(EngineCore_DP0 pid=503263) 	// begin inline asm
(EngineCore_DP0 pid=503263) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=503263) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=503263) 	// end inline asm
(EngineCore_DP0 pid=503263) 	// begin inline asm
(EngineCore_DP0 pid=503263) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=503263) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=503263) 	// end inline asm
(EngineCore_DP0 pid=503263) 	.loc	1 177 79                        // quant_slide_tuned_Qwen2.5-7B.py:177:79
(EngineCore_DP0 pid=503263) 	cvt.f32.bf16 	%r106, %rs24;
(EngineCore_DP0 pid=503263) 	cvt.f32.bf16 	%r107, %rs26;
(EngineCore_DP0 pid=503263) 	.loc	1 179 48                        // quant_slide_tuned_Qwen2.5-7B.py:179:48
(EngineCore_DP0 pid=503263) 	or.b32 	%r108, %r105, 1;
(EngineCore_DP0 pid=503263) 	or.b32 	%r109, %r104, 1;
(EngineCore_DP0 pid=503263) 	.loc	1 179 53                        // quant_slide_tuned_Qwen2.5-7B.py:179:53
(EngineCore_DP0 pid=503263) 	setp.lt.s32 	%p20, %r108, %r23;
(EngineCore_DP0 pid=503263) 	setp.lt.s32 	%p21, %r109, %r23;
(EngineCore_DP0 pid=503263) 	.loc	1 179 37                        // quant_slide_tuned_Qwen2.5-7B.py:179:37
(EngineCore_DP0 pid=503263) 	and.pred 	%p11, %p17, %p20;
(EngineCore_DP0 pid=503263) 	and.pred 	%p12, %p17, %p21;
(EngineCore_DP0 pid=503263) 	.loc	1 178 39                        // quant_slide_tuned_Qwen2.5-7B.py:178:39
(EngineCore_DP0 pid=503263) 	add.s64 	%rd10, %rd8, 2;
(EngineCore_DP0 pid=503263) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=503263) 	.loc	1 178 21                        // quant_slide_tuned_Qwen2.5-7B.py:178:21
(EngineCore_DP0 pid=503263) 	// begin inline asm
(EngineCore_DP0 pid=503263) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=503263) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=503263) 	// end inline asm
(EngineCore_DP0 pid=503263) 	// begin inline asm
(EngineCore_DP0 pid=503263) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=503263) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=503263) 	// end inline asm
(EngineCore_DP0 pid=503263) 	.loc	1 179 79                        // quant_slide_tuned_Qwen2.5-7B.py:179:79
(EngineCore_DP0 pid=503263) 	cvt.f32.bf16 	%r110, %rs28;
(EngineCore_DP0 pid=503263) 	cvt.f32.bf16 	%r111, %rs30;
(EngineCore_DP0 pid=503263) 	.loc	1 183 48                        // quant_slide_tuned_Qwen2.5-7B.py:183:48
(EngineCore_DP0 pid=503263) 	add.s32 	%r112, %r105, 2;
(EngineCore_DP0 pid=503263) 	add.s32 	%r113, %r104, 2;
(EngineCore_DP0 pid=503263) 	add.s32 	%r114, %r105, 3;
(EngineCore_DP0 pid=503263) 	add.s32 	%r115, %r104, 3;
(EngineCore_DP0 pid=503263) 	.loc	1 183 53                        // quant_slide_tuned_Qwen2.5-7B.py:183:53
(EngineCore_DP0 pid=503263) 	setp.lt.s32 	%p22, %r115, %r23;
(EngineCore_DP0 pid=503263) 	setp.lt.s32 	%p23, %r114, %r23;
(EngineCore_DP0 pid=503263) 	setp.lt.s32 	%p24, %r113, %r23;
(EngineCore_DP0 pid=503263) 	setp.lt.s32 	%p25, %r112, %r23;
(EngineCore_DP0 pid=503263) 	.loc	1 181 37                        // quant_slide_tuned_Qwen2.5-7B.py:181:37
(EngineCore_DP0 pid=503263) 	and.pred 	%p13, %p17, %p25;
(EngineCore_DP0 pid=503263) 	and.pred 	%p14, %p17, %p24;
(EngineCore_DP0 pid=503263) 	.loc	1 180 39                        // quant_slide_tuned_Qwen2.5-7B.py:180:39
(EngineCore_DP0 pid=503263) 	add.s64 	%rd12, %rd8, 4;
(EngineCore_DP0 pid=503263) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=503263) 	.loc	1 180 21                        // quant_slide_tuned_Qwen2.5-7B.py:180:21
(EngineCore_DP0 pid=503263) 	// begin inline asm
(EngineCore_DP0 pid=503263) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=503263) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=503263) 	// end inline asm
(EngineCore_DP0 pid=503263) 	// begin inline asm
(EngineCore_DP0 pid=503263) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=503263) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=503263) 	// end inline asm
(EngineCore_DP0 pid=503263) 	.loc	1 181 79                        // quant_slide_tuned_Qwen2.5-7B.py:181:79
(EngineCore_DP0 pid=503263) 	cvt.f32.bf16 	%r116, %rs32;
(EngineCore_DP0 pid=503263) 	cvt.f32.bf16 	%r117, %rs34;
(EngineCore_DP0 pid=503263) 	.loc	1 183 37                        // quant_slide_tuned_Qwen2.5-7B.py:183:37
(EngineCore_DP0 pid=503263) 	and.pred 	%p15, %p17, %p23;
(EngineCore_DP0 pid=503263) 	and.pred 	%p16, %p17, %p22;
(EngineCore_DP0 pid=503263) 	.loc	1 182 39                        // quant_slide_tuned_Qwen2.5-7B.py:182:39
(EngineCore_DP0 pid=503263) 	add.s64 	%rd14, %rd8, 6;
(EngineCore_DP0 pid=503263) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=503263) 	.loc	1 182 21                        // quant_slide_tuned_Qwen2.5-7B.py:182:21
(EngineCore_DP0 pid=503263) 	// begin inline asm
(EngineCore_DP0 pid=503263) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=503263) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=503263) 	// end inline asm
(EngineCore_DP0 pid=503263) 	// begin inline asm
(EngineCore_DP0 pid=503263) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=503263) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=503263) 	// end inline asm
(EngineCore_DP0 pid=503263) 	.loc	1 183 79                        // quant_slide_tuned_Qwen2.5-7B.py:183:79
(EngineCore_DP0 pid=503263) 	cvt.f32.bf16 	%r118, %rs36;
(EngineCore_DP0 pid=503263) 	cvt.f32.bf16 	%r119, %rs38;
(EngineCore_DP0 pid=503263) 	.loc	1 185 27                        // quant_slide_tuned_Qwen2.5-7B.py:185:27
(EngineCore_DP0 pid=503263) 	mul.f32 	%r120, %r14, %r106;
(EngineCore_DP0 pid=503263) 	mul.f32 	%r121, %r14, %r107;
(EngineCore_DP0 pid=503263) 	mov.b32 	%r122, 0f43E00000;
(EngineCore_DP0 pid=503263) 	.loc	1 185 48                        // quant_slide_tuned_Qwen2.5-7B.py:185:48
(EngineCore_DP0 pid=503263) 	min.xorsign.abs.f32 	%r78, %r120, %r122;
(EngineCore_DP0 pid=503263) 	min.xorsign.abs.f32 	%r79, %r121, %r122;
(EngineCore_DP0 pid=503263) 	.loc	1 185 60                        // quant_slide_tuned_Qwen2.5-7B.py:185:60
(EngineCore_DP0 pid=503263) 	// begin inline asm
(EngineCore_DP0 pid=503263) 	cvt.rn.satfinite.e4m3x2.f32  %rs40, %r79, %r78; 
(EngineCore_DP0 pid=503263) 
(EngineCore_DP0 pid=503263) 	// end inline asm
(EngineCore_DP0 pid=503263) 	shr.u16 	%rs44, %rs40, 8;
(EngineCore_DP0 pid=503263) 	.loc	1 186 27                        // quant_slide_tuned_Qwen2.5-7B.py:186:27
(EngineCore_DP0 pid=503263) 	mul.f32 	%r123, %r14, %r110;
(EngineCore_DP0 pid=503263) 	mul.f32 	%r124, %r14, %r111;
(EngineCore_DP0 pid=503263) 	.loc	1 186 48                        // quant_slide_tuned_Qwen2.5-7B.py:186:48
(EngineCore_DP0 pid=503263) 	min.xorsign.abs.f32 	%r80, %r123, %r122;
(EngineCore_DP0 pid=503263) 	min.xorsign.abs.f32 	%r81, %r124, %r122;
(EngineCore_DP0 pid=503263) 	.loc	1 186 60                        // quant_slide_tuned_Qwen2.5-7B.py:186:60
(EngineCore_DP0 pid=503263) 	// begin inline asm
(EngineCore_DP0 pid=503263) 	cvt.rn.satfinite.e4m3x2.f32  %rs41, %r81, %r80; 
(EngineCore_DP0 pid=503263) 
(EngineCore_DP0 pid=503263) 	// end inline asm
(EngineCore_DP0 pid=503263) 	shr.u16 	%rs45, %rs41, 8;
(EngineCore_DP0 pid=503263) 	.loc	1 187 27                        // quant_slide_tuned_Qwen2.5-7B.py:187:27
(EngineCore_DP0 pid=503263) 	mul.f32 	%r125, %r14, %r116;
(EngineCore_DP0 pid=503263) 	mul.f32 	%r126, %r14, %r117;
(EngineCore_DP0 pid=503263) 	.loc	1 187 48                        // quant_slide_tuned_Qwen2.5-7B.py:187:48
(EngineCore_DP0 pid=503263) 	min.xorsign.abs.f32 	%r82, %r125, %r122;
(EngineCore_DP0 pid=503263) 	min.xorsign.abs.f32 	%r83, %r126, %r122;
(EngineCore_DP0 pid=503263) 	.loc	1 187 60                        // quant_slide_tuned_Qwen2.5-7B.py:187:60
(EngineCore_DP0 pid=503263) 	// begin inline asm
(EngineCore_DP0 pid=503263) 	cvt.rn.satfinite.e4m3x2.f32  %rs42, %r83, %r82; 
(EngineCore_DP0 pid=503263) 
(EngineCore_DP0 pid=503263) 	// end inline asm
(EngineCore_DP0 pid=503263) 	shr.u16 	%rs46, %rs42, 8;
(EngineCore_DP0 pid=503263) 	.loc	1 188 27                        // quant_slide_tuned_Qwen2.5-7B.py:188:27
(EngineCore_DP0 pid=503263) 	mul.f32 	%r127, %r14, %r118;
(EngineCore_DP0 pid=503263) 	mul.f32 	%r128, %r14, %r119;
(EngineCore_DP0 pid=503263) 	.loc	1 188 48                        // quant_slide_tuned_Qwen2.5-7B.py:188:48
(EngineCore_DP0 pid=503263) 	min.xorsign.abs.f32 	%r84, %r127, %r122;
(EngineCore_DP0 pid=503263) 	min.xorsign.abs.f32 	%r85, %r128, %r122;
(EngineCore_DP0 pid=503263) 	.loc	1 188 60                        // quant_slide_tuned_Qwen2.5-7B.py:188:60
(EngineCore_DP0 pid=503263) 	// begin inline asm
(EngineCore_DP0 pid=503263) 	cvt.rn.satfinite.e4m3x2.f32  %rs43, %r85, %r84; 
(EngineCore_DP0 pid=503263) 
(EngineCore_DP0 pid=503263) 	// end inline asm
(EngineCore_DP0 pid=503263) 	shr.u16 	%rs47, %rs43, 8;
(EngineCore_DP0 pid=503263) 	.loc	1 190 45                        // quant_slide_tuned_Qwen2.5-7B.py:190:45
(EngineCore_DP0 pid=503263) 	cvt.u32.u16 	%r129, %rs40;
(EngineCore_DP0 pid=503263) 	and.b32 	%r130, %r129, 255;
(EngineCore_DP0 pid=503263) 	cvt.u32.u16 	%r131, %rs44;
(EngineCore_DP0 pid=503263) 	.loc	1 192 45                        // quant_slide_tuned_Qwen2.5-7B.py:192:45
(EngineCore_DP0 pid=503263) 	cvt.u32.u16 	%r132, %rs42;
(EngineCore_DP0 pid=503263) 	and.b32 	%r133, %r132, 255;
(EngineCore_DP0 pid=503263) 	cvt.u32.u16 	%r134, %rs46;
(EngineCore_DP0 pid=503263) 	.loc	1 193 45                        // quant_slide_tuned_Qwen2.5-7B.py:193:45
(EngineCore_DP0 pid=503263) 	cvt.u32.u16 	%r135, %rs43;
(EngineCore_DP0 pid=503263) 	cvt.u32.u16 	%r136, %rs47;
(EngineCore_DP0 pid=503263) 	.loc	1 195 30                        // quant_slide_tuned_Qwen2.5-7B.py:195:30
(EngineCore_DP0 pid=503263) 	and.b16 	%rs48, %rs41, 255;
(EngineCore_DP0 pid=503263) 	mul.wide.u16 	%r137, %rs48, 256;
(EngineCore_DP0 pid=503263) 	mul.wide.u16 	%r138, %rs45, 256;
(EngineCore_DP0 pid=503263) 	.loc	1 195 24                        // quant_slide_tuned_Qwen2.5-7B.py:195:24
(EngineCore_DP0 pid=503263) 	or.b32 	%r139, %r137, %r130;
(EngineCore_DP0 pid=503263) 	or.b32 	%r140, %r138, %r131;
(EngineCore_DP0 pid=503263) 	.loc	1 195 42                        // quant_slide_tuned_Qwen2.5-7B.py:195:42
(EngineCore_DP0 pid=503263) 	shl.b32 	%r141, %r133, 16;
(EngineCore_DP0 pid=503263) 	shl.b32 	%r142, %r134, 16;
(EngineCore_DP0 pid=503263) 	.loc	1 195 36                        // quant_slide_tuned_Qwen2.5-7B.py:195:36
(EngineCore_DP0 pid=503263) 	or.b32 	%r143, %r139, %r141;
(EngineCore_DP0 pid=503263) 	or.b32 	%r144, %r140, %r142;
(EngineCore_DP0 pid=503263) 	.loc	1 195 55                        // quant_slide_tuned_Qwen2.5-7B.py:195:55
(EngineCore_DP0 pid=503263) 	shl.b32 	%r145, %r135, 24;
(EngineCore_DP0 pid=503263) 	shl.b32 	%r146, %r136, 24;
(EngineCore_DP0 pid=503263) 	.loc	1 195 49                        // quant_slide_tuned_Qwen2.5-7B.py:195:49
(EngineCore_DP0 pid=503263) 	or.b32 	%r86, %r143, %r145;
(EngineCore_DP0 pid=503263) 	or.b32 	%r87, %r144, %r146;
(EngineCore_DP0 pid=503263) 	.loc	1 196 29                        // quant_slide_tuned_Qwen2.5-7B.py:196:29
(EngineCore_DP0 pid=503263) 	mad.wide.s32 	%rd16, %r88, 4, %rd2;
(EngineCore_DP0 pid=503263) 	.loc	1 196 39                        // quant_slide_tuned_Qwen2.5-7B.py:196:39
(EngineCore_DP0 pid=503263) 	// begin inline asm
(EngineCore_DP0 pid=503263) 	@%p17 st.global.v2.b32 [ %rd16 + 0 ], { %r86, %r87 };
(EngineCore_DP0 pid=503263) 	// end inline asm
(EngineCore_DP0 pid=503263) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=503263) 	add.s32 	%r150, %r150, 1024;
(EngineCore_DP0 pid=503263) 	setp.lt.s32 	%p26, %r150, %r15;
(EngineCore_DP0 pid=503263) 	@%p26 bra 	$L__BB0_6;
(EngineCore_DP0 pid=503263) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=503263) 	.loc	1 167 4                         // quant_slide_tuned_Qwen2.5-7B.py:167:4
(EngineCore_DP0 pid=503263) 	ret;
(EngineCore_DP0 pid=503263) $L__tmp3:
(EngineCore_DP0 pid=503263) $L__func_end0:
(EngineCore_DP0 pid=503263)                                         // -- End function
(EngineCore_DP0 pid=503263) }
(EngineCore_DP0 pid=503263) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py"
(EngineCore_DP0 pid=503263) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=503263) 	.section	.debug_abbrev
(EngineCore_DP0 pid=503263) 	{
(EngineCore_DP0 pid=503263) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=503263) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=503263) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=503263) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=503263) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=503263) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=503263) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=503263) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=503263) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=503263) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=503263) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=503263) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=503263) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=503263) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=503263) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=503263) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=503263) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=503263) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=503263) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=503263) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=503263) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=503263) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=503263) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=503263) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=503263) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=503263) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=503263) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=503263) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=503263) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=503263) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=503263) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=503263) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=503263) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=503263) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=503263) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=503263) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=503263) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=503263) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=503263) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=503263) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=503263) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=503263) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=503263) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=503263) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=503263) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=503263) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=503263) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=503263) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=503263) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=503263) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=503263) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=503263) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=503263) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=503263) 	}
(EngineCore_DP0 pid=503263) 	.section	.debug_info
(EngineCore_DP0 pid=503263) 	{
(EngineCore_DP0 pid=503263) .b32 221                                // Length of Unit
(EngineCore_DP0 pid=503263) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=503263) .b8 0
(EngineCore_DP0 pid=503263) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=503263) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=503263) .b8 1                                   // Abbrev [1] 0xb:0xd6 DW_TAG_compile_unit
(EngineCore_DP0 pid=503263) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=503263) .b8 114
(EngineCore_DP0 pid=503263) .b8 105
(EngineCore_DP0 pid=503263) .b8 116
(EngineCore_DP0 pid=503263) .b8 111
(EngineCore_DP0 pid=503263) .b8 110
(EngineCore_DP0 pid=503263) .b8 0
(EngineCore_DP0 pid=503263) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=503263) .b8 0
(EngineCore_DP0 pid=503263) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=503263) .b8 117
(EngineCore_DP0 pid=503263) .b8 97
(EngineCore_DP0 pid=503263) .b8 110
(EngineCore_DP0 pid=503263) .b8 116
(EngineCore_DP0 pid=503263) .b8 95
(EngineCore_DP0 pid=503263) .b8 115
(EngineCore_DP0 pid=503263) .b8 108
(EngineCore_DP0 pid=503263) .b8 105
(EngineCore_DP0 pid=503263) .b8 100
(EngineCore_DP0 pid=503263) .b8 101
(EngineCore_DP0 pid=503263) .b8 95
(EngineCore_DP0 pid=503263) .b8 116
(EngineCore_DP0 pid=503263) .b8 117
(EngineCore_DP0 pid=503263) .b8 110
(EngineCore_DP0 pid=503263) .b8 101
(EngineCore_DP0 pid=503263) .b8 100
(EngineCore_DP0 pid=503263) .b8 95
(EngineCore_DP0 pid=503263) .b8 81
(EngineCore_DP0 pid=503263) .b8 119
(EngineCore_DP0 pid=503263) .b8 101
(EngineCore_DP0 pid=503263) .b8 110
(EngineCore_DP0 pid=503263) .b8 50
(EngineCore_DP0 pid=503263) .b8 46
(EngineCore_DP0 pid=503263) .b8 53
(EngineCore_DP0 pid=503263) .b8 45
(EngineCore_DP0 pid=503263) .b8 55
(EngineCore_DP0 pid=503263) .b8 66
(EngineCore_DP0 pid=503263) .b8 46
(EngineCore_DP0 pid=503263) .b8 112
(EngineCore_DP0 pid=503263) .b8 121
(EngineCore_DP0 pid=503263) .b8 0
(EngineCore_DP0 pid=503263) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=503263) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=503263) .b8 114
(EngineCore_DP0 pid=503263) .b8 111
(EngineCore_DP0 pid=503263) .b8 111
(EngineCore_DP0 pid=503263) .b8 116
(EngineCore_DP0 pid=503263) .b8 47
(EngineCore_DP0 pid=503263) .b8 118
(EngineCore_DP0 pid=503263) .b8 108
(EngineCore_DP0 pid=503263) .b8 108
(EngineCore_DP0 pid=503263) .b8 109
(EngineCore_DP0 pid=503263) .b8 98
(EngineCore_DP0 pid=503263) .b8 101
(EngineCore_DP0 pid=503263) .b8 110
(EngineCore_DP0 pid=503263) .b8 99
(EngineCore_DP0 pid=503263) .b8 104
(EngineCore_DP0 pid=503263) .b8 47
(EngineCore_DP0 pid=503263) .b8 115
(EngineCore_DP0 pid=503263) .b8 108
(EngineCore_DP0 pid=503263) .b8 105
(EngineCore_DP0 pid=503263) .b8 100
(EngineCore_DP0 pid=503263) .b8 101
(EngineCore_DP0 pid=503263) .b8 115
(EngineCore_DP0 pid=503263) .b8 112
(EngineCore_DP0 pid=503263) .b8 97
(EngineCore_DP0 pid=503263) .b8 114
(EngineCore_DP0 pid=503263) .b8 115
(EngineCore_DP0 pid=503263) .b8 101
(EngineCore_DP0 pid=503263) .b8 47
(EngineCore_DP0 pid=503263) .b8 99
(EngineCore_DP0 pid=503263) .b8 115
(EngineCore_DP0 pid=503263) .b8 114
(EngineCore_DP0 pid=503263) .b8 99
(EngineCore_DP0 pid=503263) .b8 47
(EngineCore_DP0 pid=503263) .b8 102
(EngineCore_DP0 pid=503263) .b8 117
(EngineCore_DP0 pid=503263) .b8 115
(EngineCore_DP0 pid=503263) .b8 101
(EngineCore_DP0 pid=503263) .b8 100
(EngineCore_DP0 pid=503263) .b8 95
(EngineCore_DP0 pid=503263) .b8 113
(EngineCore_DP0 pid=503263) .b8 117
(EngineCore_DP0 pid=503263) .b8 97
(EngineCore_DP0 pid=503263) .b8 110
(EngineCore_DP0 pid=503263) .b8 116
(EngineCore_DP0 pid=503263) .b8 95
(EngineCore_DP0 pid=503263) .b8 115
(EngineCore_DP0 pid=503263) .b8 108
(EngineCore_DP0 pid=503263) .b8 105
(EngineCore_DP0 pid=503263) .b8 100
(EngineCore_DP0 pid=503263) .b8 101
(EngineCore_DP0 pid=503263) .b8 95
(EngineCore_DP0 pid=503263) .b8 116
(EngineCore_DP0 pid=503263) .b8 114
(EngineCore_DP0 pid=503263) .b8 105
(EngineCore_DP0 pid=503263) .b8 116
(EngineCore_DP0 pid=503263) .b8 111
(EngineCore_DP0 pid=503263) .b8 110
(EngineCore_DP0 pid=503263) .b8 47
(EngineCore_DP0 pid=503263) .b8 98
(EngineCore_DP0 pid=503263) .b8 117
(EngineCore_DP0 pid=503263) .b8 105
(EngineCore_DP0 pid=503263) .b8 108
(EngineCore_DP0 pid=503263) .b8 100
(EngineCore_DP0 pid=503263) .b8 47
(EngineCore_DP0 pid=503263) .b8 71
(EngineCore_DP0 pid=503263) .b8 66
(EngineCore_DP0 pid=503263) .b8 49
(EngineCore_DP0 pid=503263) .b8 48
(EngineCore_DP0 pid=503263) .b8 95
(EngineCore_DP0 pid=503263) .b8 99
(EngineCore_DP0 pid=503263) .b8 99
(EngineCore_DP0 pid=503263) .b8 49
(EngineCore_DP0 pid=503263) .b8 50
(EngineCore_DP0 pid=503263) .b8 49
(EngineCore_DP0 pid=503263) .b8 95
(EngineCore_DP0 pid=503263) .b8 112
(EngineCore_DP0 pid=503263) .b8 121
(EngineCore_DP0 pid=503263) .b8 51
(EngineCore_DP0 pid=503263) .b8 49
(EngineCore_DP0 pid=503263) .b8 50
(EngineCore_DP0 pid=503263) .b8 95
(EngineCore_DP0 pid=503263) .b8 99
(EngineCore_DP0 pid=503263) .b8 117
(EngineCore_DP0 pid=503263) .b8 49
(EngineCore_DP0 pid=503263) .b8 50
(EngineCore_DP0 pid=503263) .b8 57
(EngineCore_DP0 pid=503263) .b8 95
(EngineCore_DP0 pid=503263) .b8 97
(EngineCore_DP0 pid=503263) .b8 97
(EngineCore_DP0 pid=503263) .b8 114
(EngineCore_DP0 pid=503263) .b8 99
(EngineCore_DP0 pid=503263) .b8 104
(EngineCore_DP0 pid=503263) .b8 54
(EngineCore_DP0 pid=503263) .b8 52
(EngineCore_DP0 pid=503263) .b8 0
(EngineCore_DP0 pid=503263) .b8 2                                   // Abbrev [2] 0x98:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=503263) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=503263) .b8 113
(EngineCore_DP0 pid=503263) .b8 117
(EngineCore_DP0 pid=503263) .b8 97
(EngineCore_DP0 pid=503263) .b8 110
(EngineCore_DP0 pid=503263) .b8 116
(EngineCore_DP0 pid=503263) .b8 95
(EngineCore_DP0 pid=503263) .b8 115
(EngineCore_DP0 pid=503263) .b8 108
(EngineCore_DP0 pid=503263) .b8 105
(EngineCore_DP0 pid=503263) .b8 100
(EngineCore_DP0 pid=503263) .b8 101
(EngineCore_DP0 pid=503263) .b8 95
(EngineCore_DP0 pid=503263) .b8 102
(EngineCore_DP0 pid=503263) .b8 112
(EngineCore_DP0 pid=503263) .b8 56
(EngineCore_DP0 pid=503263) .b8 95
(EngineCore_DP0 pid=503263) .b8 107
(EngineCore_DP0 pid=503263) .b8 101
(EngineCore_DP0 pid=503263) .b8 114
(EngineCore_DP0 pid=503263) .b8 110
(EngineCore_DP0 pid=503263) .b8 101
(EngineCore_DP0 pid=503263) .b8 108
(EngineCore_DP0 pid=503263) .b8 0
(EngineCore_DP0 pid=503263) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=503263) .b8 3                                   // Abbrev [3] 0xb2:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=503263) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=503263) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=503263) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=503263) .b8 4                                   // Abbrev [4] 0xc7:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=503263) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=503263) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=503263) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=503263) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=503263) .b8 157                                 // DW_AT_call_line
(EngineCore_DP0 pid=503263) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=503263) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=503263) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=503263) 	}
(EngineCore_DP0 pid=503263) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=503263) 
(EngineCore_DP0 pid=503263) ================================================================
(EngineCore_DP0 pid=503263) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=503263) 
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpbqwx5tg4.ptx', '-o', '/tmp/tmpbqwx5tg4.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866] 
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866] 
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866] 
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpbqwx5tg4.ptx -o /tmp/tmpbqwx5tg4.ptx.o
(EngineCore_DP0 pid=503263) ERROR 01-25 21:55:24 [core.py:866] 

STDERR:
[2026-01-25 21:54:13] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:54:13] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:54:13] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:54:13] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:54:13] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:54:13] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:54:13] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:54:13] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:54:13] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:54:13] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:54:13] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:54:13] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:54:13] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:54:13] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:54:16] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:54:16] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:54:16] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:54:16] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:54:16] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:54:16] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:54:16] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:54:16] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:54:16] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:54:16] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:54:16] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:54:16] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:54:16] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:54:16] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=503263) [2026-01-25 21:54:17] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=503263) [2026-01-25 21:54:17] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=503263) [2026-01-25 21:54:17] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=503263) [2026-01-25 21:54:17] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=503263) [2026-01-25 21:54:17] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=503263) [2026-01-25 21:54:17] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=503263) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=503263) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:27<00:27, 27.61s/it]
(EngineCore_DP0 pid=503263) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:04<00:00, 32.96s/it]
(EngineCore_DP0 pid=503263) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:04<00:00, 32.16s/it]
(EngineCore_DP0 pid=503263) 
(EngineCore_DP0 pid=503263) [2026-01-25 21:55:23] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=503263) [2026-01-25 21:55:23] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16588800 bytes
(EngineCore_DP0 pid=503263) [2026-01-25 21:55:23] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=503263) [2026-01-25 21:55:23] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 12902400 bytes
(EngineCore_DP0 pid=503263) [2026-01-25 21:55:23] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=503263) [2026-01-25 21:55:23] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 136396800 bytes
(EngineCore_DP0 pid=503263) [2026-01-25 21:55:23] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=503263) [2026-01-25 21:55:23] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 67952640 bytes
(EngineCore_DP0 pid=503263) Process EngineCore_DP0:
(EngineCore_DP0 pid=503263) Traceback (most recent call last):
(EngineCore_DP0 pid=503263)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=503263)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=503263)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=503263)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=503263) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpbqwx5tg4.ptx', '-o', '/tmp/tmpbqwx5tg4.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=503263) 
(EngineCore_DP0 pid=503263) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=503263) 
(EngineCore_DP0 pid=503263) Traceback (most recent call last):
(EngineCore_DP0 pid=503263)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=503263)     self.run()
(EngineCore_DP0 pid=503263)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=503263)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=503263)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=503263)     raise e
(EngineCore_DP0 pid=503263)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=503263)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=503263)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=503263)     super().__init__(
(EngineCore_DP0 pid=503263)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=503263)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=503263)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=503263)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=503263)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=503263)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=503263)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=503263)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=503263)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=503263)     return func(*args, **kwargs)
(EngineCore_DP0 pid=503263)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=503263)     return func(*args, **kwargs)
(EngineCore_DP0 pid=503263)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=503263)     self.model_runner.profile_run()
(EngineCore_DP0 pid=503263)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=503263)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=503263)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=503263)     return func(*args, **kwargs)
(EngineCore_DP0 pid=503263)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=503263)     outputs = self.model(
(EngineCore_DP0 pid=503263)               ^^^^^^^^^^^
(EngineCore_DP0 pid=503263)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=503263)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=503263)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=503263)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=503263)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=503263)     hidden_states = self.model(
(EngineCore_DP0 pid=503263)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=503263)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=503263)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=503263)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=503263)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=503263)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=503263)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=503263)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=503263)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=503263)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=503263)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=503263)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=503263)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=503263)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=503263)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=503263)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=503263)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=503263)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=503263)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=503263)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=503263)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=503263)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=503263)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=503263)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=503263)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=503263)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=503263)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=503263)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=503263)     return self._linear_fn(
(EngineCore_DP0 pid=503263)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=503263)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=503263)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=503263)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=503263)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=503263)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=503263)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=503263)     return fn(input, L)
(EngineCore_DP0 pid=503263)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=503263)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=503263)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=503263)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=503263)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=503263)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=503263)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=503263)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=503263)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=503263)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=503263)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=503263)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=503263)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=503263)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=503263)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=503263)     raise PTXASError(error)
(EngineCore_DP0 pid=503263) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=503263) `ptxas` stderr:
(EngineCore_DP0 pid=503263) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=503263) 
(EngineCore_DP0 pid=503263) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpbqwx5tg4.ptx -o /tmp/tmpbqwx5tg4.ptx.o
(EngineCore_DP0 pid=503263) 
[rank0]:[W125 21:55:24.773122308 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=32768

========== M=65536 ==========
Time: 2026-01-25 21:55:26
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Qwen2.5-7B-FP8_M65536.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:55:58 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 21:55:58 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=504917) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=504917) 
(EngineCore_DP0 pid=504917) 
(EngineCore_DP0 pid=504917) ================================================================
(EngineCore_DP0 pid=504917) Internal Triton PTX codegen error
(EngineCore_DP0 pid=504917) `ptxas` stderr:
(EngineCore_DP0 pid=504917) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=504917) 
(EngineCore_DP0 pid=504917) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpqr377dok.ptx -o /tmp/tmpqr377dok.ptx.o
(EngineCore_DP0 pid=504917) 
(EngineCore_DP0 pid=504917) 
(EngineCore_DP0 pid=504917) //
(EngineCore_DP0 pid=504917) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=504917) //
(EngineCore_DP0 pid=504917) 
(EngineCore_DP0 pid=504917) .version 8.7
(EngineCore_DP0 pid=504917) .target sm_121a
(EngineCore_DP0 pid=504917) .address_size 64
(EngineCore_DP0 pid=504917) 
(EngineCore_DP0 pid=504917) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=504917) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=504917)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=504917) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=504917) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=504917) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=504917) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=504917) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=504917) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=504917) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=504917) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=504917) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=504917) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=504917) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=504917) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=504917) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=504917) )
(EngineCore_DP0 pid=504917) .reqntid 512
(EngineCore_DP0 pid=504917) {
(EngineCore_DP0 pid=504917) 	.reg .pred 	%p<21>;
(EngineCore_DP0 pid=504917) 	.reg .b16 	%rs<61>;
(EngineCore_DP0 pid=504917) 	.reg .b32 	%r<127>;
(EngineCore_DP0 pid=504917) 	.reg .b64 	%rd<14>;
(EngineCore_DP0 pid=504917) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=504917) $L__func_begin0:
(EngineCore_DP0 pid=504917) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=504917) 
(EngineCore_DP0 pid=504917) // %bb.0:
(EngineCore_DP0 pid=504917) 	ld.param.b32 	%r20, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=504917) 	ld.param.b32 	%r19, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=504917) 	ld.param.b32 	%r18, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=504917) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=504917) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=504917) $L__tmp0:
(EngineCore_DP0 pid=504917) 	.loc	1 143 24                        // quant_slide_tuned_Qwen2.5-7B.py:143:24
(EngineCore_DP0 pid=504917) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=504917) 	ld.param.b32 	%r22, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=504917) 	.loc	1 148 26                        // quant_slide_tuned_Qwen2.5-7B.py:148:26
(EngineCore_DP0 pid=504917) 	mul.lo.s32 	%r23, %r22, %r1;
(EngineCore_DP0 pid=504917) 	.loc	1 148 20                        // quant_slide_tuned_Qwen2.5-7B.py:148:20
(EngineCore_DP0 pid=504917) 	mad.wide.s32 	%rd1, %r23, 2, %rd4;
(EngineCore_DP0 pid=504917) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=504917) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=504917) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=504917) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=504917) 	setp.lt.s32 	%p1, %r19, 1;
(EngineCore_DP0 pid=504917) 	mov.b32 	%r125, 0f2B8CBCCC;
(EngineCore_DP0 pid=504917) 	setp.eq.b32 	%p20, %r2, 0;
(EngineCore_DP0 pid=504917) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=504917) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=504917) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=504917) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=504917) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=504917) 	shr.u32 	%r32, %r2, 3;
(EngineCore_DP0 pid=504917) 	and.b32 	%r33, %r32, 60;
(EngineCore_DP0 pid=504917) 	mov.b32 	%r34, global_smem;
(EngineCore_DP0 pid=504917) 	add.s32 	%r52, %r34, %r33;
(EngineCore_DP0 pid=504917) 	shl.b32 	%r35, %r2, 2;
(EngineCore_DP0 pid=504917) 	add.s32 	%r55, %r34, %r35;
(EngineCore_DP0 pid=504917) 	mov.b32 	%r40, 0;
(EngineCore_DP0 pid=504917) 	mov.b32 	%r123, 0f00000000;
(EngineCore_DP0 pid=504917) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=504917) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=504917) 	mov.b32 	%r124, %r40;
(EngineCore_DP0 pid=504917) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=504917) 	.loc	1 154 19                        // quant_slide_tuned_Qwen2.5-7B.py:154:19
(EngineCore_DP0 pid=504917) 	add.s32 	%r58, %r4, %r124;
(EngineCore_DP0 pid=504917) 	.loc	1 155 22                        // quant_slide_tuned_Qwen2.5-7B.py:155:22
(EngineCore_DP0 pid=504917) 	add.s32 	%r59, %r58, 4096;
(EngineCore_DP0 pid=504917) 	setp.lt.s32 	%p2, %r58, %r18;
(EngineCore_DP0 pid=504917) 	setp.lt.s32 	%p3, %r59, %r18;
(EngineCore_DP0 pid=504917) 	.loc	1 156 29                        // quant_slide_tuned_Qwen2.5-7B.py:156:29
(EngineCore_DP0 pid=504917) 	mad.wide.s32 	%rd6, %r58, 2, %rd1;
(EngineCore_DP0 pid=504917) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=504917) 	.loc	1 156 21                        // quant_slide_tuned_Qwen2.5-7B.py:156:21
(EngineCore_DP0 pid=504917) 	// begin inline asm
(EngineCore_DP0 pid=504917) 	mov.u32 %r36, %r40;
(EngineCore_DP0 pid=504917) 	mov.u32 %r37, %r40;
(EngineCore_DP0 pid=504917) 	mov.u32 %r38, %r40;
(EngineCore_DP0 pid=504917) 	mov.u32 %r39, %r40;
(EngineCore_DP0 pid=504917) 	@%p2 ld.global.v4.b32 { %r36, %r37, %r38, %r39 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=504917) 	// end inline asm
(EngineCore_DP0 pid=504917) 	mov.b32 	{%rs1, %rs2}, %r36;
(EngineCore_DP0 pid=504917) 	mov.b32 	{%rs3, %rs4}, %r37;
(EngineCore_DP0 pid=504917) 	mov.b32 	{%rs5, %rs6}, %r38;
(EngineCore_DP0 pid=504917) 	mov.b32 	{%rs7, %rs8}, %r39;
(EngineCore_DP0 pid=504917) 	// begin inline asm
(EngineCore_DP0 pid=504917) 	mov.u32 %r44, %r40;
(EngineCore_DP0 pid=504917) 	mov.u32 %r45, %r40;
(EngineCore_DP0 pid=504917) 	mov.u32 %r46, %r40;
(EngineCore_DP0 pid=504917) 	mov.u32 %r47, %r40;
(EngineCore_DP0 pid=504917) 	@%p3 ld.global.v4.b32 { %r44, %r45, %r46, %r47 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=504917) 	// end inline asm
(EngineCore_DP0 pid=504917) 	mov.b32 	{%rs9, %rs10}, %r44;
(EngineCore_DP0 pid=504917) 	mov.b32 	{%rs11, %rs12}, %r45;
(EngineCore_DP0 pid=504917) 	mov.b32 	{%rs13, %rs14}, %r46;
(EngineCore_DP0 pid=504917) 	mov.b32 	{%rs15, %rs16}, %r47;
(EngineCore_DP0 pid=504917) 	.loc	1 157 50                        // quant_slide_tuned_Qwen2.5-7B.py:157:50
(EngineCore_DP0 pid=504917) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=504917) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=504917) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=504917) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=504917) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=504917) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=504917) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=504917) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=504917) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=504917) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=504917) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=504917) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=504917) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=504917) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=504917) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=504917) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=504917) $L__tmp1:
(EngineCore_DP0 pid=504917) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=504917) 	bar.sync 	0;
(EngineCore_DP0 pid=504917) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=504917) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=504917) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=504917) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=504917) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=504917) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=504917) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=504917) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=504917) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=504917) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=504917) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=504917) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=504917) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=504917) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=504917) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=504917) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=504917) 	cvt.f32.bf16 	%r60, %rs47;
(EngineCore_DP0 pid=504917) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=504917) 	shfl.sync.bfly.b32 	%r61, %r60, 16, 31, -1;
(EngineCore_DP0 pid=504917) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=504917) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=504917) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=504917) 	shfl.sync.bfly.b32 	%r63, %r62, 8, 31, -1;
(EngineCore_DP0 pid=504917) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=504917) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=504917) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=504917) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=504917) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=504917) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=504917) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=504917) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=504917) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=504917) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=504917) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=504917) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=504917) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=504917) 	max.f32 	%r53, %r68, %r69;
(EngineCore_DP0 pid=504917) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=504917) 	// begin inline asm
(EngineCore_DP0 pid=504917) 	@%p4 st.shared.b32 [ %r52 + 0 ], %r53;
(EngineCore_DP0 pid=504917) 	// end inline asm
(EngineCore_DP0 pid=504917) 	bar.sync 	0;
(EngineCore_DP0 pid=504917) 	// begin inline asm
(EngineCore_DP0 pid=504917) 	@%p5 ld.shared.b32 %r54, [ %r55 + 0 ];
(EngineCore_DP0 pid=504917) 	// end inline asm
(EngineCore_DP0 pid=504917) 	shfl.sync.bfly.b32 	%r70, %r54, 8, 31, -1;
(EngineCore_DP0 pid=504917) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=504917) 	max.f32 	%r71, %r54, %r70;
(EngineCore_DP0 pid=504917) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=504917) 	shfl.sync.bfly.b32 	%r72, %r71, 4, 31, -1;
(EngineCore_DP0 pid=504917) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=504917) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=504917) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=504917) 	shfl.sync.bfly.b32 	%r74, %r73, 2, 31, -1;
(EngineCore_DP0 pid=504917) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=504917) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=504917) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=504917) 	shfl.sync.bfly.b32 	%r76, %r75, 1, 31, -1;
(EngineCore_DP0 pid=504917) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=504917) 	max.f32 	%r57, %r75, %r76;
(EngineCore_DP0 pid=504917) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=504917) 	// begin inline asm
(EngineCore_DP0 pid=504917) 	@%p20 st.shared.b32 [ %r55 + 0 ], %r57;
(EngineCore_DP0 pid=504917) 	// end inline asm
(EngineCore_DP0 pid=504917) 	bar.sync 	0;
(EngineCore_DP0 pid=504917) 	ld.shared.b32 	%r77, [global_smem];
(EngineCore_DP0 pid=504917) $L__tmp2:
(EngineCore_DP0 pid=504917) 	.loc	1 157 36                        // quant_slide_tuned_Qwen2.5-7B.py:157:36
(EngineCore_DP0 pid=504917) 	max.f32 	%r123, %r123, %r77;
(EngineCore_DP0 pid=504917) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=504917) 	add.s32 	%r124, %r124, 8192;
(EngineCore_DP0 pid=504917) 	setp.lt.s32 	%p7, %r124, %r19;
(EngineCore_DP0 pid=504917) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=504917) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=504917) 	.loc	1 159 32                        // quant_slide_tuned_Qwen2.5-7B.py:159:32
(EngineCore_DP0 pid=504917) 	max.f32 	%r125, %r123, 0f2B8CBCCC;
(EngineCore_DP0 pid=504917) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=504917) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-7B.py:0:32
(EngineCore_DP0 pid=504917) 	mov.b32 	%r79, 0f43E00000;
(EngineCore_DP0 pid=504917) 	.loc	1 160 32                        // quant_slide_tuned_Qwen2.5-7B.py:160:32
(EngineCore_DP0 pid=504917) 	div.full.f32 	%r80, %r125, %r79;
(EngineCore_DP0 pid=504917) 	.loc	1 160 41                        // quant_slide_tuned_Qwen2.5-7B.py:160:41
(EngineCore_DP0 pid=504917) 	max.f32 	%r78, %r80, 0f36924925;
(EngineCore_DP0 pid=504917) 	.loc	1 162 25                        // quant_slide_tuned_Qwen2.5-7B.py:162:25
(EngineCore_DP0 pid=504917) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=504917) 	.loc	1 162 30                        // quant_slide_tuned_Qwen2.5-7B.py:162:30
(EngineCore_DP0 pid=504917) 	// begin inline asm
(EngineCore_DP0 pid=504917) 	@%p20 st.global.b32 [ %rd8 + 0 ], { %r78 };
(EngineCore_DP0 pid=504917) 	// end inline asm
(EngineCore_DP0 pid=504917) 	.loc	1 165 29                        // quant_slide_tuned_Qwen2.5-7B.py:165:29
(EngineCore_DP0 pid=504917) 	shl.b32 	%r15, %r20, 2;
(EngineCore_DP0 pid=504917) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=504917) 	setp.lt.s32 	%p9, %r15, 1;
(EngineCore_DP0 pid=504917) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=504917) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=504917) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-7B.py:0:41
(EngineCore_DP0 pid=504917) 	ld.param.b32 	%r24, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=504917) 	shr.s32 	%r25, %r24, 31;
(EngineCore_DP0 pid=504917) 	shr.u32 	%r26, %r25, 30;
(EngineCore_DP0 pid=504917) 	add.s32 	%r27, %r24, %r26;
(EngineCore_DP0 pid=504917) 	shr.s32 	%r28, %r27, 2;
(EngineCore_DP0 pid=504917) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=504917) 	mul.lo.s32 	%r29, %r28, %r1;
(EngineCore_DP0 pid=504917) 	mad.wide.s32 	%rd2, %r29, 4, %rd5;
(EngineCore_DP0 pid=504917) 	div.full.f32 	%r14, %r79, %r125;
(EngineCore_DP0 pid=504917) 	mov.b32 	%r126, 0;
(EngineCore_DP0 pid=504917) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=504917)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=504917) 	.loc	1 169 30                        // quant_slide_tuned_Qwen2.5-7B.py:169:30
(EngineCore_DP0 pid=504917) 	add.s32 	%r92, %r3, %r126;
(EngineCore_DP0 pid=504917) 	setp.lt.s32 	%p14, %r92, %r15;
(EngineCore_DP0 pid=504917) 	.loc	1 172 24                        // quant_slide_tuned_Qwen2.5-7B.py:172:24
(EngineCore_DP0 pid=504917) 	shr.s32 	%r93, %r92, 31;
(EngineCore_DP0 pid=504917) 	shr.u32 	%r94, %r93, 30;
(EngineCore_DP0 pid=504917) 	add.s32 	%r95, %r92, %r94;
(EngineCore_DP0 pid=504917) 	shr.s32 	%r96, %r95, 2;
(EngineCore_DP0 pid=504917) 	.loc	1 173 23                        // quant_slide_tuned_Qwen2.5-7B.py:173:23
(EngineCore_DP0 pid=504917) 	and.b32 	%r97, %r95, 2147483644;
(EngineCore_DP0 pid=504917) 	sub.s32 	%r98, %r92, %r97;
(EngineCore_DP0 pid=504917) 	.loc	1 174 30                        // quant_slide_tuned_Qwen2.5-7B.py:174:30
(EngineCore_DP0 pid=504917) 	shl.b32 	%r99, %r98, 1;
(EngineCore_DP0 pid=504917) 	.loc	1 174 26                        // quant_slide_tuned_Qwen2.5-7B.py:174:26
(EngineCore_DP0 pid=504917) 	mad.lo.s32 	%r100, %r96, 10, %r99;
(EngineCore_DP0 pid=504917) 	.loc	1 177 53                        // quant_slide_tuned_Qwen2.5-7B.py:177:53
(EngineCore_DP0 pid=504917) 	setp.lt.s32 	%p15, %r100, %r18;
(EngineCore_DP0 pid=504917) 	.loc	1 177 37                        // quant_slide_tuned_Qwen2.5-7B.py:177:37
(EngineCore_DP0 pid=504917) 	and.pred 	%p10, %p14, %p15;
(EngineCore_DP0 pid=504917) 	.loc	1 176 29                        // quant_slide_tuned_Qwen2.5-7B.py:176:29
(EngineCore_DP0 pid=504917) 	mad.wide.s32 	%rd9, %r100, 2, %rd1;
(EngineCore_DP0 pid=504917) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=504917) 	.loc	1 176 21                        // quant_slide_tuned_Qwen2.5-7B.py:176:21
(EngineCore_DP0 pid=504917) 	// begin inline asm
(EngineCore_DP0 pid=504917) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=504917) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=504917) 	// end inline asm
(EngineCore_DP0 pid=504917) 	.loc	1 177 79                        // quant_slide_tuned_Qwen2.5-7B.py:177:79
(EngineCore_DP0 pid=504917) 	cvt.f32.bf16 	%r101, %rs48;
(EngineCore_DP0 pid=504917) 	.loc	1 179 48                        // quant_slide_tuned_Qwen2.5-7B.py:179:48
(EngineCore_DP0 pid=504917) 	or.b32 	%r102, %r100, 1;
(EngineCore_DP0 pid=504917) 	.loc	1 179 53                        // quant_slide_tuned_Qwen2.5-7B.py:179:53
(EngineCore_DP0 pid=504917) 	setp.lt.s32 	%p16, %r102, %r18;
(EngineCore_DP0 pid=504917) 	.loc	1 179 37                        // quant_slide_tuned_Qwen2.5-7B.py:179:37
(EngineCore_DP0 pid=504917) 	and.pred 	%p11, %p14, %p16;
(EngineCore_DP0 pid=504917) 	.loc	1 178 39                        // quant_slide_tuned_Qwen2.5-7B.py:178:39
(EngineCore_DP0 pid=504917) 	add.s64 	%rd10, %rd9, 2;
(EngineCore_DP0 pid=504917) 	.loc	1 178 21                        // quant_slide_tuned_Qwen2.5-7B.py:178:21
(EngineCore_DP0 pid=504917) 	// begin inline asm
(EngineCore_DP0 pid=504917) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=504917) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=504917) 	// end inline asm
(EngineCore_DP0 pid=504917) 	.loc	1 179 79                        // quant_slide_tuned_Qwen2.5-7B.py:179:79
(EngineCore_DP0 pid=504917) 	cvt.f32.bf16 	%r103, %rs50;
(EngineCore_DP0 pid=504917) 	.loc	1 181 48                        // quant_slide_tuned_Qwen2.5-7B.py:181:48
(EngineCore_DP0 pid=504917) 	add.s32 	%r104, %r100, 2;
(EngineCore_DP0 pid=504917) 	.loc	1 181 53                        // quant_slide_tuned_Qwen2.5-7B.py:181:53
(EngineCore_DP0 pid=504917) 	setp.lt.s32 	%p17, %r104, %r18;
(EngineCore_DP0 pid=504917) 	.loc	1 181 37                        // quant_slide_tuned_Qwen2.5-7B.py:181:37
(EngineCore_DP0 pid=504917) 	and.pred 	%p12, %p14, %p17;
(EngineCore_DP0 pid=504917) 	.loc	1 180 39                        // quant_slide_tuned_Qwen2.5-7B.py:180:39
(EngineCore_DP0 pid=504917) 	add.s64 	%rd11, %rd9, 4;
(EngineCore_DP0 pid=504917) 	.loc	1 180 21                        // quant_slide_tuned_Qwen2.5-7B.py:180:21
(EngineCore_DP0 pid=504917) 	// begin inline asm
(EngineCore_DP0 pid=504917) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=504917) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=504917) 	// end inline asm
(EngineCore_DP0 pid=504917) 	.loc	1 181 79                        // quant_slide_tuned_Qwen2.5-7B.py:181:79
(EngineCore_DP0 pid=504917) 	cvt.f32.bf16 	%r105, %rs52;
(EngineCore_DP0 pid=504917) 	.loc	1 183 48                        // quant_slide_tuned_Qwen2.5-7B.py:183:48
(EngineCore_DP0 pid=504917) 	add.s32 	%r106, %r100, 3;
(EngineCore_DP0 pid=504917) 	.loc	1 183 53                        // quant_slide_tuned_Qwen2.5-7B.py:183:53
(EngineCore_DP0 pid=504917) 	setp.lt.s32 	%p18, %r106, %r18;
(EngineCore_DP0 pid=504917) 	.loc	1 183 37                        // quant_slide_tuned_Qwen2.5-7B.py:183:37
(EngineCore_DP0 pid=504917) 	and.pred 	%p13, %p14, %p18;
(EngineCore_DP0 pid=504917) 	.loc	1 182 39                        // quant_slide_tuned_Qwen2.5-7B.py:182:39
(EngineCore_DP0 pid=504917) 	add.s64 	%rd12, %rd9, 6;
(EngineCore_DP0 pid=504917) 	.loc	1 182 21                        // quant_slide_tuned_Qwen2.5-7B.py:182:21
(EngineCore_DP0 pid=504917) 	// begin inline asm
(EngineCore_DP0 pid=504917) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=504917) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=504917) 	// end inline asm
(EngineCore_DP0 pid=504917) 	.loc	1 183 79                        // quant_slide_tuned_Qwen2.5-7B.py:183:79
(EngineCore_DP0 pid=504917) 	cvt.f32.bf16 	%r107, %rs54;
(EngineCore_DP0 pid=504917) 	.loc	1 185 27                        // quant_slide_tuned_Qwen2.5-7B.py:185:27
(EngineCore_DP0 pid=504917) 	mul.f32 	%r108, %r14, %r101;
(EngineCore_DP0 pid=504917) 	mov.b32 	%r109, 0f43E00000;
(EngineCore_DP0 pid=504917) 	.loc	1 185 48                        // quant_slide_tuned_Qwen2.5-7B.py:185:48
(EngineCore_DP0 pid=504917) 	min.xorsign.abs.f32 	%r82, %r108, %r109;
(EngineCore_DP0 pid=504917) 	.loc	1 185 60                        // quant_slide_tuned_Qwen2.5-7B.py:185:60
(EngineCore_DP0 pid=504917) 	// begin inline asm
(EngineCore_DP0 pid=504917) 	cvt.rn.satfinite.e4m3x2.f32  %rs56, %r83, %r82; 
(EngineCore_DP0 pid=504917) 
(EngineCore_DP0 pid=504917) 	// end inline asm
(EngineCore_DP0 pid=504917) 	.loc	1 186 27                        // quant_slide_tuned_Qwen2.5-7B.py:186:27
(EngineCore_DP0 pid=504917) 	mul.f32 	%r110, %r14, %r103;
(EngineCore_DP0 pid=504917) 	.loc	1 186 48                        // quant_slide_tuned_Qwen2.5-7B.py:186:48
(EngineCore_DP0 pid=504917) 	min.xorsign.abs.f32 	%r84, %r110, %r109;
(EngineCore_DP0 pid=504917) 	.loc	1 186 60                        // quant_slide_tuned_Qwen2.5-7B.py:186:60
(EngineCore_DP0 pid=504917) 	// begin inline asm
(EngineCore_DP0 pid=504917) 	cvt.rn.satfinite.e4m3x2.f32  %rs57, %r85, %r84; 
(EngineCore_DP0 pid=504917) 
(EngineCore_DP0 pid=504917) 	// end inline asm
(EngineCore_DP0 pid=504917) 	.loc	1 187 27                        // quant_slide_tuned_Qwen2.5-7B.py:187:27
(EngineCore_DP0 pid=504917) 	mul.f32 	%r111, %r14, %r105;
(EngineCore_DP0 pid=504917) 	.loc	1 187 48                        // quant_slide_tuned_Qwen2.5-7B.py:187:48
(EngineCore_DP0 pid=504917) 	min.xorsign.abs.f32 	%r86, %r111, %r109;
(EngineCore_DP0 pid=504917) 	.loc	1 187 60                        // quant_slide_tuned_Qwen2.5-7B.py:187:60
(EngineCore_DP0 pid=504917) 	// begin inline asm
(EngineCore_DP0 pid=504917) 	cvt.rn.satfinite.e4m3x2.f32  %rs58, %r87, %r86; 
(EngineCore_DP0 pid=504917) 
(EngineCore_DP0 pid=504917) 	// end inline asm
(EngineCore_DP0 pid=504917) 	.loc	1 188 27                        // quant_slide_tuned_Qwen2.5-7B.py:188:27
(EngineCore_DP0 pid=504917) 	mul.f32 	%r112, %r14, %r107;
(EngineCore_DP0 pid=504917) 	.loc	1 188 48                        // quant_slide_tuned_Qwen2.5-7B.py:188:48
(EngineCore_DP0 pid=504917) 	min.xorsign.abs.f32 	%r88, %r112, %r109;
(EngineCore_DP0 pid=504917) 	.loc	1 188 60                        // quant_slide_tuned_Qwen2.5-7B.py:188:60
(EngineCore_DP0 pid=504917) 	// begin inline asm
(EngineCore_DP0 pid=504917) 	cvt.rn.satfinite.e4m3x2.f32  %rs59, %r89, %r88; 
(EngineCore_DP0 pid=504917) 
(EngineCore_DP0 pid=504917) 	// end inline asm
(EngineCore_DP0 pid=504917) 	.loc	1 190 45                        // quant_slide_tuned_Qwen2.5-7B.py:190:45
(EngineCore_DP0 pid=504917) 	cvt.u32.u16 	%r113, %rs56;
(EngineCore_DP0 pid=504917) 	and.b32 	%r114, %r113, 255;
(EngineCore_DP0 pid=504917) 	.loc	1 192 45                        // quant_slide_tuned_Qwen2.5-7B.py:192:45
(EngineCore_DP0 pid=504917) 	cvt.u32.u16 	%r115, %rs58;
(EngineCore_DP0 pid=504917) 	and.b32 	%r116, %r115, 255;
(EngineCore_DP0 pid=504917) 	.loc	1 193 45                        // quant_slide_tuned_Qwen2.5-7B.py:193:45
(EngineCore_DP0 pid=504917) 	cvt.u32.u16 	%r117, %rs59;
(EngineCore_DP0 pid=504917) 	.loc	1 195 30                        // quant_slide_tuned_Qwen2.5-7B.py:195:30
(EngineCore_DP0 pid=504917) 	and.b16 	%rs60, %rs57, 255;
(EngineCore_DP0 pid=504917) 	mul.wide.u16 	%r118, %rs60, 256;
(EngineCore_DP0 pid=504917) 	.loc	1 195 24                        // quant_slide_tuned_Qwen2.5-7B.py:195:24
(EngineCore_DP0 pid=504917) 	or.b32 	%r119, %r118, %r114;
(EngineCore_DP0 pid=504917) 	.loc	1 195 42                        // quant_slide_tuned_Qwen2.5-7B.py:195:42
(EngineCore_DP0 pid=504917) 	shl.b32 	%r120, %r116, 16;
(EngineCore_DP0 pid=504917) 	.loc	1 195 36                        // quant_slide_tuned_Qwen2.5-7B.py:195:36
(EngineCore_DP0 pid=504917) 	or.b32 	%r121, %r119, %r120;
(EngineCore_DP0 pid=504917) 	.loc	1 195 55                        // quant_slide_tuned_Qwen2.5-7B.py:195:55
(EngineCore_DP0 pid=504917) 	shl.b32 	%r122, %r117, 24;
(EngineCore_DP0 pid=504917) 	.loc	1 195 49                        // quant_slide_tuned_Qwen2.5-7B.py:195:49
(EngineCore_DP0 pid=504917) 	or.b32 	%r90, %r121, %r122;
(EngineCore_DP0 pid=504917) 	.loc	1 196 29                        // quant_slide_tuned_Qwen2.5-7B.py:196:29
(EngineCore_DP0 pid=504917) 	mad.wide.s32 	%rd13, %r92, 4, %rd2;
(EngineCore_DP0 pid=504917) 	.loc	1 196 39                        // quant_slide_tuned_Qwen2.5-7B.py:196:39
(EngineCore_DP0 pid=504917) 	// begin inline asm
(EngineCore_DP0 pid=504917) 	@%p14 st.global.b32 [ %rd13 + 0 ], { %r90 };
(EngineCore_DP0 pid=504917) 	// end inline asm
(EngineCore_DP0 pid=504917) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=504917) 	add.s32 	%r126, %r126, 512;
(EngineCore_DP0 pid=504917) 	setp.lt.s32 	%p19, %r126, %r15;
(EngineCore_DP0 pid=504917) 	@%p19 bra 	$L__BB0_6;
(EngineCore_DP0 pid=504917) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=504917) 	.loc	1 167 4                         // quant_slide_tuned_Qwen2.5-7B.py:167:4
(EngineCore_DP0 pid=504917) 	ret;
(EngineCore_DP0 pid=504917) $L__tmp3:
(EngineCore_DP0 pid=504917) $L__func_end0:
(EngineCore_DP0 pid=504917)                                         // -- End function
(EngineCore_DP0 pid=504917) }
(EngineCore_DP0 pid=504917) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py"
(EngineCore_DP0 pid=504917) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=504917) 	.section	.debug_abbrev
(EngineCore_DP0 pid=504917) 	{
(EngineCore_DP0 pid=504917) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=504917) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=504917) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=504917) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=504917) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=504917) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=504917) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=504917) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=504917) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=504917) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=504917) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=504917) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=504917) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=504917) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=504917) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=504917) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=504917) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=504917) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=504917) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=504917) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=504917) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=504917) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=504917) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=504917) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=504917) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=504917) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=504917) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=504917) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=504917) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=504917) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=504917) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=504917) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=504917) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=504917) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=504917) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=504917) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=504917) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=504917) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=504917) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=504917) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=504917) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=504917) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=504917) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=504917) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=504917) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=504917) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=504917) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=504917) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=504917) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=504917) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=504917) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=504917) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=504917) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=504917) 	}
(EngineCore_DP0 pid=504917) 	.section	.debug_info
(EngineCore_DP0 pid=504917) 	{
(EngineCore_DP0 pid=504917) .b32 221                                // Length of Unit
(EngineCore_DP0 pid=504917) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=504917) .b8 0
(EngineCore_DP0 pid=504917) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=504917) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=504917) .b8 1                                   // Abbrev [1] 0xb:0xd6 DW_TAG_compile_unit
(EngineCore_DP0 pid=504917) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=504917) .b8 114
(EngineCore_DP0 pid=504917) .b8 105
(EngineCore_DP0 pid=504917) .b8 116
(EngineCore_DP0 pid=504917) .b8 111
(EngineCore_DP0 pid=504917) .b8 110
(EngineCore_DP0 pid=504917) .b8 0
(EngineCore_DP0 pid=504917) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=504917) .b8 0
(EngineCore_DP0 pid=504917) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=504917) .b8 117
(EngineCore_DP0 pid=504917) .b8 97
(EngineCore_DP0 pid=504917) .b8 110
(EngineCore_DP0 pid=504917) .b8 116
(EngineCore_DP0 pid=504917) .b8 95
(EngineCore_DP0 pid=504917) .b8 115
(EngineCore_DP0 pid=504917) .b8 108
(EngineCore_DP0 pid=504917) .b8 105
(EngineCore_DP0 pid=504917) .b8 100
(EngineCore_DP0 pid=504917) .b8 101
(EngineCore_DP0 pid=504917) .b8 95
(EngineCore_DP0 pid=504917) .b8 116
(EngineCore_DP0 pid=504917) .b8 117
(EngineCore_DP0 pid=504917) .b8 110
(EngineCore_DP0 pid=504917) .b8 101
(EngineCore_DP0 pid=504917) .b8 100
(EngineCore_DP0 pid=504917) .b8 95
(EngineCore_DP0 pid=504917) .b8 81
(EngineCore_DP0 pid=504917) .b8 119
(EngineCore_DP0 pid=504917) .b8 101
(EngineCore_DP0 pid=504917) .b8 110
(EngineCore_DP0 pid=504917) .b8 50
(EngineCore_DP0 pid=504917) .b8 46
(EngineCore_DP0 pid=504917) .b8 53
(EngineCore_DP0 pid=504917) .b8 45
(EngineCore_DP0 pid=504917) .b8 55
(EngineCore_DP0 pid=504917) .b8 66
(EngineCore_DP0 pid=504917) .b8 46
(EngineCore_DP0 pid=504917) .b8 112
(EngineCore_DP0 pid=504917) .b8 121
(EngineCore_DP0 pid=504917) .b8 0
(EngineCore_DP0 pid=504917) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=504917) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=504917) .b8 114
(EngineCore_DP0 pid=504917) .b8 111
(EngineCore_DP0 pid=504917) .b8 111
(EngineCore_DP0 pid=504917) .b8 116
(EngineCore_DP0 pid=504917) .b8 47
(EngineCore_DP0 pid=504917) .b8 118
(EngineCore_DP0 pid=504917) .b8 108
(EngineCore_DP0 pid=504917) .b8 108
(EngineCore_DP0 pid=504917) .b8 109
(EngineCore_DP0 pid=504917) .b8 98
(EngineCore_DP0 pid=504917) .b8 101
(EngineCore_DP0 pid=504917) .b8 110
(EngineCore_DP0 pid=504917) .b8 99
(EngineCore_DP0 pid=504917) .b8 104
(EngineCore_DP0 pid=504917) .b8 47
(EngineCore_DP0 pid=504917) .b8 115
(EngineCore_DP0 pid=504917) .b8 108
(EngineCore_DP0 pid=504917) .b8 105
(EngineCore_DP0 pid=504917) .b8 100
(EngineCore_DP0 pid=504917) .b8 101
(EngineCore_DP0 pid=504917) .b8 115
(EngineCore_DP0 pid=504917) .b8 112
(EngineCore_DP0 pid=504917) .b8 97
(EngineCore_DP0 pid=504917) .b8 114
(EngineCore_DP0 pid=504917) .b8 115
(EngineCore_DP0 pid=504917) .b8 101
(EngineCore_DP0 pid=504917) .b8 47
(EngineCore_DP0 pid=504917) .b8 99
(EngineCore_DP0 pid=504917) .b8 115
(EngineCore_DP0 pid=504917) .b8 114
(EngineCore_DP0 pid=504917) .b8 99
(EngineCore_DP0 pid=504917) .b8 47
(EngineCore_DP0 pid=504917) .b8 102
(EngineCore_DP0 pid=504917) .b8 117
(EngineCore_DP0 pid=504917) .b8 115
(EngineCore_DP0 pid=504917) .b8 101
(EngineCore_DP0 pid=504917) .b8 100
(EngineCore_DP0 pid=504917) .b8 95
(EngineCore_DP0 pid=504917) .b8 113
(EngineCore_DP0 pid=504917) .b8 117
(EngineCore_DP0 pid=504917) .b8 97
(EngineCore_DP0 pid=504917) .b8 110
(EngineCore_DP0 pid=504917) .b8 116
(EngineCore_DP0 pid=504917) .b8 95
(EngineCore_DP0 pid=504917) .b8 115
(EngineCore_DP0 pid=504917) .b8 108
(EngineCore_DP0 pid=504917) .b8 105
(EngineCore_DP0 pid=504917) .b8 100
(EngineCore_DP0 pid=504917) .b8 101
(EngineCore_DP0 pid=504917) .b8 95
(EngineCore_DP0 pid=504917) .b8 116
(EngineCore_DP0 pid=504917) .b8 114
(EngineCore_DP0 pid=504917) .b8 105
(EngineCore_DP0 pid=504917) .b8 116
(EngineCore_DP0 pid=504917) .b8 111
(EngineCore_DP0 pid=504917) .b8 110
(EngineCore_DP0 pid=504917) .b8 47
(EngineCore_DP0 pid=504917) .b8 98
(EngineCore_DP0 pid=504917) .b8 117
(EngineCore_DP0 pid=504917) .b8 105
(EngineCore_DP0 pid=504917) .b8 108
(EngineCore_DP0 pid=504917) .b8 100
(EngineCore_DP0 pid=504917) .b8 47
(EngineCore_DP0 pid=504917) .b8 71
(EngineCore_DP0 pid=504917) .b8 66
(EngineCore_DP0 pid=504917) .b8 49
(EngineCore_DP0 pid=504917) .b8 48
(EngineCore_DP0 pid=504917) .b8 95
(EngineCore_DP0 pid=504917) .b8 99
(EngineCore_DP0 pid=504917) .b8 99
(EngineCore_DP0 pid=504917) .b8 49
(EngineCore_DP0 pid=504917) .b8 50
(EngineCore_DP0 pid=504917) .b8 49
(EngineCore_DP0 pid=504917) .b8 95
(EngineCore_DP0 pid=504917) .b8 112
(EngineCore_DP0 pid=504917) .b8 121
(EngineCore_DP0 pid=504917) .b8 51
(EngineCore_DP0 pid=504917) .b8 49
(EngineCore_DP0 pid=504917) .b8 50
(EngineCore_DP0 pid=504917) .b8 95
(EngineCore_DP0 pid=504917) .b8 99
(EngineCore_DP0 pid=504917) .b8 117
(EngineCore_DP0 pid=504917) .b8 49
(EngineCore_DP0 pid=504917) .b8 50
(EngineCore_DP0 pid=504917) .b8 57
(EngineCore_DP0 pid=504917) .b8 95
(EngineCore_DP0 pid=504917) .b8 97
(EngineCore_DP0 pid=504917) .b8 97
(EngineCore_DP0 pid=504917) .b8 114
(EngineCore_DP0 pid=504917) .b8 99
(EngineCore_DP0 pid=504917) .b8 104
(EngineCore_DP0 pid=504917) .b8 54
(EngineCore_DP0 pid=504917) .b8 52
(EngineCore_DP0 pid=504917) .b8 0
(EngineCore_DP0 pid=504917) .b8 2                                   // Abbrev [2] 0x98:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=504917) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=504917) .b8 113
(EngineCore_DP0 pid=504917) .b8 117
(EngineCore_DP0 pid=504917) .b8 97
(EngineCore_DP0 pid=504917) .b8 110
(EngineCore_DP0 pid=504917) .b8 116
(EngineCore_DP0 pid=504917) .b8 95
(EngineCore_DP0 pid=504917) .b8 115
(EngineCore_DP0 pid=504917) .b8 108
(EngineCore_DP0 pid=504917) .b8 105
(EngineCore_DP0 pid=504917) .b8 100
(EngineCore_DP0 pid=504917) .b8 101
(EngineCore_DP0 pid=504917) .b8 95
(EngineCore_DP0 pid=504917) .b8 102
(EngineCore_DP0 pid=504917) .b8 112
(EngineCore_DP0 pid=504917) .b8 56
(EngineCore_DP0 pid=504917) .b8 95
(EngineCore_DP0 pid=504917) .b8 107
(EngineCore_DP0 pid=504917) .b8 101
(EngineCore_DP0 pid=504917) .b8 114
(EngineCore_DP0 pid=504917) .b8 110
(EngineCore_DP0 pid=504917) .b8 101
(EngineCore_DP0 pid=504917) .b8 108
(EngineCore_DP0 pid=504917) .b8 0
(EngineCore_DP0 pid=504917) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=504917) .b8 3                                   // Abbrev [3] 0xb2:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=504917) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=504917) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=504917) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=504917) .b8 4                                   // Abbrev [4] 0xc7:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=504917) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=504917) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=504917) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=504917) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=504917) .b8 157                                 // DW_AT_call_line
(EngineCore_DP0 pid=504917) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=504917) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=504917) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=504917) 	}
(EngineCore_DP0 pid=504917) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=504917) 
(EngineCore_DP0 pid=504917) ================================================================
(EngineCore_DP0 pid=504917) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=504917) 
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpqr377dok.ptx', '-o', '/tmp/tmpqr377dok.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866] 
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866] 
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866] 
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpqr377dok.ptx -o /tmp/tmpqr377dok.ptx.o
(EngineCore_DP0 pid=504917) ERROR 01-25 21:57:08 [core.py:866] 

STDERR:
[2026-01-25 21:55:58] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:55:58] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:55:58] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:55:58] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:55:58] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:55:58] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:55:58] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:55:58] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:55:58] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:55:58] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:55:58] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:55:58] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:55:58] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:55:58] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:56:01] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:56:01] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:56:01] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:56:01] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:56:01] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:56:01] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:56:01] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:56:01] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:56:01] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:56:01] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:56:01] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:56:01] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:56:01] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:56:01] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=504917) [2026-01-25 21:56:02] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=504917) [2026-01-25 21:56:02] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=504917) [2026-01-25 21:56:02] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=504917) [2026-01-25 21:56:02] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=504917) [2026-01-25 21:56:02] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=504917) [2026-01-25 21:56:02] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=504917) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=504917) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:27<00:27, 27.49s/it]
(EngineCore_DP0 pid=504917) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:03<00:00, 32.40s/it]
(EngineCore_DP0 pid=504917) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:03<00:00, 31.66s/it]
(EngineCore_DP0 pid=504917) 
(EngineCore_DP0 pid=504917) [2026-01-25 21:57:07] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=504917) [2026-01-25 21:57:07] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16588800 bytes
(EngineCore_DP0 pid=504917) [2026-01-25 21:57:07] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=504917) [2026-01-25 21:57:07] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 12902400 bytes
(EngineCore_DP0 pid=504917) [2026-01-25 21:57:07] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=504917) [2026-01-25 21:57:07] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 136396800 bytes
(EngineCore_DP0 pid=504917) [2026-01-25 21:57:07] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=504917) [2026-01-25 21:57:07] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 67952640 bytes
(EngineCore_DP0 pid=504917) Process EngineCore_DP0:
(EngineCore_DP0 pid=504917) Traceback (most recent call last):
(EngineCore_DP0 pid=504917)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=504917)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=504917)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=504917)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=504917) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpqr377dok.ptx', '-o', '/tmp/tmpqr377dok.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=504917) 
(EngineCore_DP0 pid=504917) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=504917) 
(EngineCore_DP0 pid=504917) Traceback (most recent call last):
(EngineCore_DP0 pid=504917)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=504917)     self.run()
(EngineCore_DP0 pid=504917)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=504917)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=504917)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=504917)     raise e
(EngineCore_DP0 pid=504917)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=504917)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=504917)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=504917)     super().__init__(
(EngineCore_DP0 pid=504917)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=504917)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=504917)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=504917)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=504917)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=504917)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=504917)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=504917)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=504917)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=504917)     return func(*args, **kwargs)
(EngineCore_DP0 pid=504917)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=504917)     return func(*args, **kwargs)
(EngineCore_DP0 pid=504917)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=504917)     self.model_runner.profile_run()
(EngineCore_DP0 pid=504917)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=504917)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=504917)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=504917)     return func(*args, **kwargs)
(EngineCore_DP0 pid=504917)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=504917)     outputs = self.model(
(EngineCore_DP0 pid=504917)               ^^^^^^^^^^^
(EngineCore_DP0 pid=504917)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=504917)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=504917)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=504917)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=504917)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=504917)     hidden_states = self.model(
(EngineCore_DP0 pid=504917)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=504917)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=504917)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=504917)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=504917)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=504917)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=504917)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=504917)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=504917)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=504917)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=504917)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=504917)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=504917)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=504917)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=504917)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=504917)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=504917)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=504917)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=504917)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=504917)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=504917)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=504917)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=504917)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=504917)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=504917)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=504917)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=504917)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=504917)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=504917)     return self._linear_fn(
(EngineCore_DP0 pid=504917)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=504917)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=504917)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=504917)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=504917)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=504917)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=504917)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=504917)     return fn(input, L)
(EngineCore_DP0 pid=504917)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=504917)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=504917)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=504917)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=504917)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=504917)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=504917)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=504917)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=504917)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=504917)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=504917)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=504917)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=504917)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=504917)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=504917)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=504917)     raise PTXASError(error)
(EngineCore_DP0 pid=504917) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=504917) `ptxas` stderr:
(EngineCore_DP0 pid=504917) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=504917) 
(EngineCore_DP0 pid=504917) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpqr377dok.ptx -o /tmp/tmpqr377dok.ptx.o
(EngineCore_DP0 pid=504917) 
[rank0]:[W125 21:57:08.040794659 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=65536

========== M=16 ==========
Time: 2026-01-26 02:41:36
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10
Params: prompt_len=16, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 17 --max-num-batched-tokens 17 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-1B-FP8_M16.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 02:41:40 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 02:41:40 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=759198) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=759198) WARNING 01-26 02:42:02 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 77.26 requests/s, 1313.34 total tokens/s, 77.26 output tokens/s
Total num prompt tokens:  2048
Total num output tokens:  128

STDERR:
[2026-01-26 02:41:40] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 02:41:40] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 02:41:40] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 02:41:40] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:41:40] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:41:40] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:41:40] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:41:40] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:41:40] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 02:41:40] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:41:40] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:41:40] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:41:40] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:41:40] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 02:41:43] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 02:41:43] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 02:41:43] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 02:41:43] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:41:43] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:41:43] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:41:43] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:41:43] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:41:43] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 02:41:43] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:41:43] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:41:43] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:41:43] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:41:43] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=759198) [2026-01-26 02:41:44] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=759198) [2026-01-26 02:41:44] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=759198) [2026-01-26 02:41:44] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=759198) [2026-01-26 02:41:44] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=759198) [2026-01-26 02:41:44] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=759198) [2026-01-26 02:41:44] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=759198) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=759198) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.88s/it]
(EngineCore_DP0 pid=759198) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.88s/it]
(EngineCore_DP0 pid=759198) 
(EngineCore_DP0 pid=759198) [2026-01-26 02:41:56] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=759198) [2026-01-26 02:41:56] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6340608 bytes
(EngineCore_DP0 pid=759198) [2026-01-26 02:41:56] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=759198) [2026-01-26 02:41:56] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 4227072 bytes
(EngineCore_DP0 pid=759198) [2026-01-26 02:41:56] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=759198) [2026-01-26 02:41:56] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 33816576 bytes
(EngineCore_DP0 pid=759198) [2026-01-26 02:41:56] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=759198) [2026-01-26 02:41:56] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16809984 bytes
(EngineCore_DP0 pid=759198) 2026-01-26 02:42:01,864 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=759198) 2026-01-26 02:42:01,872 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 12410.62it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:25,  5.04it/s, est. speed input: 80.69 toks/s, output: 5.04 toks/s]
Processed prompts:   8%|         | 10/128 [00:00<00:03, 38.99it/s, est. speed input: 519.03 toks/s, output: 32.44 toks/s]
Processed prompts:  15%|        | 19/128 [00:00<00:01, 56.75it/s, est. speed input: 737.19 toks/s, output: 46.07 toks/s]
Processed prompts:  22%|       | 28/128 [00:00<00:01, 67.42it/s, est. speed input: 869.90 toks/s, output: 54.37 toks/s]
Processed prompts:  29%|       | 37/128 [00:00<00:01, 74.03it/s, est. speed input: 957.94 toks/s, output: 59.87 toks/s]
Processed prompts:  36%|      | 46/128 [00:00<00:01, 78.82it/s, est. speed input: 1023.73 toks/s, output: 63.98 toks/s]
Processed prompts:  43%|     | 55/128 [00:00<00:00, 81.83it/s, est. speed input: 1072.25 toks/s, output: 67.01 toks/s]
Processed prompts:  50%|     | 64/128 [00:00<00:00, 84.03it/s, est. speed input: 1110.80 toks/s, output: 69.42 toks/s]
Processed prompts:  57%|    | 73/128 [00:01<00:00, 85.49it/s, est. speed input: 1141.49 toks/s, output: 71.34 toks/s]
Processed prompts:  64%|   | 82/128 [00:01<00:00, 86.57it/s, est. speed input: 1166.98 toks/s, output: 72.94 toks/s]
Processed prompts:  71%|   | 91/128 [00:01<00:00, 87.31it/s, est. speed input: 1188.20 toks/s, output: 74.26 toks/s]
Processed prompts:  78%|  | 100/128 [00:01<00:00, 86.65it/s, est. speed input: 1202.07 toks/s, output: 75.13 toks/s]
Processed prompts:  85%| | 109/128 [00:01<00:00, 87.10it/s, est. speed input: 1216.91 toks/s, output: 76.06 toks/s]
Processed prompts:  92%|| 118/128 [00:01<00:00, 87.78it/s, est. speed input: 1230.91 toks/s, output: 76.93 toks/s]
Processed prompts:  99%|| 127/128 [00:01<00:00, 88.30it/s, est. speed input: 1243.32 toks/s, output: 77.71 toks/s]
Processed prompts: 100%|| 128/128 [00:01<00:00, 88.30it/s, est. speed input: 1244.42 toks/s, output: 77.78 toks/s]
Processed prompts: 100%|| 128/128 [00:01<00:00, 77.77it/s, est. speed input: 1244.42 toks/s, output: 77.78 toks/s]
[rank0]:[W126 02:42:04.752936289 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=128 ==========
Time: 2026-01-26 02:42:06
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10
Params: prompt_len=128, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10 --dataset-name random --input-len 128 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 129 --max-num-batched-tokens 129 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-1B-FP8_M128.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 02:42:10 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 02:42:10 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=759817) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=759817) WARNING 01-26 02:42:32 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 68.92 requests/s, 8890.32 total tokens/s, 68.92 output tokens/s
Total num prompt tokens:  16384
Total num output tokens:  128

STDERR:
[2026-01-26 02:42:10] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 02:42:10] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 02:42:10] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 02:42:10] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:42:10] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:42:10] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:42:10] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:42:10] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:42:10] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 02:42:10] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:42:10] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:42:10] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:42:10] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:42:10] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 02:42:14] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 02:42:14] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 02:42:14] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 02:42:14] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:42:14] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:42:14] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:42:14] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:42:14] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:42:14] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 02:42:14] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:42:14] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:42:14] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:42:14] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:42:14] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=759817) [2026-01-26 02:42:15] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=759817) [2026-01-26 02:42:15] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=759817) [2026-01-26 02:42:15] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=759817) [2026-01-26 02:42:15] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=759817) [2026-01-26 02:42:15] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=759817) [2026-01-26 02:42:15] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=759817) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=759817) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.77s/it]
(EngineCore_DP0 pid=759817) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.77s/it]
(EngineCore_DP0 pid=759817) 
(EngineCore_DP0 pid=759817) [2026-01-26 02:42:26] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=759817) [2026-01-26 02:42:26] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6340608 bytes
(EngineCore_DP0 pid=759817) [2026-01-26 02:42:26] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=759817) [2026-01-26 02:42:26] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 4227072 bytes
(EngineCore_DP0 pid=759817) [2026-01-26 02:42:26] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=759817) [2026-01-26 02:42:26] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 33816576 bytes
(EngineCore_DP0 pid=759817) [2026-01-26 02:42:26] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=759817) [2026-01-26 02:42:26] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16809984 bytes
(EngineCore_DP0 pid=759817) 2026-01-26 02:42:32,104 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=759817) 2026-01-26 02:42:32,112 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 3874.53it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:24,  5.23it/s, est. speed input: 670.16 toks/s, output: 5.24 toks/s]
Processed prompts:   7%|         | 9/128 [00:00<00:03, 36.28it/s, est. speed input: 3877.61 toks/s, output: 30.29 toks/s]
Processed prompts:  13%|        | 17/128 [00:00<00:02, 50.65it/s, est. speed input: 5340.85 toks/s, output: 41.72 toks/s]
Processed prompts:  20%|        | 25/128 [00:00<00:01, 60.21it/s, est. speed input: 6282.52 toks/s, output: 49.08 toks/s]
Processed prompts:  26%|       | 33/128 [00:00<00:01, 66.50it/s, est. speed input: 6924.14 toks/s, output: 54.09 toks/s]
Processed prompts:  32%|      | 41/128 [00:00<00:01, 70.00it/s, est. speed input: 7354.93 toks/s, output: 57.46 toks/s]
Processed prompts:  38%|      | 49/128 [00:00<00:01, 72.62it/s, est. speed input: 7689.64 toks/s, output: 60.07 toks/s]
Processed prompts:  45%|     | 57/128 [00:00<00:00, 74.56it/s, est. speed input: 7956.59 toks/s, output: 62.16 toks/s]
Processed prompts:  51%|     | 65/128 [00:01<00:00, 76.09it/s, est. speed input: 8176.97 toks/s, output: 63.88 toks/s]
Processed prompts:  57%|    | 73/128 [00:01<00:00, 76.77it/s, est. speed input: 8345.34 toks/s, output: 65.20 toks/s]
Processed prompts:  63%|   | 81/128 [00:01<00:00, 77.49it/s, est. speed input: 8493.21 toks/s, output: 66.35 toks/s]
Processed prompts:  70%|   | 89/128 [00:01<00:00, 77.77it/s, est. speed input: 8612.29 toks/s, output: 67.28 toks/s]
Processed prompts:  76%|  | 97/128 [00:01<00:00, 77.11it/s, est. speed input: 8691.41 toks/s, output: 67.90 toks/s]
Processed prompts:  82%| | 105/128 [00:01<00:00, 77.34it/s, est. speed input: 8777.11 toks/s, output: 68.57 toks/s]
Processed prompts:  88%| | 113/128 [00:01<00:00, 78.00it/s, est. speed input: 8863.79 toks/s, output: 69.25 toks/s]
Processed prompts:  95%|| 121/128 [00:01<00:00, 77.84it/s, est. speed input: 8926.51 toks/s, output: 69.74 toks/s]
Processed prompts: 100%|| 128/128 [00:01<00:00, 77.84it/s, est. speed input: 8985.81 toks/s, output: 70.20 toks/s]
Processed prompts: 100%|| 128/128 [00:01<00:00, 70.20it/s, est. speed input: 8985.81 toks/s, output: 70.20 toks/s]
[rank0]:[W126 02:42:34.023295662 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=256 ==========
Time: 2026-01-26 02:42:37
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10
Params: prompt_len=256, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10 --dataset-name random --input-len 256 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 257 --max-num-batched-tokens 257 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-1B-FP8_M256.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 02:42:40 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 02:42:40 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=760428) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=760428) WARNING 01-26 02:43:02 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 61.39 requests/s, 15776.30 total tokens/s, 61.39 output tokens/s
Total num prompt tokens:  32768
Total num output tokens:  128

STDERR:
[2026-01-26 02:42:40] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 02:42:40] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 02:42:40] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 02:42:40] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:42:40] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:42:40] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:42:40] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:42:40] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:42:40] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 02:42:40] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:42:40] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:42:40] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:42:40] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:42:40] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 02:42:44] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 02:42:44] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 02:42:44] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 02:42:44] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:42:44] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:42:44] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:42:44] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:42:44] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:42:44] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 02:42:44] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:42:44] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:42:44] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:42:44] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:42:44] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=760428) [2026-01-26 02:42:45] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=760428) [2026-01-26 02:42:45] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=760428) [2026-01-26 02:42:45] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=760428) [2026-01-26 02:42:45] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=760428) [2026-01-26 02:42:45] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=760428) [2026-01-26 02:42:45] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=760428) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=760428) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.83s/it]
(EngineCore_DP0 pid=760428) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.83s/it]
(EngineCore_DP0 pid=760428) 
(EngineCore_DP0 pid=760428) [2026-01-26 02:42:56] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=760428) [2026-01-26 02:42:56] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6340608 bytes
(EngineCore_DP0 pid=760428) [2026-01-26 02:42:56] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=760428) [2026-01-26 02:42:56] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 4227072 bytes
(EngineCore_DP0 pid=760428) [2026-01-26 02:42:56] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=760428) [2026-01-26 02:42:56] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 33816576 bytes
(EngineCore_DP0 pid=760428) [2026-01-26 02:42:56] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=760428) [2026-01-26 02:42:56] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16809984 bytes
(EngineCore_DP0 pid=760428) 2026-01-26 02:43:01,808 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=760428) 2026-01-26 02:43:01,815 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 1418.34it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:15,  8.24it/s, est. speed input: 2108.51 toks/s, output: 8.24 toks/s]
Processed prompts:   6%|         | 8/128 [00:00<00:02, 40.83it/s, est. speed input: 9102.09 toks/s, output: 35.55 toks/s]
Processed prompts:  12%|        | 15/128 [00:00<00:02, 52.67it/s, est. speed input: 11699.18 toks/s, output: 45.70 toks/s]
Processed prompts:  17%|        | 22/128 [00:00<00:01, 58.70it/s, est. speed input: 13080.39 toks/s, output: 51.09 toks/s]
Processed prompts:  23%|       | 29/128 [00:00<00:01, 62.59it/s, est. speed input: 13986.44 toks/s, output: 54.63 toks/s]
Processed prompts:  28%|       | 36/128 [00:00<00:01, 64.67it/s, est. speed input: 14568.73 toks/s, output: 56.91 toks/s]
Processed prompts:  34%|      | 43/128 [00:00<00:01, 66.17it/s, est. speed input: 15006.97 toks/s, output: 58.62 toks/s]
Processed prompts:  39%|      | 50/128 [00:00<00:01, 66.82it/s, est. speed input: 15307.49 toks/s, output: 59.79 toks/s]
Processed prompts:  45%|     | 57/128 [00:00<00:01, 65.56it/s, est. speed input: 15404.39 toks/s, output: 60.17 toks/s]
Processed prompts:  50%|     | 64/128 [00:01<00:00, 66.62it/s, est. speed input: 15624.72 toks/s, output: 61.03 toks/s]
Processed prompts:  55%|    | 71/128 [00:01<00:00, 67.15it/s, est. speed input: 15792.29 toks/s, output: 61.69 toks/s]
Processed prompts:  61%|    | 78/128 [00:01<00:00, 67.25it/s, est. speed input: 15914.03 toks/s, output: 62.16 toks/s]
Processed prompts:  66%|   | 85/128 [00:01<00:00, 67.31it/s, est. speed input: 16017.44 toks/s, output: 62.57 toks/s]
Processed prompts:  72%|  | 92/128 [00:01<00:00, 67.31it/s, est. speed input: 16103.72 toks/s, output: 62.90 toks/s]
Processed prompts:  77%|  | 99/128 [00:01<00:00, 67.55it/s, est. speed input: 16191.52 toks/s, output: 63.25 toks/s]
Processed prompts:  83%| | 106/128 [00:01<00:00, 67.64it/s, est. speed input: 16263.95 toks/s, output: 63.53 toks/s]
Processed prompts:  88%| | 113/128 [00:01<00:00, 67.90it/s, est. speed input: 16337.63 toks/s, output: 63.82 toks/s]
Processed prompts:  94%|| 120/128 [00:01<00:00, 68.37it/s, est. speed input: 16415.66 toks/s, output: 64.12 toks/s]
Processed prompts:  99%|| 127/128 [00:01<00:00, 67.33it/s, est. speed input: 16428.43 toks/s, output: 64.17 toks/s]
Processed prompts: 100%|| 128/128 [00:01<00:00, 67.33it/s, est. speed input: 16434.98 toks/s, output: 64.20 toks/s]
Processed prompts: 100%|| 128/128 [00:01<00:00, 64.20it/s, est. speed input: 16434.98 toks/s, output: 64.20 toks/s]
[rank0]:[W126 02:43:04.940147405 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-26 08:41:58
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-1B-FP8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:42:02 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 08:42:02 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1087631) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1087631) WARNING 01-26 08:42:23 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 48.61 requests/s, 24935.78 total tokens/s, 48.61 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-26 08:42:02] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:42:02] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:42:02] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:42:02] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:42:02] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:42:02] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:42:02] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:42:02] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:42:02] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:42:02] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:42:02] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:42:02] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:42:02] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:42:02] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:42:05] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:42:05] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:42:05] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:42:05] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:42:05] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:42:05] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:42:05] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:42:05] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:42:05] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:42:05] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:42:05] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:42:05] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:42:05] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:42:05] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1087631) [2026-01-26 08:42:06] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1087631) [2026-01-26 08:42:06] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1087631) [2026-01-26 08:42:06] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1087631) [2026-01-26 08:42:06] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1087631) [2026-01-26 08:42:06] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1087631) [2026-01-26 08:42:06] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1087631) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1087631) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.72s/it]
(EngineCore_DP0 pid=1087631) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.72s/it]
(EngineCore_DP0 pid=1087631) 
(EngineCore_DP0 pid=1087631) [2026-01-26 08:42:17] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=1087631) [2026-01-26 08:42:17] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6340608 bytes
(EngineCore_DP0 pid=1087631) [2026-01-26 08:42:17] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=1087631) [2026-01-26 08:42:17] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 4227072 bytes
(EngineCore_DP0 pid=1087631) [2026-01-26 08:42:17] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=1087631) [2026-01-26 08:42:17] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 33816576 bytes
(EngineCore_DP0 pid=1087631) [2026-01-26 08:42:17] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=1087631) [2026-01-26 08:42:17] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16809984 bytes
(EngineCore_DP0 pid=1087631) 2026-01-26 08:42:22,935 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1087631) 2026-01-26 08:42:22,942 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  89%| | 114/128 [00:00<00:00, 1122.85it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 1106.93it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|         | 7/128 [00:00<00:01, 68.54it/s, est. speed input: 35104.11 toks/s, output: 68.55 toks/s]
Processed prompts:  11%|         | 14/128 [00:00<00:02, 56.42it/s, est. speed input: 29677.69 toks/s, output: 57.96 toks/s]
Processed prompts:  16%|        | 20/128 [00:00<00:02, 53.65it/s, est. speed input: 28365.18 toks/s, output: 55.40 toks/s]
Processed prompts:  20%|        | 26/128 [00:00<00:01, 52.41it/s, est. speed input: 27739.19 toks/s, output: 54.18 toks/s]
Processed prompts:  25%|       | 32/128 [00:00<00:01, 51.30it/s, est. speed input: 27239.31 toks/s, output: 53.20 toks/s]
Processed prompts:  30%|       | 38/128 [00:00<00:01, 51.06it/s, est. speed input: 27019.65 toks/s, output: 52.77 toks/s]
Processed prompts:  34%|      | 44/128 [00:00<00:01, 51.04it/s, est. speed input: 26891.19 toks/s, output: 52.52 toks/s]
Processed prompts:  39%|      | 50/128 [00:00<00:01, 49.84it/s, est. speed input: 26547.93 toks/s, output: 51.85 toks/s]
Processed prompts:  44%|     | 56/128 [00:01<00:01, 49.95it/s, est. speed input: 26454.20 toks/s, output: 51.67 toks/s]
Processed prompts:  48%|     | 62/128 [00:01<00:01, 50.15it/s, est. speed input: 26401.53 toks/s, output: 51.56 toks/s]
Processed prompts:  53%|    | 68/128 [00:01<00:01, 50.40it/s, est. speed input: 26374.80 toks/s, output: 51.51 toks/s]
Processed prompts:  58%|    | 74/128 [00:01<00:01, 50.34it/s, est. speed input: 26319.05 toks/s, output: 51.40 toks/s]
Processed prompts:  62%|   | 80/128 [00:01<00:00, 50.41it/s, est. speed input: 26286.49 toks/s, output: 51.34 toks/s]
Processed prompts:  67%|   | 86/128 [00:01<00:00, 50.55it/s, est. speed input: 26269.40 toks/s, output: 51.31 toks/s]
Processed prompts:  72%|  | 92/128 [00:01<00:00, 50.55it/s, est. speed input: 26243.80 toks/s, output: 51.26 toks/s]
Processed prompts:  77%|  | 98/128 [00:01<00:00, 50.10it/s, est. speed input: 26172.97 toks/s, output: 51.12 toks/s]
Processed prompts:  81%| | 104/128 [00:02<00:00, 49.58it/s, est. speed input: 26088.42 toks/s, output: 50.95 toks/s]
Processed prompts:  85%| | 109/128 [00:02<00:00, 49.64it/s, est. speed input: 26061.07 toks/s, output: 50.90 toks/s]
Processed prompts:  90%| | 115/128 [00:02<00:00, 50.05it/s, est. speed input: 26063.44 toks/s, output: 50.90 toks/s]
Processed prompts:  95%|| 121/128 [00:02<00:00, 50.17it/s, est. speed input: 26051.36 toks/s, output: 50.88 toks/s]
Processed prompts:  99%|| 127/128 [00:02<00:00, 50.26it/s, est. speed input: 26041.14 toks/s, output: 50.86 toks/s]
Processed prompts: 100%|| 128/128 [00:02<00:00, 50.26it/s, est. speed input: 26038.59 toks/s, output: 50.86 toks/s]
Processed prompts: 100%|| 128/128 [00:02<00:00, 50.85it/s, est. speed input: 26038.59 toks/s, output: 50.86 toks/s]
[rank0]:[W126 08:42:26.641805340 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-26 08:42:28
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-1B-FP8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:42:32 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 08:42:32 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1088239) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1088239) WARNING 01-26 08:42:54 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 25.62 requests/s, 26260.89 total tokens/s, 25.62 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-26 08:42:32] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:42:32] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:42:32] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:42:32] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:42:32] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:42:32] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:42:32] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:42:32] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:42:32] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:42:32] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:42:32] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:42:32] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:42:32] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:42:32] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:42:36] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:42:36] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:42:36] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:42:36] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:42:36] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:42:36] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:42:36] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:42:36] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:42:36] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:42:36] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:42:36] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:42:36] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:42:36] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:42:36] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1088239) [2026-01-26 08:42:37] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1088239) [2026-01-26 08:42:37] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1088239) [2026-01-26 08:42:37] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1088239) [2026-01-26 08:42:37] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1088239) [2026-01-26 08:42:37] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1088239) [2026-01-26 08:42:37] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1088239) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1088239) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.77s/it]
(EngineCore_DP0 pid=1088239) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.77s/it]
(EngineCore_DP0 pid=1088239) 
(EngineCore_DP0 pid=1088239) [2026-01-26 08:42:48] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=1088239) [2026-01-26 08:42:48] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6340608 bytes
(EngineCore_DP0 pid=1088239) [2026-01-26 08:42:48] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=1088239) [2026-01-26 08:42:48] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 4227072 bytes
(EngineCore_DP0 pid=1088239) [2026-01-26 08:42:48] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=1088239) [2026-01-26 08:42:48] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 33816576 bytes
(EngineCore_DP0 pid=1088239) [2026-01-26 08:42:48] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=1088239) [2026-01-26 08:42:48] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16809984 bytes
(EngineCore_DP0 pid=1088239) 2026-01-26 08:42:53,685 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1088239) 2026-01-26 08:42:53,691 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  45%|     | 58/128 [00:00<00:00, 575.52it/s]
Adding requests:  91%| | 116/128 [00:00<00:00, 515.11it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 520.72it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|         | 8/128 [00:00<00:02, 58.75it/s, est. speed input: 60162.13 toks/s, output: 58.75 toks/s]
Processed prompts:  11%|         | 14/128 [00:00<00:03, 34.74it/s, est. speed input: 38259.13 toks/s, output: 37.36 toks/s]
Processed prompts:  14%|        | 18/128 [00:00<00:03, 31.49it/s, est. speed input: 35049.02 toks/s, output: 34.23 toks/s]
Processed prompts:  17%|        | 22/128 [00:00<00:03, 29.64it/s, est. speed input: 33240.76 toks/s, output: 32.46 toks/s]
Processed prompts:  20%|        | 26/128 [00:00<00:03, 28.50it/s, est. speed input: 32082.14 toks/s, output: 31.33 toks/s]
Processed prompts:  23%|       | 29/128 [00:00<00:03, 27.78it/s, est. speed input: 31393.18 toks/s, output: 30.66 toks/s]
Processed prompts:  25%|       | 32/128 [00:01<00:03, 27.25it/s, est. speed input: 30859.24 toks/s, output: 30.14 toks/s]
Processed prompts:  27%|       | 35/128 [00:01<00:03, 27.08it/s, est. speed input: 30515.22 toks/s, output: 29.80 toks/s]
Processed prompts:  30%|       | 38/128 [00:01<00:03, 26.35it/s, est. speed input: 30019.69 toks/s, output: 29.32 toks/s]
Processed prompts:  32%|      | 41/128 [00:01<00:03, 26.24it/s, est. speed input: 29739.38 toks/s, output: 29.04 toks/s]
Processed prompts:  34%|      | 44/128 [00:01<00:03, 26.25it/s, est. speed input: 29526.76 toks/s, output: 28.83 toks/s]
Processed prompts:  37%|      | 47/128 [00:01<00:03, 26.01it/s, est. speed input: 29279.60 toks/s, output: 28.59 toks/s]
Processed prompts:  39%|      | 50/128 [00:01<00:02, 26.29it/s, est. speed input: 29173.93 toks/s, output: 28.49 toks/s]
Processed prompts:  41%|     | 53/128 [00:01<00:02, 26.29it/s, est. speed input: 29037.51 toks/s, output: 28.36 toks/s]
Processed prompts:  44%|     | 56/128 [00:01<00:02, 26.39it/s, est. speed input: 28935.16 toks/s, output: 28.26 toks/s]
Processed prompts:  46%|     | 59/128 [00:02<00:02, 26.15it/s, est. speed input: 28784.82 toks/s, output: 28.11 toks/s]
Processed prompts:  48%|     | 62/128 [00:02<00:02, 26.17it/s, est. speed input: 28683.76 toks/s, output: 28.01 toks/s]
Processed prompts:  51%|     | 65/128 [00:02<00:02, 25.77it/s, est. speed input: 28519.11 toks/s, output: 27.85 toks/s]
Processed prompts:  53%|    | 68/128 [00:02<00:02, 25.80it/s, est. speed input: 28422.29 toks/s, output: 27.76 toks/s]
Processed prompts:  55%|    | 71/128 [00:02<00:02, 25.92it/s, est. speed input: 28351.95 toks/s, output: 27.69 toks/s]
Processed prompts:  58%|    | 74/128 [00:02<00:02, 25.86it/s, est. speed input: 28263.43 toks/s, output: 27.60 toks/s]
Processed prompts:  60%|    | 77/128 [00:02<00:01, 26.14it/s, est. speed input: 28231.13 toks/s, output: 27.57 toks/s]
Processed prompts:  62%|   | 80/128 [00:02<00:01, 26.10it/s, est. speed input: 28167.57 toks/s, output: 27.51 toks/s]
Processed prompts:  65%|   | 83/128 [00:03<00:01, 26.22it/s, est. speed input: 28130.10 toks/s, output: 27.47 toks/s]
Processed prompts:  67%|   | 86/128 [00:03<00:01, 26.19it/s, est. speed input: 28079.21 toks/s, output: 27.42 toks/s]
Processed prompts:  70%|   | 89/128 [00:03<00:01, 26.35it/s, est. speed input: 28053.93 toks/s, output: 27.40 toks/s]
Processed prompts:  72%|  | 92/128 [00:03<00:01, 25.84it/s, est. speed input: 27956.30 toks/s, output: 27.30 toks/s]
Processed prompts:  74%|  | 95/128 [00:03<00:01, 25.87it/s, est. speed input: 27909.69 toks/s, output: 27.26 toks/s]
Processed prompts:  77%|  | 98/128 [00:03<00:01, 26.08it/s, est. speed input: 27887.95 toks/s, output: 27.23 toks/s]
Processed prompts:  79%|  | 101/128 [00:03<00:01, 26.03it/s, est. speed input: 27845.65 toks/s, output: 27.19 toks/s]
Processed prompts:  81%| | 104/128 [00:03<00:00, 26.17it/s, est. speed input: 27824.84 toks/s, output: 27.17 toks/s]
Processed prompts:  84%| | 107/128 [00:03<00:00, 26.26it/s, est. speed input: 27803.89 toks/s, output: 27.15 toks/s]
Processed prompts:  86%| | 110/128 [00:04<00:00, 26.30it/s, est. speed input: 27782.18 toks/s, output: 27.13 toks/s]
Processed prompts:  88%| | 113/128 [00:04<00:00, 26.12it/s, est. speed input: 27741.19 toks/s, output: 27.09 toks/s]
Processed prompts:  91%| | 116/128 [00:04<00:00, 26.23it/s, est. speed input: 27725.58 toks/s, output: 27.08 toks/s]
Processed prompts:  93%|| 119/128 [00:04<00:00, 25.92it/s, est. speed input: 27673.96 toks/s, output: 27.03 toks/s]
Processed prompts:  95%|| 122/128 [00:04<00:00, 26.01it/s, est. speed input: 27653.02 toks/s, output: 27.00 toks/s]
Processed prompts:  98%|| 125/128 [00:04<00:00, 25.92it/s, est. speed input: 27620.09 toks/s, output: 26.97 toks/s]
Processed prompts: 100%|| 128/128 [00:04<00:00, 25.98it/s, est. speed input: 27598.53 toks/s, output: 26.95 toks/s]
Processed prompts: 100%|| 128/128 [00:04<00:00, 25.98it/s, est. speed input: 27598.53 toks/s, output: 26.95 toks/s]
Processed prompts: 100%|| 128/128 [00:04<00:00, 26.95it/s, est. speed input: 27598.53 toks/s, output: 26.95 toks/s]
[rank0]:[W126 08:42:59.760508618 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-26 08:43:01
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-1B-FP8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:43:06 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 08:43:06 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1088908) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1088908) WARNING 01-26 08:43:27 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 27.14 requests/s, 27818.17 total tokens/s, 27.14 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-26 08:43:06] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:43:06] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:43:06] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:43:06] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:43:06] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:43:06] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:43:06] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:43:06] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:43:06] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:43:06] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:43:06] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:43:06] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:43:06] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:43:06] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:43:09] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:43:09] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:43:09] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:43:09] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:43:09] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:43:09] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:43:09] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:43:09] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:43:09] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:43:09] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:43:09] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:43:09] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:43:09] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:43:09] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1088908) [2026-01-26 08:43:10] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1088908) [2026-01-26 08:43:10] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1088908) [2026-01-26 08:43:10] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1088908) [2026-01-26 08:43:10] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1088908) [2026-01-26 08:43:10] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1088908) [2026-01-26 08:43:10] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1088908) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1088908) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.75s/it]
(EngineCore_DP0 pid=1088908) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.75s/it]
(EngineCore_DP0 pid=1088908) 
(EngineCore_DP0 pid=1088908) [2026-01-26 08:43:21] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=1088908) [2026-01-26 08:43:21] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6340608 bytes
(EngineCore_DP0 pid=1088908) [2026-01-26 08:43:21] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=1088908) [2026-01-26 08:43:21] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 4227072 bytes
(EngineCore_DP0 pid=1088908) [2026-01-26 08:43:21] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=1088908) [2026-01-26 08:43:21] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 33816576 bytes
(EngineCore_DP0 pid=1088908) [2026-01-26 08:43:21] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=1088908) [2026-01-26 08:43:21] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16809984 bytes
(EngineCore_DP0 pid=1088908) 2026-01-26 08:43:27,056 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1088908) 2026-01-26 08:43:27,063 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  24%|       | 62/256 [00:00<00:00, 612.22it/s]
Adding requests:  48%|     | 124/256 [00:00<00:00, 593.03it/s]
Adding requests:  72%|  | 184/256 [00:00<00:00, 559.97it/s]
Adding requests:  94%|| 241/256 [00:00<00:00, 549.89it/s]
Adding requests: 100%|| 256/256 [00:00<00:00, 558.49it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|         | 12/256 [00:00<00:02, 89.44it/s, est. speed input: 91614.57 toks/s, output: 89.45 toks/s]
Processed prompts:   8%|         | 21/256 [00:00<00:05, 45.12it/s, est. speed input: 50493.92 toks/s, output: 49.31 toks/s]
Processed prompts:  11%|         | 27/256 [00:00<00:06, 37.31it/s, est. speed input: 42983.02 toks/s, output: 41.98 toks/s]
Processed prompts:  12%|        | 32/256 [00:00<00:07, 31.74it/s, est. speed input: 38077.27 toks/s, output: 37.18 toks/s]
Processed prompts:  14%|        | 36/256 [00:01<00:07, 30.69it/s, est. speed input: 36705.98 toks/s, output: 35.85 toks/s]
Processed prompts:  16%|        | 40/256 [00:01<00:07, 29.73it/s, est. speed input: 35591.21 toks/s, output: 34.76 toks/s]
Processed prompts:  17%|        | 44/256 [00:01<00:07, 29.01it/s, est. speed input: 34718.98 toks/s, output: 33.90 toks/s]
Processed prompts:  19%|        | 48/256 [00:01<00:07, 28.78it/s, est. speed input: 34140.33 toks/s, output: 33.34 toks/s]
Processed prompts:  20%|        | 52/256 [00:01<00:07, 28.45it/s, est. speed input: 33607.65 toks/s, output: 32.82 toks/s]
Processed prompts:  22%|       | 56/256 [00:01<00:07, 28.26it/s, est. speed input: 33182.83 toks/s, output: 32.40 toks/s]
Processed prompts:  23%|       | 60/256 [00:01<00:06, 28.24it/s, est. speed input: 32854.49 toks/s, output: 32.08 toks/s]
Processed prompts:  25%|       | 64/256 [00:02<00:06, 27.99it/s, est. speed input: 32507.22 toks/s, output: 31.74 toks/s]
Processed prompts:  27%|       | 68/256 [00:02<00:06, 27.96it/s, est. speed input: 32245.82 toks/s, output: 31.49 toks/s]
Processed prompts:  28%|       | 72/256 [00:02<00:06, 27.58it/s, est. speed input: 31929.26 toks/s, output: 31.18 toks/s]
Processed prompts:  30%|       | 76/256 [00:02<00:06, 27.45it/s, est. speed input: 31681.67 toks/s, output: 30.94 toks/s]
Processed prompts:  31%|      | 80/256 [00:02<00:06, 27.49it/s, est. speed input: 31490.11 toks/s, output: 30.75 toks/s]
Processed prompts:  33%|      | 84/256 [00:02<00:06, 27.75it/s, est. speed input: 31364.98 toks/s, output: 30.63 toks/s]
Processed prompts:  34%|      | 88/256 [00:02<00:06, 27.71it/s, est. speed input: 31209.34 toks/s, output: 30.48 toks/s]
Processed prompts:  36%|      | 92/256 [00:03<00:05, 27.57it/s, est. speed input: 31050.51 toks/s, output: 30.32 toks/s]
Processed prompts:  38%|      | 96/256 [00:03<00:05, 27.64it/s, est. speed input: 30933.18 toks/s, output: 30.21 toks/s]
Processed prompts:  39%|      | 100/256 [00:03<00:05, 27.29it/s, est. speed input: 30761.85 toks/s, output: 30.04 toks/s]
Processed prompts:  41%|      | 104/256 [00:03<00:05, 27.43it/s, est. speed input: 30665.08 toks/s, output: 29.95 toks/s]
Processed prompts:  42%|     | 108/256 [00:03<00:05, 27.68it/s, est. speed input: 30598.68 toks/s, output: 29.88 toks/s]
Processed prompts:  44%|     | 112/256 [00:03<00:05, 27.71it/s, est. speed input: 30515.81 toks/s, output: 29.80 toks/s]
Processed prompts:  45%|     | 116/256 [00:03<00:05, 27.59it/s, est. speed input: 30420.12 toks/s, output: 29.71 toks/s]
Processed prompts:  47%|     | 120/256 [00:04<00:04, 27.56it/s, est. speed input: 30338.25 toks/s, output: 29.63 toks/s]
Processed prompts:  48%|     | 124/256 [00:04<00:04, 27.58it/s, est. speed input: 30267.74 toks/s, output: 29.56 toks/s]
Processed prompts:  50%|     | 128/256 [00:04<00:04, 27.32it/s, est. speed input: 30168.03 toks/s, output: 29.46 toks/s]
Processed prompts:  52%|    | 132/256 [00:04<00:04, 27.43it/s, est. speed input: 30109.36 toks/s, output: 29.40 toks/s]
Processed prompts:  53%|    | 136/256 [00:04<00:04, 27.41it/s, est. speed input: 30043.48 toks/s, output: 29.34 toks/s]
Processed prompts:  55%|    | 140/256 [00:04<00:04, 27.60it/s, est. speed input: 30004.50 toks/s, output: 29.30 toks/s]
Processed prompts:  56%|    | 144/256 [00:04<00:04, 27.55it/s, est. speed input: 29947.64 toks/s, output: 29.25 toks/s]
Processed prompts:  58%|    | 148/256 [00:05<00:03, 27.38it/s, est. speed input: 29880.13 toks/s, output: 29.18 toks/s]
Processed prompts:  59%|    | 152/256 [00:05<00:03, 27.44it/s, est. speed input: 29834.82 toks/s, output: 29.14 toks/s]
Processed prompts:  61%|    | 156/256 [00:05<00:03, 27.55it/s, est. speed input: 29797.88 toks/s, output: 29.10 toks/s]
Processed prompts:  62%|   | 160/256 [00:05<00:03, 27.10it/s, est. speed input: 29713.21 toks/s, output: 29.02 toks/s]
Processed prompts:  64%|   | 164/256 [00:05<00:03, 27.21it/s, est. speed input: 29672.76 toks/s, output: 28.98 toks/s]
Processed prompts:  66%|   | 168/256 [00:05<00:03, 27.24it/s, est. speed input: 29629.29 toks/s, output: 28.93 toks/s]
Processed prompts:  67%|   | 172/256 [00:05<00:03, 27.44it/s, est. speed input: 29603.80 toks/s, output: 28.91 toks/s]
Processed prompts:  69%|   | 176/256 [00:06<00:02, 27.39it/s, est. speed input: 29563.91 toks/s, output: 28.87 toks/s]
Processed prompts:  70%|   | 180/256 [00:06<00:02, 27.43it/s, est. speed input: 29531.46 toks/s, output: 28.84 toks/s]
Processed prompts:  72%|  | 184/256 [00:06<00:02, 27.58it/s, est. speed input: 29511.19 toks/s, output: 28.82 toks/s]
Processed prompts:  73%|  | 188/256 [00:06<00:02, 27.30it/s, est. speed input: 29460.09 toks/s, output: 28.77 toks/s]
Processed prompts:  75%|  | 192/256 [00:06<00:02, 27.47it/s, est. speed input: 29440.65 toks/s, output: 28.75 toks/s]
Processed prompts:  77%|  | 196/256 [00:06<00:02, 27.38it/s, est. speed input: 29406.01 toks/s, output: 28.72 toks/s]
Processed prompts:  78%|  | 200/256 [00:06<00:02, 27.59it/s, est. speed input: 29392.53 toks/s, output: 28.70 toks/s]
Processed prompts:  80%|  | 204/256 [00:07<00:01, 27.55it/s, est. speed input: 29366.18 toks/s, output: 28.68 toks/s]
Processed prompts:  81%| | 208/256 [00:07<00:01, 27.48it/s, est. speed input: 29338.41 toks/s, output: 28.65 toks/s]
Processed prompts:  83%| | 212/256 [00:07<00:01, 27.38it/s, est. speed input: 29307.64 toks/s, output: 28.62 toks/s]
Processed prompts:  84%| | 216/256 [00:07<00:01, 27.23it/s, est. speed input: 29272.85 toks/s, output: 28.59 toks/s]
Processed prompts:  86%| | 220/256 [00:07<00:01, 27.40it/s, est. speed input: 29258.17 toks/s, output: 28.57 toks/s]
Processed prompts:  88%| | 224/256 [00:07<00:01, 27.53it/s, est. speed input: 29244.21 toks/s, output: 28.56 toks/s]
Processed prompts:  89%| | 228/256 [00:07<00:01, 27.39it/s, est. speed input: 29215.72 toks/s, output: 28.53 toks/s]
Processed prompts:  91%| | 232/256 [00:08<00:00, 27.44it/s, est. speed input: 29198.21 toks/s, output: 28.51 toks/s]
Processed prompts:  92%|| 236/256 [00:08<00:00, 27.58it/s, est. speed input: 29187.58 toks/s, output: 28.50 toks/s]
Processed prompts:  94%|| 240/256 [00:08<00:00, 27.56it/s, est. speed input: 29170.28 toks/s, output: 28.49 toks/s]
Processed prompts:  95%|| 244/256 [00:08<00:00, 27.37it/s, est. speed input: 29142.74 toks/s, output: 28.46 toks/s]
Processed prompts:  97%|| 248/256 [00:08<00:00, 27.55it/s, est. speed input: 29134.63 toks/s, output: 28.45 toks/s]
Processed prompts:  98%|| 252/256 [00:08<00:00, 27.53it/s, est. speed input: 29118.13 toks/s, output: 28.44 toks/s]
Processed prompts: 100%|| 256/256 [00:08<00:00, 29.62it/s, est. speed input: 29214.18 toks/s, output: 28.53 toks/s]
Processed prompts: 100%|| 256/256 [00:08<00:00, 29.62it/s, est. speed input: 29214.18 toks/s, output: 28.53 toks/s]
Processed prompts: 100%|| 256/256 [00:08<00:00, 28.53it/s, est. speed input: 29214.18 toks/s, output: 28.53 toks/s]
[rank0]:[W126 08:43:37.600049545 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-26 08:43:39
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-1B-FP8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:43:44 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 08:43:44 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1089642) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1089642) WARNING 01-26 08:44:06 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 26.57 requests/s, 27236.79 total tokens/s, 26.57 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-26 08:43:44] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:43:44] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:43:44] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:43:44] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:43:44] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:43:44] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:43:44] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:43:44] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:43:44] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:43:44] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:43:44] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:43:44] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:43:44] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:43:44] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:43:48] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:43:48] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:43:48] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:43:48] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:43:48] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:43:48] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:43:48] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:43:48] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:43:48] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:43:48] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:43:48] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:43:48] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:43:48] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:43:48] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1089642) [2026-01-26 08:43:49] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1089642) [2026-01-26 08:43:49] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1089642) [2026-01-26 08:43:49] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1089642) [2026-01-26 08:43:49] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1089642) [2026-01-26 08:43:49] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1089642) [2026-01-26 08:43:49] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1089642) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1089642) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.93s/it]
(EngineCore_DP0 pid=1089642) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.93s/it]
(EngineCore_DP0 pid=1089642) 
(EngineCore_DP0 pid=1089642) [2026-01-26 08:44:00] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=1089642) [2026-01-26 08:44:00] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6340608 bytes
(EngineCore_DP0 pid=1089642) [2026-01-26 08:44:00] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=1089642) [2026-01-26 08:44:00] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 4227072 bytes
(EngineCore_DP0 pid=1089642) [2026-01-26 08:44:00] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=1089642) [2026-01-26 08:44:00] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 33816576 bytes
(EngineCore_DP0 pid=1089642) [2026-01-26 08:44:00] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=1089642) [2026-01-26 08:44:00] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16809984 bytes
(EngineCore_DP0 pid=1089642) 2026-01-26 08:44:05,640 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1089642) 2026-01-26 08:44:05,646 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:  12%|        | 61/512 [00:00<00:00, 597.18it/s]
Adding requests:  24%|       | 121/512 [00:00<00:00, 565.96it/s]
Adding requests:  35%|      | 178/512 [00:00<00:00, 542.64it/s]
Adding requests:  46%|     | 233/512 [00:00<00:00, 536.90it/s]
Adding requests:  56%|    | 287/512 [00:00<00:00, 526.58it/s]
Adding requests:  66%|   | 340/512 [00:00<00:00, 516.58it/s]
Adding requests:  77%|  | 394/512 [00:00<00:00, 522.85it/s]
Adding requests:  87%| | 447/512 [00:00<00:00, 512.94it/s]
Adding requests:  97%|| 499/512 [00:00<00:00, 504.64it/s]
Adding requests: 100%|| 512/512 [00:00<00:00, 521.90it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|         | 26/512 [00:00<00:04, 116.85it/s, est. speed input: 119662.48 toks/s, output: 116.85 toks/s]
Processed prompts:   7%|         | 38/512 [00:00<00:09, 49.74it/s, est. speed input: 57742.80 toks/s, output: 56.39 toks/s]   
Processed prompts:   9%|         | 45/512 [00:00<00:09, 48.59it/s, est. speed input: 55647.76 toks/s, output: 54.34 toks/s]
Processed prompts:  10%|         | 51/512 [00:01<00:12, 36.46it/s, est. speed input: 46319.63 toks/s, output: 45.23 toks/s]
Processed prompts:  11%|         | 56/512 [00:01<00:12, 36.05it/s, est. speed input: 45086.81 toks/s, output: 44.03 toks/s]
Processed prompts:  12%|        | 60/512 [00:01<00:13, 33.66it/s, est. speed input: 43197.21 toks/s, output: 42.18 toks/s]
Processed prompts:  12%|        | 64/512 [00:01<00:13, 32.01it/s, est. speed input: 41772.99 toks/s, output: 40.79 toks/s]
Processed prompts:  13%|        | 68/512 [00:01<00:14, 30.76it/s, est. speed input: 40602.57 toks/s, output: 39.65 toks/s]
Processed prompts:  14%|        | 72/512 [00:01<00:14, 29.49it/s, est. speed input: 39490.57 toks/s, output: 38.56 toks/s]
Processed prompts:  15%|        | 75/512 [00:02<00:16, 26.78it/s, est. speed input: 38086.20 toks/s, output: 37.19 toks/s]
Processed prompts:  15%|        | 78/512 [00:02<00:17, 24.92it/s, est. speed input: 36907.37 toks/s, output: 36.04 toks/s]
Processed prompts:  16%|        | 82/512 [00:02<00:16, 25.44it/s, est. speed input: 36287.81 toks/s, output: 35.44 toks/s]
Processed prompts:  17%|        | 86/512 [00:02<00:16, 25.75it/s, est. speed input: 35725.48 toks/s, output: 34.89 toks/s]
Processed prompts:  18%|        | 90/512 [00:02<00:16, 26.12it/s, est. speed input: 35266.93 toks/s, output: 34.44 toks/s]
Processed prompts:  18%|        | 94/512 [00:02<00:15, 26.33it/s, est. speed input: 34846.59 toks/s, output: 34.03 toks/s]
Processed prompts:  19%|        | 98/512 [00:02<00:15, 26.21it/s, est. speed input: 34408.27 toks/s, output: 33.60 toks/s]
Processed prompts:  20%|        | 102/512 [00:03<00:15, 26.34it/s, est. speed input: 34059.36 toks/s, output: 33.26 toks/s]
Processed prompts:  21%|        | 106/512 [00:03<00:15, 26.48it/s, est. speed input: 33752.32 toks/s, output: 32.96 toks/s]
Processed prompts:  21%|       | 110/512 [00:03<00:15, 26.73it/s, est. speed input: 33501.57 toks/s, output: 32.72 toks/s]
Processed prompts:  22%|       | 114/512 [00:03<00:14, 26.75it/s, est. speed input: 33243.71 toks/s, output: 32.46 toks/s]
Processed prompts:  23%|       | 118/512 [00:03<00:14, 26.75it/s, est. speed input: 33005.36 toks/s, output: 32.23 toks/s]
Processed prompts:  24%|       | 122/512 [00:03<00:14, 26.78it/s, est. speed input: 32790.12 toks/s, output: 32.02 toks/s]
Processed prompts:  25%|       | 126/512 [00:03<00:14, 26.77it/s, est. speed input: 32585.79 toks/s, output: 31.82 toks/s]
Processed prompts:  25%|       | 130/512 [00:04<00:14, 26.74it/s, est. speed input: 32392.46 toks/s, output: 31.63 toks/s]
Processed prompts:  26%|       | 134/512 [00:04<00:14, 26.71it/s, est. speed input: 32212.13 toks/s, output: 31.46 toks/s]
Processed prompts:  27%|       | 138/512 [00:04<00:13, 26.75it/s, est. speed input: 32052.73 toks/s, output: 31.30 toks/s]
Processed prompts:  28%|       | 142/512 [00:04<00:13, 26.69it/s, est. speed input: 31891.80 toks/s, output: 31.14 toks/s]
Processed prompts:  29%|       | 146/512 [00:04<00:13, 26.76it/s, est. speed input: 31756.20 toks/s, output: 31.01 toks/s]
Processed prompts:  29%|       | 150/512 [00:04<00:13, 26.74it/s, est. speed input: 31619.38 toks/s, output: 30.88 toks/s]
Processed prompts:  30%|       | 154/512 [00:05<00:13, 26.76it/s, est. speed input: 31495.56 toks/s, output: 30.76 toks/s]
Processed prompts:  31%|       | 158/512 [00:05<00:13, 26.50it/s, est. speed input: 31346.69 toks/s, output: 30.61 toks/s]
Processed prompts:  32%|      | 162/512 [00:05<00:13, 26.61it/s, est. speed input: 31239.06 toks/s, output: 30.51 toks/s]
Processed prompts:  32%|      | 166/512 [00:05<00:12, 26.66it/s, est. speed input: 31135.26 toks/s, output: 30.41 toks/s]
Processed prompts:  33%|      | 170/512 [00:05<00:12, 26.78it/s, est. speed input: 31044.92 toks/s, output: 30.32 toks/s]
Processed prompts:  34%|      | 174/512 [00:05<00:12, 26.77it/s, est. speed input: 30949.61 toks/s, output: 30.22 toks/s]
Processed prompts:  35%|      | 178/512 [00:05<00:12, 26.74it/s, est. speed input: 30857.00 toks/s, output: 30.13 toks/s]
Processed prompts:  36%|      | 182/512 [00:06<00:12, 26.79it/s, est. speed input: 30775.94 toks/s, output: 30.05 toks/s]
Processed prompts:  36%|      | 186/512 [00:06<00:12, 26.55it/s, est. speed input: 30673.01 toks/s, output: 29.95 toks/s]
Processed prompts:  37%|      | 190/512 [00:06<00:12, 26.51it/s, est. speed input: 30587.06 toks/s, output: 29.87 toks/s]
Processed prompts:  38%|      | 194/512 [00:06<00:11, 26.51it/s, est. speed input: 30507.67 toks/s, output: 29.79 toks/s]
Processed prompts:  39%|      | 198/512 [00:06<00:11, 26.72it/s, est. speed input: 30449.65 toks/s, output: 29.74 toks/s]
Processed prompts:  39%|      | 202/512 [00:06<00:11, 26.84it/s, est. speed input: 30391.79 toks/s, output: 29.68 toks/s]
Processed prompts:  40%|      | 206/512 [00:06<00:11, 26.85it/s, est. speed input: 30330.22 toks/s, output: 29.62 toks/s]
Processed prompts:  41%|      | 210/512 [00:07<00:11, 26.87it/s, est. speed input: 30271.94 toks/s, output: 29.56 toks/s]
Processed prompts:  42%|     | 214/512 [00:07<00:11, 26.54it/s, est. speed input: 30189.90 toks/s, output: 29.48 toks/s]
Processed prompts:  43%|     | 218/512 [00:07<00:11, 26.67it/s, est. speed input: 30138.42 toks/s, output: 29.43 toks/s]
Processed prompts:  43%|     | 222/512 [00:07<00:10, 26.74it/s, est. speed input: 30087.91 toks/s, output: 29.38 toks/s]
Processed prompts:  44%|     | 226/512 [00:07<00:10, 26.87it/s, est. speed input: 30044.30 toks/s, output: 29.34 toks/s]
Processed prompts:  45%|     | 230/512 [00:07<00:10, 26.79it/s, est. speed input: 29990.89 toks/s, output: 29.29 toks/s]
Processed prompts:  46%|     | 234/512 [00:08<00:10, 26.74it/s, est. speed input: 29939.58 toks/s, output: 29.24 toks/s]
Processed prompts:  46%|     | 238/512 [00:08<00:10, 26.88it/s, est. speed input: 29902.29 toks/s, output: 29.20 toks/s]
Processed prompts:  47%|     | 242/512 [00:08<00:10, 26.62it/s, est. speed input: 29842.05 toks/s, output: 29.14 toks/s]
Processed prompts:  48%|     | 246/512 [00:08<00:09, 26.65it/s, est. speed input: 29798.12 toks/s, output: 29.10 toks/s]
Processed prompts:  49%|     | 250/512 [00:08<00:09, 26.71it/s, est. speed input: 29758.07 toks/s, output: 29.06 toks/s]
Processed prompts:  50%|     | 254/512 [00:08<00:09, 26.83it/s, est. speed input: 29724.48 toks/s, output: 29.03 toks/s]
Processed prompts:  50%|     | 258/512 [00:08<00:09, 26.68it/s, est. speed input: 29677.37 toks/s, output: 28.98 toks/s]
Processed prompts:  51%|     | 262/512 [00:09<00:09, 26.77it/s, est. speed input: 29644.22 toks/s, output: 28.95 toks/s]
Processed prompts:  52%|    | 266/512 [00:09<00:09, 26.72it/s, est. speed input: 29604.75 toks/s, output: 28.91 toks/s]
Processed prompts:  53%|    | 270/512 [00:09<00:09, 26.43it/s, est. speed input: 29551.50 toks/s, output: 28.86 toks/s]
Processed prompts:  54%|    | 274/512 [00:09<00:08, 26.61it/s, est. speed input: 29522.41 toks/s, output: 28.83 toks/s]
Processed prompts:  54%|    | 278/512 [00:09<00:08, 26.64it/s, est. speed input: 29488.89 toks/s, output: 28.80 toks/s]
Processed prompts:  55%|    | 282/512 [00:09<00:08, 26.61it/s, est. speed input: 29453.33 toks/s, output: 28.76 toks/s]
Processed prompts:  56%|    | 286/512 [00:09<00:08, 26.67it/s, est. speed input: 29423.24 toks/s, output: 28.73 toks/s]
Processed prompts:  57%|    | 290/512 [00:10<00:08, 26.78it/s, est. speed input: 29397.71 toks/s, output: 28.71 toks/s]
Processed prompts:  57%|    | 294/512 [00:10<00:08, 26.74it/s, est. speed input: 29367.08 toks/s, output: 28.68 toks/s]
Processed prompts:  58%|    | 298/512 [00:10<00:08, 26.49it/s, est. speed input: 29325.35 toks/s, output: 28.64 toks/s]
Processed prompts:  59%|    | 302/512 [00:10<00:07, 26.60it/s, est. speed input: 29299.52 toks/s, output: 28.61 toks/s]
Processed prompts:  60%|    | 306/512 [00:10<00:07, 26.66it/s, est. speed input: 29273.45 toks/s, output: 28.59 toks/s]
Processed prompts:  61%|    | 310/512 [00:10<00:07, 26.64it/s, est. speed input: 29245.44 toks/s, output: 28.56 toks/s]
Processed prompts:  61%|   | 314/512 [00:11<00:07, 26.72it/s, est. speed input: 29222.57 toks/s, output: 28.54 toks/s]
Processed prompts:  62%|   | 318/512 [00:11<00:07, 26.78it/s, est. speed input: 29200.47 toks/s, output: 28.52 toks/s]
Processed prompts:  63%|   | 322/512 [00:11<00:07, 26.87it/s, est. speed input: 29181.43 toks/s, output: 28.50 toks/s]
Processed prompts:  64%|   | 326/512 [00:11<00:06, 26.63it/s, est. speed input: 29148.18 toks/s, output: 28.46 toks/s]
Processed prompts:  64%|   | 330/512 [00:11<00:06, 26.73it/s, est. speed input: 29128.65 toks/s, output: 28.45 toks/s]
Processed prompts:  65%|   | 334/512 [00:11<00:06, 26.91it/s, est. speed input: 29114.76 toks/s, output: 28.43 toks/s]
Processed prompts:  66%|   | 338/512 [00:11<00:06, 26.93it/s, est. speed input: 29096.07 toks/s, output: 28.41 toks/s]
Processed prompts:  67%|   | 342/512 [00:12<00:06, 27.51it/s, est. speed input: 29102.30 toks/s, output: 28.42 toks/s]
Processed prompts:  68%|   | 346/512 [00:12<00:06, 27.47it/s, est. speed input: 29089.53 toks/s, output: 28.41 toks/s]
Processed prompts:  68%|   | 350/512 [00:12<00:05, 27.35it/s, est. speed input: 29073.09 toks/s, output: 28.39 toks/s]
Processed prompts:  69%|   | 354/512 [00:12<00:05, 26.93it/s, est. speed input: 29042.87 toks/s, output: 28.36 toks/s]
Processed prompts:  70%|   | 358/512 [00:12<00:05, 26.85it/s, est. speed input: 29022.26 toks/s, output: 28.34 toks/s]
Processed prompts:  71%|   | 362/512 [00:12<00:05, 26.76it/s, est. speed input: 29000.76 toks/s, output: 28.32 toks/s]
Processed prompts:  71%|  | 366/512 [00:12<00:05, 26.80it/s, est. speed input: 28984.06 toks/s, output: 28.30 toks/s]
Processed prompts:  72%|  | 370/512 [00:13<00:05, 26.84it/s, est. speed input: 28968.01 toks/s, output: 28.29 toks/s]
Processed prompts:  73%|  | 374/512 [00:13<00:05, 26.83it/s, est. speed input: 28950.93 toks/s, output: 28.27 toks/s]
Processed prompts:  74%|  | 378/512 [00:13<00:04, 26.81it/s, est. speed input: 28933.72 toks/s, output: 28.26 toks/s]
Processed prompts:  75%|  | 382/512 [00:13<00:04, 26.71it/s, est. speed input: 28913.43 toks/s, output: 28.24 toks/s]
Processed prompts:  75%|  | 386/512 [00:13<00:04, 26.50it/s, est. speed input: 28887.93 toks/s, output: 28.21 toks/s]
Processed prompts:  76%|  | 390/512 [00:13<00:04, 26.59it/s, est. speed input: 28872.42 toks/s, output: 28.20 toks/s]
Processed prompts:  77%|  | 394/512 [00:13<00:04, 26.56it/s, est. speed input: 28853.67 toks/s, output: 28.18 toks/s]
Processed prompts:  78%|  | 398/512 [00:14<00:04, 26.72it/s, est. speed input: 28842.18 toks/s, output: 28.17 toks/s]
Processed prompts:  79%|  | 402/512 [00:14<00:04, 26.77it/s, est. speed input: 28828.55 toks/s, output: 28.15 toks/s]
Processed prompts:  79%|  | 406/512 [00:14<00:03, 26.80it/s, est. speed input: 28815.08 toks/s, output: 28.14 toks/s]
Processed prompts:  80%|  | 410/512 [00:14<00:03, 26.88it/s, est. speed input: 28803.97 toks/s, output: 28.13 toks/s]
Processed prompts:  81%|  | 414/512 [00:14<00:03, 26.53it/s, est. speed input: 28778.25 toks/s, output: 28.10 toks/s]
Processed prompts:  82%| | 418/512 [00:14<00:03, 26.52it/s, est. speed input: 28761.46 toks/s, output: 28.09 toks/s]
Processed prompts:  82%| | 422/512 [00:15<00:03, 26.66it/s, est. speed input: 28750.54 toks/s, output: 28.08 toks/s]
Processed prompts:  83%| | 426/512 [00:15<00:03, 26.82it/s, est. speed input: 28741.75 toks/s, output: 28.07 toks/s]
Processed prompts:  84%| | 430/512 [00:15<00:03, 26.84it/s, est. speed input: 28730.03 toks/s, output: 28.06 toks/s]
Processed prompts:  85%| | 434/512 [00:15<00:02, 26.78it/s, est. speed input: 28716.07 toks/s, output: 28.04 toks/s]
Processed prompts:  86%| | 438/512 [00:15<00:02, 26.83it/s, est. speed input: 28705.32 toks/s, output: 28.03 toks/s]
Processed prompts:  86%| | 442/512 [00:15<00:02, 26.47it/s, est. speed input: 28681.62 toks/s, output: 28.01 toks/s]
Processed prompts:  87%| | 446/512 [00:15<00:02, 26.57it/s, est. speed input: 28669.98 toks/s, output: 28.00 toks/s]
Processed prompts:  88%| | 450/512 [00:16<00:02, 27.62it/s, est. speed input: 28690.42 toks/s, output: 28.02 toks/s]
Processed prompts:  89%| | 454/512 [00:16<00:02, 27.40it/s, est. speed input: 28679.92 toks/s, output: 28.01 toks/s]
Processed prompts:  89%| | 458/512 [00:16<00:01, 27.26it/s, est. speed input: 28669.98 toks/s, output: 28.00 toks/s]
Processed prompts:  90%| | 462/512 [00:16<00:01, 27.31it/s, est. speed input: 28664.91 toks/s, output: 27.99 toks/s]
Processed prompts:  91%| | 466/512 [00:16<00:01, 27.27it/s, est. speed input: 28657.58 toks/s, output: 27.99 toks/s]
Processed prompts:  92%|| 470/512 [00:16<00:01, 26.94it/s, est. speed input: 28640.93 toks/s, output: 27.97 toks/s]
Processed prompts:  93%|| 474/512 [00:16<00:01, 26.96it/s, est. speed input: 28632.10 toks/s, output: 27.96 toks/s]
Processed prompts:  93%|| 478/512 [00:17<00:01, 26.89it/s, est. speed input: 28621.17 toks/s, output: 27.95 toks/s]
Processed prompts:  94%|| 482/512 [00:17<00:01, 26.82it/s, est. speed input: 28609.68 toks/s, output: 27.94 toks/s]
Processed prompts:  95%|| 486/512 [00:17<00:00, 26.85it/s, est. speed input: 28600.65 toks/s, output: 27.93 toks/s]
Processed prompts:  96%|| 490/512 [00:17<00:00, 26.88it/s, est. speed input: 28592.29 toks/s, output: 27.92 toks/s]
Processed prompts:  96%|| 494/512 [00:17<00:00, 26.89it/s, est. speed input: 28583.66 toks/s, output: 27.91 toks/s]
Processed prompts:  97%|| 498/512 [00:17<00:00, 26.53it/s, est. speed input: 28563.99 toks/s, output: 27.89 toks/s]
Processed prompts:  98%|| 502/512 [00:18<00:00, 26.62it/s, est. speed input: 28554.94 toks/s, output: 27.89 toks/s]
Processed prompts:  99%|| 506/512 [00:18<00:00, 26.68it/s, est. speed input: 28546.18 toks/s, output: 27.88 toks/s]
Processed prompts: 100%|| 510/512 [00:18<00:00, 27.54it/s, est. speed input: 28560.50 toks/s, output: 27.89 toks/s]
Processed prompts: 100%|| 512/512 [00:18<00:00, 27.54it/s, est. speed input: 28672.35 toks/s, output: 28.00 toks/s]
Processed prompts: 100%|| 512/512 [00:18<00:00, 28.00it/s, est. speed input: 28672.35 toks/s, output: 28.00 toks/s]
[rank0]:[W126 08:44:25.069862322 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-26 08:44:28
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-1B-FP8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:44:34 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 08:44:34 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1090525) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1090525) WARNING 01-26 08:44:56 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 26.61 requests/s, 27271.05 total tokens/s, 26.61 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-26 08:44:34] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:44:34] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:44:34] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:44:34] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:44:34] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:44:34] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:44:34] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:44:34] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:44:34] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:44:34] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:44:34] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:44:34] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:44:34] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:44:34] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:44:37] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:44:38] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:44:38] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:44:38] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:44:38] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:44:38] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:44:38] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:44:38] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:44:38] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:44:38] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:44:38] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:44:38] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:44:38] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:44:38] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1090525) [2026-01-26 08:44:38] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1090525) [2026-01-26 08:44:38] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1090525) [2026-01-26 08:44:38] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1090525) [2026-01-26 08:44:38] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1090525) [2026-01-26 08:44:38] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1090525) [2026-01-26 08:44:38] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1090525) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1090525) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.75s/it]
(EngineCore_DP0 pid=1090525) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.75s/it]
(EngineCore_DP0 pid=1090525) 
(EngineCore_DP0 pid=1090525) [2026-01-26 08:44:50] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=1090525) [2026-01-26 08:44:50] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6340608 bytes
(EngineCore_DP0 pid=1090525) [2026-01-26 08:44:50] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=1090525) [2026-01-26 08:44:50] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 4227072 bytes
(EngineCore_DP0 pid=1090525) [2026-01-26 08:44:50] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=1090525) [2026-01-26 08:44:50] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 33816576 bytes
(EngineCore_DP0 pid=1090525) [2026-01-26 08:44:50] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=1090525) [2026-01-26 08:44:50] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16809984 bytes
(EngineCore_DP0 pid=1090525) 2026-01-26 08:44:55,665 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1090525) 2026-01-26 08:44:55,720 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   5%|         | 56/1024 [00:00<00:01, 551.32it/s]
Adding requests:  11%|         | 112/1024 [00:00<00:01, 526.95it/s]
Adding requests:  16%|        | 165/1024 [00:00<00:01, 512.98it/s]
Adding requests:  21%|        | 217/1024 [00:00<00:01, 505.40it/s]
Adding requests:  26%|       | 268/1024 [00:00<00:01, 500.77it/s]
Adding requests:  31%|       | 319/1024 [00:00<00:01, 499.88it/s]
Adding requests:  36%|      | 371/1024 [00:00<00:01, 503.35it/s]
Adding requests:  41%|      | 422/1024 [00:00<00:01, 495.02it/s]
Adding requests:  46%|     | 472/1024 [00:00<00:01, 490.27it/s]
Adding requests:  51%|     | 522/1024 [00:01<00:01, 485.96it/s]
Adding requests:  56%|    | 571/1024 [00:01<00:00, 466.96it/s]
Adding requests:  61%|    | 623/1024 [00:01<00:00, 479.94it/s]
Adding requests:  66%|   | 672/1024 [00:01<00:00, 482.69it/s]
Adding requests:  70%|   | 721/1024 [00:01<00:00, 482.71it/s]
Adding requests:  75%|  | 770/1024 [00:01<00:00, 478.58it/s]
Adding requests:  80%|  | 818/1024 [00:01<00:00, 475.96it/s]
Adding requests:  85%| | 866/1024 [00:01<00:00, 472.68it/s]
Adding requests:  90%| | 918/1024 [00:01<00:00, 483.57it/s]
Adding requests:  94%|| 967/1024 [00:01<00:00, 480.57it/s]
Adding requests:  99%|| 1017/1024 [00:02<00:00, 485.73it/s]
Adding requests: 100%|| 1024/1024 [00:02<00:00, 488.21it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|         | 50/1024 [00:00<00:03, 317.76it/s, est. speed input: 325422.17 toks/s, output: 317.77 toks/s]
Processed prompts:   8%|         | 82/1024 [00:01<00:18, 51.19it/s, est. speed input: 61919.30 toks/s, output: 60.47 toks/s]   
Processed prompts:   9%|         | 97/1024 [00:01<00:18, 50.76it/s, est. speed input: 59859.34 toks/s, output: 58.46 toks/s]
Processed prompts:  11%|         | 108/1024 [00:02<00:24, 37.25it/s, est. speed input: 48843.77 toks/s, output: 47.70 toks/s]
Processed prompts:  11%|         | 115/1024 [00:02<00:26, 34.16it/s, est. speed input: 45970.92 toks/s, output: 44.89 toks/s]
Processed prompts:  12%|        | 122/1024 [00:02<00:28, 31.50it/s, est. speed input: 43656.90 toks/s, output: 42.63 toks/s]
Processed prompts:  13%|        | 130/1024 [00:03<00:29, 30.31it/s, est. speed input: 42136.35 toks/s, output: 41.15 toks/s]
Processed prompts:  13%|        | 138/1024 [00:03<00:30, 29.28it/s, est. speed input: 40833.11 toks/s, output: 39.88 toks/s]
Processed prompts:  14%|        | 146/1024 [00:03<00:30, 28.56it/s, est. speed input: 39758.30 toks/s, output: 38.83 toks/s]
Processed prompts:  15%|        | 154/1024 [00:04<00:31, 28.03it/s, est. speed input: 38838.98 toks/s, output: 37.93 toks/s]
Processed prompts:  16%|        | 162/1024 [00:04<00:31, 27.54it/s, est. speed input: 38016.55 toks/s, output: 37.13 toks/s]
Processed prompts:  17%|        | 170/1024 [00:04<00:31, 27.26it/s, est. speed input: 37319.16 toks/s, output: 36.44 toks/s]
Processed prompts:  17%|        | 178/1024 [00:04<00:31, 27.14it/s, est. speed input: 36728.63 toks/s, output: 35.87 toks/s]
Processed prompts:  18%|        | 186/1024 [00:05<00:31, 26.96it/s, est. speed input: 36181.89 toks/s, output: 35.33 toks/s]
Processed prompts:  19%|        | 194/1024 [00:05<00:30, 26.79it/s, est. speed input: 35681.92 toks/s, output: 34.85 toks/s]
Processed prompts:  20%|        | 202/1024 [00:05<00:30, 26.81it/s, est. speed input: 35267.31 toks/s, output: 34.44 toks/s]
Processed prompts:  21%|        | 210/1024 [00:06<00:30, 26.79it/s, est. speed input: 34884.94 toks/s, output: 34.07 toks/s]
Processed prompts:  21%|       | 218/1024 [00:06<00:30, 26.62it/s, est. speed input: 34507.26 toks/s, output: 33.70 toks/s]
Processed prompts:  22%|       | 226/1024 [00:06<00:29, 26.65it/s, est. speed input: 34190.81 toks/s, output: 33.39 toks/s]
Processed prompts:  23%|       | 234/1024 [00:07<00:29, 26.71it/s, est. speed input: 33908.82 toks/s, output: 33.11 toks/s]
Processed prompts:  24%|       | 242/1024 [00:07<00:29, 26.79it/s, est. speed input: 33655.06 toks/s, output: 32.87 toks/s]
Processed prompts:  24%|       | 250/1024 [00:07<00:29, 26.64it/s, est. speed input: 33387.73 toks/s, output: 32.61 toks/s]
Processed prompts:  25%|       | 258/1024 [00:07<00:28, 26.72it/s, est. speed input: 33170.61 toks/s, output: 32.39 toks/s]
Processed prompts:  26%|       | 266/1024 [00:08<00:28, 26.67it/s, est. speed input: 32952.50 toks/s, output: 32.18 toks/s]
Processed prompts:  27%|       | 274/1024 [00:08<00:28, 26.61it/s, est. speed input: 32745.90 toks/s, output: 31.98 toks/s]
Processed prompts:  28%|       | 282/1024 [00:08<00:27, 26.72it/s, est. speed input: 32575.46 toks/s, output: 31.81 toks/s]
Processed prompts:  28%|       | 290/1024 [00:09<00:27, 26.78it/s, est. speed input: 32413.29 toks/s, output: 31.65 toks/s]
Processed prompts:  29%|       | 298/1024 [00:09<00:27, 26.77it/s, est. speed input: 32254.13 toks/s, output: 31.50 toks/s]
Processed prompts:  30%|       | 306/1024 [00:09<00:26, 26.62it/s, est. speed input: 32087.08 toks/s, output: 31.34 toks/s]
Processed prompts:  31%|       | 314/1024 [00:10<00:26, 26.61it/s, est. speed input: 31941.60 toks/s, output: 31.19 toks/s]
Processed prompts:  31%|      | 322/1024 [00:10<00:26, 26.68it/s, est. speed input: 31814.07 toks/s, output: 31.07 toks/s]
Processed prompts:  32%|      | 330/1024 [00:10<00:26, 26.67it/s, est. speed input: 31686.64 toks/s, output: 30.94 toks/s]
Processed prompts:  33%|      | 338/1024 [00:10<00:25, 26.61it/s, est. speed input: 31559.98 toks/s, output: 30.82 toks/s]
Processed prompts:  34%|      | 346/1024 [00:11<00:25, 26.62it/s, est. speed input: 31446.20 toks/s, output: 30.71 toks/s]
Processed prompts:  35%|      | 354/1024 [00:11<00:25, 26.65it/s, est. speed input: 31340.26 toks/s, output: 30.61 toks/s]
Processed prompts:  35%|      | 362/1024 [00:11<00:24, 26.59it/s, est. speed input: 31231.91 toks/s, output: 30.50 toks/s]
Processed prompts:  36%|      | 370/1024 [00:12<00:24, 26.61it/s, est. speed input: 31134.81 toks/s, output: 30.40 toks/s]
Processed prompts:  37%|      | 378/1024 [00:12<00:24, 26.65it/s, est. speed input: 31044.90 toks/s, output: 30.32 toks/s]
Processed prompts:  38%|      | 386/1024 [00:12<00:23, 26.67it/s, est. speed input: 30958.76 toks/s, output: 30.23 toks/s]
Processed prompts:  38%|      | 394/1024 [00:13<00:23, 26.58it/s, est. speed input: 30866.45 toks/s, output: 30.14 toks/s]
Processed prompts:  39%|      | 402/1024 [00:13<00:23, 26.68it/s, est. speed input: 30793.28 toks/s, output: 30.07 toks/s]
Processed prompts:  40%|      | 410/1024 [00:13<00:22, 26.71it/s, est. speed input: 30719.56 toks/s, output: 30.00 toks/s]
Processed prompts:  41%|      | 418/1024 [00:13<00:22, 26.58it/s, est. speed input: 30636.66 toks/s, output: 29.92 toks/s]
Processed prompts:  42%|     | 426/1024 [00:14<00:22, 26.63it/s, est. speed input: 30568.58 toks/s, output: 29.85 toks/s]
Processed prompts:  42%|     | 434/1024 [00:14<00:22, 26.66it/s, est. speed input: 30503.23 toks/s, output: 29.79 toks/s]
Processed prompts:  43%|     | 442/1024 [00:14<00:21, 26.72it/s, est. speed input: 30442.56 toks/s, output: 29.73 toks/s]
Processed prompts:  44%|     | 450/1024 [00:15<00:21, 27.02it/s, est. speed input: 30404.27 toks/s, output: 29.69 toks/s]
Processed prompts:  45%|     | 458/1024 [00:15<00:21, 26.92it/s, est. speed input: 30344.54 toks/s, output: 29.63 toks/s]
Processed prompts:  46%|     | 466/1024 [00:15<00:20, 26.89it/s, est. speed input: 30289.77 toks/s, output: 29.58 toks/s]
Processed prompts:  46%|     | 474/1024 [00:16<00:20, 26.66it/s, est. speed input: 30222.94 toks/s, output: 29.51 toks/s]
Processed prompts:  47%|     | 482/1024 [00:16<00:20, 26.71it/s, est. speed input: 30172.48 toks/s, output: 29.47 toks/s]
Processed prompts:  48%|     | 490/1024 [00:16<00:20, 26.68it/s, est. speed input: 30120.13 toks/s, output: 29.41 toks/s]
Processed prompts:  49%|     | 498/1024 [00:16<00:19, 26.79it/s, est. speed input: 30077.81 toks/s, output: 29.37 toks/s]
Processed prompts:  49%|     | 506/1024 [00:17<00:19, 26.58it/s, est. speed input: 30018.66 toks/s, output: 29.32 toks/s]
Processed prompts:  50%|     | 514/1024 [00:17<00:19, 26.69it/s, est. speed input: 29977.76 toks/s, output: 29.28 toks/s]
Processed prompts:  51%|     | 522/1024 [00:17<00:18, 26.71it/s, est. speed input: 29934.46 toks/s, output: 29.23 toks/s]
Processed prompts:  52%|    | 530/1024 [00:18<00:18, 26.54it/s, est. speed input: 29881.44 toks/s, output: 29.18 toks/s]
Processed prompts:  53%|    | 538/1024 [00:18<00:18, 26.63it/s, est. speed input: 29842.62 toks/s, output: 29.14 toks/s]
Processed prompts:  53%|    | 546/1024 [00:18<00:17, 26.68it/s, est. speed input: 29804.54 toks/s, output: 29.11 toks/s]
Processed prompts:  54%|    | 554/1024 [00:19<00:17, 26.77it/s, est. speed input: 29770.38 toks/s, output: 29.07 toks/s]
Processed prompts:  55%|    | 562/1024 [00:19<00:17, 26.64it/s, est. speed input: 29726.62 toks/s, output: 29.03 toks/s]
Processed prompts:  56%|    | 570/1024 [00:19<00:16, 26.72it/s, est. speed input: 29693.99 toks/s, output: 29.00 toks/s]
Processed prompts:  56%|    | 578/1024 [00:19<00:16, 26.70it/s, est. speed input: 29657.83 toks/s, output: 28.96 toks/s]
Processed prompts:  57%|    | 586/1024 [00:20<00:16, 26.66it/s, est. speed input: 29621.06 toks/s, output: 28.93 toks/s]
Processed prompts:  58%|    | 594/1024 [00:20<00:16, 26.59it/s, est. speed input: 29583.79 toks/s, output: 28.89 toks/s]
Processed prompts:  59%|    | 602/1024 [00:20<00:15, 26.59it/s, est. speed input: 29549.89 toks/s, output: 28.86 toks/s]
Processed prompts:  60%|    | 610/1024 [00:21<00:15, 26.64it/s, est. speed input: 29519.18 toks/s, output: 28.83 toks/s]
Processed prompts:  60%|    | 618/1024 [00:21<00:15, 26.53it/s, est. speed input: 29482.25 toks/s, output: 28.79 toks/s]
Processed prompts:  61%|    | 626/1024 [00:21<00:14, 26.60it/s, est. speed input: 29453.92 toks/s, output: 28.76 toks/s]
Processed prompts:  62%|   | 634/1024 [00:22<00:14, 26.61it/s, est. speed input: 29423.96 toks/s, output: 28.73 toks/s]
Processed prompts:  63%|   | 642/1024 [00:22<00:14, 26.57it/s, est. speed input: 29393.03 toks/s, output: 28.70 toks/s]
Processed prompts:  63%|   | 650/1024 [00:22<00:14, 26.54it/s, est. speed input: 29362.39 toks/s, output: 28.67 toks/s]
Processed prompts:  64%|   | 658/1024 [00:22<00:13, 26.65it/s, est. speed input: 29338.87 toks/s, output: 28.65 toks/s]
Processed prompts:  65%|   | 666/1024 [00:23<00:13, 26.71it/s, est. speed input: 29315.42 toks/s, output: 28.63 toks/s]
Processed prompts:  66%|   | 674/1024 [00:23<00:13, 26.57it/s, est. speed input: 29284.04 toks/s, output: 28.60 toks/s]
Processed prompts:  67%|   | 682/1024 [00:23<00:12, 26.61it/s, est. speed input: 29259.71 toks/s, output: 28.57 toks/s]
Processed prompts:  67%|   | 690/1024 [00:24<00:12, 26.72it/s, est. speed input: 29239.40 toks/s, output: 28.55 toks/s]
Processed prompts:  68%|   | 698/1024 [00:24<00:12, 26.74it/s, est. speed input: 29217.63 toks/s, output: 28.53 toks/s]
Processed prompts:  69%|   | 706/1024 [00:24<00:11, 26.63it/s, est. speed input: 29190.35 toks/s, output: 28.51 toks/s]
Processed prompts:  70%|   | 714/1024 [00:25<00:11, 26.57it/s, est. speed input: 29164.95 toks/s, output: 28.48 toks/s]
Processed prompts:  71%|   | 722/1024 [00:25<00:11, 26.67it/s, est. speed input: 29145.81 toks/s, output: 28.46 toks/s]
Processed prompts:  71%|  | 730/1024 [00:25<00:11, 26.60it/s, est. speed input: 29121.36 toks/s, output: 28.44 toks/s]
Processed prompts:  72%|  | 738/1024 [00:25<00:10, 26.70it/s, est. speed input: 29103.96 toks/s, output: 28.42 toks/s]
Processed prompts:  73%|  | 746/1024 [00:26<00:10, 26.70it/s, est. speed input: 29083.92 toks/s, output: 28.40 toks/s]
Processed prompts:  74%|  | 754/1024 [00:26<00:10, 26.65it/s, est. speed input: 29061.89 toks/s, output: 28.38 toks/s]
Processed prompts:  74%|  | 762/1024 [00:26<00:09, 26.56it/s, est. speed input: 29038.73 toks/s, output: 28.36 toks/s]
Processed prompts:  75%|  | 770/1024 [00:27<00:09, 26.59it/s, est. speed input: 29019.21 toks/s, output: 28.34 toks/s]
Processed prompts:  76%|  | 778/1024 [00:27<00:09, 26.67it/s, est. speed input: 29002.84 toks/s, output: 28.32 toks/s]
Processed prompts:  77%|  | 786/1024 [00:27<00:08, 26.51it/s, est. speed input: 28978.23 toks/s, output: 28.30 toks/s]
Processed prompts:  78%|  | 794/1024 [00:28<00:08, 26.62it/s, est. speed input: 28962.78 toks/s, output: 28.28 toks/s]
Processed prompts:  78%|  | 802/1024 [00:28<00:08, 26.61it/s, est. speed input: 28944.45 toks/s, output: 28.27 toks/s]
Processed prompts:  79%|  | 810/1024 [00:28<00:08, 26.70it/s, est. speed input: 28930.21 toks/s, output: 28.25 toks/s]
Processed prompts:  80%|  | 818/1024 [00:28<00:07, 26.54it/s, est. speed input: 28907.85 toks/s, output: 28.23 toks/s]
Processed prompts:  81%|  | 826/1024 [00:29<00:07, 26.58it/s, est. speed input: 28891.26 toks/s, output: 28.21 toks/s]
Processed prompts:  81%| | 834/1024 [00:29<00:07, 26.62it/s, est. speed input: 28875.69 toks/s, output: 28.20 toks/s]
Processed prompts:  82%| | 842/1024 [00:29<00:06, 26.54it/s, est. speed input: 28856.63 toks/s, output: 28.18 toks/s]
Processed prompts:  83%| | 850/1024 [00:30<00:06, 26.59it/s, est. speed input: 28841.50 toks/s, output: 28.17 toks/s]
Processed prompts:  84%| | 858/1024 [00:30<00:06, 26.69it/s, est. speed input: 28829.13 toks/s, output: 28.15 toks/s]
Processed prompts:  85%| | 866/1024 [00:30<00:05, 26.72it/s, est. speed input: 28815.68 toks/s, output: 28.14 toks/s]
Processed prompts:  85%| | 874/1024 [00:31<00:05, 26.62it/s, est. speed input: 28798.25 toks/s, output: 28.12 toks/s]
Processed prompts:  86%| | 882/1024 [00:31<00:05, 26.65it/s, est. speed input: 28784.37 toks/s, output: 28.11 toks/s]
Processed prompts:  87%| | 890/1024 [00:31<00:05, 26.61it/s, est. speed input: 28769.03 toks/s, output: 28.09 toks/s]
Processed prompts:  88%| | 898/1024 [00:31<00:04, 26.74it/s, est. speed input: 28758.99 toks/s, output: 28.08 toks/s]
Processed prompts:  88%| | 906/1024 [00:32<00:04, 26.64it/s, est. speed input: 28742.77 toks/s, output: 28.07 toks/s]
Processed prompts:  89%| | 914/1024 [00:32<00:04, 26.67it/s, est. speed input: 28730.34 toks/s, output: 28.06 toks/s]
Processed prompts:  90%| | 922/1024 [00:32<00:03, 26.74it/s, est. speed input: 28719.56 toks/s, output: 28.05 toks/s]
Processed prompts:  91%| | 930/1024 [00:33<00:03, 26.62it/s, est. speed input: 28703.56 toks/s, output: 28.03 toks/s]
Processed prompts:  92%|| 938/1024 [00:33<00:03, 27.72it/s, est. speed input: 28724.90 toks/s, output: 28.05 toks/s]
Processed prompts:  92%|| 946/1024 [00:33<00:02, 27.40it/s, est. speed input: 28712.46 toks/s, output: 28.04 toks/s]
Processed prompts:  93%|| 954/1024 [00:34<00:02, 27.18it/s, est. speed input: 28700.02 toks/s, output: 28.03 toks/s]
Processed prompts:  94%|| 962/1024 [00:34<00:02, 26.91it/s, est. speed input: 28684.49 toks/s, output: 28.01 toks/s]
Processed prompts:  95%|| 970/1024 [00:34<00:02, 26.82it/s, est. speed input: 28672.10 toks/s, output: 28.00 toks/s]
Processed prompts:  96%|| 978/1024 [00:34<00:01, 26.78it/s, est. speed input: 28660.42 toks/s, output: 27.99 toks/s]
Processed prompts:  96%|| 986/1024 [00:35<00:01, 27.75it/s, est. speed input: 28678.40 toks/s, output: 28.01 toks/s]
Processed prompts:  97%|| 994/1024 [00:35<00:01, 27.33it/s, est. speed input: 28664.30 toks/s, output: 27.99 toks/s]
Processed prompts:  98%|| 1002/1024 [00:35<00:00, 27.17it/s, est. speed input: 28654.08 toks/s, output: 27.98 toks/s]
Processed prompts:  99%|| 1010/1024 [00:36<00:00, 27.08it/s, est. speed input: 28644.69 toks/s, output: 27.97 toks/s]
Processed prompts:  99%|| 1018/1024 [00:36<00:00, 27.42it/s, est. speed input: 28647.00 toks/s, output: 27.98 toks/s]
Processed prompts: 100%|| 1024/1024 [00:36<00:00, 27.42it/s, est. speed input: 28815.65 toks/s, output: 28.14 toks/s]
Processed prompts: 100%|| 1024/1024 [00:36<00:00, 28.14it/s, est. speed input: 28815.65 toks/s, output: 28.14 toks/s]
[rank0]:[W126 08:45:35.492653377 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-26 08:45:37
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-1B-FP8_M16384.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:45:46 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 08:45:47 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1091698) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1091698) WARNING 01-26 08:46:09 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 27.23 requests/s, 27914.42 total tokens/s, 27.23 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-26 08:45:46] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:45:46] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:45:46] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:45:46] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:45:46] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:45:46] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:45:46] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:45:46] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:45:46] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:45:46] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:45:46] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:45:46] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:45:46] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:45:46] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:45:50] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:45:50] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:45:50] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:45:50] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:45:50] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:45:50] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:45:50] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:45:50] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:45:50] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:45:50] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:45:50] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:45:50] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:45:50] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:45:50] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1091698) [2026-01-26 08:45:51] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1091698) [2026-01-26 08:45:51] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1091698) [2026-01-26 08:45:51] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1091698) [2026-01-26 08:45:51] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1091698) [2026-01-26 08:45:51] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1091698) [2026-01-26 08:45:51] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1091698) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1091698) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.73s/it]
(EngineCore_DP0 pid=1091698) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.73s/it]
(EngineCore_DP0 pid=1091698) 
(EngineCore_DP0 pid=1091698) [2026-01-26 08:46:02] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=1091698) [2026-01-26 08:46:02] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6340608 bytes
(EngineCore_DP0 pid=1091698) [2026-01-26 08:46:02] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=1091698) [2026-01-26 08:46:02] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 4227072 bytes
(EngineCore_DP0 pid=1091698) [2026-01-26 08:46:02] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=1091698) [2026-01-26 08:46:02] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 33816576 bytes
(EngineCore_DP0 pid=1091698) [2026-01-26 08:46:02] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=1091698) [2026-01-26 08:46:02] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16809984 bytes
(EngineCore_DP0 pid=1091698) 2026-01-26 08:46:08,344 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1091698) 2026-01-26 08:46:08,421 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   3%|         | 60/2048 [00:00<00:03, 590.22it/s]
Adding requests:   6%|         | 120/2048 [00:00<00:03, 538.50it/s]
Adding requests:   9%|         | 175/2048 [00:00<00:03, 515.25it/s]
Adding requests:  11%|         | 227/2048 [00:00<00:03, 508.52it/s]
Adding requests:  14%|        | 278/2048 [00:00<00:03, 505.48it/s]
Adding requests:  16%|        | 329/2048 [00:00<00:03, 500.16it/s]
Adding requests:  19%|        | 381/2048 [00:00<00:03, 505.61it/s]
Adding requests:  21%|        | 432/2048 [00:00<00:03, 495.98it/s]
Adding requests:  24%|       | 482/2048 [00:00<00:03, 489.74it/s]
Adding requests:  26%|       | 532/2048 [00:01<00:03, 475.40it/s]
Adding requests:  28%|       | 583/2048 [00:01<00:03, 483.28it/s]
Adding requests:  31%|       | 635/2048 [00:01<00:02, 492.42it/s]
Adding requests:  33%|      | 685/2048 [00:01<00:02, 488.01it/s]
Adding requests:  36%|      | 734/2048 [00:01<00:02, 484.89it/s]
Adding requests:  38%|      | 783/2048 [00:01<00:02, 456.12it/s]
Adding requests:  40%|      | 829/2048 [00:01<00:02, 456.31it/s]
Adding requests:  43%|     | 875/2048 [00:02<00:07, 160.58it/s]
Adding requests:  45%|     | 922/2048 [00:02<00:05, 199.34it/s]
Adding requests:  47%|     | 968/2048 [00:02<00:04, 238.82it/s]
Adding requests:  50%|     | 1018/2048 [00:02<00:03, 285.09it/s]
Adding requests:  52%|    | 1067/2048 [00:02<00:03, 326.26it/s]
Adding requests:  54%|    | 1115/2048 [00:02<00:02, 360.13it/s]
Adding requests:  57%|    | 1164/2048 [00:03<00:02, 391.21it/s]
Adding requests:  59%|    | 1212/2048 [00:03<00:02, 411.96it/s]
Adding requests:  61%|   | 1259/2048 [00:03<00:01, 424.47it/s]
Adding requests:  64%|   | 1311/2048 [00:03<00:01, 448.53it/s]
Adding requests:  66%|   | 1359/2048 [00:03<00:01, 455.10it/s]
Adding requests:  69%|   | 1412/2048 [00:03<00:01, 474.36it/s]
Adding requests:  71%|  | 1462/2048 [00:03<00:01, 481.35it/s]
Adding requests:  74%|  | 1512/2048 [00:03<00:01, 480.32it/s]
Adding requests:  76%|  | 1561/2048 [00:03<00:01, 479.57it/s]
Adding requests:  79%|  | 1612/2048 [00:03<00:00, 486.02it/s]
Adding requests:  81%|  | 1661/2048 [00:04<00:00, 485.07it/s]
Adding requests:  83%| | 1710/2048 [00:04<00:00, 485.62it/s]
Adding requests:  86%| | 1759/2048 [00:04<00:00, 475.68it/s]
Adding requests:  88%| | 1807/2048 [00:04<00:00, 476.14it/s]
Adding requests:  91%| | 1856/2048 [00:04<00:00, 478.09it/s]
Adding requests:  93%|| 1906/2048 [00:04<00:00, 482.91it/s]
Adding requests:  95%|| 1955/2048 [00:04<00:00, 477.99it/s]
Adding requests:  98%|| 2006/2048 [00:04<00:00, 466.56it/s]
Adding requests: 100%|| 2048/2048 [00:04<00:00, 417.90it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|         | 130/2048 [00:00<00:08, 233.02it/s, est. speed input: 238623.88 toks/s, output: 233.03 toks/s]
Processed prompts:   8%|         | 154/2048 [00:01<00:16, 117.92it/s, est. speed input: 138010.84 toks/s, output: 134.78 toks/s]
Processed prompts:   8%|         | 167/2048 [00:01<00:25, 73.23it/s, est. speed input: 98461.19 toks/s, output: 96.15 toks/s]   
Processed prompts:   9%|         | 178/2048 [00:02<00:36, 51.68it/s, est. speed input: 78484.13 toks/s, output: 76.64 toks/s]
Processed prompts:   9%|         | 194/2048 [00:02<00:43, 42.71it/s, est. speed input: 68164.68 toks/s, output: 66.57 toks/s]
Processed prompts:  10%|         | 210/2048 [00:03<00:49, 37.49it/s, est. speed input: 61447.22 toks/s, output: 60.01 toks/s]
Processed prompts:  11%|         | 226/2048 [00:04<00:53, 34.06it/s, est. speed input: 56568.52 toks/s, output: 55.24 toks/s]
Processed prompts:  12%|        | 242/2048 [00:04<00:56, 31.89it/s, est. speed input: 52971.20 toks/s, output: 51.73 toks/s]
Processed prompts:  13%|        | 258/2048 [00:05<00:58, 30.37it/s, est. speed input: 50131.94 toks/s, output: 48.96 toks/s]
Processed prompts:  13%|        | 274/2048 [00:05<01:00, 29.35it/s, est. speed input: 47874.99 toks/s, output: 46.75 toks/s]
Processed prompts:  14%|        | 290/2048 [00:06<01:01, 28.75it/s, est. speed input: 46071.88 toks/s, output: 44.99 toks/s]
Processed prompts:  15%|        | 306/2048 [00:07<01:01, 28.20it/s, est. speed input: 44513.80 toks/s, output: 43.47 toks/s]
Processed prompts:  16%|        | 322/2048 [00:07<01:01, 27.94it/s, est. speed input: 43248.01 toks/s, output: 42.23 toks/s]
Processed prompts:  17%|        | 338/2048 [00:08<01:01, 27.80it/s, est. speed input: 42174.52 toks/s, output: 41.19 toks/s]
Processed prompts:  17%|        | 354/2048 [00:08<01:01, 27.59it/s, est. speed input: 41208.88 toks/s, output: 40.24 toks/s]
Processed prompts:  18%|        | 370/2048 [00:09<01:01, 27.44it/s, est. speed input: 40359.63 toks/s, output: 39.41 toks/s]
Processed prompts:  19%|        | 386/2048 [00:09<01:00, 27.43it/s, est. speed input: 39639.88 toks/s, output: 38.71 toks/s]
Processed prompts:  20%|        | 402/2048 [00:10<01:00, 27.35it/s, est. speed input: 38981.21 toks/s, output: 38.07 toks/s]
Processed prompts:  20%|        | 418/2048 [00:11<00:59, 27.33it/s, est. speed input: 38400.47 toks/s, output: 37.50 toks/s]
Processed prompts:  21%|        | 434/2048 [00:11<00:59, 27.21it/s, est. speed input: 37853.69 toks/s, output: 36.97 toks/s]
Processed prompts:  22%|       | 450/2048 [00:12<00:58, 27.41it/s, est. speed input: 37420.14 toks/s, output: 36.54 toks/s]
Processed prompts:  23%|       | 466/2048 [00:12<00:57, 27.41it/s, est. speed input: 36996.49 toks/s, output: 36.13 toks/s]
Processed prompts:  24%|       | 482/2048 [00:13<00:57, 27.32it/s, est. speed input: 36592.85 toks/s, output: 35.74 toks/s]
Processed prompts:  24%|       | 498/2048 [00:14<00:56, 27.32it/s, est. speed input: 36234.91 toks/s, output: 35.39 toks/s]
Processed prompts:  25%|       | 514/2048 [00:14<00:56, 27.26it/s, est. speed input: 35893.34 toks/s, output: 35.05 toks/s]
Processed prompts:  26%|       | 530/2048 [00:15<00:55, 27.27it/s, est. speed input: 35588.20 toks/s, output: 34.75 toks/s]
Processed prompts:  27%|       | 546/2048 [00:15<00:55, 27.18it/s, est. speed input: 35289.34 toks/s, output: 34.46 toks/s]
Processed prompts:  27%|       | 562/2048 [00:16<00:54, 27.23it/s, est. speed input: 35030.29 toks/s, output: 34.21 toks/s]
Processed prompts:  28%|       | 578/2048 [00:17<00:54, 27.17it/s, est. speed input: 34775.05 toks/s, output: 33.96 toks/s]
Processed prompts:  29%|       | 594/2048 [00:17<00:53, 27.13it/s, est. speed input: 34536.88 toks/s, output: 33.73 toks/s]
Processed prompts:  30%|       | 610/2048 [00:18<00:52, 27.18it/s, est. speed input: 34324.76 toks/s, output: 33.52 toks/s]
Processed prompts:  31%|       | 626/2048 [00:18<00:52, 27.10it/s, est. speed input: 34110.23 toks/s, output: 33.31 toks/s]
Processed prompts:  31%|      | 642/2048 [00:19<00:51, 27.17it/s, est. speed input: 33925.52 toks/s, output: 33.13 toks/s]
Processed prompts:  32%|      | 658/2048 [00:19<00:51, 27.12it/s, est. speed input: 33739.00 toks/s, output: 32.95 toks/s]
Processed prompts:  33%|      | 674/2048 [00:20<00:50, 27.18it/s, est. speed input: 33575.05 toks/s, output: 32.79 toks/s]
Processed prompts:  34%|      | 690/2048 [00:21<00:50, 27.13it/s, est. speed input: 33409.94 toks/s, output: 32.63 toks/s]
Processed prompts:  34%|      | 706/2048 [00:21<00:49, 27.22it/s, est. speed input: 33266.59 toks/s, output: 32.49 toks/s]
Processed prompts:  35%|      | 722/2048 [00:22<00:48, 27.15it/s, est. speed input: 33116.89 toks/s, output: 32.34 toks/s]
Processed prompts:  36%|      | 738/2048 [00:22<00:48, 27.20it/s, est. speed input: 32986.01 toks/s, output: 32.21 toks/s]
Processed prompts:  37%|      | 754/2048 [00:23<00:47, 27.16it/s, est. speed input: 32853.51 toks/s, output: 32.08 toks/s]
Processed prompts:  38%|      | 770/2048 [00:24<00:47, 27.10it/s, est. speed input: 32724.62 toks/s, output: 31.96 toks/s]
Processed prompts:  38%|      | 786/2048 [00:24<00:46, 27.18it/s, est. speed input: 32612.60 toks/s, output: 31.85 toks/s]
Processed prompts:  39%|      | 802/2048 [00:25<00:45, 27.12it/s, est. speed input: 32495.45 toks/s, output: 31.73 toks/s]
Processed prompts:  40%|      | 818/2048 [00:25<00:45, 27.17it/s, est. speed input: 32392.04 toks/s, output: 31.63 toks/s]
Processed prompts:  41%|      | 834/2048 [00:26<00:44, 27.19it/s, est. speed input: 32291.97 toks/s, output: 31.54 toks/s]
Processed prompts:  42%|     | 850/2048 [00:27<00:44, 27.21it/s, est. speed input: 32197.35 toks/s, output: 31.44 toks/s]
Processed prompts:  42%|     | 866/2048 [00:27<00:43, 27.16it/s, est. speed input: 32100.45 toks/s, output: 31.35 toks/s]
Processed prompts:  43%|     | 882/2048 [00:28<00:42, 27.21it/s, est. speed input: 32015.02 toks/s, output: 31.26 toks/s]
Processed prompts:  44%|     | 898/2048 [00:28<00:42, 27.14it/s, est. speed input: 31924.88 toks/s, output: 31.18 toks/s]
Processed prompts:  45%|     | 914/2048 [00:29<00:41, 27.12it/s, est. speed input: 31840.46 toks/s, output: 31.09 toks/s]
Processed prompts:  45%|     | 930/2048 [00:29<00:40, 27.59it/s, est. speed input: 31795.97 toks/s, output: 31.05 toks/s]
Processed prompts:  46%|     | 946/2048 [00:30<00:40, 27.43it/s, est. speed input: 31716.70 toks/s, output: 30.97 toks/s]
Processed prompts:  47%|     | 962/2048 [00:31<00:39, 27.38it/s, est. speed input: 31645.44 toks/s, output: 30.90 toks/s]
Processed prompts:  48%|     | 978/2048 [00:31<00:38, 27.72it/s, est. speed input: 31602.49 toks/s, output: 30.86 toks/s]
Processed prompts:  49%|     | 994/2048 [00:32<00:38, 27.57it/s, est. speed input: 31534.43 toks/s, output: 30.80 toks/s]
Processed prompts:  49%|     | 1010/2048 [00:32<00:37, 27.40it/s, est. speed input: 31465.02 toks/s, output: 30.73 toks/s]
Processed prompts:  50%|     | 1026/2048 [00:33<00:37, 27.38it/s, est. speed input: 31404.31 toks/s, output: 30.67 toks/s]
Processed prompts:  51%|     | 1042/2048 [00:34<00:36, 27.30it/s, est. speed input: 31341.01 toks/s, output: 30.61 toks/s]
Processed prompts:  52%|    | 1058/2048 [00:34<00:36, 27.29it/s, est. speed input: 31283.00 toks/s, output: 30.55 toks/s]
Processed prompts:  52%|    | 1074/2048 [00:35<00:35, 27.22it/s, est. speed input: 31222.92 toks/s, output: 30.49 toks/s]
Processed prompts:  53%|    | 1090/2048 [00:35<00:35, 27.18it/s, est. speed input: 31165.49 toks/s, output: 30.44 toks/s]
Processed prompts:  54%|    | 1106/2048 [00:36<00:34, 27.18it/s, est. speed input: 31111.31 toks/s, output: 30.38 toks/s]
Processed prompts:  55%|    | 1122/2048 [00:36<00:34, 27.12it/s, est. speed input: 31055.37 toks/s, output: 30.33 toks/s]
Processed prompts:  56%|    | 1138/2048 [00:37<00:33, 27.17it/s, est. speed input: 31006.75 toks/s, output: 30.28 toks/s]
Processed prompts:  56%|    | 1154/2048 [00:38<00:32, 27.52it/s, est. speed input: 30978.17 toks/s, output: 30.25 toks/s]
Processed prompts:  57%|    | 1170/2048 [00:38<00:31, 27.46it/s, est. speed input: 30932.64 toks/s, output: 30.21 toks/s]
Processed prompts:  58%|    | 1186/2048 [00:39<00:31, 27.34it/s, est. speed input: 30884.17 toks/s, output: 30.16 toks/s]
Processed prompts:  59%|    | 1202/2048 [00:39<00:30, 27.31it/s, est. speed input: 30840.56 toks/s, output: 30.12 toks/s]
Processed prompts:  59%|    | 1218/2048 [00:40<00:30, 27.23it/s, est. speed input: 30794.23 toks/s, output: 30.07 toks/s]
Processed prompts:  60%|    | 1234/2048 [00:41<00:29, 27.24it/s, est. speed input: 30753.31 toks/s, output: 30.03 toks/s]
Processed prompts:  61%|    | 1250/2048 [00:41<00:29, 27.17it/s, est. speed input: 30709.32 toks/s, output: 29.99 toks/s]
Processed prompts:  62%|   | 1266/2048 [00:42<00:28, 27.53it/s, est. speed input: 30687.81 toks/s, output: 29.97 toks/s]
Processed prompts:  63%|   | 1282/2048 [00:42<00:27, 27.46it/s, est. speed input: 30650.47 toks/s, output: 29.93 toks/s]
Processed prompts:  63%|   | 1298/2048 [00:43<00:27, 27.77it/s, est. speed input: 30631.62 toks/s, output: 29.91 toks/s]
Processed prompts:  64%|   | 1314/2048 [00:43<00:26, 27.64it/s, est. speed input: 30596.65 toks/s, output: 29.88 toks/s]
Processed prompts:  65%|   | 1330/2048 [00:44<00:26, 27.44it/s, est. speed input: 30557.15 toks/s, output: 29.84 toks/s]
Processed prompts:  66%|   | 1346/2048 [00:45<00:25, 27.39it/s, est. speed input: 30522.96 toks/s, output: 29.81 toks/s]
Processed prompts:  67%|   | 1362/2048 [00:45<00:25, 27.26it/s, est. speed input: 30485.34 toks/s, output: 29.77 toks/s]
Processed prompts:  67%|   | 1378/2048 [00:46<00:24, 27.27it/s, est. speed input: 30453.09 toks/s, output: 29.74 toks/s]
Processed prompts:  68%|   | 1394/2048 [00:46<00:24, 27.20it/s, est. speed input: 30418.29 toks/s, output: 29.71 toks/s]
Processed prompts:  69%|   | 1410/2048 [00:47<00:23, 27.18it/s, est. speed input: 30385.34 toks/s, output: 29.67 toks/s]
Processed prompts:  70%|   | 1426/2048 [00:48<00:22, 27.21it/s, est. speed input: 30355.40 toks/s, output: 29.64 toks/s]
Processed prompts:  70%|   | 1442/2048 [00:48<00:22, 27.15it/s, est. speed input: 30322.59 toks/s, output: 29.61 toks/s]
Processed prompts:  71%|   | 1458/2048 [00:49<00:21, 27.19it/s, est. speed input: 30294.47 toks/s, output: 29.58 toks/s]
Processed prompts:  72%|  | 1474/2048 [00:49<00:21, 27.14it/s, est. speed input: 30263.08 toks/s, output: 29.55 toks/s]
Processed prompts:  73%|  | 1490/2048 [00:50<00:20, 27.16it/s, est. speed input: 30235.00 toks/s, output: 29.53 toks/s]
Processed prompts:  74%|  | 1506/2048 [00:51<00:19, 27.14it/s, est. speed input: 30206.08 toks/s, output: 29.50 toks/s]
Processed prompts:  74%|  | 1522/2048 [00:51<00:19, 27.20it/s, est. speed input: 30181.35 toks/s, output: 29.47 toks/s]
Processed prompts:  75%|  | 1538/2048 [00:52<00:18, 27.14it/s, est. speed input: 30152.51 toks/s, output: 29.45 toks/s]
Processed prompts:  76%|  | 1554/2048 [00:52<00:18, 27.17it/s, est. speed input: 30127.39 toks/s, output: 29.42 toks/s]
Processed prompts:  77%|  | 1570/2048 [00:53<00:17, 27.11it/s, est. speed input: 30099.41 toks/s, output: 29.39 toks/s]
Processed prompts:  77%|  | 1586/2048 [00:53<00:16, 27.53it/s, est. speed input: 30090.49 toks/s, output: 29.39 toks/s]
Processed prompts:  78%|  | 1602/2048 [00:54<00:16, 27.45it/s, est. speed input: 30067.23 toks/s, output: 29.36 toks/s]
Processed prompts:  79%|  | 1618/2048 [00:55<00:15, 27.33it/s, est. speed input: 30042.04 toks/s, output: 29.34 toks/s]
Processed prompts:  80%|  | 1634/2048 [00:55<00:15, 27.29it/s, est. speed input: 30018.81 toks/s, output: 29.32 toks/s]
Processed prompts:  81%|  | 1650/2048 [00:56<00:14, 27.67it/s, est. speed input: 30011.52 toks/s, output: 29.31 toks/s]
Processed prompts:  81%| | 1666/2048 [00:56<00:13, 27.56it/s, est. speed input: 29990.33 toks/s, output: 29.29 toks/s]
Processed prompts:  82%| | 1682/2048 [00:57<00:13, 27.38it/s, est. speed input: 29965.99 toks/s, output: 29.26 toks/s]
Processed prompts:  83%| | 1698/2048 [00:58<00:12, 27.36it/s, est. speed input: 29945.63 toks/s, output: 29.24 toks/s]
Processed prompts:  84%| | 1714/2048 [00:58<00:12, 27.26it/s, est. speed input: 29922.84 toks/s, output: 29.22 toks/s]
Processed prompts:  84%| | 1730/2048 [00:59<00:11, 27.26it/s, est. speed input: 29903.10 toks/s, output: 29.20 toks/s]
Processed prompts:  85%| | 1746/2048 [00:59<00:11, 27.21it/s, est. speed input: 29881.58 toks/s, output: 29.18 toks/s]
Processed prompts:  86%| | 1762/2048 [01:00<00:10, 27.15it/s, est. speed input: 29859.82 toks/s, output: 29.16 toks/s]
Processed prompts:  87%| | 1778/2048 [01:01<00:09, 27.15it/s, est. speed input: 29840.14 toks/s, output: 29.14 toks/s]
Processed prompts:  88%| | 1794/2048 [01:01<00:09, 27.13it/s, est. speed input: 29819.65 toks/s, output: 29.12 toks/s]
Processed prompts:  88%| | 1810/2048 [01:02<00:08, 27.16it/s, est. speed input: 29801.44 toks/s, output: 29.10 toks/s]
Processed prompts:  89%| | 1826/2048 [01:02<00:08, 27.10it/s, est. speed input: 29780.85 toks/s, output: 29.08 toks/s]
Processed prompts:  90%| | 1842/2048 [01:03<00:07, 27.15it/s, est. speed input: 29763.71 toks/s, output: 29.07 toks/s]
Processed prompts:  91%| | 1858/2048 [01:03<00:07, 27.09it/s, est. speed input: 29743.33 toks/s, output: 29.05 toks/s]
Processed prompts:  92%|| 1874/2048 [01:04<00:06, 27.61it/s, est. speed input: 29742.10 toks/s, output: 29.05 toks/s]
Processed prompts:  92%|| 1890/2048 [01:05<00:05, 27.37it/s, est. speed input: 29721.51 toks/s, output: 29.02 toks/s]
Processed prompts:  93%|| 1906/2048 [01:05<00:05, 27.29it/s, est. speed input: 29703.71 toks/s, output: 29.01 toks/s]
Processed prompts:  94%|| 1922/2048 [01:06<00:04, 27.27it/s, est. speed input: 29687.37 toks/s, output: 28.99 toks/s]
Processed prompts:  95%|| 1938/2048 [01:06<00:04, 27.17it/s, est. speed input: 29668.74 toks/s, output: 28.97 toks/s]
Processed prompts:  95%|| 1954/2048 [01:07<00:03, 27.63it/s, est. speed input: 29666.94 toks/s, output: 28.97 toks/s]
Processed prompts:  96%|| 1970/2048 [01:08<00:02, 27.39it/s, est. speed input: 29648.04 toks/s, output: 28.95 toks/s]
Processed prompts:  97%|| 1986/2048 [01:08<00:02, 27.78it/s, est. speed input: 29646.03 toks/s, output: 28.95 toks/s]
Processed prompts:  98%|| 2002/2048 [01:09<00:01, 28.32it/s, est. speed input: 29651.96 toks/s, output: 28.96 toks/s]
Processed prompts:  99%|| 2018/2048 [01:09<00:01, 27.98it/s, est. speed input: 29636.82 toks/s, output: 28.94 toks/s]
Processed prompts:  99%|| 2034/2048 [01:10<00:00, 27.96it/s, est. speed input: 29628.12 toks/s, output: 28.93 toks/s]
Processed prompts: 100%|| 2048/2048 [01:10<00:00, 27.96it/s, est. speed input: 29831.98 toks/s, output: 29.13 toks/s]
Processed prompts: 100%|| 2048/2048 [01:10<00:00, 29.13it/s, est. speed input: 29831.98 toks/s, output: 29.13 toks/s]
[rank0]:[W126 08:47:25.186170270 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-26 08:47:27
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-1B-FP8_M32768.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:47:42 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 08:47:42 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1093472) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1093472) WARNING 01-26 08:48:06 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 27.54 requests/s, 28225.66 total tokens/s, 27.54 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-26 08:47:42] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:47:42] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:47:42] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:47:42] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:47:42] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:47:42] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:47:42] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:47:42] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:47:42] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:47:42] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:47:42] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:47:42] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:47:42] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:47:42] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:47:46] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:47:46] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:47:46] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:47:46] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:47:46] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:47:46] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:47:46] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:47:46] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:47:46] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:47:46] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:47:46] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:47:46] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:47:46] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:47:46] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1093472) [2026-01-26 08:47:47] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1093472) [2026-01-26 08:47:47] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1093472) [2026-01-26 08:47:47] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1093472) [2026-01-26 08:47:47] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1093472) [2026-01-26 08:47:47] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1093472) [2026-01-26 08:47:47] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1093472) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1093472) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.75s/it]
(EngineCore_DP0 pid=1093472) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.75s/it]
(EngineCore_DP0 pid=1093472) 
(EngineCore_DP0 pid=1093472) [2026-01-26 08:47:58] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=1093472) [2026-01-26 08:47:58] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6340608 bytes
(EngineCore_DP0 pid=1093472) [2026-01-26 08:47:58] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=1093472) [2026-01-26 08:47:58] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 4227072 bytes
(EngineCore_DP0 pid=1093472) [2026-01-26 08:47:58] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=1093472) [2026-01-26 08:47:58] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 33816576 bytes
(EngineCore_DP0 pid=1093472) [2026-01-26 08:47:58] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=1093472) [2026-01-26 08:47:58] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16809984 bytes
(EngineCore_DP0 pid=1093472) 2026-01-26 08:48:04,714 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1093472) 2026-01-26 08:48:04,935 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|         | 56/4096 [00:00<00:07, 551.95it/s]
Adding requests:   3%|         | 112/4096 [00:00<00:07, 503.85it/s]
Adding requests:   4%|         | 163/4096 [00:00<00:08, 483.71it/s]
Adding requests:   5%|         | 212/4096 [00:00<00:08, 480.40it/s]
Adding requests:   6%|         | 262/4096 [00:00<00:07, 485.38it/s]
Adding requests:   8%|         | 311/4096 [00:00<00:07, 475.55it/s]
Adding requests:   9%|         | 360/4096 [00:00<00:07, 477.89it/s]
Adding requests:  10%|         | 408/4096 [00:00<00:07, 472.61it/s]
Adding requests:  11%|         | 456/4096 [00:00<00:07, 471.08it/s]
Adding requests:  12%|        | 504/4096 [00:01<00:07, 469.71it/s]
Adding requests:  13%|        | 551/4096 [00:01<00:07, 459.90it/s]
Adding requests:  15%|        | 601/4096 [00:01<00:07, 469.65it/s]
Adding requests:  16%|        | 649/4096 [00:01<00:07, 470.45it/s]
Adding requests:  17%|        | 697/4096 [00:01<00:07, 469.32it/s]
Adding requests:  18%|        | 744/4096 [00:01<00:07, 469.30it/s]
Adding requests:  19%|        | 793/4096 [00:01<00:06, 473.80it/s]
Adding requests:  21%|        | 841/4096 [00:01<00:07, 463.35it/s]
Adding requests:  22%|       | 891/4096 [00:01<00:06, 468.25it/s]
Adding requests:  23%|       | 938/4096 [00:01<00:06, 463.23it/s]
Adding requests:  24%|       | 986/4096 [00:02<00:06, 468.03it/s]
Adding requests:  25%|       | 1033/4096 [00:02<00:06, 465.00it/s]
Adding requests:  26%|       | 1082/4096 [00:02<00:06, 471.37it/s]
Adding requests:  28%|       | 1130/4096 [00:02<00:06, 467.35it/s]
Adding requests:  29%|       | 1180/4096 [00:02<00:06, 476.01it/s]
Adding requests:  30%|       | 1228/4096 [00:02<00:06, 465.21it/s]
Adding requests:  31%|       | 1275/4096 [00:02<00:06, 463.51it/s]
Adding requests:  32%|      | 1322/4096 [00:02<00:06, 439.27it/s]
Adding requests:  33%|      | 1368/4096 [00:02<00:06, 444.24it/s]
Adding requests:  35%|      | 1417/4096 [00:03<00:05, 455.89it/s]
Adding requests:  36%|      | 1466/4096 [00:03<00:05, 464.20it/s]
Adding requests:  37%|      | 1514/4096 [00:03<00:05, 466.43it/s]
Adding requests:  38%|      | 1564/4096 [00:03<00:05, 475.36it/s]
Adding requests:  39%|      | 1612/4096 [00:03<00:05, 468.67it/s]
Adding requests:  41%|      | 1663/4096 [00:03<00:05, 476.31it/s]
Adding requests:  42%|     | 1711/4096 [00:03<00:05, 473.60it/s]
Adding requests:  43%|     | 1759/4096 [00:03<00:04, 469.24it/s]
Adding requests:  44%|     | 1808/4096 [00:03<00:04, 473.78it/s]
Adding requests:  45%|     | 1857/4096 [00:03<00:04, 475.67it/s]
Adding requests:  47%|     | 1905/4096 [00:04<00:04, 474.29it/s]
Adding requests:  48%|     | 1953/4096 [00:04<00:04, 472.31it/s]
Adding requests:  49%|     | 2002/4096 [00:04<00:04, 474.56it/s]
Adding requests:  50%|     | 2054/4096 [00:04<00:04, 485.14it/s]
Adding requests:  51%|    | 2103/4096 [00:04<00:04, 479.24it/s]
Adding requests:  53%|    | 2153/4096 [00:04<00:04, 485.03it/s]
Adding requests:  54%|    | 2202/4096 [00:04<00:04, 469.37it/s]
Adding requests:  55%|    | 2253/4096 [00:04<00:03, 480.03it/s]
Adding requests:  56%|    | 2302/4096 [00:04<00:03, 477.74it/s]
Adding requests:  57%|    | 2350/4096 [00:04<00:03, 471.17it/s]
Adding requests:  59%|    | 2401/4096 [00:05<00:03, 479.58it/s]
Adding requests:  60%|    | 2450/4096 [00:05<00:03, 472.90it/s]
Adding requests:  61%|    | 2501/4096 [00:05<00:03, 481.85it/s]
Adding requests:  62%|   | 2550/4096 [00:05<00:03, 451.91it/s]
Adding requests:  63%|   | 2600/4096 [00:05<00:03, 463.00it/s]
Adding requests:  65%|   | 2649/4096 [00:05<00:03, 468.30it/s]
Adding requests:  66%|   | 2699/4096 [00:05<00:02, 475.46it/s]
Adding requests:  67%|   | 2748/4096 [00:05<00:02, 479.18it/s]
Adding requests:  68%|   | 2797/4096 [00:05<00:02, 469.52it/s]
Adding requests:  70%|   | 2847/4096 [00:06<00:02, 476.76it/s]
Adding requests:  71%|   | 2895/4096 [00:06<00:02, 461.43it/s]
Adding requests:  72%|  | 2942/4096 [00:06<00:02, 463.80it/s]
Adding requests:  73%|  | 2991/4096 [00:06<00:02, 469.02it/s]
Adding requests:  74%|  | 3038/4096 [00:06<00:02, 463.39it/s]
Adding requests:  75%|  | 3087/4096 [00:06<00:02, 471.05it/s]
Adding requests:  77%|  | 3135/4096 [00:06<00:02, 466.64it/s]
Adding requests:  78%|  | 3183/4096 [00:06<00:01, 467.70it/s]
Adding requests:  79%|  | 3231/4096 [00:06<00:01, 470.98it/s]
Adding requests:  80%|  | 3280/4096 [00:06<00:01, 474.87it/s]
Adding requests:  81%| | 3331/4096 [00:07<00:01, 483.93it/s]
Adding requests:  83%| | 3380/4096 [00:07<00:01, 482.77it/s]
Adding requests:  84%| | 3429/4096 [00:07<00:01, 476.28it/s]
Adding requests:  85%| | 3477/4096 [00:07<00:01, 464.06it/s]
Adding requests:  86%| | 3525/4096 [00:07<00:01, 467.89it/s]
Adding requests:  87%| | 3574/4096 [00:07<00:01, 472.85it/s]
Adding requests:  88%| | 3622/4096 [00:07<00:01, 472.36it/s]
Adding requests:  90%| | 3672/4096 [00:07<00:00, 479.88it/s]
Adding requests:  91%| | 3721/4096 [00:07<00:00, 482.48it/s]
Adding requests:  92%|| 3771/4096 [00:07<00:00, 486.54it/s]
Adding requests:  93%|| 3825/4096 [00:08<00:00, 498.04it/s]
Adding requests:  95%|| 3875/4096 [00:08<00:00, 495.94it/s]
Adding requests:  96%|| 3925/4096 [00:08<00:00, 456.21it/s]
Adding requests:  97%|| 3973/4096 [00:08<00:00, 458.85it/s]
Adding requests:  98%|| 4020/4096 [00:08<00:00, 454.78it/s]
Adding requests:  99%|| 4068/4096 [00:08<00:00, 460.70it/s]
Adding requests: 100%|| 4096/4096 [00:08<00:00, 471.41it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|         | 226/4096 [00:00<00:14, 260.22it/s, est. speed input: 266466.87 toks/s, output: 260.22 toks/s]
Processed prompts:   6%|         | 258/4096 [00:02<00:36, 106.59it/s, est. speed input: 129196.89 toks/s, output: 126.17 toks/s]
Processed prompts:   7%|         | 290/4096 [00:03<00:55, 68.13it/s, est. speed input: 92232.15 toks/s, output: 90.07 toks/s]   
Processed prompts:   8%|         | 322/4096 [00:04<01:13, 51.49it/s, est. speed input: 75118.34 toks/s, output: 73.36 toks/s]
Processed prompts:   9%|         | 354/4096 [00:05<01:27, 42.53it/s, est. speed input: 65146.57 toks/s, output: 63.62 toks/s]
Processed prompts:   9%|         | 386/4096 [00:06<01:39, 37.25it/s, est. speed input: 58654.74 toks/s, output: 57.28 toks/s]
Processed prompts:  10%|         | 418/4096 [00:07<01:48, 33.92it/s, est. speed input: 54069.12 toks/s, output: 52.80 toks/s]
Processed prompts:  11%|         | 450/4096 [00:09<01:54, 31.92it/s, est. speed input: 50774.66 toks/s, output: 49.58 toks/s]
Processed prompts:  12%|        | 482/4096 [00:10<01:58, 30.43it/s, est. speed input: 48147.59 toks/s, output: 47.02 toks/s]
Processed prompts:  13%|        | 514/4096 [00:11<02:01, 29.46it/s, est. speed input: 46074.64 toks/s, output: 44.99 toks/s]
Processed prompts:  13%|        | 546/4096 [00:12<02:03, 28.79it/s, est. speed input: 44383.10 toks/s, output: 43.34 toks/s]
Processed prompts:  14%|        | 578/4096 [00:13<02:04, 28.31it/s, est. speed input: 42974.32 toks/s, output: 41.97 toks/s]
Processed prompts:  15%|        | 610/4096 [00:14<02:04, 27.97it/s, est. speed input: 41782.75 toks/s, output: 40.80 toks/s]
Processed prompts:  16%|        | 642/4096 [00:16<02:04, 27.76it/s, est. speed input: 40774.75 toks/s, output: 39.82 toks/s]
Processed prompts:  16%|        | 674/4096 [00:17<02:04, 27.58it/s, est. speed input: 39893.72 toks/s, output: 38.96 toks/s]
Processed prompts:  17%|        | 706/4096 [00:18<02:03, 27.49it/s, est. speed input: 39133.31 toks/s, output: 38.22 toks/s]
Processed prompts:  18%|        | 738/4096 [00:19<02:02, 27.39it/s, est. speed input: 38454.42 toks/s, output: 37.55 toks/s]
Processed prompts:  19%|        | 770/4096 [00:20<02:01, 27.34it/s, est. speed input: 37858.08 toks/s, output: 36.97 toks/s]
Processed prompts:  20%|        | 802/4096 [00:22<02:00, 27.32it/s, est. speed input: 37328.44 toks/s, output: 36.45 toks/s]
Processed prompts:  20%|        | 834/4096 [00:23<01:59, 27.32it/s, est. speed input: 36855.70 toks/s, output: 35.99 toks/s]
Processed prompts:  21%|        | 866/4096 [00:24<01:58, 27.31it/s, est. speed input: 36425.98 toks/s, output: 35.57 toks/s]
Processed prompts:  22%|       | 898/4096 [00:25<01:57, 27.26it/s, est. speed input: 36027.84 toks/s, output: 35.18 toks/s]
Processed prompts:  23%|       | 930/4096 [00:26<01:55, 27.48it/s, est. speed input: 35712.75 toks/s, output: 34.88 toks/s]
Processed prompts:  23%|       | 962/4096 [00:27<01:53, 27.58it/s, est. speed input: 35413.00 toks/s, output: 34.58 toks/s]
Processed prompts:  24%|       | 994/4096 [00:28<01:52, 27.46it/s, est. speed input: 35105.55 toks/s, output: 34.28 toks/s]
Processed prompts:  25%|       | 1026/4096 [00:30<01:52, 27.37it/s, est. speed input: 34821.57 toks/s, output: 34.01 toks/s]
Processed prompts:  26%|       | 1058/4096 [00:31<01:51, 27.29it/s, est. speed input: 34554.98 toks/s, output: 33.75 toks/s]
Processed prompts:  27%|       | 1090/4096 [00:32<01:50, 27.24it/s, est. speed input: 34309.60 toks/s, output: 33.51 toks/s]
Processed prompts:  27%|       | 1122/4096 [00:33<01:49, 27.22it/s, est. speed input: 34082.92 toks/s, output: 33.28 toks/s]
Processed prompts:  28%|       | 1154/4096 [00:34<01:47, 27.42it/s, est. speed input: 33900.93 toks/s, output: 33.11 toks/s]
Processed prompts:  29%|       | 1186/4096 [00:36<01:46, 27.33it/s, est. speed input: 33701.32 toks/s, output: 32.91 toks/s]
Processed prompts:  30%|       | 1218/4096 [00:37<01:45, 27.31it/s, est. speed input: 33518.59 toks/s, output: 32.73 toks/s]
Processed prompts:  31%|       | 1250/4096 [00:38<01:43, 27.47it/s, est. speed input: 33368.10 toks/s, output: 32.59 toks/s]
Processed prompts:  31%|      | 1282/4096 [00:39<01:41, 27.60it/s, est. speed input: 33229.89 toks/s, output: 32.45 toks/s]
Processed prompts:  32%|      | 1314/4096 [00:40<01:41, 27.48it/s, est. speed input: 33074.39 toks/s, output: 32.30 toks/s]
Processed prompts:  33%|      | 1346/4096 [00:41<01:40, 27.40it/s, est. speed input: 32928.33 toks/s, output: 32.16 toks/s]
Processed prompts:  34%|      | 1378/4096 [00:43<01:39, 27.34it/s, est. speed input: 32789.53 toks/s, output: 32.02 toks/s]
Processed prompts:  34%|      | 1410/4096 [00:44<01:38, 27.28it/s, est. speed input: 32655.86 toks/s, output: 31.89 toks/s]
Processed prompts:  35%|      | 1442/4096 [00:45<01:37, 27.23it/s, est. speed input: 32529.20 toks/s, output: 31.77 toks/s]
Processed prompts:  36%|      | 1474/4096 [00:46<01:36, 27.22it/s, est. speed input: 32410.85 toks/s, output: 31.65 toks/s]
Processed prompts:  37%|      | 1506/4096 [00:47<01:35, 27.23it/s, est. speed input: 32299.62 toks/s, output: 31.54 toks/s]
Processed prompts:  38%|      | 1538/4096 [00:48<01:33, 27.22it/s, est. speed input: 32193.24 toks/s, output: 31.44 toks/s]
Processed prompts:  38%|      | 1570/4096 [00:50<01:32, 27.42it/s, est. speed input: 32109.94 toks/s, output: 31.36 toks/s]
Processed prompts:  39%|      | 1602/4096 [00:51<01:31, 27.37it/s, est. speed input: 32014.00 toks/s, output: 31.26 toks/s]
Processed prompts:  40%|      | 1634/4096 [00:52<01:29, 27.53it/s, est. speed input: 31938.28 toks/s, output: 31.19 toks/s]
Processed prompts:  41%|      | 1666/4096 [00:53<01:28, 27.42it/s, est. speed input: 31848.16 toks/s, output: 31.10 toks/s]
Processed prompts:  41%|     | 1698/4096 [00:54<01:27, 27.36it/s, est. speed input: 31762.95 toks/s, output: 31.02 toks/s]
Processed prompts:  42%|     | 1730/4096 [00:55<01:26, 27.32it/s, est. speed input: 31681.33 toks/s, output: 30.94 toks/s]
Processed prompts:  43%|     | 1762/4096 [00:57<01:25, 27.27it/s, est. speed input: 31601.19 toks/s, output: 30.86 toks/s]
Processed prompts:  44%|     | 1794/4096 [00:58<01:24, 27.24it/s, est. speed input: 31525.05 toks/s, output: 30.79 toks/s]
Processed prompts:  45%|     | 1826/4096 [00:59<01:23, 27.23it/s, est. speed input: 31452.36 toks/s, output: 30.72 toks/s]
Processed prompts:  45%|     | 1858/4096 [01:00<01:21, 27.42it/s, est. speed input: 31397.52 toks/s, output: 30.66 toks/s]
Processed prompts:  46%|     | 1890/4096 [01:01<01:20, 27.38it/s, est. speed input: 31331.65 toks/s, output: 30.60 toks/s]
Processed prompts:  47%|     | 1922/4096 [01:02<01:19, 27.32it/s, est. speed input: 31266.39 toks/s, output: 30.53 toks/s]
Processed prompts:  48%|     | 1954/4096 [01:04<01:17, 27.48it/s, est. speed input: 31217.04 toks/s, output: 30.49 toks/s]
Processed prompts:  48%|     | 1986/4096 [01:05<01:15, 28.00it/s, est. speed input: 31196.60 toks/s, output: 30.47 toks/s]
Processed prompts:  49%|     | 2018/4096 [01:06<01:14, 27.74it/s, est. speed input: 31136.27 toks/s, output: 30.41 toks/s]
Processed prompts:  50%|     | 2050/4096 [01:07<01:13, 27.94it/s, est. speed input: 31102.54 toks/s, output: 30.37 toks/s]
Processed prompts:  51%|     | 2082/4096 [01:08<01:12, 27.93it/s, est. speed input: 31060.09 toks/s, output: 30.33 toks/s]
Processed prompts:  52%|    | 2114/4096 [01:09<01:11, 27.66it/s, est. speed input: 31003.49 toks/s, output: 30.28 toks/s]
Processed prompts:  52%|    | 2146/4096 [01:10<01:10, 27.55it/s, est. speed input: 30952.85 toks/s, output: 30.23 toks/s]
Processed prompts:  53%|    | 2178/4096 [01:12<01:08, 27.89it/s, est. speed input: 30928.86 toks/s, output: 30.20 toks/s]
Processed prompts:  54%|    | 2210/4096 [01:13<01:07, 28.14it/s, est. speed input: 30906.10 toks/s, output: 30.18 toks/s]
Processed prompts:  55%|    | 2242/4096 [01:14<01:06, 27.85it/s, est. speed input: 30857.80 toks/s, output: 30.13 toks/s]
Processed prompts:  56%|    | 2274/4096 [01:15<01:05, 27.88it/s, est. speed input: 30823.87 toks/s, output: 30.10 toks/s]
Processed prompts:  56%|    | 2306/4096 [01:16<01:04, 27.87it/s, est. speed input: 30789.13 toks/s, output: 30.07 toks/s]
Processed prompts:  57%|    | 2338/4096 [01:17<01:03, 27.89it/s, est. speed input: 30756.90 toks/s, output: 30.04 toks/s]
Processed prompts:  58%|    | 2370/4096 [01:18<01:00, 28.41it/s, est. speed input: 30752.49 toks/s, output: 30.03 toks/s]
Processed prompts:  59%|    | 2402/4096 [01:20<00:59, 28.25it/s, est. speed input: 30720.96 toks/s, output: 30.00 toks/s]
Processed prompts:  59%|    | 2434/4096 [01:21<00:59, 28.13it/s, est. speed input: 30689.60 toks/s, output: 29.97 toks/s]
Processed prompts:  60%|    | 2466/4096 [01:22<00:58, 28.05it/s, est. speed input: 30659.43 toks/s, output: 29.94 toks/s]
Processed prompts:  61%|    | 2498/4096 [01:23<00:57, 28.00it/s, est. speed input: 30630.67 toks/s, output: 29.91 toks/s]
Processed prompts:  62%|   | 2530/4096 [01:24<00:56, 27.74it/s, est. speed input: 30591.49 toks/s, output: 29.87 toks/s]
Processed prompts:  63%|   | 2562/4096 [01:25<00:55, 27.75it/s, est. speed input: 30562.49 toks/s, output: 29.85 toks/s]
Processed prompts:  63%|   | 2594/4096 [01:26<00:54, 27.79it/s, est. speed input: 30535.83 toks/s, output: 29.82 toks/s]
Processed prompts:  64%|   | 2626/4096 [01:28<00:53, 27.60it/s, est. speed input: 30499.76 toks/s, output: 29.78 toks/s]
Processed prompts:  65%|   | 2658/4096 [01:29<00:52, 27.48it/s, est. speed input: 30464.81 toks/s, output: 29.75 toks/s]
Processed prompts:  66%|   | 2690/4096 [01:30<00:50, 27.85it/s, est. speed input: 30452.30 toks/s, output: 29.74 toks/s]
Processed prompts:  66%|   | 2722/4096 [01:31<00:49, 27.63it/s, est. speed input: 30417.87 toks/s, output: 29.70 toks/s]
Processed prompts:  67%|   | 2754/4096 [01:32<00:48, 27.69it/s, est. speed input: 30394.16 toks/s, output: 29.68 toks/s]
Processed prompts:  68%|   | 2786/4096 [01:33<00:47, 27.54it/s, est. speed input: 30362.45 toks/s, output: 29.65 toks/s]
Processed prompts:  69%|   | 2818/4096 [01:35<00:45, 27.90it/s, est. speed input: 30351.84 toks/s, output: 29.64 toks/s]
Processed prompts:  70%|   | 2850/4096 [01:36<00:44, 27.87it/s, est. speed input: 30329.49 toks/s, output: 29.62 toks/s]
Processed prompts:  70%|   | 2882/4096 [01:37<00:43, 27.67it/s, est. speed input: 30299.56 toks/s, output: 29.59 toks/s]
Processed prompts:  71%|   | 2914/4096 [01:38<00:42, 27.52it/s, est. speed input: 30270.05 toks/s, output: 29.56 toks/s]
Processed prompts:  72%|  | 2946/4096 [01:39<00:41, 27.59it/s, est. speed input: 30248.83 toks/s, output: 29.54 toks/s]
Processed prompts:  73%|  | 2978/4096 [01:40<00:40, 27.48it/s, est. speed input: 30221.35 toks/s, output: 29.51 toks/s]
Processed prompts:  73%|  | 3010/4096 [01:42<00:38, 27.86it/s, est. speed input: 30212.92 toks/s, output: 29.50 toks/s]
Processed prompts:  74%|  | 3042/4096 [01:43<00:37, 27.87it/s, est. speed input: 30194.70 toks/s, output: 29.49 toks/s]
Processed prompts:  75%|  | 3074/4096 [01:44<00:36, 27.63it/s, est. speed input: 30166.96 toks/s, output: 29.46 toks/s]
Processed prompts:  76%|  | 3106/4096 [01:45<00:35, 28.21it/s, est. speed input: 30169.21 toks/s, output: 29.46 toks/s]
Processed prompts:  77%|  | 3138/4096 [01:46<00:33, 28.38it/s, est. speed input: 30161.79 toks/s, output: 29.45 toks/s]
Processed prompts:  77%|  | 3170/4096 [01:47<00:33, 28.02it/s, est. speed input: 30136.69 toks/s, output: 29.43 toks/s]
Processed prompts:  78%|  | 3202/4096 [01:48<00:31, 28.22it/s, est. speed input: 30129.16 toks/s, output: 29.42 toks/s]
Processed prompts:  79%|  | 3234/4096 [01:49<00:30, 28.11it/s, est. speed input: 30112.32 toks/s, output: 29.41 toks/s]
Processed prompts:  80%|  | 3266/4096 [01:51<00:29, 27.83it/s, est. speed input: 30088.33 toks/s, output: 29.38 toks/s]
Processed prompts:  81%|  | 3298/4096 [01:52<00:28, 27.84it/s, est. speed input: 30072.41 toks/s, output: 29.37 toks/s]
Processed prompts:  81%| | 3330/4096 [01:53<00:27, 28.10it/s, est. speed input: 30065.87 toks/s, output: 29.36 toks/s]
Processed prompts:  82%| | 3362/4096 [01:54<00:26, 27.83it/s, est. speed input: 30043.43 toks/s, output: 29.34 toks/s]
Processed prompts:  83%| | 3394/4096 [01:55<00:25, 27.59it/s, est. speed input: 30019.54 toks/s, output: 29.32 toks/s]
Processed prompts:  84%| | 3426/4096 [01:56<00:24, 27.65it/s, est. speed input: 30004.02 toks/s, output: 29.30 toks/s]
Processed prompts:  84%| | 3458/4096 [01:58<00:23, 27.71it/s, est. speed input: 29989.65 toks/s, output: 29.29 toks/s]
Processed prompts:  85%| | 3490/4096 [01:59<00:21, 28.00it/s, est. speed input: 29984.01 toks/s, output: 29.28 toks/s]
Processed prompts:  86%| | 3522/4096 [02:00<00:20, 27.76it/s, est. speed input: 29963.44 toks/s, output: 29.26 toks/s]
Processed prompts:  87%| | 3554/4096 [02:01<00:19, 27.58it/s, est. speed input: 29942.67 toks/s, output: 29.24 toks/s]
Processed prompts:  88%| | 3586/4096 [02:02<00:18, 27.44it/s, est. speed input: 29921.65 toks/s, output: 29.22 toks/s]
Processed prompts:  88%| | 3618/4096 [02:03<00:17, 27.37it/s, est. speed input: 29902.26 toks/s, output: 29.20 toks/s]
Processed prompts:  89%| | 3650/4096 [02:05<00:16, 27.54it/s, est. speed input: 29890.42 toks/s, output: 29.19 toks/s]
Processed prompts:  90%| | 3682/4096 [02:06<00:14, 27.64it/s, est. speed input: 29878.11 toks/s, output: 29.18 toks/s]
Processed prompts:  91%| | 3714/4096 [02:07<00:13, 27.67it/s, est. speed input: 29864.92 toks/s, output: 29.16 toks/s]
Processed prompts:  91%|| 3746/4096 [02:08<00:12, 27.54it/s, est. speed input: 29846.70 toks/s, output: 29.15 toks/s]
Processed prompts:  92%|| 3778/4096 [02:09<00:11, 27.43it/s, est. speed input: 29828.49 toks/s, output: 29.13 toks/s]
Processed prompts:  93%|| 3810/4096 [02:10<00:10, 27.54it/s, est. speed input: 29816.40 toks/s, output: 29.12 toks/s]
Processed prompts:  94%|| 3842/4096 [02:11<00:09, 27.90it/s, est. speed input: 29813.56 toks/s, output: 29.11 toks/s]
Processed prompts:  95%|| 3874/4096 [02:13<00:08, 27.68it/s, est. speed input: 29795.98 toks/s, output: 29.10 toks/s]
Processed prompts:  95%|| 3906/4096 [02:14<00:06, 27.52it/s, est. speed input: 29778.63 toks/s, output: 29.08 toks/s]
Processed prompts:  96%|| 3938/4096 [02:15<00:05, 27.61it/s, est. speed input: 29767.69 toks/s, output: 29.07 toks/s]
Processed prompts:  97%|| 3970/4096 [02:16<00:04, 27.47it/s, est. speed input: 29750.61 toks/s, output: 29.05 toks/s]
Processed prompts:  98%|| 4002/4096 [02:17<00:03, 27.37it/s, est. speed input: 29734.03 toks/s, output: 29.04 toks/s]
Processed prompts:  98%|| 4034/4096 [02:18<00:02, 28.08it/s, est. speed input: 29740.66 toks/s, output: 29.04 toks/s]
Processed prompts:  99%|| 4066/4096 [02:20<00:01, 27.95it/s, est. speed input: 29728.85 toks/s, output: 29.03 toks/s]
Processed prompts: 100%|| 4096/4096 [02:20<00:00, 27.95it/s, est. speed input: 29948.09 toks/s, output: 29.25 toks/s]
Processed prompts: 100%|| 4096/4096 [02:20<00:00, 29.25it/s, est. speed input: 29948.09 toks/s, output: 29.25 toks/s]
[rank0]:[W126 08:50:35.109329551 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-26 08:50:38
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-1B-FP8_M65536.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:51:04 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 08:51:04 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1096450) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1096450) WARNING 01-26 08:51:31 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 27.82 requests/s, 28520.41 total tokens/s, 27.82 output tokens/s
Total num prompt tokens:  8388608
Total num output tokens:  8192

STDERR:
[2026-01-26 08:51:04] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:51:04] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:51:04] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:51:04] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:51:04] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:51:04] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:51:04] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:51:04] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:51:04] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:51:04] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:51:04] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:51:04] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:51:04] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:51:04] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:51:08] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:51:08] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:51:08] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:51:08] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:51:08] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:51:08] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:51:08] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:51:08] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:51:08] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:51:08] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:51:08] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:51:08] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:51:08] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:51:08] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1096450) [2026-01-26 08:51:09] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1096450) [2026-01-26 08:51:09] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1096450) [2026-01-26 08:51:09] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1096450) [2026-01-26 08:51:09] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1096450) [2026-01-26 08:51:09] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1096450) [2026-01-26 08:51:09] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1096450) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1096450) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.83s/it]
(EngineCore_DP0 pid=1096450) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.83s/it]
(EngineCore_DP0 pid=1096450) 
(EngineCore_DP0 pid=1096450) [2026-01-26 08:51:21] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=1096450) [2026-01-26 08:51:21] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6340608 bytes
(EngineCore_DP0 pid=1096450) [2026-01-26 08:51:21] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=1096450) [2026-01-26 08:51:21] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 4227072 bytes
(EngineCore_DP0 pid=1096450) [2026-01-26 08:51:21] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=1096450) [2026-01-26 08:51:21] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 33816576 bytes
(EngineCore_DP0 pid=1096450) [2026-01-26 08:51:21] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=1096450) [2026-01-26 08:51:21] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16809984 bytes
(EngineCore_DP0 pid=1096450) 2026-01-26 08:51:28,412 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1096450) 2026-01-26 08:51:28,659 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/8192 [00:00<?, ?it/s]
Adding requests:   1%|          | 60/8192 [00:00<00:13, 597.78it/s]
Adding requests:   1%|         | 120/8192 [00:00<00:18, 443.37it/s]
Adding requests:   2%|         | 167/8192 [00:00<00:18, 445.38it/s]
Adding requests:   3%|         | 213/8192 [00:00<00:17, 450.29it/s]
Adding requests:   3%|         | 262/8192 [00:00<00:17, 460.27it/s]
Adding requests:   4%|         | 309/8192 [00:00<00:17, 458.75it/s]
Adding requests:   4%|         | 358/8192 [00:00<00:16, 467.34it/s]
Adding requests:   5%|         | 407/8192 [00:00<00:16, 472.60it/s]
Adding requests:   6%|         | 455/8192 [00:00<00:16, 470.14it/s]
Adding requests:   6%|         | 503/8192 [00:01<00:16, 465.90it/s]
Adding requests:   7%|         | 552/8192 [00:01<00:16, 470.20it/s]
Adding requests:   7%|         | 600/8192 [00:01<00:16, 471.28it/s]
Adding requests:   8%|         | 649/8192 [00:01<00:15, 474.66it/s]
Adding requests:   9%|         | 702/8192 [00:01<00:15, 487.31it/s]
Adding requests:   9%|         | 751/8192 [00:01<00:15, 483.88it/s]
Adding requests:  10%|         | 800/8192 [00:01<00:16, 460.79it/s]
Adding requests:  10%|         | 847/8192 [00:01<00:16, 452.62it/s]
Adding requests:  11%|         | 899/8192 [00:01<00:15, 468.51it/s]
Adding requests:  12%|        | 947/8192 [00:02<00:15, 469.27it/s]
Adding requests:  12%|        | 995/8192 [00:02<00:15, 470.40it/s]
Adding requests:  13%|        | 1043/8192 [00:02<00:15, 465.84it/s]
Adding requests:  13%|        | 1093/8192 [00:02<00:14, 475.46it/s]
Adding requests:  14%|        | 1141/8192 [00:02<00:15, 469.16it/s]
Adding requests:  15%|        | 1192/8192 [00:02<00:14, 476.95it/s]
Adding requests:  15%|        | 1240/8192 [00:02<00:14, 474.50it/s]
Adding requests:  16%|        | 1288/8192 [00:02<00:14, 468.03it/s]
Adding requests:  16%|        | 1336/8192 [00:02<00:14, 470.88it/s]
Adding requests:  17%|        | 1385/8192 [00:02<00:14, 473.20it/s]
Adding requests:  18%|        | 1435/8192 [00:03<00:14, 480.46it/s]
Adding requests:  18%|        | 1484/8192 [00:03<00:14, 479.10it/s]
Adding requests:  19%|        | 1534/8192 [00:03<00:13, 482.72it/s]
Adding requests:  19%|        | 1586/8192 [00:03<00:13, 491.22it/s]
Adding requests:  20%|        | 1636/8192 [00:03<00:13, 493.06it/s]
Adding requests:  21%|        | 1686/8192 [00:03<00:13, 484.43it/s]
Adding requests:  21%|        | 1739/8192 [00:03<00:12, 496.88it/s]
Adding requests:  22%|       | 1789/8192 [00:03<00:13, 492.15it/s]
Adding requests:  22%|       | 1839/8192 [00:03<00:12, 493.98it/s]
Adding requests:  23%|       | 1889/8192 [00:03<00:12, 487.29it/s]
Adding requests:  24%|       | 1940/8192 [00:04<00:12, 490.90it/s]
Adding requests:  24%|       | 1990/8192 [00:04<00:13, 450.78it/s]
Adding requests:  25%|       | 2039/8192 [00:04<00:13, 459.99it/s]
Adding requests:  25%|       | 2088/8192 [00:04<00:13, 464.98it/s]
Adding requests:  26%|       | 2140/8192 [00:04<00:12, 479.04it/s]
Adding requests:  27%|       | 2189/8192 [00:04<00:12, 476.95it/s]
Adding requests:  27%|       | 2237/8192 [00:04<00:12, 467.49it/s]
Adding requests:  28%|       | 2287/8192 [00:04<00:12, 476.32it/s]
Adding requests:  29%|       | 2335/8192 [00:04<00:12, 462.22it/s]
Adding requests:  29%|       | 2382/8192 [00:05<00:12, 458.79it/s]
Adding requests:  30%|       | 2430/8192 [00:05<00:12, 461.31it/s]
Adding requests:  30%|       | 2482/8192 [00:05<00:11, 475.89it/s]
Adding requests:  31%|       | 2530/8192 [00:05<00:11, 472.58it/s]
Adding requests:  31%|      | 2578/8192 [00:05<00:11, 473.65it/s]
Adding requests:  32%|      | 2629/8192 [00:05<00:11, 482.30it/s]
Adding requests:  33%|      | 2678/8192 [00:05<00:11, 478.37it/s]
Adding requests:  33%|      | 2726/8192 [00:05<00:11, 478.21it/s]
Adding requests:  34%|      | 2774/8192 [00:05<00:11, 477.13it/s]
Adding requests:  34%|      | 2824/8192 [00:05<00:11, 482.01it/s]
Adding requests:  35%|      | 2873/8192 [00:06<00:11, 480.93it/s]
Adding requests:  36%|      | 2922/8192 [00:06<00:10, 479.36it/s]
Adding requests:  36%|      | 2975/8192 [00:06<00:10, 491.84it/s]
Adding requests:  37%|      | 3025/8192 [00:06<00:10, 485.52it/s]
Adding requests:  38%|      | 3074/8192 [00:06<00:10, 481.62it/s]
Adding requests:  38%|      | 3124/8192 [00:06<00:10, 486.19it/s]
Adding requests:  39%|      | 3175/8192 [00:06<00:10, 492.03it/s]
Adding requests:  39%|      | 3225/8192 [00:06<00:10, 491.32it/s]
Adding requests:  40%|      | 3275/8192 [00:06<00:10, 486.45it/s]
Adding requests:  41%|      | 3324/8192 [00:07<00:10, 455.59it/s]
Adding requests:  41%|      | 3370/8192 [00:07<00:10, 450.42it/s]
Adding requests:  42%|     | 3417/8192 [00:07<00:10, 455.58it/s]
Adding requests:  42%|     | 3463/8192 [00:07<00:10, 444.20it/s]
Adding requests:  43%|     | 3513/8192 [00:07<00:10, 459.82it/s]
Adding requests:  43%|     | 3560/8192 [00:07<00:10, 454.14it/s]
Adding requests:  44%|     | 3607/8192 [00:07<00:10, 458.38it/s]
Adding requests:  45%|     | 3659/8192 [00:07<00:09, 475.62it/s]
Adding requests:  45%|     | 3709/8192 [00:07<00:09, 482.33it/s]
Adding requests:  46%|     | 3758/8192 [00:07<00:09, 475.00it/s]
Adding requests:  47%|     | 3810/8192 [00:08<00:08, 487.29it/s]
Adding requests:  47%|     | 3862/8192 [00:08<00:08, 494.90it/s]
Adding requests:  48%|     | 3912/8192 [00:08<00:08, 486.92it/s]
Adding requests:  48%|     | 3963/8192 [00:08<00:08, 490.94it/s]
Adding requests:  49%|     | 4014/8192 [00:08<00:08, 496.35it/s]
Adding requests:  50%|     | 4064/8192 [00:08<00:08, 491.58it/s]
Adding requests:  50%|     | 4114/8192 [00:08<00:08, 491.99it/s]
Adding requests:  51%|     | 4165/8192 [00:08<00:08, 496.99it/s]
Adding requests:  51%|    | 4217/8192 [00:08<00:07, 502.66it/s]
Adding requests:  52%|    | 4268/8192 [00:08<00:07, 495.66it/s]
Adding requests:  53%|    | 4320/8192 [00:09<00:07, 502.27it/s]
Adding requests:  53%|    | 4371/8192 [00:09<00:07, 502.49it/s]
Adding requests:  54%|    | 4422/8192 [00:09<00:07, 500.82it/s]
Adding requests:  55%|    | 4473/8192 [00:09<00:07, 495.59it/s]
Adding requests:  55%|    | 4524/8192 [00:09<00:07, 497.68it/s]
Adding requests:  56%|    | 4574/8192 [00:09<00:07, 485.11it/s]
Adding requests:  56%|    | 4623/8192 [00:09<00:07, 475.48it/s]
Adding requests:  57%|    | 4674/8192 [00:09<00:07, 483.84it/s]
Adding requests:  58%|    | 4723/8192 [00:09<00:07, 444.71it/s]
Adding requests:  58%|    | 4773/8192 [00:10<00:07, 458.89it/s]
Adding requests:  59%|    | 4820/8192 [00:10<00:07, 459.49it/s]
Adding requests:  59%|    | 4871/8192 [00:10<00:07, 471.88it/s]
Adding requests:  60%|    | 4922/8192 [00:10<00:06, 480.96it/s]
Adding requests:  61%|    | 4971/8192 [00:10<00:06, 482.73it/s]
Adding requests:  61%|   | 5022/8192 [00:10<00:06, 490.03it/s]
Adding requests:  62%|   | 5074/8192 [00:10<00:06, 497.30it/s]
Adding requests:  63%|   | 5125/8192 [00:10<00:06, 500.06it/s]
Adding requests:  63%|   | 5176/8192 [00:10<00:06, 492.99it/s]
Adding requests:  64%|   | 5229/8192 [00:10<00:05, 500.88it/s]
Adding requests:  64%|   | 5280/8192 [00:11<00:05, 498.33it/s]
Adding requests:  65%|   | 5330/8192 [00:11<00:05, 492.21it/s]
Adding requests:  66%|   | 5380/8192 [00:11<00:05, 491.13it/s]
Adding requests:  66%|   | 5433/8192 [00:11<00:05, 501.54it/s]
Adding requests:  67%|   | 5484/8192 [00:11<00:05, 494.55it/s]
Adding requests:  68%|   | 5534/8192 [00:11<00:05, 486.27it/s]
Adding requests:  68%|   | 5586/8192 [00:11<00:05, 494.77it/s]
Adding requests:  69%|   | 5636/8192 [00:11<00:05, 491.37it/s]
Adding requests:  69%|   | 5686/8192 [00:11<00:05, 492.18it/s]
Adding requests:  70%|   | 5736/8192 [00:11<00:04, 493.99it/s]
Adding requests:  71%|   | 5786/8192 [00:12<00:04, 493.09it/s]
Adding requests:  71%|   | 5836/8192 [00:12<00:04, 474.90it/s]
Adding requests:  72%|  | 5884/8192 [00:12<00:04, 471.12it/s]
Adding requests:  72%|  | 5935/8192 [00:12<00:04, 480.95it/s]
Adding requests:  73%|  | 5984/8192 [00:12<00:04, 481.55it/s]
Adding requests:  74%|  | 6035/8192 [00:12<00:04, 487.63it/s]
Adding requests:  74%|  | 6084/8192 [00:12<00:04, 465.64it/s]
Adding requests:  75%|  | 6135/8192 [00:12<00:04, 477.96it/s]
Adding requests:  75%|  | 6184/8192 [00:12<00:04, 477.96it/s]
Adding requests:  76%|  | 6236/8192 [00:13<00:04, 486.58it/s]
Adding requests:  77%|  | 6290/8192 [00:13<00:03, 499.03it/s]
Adding requests:  77%|  | 6341/8192 [00:13<00:03, 500.28it/s]
Adding requests:  78%|  | 6392/8192 [00:13<00:03, 498.87it/s]
Adding requests:  79%|  | 6445/8192 [00:13<00:03, 504.61it/s]
Adding requests:  79%|  | 6498/8192 [00:13<00:03, 509.63it/s]
Adding requests:  80%|  | 6549/8192 [00:13<00:03, 500.93it/s]
Adding requests:  81%|  | 6600/8192 [00:13<00:03, 495.55it/s]
Adding requests:  81%|  | 6653/8192 [00:13<00:03, 503.55it/s]
Adding requests:  82%| | 6705/8192 [00:13<00:02, 508.11it/s]
Adding requests:  82%| | 6756/8192 [00:14<00:02, 495.62it/s]
Adding requests:  83%| | 6807/8192 [00:14<00:02, 498.28it/s]
Adding requests:  84%| | 6857/8192 [00:14<00:02, 494.13it/s]
Adding requests:  84%| | 6907/8192 [00:14<00:02, 491.06it/s]
Adding requests:  85%| | 6958/8192 [00:14<00:02, 495.83it/s]
Adding requests:  86%| | 7009/8192 [00:14<00:02, 498.02it/s]
Adding requests:  86%| | 7059/8192 [00:14<00:02, 494.07it/s]
Adding requests:  87%| | 7109/8192 [00:14<00:02, 493.12it/s]
Adding requests:  87%| | 7163/8192 [00:14<00:02, 506.55it/s]
Adding requests:  88%| | 7214/8192 [00:14<00:01, 504.13it/s]
Adding requests:  89%| | 7265/8192 [00:15<00:01, 503.67it/s]
Adding requests:  89%| | 7316/8192 [00:15<00:01, 493.04it/s]
Adding requests:  90%| | 7370/8192 [00:15<00:01, 504.46it/s]
Adding requests:  91%| | 7421/8192 [00:15<00:01, 480.94it/s]
Adding requests:  91%| | 7470/8192 [00:15<00:01, 482.18it/s]
Adding requests:  92%|| 7526/8192 [00:15<00:01, 503.00it/s]
Adding requests:  92%|| 7577/8192 [00:15<00:01, 482.47it/s]
Adding requests:  93%|| 7626/8192 [00:15<00:01, 479.30it/s]
Adding requests:  94%|| 7675/8192 [00:15<00:01, 482.13it/s]
Adding requests:  94%|| 7729/8192 [00:16<00:00, 495.72it/s]
Adding requests:  95%|| 7779/8192 [00:16<00:00, 482.92it/s]
Adding requests:  96%|| 7828/8192 [00:16<00:00, 483.56it/s]
Adding requests:  96%|| 7877/8192 [00:16<00:00, 481.72it/s]
Adding requests:  97%|| 7927/8192 [00:16<00:00, 486.28it/s]
Adding requests:  97%|| 7976/8192 [00:16<00:00, 483.97it/s]
Adding requests:  98%|| 8025/8192 [00:16<00:00, 475.43it/s]
Adding requests:  99%|| 8075/8192 [00:16<00:00, 481.08it/s]
Adding requests:  99%|| 8124/8192 [00:16<00:00, 475.86it/s]
Adding requests: 100%|| 8172/8192 [00:16<00:00, 474.27it/s]
Adding requests: 100%|| 8192/8192 [00:16<00:00, 482.06it/s]

Processed prompts:   0%|          | 0/8192 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|         | 450/8192 [00:01<00:32, 241.68it/s, est. speed input: 247486.32 toks/s, output: 241.68 toks/s]
Processed prompts:   6%|         | 514/8192 [00:04<01:13, 104.32it/s, est. speed input: 125574.99 toks/s, output: 122.63 toks/s]
Processed prompts:   7%|         | 578/8192 [00:06<01:52, 67.65it/s, est. speed input: 90836.02 toks/s, output: 88.71 toks/s]   
Processed prompts:   8%|         | 642/8192 [00:08<02:26, 51.40it/s, est. speed input: 74377.69 toks/s, output: 72.63 toks/s]
Processed prompts:   9%|         | 706/8192 [00:11<02:55, 42.61it/s, est. speed input: 64734.62 toks/s, output: 63.22 toks/s]
Processed prompts:   9%|         | 770/8192 [00:13<03:18, 37.41it/s, est. speed input: 58421.89 toks/s, output: 57.05 toks/s]
Processed prompts:  10%|         | 834/8192 [00:15<03:35, 34.14it/s, est. speed input: 53966.03 toks/s, output: 52.70 toks/s]
Processed prompts:  11%|         | 898/8192 [00:18<03:47, 32.13it/s, est. speed input: 50729.42 toks/s, output: 49.54 toks/s]
Processed prompts:  12%|        | 962/8192 [00:20<03:54, 30.77it/s, est. speed input: 48217.50 toks/s, output: 47.09 toks/s]
Processed prompts:  13%|        | 1026/8192 [00:22<04:00, 29.75it/s, est. speed input: 46166.46 toks/s, output: 45.08 toks/s]
Processed prompts:  13%|        | 1090/8192 [00:25<04:04, 29.04it/s, est. speed input: 44485.37 toks/s, output: 43.44 toks/s]
Processed prompts:  14%|        | 1154/8192 [00:27<04:05, 28.65it/s, est. speed input: 43132.63 toks/s, output: 42.12 toks/s]
Processed prompts:  15%|        | 1218/8192 [00:29<04:05, 28.39it/s, est. speed input: 41994.40 toks/s, output: 41.01 toks/s]
Processed prompts:  16%|        | 1282/8192 [00:32<04:04, 28.21it/s, est. speed input: 41019.44 toks/s, output: 40.06 toks/s]
Processed prompts:  16%|        | 1346/8192 [00:34<04:04, 27.99it/s, est. speed input: 40146.94 toks/s, output: 39.21 toks/s]
Processed prompts:  17%|        | 1410/8192 [00:36<04:03, 27.83it/s, est. speed input: 39383.71 toks/s, output: 38.46 toks/s]
Processed prompts:  18%|        | 1474/8192 [00:39<04:02, 27.68it/s, est. speed input: 38698.74 toks/s, output: 37.79 toks/s]
Processed prompts:  19%|        | 1538/8192 [00:41<04:00, 27.71it/s, est. speed input: 38127.08 toks/s, output: 37.23 toks/s]
Processed prompts:  20%|        | 1602/8192 [00:43<03:57, 27.72it/s, est. speed input: 37611.99 toks/s, output: 36.73 toks/s]
Processed prompts:  20%|        | 1666/8192 [00:45<03:55, 27.65it/s, est. speed input: 37133.74 toks/s, output: 36.26 toks/s]
Processed prompts:  21%|        | 1730/8192 [00:48<03:54, 27.61it/s, est. speed input: 36701.18 toks/s, output: 35.84 toks/s]
Processed prompts:  22%|       | 1794/8192 [00:50<03:52, 27.57it/s, est. speed input: 36307.89 toks/s, output: 35.46 toks/s]
Processed prompts:  23%|       | 1858/8192 [00:52<03:49, 27.62it/s, est. speed input: 35963.22 toks/s, output: 35.12 toks/s]
Processed prompts:  23%|       | 1922/8192 [00:55<03:46, 27.66it/s, est. speed input: 35647.90 toks/s, output: 34.81 toks/s]
Processed prompts:  24%|       | 1986/8192 [00:57<03:42, 27.88it/s, est. speed input: 35390.01 toks/s, output: 34.56 toks/s]
Processed prompts:  25%|       | 2050/8192 [00:59<03:38, 28.10it/s, est. speed input: 35162.44 toks/s, output: 34.34 toks/s]
Processed prompts:  26%|       | 2114/8192 [01:02<03:37, 27.90it/s, est. speed input: 34897.36 toks/s, output: 34.08 toks/s]
Processed prompts:  27%|       | 2178/8192 [01:04<03:33, 28.18it/s, est. speed input: 34713.00 toks/s, output: 33.90 toks/s]
Processed prompts:  27%|       | 2242/8192 [01:06<03:32, 28.04it/s, est. speed input: 34493.01 toks/s, output: 33.68 toks/s]
Processed prompts:  28%|       | 2306/8192 [01:08<03:30, 28.01it/s, est. speed input: 34296.78 toks/s, output: 33.49 toks/s]
Processed prompts:  29%|       | 2370/8192 [01:11<03:25, 28.30it/s, est. speed input: 34154.53 toks/s, output: 33.35 toks/s]
Processed prompts:  30%|       | 2434/8192 [01:13<03:23, 28.23it/s, est. speed input: 33986.49 toks/s, output: 33.19 toks/s]
Processed prompts:  30%|       | 2498/8192 [01:15<03:22, 28.09it/s, est. speed input: 33817.42 toks/s, output: 33.02 toks/s]
Processed prompts:  31%|      | 2562/8192 [01:17<03:20, 28.09it/s, est. speed input: 33669.43 toks/s, output: 32.88 toks/s]
Processed prompts:  32%|      | 2626/8192 [01:20<03:19, 27.89it/s, est. speed input: 33507.84 toks/s, output: 32.72 toks/s]
Processed prompts:  33%|      | 2690/8192 [01:22<03:16, 27.94it/s, est. speed input: 33375.20 toks/s, output: 32.59 toks/s]
Processed prompts:  34%|      | 2754/8192 [01:24<03:14, 27.90it/s, est. speed input: 33242.32 toks/s, output: 32.46 toks/s]
Processed prompts:  34%|      | 2818/8192 [01:27<03:11, 28.07it/s, est. speed input: 33137.30 toks/s, output: 32.36 toks/s]
Processed prompts:  35%|      | 2882/8192 [01:29<03:10, 27.90it/s, est. speed input: 33007.64 toks/s, output: 32.23 toks/s]
Processed prompts:  36%|      | 2946/8192 [01:31<03:08, 27.86it/s, est. speed input: 32892.71 toks/s, output: 32.12 toks/s]
Processed prompts:  37%|      | 3010/8192 [01:33<03:04, 28.05it/s, est. speed input: 32804.54 toks/s, output: 32.04 toks/s]
Processed prompts:  38%|      | 3074/8192 [01:36<03:01, 28.20it/s, est. speed input: 32721.09 toks/s, output: 31.95 toks/s]
Processed prompts:  38%|      | 3138/8192 [01:38<02:59, 28.17it/s, est. speed input: 32630.30 toks/s, output: 31.87 toks/s]
Processed prompts:  39%|      | 3202/8192 [01:40<02:56, 28.29it/s, est. speed input: 32555.12 toks/s, output: 31.79 toks/s]
Processed prompts:  40%|      | 3266/8192 [01:43<02:55, 28.10it/s, est. speed input: 32460.33 toks/s, output: 31.70 toks/s]
Processed prompts:  41%|      | 3330/8192 [01:45<02:53, 28.09it/s, est. speed input: 32380.12 toks/s, output: 31.62 toks/s]
Processed prompts:  41%|     | 3394/8192 [01:47<02:51, 28.00it/s, est. speed input: 32295.69 toks/s, output: 31.54 toks/s]
Processed prompts:  42%|     | 3458/8192 [01:49<02:48, 28.15it/s, est. speed input: 32232.10 toks/s, output: 31.48 toks/s]
Processed prompts:  43%|     | 3522/8192 [01:52<02:47, 27.92it/s, est. speed input: 32145.12 toks/s, output: 31.39 toks/s]
Processed prompts:  44%|     | 3586/8192 [01:54<02:45, 27.78it/s, est. speed input: 32063.17 toks/s, output: 31.31 toks/s]
Processed prompts:  45%|     | 3650/8192 [01:56<02:43, 27.86it/s, est. speed input: 31997.80 toks/s, output: 31.25 toks/s]
Processed prompts:  45%|     | 3714/8192 [01:59<02:40, 27.82it/s, est. speed input: 31928.12 toks/s, output: 31.18 toks/s]
Processed prompts:  46%|     | 3778/8192 [02:01<02:38, 27.81it/s, est. speed input: 31862.03 toks/s, output: 31.12 toks/s]
Processed prompts:  47%|     | 3842/8192 [02:03<02:35, 27.89it/s, est. speed input: 31804.56 toks/s, output: 31.06 toks/s]
Processed prompts:  48%|     | 3906/8192 [02:06<02:33, 27.84it/s, est. speed input: 31741.98 toks/s, output: 31.00 toks/s]
Processed prompts:  48%|     | 3970/8192 [02:08<02:32, 27.72it/s, est. speed input: 31676.08 toks/s, output: 30.93 toks/s]
Processed prompts:  49%|     | 4034/8192 [02:10<02:28, 27.96it/s, est. speed input: 31633.58 toks/s, output: 30.89 toks/s]
Processed prompts:  50%|     | 4098/8192 [02:12<02:27, 27.76it/s, est. speed input: 31568.82 toks/s, output: 30.83 toks/s]
Processed prompts:  51%|     | 4162/8192 [02:15<02:24, 27.98it/s, est. speed input: 31529.58 toks/s, output: 30.79 toks/s]
Processed prompts:  52%|    | 4226/8192 [02:17<02:21, 28.01it/s, est. speed input: 31483.73 toks/s, output: 30.75 toks/s]
Processed prompts:  52%|    | 4290/8192 [02:19<02:19, 27.93it/s, est. speed input: 31432.68 toks/s, output: 30.70 toks/s]
Processed prompts:  53%|    | 4354/8192 [02:22<02:18, 27.78it/s, est. speed input: 31377.75 toks/s, output: 30.64 toks/s]
Processed prompts:  54%|    | 4418/8192 [02:24<02:15, 27.87it/s, est. speed input: 31336.28 toks/s, output: 30.60 toks/s]
Processed prompts:  55%|    | 4482/8192 [02:26<02:13, 27.74it/s, est. speed input: 31285.29 toks/s, output: 30.55 toks/s]
Processed prompts:  55%|    | 4546/8192 [02:28<02:10, 27.95it/s, est. speed input: 31252.86 toks/s, output: 30.52 toks/s]
Processed prompts:  56%|    | 4610/8192 [02:31<02:08, 27.89it/s, est. speed input: 31209.42 toks/s, output: 30.48 toks/s]
Processed prompts:  57%|    | 4674/8192 [02:33<02:06, 27.75it/s, est. speed input: 31161.74 toks/s, output: 30.43 toks/s]
Processed prompts:  58%|    | 4738/8192 [02:35<02:04, 27.85it/s, est. speed input: 31126.69 toks/s, output: 30.40 toks/s]
Processed prompts:  59%|    | 4802/8192 [02:38<02:01, 27.80it/s, est. speed input: 31086.44 toks/s, output: 30.36 toks/s]
Processed prompts:  59%|    | 4866/8192 [02:40<01:59, 27.79it/s, est. speed input: 31048.42 toks/s, output: 30.32 toks/s]
Processed prompts:  60%|    | 4930/8192 [02:42<01:57, 27.78it/s, est. speed input: 31011.00 toks/s, output: 30.28 toks/s]
Processed prompts:  61%|    | 4994/8192 [02:45<01:54, 27.86it/s, est. speed input: 30979.14 toks/s, output: 30.25 toks/s]
Processed prompts:  62%|   | 5058/8192 [02:47<01:51, 28.06it/s, est. speed input: 30955.72 toks/s, output: 30.23 toks/s]
Processed prompts:  63%|   | 5122/8192 [02:49<01:50, 27.86it/s, est. speed input: 30915.74 toks/s, output: 30.19 toks/s]
Processed prompts:  63%|   | 5186/8192 [02:51<01:47, 28.06it/s, est. speed input: 30893.61 toks/s, output: 30.17 toks/s]
Processed prompts:  64%|   | 5250/8192 [02:54<01:44, 28.21it/s, est. speed input: 30872.61 toks/s, output: 30.15 toks/s]
Processed prompts:  65%|   | 5314/8192 [02:56<01:41, 28.29it/s, est. speed input: 30850.92 toks/s, output: 30.13 toks/s]
Processed prompts:  66%|   | 5378/8192 [02:58<01:39, 28.16it/s, est. speed input: 30820.97 toks/s, output: 30.10 toks/s]
Processed prompts:  66%|   | 5442/8192 [03:00<01:37, 28.10it/s, est. speed input: 30793.27 toks/s, output: 30.07 toks/s]
Processed prompts:  67%|   | 5506/8192 [03:03<01:35, 28.00it/s, est. speed input: 30763.54 toks/s, output: 30.04 toks/s]
Processed prompts:  68%|   | 5570/8192 [03:05<01:34, 27.83it/s, est. speed input: 30729.95 toks/s, output: 30.01 toks/s]
Processed prompts:  69%|   | 5634/8192 [03:07<01:31, 27.88it/s, est. speed input: 30705.17 toks/s, output: 29.99 toks/s]
Processed prompts:  70%|   | 5698/8192 [03:10<01:29, 27.93it/s, est. speed input: 30681.37 toks/s, output: 29.96 toks/s]
Processed prompts:  70%|   | 5762/8192 [03:12<01:27, 27.87it/s, est. speed input: 30653.96 toks/s, output: 29.94 toks/s]
Processed prompts:  71%|   | 5826/8192 [03:14<01:25, 27.83it/s, est. speed input: 30627.12 toks/s, output: 29.91 toks/s]
Processed prompts:  72%|  | 5890/8192 [03:17<01:22, 27.88it/s, est. speed input: 30604.55 toks/s, output: 29.89 toks/s]
Processed prompts:  73%|  | 5954/8192 [03:19<01:20, 27.72it/s, est. speed input: 30573.96 toks/s, output: 29.86 toks/s]
Processed prompts:  73%|  | 6018/8192 [03:21<01:18, 27.73it/s, est. speed input: 30549.26 toks/s, output: 29.83 toks/s]
Processed prompts:  74%|  | 6082/8192 [03:24<01:16, 27.64it/s, est. speed input: 30521.27 toks/s, output: 29.81 toks/s]
Processed prompts:  75%|  | 6146/8192 [03:26<01:13, 27.89it/s, est. speed input: 30506.65 toks/s, output: 29.79 toks/s]
Processed prompts:  76%|  | 6210/8192 [03:28<01:11, 27.84it/s, est. speed input: 30483.21 toks/s, output: 29.77 toks/s]
Processed prompts:  77%|  | 6274/8192 [03:30<01:09, 27.72it/s, est. speed input: 30456.85 toks/s, output: 29.74 toks/s]
Processed prompts:  77%|  | 6338/8192 [03:33<01:06, 27.83it/s, est. speed input: 30438.61 toks/s, output: 29.73 toks/s]
Processed prompts:  78%|  | 6402/8192 [03:35<01:04, 27.81it/s, est. speed input: 30417.11 toks/s, output: 29.70 toks/s]
Processed prompts:  79%|  | 6466/8192 [03:37<01:02, 27.69it/s, est. speed input: 30392.23 toks/s, output: 29.68 toks/s]
Processed prompts:  80%|  | 6530/8192 [03:40<00:59, 27.81it/s, est. speed input: 30375.28 toks/s, output: 29.66 toks/s]
Processed prompts:  80%|  | 6594/8192 [03:42<00:57, 27.78it/s, est. speed input: 30354.49 toks/s, output: 29.64 toks/s]
Processed prompts:  81%| | 6658/8192 [03:44<00:54, 27.90it/s, est. speed input: 30339.38 toks/s, output: 29.63 toks/s]
Processed prompts:  82%| | 6722/8192 [03:47<00:53, 27.71it/s, est. speed input: 30314.47 toks/s, output: 29.60 toks/s]
Processed prompts:  83%| | 6786/8192 [03:49<00:50, 27.72it/s, est. speed input: 30295.30 toks/s, output: 29.59 toks/s]
Processed prompts:  84%| | 6850/8192 [03:51<00:48, 27.73it/s, est. speed input: 30276.56 toks/s, output: 29.57 toks/s]
Processed prompts:  84%| | 6914/8192 [03:53<00:46, 27.75it/s, est. speed input: 30258.87 toks/s, output: 29.55 toks/s]
Processed prompts:  85%| | 6978/8192 [03:56<00:43, 27.84it/s, est. speed input: 30243.93 toks/s, output: 29.54 toks/s]
Processed prompts:  86%| | 7042/8192 [03:58<00:41, 27.81it/s, est. speed input: 30226.14 toks/s, output: 29.52 toks/s]
Processed prompts:  87%| | 7106/8192 [04:00<00:38, 28.17it/s, est. speed input: 30221.68 toks/s, output: 29.51 toks/s]
Processed prompts:  88%| | 7170/8192 [04:03<00:36, 28.03it/s, est. speed input: 30204.05 toks/s, output: 29.50 toks/s]
Processed prompts:  88%| | 7234/8192 [04:05<00:34, 28.04it/s, est. speed input: 30190.64 toks/s, output: 29.48 toks/s]
Processed prompts:  89%| | 7298/8192 [04:07<00:31, 27.95it/s, est. speed input: 30173.96 toks/s, output: 29.47 toks/s]
Processed prompts:  90%| | 7362/8192 [04:09<00:29, 27.99it/s, est. speed input: 30161.15 toks/s, output: 29.45 toks/s]
Processed prompts:  91%| | 7426/8192 [04:12<00:27, 27.89it/s, est. speed input: 30144.38 toks/s, output: 29.44 toks/s]
Processed prompts:  91%|| 7490/8192 [04:14<00:24, 28.12it/s, est. speed input: 30137.30 toks/s, output: 29.43 toks/s]
Processed prompts:  92%|| 7554/8192 [04:16<00:22, 28.25it/s, est. speed input: 30129.67 toks/s, output: 29.42 toks/s]
Processed prompts:  93%|| 7618/8192 [04:18<00:20, 28.46it/s, est. speed input: 30125.67 toks/s, output: 29.42 toks/s]
Processed prompts:  94%|| 7682/8192 [04:21<00:18, 28.23it/s, est. speed input: 30110.20 toks/s, output: 29.40 toks/s]
Processed prompts:  95%|| 7746/8192 [04:23<00:15, 28.08it/s, est. speed input: 30095.06 toks/s, output: 29.39 toks/s]
Processed prompts:  95%|| 7810/8192 [04:25<00:13, 27.88it/s, est. speed input: 30077.39 toks/s, output: 29.37 toks/s]
Processed prompts:  96%|| 7874/8192 [04:28<00:11, 27.76it/s, est. speed input: 30060.51 toks/s, output: 29.36 toks/s]
Processed prompts:  97%|| 7938/8192 [04:30<00:09, 27.75it/s, est. speed input: 30046.24 toks/s, output: 29.34 toks/s]
Processed prompts:  98%|| 8002/8192 [04:32<00:06, 27.75it/s, est. speed input: 30032.66 toks/s, output: 29.33 toks/s]
Processed prompts:  98%|| 8066/8192 [04:35<00:04, 27.86it/s, est. speed input: 30022.36 toks/s, output: 29.32 toks/s]
Processed prompts:  99%|| 8130/8192 [04:37<00:02, 27.85it/s, est. speed input: 30009.58 toks/s, output: 29.31 toks/s]
Processed prompts: 100%|| 8192/8192 [04:37<00:00, 27.85it/s, est. speed input: 30238.38 toks/s, output: 29.53 toks/s]
Processed prompts: 100%|| 8192/8192 [04:37<00:00, 29.53it/s, est. speed input: 30238.38 toks/s, output: 29.53 toks/s]
[rank0]:[W126 08:56:26.497783449 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-26 13:22:08
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-3B-FP8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 13:22:12 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 13:22:12 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1334553) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1334553) WARNING 01-26 13:22:49 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 22.34 requests/s, 11462.69 total tokens/s, 22.34 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-26 13:22:12] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 13:22:12] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 13:22:12] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 13:22:12] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:22:12] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:22:12] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:22:12] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:22:12] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:22:12] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 13:22:12] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:22:12] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:22:12] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:22:12] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:22:12] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 13:22:15] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 13:22:15] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 13:22:15] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 13:22:15] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:22:15] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:22:15] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:22:15] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:22:15] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:22:15] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 13:22:15] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:22:15] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:22:15] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:22:15] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:22:15] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1334553) [2026-01-26 13:22:16] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1334553) [2026-01-26 13:22:16] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1334553) [2026-01-26 13:22:16] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1334553) [2026-01-26 13:22:16] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1334553) [2026-01-26 13:22:16] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1334553) [2026-01-26 13:22:16] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1334553) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1334553) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:25<00:00, 25.51s/it]
(EngineCore_DP0 pid=1334553) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:25<00:00, 25.51s/it]
(EngineCore_DP0 pid=1334553) 
(EngineCore_DP0 pid=1334553) [2026-01-26 13:22:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4928] -> 1D uint8
(EngineCore_DP0 pid=1334553) [2026-01-26 13:22:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15810560 bytes
(EngineCore_DP0 pid=1334553) [2026-01-26 13:22:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4928] -> 1D uint8
(EngineCore_DP0 pid=1334553) [2026-01-26 13:22:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9486336 bytes
(EngineCore_DP0 pid=1334553) [2026-01-26 13:22:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4928] -> 1D uint8
(EngineCore_DP0 pid=1334553) [2026-01-26 13:22:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 50593792 bytes
(EngineCore_DP0 pid=1334553) [2026-01-26 13:22:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 13120] -> 1D uint8
(EngineCore_DP0 pid=1334553) [2026-01-26 13:22:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 25214976 bytes
(EngineCore_DP0 pid=1334553) 2026-01-26 13:22:48,790 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1334553) 2026-01-26 13:22:48,803 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  55%|    | 71/128 [00:00<00:00, 705.94it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 827.24it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 3/128 [00:00<00:04, 26.08it/s, est. speed input: 13356.71 toks/s, output: 26.09 toks/s]
Processed prompts:   5%|         | 6/128 [00:00<00:05, 24.33it/s, est. speed input: 12584.23 toks/s, output: 24.58 toks/s]
Processed prompts:   7%|         | 9/128 [00:00<00:05, 23.24it/s, est. speed input: 12122.61 toks/s, output: 23.68 toks/s]
Processed prompts:   9%|         | 12/128 [00:00<00:05, 22.93it/s, est. speed input: 11962.90 toks/s, output: 23.36 toks/s]
Processed prompts:  12%|        | 15/128 [00:00<00:04, 23.14it/s, est. speed input: 11979.18 toks/s, output: 23.40 toks/s]
Processed prompts:  14%|        | 18/128 [00:00<00:04, 22.95it/s, est. speed input: 11907.98 toks/s, output: 23.26 toks/s]
Processed prompts:  16%|        | 21/128 [00:00<00:04, 22.88it/s, est. speed input: 11868.59 toks/s, output: 23.18 toks/s]
Processed prompts:  19%|        | 24/128 [00:01<00:04, 23.07it/s, est. speed input: 11887.93 toks/s, output: 23.22 toks/s]
Processed prompts:  21%|        | 27/128 [00:01<00:04, 23.16it/s, est. speed input: 11896.35 toks/s, output: 23.23 toks/s]
Processed prompts:  23%|       | 30/128 [00:01<00:04, 23.29it/s, est. speed input: 11913.53 toks/s, output: 23.27 toks/s]
Processed prompts:  26%|       | 33/128 [00:01<00:04, 22.77it/s, est. speed input: 11834.37 toks/s, output: 23.11 toks/s]
Processed prompts:  28%|       | 36/128 [00:01<00:04, 22.96it/s, est. speed input: 11846.68 toks/s, output: 23.14 toks/s]
Processed prompts:  30%|       | 39/128 [00:01<00:03, 23.04it/s, est. speed input: 11850.42 toks/s, output: 23.15 toks/s]
Processed prompts:  33%|      | 42/128 [00:01<00:03, 22.96it/s, est. speed input: 11836.66 toks/s, output: 23.12 toks/s]
Processed prompts:  35%|      | 45/128 [00:01<00:03, 22.95it/s, est. speed input: 11830.33 toks/s, output: 23.11 toks/s]
Processed prompts:  38%|      | 48/128 [00:02<00:03, 23.05it/s, est. speed input: 11835.33 toks/s, output: 23.12 toks/s]
Processed prompts:  40%|      | 51/128 [00:02<00:03, 22.97it/s, est. speed input: 11825.55 toks/s, output: 23.10 toks/s]
Processed prompts:  42%|     | 54/128 [00:02<00:03, 22.87it/s, est. speed input: 11812.18 toks/s, output: 23.07 toks/s]
Processed prompts:  45%|     | 57/128 [00:02<00:03, 22.56it/s, est. speed input: 11778.29 toks/s, output: 23.00 toks/s]
Processed prompts:  47%|     | 60/128 [00:02<00:03, 22.62it/s, est. speed input: 11771.74 toks/s, output: 22.99 toks/s]
Processed prompts:  49%|     | 63/128 [00:02<00:02, 22.88it/s, est. speed input: 11784.16 toks/s, output: 23.02 toks/s]
Processed prompts:  52%|    | 66/128 [00:02<00:02, 22.99it/s, est. speed input: 11789.30 toks/s, output: 23.03 toks/s]
Processed prompts:  54%|    | 69/128 [00:02<00:02, 22.92it/s, est. speed input: 11783.54 toks/s, output: 23.01 toks/s]
Processed prompts:  56%|    | 72/128 [00:03<00:02, 22.94it/s, est. speed input: 11782.62 toks/s, output: 23.01 toks/s]
Processed prompts:  59%|    | 75/128 [00:03<00:02, 23.03it/s, est. speed input: 11787.66 toks/s, output: 23.02 toks/s]
Processed prompts:  61%|    | 78/128 [00:03<00:02, 23.10it/s, est. speed input: 11792.18 toks/s, output: 23.03 toks/s]
Processed prompts:  63%|   | 81/128 [00:03<00:02, 22.79it/s, est. speed input: 11773.61 toks/s, output: 23.00 toks/s]
Processed prompts:  66%|   | 84/128 [00:03<00:01, 22.88it/s, est. speed input: 11775.49 toks/s, output: 23.00 toks/s]
Processed prompts:  68%|   | 87/128 [00:03<00:01, 23.03it/s, est. speed input: 11782.04 toks/s, output: 23.01 toks/s]
Processed prompts:  70%|   | 90/128 [00:03<00:01, 22.76it/s, est. speed input: 11767.31 toks/s, output: 22.98 toks/s]
Processed prompts:  73%|  | 93/128 [00:04<00:01, 22.85it/s, est. speed input: 11768.60 toks/s, output: 22.99 toks/s]
Processed prompts:  75%|  | 96/128 [00:04<00:01, 22.97it/s, est. speed input: 11772.67 toks/s, output: 22.99 toks/s]
Processed prompts:  77%|  | 99/128 [00:04<00:01, 22.97it/s, est. speed input: 11772.40 toks/s, output: 22.99 toks/s]
Processed prompts:  80%|  | 102/128 [00:04<00:01, 22.84it/s, est. speed input: 11765.41 toks/s, output: 22.98 toks/s]
Processed prompts:  82%| | 105/128 [00:04<00:01, 22.63it/s, est. speed input: 11752.74 toks/s, output: 22.95 toks/s]
Processed prompts:  84%| | 108/128 [00:04<00:00, 22.57it/s, est. speed input: 11745.25 toks/s, output: 22.94 toks/s]
Processed prompts:  87%| | 111/128 [00:04<00:00, 22.78it/s, est. speed input: 11750.08 toks/s, output: 22.95 toks/s]
Processed prompts:  89%| | 114/128 [00:04<00:00, 22.90it/s, est. speed input: 11753.28 toks/s, output: 22.96 toks/s]
Processed prompts:  91%|| 117/128 [00:05<00:00, 22.96it/s, est. speed input: 11755.00 toks/s, output: 22.96 toks/s]
Processed prompts:  94%|| 120/128 [00:05<00:00, 22.92it/s, est. speed input: 11753.24 toks/s, output: 22.96 toks/s]
Processed prompts:  96%|| 123/128 [00:05<00:00, 23.09it/s, est. speed input: 11759.91 toks/s, output: 22.97 toks/s]
Processed prompts:  98%|| 126/128 [00:05<00:00, 23.16it/s, est. speed input: 11764.39 toks/s, output: 22.98 toks/s]
Processed prompts: 100%|| 128/128 [00:05<00:00, 23.16it/s, est. speed input: 11761.79 toks/s, output: 22.97 toks/s]
Processed prompts: 100%|| 128/128 [00:05<00:00, 22.97it/s, est. speed input: 11761.79 toks/s, output: 22.97 toks/s]
[rank0]:[W126 13:22:55.705857195 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-26 13:22:57
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-3B-FP8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 13:23:01 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 13:23:01 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1335435) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1335435) WARNING 01-26 13:23:37 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 11.66 requests/s, 11950.25 total tokens/s, 11.66 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-26 13:23:01] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 13:23:01] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 13:23:01] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 13:23:01] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:23:01] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:23:01] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:23:01] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:23:01] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:23:01] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 13:23:01] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:23:01] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:23:01] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:23:01] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:23:01] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 13:23:05] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 13:23:05] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 13:23:05] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 13:23:05] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:23:05] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:23:05] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:23:05] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:23:05] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:23:05] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 13:23:05] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:23:05] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:23:05] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:23:05] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:23:05] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1335435) [2026-01-26 13:23:06] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1335435) [2026-01-26 13:23:06] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1335435) [2026-01-26 13:23:06] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1335435) [2026-01-26 13:23:06] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1335435) [2026-01-26 13:23:06] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1335435) [2026-01-26 13:23:06] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1335435) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1335435) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:24<00:00, 24.49s/it]
(EngineCore_DP0 pid=1335435) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:24<00:00, 24.49s/it]
(EngineCore_DP0 pid=1335435) 
(EngineCore_DP0 pid=1335435) [2026-01-26 13:23:31] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4928] -> 1D uint8
(EngineCore_DP0 pid=1335435) [2026-01-26 13:23:31] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15810560 bytes
(EngineCore_DP0 pid=1335435) [2026-01-26 13:23:31] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4928] -> 1D uint8
(EngineCore_DP0 pid=1335435) [2026-01-26 13:23:31] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9486336 bytes
(EngineCore_DP0 pid=1335435) [2026-01-26 13:23:31] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4928] -> 1D uint8
(EngineCore_DP0 pid=1335435) [2026-01-26 13:23:31] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 50593792 bytes
(EngineCore_DP0 pid=1335435) [2026-01-26 13:23:31] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 13120] -> 1D uint8
(EngineCore_DP0 pid=1335435) [2026-01-26 13:23:31] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 25214976 bytes
(EngineCore_DP0 pid=1335435) 2026-01-26 13:23:36,995 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1335435) 2026-01-26 13:23:37,005 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  29%|       | 37/128 [00:00<00:00, 362.90it/s]
Adding requests:  66%|   | 85/128 [00:00<00:00, 429.86it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 449.85it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   3%|         | 4/128 [00:00<00:03, 32.18it/s, est. speed input: 32962.14 toks/s, output: 32.19 toks/s]
Processed prompts:   6%|         | 8/128 [00:00<00:07, 15.76it/s, est. speed input: 17479.51 toks/s, output: 17.07 toks/s]
Processed prompts:   9%|         | 11/128 [00:00<00:08, 14.01it/s, est. speed input: 15634.30 toks/s, output: 15.27 toks/s]
Processed prompts:  10%|         | 13/128 [00:00<00:08, 13.30it/s, est. speed input: 14931.90 toks/s, output: 14.58 toks/s]
Processed prompts:  12%|        | 15/128 [00:01<00:08, 12.81it/s, est. speed input: 14455.66 toks/s, output: 14.12 toks/s]
Processed prompts:  13%|        | 17/128 [00:01<00:08, 12.48it/s, est. speed input: 14115.63 toks/s, output: 13.78 toks/s]
Processed prompts:  15%|        | 19/128 [00:01<00:08, 12.17it/s, est. speed input: 13822.70 toks/s, output: 13.50 toks/s]
Processed prompts:  16%|        | 21/128 [00:01<00:08, 12.04it/s, est. speed input: 13626.96 toks/s, output: 13.31 toks/s]
Processed prompts:  18%|        | 23/128 [00:01<00:08, 11.91it/s, est. speed input: 13455.20 toks/s, output: 13.14 toks/s]
Processed prompts:  20%|        | 25/128 [00:01<00:08, 11.92it/s, est. speed input: 13347.08 toks/s, output: 13.03 toks/s]
Processed prompts:  21%|        | 27/128 [00:02<00:08, 11.91it/s, est. speed input: 13254.26 toks/s, output: 12.94 toks/s]
Processed prompts:  23%|       | 29/128 [00:02<00:08, 11.81it/s, est. speed input: 13146.60 toks/s, output: 12.84 toks/s]
Processed prompts:  24%|       | 31/128 [00:02<00:08, 11.66it/s, est. speed input: 13034.61 toks/s, output: 12.73 toks/s]
Processed prompts:  26%|       | 33/128 [00:02<00:08, 11.71it/s, est. speed input: 12975.03 toks/s, output: 12.67 toks/s]
Processed prompts:  27%|       | 35/128 [00:02<00:07, 11.75it/s, est. speed input: 12924.30 toks/s, output: 12.62 toks/s]
Processed prompts:  29%|       | 37/128 [00:02<00:07, 11.77it/s, est. speed input: 12876.37 toks/s, output: 12.57 toks/s]
Processed prompts:  30%|       | 39/128 [00:03<00:07, 11.81it/s, est. speed input: 12838.18 toks/s, output: 12.54 toks/s]
Processed prompts:  32%|      | 41/128 [00:03<00:07, 11.76it/s, est. speed input: 12790.26 toks/s, output: 12.49 toks/s]
Processed prompts:  34%|      | 43/128 [00:03<00:07, 11.62it/s, est. speed input: 12728.71 toks/s, output: 12.43 toks/s]
Processed prompts:  35%|      | 45/128 [00:03<00:07, 11.66it/s, est. speed input: 12695.96 toks/s, output: 12.40 toks/s]
Processed prompts:  37%|      | 47/128 [00:03<00:06, 11.68it/s, est. speed input: 12665.09 toks/s, output: 12.37 toks/s]
Processed prompts:  38%|      | 49/128 [00:03<00:06, 11.69it/s, est. speed input: 12636.65 toks/s, output: 12.34 toks/s]
Processed prompts:  40%|      | 51/128 [00:04<00:06, 11.75it/s, est. speed input: 12617.36 toks/s, output: 12.32 toks/s]
Processed prompts:  41%|     | 53/128 [00:04<00:06, 11.73it/s, est. speed input: 12591.37 toks/s, output: 12.30 toks/s]
Processed prompts:  43%|     | 55/128 [00:04<00:06, 11.78it/s, est. speed input: 12575.95 toks/s, output: 12.28 toks/s]
Processed prompts:  45%|     | 57/128 [00:04<00:06, 11.62it/s, est. speed input: 12536.84 toks/s, output: 12.24 toks/s]
Processed prompts:  46%|     | 59/128 [00:04<00:05, 11.65it/s, est. speed input: 12517.50 toks/s, output: 12.22 toks/s]
Processed prompts:  48%|     | 61/128 [00:04<00:05, 11.75it/s, est. speed input: 12509.30 toks/s, output: 12.22 toks/s]
Processed prompts:  49%|     | 63/128 [00:05<00:05, 11.80it/s, est. speed input: 12499.55 toks/s, output: 12.21 toks/s]
Processed prompts:  51%|     | 65/128 [00:05<00:05, 11.85it/s, est. speed input: 12492.46 toks/s, output: 12.20 toks/s]
Processed prompts:  52%|    | 67/128 [00:05<00:05, 11.85it/s, est. speed input: 12481.36 toks/s, output: 12.19 toks/s]
Processed prompts:  54%|    | 69/128 [00:05<00:05, 11.74it/s, est. speed input: 12459.04 toks/s, output: 12.17 toks/s]
Processed prompts:  55%|    | 71/128 [00:05<00:04, 11.74it/s, est. speed input: 12446.36 toks/s, output: 12.15 toks/s]
Processed prompts:  57%|    | 73/128 [00:06<00:04, 11.82it/s, est. speed input: 12442.21 toks/s, output: 12.15 toks/s]
Processed prompts:  59%|    | 75/128 [00:06<00:04, 11.86it/s, est. speed input: 12436.65 toks/s, output: 12.15 toks/s]
Processed prompts:  60%|    | 77/128 [00:06<00:04, 11.84it/s, est. speed input: 12427.62 toks/s, output: 12.14 toks/s]
Processed prompts:  62%|   | 79/128 [00:06<00:04, 11.79it/s, est. speed input: 12414.80 toks/s, output: 12.12 toks/s]
Processed prompts:  63%|   | 81/128 [00:06<00:04, 11.64it/s, est. speed input: 12392.81 toks/s, output: 12.10 toks/s]
Processed prompts:  65%|   | 83/128 [00:06<00:03, 11.67it/s, est. speed input: 12383.47 toks/s, output: 12.09 toks/s]
Processed prompts:  66%|   | 85/128 [00:07<00:03, 11.75it/s, est. speed input: 12379.39 toks/s, output: 12.09 toks/s]
Processed prompts:  68%|   | 87/128 [00:07<00:03, 11.79it/s, est. speed input: 12375.03 toks/s, output: 12.08 toks/s]
Processed prompts:  70%|   | 89/128 [00:07<00:03, 11.85it/s, est. speed input: 12372.40 toks/s, output: 12.08 toks/s]
Processed prompts:  71%|   | 91/128 [00:07<00:03, 11.77it/s, est. speed input: 12360.79 toks/s, output: 12.07 toks/s]
Processed prompts:  73%|  | 93/128 [00:07<00:03, 11.60it/s, est. speed input: 12340.86 toks/s, output: 12.05 toks/s]
Processed prompts:  74%|  | 95/128 [00:07<00:02, 11.65it/s, est. speed input: 12334.40 toks/s, output: 12.05 toks/s]
Processed prompts:  76%|  | 97/128 [00:08<00:02, 11.75it/s, est. speed input: 12333.39 toks/s, output: 12.04 toks/s]
Processed prompts:  77%|  | 99/128 [00:08<00:02, 11.80it/s, est. speed input: 12330.96 toks/s, output: 12.04 toks/s]
Processed prompts:  79%|  | 101/128 [00:08<00:02, 11.79it/s, est. speed input: 12325.23 toks/s, output: 12.04 toks/s]
Processed prompts:  80%|  | 103/128 [00:08<00:02, 11.77it/s, est. speed input: 12318.78 toks/s, output: 12.03 toks/s]
Processed prompts:  82%| | 105/128 [00:08<00:01, 11.68it/s, est. speed input: 12307.25 toks/s, output: 12.02 toks/s]
Processed prompts:  84%| | 107/128 [00:08<00:01, 11.68it/s, est. speed input: 12300.45 toks/s, output: 12.01 toks/s]
Processed prompts:  85%| | 109/128 [00:09<00:01, 11.70it/s, est. speed input: 12295.43 toks/s, output: 12.01 toks/s]
Processed prompts:  87%| | 111/128 [00:09<00:01, 11.69it/s, est. speed input: 12288.84 toks/s, output: 12.00 toks/s]
Processed prompts:  88%| | 113/128 [00:09<00:01, 11.77it/s, est. speed input: 12288.01 toks/s, output: 12.00 toks/s]
Processed prompts:  90%| | 115/128 [00:09<00:01, 11.83it/s, est. speed input: 12287.93 toks/s, output: 12.00 toks/s]
Processed prompts:  91%|| 117/128 [00:09<00:00, 11.85it/s, est. speed input: 12286.17 toks/s, output: 12.00 toks/s]
Processed prompts:  93%|| 119/128 [00:09<00:00, 11.71it/s, est. speed input: 12274.84 toks/s, output: 11.99 toks/s]
Processed prompts:  95%|| 121/128 [00:10<00:00, 11.67it/s, est. speed input: 12267.82 toks/s, output: 11.98 toks/s]
Processed prompts:  96%|| 123/128 [00:10<00:00, 11.68it/s, est. speed input: 12262.85 toks/s, output: 11.98 toks/s]
Processed prompts:  98%|| 125/128 [00:10<00:00, 11.73it/s, est. speed input: 12260.79 toks/s, output: 11.97 toks/s]
Processed prompts:  99%|| 127/128 [00:10<00:00, 11.74it/s, est. speed input: 12257.49 toks/s, output: 11.97 toks/s]
Processed prompts: 100%|| 128/128 [00:10<00:00, 11.74it/s, est. speed input: 12257.78 toks/s, output: 11.97 toks/s]
Processed prompts: 100%|| 128/128 [00:10<00:00, 11.97it/s, est. speed input: 12257.78 toks/s, output: 11.97 toks/s]
[rank0]:[W126 13:23:48.082383138 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-26 13:23:51
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-3B-FP8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 13:23:55 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 13:23:55 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1336361) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1336361) WARNING 01-26 13:24:31 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 11.64 requests/s, 11930.43 total tokens/s, 11.64 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-26 13:23:55] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 13:23:55] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 13:23:55] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 13:23:55] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:23:55] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:23:55] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:23:55] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:23:55] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:23:55] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 13:23:55] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:23:55] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:23:55] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:23:55] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:23:55] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 13:23:58] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 13:23:58] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 13:23:58] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 13:23:58] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:23:58] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:23:58] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:23:58] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:23:58] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:23:58] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 13:23:58] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:23:58] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:23:58] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:23:58] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:23:58] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1336361) [2026-01-26 13:23:59] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1336361) [2026-01-26 13:23:59] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1336361) [2026-01-26 13:23:59] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1336361) [2026-01-26 13:23:59] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1336361) [2026-01-26 13:23:59] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1336361) [2026-01-26 13:23:59] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1336361) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1336361) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:24<00:00, 24.45s/it]
(EngineCore_DP0 pid=1336361) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:24<00:00, 24.45s/it]
(EngineCore_DP0 pid=1336361) 
(EngineCore_DP0 pid=1336361) [2026-01-26 13:24:25] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4928] -> 1D uint8
(EngineCore_DP0 pid=1336361) [2026-01-26 13:24:25] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15810560 bytes
(EngineCore_DP0 pid=1336361) [2026-01-26 13:24:25] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4928] -> 1D uint8
(EngineCore_DP0 pid=1336361) [2026-01-26 13:24:25] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9486336 bytes
(EngineCore_DP0 pid=1336361) [2026-01-26 13:24:25] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4928] -> 1D uint8
(EngineCore_DP0 pid=1336361) [2026-01-26 13:24:25] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 50593792 bytes
(EngineCore_DP0 pid=1336361) [2026-01-26 13:24:25] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 13120] -> 1D uint8
(EngineCore_DP0 pid=1336361) [2026-01-26 13:24:25] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 25214976 bytes
(EngineCore_DP0 pid=1336361) 2026-01-26 13:24:30,553 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1336361) 2026-01-26 13:24:30,563 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  22%|       | 56/256 [00:00<00:00, 548.10it/s]
Adding requests:  43%|     | 111/256 [00:00<00:00, 484.32it/s]
Adding requests:  63%|   | 162/256 [00:00<00:00, 493.96it/s]
Adding requests:  83%| | 213/256 [00:00<00:00, 498.89it/s]
Adding requests: 100%|| 256/256 [00:00<00:00, 503.56it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 6/256 [00:00<00:07, 33.84it/s, est. speed input: 34654.02 toks/s, output: 33.84 toks/s]
Processed prompts:   4%|         | 10/256 [00:00<00:13, 17.71it/s, est. speed input: 19837.12 toks/s, output: 19.37 toks/s]
Processed prompts:   5%|         | 13/256 [00:00<00:13, 17.62it/s, est. speed input: 19343.78 toks/s, output: 18.89 toks/s]
Processed prompts:   6%|         | 15/256 [00:00<00:15, 15.71it/s, est. speed input: 17909.90 toks/s, output: 17.49 toks/s]
Processed prompts:   7%|         | 17/256 [00:01<00:16, 14.48it/s, est. speed input: 16958.28 toks/s, output: 16.56 toks/s]
Processed prompts:   7%|         | 19/256 [00:01<00:17, 13.53it/s, est. speed input: 16205.39 toks/s, output: 15.83 toks/s]
Processed prompts:   8%|         | 21/256 [00:01<00:18, 12.98it/s, est. speed input: 15687.14 toks/s, output: 15.32 toks/s]
Processed prompts:   9%|         | 23/256 [00:01<00:18, 12.63it/s, est. speed input: 15293.85 toks/s, output: 14.94 toks/s]
Processed prompts:  10%|         | 25/256 [00:01<00:18, 12.39it/s, est. speed input: 14981.20 toks/s, output: 14.63 toks/s]
Processed prompts:  11%|         | 27/256 [00:01<00:18, 12.21it/s, est. speed input: 14718.79 toks/s, output: 14.37 toks/s]
Processed prompts:  11%|        | 29/256 [00:02<00:18, 12.10it/s, est. speed input: 14503.85 toks/s, output: 14.16 toks/s]
Processed prompts:  12%|        | 31/256 [00:02<00:18, 11.94it/s, est. speed input: 14299.65 toks/s, output: 13.96 toks/s]
Processed prompts:  13%|        | 33/256 [00:02<00:18, 11.87it/s, est. speed input: 14132.88 toks/s, output: 13.80 toks/s]
Processed prompts:  14%|        | 35/256 [00:02<00:18, 11.86it/s, est. speed input: 14000.09 toks/s, output: 13.67 toks/s]
Processed prompts:  14%|        | 37/256 [00:02<00:18, 11.88it/s, est. speed input: 13889.78 toks/s, output: 13.56 toks/s]
Processed prompts:  15%|        | 39/256 [00:02<00:18, 11.87it/s, est. speed input: 13787.80 toks/s, output: 13.46 toks/s]
Processed prompts:  16%|        | 41/256 [00:03<00:18, 11.83it/s, est. speed input: 13689.45 toks/s, output: 13.37 toks/s]
Processed prompts:  17%|        | 43/256 [00:03<00:17, 11.87it/s, est. speed input: 13614.36 toks/s, output: 13.30 toks/s]
Processed prompts:  18%|        | 45/256 [00:03<00:18, 11.71it/s, est. speed input: 13511.86 toks/s, output: 13.20 toks/s]
Processed prompts:  18%|        | 47/256 [00:03<00:17, 11.70it/s, est. speed input: 13438.19 toks/s, output: 13.12 toks/s]
Processed prompts:  19%|        | 49/256 [00:03<00:17, 11.73it/s, est. speed input: 13375.95 toks/s, output: 13.06 toks/s]
Processed prompts:  20%|        | 51/256 [00:03<00:17, 11.75it/s, est. speed input: 13320.04 toks/s, output: 13.01 toks/s]
Processed prompts:  21%|        | 53/256 [00:04<00:17, 11.78it/s, est. speed input: 13271.21 toks/s, output: 12.96 toks/s]
Processed prompts:  21%|       | 55/256 [00:04<00:17, 11.78it/s, est. speed input: 13223.28 toks/s, output: 12.91 toks/s]
Processed prompts:  22%|       | 57/256 [00:04<00:17, 11.61it/s, est. speed input: 13153.53 toks/s, output: 12.85 toks/s]
Processed prompts:  23%|       | 59/256 [00:04<00:16, 11.67it/s, est. speed input: 13114.95 toks/s, output: 12.81 toks/s]
Processed prompts:  24%|       | 61/256 [00:04<00:16, 11.75it/s, est. speed input: 13083.68 toks/s, output: 12.78 toks/s]
Processed prompts:  25%|       | 63/256 [00:04<00:16, 11.72it/s, est. speed input: 13043.76 toks/s, output: 12.74 toks/s]
Processed prompts:  25%|       | 65/256 [00:05<00:16, 11.73it/s, est. speed input: 13010.51 toks/s, output: 12.71 toks/s]
Processed prompts:  26%|       | 67/256 [00:05<00:16, 11.70it/s, est. speed input: 12974.70 toks/s, output: 12.67 toks/s]
Processed prompts:  27%|       | 69/256 [00:05<00:16, 11.67it/s, est. speed input: 12939.90 toks/s, output: 12.64 toks/s]
Processed prompts:  28%|       | 71/256 [00:05<00:15, 11.68it/s, est. speed input: 12910.55 toks/s, output: 12.61 toks/s]
Processed prompts:  29%|       | 73/256 [00:05<00:15, 11.71it/s, est. speed input: 12886.41 toks/s, output: 12.58 toks/s]
Processed prompts:  29%|       | 75/256 [00:05<00:15, 11.70it/s, est. speed input: 12859.84 toks/s, output: 12.56 toks/s]
Processed prompts:  30%|       | 77/256 [00:06<00:15, 11.73it/s, est. speed input: 12837.72 toks/s, output: 12.54 toks/s]
Processed prompts:  31%|       | 79/256 [00:06<00:15, 11.76it/s, est. speed input: 12818.90 toks/s, output: 12.52 toks/s]
Processed prompts:  32%|      | 81/256 [00:06<00:15, 11.62it/s, est. speed input: 12785.16 toks/s, output: 12.49 toks/s]
Processed prompts:  32%|      | 83/256 [00:06<00:14, 11.67it/s, est. speed input: 12767.12 toks/s, output: 12.47 toks/s]
Processed prompts:  33%|      | 85/256 [00:06<00:14, 11.74it/s, est. speed input: 12753.08 toks/s, output: 12.45 toks/s]
Processed prompts:  34%|      | 87/256 [00:06<00:14, 11.76it/s, est. speed input: 12737.20 toks/s, output: 12.44 toks/s]
Processed prompts:  35%|      | 89/256 [00:07<00:14, 11.75it/s, est. speed input: 12719.97 toks/s, output: 12.42 toks/s]
Processed prompts:  36%|      | 91/256 [00:07<00:14, 11.73it/s, est. speed input: 12702.19 toks/s, output: 12.40 toks/s]
Processed prompts:  36%|      | 93/256 [00:07<00:13, 11.67it/s, est. speed input: 12681.22 toks/s, output: 12.38 toks/s]
Processed prompts:  37%|      | 95/256 [00:07<00:13, 11.62it/s, est. speed input: 12660.64 toks/s, output: 12.36 toks/s]
Processed prompts:  38%|      | 97/256 [00:07<00:13, 11.63it/s, est. speed input: 12645.32 toks/s, output: 12.35 toks/s]
Processed prompts:  39%|      | 99/256 [00:08<00:13, 11.69it/s, est. speed input: 12634.22 toks/s, output: 12.34 toks/s]
Processed prompts:  39%|      | 101/256 [00:08<00:13, 11.66it/s, est. speed input: 12617.58 toks/s, output: 12.32 toks/s]
Processed prompts:  40%|      | 103/256 [00:08<00:13, 11.69it/s, est. speed input: 12606.18 toks/s, output: 12.31 toks/s]
Processed prompts:  41%|      | 105/256 [00:08<00:12, 11.77it/s, est. speed input: 12599.45 toks/s, output: 12.30 toks/s]
Processed prompts:  42%|     | 107/256 [00:08<00:12, 11.65it/s, est. speed input: 12580.06 toks/s, output: 12.29 toks/s]
Processed prompts:  43%|     | 109/256 [00:08<00:12, 11.69it/s, est. speed input: 12570.11 toks/s, output: 12.28 toks/s]
Processed prompts:  43%|     | 111/256 [00:09<00:12, 11.73it/s, est. speed input: 12561.61 toks/s, output: 12.27 toks/s]
Processed prompts:  44%|     | 113/256 [00:09<00:12, 11.80it/s, est. speed input: 12555.96 toks/s, output: 12.26 toks/s]
Processed prompts:  45%|     | 115/256 [00:09<00:11, 11.78it/s, est. speed input: 12546.20 toks/s, output: 12.25 toks/s]
Processed prompts:  46%|     | 117/256 [00:09<00:11, 11.82it/s, est. speed input: 12540.18 toks/s, output: 12.25 toks/s]
Processed prompts:  46%|     | 119/256 [00:09<00:11, 11.67it/s, est. speed input: 12523.07 toks/s, output: 12.23 toks/s]
Processed prompts:  47%|     | 121/256 [00:09<00:11, 11.73it/s, est. speed input: 12516.84 toks/s, output: 12.22 toks/s]
Processed prompts:  48%|     | 123/256 [00:10<00:11, 11.73it/s, est. speed input: 12508.31 toks/s, output: 12.22 toks/s]
Processed prompts:  49%|     | 125/256 [00:10<00:11, 11.70it/s, est. speed input: 12498.37 toks/s, output: 12.21 toks/s]
Processed prompts:  50%|     | 127/256 [00:10<00:11, 11.71it/s, est. speed input: 12490.36 toks/s, output: 12.20 toks/s]
Processed prompts:  50%|     | 129/256 [00:10<00:10, 11.69it/s, est. speed input: 12481.15 toks/s, output: 12.19 toks/s]
Processed prompts:  51%|     | 131/256 [00:10<00:10, 11.57it/s, est. speed input: 12466.33 toks/s, output: 12.17 toks/s]
Processed prompts:  52%|    | 133/256 [00:10<00:10, 11.59it/s, est. speed input: 12457.83 toks/s, output: 12.17 toks/s]
Processed prompts:  53%|    | 135/256 [00:11<00:10, 11.67it/s, est. speed input: 12452.81 toks/s, output: 12.16 toks/s]
Processed prompts:  54%|    | 137/256 [00:11<00:10, 11.77it/s, est. speed input: 12450.57 toks/s, output: 12.16 toks/s]
Processed prompts:  54%|    | 139/256 [00:11<00:09, 11.78it/s, est. speed input: 12445.35 toks/s, output: 12.15 toks/s]
Processed prompts:  55%|    | 141/256 [00:11<00:09, 11.77it/s, est. speed input: 12439.04 toks/s, output: 12.15 toks/s]
Processed prompts:  56%|    | 143/256 [00:11<00:09, 11.65it/s, est. speed input: 12427.24 toks/s, output: 12.14 toks/s]
Processed prompts:  57%|    | 145/256 [00:11<00:09, 11.66it/s, est. speed input: 12420.66 toks/s, output: 12.13 toks/s]
Processed prompts:  57%|    | 147/256 [00:12<00:09, 11.73it/s, est. speed input: 12417.22 toks/s, output: 12.13 toks/s]
Processed prompts:  58%|    | 149/256 [00:12<00:09, 11.70it/s, est. speed input: 12410.18 toks/s, output: 12.12 toks/s]
Processed prompts:  59%|    | 151/256 [00:12<00:08, 11.74it/s, est. speed input: 12406.31 toks/s, output: 12.12 toks/s]
Processed prompts:  60%|    | 153/256 [00:12<00:08, 11.72it/s, est. speed input: 12400.05 toks/s, output: 12.11 toks/s]
Processed prompts:  61%|    | 155/256 [00:12<00:08, 11.68it/s, est. speed input: 12392.89 toks/s, output: 12.10 toks/s]
Processed prompts:  61%|   | 157/256 [00:12<00:08, 11.59it/s, est. speed input: 12383.08 toks/s, output: 12.09 toks/s]
Processed prompts:  62%|   | 159/256 [00:13<00:08, 11.59it/s, est. speed input: 12376.40 toks/s, output: 12.09 toks/s]
Processed prompts:  63%|   | 161/256 [00:13<00:08, 11.66it/s, est. speed input: 12372.89 toks/s, output: 12.08 toks/s]
Processed prompts:  64%|   | 163/256 [00:13<00:07, 11.66it/s, est. speed input: 12367.22 toks/s, output: 12.08 toks/s]
Processed prompts:  64%|   | 165/256 [00:13<00:07, 11.70it/s, est. speed input: 12363.73 toks/s, output: 12.07 toks/s]
Processed prompts:  65%|   | 167/256 [00:13<00:07, 11.69it/s, est. speed input: 12358.70 toks/s, output: 12.07 toks/s]
Processed prompts:  66%|   | 169/256 [00:14<00:07, 11.60it/s, est. speed input: 12349.78 toks/s, output: 12.06 toks/s]
Processed prompts:  67%|   | 171/256 [00:14<00:07, 11.62it/s, est. speed input: 12344.99 toks/s, output: 12.06 toks/s]
Processed prompts:  68%|   | 173/256 [00:14<00:07, 11.65it/s, est. speed input: 12341.12 toks/s, output: 12.05 toks/s]
Processed prompts:  68%|   | 175/256 [00:14<00:06, 11.65it/s, est. speed input: 12335.99 toks/s, output: 12.05 toks/s]
Processed prompts:  69%|   | 177/256 [00:14<00:06, 11.65it/s, est. speed input: 12331.45 toks/s, output: 12.04 toks/s]
Processed prompts:  70%|   | 179/256 [00:14<00:06, 11.64it/s, est. speed input: 12326.30 toks/s, output: 12.04 toks/s]
Processed prompts:  71%|   | 181/256 [00:15<00:06, 11.56it/s, est. speed input: 12318.47 toks/s, output: 12.03 toks/s]
Processed prompts:  71%|  | 183/256 [00:15<00:06, 11.64it/s, est. speed input: 12316.06 toks/s, output: 12.03 toks/s]
Processed prompts:  72%|  | 185/256 [00:15<00:06, 11.66it/s, est. speed input: 12312.68 toks/s, output: 12.02 toks/s]
Processed prompts:  73%|  | 187/256 [00:15<00:05, 11.69it/s, est. speed input: 12309.80 toks/s, output: 12.02 toks/s]
Processed prompts:  74%|  | 189/256 [00:15<00:05, 11.70it/s, est. speed input: 12306.37 toks/s, output: 12.02 toks/s]
Processed prompts:  75%|  | 191/256 [00:15<00:05, 11.63it/s, est. speed input: 12300.23 toks/s, output: 12.01 toks/s]
Processed prompts:  75%|  | 193/256 [00:16<00:05, 11.57it/s, est. speed input: 12293.70 toks/s, output: 12.01 toks/s]
Processed prompts:  76%|  | 195/256 [00:16<00:05, 11.61it/s, est. speed input: 12290.40 toks/s, output: 12.00 toks/s]
Processed prompts:  77%|  | 197/256 [00:16<00:05, 11.63it/s, est. speed input: 12287.06 toks/s, output: 12.00 toks/s]
Processed prompts:  78%|  | 199/256 [00:16<00:04, 11.71it/s, est. speed input: 12285.97 toks/s, output: 12.00 toks/s]
Processed prompts:  79%|  | 201/256 [00:16<00:04, 11.73it/s, est. speed input: 12283.83 toks/s, output: 12.00 toks/s]
Processed prompts:  79%|  | 203/256 [00:16<00:04, 11.67it/s, est. speed input: 12278.89 toks/s, output: 11.99 toks/s]
Processed prompts:  80%|  | 205/256 [00:17<00:04, 11.59it/s, est. speed input: 12272.81 toks/s, output: 11.99 toks/s]
Processed prompts:  81%|  | 207/256 [00:17<00:04, 11.63it/s, est. speed input: 12270.09 toks/s, output: 11.98 toks/s]
Processed prompts:  82%| | 209/256 [00:17<00:04, 11.66it/s, est. speed input: 12267.67 toks/s, output: 11.98 toks/s]
Processed prompts:  82%| | 211/256 [00:17<00:03, 11.64it/s, est. speed input: 12263.69 toks/s, output: 11.98 toks/s]
Processed prompts:  83%| | 213/256 [00:17<00:03, 11.64it/s, est. speed input: 12260.35 toks/s, output: 11.97 toks/s]
Processed prompts:  84%| | 215/256 [00:17<00:03, 11.64it/s, est. speed input: 12257.16 toks/s, output: 11.97 toks/s]
Processed prompts:  85%| | 217/256 [00:18<00:03, 11.59it/s, est. speed input: 12252.29 toks/s, output: 11.97 toks/s]
Processed prompts:  86%| | 219/256 [00:18<00:03, 11.57it/s, est. speed input: 12248.03 toks/s, output: 11.96 toks/s]
Processed prompts:  86%| | 221/256 [00:18<00:03, 11.64it/s, est. speed input: 12246.71 toks/s, output: 11.96 toks/s]
Processed prompts:  87%| | 223/256 [00:18<00:02, 11.66it/s, est. speed input: 12244.38 toks/s, output: 11.96 toks/s]
Processed prompts:  88%| | 225/256 [00:18<00:02, 11.63it/s, est. speed input: 12240.52 toks/s, output: 11.95 toks/s]
Processed prompts:  89%| | 227/256 [00:18<00:02, 11.66it/s, est. speed input: 12238.53 toks/s, output: 11.95 toks/s]
Processed prompts:  89%| | 229/256 [00:19<00:02, 11.67it/s, est. speed input: 12236.04 toks/s, output: 11.95 toks/s]
Processed prompts:  90%| | 231/256 [00:19<00:02, 11.59it/s, est. speed input: 12231.12 toks/s, output: 11.94 toks/s]
Processed prompts:  91%| | 233/256 [00:19<00:01, 11.63it/s, est. speed input: 12229.22 toks/s, output: 11.94 toks/s]
Processed prompts:  92%|| 235/256 [00:19<00:01, 11.67it/s, est. speed input: 12227.56 toks/s, output: 11.94 toks/s]
Processed prompts:  93%|| 237/256 [00:19<00:01, 11.68it/s, est. speed input: 12225.46 toks/s, output: 11.94 toks/s]
Processed prompts:  93%|| 239/256 [00:20<00:01, 11.69it/s, est. speed input: 12223.37 toks/s, output: 11.94 toks/s]
Processed prompts:  94%|| 241/256 [00:20<00:01, 11.69it/s, est. speed input: 12221.27 toks/s, output: 11.93 toks/s]
Processed prompts:  95%|| 243/256 [00:20<00:01, 11.59it/s, est. speed input: 12216.22 toks/s, output: 11.93 toks/s]
Processed prompts:  96%|| 245/256 [00:20<00:00, 11.69it/s, est. speed input: 12216.11 toks/s, output: 11.93 toks/s]
Processed prompts:  96%|| 247/256 [00:20<00:00, 11.73it/s, est. speed input: 12215.25 toks/s, output: 11.93 toks/s]
Processed prompts:  97%|| 249/256 [00:20<00:00, 11.68it/s, est. speed input: 12212.31 toks/s, output: 11.93 toks/s]
Processed prompts:  98%|| 251/256 [00:21<00:00, 11.65it/s, est. speed input: 12209.33 toks/s, output: 11.92 toks/s]
Processed prompts:  99%|| 253/256 [00:21<00:00, 11.71it/s, est. speed input: 12208.68 toks/s, output: 11.92 toks/s]
Processed prompts: 100%|| 255/256 [00:21<00:00, 11.55it/s, est. speed input: 12202.37 toks/s, output: 11.92 toks/s]
Processed prompts: 100%|| 256/256 [00:21<00:00, 11.55it/s, est. speed input: 12201.54 toks/s, output: 11.92 toks/s]
Processed prompts: 100%|| 256/256 [00:21<00:00, 11.92it/s, est. speed input: 12201.54 toks/s, output: 11.92 toks/s]
[rank0]:[W126 13:24:53.772568351 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-26 13:24:55
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-3B-FP8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 13:25:00 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 13:25:01 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1337508) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1337508) WARNING 01-26 13:25:37 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 11.30 requests/s, 11577.44 total tokens/s, 11.30 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-26 13:25:00] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 13:25:00] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 13:25:00] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 13:25:00] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:25:00] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:25:00] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:25:00] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:25:00] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:25:00] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 13:25:00] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:25:00] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:25:00] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:25:00] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:25:00] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 13:25:04] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 13:25:04] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 13:25:04] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 13:25:04] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:25:04] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:25:04] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:25:04] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:25:04] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:25:04] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 13:25:04] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:25:04] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:25:04] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:25:04] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:25:04] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1337508) [2026-01-26 13:25:05] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1337508) [2026-01-26 13:25:05] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1337508) [2026-01-26 13:25:05] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1337508) [2026-01-26 13:25:05] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1337508) [2026-01-26 13:25:05] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1337508) [2026-01-26 13:25:05] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1337508) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1337508) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:24<00:00, 24.43s/it]
(EngineCore_DP0 pid=1337508) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:24<00:00, 24.43s/it]
(EngineCore_DP0 pid=1337508) 
(EngineCore_DP0 pid=1337508) [2026-01-26 13:25:30] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4928] -> 1D uint8
(EngineCore_DP0 pid=1337508) [2026-01-26 13:25:30] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15810560 bytes
(EngineCore_DP0 pid=1337508) [2026-01-26 13:25:30] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4928] -> 1D uint8
(EngineCore_DP0 pid=1337508) [2026-01-26 13:25:30] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9486336 bytes
(EngineCore_DP0 pid=1337508) [2026-01-26 13:25:30] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4928] -> 1D uint8
(EngineCore_DP0 pid=1337508) [2026-01-26 13:25:30] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 50593792 bytes
(EngineCore_DP0 pid=1337508) [2026-01-26 13:25:30] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 13120] -> 1D uint8
(EngineCore_DP0 pid=1337508) [2026-01-26 13:25:30] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 25214976 bytes
(EngineCore_DP0 pid=1337508) 2026-01-26 13:25:36,236 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1337508) 2026-01-26 13:25:36,246 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:  11%|         | 55/512 [00:00<00:00, 539.53it/s]
Adding requests:  21%|       | 109/512 [00:00<00:00, 482.40it/s]
Adding requests:  31%|      | 160/512 [00:00<00:00, 492.03it/s]
Adding requests:  41%|      | 211/512 [00:00<00:00, 497.10it/s]
Adding requests:  52%|    | 265/512 [00:00<00:00, 511.53it/s]
Adding requests:  62%|   | 317/512 [00:00<00:00, 507.04it/s]
Adding requests:  72%|  | 371/512 [00:00<00:00, 514.19it/s]
Adding requests:  83%| | 424/512 [00:00<00:00, 518.55it/s]
Adding requests:  93%|| 476/512 [00:00<00:00, 512.39it/s]
Adding requests: 100%|| 512/512 [00:01<00:00, 508.26it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 10/512 [00:00<00:11, 43.33it/s, est. speed input: 44376.33 toks/s, output: 43.33 toks/s]
Processed prompts:   3%|         | 15/512 [00:00<00:21, 23.48it/s, est. speed input: 26470.27 toks/s, output: 25.85 toks/s]
Processed prompts:   4%|         | 18/512 [00:00<00:30, 16.09it/s, est. speed input: 19801.54 toks/s, output: 19.34 toks/s]
Processed prompts:   4%|         | 22/512 [00:01<00:34, 14.01it/s, est. speed input: 17463.34 toks/s, output: 17.05 toks/s]
Processed prompts:   5%|         | 26/512 [00:01<00:37, 13.02it/s, est. speed input: 16205.94 toks/s, output: 15.83 toks/s]
Processed prompts:   6%|         | 30/512 [00:01<00:38, 12.49it/s, est. speed input: 15429.16 toks/s, output: 15.07 toks/s]
Processed prompts:   7%|         | 34/512 [00:02<00:39, 12.04it/s, est. speed input: 14815.79 toks/s, output: 14.47 toks/s]
Processed prompts:   7%|         | 38/512 [00:02<00:40, 11.84it/s, est. speed input: 14408.84 toks/s, output: 14.07 toks/s]
Processed prompts:   8%|         | 42/512 [00:03<00:40, 11.67it/s, est. speed input: 14081.46 toks/s, output: 13.75 toks/s]
Processed prompts:   9%|         | 46/512 [00:03<00:40, 11.54it/s, est. speed input: 13812.24 toks/s, output: 13.49 toks/s]
Processed prompts:  10%|         | 50/512 [00:03<00:40, 11.52it/s, est. speed input: 13622.36 toks/s, output: 13.30 toks/s]
Processed prompts:  11%|         | 54/512 [00:04<00:39, 11.48it/s, est. speed input: 13454.60 toks/s, output: 13.14 toks/s]
Processed prompts:  11%|        | 58/512 [00:04<00:39, 11.39it/s, est. speed input: 13294.30 toks/s, output: 12.98 toks/s]
Processed prompts:  12%|        | 62/512 [00:04<00:39, 11.37it/s, est. speed input: 13169.50 toks/s, output: 12.86 toks/s]
Processed prompts:  13%|        | 66/512 [00:05<00:39, 11.37it/s, est. speed input: 13067.20 toks/s, output: 12.76 toks/s]
Processed prompts:  14%|        | 70/512 [00:05<00:38, 11.34it/s, est. speed input: 12968.69 toks/s, output: 12.66 toks/s]
Processed prompts:  14%|        | 74/512 [00:05<00:38, 11.35it/s, est. speed input: 12890.34 toks/s, output: 12.59 toks/s]
Processed prompts:  15%|        | 78/512 [00:06<00:38, 11.37it/s, est. speed input: 12821.80 toks/s, output: 12.52 toks/s]
Processed prompts:  16%|        | 82/512 [00:06<00:38, 11.31it/s, est. speed input: 12747.16 toks/s, output: 12.45 toks/s]
Processed prompts:  17%|        | 86/512 [00:06<00:37, 11.32it/s, est. speed input: 12689.43 toks/s, output: 12.39 toks/s]
Processed prompts:  18%|        | 90/512 [00:07<00:37, 11.34it/s, est. speed input: 12639.63 toks/s, output: 12.34 toks/s]
Processed prompts:  18%|        | 94/512 [00:07<00:36, 11.32it/s, est. speed input: 12589.89 toks/s, output: 12.29 toks/s]
Processed prompts:  19%|        | 98/512 [00:07<00:36, 11.32it/s, est. speed input: 12544.96 toks/s, output: 12.25 toks/s]
Processed prompts:  20%|        | 102/512 [00:08<00:36, 11.33it/s, est. speed input: 12506.54 toks/s, output: 12.21 toks/s]
Processed prompts:  21%|        | 106/512 [00:08<00:35, 11.29it/s, est. speed input: 12463.88 toks/s, output: 12.17 toks/s]
Processed prompts:  21%|       | 110/512 [00:09<00:35, 11.30it/s, est. speed input: 12430.10 toks/s, output: 12.14 toks/s]
Processed prompts:  22%|       | 114/512 [00:09<00:35, 11.31it/s, est. speed input: 12398.43 toks/s, output: 12.11 toks/s]
Processed prompts:  23%|       | 118/512 [00:09<00:35, 11.24it/s, est. speed input: 12360.08 toks/s, output: 12.07 toks/s]
Processed prompts:  24%|       | 122/512 [00:10<00:34, 11.26it/s, est. speed input: 12332.36 toks/s, output: 12.04 toks/s]
Processed prompts:  25%|       | 126/512 [00:10<00:34, 11.32it/s, est. speed input: 12313.37 toks/s, output: 12.02 toks/s]
Processed prompts:  25%|       | 130/512 [00:10<00:33, 11.29it/s, est. speed input: 12285.40 toks/s, output: 12.00 toks/s]
Processed prompts:  26%|       | 134/512 [00:11<00:33, 11.35it/s, est. speed input: 12269.22 toks/s, output: 11.98 toks/s]
Processed prompts:  27%|       | 138/512 [00:11<00:32, 11.38it/s, est. speed input: 12252.47 toks/s, output: 11.97 toks/s]
Processed prompts:  28%|       | 142/512 [00:11<00:32, 11.32it/s, est. speed input: 12228.92 toks/s, output: 11.94 toks/s]
Processed prompts:  29%|       | 146/512 [00:12<00:32, 11.33it/s, est. speed input: 12211.02 toks/s, output: 11.92 toks/s]
Processed prompts:  29%|       | 150/512 [00:12<00:31, 11.35it/s, est. speed input: 12196.43 toks/s, output: 11.91 toks/s]
Processed prompts:  30%|       | 154/512 [00:12<00:31, 11.32it/s, est. speed input: 12177.64 toks/s, output: 11.89 toks/s]
Processed prompts:  31%|       | 158/512 [00:13<00:31, 11.32it/s, est. speed input: 12162.58 toks/s, output: 11.88 toks/s]
Processed prompts:  32%|      | 162/512 [00:13<00:30, 11.33it/s, est. speed input: 12148.26 toks/s, output: 11.86 toks/s]
Processed prompts:  32%|      | 166/512 [00:14<00:30, 11.27it/s, est. speed input: 12129.30 toks/s, output: 11.84 toks/s]
Processed prompts:  33%|      | 170/512 [00:14<00:30, 11.29it/s, est. speed input: 12116.37 toks/s, output: 11.83 toks/s]
Processed prompts:  34%|      | 174/512 [00:14<00:29, 11.32it/s, est. speed input: 12105.78 toks/s, output: 11.82 toks/s]
Processed prompts:  35%|      | 178/512 [00:15<00:29, 11.31it/s, est. speed input: 12092.54 toks/s, output: 11.81 toks/s]
Processed prompts:  36%|      | 182/512 [00:15<00:29, 11.32it/s, est. speed input: 12081.90 toks/s, output: 11.80 toks/s]
Processed prompts:  36%|      | 186/512 [00:15<00:28, 11.31it/s, est. speed input: 12070.03 toks/s, output: 11.79 toks/s]
Processed prompts:  37%|      | 190/512 [00:16<00:28, 11.28it/s, est. speed input: 12056.87 toks/s, output: 11.77 toks/s]
Processed prompts:  38%|      | 194/512 [00:16<00:28, 11.29it/s, est. speed input: 12047.13 toks/s, output: 11.76 toks/s]
Processed prompts:  39%|      | 198/512 [00:16<00:27, 11.27it/s, est. speed input: 12035.57 toks/s, output: 11.75 toks/s]
Processed prompts:  39%|      | 202/512 [00:17<00:27, 11.26it/s, est. speed input: 12024.03 toks/s, output: 11.74 toks/s]
Processed prompts:  40%|      | 206/512 [00:17<00:27, 11.30it/s, est. speed input: 12017.18 toks/s, output: 11.74 toks/s]
Processed prompts:  41%|      | 210/512 [00:17<00:26, 11.31it/s, est. speed input: 12008.86 toks/s, output: 11.73 toks/s]
Processed prompts:  42%|     | 214/512 [00:18<00:26, 11.25it/s, est. speed input: 11996.62 toks/s, output: 11.72 toks/s]
Processed prompts:  43%|     | 218/512 [00:18<00:26, 11.28it/s, est. speed input: 11989.57 toks/s, output: 11.71 toks/s]
Processed prompts:  43%|     | 222/512 [00:18<00:25, 11.31it/s, est. speed input: 11983.48 toks/s, output: 11.70 toks/s]
Processed prompts:  44%|     | 226/512 [00:19<00:25, 11.27it/s, est. speed input: 11973.53 toks/s, output: 11.69 toks/s]
Processed prompts:  45%|     | 230/512 [00:19<00:24, 11.30it/s, est. speed input: 11967.54 toks/s, output: 11.69 toks/s]
Processed prompts:  46%|     | 234/512 [00:20<00:24, 11.34it/s, est. speed input: 11963.15 toks/s, output: 11.68 toks/s]
Processed prompts:  46%|     | 238/512 [00:20<00:24, 11.29it/s, est. speed input: 11954.21 toks/s, output: 11.67 toks/s]
Processed prompts:  47%|     | 242/512 [00:20<00:23, 11.30it/s, est. speed input: 11947.96 toks/s, output: 11.67 toks/s]
Processed prompts:  48%|     | 246/512 [00:21<00:23, 11.34it/s, est. speed input: 11943.99 toks/s, output: 11.66 toks/s]
Processed prompts:  49%|     | 250/512 [00:21<00:23, 11.27it/s, est. speed input: 11934.56 toks/s, output: 11.65 toks/s]
Processed prompts:  50%|     | 254/512 [00:21<00:22, 11.27it/s, est. speed input: 11928.06 toks/s, output: 11.65 toks/s]
Processed prompts:  50%|     | 258/512 [00:22<00:22, 11.29it/s, est. speed input: 11923.06 toks/s, output: 11.64 toks/s]
Processed prompts:  51%|     | 262/512 [00:22<00:22, 11.27it/s, est. speed input: 11916.01 toks/s, output: 11.64 toks/s]
Processed prompts:  52%|    | 266/512 [00:22<00:21, 11.29it/s, est. speed input: 11911.38 toks/s, output: 11.63 toks/s]
Processed prompts:  53%|    | 270/512 [00:23<00:21, 11.31it/s, est. speed input: 11907.00 toks/s, output: 11.63 toks/s]
Processed prompts:  54%|    | 274/512 [00:23<00:21, 11.26it/s, est. speed input: 11899.71 toks/s, output: 11.62 toks/s]
Processed prompts:  54%|    | 278/512 [00:23<00:20, 11.30it/s, est. speed input: 11896.19 toks/s, output: 11.62 toks/s]
Processed prompts:  55%|    | 282/512 [00:24<00:20, 11.34it/s, est. speed input: 11893.26 toks/s, output: 11.61 toks/s]
Processed prompts:  56%|    | 286/512 [00:24<00:19, 11.30it/s, est. speed input: 11887.57 toks/s, output: 11.61 toks/s]
Processed prompts:  57%|    | 290/512 [00:24<00:19, 11.32it/s, est. speed input: 11883.77 toks/s, output: 11.61 toks/s]
Processed prompts:  57%|    | 294/512 [00:25<00:19, 11.32it/s, est. speed input: 11879.76 toks/s, output: 11.60 toks/s]
Processed prompts:  58%|    | 298/512 [00:25<00:19, 11.25it/s, est. speed input: 11872.67 toks/s, output: 11.59 toks/s]
Processed prompts:  59%|    | 302/512 [00:26<00:18, 11.30it/s, est. speed input: 11869.96 toks/s, output: 11.59 toks/s]
Processed prompts:  60%|    | 306/512 [00:26<00:18, 11.30it/s, est. speed input: 11866.06 toks/s, output: 11.59 toks/s]
Processed prompts:  61%|    | 310/512 [00:26<00:17, 11.24it/s, est. speed input: 11859.35 toks/s, output: 11.58 toks/s]
Processed prompts:  61%|   | 314/512 [00:27<00:17, 11.26it/s, est. speed input: 11855.66 toks/s, output: 11.58 toks/s]
Processed prompts:  62%|   | 318/512 [00:27<00:17, 11.28it/s, est. speed input: 11852.45 toks/s, output: 11.57 toks/s]
Processed prompts:  63%|   | 322/512 [00:27<00:16, 11.26it/s, est. speed input: 11847.74 toks/s, output: 11.57 toks/s]
Processed prompts:  64%|   | 326/512 [00:28<00:16, 11.28it/s, est. speed input: 11844.56 toks/s, output: 11.57 toks/s]
Processed prompts:  64%|   | 330/512 [00:28<00:16, 11.29it/s, est. speed input: 11841.20 toks/s, output: 11.56 toks/s]
Processed prompts:  65%|   | 334/512 [00:28<00:15, 11.23it/s, est. speed input: 11835.20 toks/s, output: 11.56 toks/s]
Processed prompts:  66%|   | 338/512 [00:29<00:15, 11.26it/s, est. speed input: 11832.48 toks/s, output: 11.56 toks/s]
Processed prompts:  67%|   | 342/512 [00:29<00:14, 11.77it/s, est. speed input: 11849.38 toks/s, output: 11.57 toks/s]
Processed prompts:  68%|   | 346/512 [00:29<00:14, 11.59it/s, est. speed input: 11844.61 toks/s, output: 11.57 toks/s]
Processed prompts:  68%|   | 350/512 [00:30<00:14, 11.52it/s, est. speed input: 11842.22 toks/s, output: 11.56 toks/s]
Processed prompts:  69%|   | 354/512 [00:30<00:13, 11.45it/s, est. speed input: 11838.93 toks/s, output: 11.56 toks/s]
Processed prompts:  70%|   | 358/512 [00:30<00:13, 11.36it/s, est. speed input: 11834.33 toks/s, output: 11.56 toks/s]
Processed prompts:  71%|   | 362/512 [00:31<00:13, 11.37it/s, est. speed input: 11832.28 toks/s, output: 11.55 toks/s]
Processed prompts:  71%|  | 366/512 [00:31<00:12, 11.35it/s, est. speed input: 11829.41 toks/s, output: 11.55 toks/s]
Processed prompts:  72%|  | 370/512 [00:32<00:12, 11.30it/s, est. speed input: 11825.37 toks/s, output: 11.55 toks/s]
Processed prompts:  73%|  | 374/512 [00:32<00:12, 11.32it/s, est. speed input: 11823.15 toks/s, output: 11.55 toks/s]
Processed prompts:  74%|  | 378/512 [00:32<00:11, 11.32it/s, est. speed input: 11820.67 toks/s, output: 11.54 toks/s]
Processed prompts:  75%|  | 382/512 [00:33<00:11, 11.26it/s, est. speed input: 11816.16 toks/s, output: 11.54 toks/s]
Processed prompts:  75%|  | 386/512 [00:33<00:11, 11.30it/s, est. speed input: 11814.69 toks/s, output: 11.54 toks/s]
Processed prompts:  76%|  | 390/512 [00:33<00:10, 11.31it/s, est. speed input: 11812.46 toks/s, output: 11.54 toks/s]
Processed prompts:  77%|  | 394/512 [00:34<00:10, 11.27it/s, est. speed input: 11808.59 toks/s, output: 11.53 toks/s]
Processed prompts:  78%|  | 398/512 [00:34<00:10, 11.29it/s, est. speed input: 11806.40 toks/s, output: 11.53 toks/s]
Processed prompts:  79%|  | 402/512 [00:34<00:09, 11.30it/s, est. speed input: 11804.48 toks/s, output: 11.53 toks/s]
Processed prompts:  79%|  | 406/512 [00:35<00:09, 11.23it/s, est. speed input: 11799.68 toks/s, output: 11.52 toks/s]
Processed prompts:  80%|  | 410/512 [00:35<00:09, 11.27it/s, est. speed input: 11797.84 toks/s, output: 11.52 toks/s]
Processed prompts:  81%|  | 414/512 [00:35<00:08, 11.28it/s, est. speed input: 11795.87 toks/s, output: 11.52 toks/s]
Processed prompts:  82%| | 418/512 [00:36<00:08, 11.25it/s, est. speed input: 11792.29 toks/s, output: 11.52 toks/s]
Processed prompts:  82%| | 422/512 [00:36<00:07, 11.28it/s, est. speed input: 11790.73 toks/s, output: 11.51 toks/s]
Processed prompts:  83%| | 426/512 [00:37<00:07, 11.29it/s, est. speed input: 11788.75 toks/s, output: 11.51 toks/s]
Processed prompts:  84%| | 430/512 [00:37<00:07, 11.25it/s, est. speed input: 11785.13 toks/s, output: 11.51 toks/s]
Processed prompts:  85%| | 434/512 [00:37<00:06, 11.27it/s, est. speed input: 11783.45 toks/s, output: 11.51 toks/s]
Processed prompts:  86%| | 438/512 [00:38<00:06, 11.29it/s, est. speed input: 11781.69 toks/s, output: 11.51 toks/s]
Processed prompts:  86%| | 442/512 [00:38<00:06, 11.24it/s, est. speed input: 11778.06 toks/s, output: 11.50 toks/s]
Processed prompts:  87%| | 446/512 [00:38<00:05, 11.26it/s, est. speed input: 11776.40 toks/s, output: 11.50 toks/s]
Processed prompts:  88%| | 450/512 [00:39<00:05, 11.93it/s, est. speed input: 11794.26 toks/s, output: 11.52 toks/s]
Processed prompts:  89%| | 454/512 [00:39<00:04, 11.72it/s, est. speed input: 11791.70 toks/s, output: 11.52 toks/s]
Processed prompts:  89%| | 458/512 [00:39<00:04, 11.60it/s, est. speed input: 11790.10 toks/s, output: 11.51 toks/s]
Processed prompts:  90%| | 462/512 [00:40<00:04, 11.52it/s, est. speed input: 11788.60 toks/s, output: 11.51 toks/s]
Processed prompts:  91%| | 466/512 [00:40<00:04, 11.41it/s, est. speed input: 11785.27 toks/s, output: 11.51 toks/s]
Processed prompts:  92%|| 470/512 [00:40<00:03, 11.38it/s, est. speed input: 11783.59 toks/s, output: 11.51 toks/s]
Processed prompts:  93%|| 474/512 [00:41<00:03, 11.36it/s, est. speed input: 11781.99 toks/s, output: 11.51 toks/s]
Processed prompts:  93%|| 478/512 [00:41<00:03, 11.32it/s, est. speed input: 11779.38 toks/s, output: 11.50 toks/s]
Processed prompts:  94%|| 482/512 [00:41<00:02, 11.29it/s, est. speed input: 11777.06 toks/s, output: 11.50 toks/s]
Processed prompts:  95%|| 486/512 [00:42<00:02, 11.31it/s, est. speed input: 11775.70 toks/s, output: 11.50 toks/s]
Processed prompts:  96%|| 490/512 [00:42<00:01, 11.24it/s, est. speed input: 11772.22 toks/s, output: 11.50 toks/s]
Processed prompts:  96%|| 494/512 [00:42<00:01, 11.29it/s, est. speed input: 11771.28 toks/s, output: 11.50 toks/s]
Processed prompts:  97%|| 498/512 [00:43<00:01, 11.30it/s, est. speed input: 11769.94 toks/s, output: 11.49 toks/s]
Processed prompts:  98%|| 502/512 [00:43<00:00, 11.26it/s, est. speed input: 11767.09 toks/s, output: 11.49 toks/s]
Processed prompts:  99%|| 506/512 [00:44<00:00, 11.29it/s, est. speed input: 11766.00 toks/s, output: 11.49 toks/s]
Processed prompts: 100%|| 510/512 [00:44<00:00, 12.01it/s, est. speed input: 11783.18 toks/s, output: 11.51 toks/s]
Processed prompts: 100%|| 512/512 [00:44<00:00, 12.01it/s, est. speed input: 11829.35 toks/s, output: 11.55 toks/s]
Processed prompts: 100%|| 512/512 [00:44<00:00, 11.55it/s, est. speed input: 11829.35 toks/s, output: 11.55 toks/s]
[rank0]:[W126 13:26:22.880117390 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-26 13:26:24
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-3B-FP8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 13:26:31 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 13:26:31 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1338943) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1338943) WARNING 01-26 13:27:08 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 11.41 requests/s, 11691.34 total tokens/s, 11.41 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-26 13:26:31] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 13:26:31] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 13:26:31] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 13:26:31] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:26:31] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:26:31] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:26:31] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:26:31] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:26:31] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 13:26:31] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:26:31] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:26:31] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:26:31] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:26:31] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 13:26:34] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 13:26:34] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 13:26:34] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 13:26:34] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:26:34] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:26:34] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:26:34] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:26:34] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:26:34] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 13:26:34] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:26:34] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:26:34] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:26:34] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:26:34] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1338943) [2026-01-26 13:26:35] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1338943) [2026-01-26 13:26:35] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1338943) [2026-01-26 13:26:35] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1338943) [2026-01-26 13:26:35] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1338943) [2026-01-26 13:26:35] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1338943) [2026-01-26 13:26:35] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1338943) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1338943) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:24<00:00, 24.43s/it]
(EngineCore_DP0 pid=1338943) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:24<00:00, 24.43s/it]
(EngineCore_DP0 pid=1338943) 
(EngineCore_DP0 pid=1338943) [2026-01-26 13:27:00] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4928] -> 1D uint8
(EngineCore_DP0 pid=1338943) [2026-01-26 13:27:01] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15810560 bytes
(EngineCore_DP0 pid=1338943) [2026-01-26 13:27:01] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4928] -> 1D uint8
(EngineCore_DP0 pid=1338943) [2026-01-26 13:27:01] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9486336 bytes
(EngineCore_DP0 pid=1338943) [2026-01-26 13:27:01] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4928] -> 1D uint8
(EngineCore_DP0 pid=1338943) [2026-01-26 13:27:01] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 50593792 bytes
(EngineCore_DP0 pid=1338943) [2026-01-26 13:27:01] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 13120] -> 1D uint8
(EngineCore_DP0 pid=1338943) [2026-01-26 13:27:01] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 25214976 bytes
(EngineCore_DP0 pid=1338943) 2026-01-26 13:27:06,693 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1338943) 2026-01-26 13:27:06,742 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   5%|         | 55/1024 [00:00<00:01, 547.05it/s]
Adding requests:  11%|         | 110/1024 [00:00<00:01, 492.00it/s]
Adding requests:  16%|        | 160/1024 [00:00<00:01, 489.00it/s]
Adding requests:  21%|        | 212/1024 [00:00<00:01, 498.49it/s]
Adding requests:  26%|       | 262/1024 [00:00<00:01, 498.96it/s]
Adding requests:  31%|       | 315/1024 [00:00<00:01, 505.70it/s]
Adding requests:  36%|      | 367/1024 [00:00<00:01, 509.87it/s]
Adding requests:  41%|      | 419/1024 [00:00<00:01, 510.02it/s]
Adding requests:  46%|     | 471/1024 [00:00<00:01, 494.62it/s]
Adding requests:  51%|     | 521/1024 [00:01<00:01, 489.71it/s]
Adding requests:  56%|    | 571/1024 [00:01<00:00, 470.85it/s]
Adding requests:  61%|    | 624/1024 [00:01<00:00, 485.95it/s]
Adding requests:  66%|   | 674/1024 [00:01<00:00, 487.85it/s]
Adding requests:  71%|   | 728/1024 [00:01<00:00, 501.53it/s]
Adding requests:  76%|  | 779/1024 [00:01<00:00, 496.06it/s]
Adding requests:  81%|  | 829/1024 [00:01<00:00, 489.07it/s]
Adding requests:  86%| | 878/1024 [00:01<00:00, 480.79it/s]
Adding requests:  91%| | 932/1024 [00:01<00:00, 494.75it/s]
Adding requests:  96%|| 983/1024 [00:01<00:00, 497.32it/s]
Adding requests: 100%|| 1024/1024 [00:02<00:00, 496.08it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 18/1024 [00:00<00:11, 89.45it/s, est. speed input: 91612.61 toks/s, output: 89.46 toks/s]
Processed prompts:   3%|         | 27/1024 [00:00<00:38, 25.75it/s, est. speed input: 30744.28 toks/s, output: 30.02 toks/s]
Processed prompts:   3%|         | 34/1024 [00:01<00:57, 17.26it/s, est. speed input: 21847.51 toks/s, output: 21.33 toks/s]
Processed prompts:   4%|         | 42/1024 [00:02<01:06, 14.70it/s, est. speed input: 18749.89 toks/s, output: 18.31 toks/s]
Processed prompts:   5%|         | 50/1024 [00:02<01:12, 13.48it/s, est. speed input: 17131.11 toks/s, output: 16.73 toks/s]
Processed prompts:   6%|         | 58/1024 [00:03<01:15, 12.76it/s, est. speed input: 16108.01 toks/s, output: 15.73 toks/s]
Processed prompts:   6%|         | 66/1024 [00:04<01:17, 12.33it/s, est. speed input: 15418.52 toks/s, output: 15.06 toks/s]
Processed prompts:   7%|         | 74/1024 [00:05<01:18, 12.09it/s, est. speed input: 14932.19 toks/s, output: 14.58 toks/s]
Processed prompts:   8%|         | 82/1024 [00:05<01:19, 11.87it/s, est. speed input: 14537.47 toks/s, output: 14.20 toks/s]
Processed prompts:   9%|         | 90/1024 [00:06<01:19, 11.74it/s, est. speed input: 14233.08 toks/s, output: 13.90 toks/s]
Processed prompts:  10%|         | 98/1024 [00:07<01:19, 11.68it/s, est. speed input: 14001.65 toks/s, output: 13.67 toks/s]
Processed prompts:  10%|         | 106/1024 [00:07<01:19, 11.61it/s, est. speed input: 13800.21 toks/s, output: 13.48 toks/s]
Processed prompts:  11%|         | 114/1024 [00:08<01:18, 11.54it/s, est. speed input: 13623.89 toks/s, output: 13.30 toks/s]
Processed prompts:  12%|        | 122/1024 [00:09<01:18, 11.53it/s, est. speed input: 13486.32 toks/s, output: 13.17 toks/s]
Processed prompts:  13%|        | 130/1024 [00:09<01:17, 11.50it/s, est. speed input: 13360.95 toks/s, output: 13.05 toks/s]
Processed prompts:  13%|        | 138/1024 [00:10<01:17, 11.48it/s, est. speed input: 13251.60 toks/s, output: 12.94 toks/s]
Processed prompts:  14%|        | 146/1024 [00:11<01:16, 11.51it/s, est. speed input: 13166.24 toks/s, output: 12.86 toks/s]
Processed prompts:  15%|        | 154/1024 [00:12<01:15, 11.47it/s, est. speed input: 13079.53 toks/s, output: 12.77 toks/s]
Processed prompts:  16%|        | 162/1024 [00:12<01:15, 11.46it/s, est. speed input: 13003.29 toks/s, output: 12.70 toks/s]
Processed prompts:  17%|        | 170/1024 [00:13<01:14, 11.47it/s, est. speed input: 12940.62 toks/s, output: 12.64 toks/s]
Processed prompts:  17%|        | 178/1024 [00:14<01:13, 11.45it/s, est. speed input: 12877.17 toks/s, output: 12.58 toks/s]
Processed prompts:  18%|        | 186/1024 [00:14<01:13, 11.44it/s, est. speed input: 12821.46 toks/s, output: 12.52 toks/s]
Processed prompts:  19%|        | 194/1024 [00:15<01:12, 11.47it/s, est. speed input: 12776.03 toks/s, output: 12.48 toks/s]
Processed prompts:  20%|        | 202/1024 [00:16<01:11, 11.44it/s, est. speed input: 12727.84 toks/s, output: 12.43 toks/s]
Processed prompts:  21%|        | 210/1024 [00:16<01:11, 11.45it/s, est. speed input: 12687.19 toks/s, output: 12.39 toks/s]
Processed prompts:  21%|       | 218/1024 [00:17<01:10, 11.46it/s, est. speed input: 12650.55 toks/s, output: 12.35 toks/s]
Processed prompts:  22%|       | 226/1024 [00:18<01:09, 11.45it/s, est. speed input: 12614.46 toks/s, output: 12.32 toks/s]
Processed prompts:  23%|       | 234/1024 [00:19<01:09, 11.45it/s, est. speed input: 12581.49 toks/s, output: 12.29 toks/s]
Processed prompts:  24%|       | 242/1024 [00:19<01:08, 11.46it/s, est. speed input: 12552.54 toks/s, output: 12.26 toks/s]
Processed prompts:  24%|       | 250/1024 [00:20<01:07, 11.45it/s, est. speed input: 12522.93 toks/s, output: 12.23 toks/s]
Processed prompts:  25%|       | 258/1024 [00:21<01:06, 11.44it/s, est. speed input: 12495.78 toks/s, output: 12.20 toks/s]
Processed prompts:  26%|       | 266/1024 [00:21<01:06, 11.47it/s, est. speed input: 12474.17 toks/s, output: 12.18 toks/s]
Processed prompts:  27%|       | 274/1024 [00:22<01:05, 11.44it/s, est. speed input: 12448.79 toks/s, output: 12.16 toks/s]
Processed prompts:  28%|       | 282/1024 [00:23<01:05, 11.41it/s, est. speed input: 12423.44 toks/s, output: 12.13 toks/s]
Processed prompts:  28%|       | 290/1024 [00:23<01:04, 11.44it/s, est. speed input: 12404.84 toks/s, output: 12.11 toks/s]
Processed prompts:  29%|       | 298/1024 [00:24<01:03, 11.44it/s, est. speed input: 12384.98 toks/s, output: 12.09 toks/s]
Processed prompts:  30%|       | 306/1024 [00:25<01:02, 11.44it/s, est. speed input: 12366.27 toks/s, output: 12.08 toks/s]
Processed prompts:  31%|       | 314/1024 [00:26<01:01, 11.46it/s, est. speed input: 12351.07 toks/s, output: 12.06 toks/s]
Processed prompts:  31%|      | 322/1024 [00:26<01:01, 11.45it/s, est. speed input: 12333.78 toks/s, output: 12.04 toks/s]
Processed prompts:  32%|      | 330/1024 [00:27<01:00, 11.46it/s, est. speed input: 12318.89 toks/s, output: 12.03 toks/s]
Processed prompts:  33%|      | 338/1024 [00:28<00:59, 11.54it/s, est. speed input: 12311.39 toks/s, output: 12.02 toks/s]
Processed prompts:  34%|      | 346/1024 [00:28<00:58, 11.51it/s, est. speed input: 12296.82 toks/s, output: 12.01 toks/s]
Processed prompts:  35%|      | 354/1024 [00:29<01:04, 10.47it/s, est. speed input: 12189.51 toks/s, output: 11.90 toks/s]
Processed prompts:  35%|      | 362/1024 [00:30<01:03, 10.41it/s, est. speed input: 12147.06 toks/s, output: 11.86 toks/s]
Processed prompts:  36%|      | 370/1024 [00:31<01:01, 10.68it/s, est. speed input: 12135.52 toks/s, output: 11.85 toks/s]
Processed prompts:  37%|      | 378/1024 [00:31<00:59, 10.88it/s, est. speed input: 12125.14 toks/s, output: 11.84 toks/s]
Processed prompts:  38%|      | 386/1024 [00:32<00:57, 11.04it/s, est. speed input: 12116.31 toks/s, output: 11.83 toks/s]
Processed prompts:  38%|      | 394/1024 [00:33<00:56, 11.15it/s, est. speed input: 12107.48 toks/s, output: 11.82 toks/s]
Processed prompts:  39%|      | 402/1024 [00:34<00:55, 11.22it/s, est. speed input: 12097.79 toks/s, output: 11.81 toks/s]
Processed prompts:  40%|      | 410/1024 [00:34<00:54, 11.30it/s, est. speed input: 12091.06 toks/s, output: 11.81 toks/s]
Processed prompts:  41%|      | 418/1024 [00:35<00:53, 11.32it/s, est. speed input: 12082.44 toks/s, output: 11.80 toks/s]
Processed prompts:  42%|     | 426/1024 [00:36<00:52, 11.35it/s, est. speed input: 12074.97 toks/s, output: 11.79 toks/s]
Processed prompts:  42%|     | 434/1024 [00:36<00:51, 11.40it/s, est. speed input: 12069.68 toks/s, output: 11.79 toks/s]
Processed prompts:  43%|     | 442/1024 [00:37<00:51, 11.39it/s, est. speed input: 12061.27 toks/s, output: 11.78 toks/s]
Processed prompts:  44%|     | 450/1024 [00:38<00:49, 11.68it/s, est. speed input: 12072.80 toks/s, output: 11.79 toks/s]
Processed prompts:  45%|     | 458/1024 [00:38<00:48, 11.64it/s, est. speed input: 12067.94 toks/s, output: 11.79 toks/s]
Processed prompts:  46%|     | 466/1024 [00:39<00:48, 11.56it/s, est. speed input: 12060.61 toks/s, output: 11.78 toks/s]
Processed prompts:  46%|     | 474/1024 [00:40<00:47, 11.52it/s, est. speed input: 12054.70 toks/s, output: 11.77 toks/s]
Processed prompts:  47%|     | 482/1024 [00:40<00:47, 11.52it/s, est. speed input: 12050.18 toks/s, output: 11.77 toks/s]
Processed prompts:  48%|     | 490/1024 [00:41<00:46, 11.49it/s, est. speed input: 12044.19 toks/s, output: 11.76 toks/s]
Processed prompts:  49%|     | 498/1024 [00:42<00:45, 11.48it/s, est. speed input: 12038.77 toks/s, output: 11.76 toks/s]
Processed prompts:  49%|     | 506/1024 [00:43<00:45, 11.46it/s, est. speed input: 12033.33 toks/s, output: 11.75 toks/s]
Processed prompts:  50%|     | 514/1024 [00:43<00:44, 11.44it/s, est. speed input: 12027.60 toks/s, output: 11.75 toks/s]
Processed prompts:  51%|     | 522/1024 [00:44<00:43, 11.47it/s, est. speed input: 12024.30 toks/s, output: 11.74 toks/s]
Processed prompts:  52%|    | 530/1024 [00:45<00:43, 11.44it/s, est. speed input: 12018.25 toks/s, output: 11.74 toks/s]
Processed prompts:  53%|    | 538/1024 [00:45<00:42, 11.42it/s, est. speed input: 12012.57 toks/s, output: 11.73 toks/s]
Processed prompts:  53%|    | 546/1024 [00:46<00:41, 11.43it/s, est. speed input: 12008.52 toks/s, output: 11.73 toks/s]
Processed prompts:  54%|    | 554/1024 [00:47<00:41, 11.41it/s, est. speed input: 12003.04 toks/s, output: 11.72 toks/s]
Processed prompts:  55%|    | 562/1024 [00:47<00:40, 11.41it/s, est. speed input: 11998.45 toks/s, output: 11.72 toks/s]
Processed prompts:  56%|    | 570/1024 [00:48<00:39, 11.43it/s, est. speed input: 11994.98 toks/s, output: 11.71 toks/s]
Processed prompts:  56%|    | 578/1024 [00:49<00:39, 11.40it/s, est. speed input: 11989.43 toks/s, output: 11.71 toks/s]
Processed prompts:  57%|    | 586/1024 [00:50<00:38, 11.39it/s, est. speed input: 11984.14 toks/s, output: 11.70 toks/s]
Processed prompts:  58%|    | 594/1024 [00:50<00:37, 11.41it/s, est. speed input: 11980.91 toks/s, output: 11.70 toks/s]
Processed prompts:  59%|    | 602/1024 [00:51<00:36, 11.41it/s, est. speed input: 11977.02 toks/s, output: 11.70 toks/s]
Processed prompts:  60%|    | 610/1024 [00:52<00:36, 11.40it/s, est. speed input: 11972.26 toks/s, output: 11.69 toks/s]
Processed prompts:  60%|    | 618/1024 [00:52<00:35, 11.43it/s, est. speed input: 11969.79 toks/s, output: 11.69 toks/s]
Processed prompts:  61%|    | 626/1024 [00:53<00:34, 11.41it/s, est. speed input: 11965.24 toks/s, output: 11.68 toks/s]
Processed prompts:  62%|   | 634/1024 [00:54<00:34, 11.40it/s, est. speed input: 11961.43 toks/s, output: 11.68 toks/s]
Processed prompts:  63%|   | 642/1024 [00:54<00:33, 11.43it/s, est. speed input: 11958.84 toks/s, output: 11.68 toks/s]
Processed prompts:  63%|   | 650/1024 [00:55<00:32, 11.41it/s, est. speed input: 11954.75 toks/s, output: 11.67 toks/s]
Processed prompts:  64%|   | 658/1024 [00:56<00:32, 11.40it/s, est. speed input: 11951.05 toks/s, output: 11.67 toks/s]
Processed prompts:  65%|   | 666/1024 [00:57<00:31, 11.42it/s, est. speed input: 11948.64 toks/s, output: 11.67 toks/s]
Processed prompts:  66%|   | 674/1024 [00:57<00:30, 11.40it/s, est. speed input: 11944.43 toks/s, output: 11.66 toks/s]
Processed prompts:  67%|   | 682/1024 [00:58<00:30, 11.40it/s, est. speed input: 11941.14 toks/s, output: 11.66 toks/s]
Processed prompts:  67%|   | 690/1024 [00:59<00:29, 11.43it/s, est. speed input: 11939.35 toks/s, output: 11.66 toks/s]
Processed prompts:  68%|   | 698/1024 [00:59<00:28, 11.39it/s, est. speed input: 11935.15 toks/s, output: 11.66 toks/s]
Processed prompts:  69%|   | 706/1024 [01:00<00:27, 11.38it/s, est. speed input: 11931.42 toks/s, output: 11.65 toks/s]
Processed prompts:  70%|   | 714/1024 [01:01<00:27, 11.41it/s, est. speed input: 11929.56 toks/s, output: 11.65 toks/s]
Processed prompts:  71%|   | 722/1024 [01:01<00:26, 11.40it/s, est. speed input: 11926.35 toks/s, output: 11.65 toks/s]
Processed prompts:  71%|  | 730/1024 [01:02<00:25, 11.39it/s, est. speed input: 11922.94 toks/s, output: 11.64 toks/s]
Processed prompts:  72%|  | 738/1024 [01:03<00:25, 11.39it/s, est. speed input: 11920.35 toks/s, output: 11.64 toks/s]
Processed prompts:  73%|  | 746/1024 [01:04<00:24, 11.39it/s, est. speed input: 11917.56 toks/s, output: 11.64 toks/s]
Processed prompts:  74%|  | 754/1024 [01:04<00:23, 11.40it/s, est. speed input: 11915.09 toks/s, output: 11.64 toks/s]
Processed prompts:  74%|  | 762/1024 [01:05<00:22, 11.41it/s, est. speed input: 11912.89 toks/s, output: 11.63 toks/s]
Processed prompts:  75%|  | 770/1024 [01:06<00:22, 11.41it/s, est. speed input: 11910.43 toks/s, output: 11.63 toks/s]
Processed prompts:  76%|  | 778/1024 [01:06<00:21, 11.42it/s, est. speed input: 11908.28 toks/s, output: 11.63 toks/s]
Processed prompts:  77%|  | 786/1024 [01:07<00:20, 11.43it/s, est. speed input: 11906.47 toks/s, output: 11.63 toks/s]
Processed prompts:  78%|  | 794/1024 [01:08<00:20, 11.41it/s, est. speed input: 11903.70 toks/s, output: 11.62 toks/s]
Processed prompts:  78%|  | 802/1024 [01:09<00:19, 11.40it/s, est. speed input: 11901.16 toks/s, output: 11.62 toks/s]
Processed prompts:  79%|  | 810/1024 [01:09<00:18, 11.44it/s, est. speed input: 11900.11 toks/s, output: 11.62 toks/s]
Processed prompts:  80%|  | 818/1024 [01:10<00:18, 11.41it/s, est. speed input: 11897.28 toks/s, output: 11.62 toks/s]
Processed prompts:  81%|  | 826/1024 [01:11<00:17, 11.41it/s, est. speed input: 11895.07 toks/s, output: 11.62 toks/s]
Processed prompts:  81%| | 834/1024 [01:11<00:16, 11.42it/s, est. speed input: 11893.38 toks/s, output: 11.61 toks/s]
Processed prompts:  82%| | 842/1024 [01:12<00:15, 11.41it/s, est. speed input: 11891.10 toks/s, output: 11.61 toks/s]
Processed prompts:  83%| | 850/1024 [01:13<00:15, 11.41it/s, est. speed input: 11889.20 toks/s, output: 11.61 toks/s]
Processed prompts:  84%| | 858/1024 [01:13<00:14, 11.41it/s, est. speed input: 11887.13 toks/s, output: 11.61 toks/s]
Processed prompts:  85%| | 866/1024 [01:14<00:13, 11.40it/s, est. speed input: 11884.86 toks/s, output: 11.61 toks/s]
Processed prompts:  85%| | 874/1024 [01:15<00:13, 11.43it/s, est. speed input: 11883.78 toks/s, output: 11.61 toks/s]
Processed prompts:  86%| | 882/1024 [01:16<00:12, 11.40it/s, est. speed input: 11881.34 toks/s, output: 11.60 toks/s]
Processed prompts:  87%| | 890/1024 [01:16<00:11, 11.38it/s, est. speed input: 11878.87 toks/s, output: 11.60 toks/s]
Processed prompts:  88%| | 898/1024 [01:17<00:11, 11.41it/s, est. speed input: 11877.74 toks/s, output: 11.60 toks/s]
Processed prompts:  88%| | 906/1024 [01:18<00:10, 11.39it/s, est. speed input: 11875.44 toks/s, output: 11.60 toks/s]
Processed prompts:  89%| | 914/1024 [01:18<00:09, 11.39it/s, est. speed input: 11873.37 toks/s, output: 11.60 toks/s]
Processed prompts:  90%| | 922/1024 [01:19<00:08, 11.40it/s, est. speed input: 11871.90 toks/s, output: 11.59 toks/s]
Processed prompts:  91%| | 930/1024 [01:20<00:08, 11.37it/s, est. speed input: 11869.30 toks/s, output: 11.59 toks/s]
Processed prompts:  92%|| 938/1024 [01:20<00:07, 11.75it/s, est. speed input: 11878.32 toks/s, output: 11.60 toks/s]
Processed prompts:  92%|| 946/1024 [01:21<00:06, 11.66it/s, est. speed input: 11877.25 toks/s, output: 11.60 toks/s]
Processed prompts:  93%|| 954/1024 [01:22<00:06, 11.58it/s, est. speed input: 11875.33 toks/s, output: 11.60 toks/s]
Processed prompts:  94%|| 962/1024 [01:22<00:05, 11.51it/s, est. speed input: 11873.29 toks/s, output: 11.60 toks/s]
Processed prompts:  95%|| 970/1024 [01:23<00:04, 11.51it/s, est. speed input: 11872.46 toks/s, output: 11.59 toks/s]
Processed prompts:  96%|| 978/1024 [01:24<00:04, 11.48it/s, est. speed input: 11870.84 toks/s, output: 11.59 toks/s]
Processed prompts:  96%|| 986/1024 [01:24<00:03, 11.84it/s, est. speed input: 11879.92 toks/s, output: 11.60 toks/s]
Processed prompts:  97%|| 994/1024 [01:25<00:02, 11.74it/s, est. speed input: 11879.00 toks/s, output: 11.60 toks/s]
Processed prompts:  98%|| 1002/1024 [01:26<00:01, 11.62it/s, est. speed input: 11876.96 toks/s, output: 11.60 toks/s]
Processed prompts:  99%|| 1010/1024 [01:27<00:01, 11.55it/s, est. speed input: 11875.37 toks/s, output: 11.60 toks/s]
Processed prompts:  99%|| 1018/1024 [01:27<00:00, 11.93it/s, est. speed input: 11884.99 toks/s, output: 11.61 toks/s]
Processed prompts: 100%|| 1024/1024 [01:27<00:00, 11.93it/s, est. speed input: 11955.01 toks/s, output: 11.67 toks/s]
Processed prompts: 100%|| 1024/1024 [01:27<00:00, 11.67it/s, est. speed input: 11955.01 toks/s, output: 11.67 toks/s]
[rank0]:[W126 13:28:38.232637485 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-26 13:28:40
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-3B-FP8_M16384.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 13:28:49 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 13:28:49 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1341035) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1341035) WARNING 01-26 13:29:28 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 11.57 requests/s, 11854.27 total tokens/s, 11.57 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-26 13:28:49] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 13:28:49] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 13:28:49] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 13:28:49] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:28:49] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:28:49] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:28:49] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:28:49] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:28:49] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 13:28:49] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:28:49] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:28:49] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:28:49] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:28:49] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 13:28:53] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 13:28:53] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 13:28:53] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 13:28:53] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:28:53] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:28:53] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:28:53] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:28:53] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:28:53] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 13:28:53] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:28:53] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:28:53] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:28:53] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:28:53] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1341035) [2026-01-26 13:28:54] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1341035) [2026-01-26 13:28:54] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1341035) [2026-01-26 13:28:54] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1341035) [2026-01-26 13:28:54] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1341035) [2026-01-26 13:28:54] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1341035) [2026-01-26 13:28:54] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1341035) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1341035) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:25<00:00, 25.00s/it]
(EngineCore_DP0 pid=1341035) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:25<00:00, 25.00s/it]
(EngineCore_DP0 pid=1341035) 
(EngineCore_DP0 pid=1341035) [2026-01-26 13:29:20] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4928] -> 1D uint8
(EngineCore_DP0 pid=1341035) [2026-01-26 13:29:20] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15810560 bytes
(EngineCore_DP0 pid=1341035) [2026-01-26 13:29:20] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4928] -> 1D uint8
(EngineCore_DP0 pid=1341035) [2026-01-26 13:29:20] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9486336 bytes
(EngineCore_DP0 pid=1341035) [2026-01-26 13:29:20] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4928] -> 1D uint8
(EngineCore_DP0 pid=1341035) [2026-01-26 13:29:20] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 50593792 bytes
(EngineCore_DP0 pid=1341035) [2026-01-26 13:29:20] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 13120] -> 1D uint8
(EngineCore_DP0 pid=1341035) [2026-01-26 13:29:20] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 25214976 bytes
(EngineCore_DP0 pid=1341035) 2026-01-26 13:29:26,672 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1341035) 2026-01-26 13:29:26,754 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   2%|         | 38/2048 [00:00<00:05, 370.73it/s]
Adding requests:   4%|         | 82/2048 [00:00<00:04, 406.03it/s]
Adding requests:   6%|         | 130/2048 [00:00<00:04, 438.80it/s]
Adding requests:   9%|         | 177/2048 [00:00<00:04, 448.87it/s]
Adding requests:  11%|         | 229/2048 [00:00<00:03, 472.05it/s]
Adding requests:  14%|        | 279/2048 [00:00<00:03, 479.17it/s]
Adding requests:  16%|        | 329/2048 [00:00<00:03, 483.38it/s]
Adding requests:  18%|        | 378/2048 [00:00<00:03, 479.67it/s]
Adding requests:  21%|        | 427/2048 [00:00<00:03, 480.47it/s]
Adding requests:  23%|       | 476/2048 [00:01<00:03, 479.04it/s]
Adding requests:  26%|       | 524/2048 [00:01<00:03, 471.97it/s]
Adding requests:  28%|       | 572/2048 [00:01<00:03, 474.32it/s]
Adding requests:  30%|       | 621/2048 [00:01<00:02, 477.16it/s]
Adding requests:  33%|      | 670/2048 [00:01<00:02, 478.82it/s]
Adding requests:  35%|      | 720/2048 [00:01<00:02, 482.80it/s]
Adding requests:  38%|      | 769/2048 [00:01<00:02, 455.04it/s]
Adding requests:  40%|      | 815/2048 [00:01<00:02, 446.62it/s]
Adding requests:  42%|     | 860/2048 [00:02<00:06, 183.95it/s]
Adding requests:  44%|     | 905/2048 [00:02<00:05, 222.03it/s]
Adding requests:  47%|     | 953/2048 [00:02<00:04, 265.23it/s]
Adding requests:  49%|     | 1004/2048 [00:02<00:03, 311.05it/s]
Adding requests:  51%|     | 1049/2048 [00:02<00:02, 340.96it/s]
Adding requests:  54%|    | 1097/2048 [00:02<00:02, 373.75it/s]
Adding requests:  56%|    | 1144/2048 [00:02<00:02, 396.12it/s]
Adding requests:  58%|    | 1194/2048 [00:03<00:02, 423.25it/s]
Adding requests:  61%|    | 1241/2048 [00:03<00:01, 430.82it/s]
Adding requests:  63%|   | 1289/2048 [00:03<00:01, 443.38it/s]
Adding requests:  65%|   | 1339/2048 [00:03<00:01, 457.41it/s]
Adding requests:  68%|   | 1389/2048 [00:03<00:01, 468.29it/s]
Adding requests:  70%|   | 1438/2048 [00:03<00:01, 472.80it/s]
Adding requests:  73%|  | 1488/2048 [00:03<00:01, 479.61it/s]
Adding requests:  75%|  | 1540/2048 [00:03<00:01, 489.48it/s]
Adding requests:  78%|  | 1594/2048 [00:03<00:00, 503.75it/s]
Adding requests:  80%|  | 1645/2048 [00:03<00:00, 500.63it/s]
Adding requests:  83%| | 1696/2048 [00:04<00:00, 482.52it/s]
Adding requests:  85%| | 1745/2048 [00:04<00:00, 482.57it/s]
Adding requests:  88%| | 1794/2048 [00:04<00:00, 483.99it/s]
Adding requests:  90%| | 1843/2048 [00:04<00:00, 474.95it/s]
Adding requests:  92%|| 1892/2048 [00:04<00:00, 476.95it/s]
Adding requests:  95%|| 1940/2048 [00:04<00:00, 476.12it/s]
Adding requests:  97%|| 1990/2048 [00:04<00:00, 481.72it/s]
Adding requests: 100%|| 2039/2048 [00:04<00:00, 459.07it/s]
Adding requests: 100%|| 2048/2048 [00:04<00:00, 422.02it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 50/2048 [00:00<00:33, 59.58it/s, est. speed input: 61014.89 toks/s, output: 59.58 toks/s]
Processed prompts:   3%|         | 66/2048 [00:02<01:16, 26.06it/s, est. speed input: 30601.48 toks/s, output: 29.88 toks/s]
Processed prompts:   4%|         | 82/2048 [00:03<01:44, 18.76it/s, est. speed input: 23358.86 toks/s, output: 22.81 toks/s]
Processed prompts:   5%|         | 98/2048 [00:04<02:03, 15.77it/s, est. speed input: 20172.02 toks/s, output: 19.70 toks/s]
Processed prompts:   6%|         | 114/2048 [00:06<02:16, 14.21it/s, est. speed input: 18370.33 toks/s, output: 17.94 toks/s]
Processed prompts:   6%|         | 130/2048 [00:07<02:24, 13.28it/s, est. speed input: 17198.80 toks/s, output: 16.80 toks/s]
Processed prompts:   7%|         | 146/2048 [00:09<02:29, 12.73it/s, est. speed input: 16394.16 toks/s, output: 16.01 toks/s]
Processed prompts:   8%|         | 162/2048 [00:10<02:32, 12.35it/s, est. speed input: 15794.76 toks/s, output: 15.42 toks/s]
Processed prompts:   9%|         | 178/2048 [00:11<02:34, 12.11it/s, est. speed input: 15337.63 toks/s, output: 14.98 toks/s]
Processed prompts:   9%|         | 194/2048 [00:13<02:35, 11.94it/s, est. speed input: 14972.47 toks/s, output: 14.62 toks/s]
Processed prompts:  10%|         | 210/2048 [00:14<02:35, 11.83it/s, est. speed input: 14677.82 toks/s, output: 14.33 toks/s]
Processed prompts:  11%|         | 226/2048 [00:16<02:34, 11.76it/s, est. speed input: 14437.04 toks/s, output: 14.10 toks/s]
Processed prompts:  12%|        | 242/2048 [00:17<02:34, 11.69it/s, est. speed input: 14226.40 toks/s, output: 13.89 toks/s]
Processed prompts:  13%|        | 258/2048 [00:18<02:33, 11.66it/s, est. speed input: 14054.12 toks/s, output: 13.72 toks/s]
Processed prompts:  13%|        | 274/2048 [00:20<02:32, 11.65it/s, est. speed input: 13906.65 toks/s, output: 13.58 toks/s]
Processed prompts:  14%|        | 290/2048 [00:21<02:31, 11.62it/s, est. speed input: 13774.64 toks/s, output: 13.45 toks/s]
Processed prompts:  15%|        | 306/2048 [00:22<02:29, 11.62it/s, est. speed input: 13661.44 toks/s, output: 13.34 toks/s]
Processed prompts:  16%|        | 322/2048 [00:24<02:28, 11.59it/s, est. speed input: 13555.35 toks/s, output: 13.24 toks/s]
Processed prompts:  17%|        | 338/2048 [00:25<02:26, 11.69it/s, est. speed input: 13485.33 toks/s, output: 13.17 toks/s]
Processed prompts:  17%|        | 354/2048 [00:27<02:25, 11.65it/s, est. speed input: 13400.15 toks/s, output: 13.09 toks/s]
Processed prompts:  18%|        | 370/2048 [00:28<02:24, 11.62it/s, est. speed input: 13324.67 toks/s, output: 13.01 toks/s]
Processed prompts:  19%|        | 386/2048 [00:29<02:23, 11.58it/s, est. speed input: 13251.53 toks/s, output: 12.94 toks/s]
Processed prompts:  20%|        | 402/2048 [00:31<02:22, 11.56it/s, est. speed input: 13186.97 toks/s, output: 12.88 toks/s]
Processed prompts:  20%|        | 418/2048 [00:32<02:21, 11.56it/s, est. speed input: 13128.96 toks/s, output: 12.82 toks/s]
Processed prompts:  21%|        | 434/2048 [00:33<02:19, 11.56it/s, est. speed input: 13076.03 toks/s, output: 12.77 toks/s]
Processed prompts:  22%|       | 450/2048 [00:35<02:17, 11.66it/s, est. speed input: 13043.02 toks/s, output: 12.74 toks/s]
Processed prompts:  23%|       | 466/2048 [00:36<02:16, 11.63it/s, est. speed input: 12996.65 toks/s, output: 12.69 toks/s]
Processed prompts:  24%|       | 482/2048 [00:38<02:14, 11.61it/s, est. speed input: 12955.03 toks/s, output: 12.65 toks/s]
Processed prompts:  24%|       | 498/2048 [00:39<02:13, 11.57it/s, est. speed input: 12913.08 toks/s, output: 12.61 toks/s]
Processed prompts:  25%|       | 514/2048 [00:40<02:12, 11.57it/s, est. speed input: 12876.24 toks/s, output: 12.57 toks/s]
Processed prompts:  26%|       | 530/2048 [00:42<02:11, 11.57it/s, est. speed input: 12843.25 toks/s, output: 12.54 toks/s]
Processed prompts:  27%|       | 546/2048 [00:43<02:09, 11.56it/s, est. speed input: 12809.99 toks/s, output: 12.51 toks/s]
Processed prompts:  27%|       | 562/2048 [00:45<02:08, 11.55it/s, est. speed input: 12779.63 toks/s, output: 12.48 toks/s]
Processed prompts:  28%|       | 578/2048 [00:46<02:07, 11.55it/s, est. speed input: 12751.37 toks/s, output: 12.45 toks/s]
Processed prompts:  29%|       | 594/2048 [00:47<02:06, 11.54it/s, est. speed input: 12723.11 toks/s, output: 12.42 toks/s]
Processed prompts:  30%|       | 610/2048 [00:49<02:04, 11.53it/s, est. speed input: 12696.81 toks/s, output: 12.40 toks/s]
Processed prompts:  31%|       | 626/2048 [00:50<02:03, 11.53it/s, est. speed input: 12672.74 toks/s, output: 12.38 toks/s]
Processed prompts:  31%|      | 642/2048 [00:51<02:01, 11.53it/s, est. speed input: 12649.69 toks/s, output: 12.35 toks/s]
Processed prompts:  32%|      | 658/2048 [00:53<02:00, 11.53it/s, est. speed input: 12627.12 toks/s, output: 12.33 toks/s]
Processed prompts:  33%|      | 674/2048 [00:54<01:59, 11.53it/s, est. speed input: 12606.65 toks/s, output: 12.31 toks/s]
Processed prompts:  34%|      | 690/2048 [00:56<01:57, 11.54it/s, est. speed input: 12587.36 toks/s, output: 12.29 toks/s]
Processed prompts:  34%|      | 706/2048 [00:57<01:56, 11.51it/s, est. speed input: 12566.59 toks/s, output: 12.27 toks/s]
Processed prompts:  35%|      | 722/2048 [00:58<01:55, 11.53it/s, est. speed input: 12549.53 toks/s, output: 12.26 toks/s]
Processed prompts:  36%|      | 738/2048 [01:00<01:53, 11.52it/s, est. speed input: 12532.12 toks/s, output: 12.24 toks/s]
Processed prompts:  37%|      | 754/2048 [01:01<01:52, 11.51it/s, est. speed input: 12514.51 toks/s, output: 12.22 toks/s]
Processed prompts:  38%|      | 770/2048 [01:03<01:50, 11.52it/s, est. speed input: 12499.20 toks/s, output: 12.21 toks/s]
Processed prompts:  38%|      | 786/2048 [01:04<01:49, 11.52it/s, est. speed input: 12483.87 toks/s, output: 12.19 toks/s]
Processed prompts:  39%|      | 802/2048 [01:05<01:48, 11.50it/s, est. speed input: 12467.74 toks/s, output: 12.18 toks/s]
Processed prompts:  40%|      | 818/2048 [01:07<01:46, 11.51it/s, est. speed input: 12454.11 toks/s, output: 12.16 toks/s]
Processed prompts:  41%|      | 834/2048 [01:08<01:45, 11.51it/s, est. speed input: 12440.55 toks/s, output: 12.15 toks/s]
Processed prompts:  42%|     | 850/2048 [01:10<01:44, 11.51it/s, est. speed input: 12427.90 toks/s, output: 12.14 toks/s]
Processed prompts:  42%|     | 866/2048 [01:11<01:42, 11.50it/s, est. speed input: 12414.85 toks/s, output: 12.12 toks/s]
Processed prompts:  43%|     | 882/2048 [01:12<01:41, 11.50it/s, est. speed input: 12402.19 toks/s, output: 12.11 toks/s]
Processed prompts:  44%|     | 898/2048 [01:14<01:39, 11.51it/s, est. speed input: 12391.38 toks/s, output: 12.10 toks/s]
Processed prompts:  45%|     | 914/2048 [01:15<01:38, 11.50it/s, est. speed input: 12379.61 toks/s, output: 12.09 toks/s]
Processed prompts:  45%|     | 930/2048 [01:16<01:35, 11.71it/s, est. speed input: 12382.11 toks/s, output: 12.09 toks/s]
Processed prompts:  46%|     | 946/2048 [01:18<01:34, 11.65it/s, est. speed input: 12371.83 toks/s, output: 12.08 toks/s]
Processed prompts:  47%|     | 962/2048 [01:19<01:33, 11.60it/s, est. speed input: 12361.19 toks/s, output: 12.07 toks/s]
Processed prompts:  48%|     | 978/2048 [01:21<01:30, 11.78it/s, est. speed input: 12363.68 toks/s, output: 12.07 toks/s]
Processed prompts:  49%|     | 994/2048 [01:22<01:30, 11.70it/s, est. speed input: 12353.96 toks/s, output: 12.06 toks/s]
Processed prompts:  49%|     | 1010/2048 [01:23<01:29, 11.65it/s, est. speed input: 12345.07 toks/s, output: 12.06 toks/s]
Processed prompts:  50%|     | 1026/2048 [01:25<01:28, 11.60it/s, est. speed input: 12335.58 toks/s, output: 12.05 toks/s]
Processed prompts:  51%|     | 1042/2048 [01:26<01:26, 11.57it/s, est. speed input: 12326.38 toks/s, output: 12.04 toks/s]
Processed prompts:  52%|    | 1058/2048 [01:27<01:25, 11.56it/s, est. speed input: 12318.48 toks/s, output: 12.03 toks/s]
Processed prompts:  52%|    | 1074/2048 [01:29<01:24, 11.54it/s, est. speed input: 12309.86 toks/s, output: 12.02 toks/s]
Processed prompts:  53%|    | 1090/2048 [01:30<01:22, 11.54it/s, est. speed input: 12302.53 toks/s, output: 12.01 toks/s]
Processed prompts:  54%|    | 1106/2048 [01:32<01:21, 11.53it/s, est. speed input: 12294.65 toks/s, output: 12.01 toks/s]
Processed prompts:  55%|    | 1122/2048 [01:33<01:20, 11.52it/s, est. speed input: 12286.75 toks/s, output: 12.00 toks/s]
Processed prompts:  56%|    | 1138/2048 [01:34<01:18, 11.52it/s, est. speed input: 12279.77 toks/s, output: 11.99 toks/s]
Processed prompts:  56%|    | 1154/2048 [01:36<01:16, 11.73it/s, est. speed input: 12283.49 toks/s, output: 12.00 toks/s]
Processed prompts:  57%|    | 1170/2048 [01:37<01:15, 11.68it/s, est. speed input: 12277.16 toks/s, output: 11.99 toks/s]
Processed prompts:  58%|    | 1186/2048 [01:38<01:14, 11.62it/s, est. speed input: 12269.61 toks/s, output: 11.98 toks/s]
Processed prompts:  59%|    | 1202/2048 [01:40<01:12, 11.59it/s, est. speed input: 12263.35 toks/s, output: 11.98 toks/s]
Processed prompts:  59%|    | 1218/2048 [01:41<01:11, 11.57it/s, est. speed input: 12256.96 toks/s, output: 11.97 toks/s]
Processed prompts:  60%|    | 1234/2048 [01:43<01:10, 11.54it/s, est. speed input: 12249.83 toks/s, output: 11.96 toks/s]
Processed prompts:  61%|    | 1250/2048 [01:44<01:09, 11.54it/s, est. speed input: 12244.30 toks/s, output: 11.96 toks/s]
Processed prompts:  62%|   | 1266/2048 [01:45<01:06, 11.74it/s, est. speed input: 12247.74 toks/s, output: 11.96 toks/s]
Processed prompts:  63%|   | 1282/2048 [01:47<01:05, 11.69it/s, est. speed input: 12242.46 toks/s, output: 11.96 toks/s]
Processed prompts:  63%|   | 1298/2048 [01:48<01:04, 11.64it/s, est. speed input: 12236.95 toks/s, output: 11.95 toks/s]
Processed prompts:  64%|   | 1314/2048 [01:50<01:03, 11.60it/s, est. speed input: 12231.27 toks/s, output: 11.94 toks/s]
Processed prompts:  65%|   | 1330/2048 [01:51<01:02, 11.58it/s, est. speed input: 12225.94 toks/s, output: 11.94 toks/s]
Processed prompts:  66%|   | 1346/2048 [01:52<01:00, 11.55it/s, est. speed input: 12220.00 toks/s, output: 11.93 toks/s]
Processed prompts:  67%|   | 1362/2048 [01:54<00:59, 11.54it/s, est. speed input: 12215.08 toks/s, output: 11.93 toks/s]
Processed prompts:  67%|   | 1378/2048 [01:55<00:58, 11.54it/s, est. speed input: 12210.21 toks/s, output: 11.92 toks/s]
Processed prompts:  68%|   | 1394/2048 [01:56<00:56, 11.52it/s, est. speed input: 12204.61 toks/s, output: 11.92 toks/s]
Processed prompts:  69%|   | 1410/2048 [01:58<00:55, 11.53it/s, est. speed input: 12200.33 toks/s, output: 11.91 toks/s]
Processed prompts:  70%|   | 1426/2048 [01:59<00:53, 11.53it/s, est. speed input: 12195.64 toks/s, output: 11.91 toks/s]
Processed prompts:  70%|   | 1442/2048 [02:01<00:52, 11.51it/s, est. speed input: 12190.59 toks/s, output: 11.90 toks/s]
Processed prompts:  71%|   | 1458/2048 [02:02<00:51, 11.53it/s, est. speed input: 12186.62 toks/s, output: 11.90 toks/s]
Processed prompts:  72%|  | 1474/2048 [02:03<00:49, 11.53it/s, est. speed input: 12182.39 toks/s, output: 11.90 toks/s]
Processed prompts:  73%|  | 1490/2048 [02:05<00:48, 11.52it/s, est. speed input: 12177.88 toks/s, output: 11.89 toks/s]
Processed prompts:  74%|  | 1506/2048 [02:06<00:47, 11.53it/s, est. speed input: 12173.91 toks/s, output: 11.89 toks/s]
Processed prompts:  74%|  | 1522/2048 [02:08<00:45, 11.53it/s, est. speed input: 12170.05 toks/s, output: 11.88 toks/s]
Processed prompts:  75%|  | 1538/2048 [02:09<00:44, 11.52it/s, est. speed input: 12165.86 toks/s, output: 11.88 toks/s]
Processed prompts:  76%|  | 1554/2048 [02:10<00:42, 11.50it/s, est. speed input: 12161.24 toks/s, output: 11.88 toks/s]
Processed prompts:  77%|  | 1570/2048 [02:12<00:41, 11.51it/s, est. speed input: 12157.45 toks/s, output: 11.87 toks/s]
Processed prompts:  77%|  | 1586/2048 [02:13<00:39, 11.71it/s, est. speed input: 12160.71 toks/s, output: 11.88 toks/s]
Processed prompts:  78%|  | 1602/2048 [02:14<00:38, 11.64it/s, est. speed input: 12156.55 toks/s, output: 11.87 toks/s]
Processed prompts:  79%|  | 1618/2048 [02:16<00:37, 11.61it/s, est. speed input: 12153.14 toks/s, output: 11.87 toks/s]
Processed prompts:  80%|  | 1634/2048 [02:17<00:35, 11.59it/s, est. speed input: 12149.68 toks/s, output: 11.86 toks/s]
Processed prompts:  81%|  | 1650/2048 [02:19<00:34, 11.56it/s, est. speed input: 12145.81 toks/s, output: 11.86 toks/s]
Processed prompts:  81%| | 1666/2048 [02:20<00:33, 11.54it/s, est. speed input: 12142.18 toks/s, output: 11.86 toks/s]
Processed prompts:  82%| | 1682/2048 [02:21<00:31, 11.53it/s, est. speed input: 12138.70 toks/s, output: 11.85 toks/s]
Processed prompts:  83%| | 1698/2048 [02:23<00:30, 11.53it/s, est. speed input: 12135.61 toks/s, output: 11.85 toks/s]
Processed prompts:  84%| | 1714/2048 [02:24<00:28, 11.52it/s, est. speed input: 12132.17 toks/s, output: 11.85 toks/s]
Processed prompts:  84%| | 1730/2048 [02:26<00:27, 11.54it/s, est. speed input: 12129.38 toks/s, output: 11.85 toks/s]
Processed prompts:  85%| | 1746/2048 [02:27<00:26, 11.52it/s, est. speed input: 12125.74 toks/s, output: 11.84 toks/s]
Processed prompts:  86%| | 1762/2048 [02:28<00:24, 11.51it/s, est. speed input: 12122.60 toks/s, output: 11.84 toks/s]
Processed prompts:  87%| | 1778/2048 [02:30<00:23, 11.53it/s, est. speed input: 12120.06 toks/s, output: 11.84 toks/s]
Processed prompts:  88%| | 1794/2048 [02:31<00:22, 11.51it/s, est. speed input: 12116.67 toks/s, output: 11.83 toks/s]
Processed prompts:  88%| | 1810/2048 [02:33<00:20, 11.50it/s, est. speed input: 12113.29 toks/s, output: 11.83 toks/s]
Processed prompts:  89%| | 1826/2048 [02:34<00:19, 11.51it/s, est. speed input: 12110.66 toks/s, output: 11.83 toks/s]
Processed prompts:  90%| | 1842/2048 [02:35<00:17, 11.51it/s, est. speed input: 12107.66 toks/s, output: 11.82 toks/s]
Processed prompts:  91%| | 1858/2048 [02:37<00:16, 11.49it/s, est. speed input: 12104.35 toks/s, output: 11.82 toks/s]
Processed prompts:  92%|| 1874/2048 [02:38<00:14, 11.71it/s, est. speed input: 12107.83 toks/s, output: 11.82 toks/s]
Processed prompts:  92%|| 1890/2048 [02:39<00:13, 11.66it/s, est. speed input: 12105.32 toks/s, output: 11.82 toks/s]
Processed prompts:  93%|| 1906/2048 [02:41<00:12, 11.62it/s, est. speed input: 12102.71 toks/s, output: 11.82 toks/s]
Processed prompts:  94%|| 1922/2048 [02:42<00:10, 11.58it/s, est. speed input: 12099.75 toks/s, output: 11.82 toks/s]
Processed prompts:  95%|| 1938/2048 [02:44<00:09, 11.57it/s, est. speed input: 12097.40 toks/s, output: 11.81 toks/s]
Processed prompts:  95%|| 1954/2048 [02:45<00:07, 11.76it/s, est. speed input: 12100.84 toks/s, output: 11.82 toks/s]
Processed prompts:  96%|| 1970/2048 [02:46<00:06, 11.67it/s, est. speed input: 12097.94 toks/s, output: 11.81 toks/s]
Processed prompts:  97%|| 1986/2048 [02:48<00:05, 11.63it/s, est. speed input: 12095.51 toks/s, output: 11.81 toks/s]
Processed prompts:  98%|| 2002/2048 [02:49<00:03, 11.59it/s, est. speed input: 12092.96 toks/s, output: 11.81 toks/s]
Processed prompts:  99%|| 2018/2048 [02:50<00:02, 11.56it/s, est. speed input: 12090.21 toks/s, output: 11.81 toks/s]
Processed prompts:  99%|| 2034/2048 [02:52<00:01, 11.74it/s, est. speed input: 12093.29 toks/s, output: 11.81 toks/s]
Processed prompts: 100%|| 2048/2048 [02:52<00:00, 11.74it/s, est. speed input: 12176.51 toks/s, output: 11.89 toks/s]
Processed prompts: 100%|| 2048/2048 [02:52<00:00, 11.89it/s, est. speed input: 12176.51 toks/s, output: 11.89 toks/s]
[rank0]:[W126 13:32:26.181402137 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-26 13:32:28
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-3B-FP8_M32768.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 13:32:43 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 13:32:43 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1344426) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1344426) WARNING 01-26 13:33:24 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 11.59 requests/s, 11877.37 total tokens/s, 11.59 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-26 13:32:43] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 13:32:43] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 13:32:43] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 13:32:43] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:32:43] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:32:43] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:32:43] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:32:43] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:32:43] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 13:32:43] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:32:43] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:32:43] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:32:43] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:32:43] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 13:32:46] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 13:32:46] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 13:32:46] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 13:32:46] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:32:46] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:32:46] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:32:46] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:32:46] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:32:46] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 13:32:46] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:32:46] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:32:46] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:32:46] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:32:46] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1344426) [2026-01-26 13:32:47] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1344426) [2026-01-26 13:32:47] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1344426) [2026-01-26 13:32:47] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1344426) [2026-01-26 13:32:47] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1344426) [2026-01-26 13:32:47] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1344426) [2026-01-26 13:32:47] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1344426) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1344426) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:24<00:00, 24.21s/it]
(EngineCore_DP0 pid=1344426) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:24<00:00, 24.21s/it]
(EngineCore_DP0 pid=1344426) 
(EngineCore_DP0 pid=1344426) [2026-01-26 13:33:12] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4928] -> 1D uint8
(EngineCore_DP0 pid=1344426) [2026-01-26 13:33:12] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15810560 bytes
(EngineCore_DP0 pid=1344426) [2026-01-26 13:33:13] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4928] -> 1D uint8
(EngineCore_DP0 pid=1344426) [2026-01-26 13:33:13] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9486336 bytes
(EngineCore_DP0 pid=1344426) [2026-01-26 13:33:13] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4928] -> 1D uint8
(EngineCore_DP0 pid=1344426) [2026-01-26 13:33:13] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 50593792 bytes
(EngineCore_DP0 pid=1344426) [2026-01-26 13:33:13] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 13120] -> 1D uint8
(EngineCore_DP0 pid=1344426) [2026-01-26 13:33:13] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 25214976 bytes
(EngineCore_DP0 pid=1344426) 2026-01-26 13:33:20,661 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1344426) 2026-01-26 13:33:20,942 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|         | 58/4096 [00:00<00:07, 573.51it/s]
Adding requests:   3%|         | 116/4096 [00:00<00:07, 526.09it/s]
Adding requests:   4%|         | 169/4096 [00:00<00:07, 510.68it/s]
Adding requests:   5%|         | 221/4096 [00:00<00:07, 495.50it/s]
Adding requests:   7%|         | 273/4096 [00:00<00:07, 503.59it/s]
Adding requests:   8%|         | 324/4096 [00:00<00:07, 493.50it/s]
Adding requests:   9%|         | 377/4096 [00:00<00:07, 502.21it/s]
Adding requests:  10%|         | 428/4096 [00:00<00:07, 501.78it/s]
Adding requests:  12%|        | 480/4096 [00:00<00:07, 506.99it/s]
Adding requests:  13%|        | 531/4096 [00:01<00:07, 495.95it/s]
Adding requests:  14%|        | 585/4096 [00:01<00:06, 507.11it/s]
Adding requests:  16%|        | 636/4096 [00:01<00:06, 507.93it/s]
Adding requests:  17%|        | 687/4096 [00:01<00:06, 506.70it/s]
Adding requests:  18%|        | 738/4096 [00:01<00:06, 507.01it/s]
Adding requests:  19%|        | 789/4096 [00:01<00:06, 501.61it/s]
Adding requests:  21%|        | 840/4096 [00:01<00:06, 492.52it/s]
Adding requests:  22%|       | 893/4096 [00:01<00:06, 499.54it/s]
Adding requests:  23%|       | 944/4096 [00:01<00:06, 500.59it/s]
Adding requests:  24%|       | 996/4096 [00:01<00:06, 504.84it/s]
Adding requests:  26%|       | 1048/4096 [00:02<00:06, 507.74it/s]
Adding requests:  27%|       | 1099/4096 [00:02<00:05, 506.20it/s]
Adding requests:  28%|       | 1150/4096 [00:02<00:05, 501.09it/s]
Adding requests:  29%|       | 1201/4096 [00:02<00:06, 472.06it/s]
Adding requests:  31%|       | 1252/4096 [00:02<00:05, 480.49it/s]
Adding requests:  32%|      | 1301/4096 [00:02<00:05, 480.18it/s]
Adding requests:  33%|      | 1352/4096 [00:02<00:05, 488.07it/s]
Adding requests:  34%|      | 1404/4096 [00:02<00:05, 495.70it/s]
Adding requests:  36%|      | 1455/4096 [00:02<00:05, 499.77it/s]
Adding requests:  37%|      | 1506/4096 [00:03<00:05, 492.16it/s]
Adding requests:  38%|      | 1559/4096 [00:03<00:05, 501.84it/s]
Adding requests:  39%|      | 1612/4096 [00:03<00:04, 507.90it/s]
Adding requests:  41%|      | 1663/4096 [00:03<00:04, 504.45it/s]
Adding requests:  42%|     | 1714/4096 [00:03<00:04, 502.70it/s]
Adding requests:  43%|     | 1766/4096 [00:03<00:04, 506.49it/s]
Adding requests:  44%|     | 1817/4096 [00:03<00:04, 507.48it/s]
Adding requests:  46%|     | 1868/4096 [00:03<00:04, 501.27it/s]
Adding requests:  47%|     | 1919/4096 [00:03<00:04, 502.50it/s]
Adding requests:  48%|     | 1970/4096 [00:03<00:04, 504.35it/s]
Adding requests:  49%|     | 2024/4096 [00:04<00:04, 514.03it/s]
Adding requests:  51%|     | 2077/4096 [00:04<00:03, 517.26it/s]
Adding requests:  52%|    | 2129/4096 [00:04<00:03, 511.38it/s]
Adding requests:  53%|    | 2181/4096 [00:04<00:03, 496.16it/s]
Adding requests:  54%|    | 2231/4096 [00:04<00:03, 496.56it/s]
Adding requests:  56%|    | 2283/4096 [00:04<00:03, 501.66it/s]
Adding requests:  57%|    | 2334/4096 [00:04<00:03, 500.45it/s]
Adding requests:  58%|    | 2387/4096 [00:04<00:03, 507.16it/s]
Adding requests:  60%|    | 2438/4096 [00:04<00:03, 475.01it/s]
Adding requests:  61%|    | 2487/4096 [00:04<00:03, 479.21it/s]
Adding requests:  62%|   | 2538/4096 [00:05<00:03, 487.93it/s]
Adding requests:  63%|   | 2589/4096 [00:05<00:03, 494.08it/s]
Adding requests:  64%|   | 2641/4096 [00:05<00:02, 501.25it/s]
Adding requests:  66%|   | 2692/4096 [00:05<00:02, 502.69it/s]
Adding requests:  67%|   | 2743/4096 [00:05<00:02, 495.99it/s]
Adding requests:  68%|   | 2793/4096 [00:05<00:02, 494.85it/s]
Adding requests:  69%|   | 2846/4096 [00:05<00:02, 505.17it/s]
Adding requests:  71%|   | 2897/4096 [00:05<00:02, 494.70it/s]
Adding requests:  72%|  | 2947/4096 [00:05<00:02, 496.21it/s]
Adding requests:  73%|  | 2997/4096 [00:05<00:02, 495.83it/s]
Adding requests:  74%|  | 3047/4096 [00:06<00:02, 491.11it/s]
Adding requests:  76%|  | 3097/4096 [00:06<00:02, 483.55it/s]
Adding requests:  77%|  | 3146/4096 [00:06<00:01, 484.33it/s]
Adding requests:  78%|  | 3197/4096 [00:06<00:01, 491.41it/s]
Adding requests:  79%|  | 3248/4096 [00:06<00:01, 495.39it/s]
Adding requests:  81%|  | 3300/4096 [00:06<00:01, 500.32it/s]
Adding requests:  82%| | 3351/4096 [00:06<00:01, 497.88it/s]
Adding requests:  83%| | 3402/4096 [00:06<00:01, 499.88it/s]
Adding requests:  84%| | 3453/4096 [00:06<00:01, 502.61it/s]
Adding requests:  86%| | 3504/4096 [00:07<00:01, 500.80it/s]
Adding requests:  87%| | 3556/4096 [00:07<00:01, 503.29it/s]
Adding requests:  88%| | 3607/4096 [00:07<00:00, 503.87it/s]
Adding requests:  89%| | 3659/4096 [00:07<00:00, 508.27it/s]
Adding requests:  91%| | 3712/4096 [00:07<00:00, 513.80it/s]
Adding requests:  92%|| 3765/4096 [00:07<00:00, 517.95it/s]
Adding requests:  93%|| 3817/4096 [00:07<00:00, 476.45it/s]
Adding requests:  94%|| 3870/4096 [00:07<00:00, 491.21it/s]
Adding requests:  96%|| 3921/4096 [00:07<00:00, 495.61it/s]
Adding requests:  97%|| 3974/4096 [00:07<00:00, 505.08it/s]
Adding requests:  98%|| 4026/4096 [00:08<00:00, 504.83it/s]
Adding requests: 100%|| 4077/4096 [00:08<00:00, 496.87it/s]
Adding requests: 100%|| 4096/4096 [00:08<00:00, 499.54it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 66/4096 [00:00<00:16, 249.23it/s, est. speed input: 255230.42 toks/s, output: 249.24 toks/s]
Processed prompts:   2%|         | 98/4096 [00:03<02:30, 26.60it/s, est. speed input: 33233.97 toks/s, output: 32.45 toks/s]   
Processed prompts:   3%|         | 130/4096 [00:05<03:40, 17.99it/s, est. speed input: 23016.75 toks/s, output: 22.48 toks/s]
Processed prompts:   4%|         | 162/4096 [00:08<04:20, 15.11it/s, est. speed input: 19418.67 toks/s, output: 18.96 toks/s]
Processed prompts:   5%|         | 194/4096 [00:11<04:44, 13.74it/s, est. speed input: 17574.61 toks/s, output: 17.16 toks/s]
Processed prompts:   6%|         | 226/4096 [00:14<04:58, 12.96it/s, est. speed input: 16448.62 toks/s, output: 16.06 toks/s]
Processed prompts:   6%|         | 258/4096 [00:16<05:07, 12.50it/s, est. speed input: 15700.46 toks/s, output: 15.33 toks/s]
Processed prompts:   7%|         | 290/4096 [00:19<05:12, 12.19it/s, est. speed input: 15153.64 toks/s, output: 14.80 toks/s]
Processed prompts:   8%|         | 322/4096 [00:22<05:12, 12.08it/s, est. speed input: 14783.73 toks/s, output: 14.44 toks/s]
Processed prompts:   9%|         | 354/4096 [00:25<05:14, 11.91it/s, est. speed input: 14456.68 toks/s, output: 14.12 toks/s]
Processed prompts:   9%|         | 386/4096 [00:27<05:14, 11.80it/s, est. speed input: 14195.64 toks/s, output: 13.86 toks/s]
Processed prompts:  10%|         | 418/4096 [00:30<05:13, 11.73it/s, est. speed input: 13982.67 toks/s, output: 13.65 toks/s]
Processed prompts:  11%|         | 450/4096 [00:33<05:10, 11.75it/s, est. speed input: 13827.83 toks/s, output: 13.50 toks/s]
Processed prompts:  12%|        | 482/4096 [00:36<05:08, 11.70it/s, est. speed input: 13676.74 toks/s, output: 13.36 toks/s]
Processed prompts:  13%|        | 514/4096 [00:38<05:07, 11.65it/s, est. speed input: 13544.52 toks/s, output: 13.23 toks/s]
Processed prompts:  13%|        | 546/4096 [00:41<05:05, 11.62it/s, est. speed input: 13429.35 toks/s, output: 13.11 toks/s]
Processed prompts:  14%|        | 578/4096 [00:44<05:03, 11.60it/s, est. speed input: 13329.56 toks/s, output: 13.02 toks/s]
Processed prompts:  15%|        | 610/4096 [00:47<05:00, 11.58it/s, est. speed input: 13240.99 toks/s, output: 12.93 toks/s]
Processed prompts:  16%|        | 642/4096 [00:49<04:58, 11.57it/s, est. speed input: 13162.66 toks/s, output: 12.85 toks/s]
Processed prompts:  16%|        | 674/4096 [00:52<04:55, 11.57it/s, est. speed input: 13092.38 toks/s, output: 12.79 toks/s]
Processed prompts:  17%|        | 706/4096 [00:55<04:53, 11.55it/s, est. speed input: 13027.15 toks/s, output: 12.72 toks/s]
Processed prompts:  18%|        | 738/4096 [00:58<04:50, 11.55it/s, est. speed input: 12970.12 toks/s, output: 12.67 toks/s]
Processed prompts:  19%|        | 770/4096 [01:01<04:48, 11.54it/s, est. speed input: 12917.39 toks/s, output: 12.61 toks/s]
Processed prompts:  20%|        | 802/4096 [01:03<04:45, 11.55it/s, est. speed input: 12870.25 toks/s, output: 12.57 toks/s]
Processed prompts:  20%|        | 834/4096 [01:06<04:42, 11.55it/s, est. speed input: 12826.98 toks/s, output: 12.53 toks/s]
Processed prompts:  21%|        | 866/4096 [01:09<04:39, 11.54it/s, est. speed input: 12786.22 toks/s, output: 12.49 toks/s]
Processed prompts:  22%|       | 898/4096 [01:12<04:36, 11.55it/s, est. speed input: 12750.11 toks/s, output: 12.45 toks/s]
Processed prompts:  23%|       | 930/4096 [01:14<04:32, 11.63it/s, est. speed input: 12727.18 toks/s, output: 12.43 toks/s]
Processed prompts:  23%|       | 962/4096 [01:17<04:27, 11.70it/s, est. speed input: 12706.49 toks/s, output: 12.41 toks/s]
Processed prompts:  24%|       | 994/4096 [01:20<04:26, 11.65it/s, est. speed input: 12675.89 toks/s, output: 12.38 toks/s]
Processed prompts:  25%|       | 1026/4096 [01:23<04:24, 11.61it/s, est. speed input: 12646.72 toks/s, output: 12.35 toks/s]
Processed prompts:  26%|       | 1058/4096 [01:25<04:22, 11.59it/s, est. speed input: 12620.11 toks/s, output: 12.32 toks/s]
Processed prompts:  27%|       | 1090/4096 [01:28<04:19, 11.57it/s, est. speed input: 12594.71 toks/s, output: 12.30 toks/s]
Processed prompts:  27%|       | 1122/4096 [01:31<04:17, 11.56it/s, est. speed input: 12570.68 toks/s, output: 12.28 toks/s]
Processed prompts:  28%|       | 1154/4096 [01:34<04:12, 11.64it/s, est. speed input: 12558.03 toks/s, output: 12.26 toks/s]
Processed prompts:  29%|       | 1186/4096 [01:36<04:10, 11.61it/s, est. speed input: 12536.25 toks/s, output: 12.24 toks/s]
Processed prompts:  30%|       | 1218/4096 [01:39<04:08, 11.59it/s, est. speed input: 12516.73 toks/s, output: 12.22 toks/s]
Processed prompts:  31%|       | 1250/4096 [01:42<04:03, 11.67it/s, est. speed input: 12506.57 toks/s, output: 12.21 toks/s]
Processed prompts:  31%|      | 1282/4096 [01:45<04:01, 11.63it/s, est. speed input: 12488.74 toks/s, output: 12.20 toks/s]
Processed prompts:  32%|      | 1314/4096 [01:47<03:59, 11.60it/s, est. speed input: 12471.10 toks/s, output: 12.18 toks/s]
Processed prompts:  33%|      | 1346/4096 [01:50<03:57, 11.58it/s, est. speed input: 12454.66 toks/s, output: 12.16 toks/s]
Processed prompts:  34%|      | 1378/4096 [01:53<03:55, 11.56it/s, est. speed input: 12438.58 toks/s, output: 12.15 toks/s]
Processed prompts:  34%|      | 1410/4096 [01:56<03:52, 11.56it/s, est. speed input: 12424.02 toks/s, output: 12.13 toks/s]
Processed prompts:  35%|      | 1442/4096 [01:58<03:49, 11.55it/s, est. speed input: 12409.81 toks/s, output: 12.12 toks/s]
Processed prompts:  36%|      | 1474/4096 [02:01<03:47, 11.55it/s, est. speed input: 12396.14 toks/s, output: 12.11 toks/s]
Processed prompts:  37%|      | 1506/4096 [02:04<03:44, 11.54it/s, est. speed input: 12382.78 toks/s, output: 12.09 toks/s]
Processed prompts:  38%|      | 1538/4096 [02:07<03:41, 11.54it/s, est. speed input: 12370.38 toks/s, output: 12.08 toks/s]
Processed prompts:  38%|      | 1570/4096 [02:10<03:37, 11.63it/s, est. speed input: 12365.33 toks/s, output: 12.08 toks/s]
Processed prompts:  39%|      | 1602/4096 [02:12<03:34, 11.61it/s, est. speed input: 12354.31 toks/s, output: 12.06 toks/s]
Processed prompts:  40%|      | 1634/4096 [02:15<03:32, 11.58it/s, est. speed input: 12342.76 toks/s, output: 12.05 toks/s]
Processed prompts:  41%|      | 1666/4096 [02:18<03:30, 11.56it/s, est. speed input: 12331.97 toks/s, output: 12.04 toks/s]
Processed prompts:  41%|     | 1698/4096 [02:21<03:27, 11.57it/s, est. speed input: 12322.84 toks/s, output: 12.03 toks/s]
Processed prompts:  42%|     | 1730/4096 [02:23<03:24, 11.56it/s, est. speed input: 12312.81 toks/s, output: 12.02 toks/s]
Processed prompts:  43%|     | 1762/4096 [02:26<03:22, 11.55it/s, est. speed input: 12303.46 toks/s, output: 12.02 toks/s]
Processed prompts:  44%|     | 1794/4096 [02:29<03:19, 11.55it/s, est. speed input: 12294.57 toks/s, output: 12.01 toks/s]
Processed prompts:  45%|     | 1826/4096 [02:32<03:16, 11.54it/s, est. speed input: 12285.43 toks/s, output: 12.00 toks/s]
Processed prompts:  45%|     | 1858/4096 [02:34<03:12, 11.63it/s, est. speed input: 12282.83 toks/s, output: 11.99 toks/s]
Processed prompts:  46%|     | 1890/4096 [02:37<03:10, 11.60it/s, est. speed input: 12274.33 toks/s, output: 11.99 toks/s]
Processed prompts:  47%|     | 1922/4096 [02:40<03:07, 11.58it/s, est. speed input: 12266.55 toks/s, output: 11.98 toks/s]
Processed prompts:  48%|     | 1954/4096 [02:43<03:03, 11.65it/s, est. speed input: 12263.83 toks/s, output: 11.98 toks/s]
Processed prompts:  48%|     | 1986/4096 [02:45<03:01, 11.62it/s, est. speed input: 12256.20 toks/s, output: 11.97 toks/s]
Processed prompts:  49%|     | 2018/4096 [02:48<02:59, 11.59it/s, est. speed input: 12248.71 toks/s, output: 11.96 toks/s]
Processed prompts:  50%|     | 2050/4096 [02:51<02:56, 11.57it/s, est. speed input: 12241.50 toks/s, output: 11.95 toks/s]
Processed prompts:  51%|     | 2082/4096 [02:54<02:54, 11.56it/s, est. speed input: 12234.83 toks/s, output: 11.95 toks/s]
Processed prompts:  52%|    | 2114/4096 [02:57<02:51, 11.55it/s, est. speed input: 12227.80 toks/s, output: 11.94 toks/s]
Processed prompts:  52%|    | 2146/4096 [02:59<02:48, 11.54it/s, est. speed input: 12221.37 toks/s, output: 11.93 toks/s]
Processed prompts:  53%|    | 2178/4096 [03:02<02:46, 11.55it/s, est. speed input: 12215.41 toks/s, output: 11.93 toks/s]
Processed prompts:  54%|    | 2210/4096 [03:05<02:40, 11.74it/s, est. speed input: 12219.68 toks/s, output: 11.93 toks/s]
Processed prompts:  55%|    | 2242/4096 [03:07<02:38, 11.68it/s, est. speed input: 12213.84 toks/s, output: 11.93 toks/s]
Processed prompts:  56%|    | 2274/4096 [03:10<02:35, 11.72it/s, est. speed input: 12212.10 toks/s, output: 11.93 toks/s]
Processed prompts:  56%|    | 2306/4096 [03:13<02:33, 11.67it/s, est. speed input: 12206.57 toks/s, output: 11.92 toks/s]
Processed prompts:  57%|    | 2338/4096 [03:16<02:30, 11.72it/s, est. speed input: 12205.32 toks/s, output: 11.92 toks/s]
Processed prompts:  58%|    | 2370/4096 [03:18<02:25, 11.88it/s, est. speed input: 12210.33 toks/s, output: 11.92 toks/s]
Processed prompts:  59%|    | 2402/4096 [03:21<02:23, 11.77it/s, est. speed input: 12204.58 toks/s, output: 11.92 toks/s]
Processed prompts:  59%|    | 2434/4096 [03:24<02:22, 11.69it/s, est. speed input: 12198.76 toks/s, output: 11.91 toks/s]
Processed prompts:  60%|    | 2466/4096 [03:27<02:19, 11.65it/s, est. speed input: 12193.84 toks/s, output: 11.91 toks/s]
Processed prompts:  61%|    | 2498/4096 [03:29<02:16, 11.70it/s, est. speed input: 12192.61 toks/s, output: 11.91 toks/s]
Processed prompts:  62%|   | 2530/4096 [03:32<02:14, 11.65it/s, est. speed input: 12187.86 toks/s, output: 11.90 toks/s]
Processed prompts:  63%|   | 2562/4096 [03:35<02:11, 11.70it/s, est. speed input: 12186.62 toks/s, output: 11.90 toks/s]
Processed prompts:  63%|   | 2594/4096 [03:38<02:08, 11.64it/s, est. speed input: 12181.67 toks/s, output: 11.90 toks/s]
Processed prompts:  64%|   | 2626/4096 [03:40<02:06, 11.61it/s, est. speed input: 12177.05 toks/s, output: 11.89 toks/s]
Processed prompts:  65%|   | 2658/4096 [03:43<02:04, 11.58it/s, est. speed input: 12172.18 toks/s, output: 11.89 toks/s]
Processed prompts:  66%|   | 2690/4096 [03:46<02:01, 11.57it/s, est. speed input: 12167.94 toks/s, output: 11.88 toks/s]
Processed prompts:  66%|   | 2722/4096 [03:49<01:58, 11.55it/s, est. speed input: 12163.19 toks/s, output: 11.88 toks/s]
Processed prompts:  67%|   | 2754/4096 [03:51<01:56, 11.54it/s, est. speed input: 12158.77 toks/s, output: 11.87 toks/s]
Processed prompts:  68%|   | 2786/4096 [03:54<01:53, 11.55it/s, est. speed input: 12155.13 toks/s, output: 11.87 toks/s]
Processed prompts:  69%|   | 2818/4096 [03:57<01:50, 11.54it/s, est. speed input: 12150.83 toks/s, output: 11.87 toks/s]
Processed prompts:  70%|   | 2850/4096 [04:00<01:48, 11.53it/s, est. speed input: 12146.75 toks/s, output: 11.86 toks/s]
Processed prompts:  70%|   | 2882/4096 [04:03<01:45, 11.53it/s, est. speed input: 12142.77 toks/s, output: 11.86 toks/s]
Processed prompts:  71%|   | 2914/4096 [04:05<01:42, 11.52it/s, est. speed input: 12138.59 toks/s, output: 11.85 toks/s]
Processed prompts:  72%|  | 2946/4096 [04:08<01:39, 11.53it/s, est. speed input: 12135.00 toks/s, output: 11.85 toks/s]
Processed prompts:  73%|  | 2978/4096 [04:11<01:37, 11.52it/s, est. speed input: 12131.24 toks/s, output: 11.85 toks/s]
Processed prompts:  73%|  | 3010/4096 [04:14<01:34, 11.53it/s, est. speed input: 12127.90 toks/s, output: 11.84 toks/s]
Processed prompts:  74%|  | 3042/4096 [04:16<01:31, 11.52it/s, est. speed input: 12124.10 toks/s, output: 11.84 toks/s]
Processed prompts:  75%|  | 3074/4096 [04:19<01:28, 11.52it/s, est. speed input: 12120.61 toks/s, output: 11.84 toks/s]
Processed prompts:  76%|  | 3106/4096 [04:22<01:25, 11.52it/s, est. speed input: 12117.29 toks/s, output: 11.83 toks/s]
Processed prompts:  77%|  | 3138/4096 [04:25<01:22, 11.61it/s, est. speed input: 12116.98 toks/s, output: 11.83 toks/s]
Processed prompts:  77%|  | 3170/4096 [04:27<01:19, 11.58it/s, est. speed input: 12113.64 toks/s, output: 11.83 toks/s]
Processed prompts:  78%|  | 3202/4096 [04:30<01:17, 11.56it/s, est. speed input: 12110.49 toks/s, output: 11.83 toks/s]
Processed prompts:  79%|  | 3234/4096 [04:33<01:14, 11.55it/s, est. speed input: 12107.34 toks/s, output: 11.82 toks/s]
Processed prompts:  80%|  | 3266/4096 [04:36<01:11, 11.55it/s, est. speed input: 12104.35 toks/s, output: 11.82 toks/s]
Processed prompts:  81%|  | 3298/4096 [04:39<01:09, 11.53it/s, est. speed input: 12101.16 toks/s, output: 11.82 toks/s]
Processed prompts:  81%| | 3330/4096 [04:41<01:06, 11.53it/s, est. speed input: 12098.20 toks/s, output: 11.81 toks/s]
Processed prompts:  82%| | 3362/4096 [04:44<01:03, 11.53it/s, est. speed input: 12095.30 toks/s, output: 11.81 toks/s]
Processed prompts:  83%| | 3394/4096 [04:47<01:00, 11.52it/s, est. speed input: 12092.34 toks/s, output: 11.81 toks/s]
Processed prompts:  84%| | 3426/4096 [04:50<00:58, 11.53it/s, est. speed input: 12089.65 toks/s, output: 11.81 toks/s]
Processed prompts:  84%| | 3458/4096 [04:52<00:55, 11.52it/s, est. speed input: 12086.70 toks/s, output: 11.80 toks/s]
Processed prompts:  85%| | 3490/4096 [04:55<00:51, 11.74it/s, est. speed input: 12091.07 toks/s, output: 11.81 toks/s]
Processed prompts:  86%| | 3522/4096 [04:58<00:49, 11.67it/s, est. speed input: 12088.28 toks/s, output: 11.80 toks/s]
Processed prompts:  87%| | 3554/4096 [05:01<00:46, 11.63it/s, est. speed input: 12085.63 toks/s, output: 11.80 toks/s]
Processed prompts:  88%| | 3586/4096 [05:03<00:43, 11.60it/s, est. speed input: 12083.05 toks/s, output: 11.80 toks/s]
Processed prompts:  88%| | 3618/4096 [05:06<00:41, 11.57it/s, est. speed input: 12080.42 toks/s, output: 11.80 toks/s]
Processed prompts:  89%| | 3650/4096 [05:09<00:38, 11.56it/s, est. speed input: 12078.04 toks/s, output: 11.79 toks/s]
Processed prompts:  90%| | 3682/4096 [05:12<00:35, 11.55it/s, est. speed input: 12075.66 toks/s, output: 11.79 toks/s]
Processed prompts:  91%| | 3714/4096 [05:14<00:32, 11.63it/s, est. speed input: 12075.83 toks/s, output: 11.79 toks/s]
Processed prompts:  91%|| 3746/4096 [05:17<00:30, 11.60it/s, est. speed input: 12073.43 toks/s, output: 11.79 toks/s]
Processed prompts:  92%|| 3778/4096 [05:20<00:27, 11.57it/s, est. speed input: 12071.03 toks/s, output: 11.79 toks/s]
Processed prompts:  93%|| 3810/4096 [05:23<00:24, 11.57it/s, est. speed input: 12068.92 toks/s, output: 11.79 toks/s]
Processed prompts:  94%|| 3842/4096 [05:25<00:21, 11.64it/s, est. speed input: 12069.19 toks/s, output: 11.79 toks/s]
Processed prompts:  95%|| 3874/4096 [05:28<00:19, 11.60it/s, est. speed input: 12066.69 toks/s, output: 11.78 toks/s]
Processed prompts:  95%|| 3906/4096 [05:31<00:16, 11.58it/s, est. speed input: 12064.57 toks/s, output: 11.78 toks/s]
Processed prompts:  96%|| 3938/4096 [05:34<00:13, 11.55it/s, est. speed input: 12062.12 toks/s, output: 11.78 toks/s]
Processed prompts:  97%|| 3970/4096 [05:37<00:10, 11.55it/s, est. speed input: 12060.00 toks/s, output: 11.78 toks/s]
Processed prompts:  98%|| 4002/4096 [05:39<00:08, 11.54it/s, est. speed input: 12057.89 toks/s, output: 11.78 toks/s]
Processed prompts:  98%|| 4034/4096 [05:42<00:05, 11.62it/s, est. speed input: 12058.29 toks/s, output: 11.78 toks/s]
Processed prompts:  99%|| 4066/4096 [05:45<00:02, 11.68it/s, est. speed input: 12058.70 toks/s, output: 11.78 toks/s]
Processed prompts: 100%|| 4096/4096 [05:45<00:00, 11.68it/s, est. speed input: 12147.66 toks/s, output: 11.86 toks/s]
Processed prompts: 100%|| 4096/4096 [05:45<00:00, 11.86it/s, est. speed input: 12147.66 toks/s, output: 11.86 toks/s]
[rank0]:[W126 13:39:18.338405801 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-26 13:39:20
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Llama3.2-3B-FP8_M65536.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 13:39:46 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 13:39:47 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1350441) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1350441) WARNING 01-26 13:40:33 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 11.61 requests/s, 11905.29 total tokens/s, 11.61 output tokens/s
Total num prompt tokens:  8388608
Total num output tokens:  8192

STDERR:
[2026-01-26 13:39:46] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 13:39:46] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 13:39:46] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 13:39:46] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:39:46] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:39:46] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:39:46] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:39:46] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:39:46] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 13:39:46] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:39:46] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:39:46] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:39:46] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:39:46] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 13:39:50] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 13:39:50] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 13:39:50] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 13:39:50] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:39:50] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:39:50] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:39:50] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:39:50] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:39:50] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 13:39:50] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:39:50] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:39:50] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:39:50] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:39:50] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1350441) [2026-01-26 13:39:51] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1350441) [2026-01-26 13:39:51] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1350441) [2026-01-26 13:39:51] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1350441) [2026-01-26 13:39:51] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1350441) [2026-01-26 13:39:51] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1350441) [2026-01-26 13:39:51] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1350441) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1350441) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:24<00:00, 24.68s/it]
(EngineCore_DP0 pid=1350441) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:24<00:00, 24.68s/it]
(EngineCore_DP0 pid=1350441) 
(EngineCore_DP0 pid=1350441) [2026-01-26 13:40:17] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4928] -> 1D uint8
(EngineCore_DP0 pid=1350441) [2026-01-26 13:40:17] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15810560 bytes
(EngineCore_DP0 pid=1350441) [2026-01-26 13:40:17] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4928] -> 1D uint8
(EngineCore_DP0 pid=1350441) [2026-01-26 13:40:17] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9486336 bytes
(EngineCore_DP0 pid=1350441) [2026-01-26 13:40:17] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4928] -> 1D uint8
(EngineCore_DP0 pid=1350441) [2026-01-26 13:40:17] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 50593792 bytes
(EngineCore_DP0 pid=1350441) [2026-01-26 13:40:17] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 13120] -> 1D uint8
(EngineCore_DP0 pid=1350441) [2026-01-26 13:40:17] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 25214976 bytes
(EngineCore_DP0 pid=1350441) 2026-01-26 13:40:27,393 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1350441) 2026-01-26 13:40:27,724 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/8192 [00:00<?, ?it/s]
Adding requests:   1%|          | 57/8192 [00:00<00:14, 566.98it/s]
Adding requests:   1%|         | 114/8192 [00:00<00:15, 521.36it/s]
Adding requests:   2%|         | 167/8192 [00:00<00:15, 518.75it/s]
Adding requests:   3%|         | 219/8192 [00:00<00:15, 502.51it/s]
Adding requests:   3%|         | 274/8192 [00:00<00:15, 514.28it/s]
Adding requests:   4%|         | 326/8192 [00:00<00:15, 503.46it/s]
Adding requests:   5%|         | 379/8192 [00:00<00:15, 511.37it/s]
Adding requests:   5%|         | 432/8192 [00:00<00:15, 515.25it/s]
Adding requests:   6%|         | 485/8192 [00:00<00:14, 518.09it/s]
Adding requests:   7%|         | 537/8192 [00:01<00:15, 507.18it/s]
Adding requests:   7%|         | 593/8192 [00:01<00:14, 522.42it/s]
Adding requests:   8%|         | 646/8192 [00:01<00:14, 521.85it/s]
Adding requests:   9%|         | 699/8192 [00:01<00:14, 510.27it/s]
Adding requests:   9%|         | 752/8192 [00:01<00:14, 514.67it/s]
Adding requests:  10%|         | 804/8192 [00:01<00:14, 506.91it/s]
Adding requests:  10%|         | 859/8192 [00:01<00:14, 517.89it/s]
Adding requests:  11%|         | 911/8192 [00:01<00:14, 515.86it/s]
Adding requests:  12%|        | 968/8192 [00:01<00:13, 529.47it/s]
Adding requests:  12%|        | 1021/8192 [00:01<00:13, 512.26it/s]
Adding requests:  13%|        | 1076/8192 [00:02<00:13, 518.69it/s]
Adding requests:  14%|        | 1128/8192 [00:02<00:13, 504.68it/s]
Adding requests:  14%|        | 1180/8192 [00:02<00:13, 507.13it/s]
Adding requests:  15%|        | 1233/8192 [00:02<00:13, 511.60it/s]
Adding requests:  16%|        | 1285/8192 [00:02<00:13, 508.21it/s]
Adding requests:  16%|        | 1336/8192 [00:02<00:13, 507.97it/s]
Adding requests:  17%|        | 1387/8192 [00:02<00:13, 505.29it/s]
Adding requests:  18%|        | 1439/8192 [00:02<00:13, 509.40it/s]
Adding requests:  18%|        | 1493/8192 [00:02<00:12, 516.28it/s]
Adding requests:  19%|        | 1545/8192 [00:03<00:12, 515.68it/s]
Adding requests:  20%|        | 1598/8192 [00:03<00:12, 519.22it/s]
Adding requests:  20%|        | 1651/8192 [00:03<00:12, 521.13it/s]
Adding requests:  21%|        | 1704/8192 [00:03<00:12, 512.47it/s]
Adding requests:  21%|       | 1759/8192 [00:03<00:12, 523.20it/s]
Adding requests:  22%|       | 1812/8192 [00:03<00:12, 523.05it/s]
Adding requests:  23%|       | 1866/8192 [00:03<00:11, 528.01it/s]
Adding requests:  23%|       | 1919/8192 [00:03<00:12, 505.26it/s]
Adding requests:  24%|       | 1975/8192 [00:03<00:12, 517.23it/s]
Adding requests:  25%|       | 2027/8192 [00:03<00:12, 510.46it/s]
Adding requests:  25%|       | 2084/8192 [00:04<00:11, 526.17it/s]
Adding requests:  26%|       | 2137/8192 [00:04<00:11, 512.57it/s]
Adding requests:  27%|       | 2190/8192 [00:04<00:11, 516.09it/s]
Adding requests:  27%|       | 2242/8192 [00:04<00:11, 517.15it/s]
Adding requests:  28%|       | 2297/8192 [00:04<00:11, 526.17it/s]
Adding requests:  29%|       | 2351/8192 [00:04<00:11, 527.78it/s]
Adding requests:  29%|       | 2404/8192 [00:04<00:10, 528.27it/s]
Adding requests:  30%|       | 2457/8192 [00:04<00:10, 527.74it/s]
Adding requests:  31%|       | 2511/8192 [00:04<00:10, 529.36it/s]
Adding requests:  31%|      | 2565/8192 [00:04<00:10, 529.85it/s]
Adding requests:  32%|      | 2618/8192 [00:05<00:10, 526.49it/s]
Adding requests:  33%|      | 2671/8192 [00:05<00:10, 522.29it/s]
Adding requests:  33%|      | 2725/8192 [00:05<00:10, 525.85it/s]
Adding requests:  34%|      | 2778/8192 [00:05<00:10, 519.06it/s]
Adding requests:  35%|      | 2832/8192 [00:05<00:10, 524.87it/s]
Adding requests:  35%|      | 2885/8192 [00:05<00:10, 525.95it/s]
Adding requests:  36%|      | 2938/8192 [00:05<00:10, 518.68it/s]
Adding requests:  36%|      | 2990/8192 [00:05<00:10, 498.01it/s]
Adding requests:  37%|      | 3043/8192 [00:05<00:10, 506.81it/s]
Adding requests:  38%|      | 3096/8192 [00:05<00:09, 511.71it/s]
Adding requests:  38%|      | 3148/8192 [00:06<00:09, 512.59it/s]
Adding requests:  39%|      | 3203/8192 [00:06<00:09, 522.96it/s]
Adding requests:  40%|      | 3256/8192 [00:06<00:10, 486.07it/s]
Adding requests:  40%|      | 3313/8192 [00:06<00:09, 507.15it/s]
Adding requests:  41%|      | 3365/8192 [00:06<00:09, 504.08it/s]
Adding requests:  42%|     | 3424/8192 [00:06<00:09, 526.23it/s]
Adding requests:  42%|     | 3477/8192 [00:06<00:09, 503.44it/s]
Adding requests:  43%|     | 3530/8192 [00:06<00:09, 510.85it/s]
Adding requests:  44%|     | 3583/8192 [00:06<00:08, 514.62it/s]
Adding requests:  44%|     | 3636/8192 [00:07<00:08, 517.26it/s]
Adding requests:  45%|     | 3689/8192 [00:07<00:08, 517.14it/s]
Adding requests:  46%|     | 3741/8192 [00:07<00:08, 512.84it/s]
Adding requests:  46%|     | 3796/8192 [00:07<00:08, 522.45it/s]
Adding requests:  47%|     | 3851/8192 [00:07<00:08, 528.94it/s]
Adding requests:  48%|     | 3904/8192 [00:07<00:08, 528.11it/s]
Adding requests:  48%|     | 3960/8192 [00:07<00:07, 535.29it/s]
Adding requests:  49%|     | 4014/8192 [00:07<00:07, 535.73it/s]
Adding requests:  50%|     | 4068/8192 [00:07<00:07, 533.07it/s]
Adding requests:  50%|     | 4123/8192 [00:07<00:07, 536.32it/s]
Adding requests:  51%|     | 4177/8192 [00:08<00:07, 537.00it/s]
Adding requests:  52%|    | 4231/8192 [00:08<00:07, 532.74it/s]
Adding requests:  52%|    | 4285/8192 [00:08<00:07, 525.40it/s]
Adding requests:  53%|    | 4343/8192 [00:08<00:07, 540.24it/s]
Adding requests:  54%|    | 4398/8192 [00:08<00:07, 534.08it/s]
Adding requests:  54%|    | 4455/8192 [00:08<00:06, 542.52it/s]
Adding requests:  55%|    | 4510/8192 [00:08<00:07, 520.07it/s]
Adding requests:  56%|    | 4568/8192 [00:08<00:06, 534.97it/s]
Adding requests:  56%|    | 4622/8192 [00:08<00:07, 489.46it/s]
Adding requests:  57%|    | 4676/8192 [00:09<00:07, 501.27it/s]
Adding requests:  58%|    | 4727/8192 [00:09<00:06, 498.52it/s]
Adding requests:  58%|    | 4778/8192 [00:09<00:06, 494.16it/s]
Adding requests:  59%|    | 4830/8192 [00:09<00:06, 500.36it/s]
Adding requests:  60%|    | 4884/8192 [00:09<00:06, 510.88it/s]
Adding requests:  60%|    | 4938/8192 [00:09<00:06, 517.44it/s]
Adding requests:  61%|    | 4991/8192 [00:09<00:06, 518.93it/s]
Adding requests:  62%|   | 5048/8192 [00:09<00:05, 532.23it/s]
Adding requests:  62%|   | 5102/8192 [00:09<00:05, 534.39it/s]
Adding requests:  63%|   | 5156/8192 [00:09<00:05, 534.69it/s]
Adding requests:  64%|   | 5210/8192 [00:10<00:05, 529.92it/s]
Adding requests:  64%|   | 5265/8192 [00:10<00:05, 534.05it/s]
Adding requests:  65%|   | 5319/8192 [00:10<00:05, 524.80it/s]
Adding requests:  66%|   | 5377/8192 [00:10<00:05, 539.39it/s]
Adding requests:  66%|   | 5432/8192 [00:10<00:05, 529.81it/s]
Adding requests:  67%|   | 5487/8192 [00:10<00:05, 534.18it/s]
Adding requests:  68%|   | 5541/8192 [00:10<00:05, 518.33it/s]
Adding requests:  68%|   | 5597/8192 [00:10<00:04, 528.01it/s]
Adding requests:  69%|   | 5650/8192 [00:10<00:04, 527.39it/s]
Adding requests:  70%|   | 5705/8192 [00:10<00:04, 532.59it/s]
Adding requests:  70%|   | 5759/8192 [00:11<00:04, 526.79it/s]
Adding requests:  71%|   | 5812/8192 [00:11<00:04, 523.67it/s]
Adding requests:  72%|  | 5865/8192 [00:11<00:04, 505.92it/s]
Adding requests:  72%|  | 5919/8192 [00:11<00:04, 513.66it/s]
Adding requests:  73%|  | 5971/8192 [00:11<00:04, 486.08it/s]
Adding requests:  74%|  | 6025/8192 [00:11<00:04, 499.90it/s]
Adding requests:  74%|  | 6079/8192 [00:11<00:04, 509.69it/s]
Adding requests:  75%|  | 6134/8192 [00:11<00:03, 519.83it/s]
Adding requests:  76%|  | 6190/8192 [00:11<00:03, 530.06it/s]
Adding requests:  76%|  | 6244/8192 [00:12<00:03, 532.14it/s]
Adding requests:  77%|  | 6300/8192 [00:12<00:03, 539.92it/s]
Adding requests:  78%|  | 6356/8192 [00:12<00:03, 545.45it/s]
Adding requests:  78%|  | 6411/8192 [00:12<00:03, 540.86it/s]
Adding requests:  79%|  | 6466/8192 [00:12<00:03, 535.75it/s]
Adding requests:  80%|  | 6524/8192 [00:12<00:03, 547.13it/s]
Adding requests:  80%|  | 6579/8192 [00:12<00:03, 530.77it/s]
Adding requests:  81%|  | 6637/8192 [00:12<00:02, 542.31it/s]
Adding requests:  82%| | 6692/8192 [00:12<00:02, 528.97it/s]
Adding requests:  82%| | 6750/8192 [00:12<00:02, 540.15it/s]
Adding requests:  83%| | 6805/8192 [00:13<00:02, 529.53it/s]
Adding requests:  84%| | 6863/8192 [00:13<00:02, 540.16it/s]
Adding requests:  84%| | 6918/8192 [00:13<00:02, 536.84it/s]
Adding requests:  85%| | 6972/8192 [00:13<00:02, 535.57it/s]
Adding requests:  86%| | 7026/8192 [00:13<00:02, 519.87it/s]
Adding requests:  86%| | 7081/8192 [00:13<00:02, 527.23it/s]
Adding requests:  87%| | 7135/8192 [00:13<00:01, 529.27it/s]
Adding requests:  88%| | 7191/8192 [00:13<00:01, 536.98it/s]
Adding requests:  88%| | 7246/8192 [00:13<00:01, 538.45it/s]
Adding requests:  89%| | 7301/8192 [00:14<00:01, 540.68it/s]
Adding requests:  90%| | 7356/8192 [00:14<00:01, 514.85it/s]
Adding requests:  90%| | 7410/8192 [00:14<00:01, 519.74it/s]
Adding requests:  91%| | 7468/8192 [00:14<00:01, 536.77it/s]
Adding requests:  92%|| 7522/8192 [00:14<00:01, 530.58it/s]
Adding requests:  93%|| 7580/8192 [00:14<00:01, 543.54it/s]
Adding requests:  93%|| 7635/8192 [00:14<00:01, 534.31it/s]
Adding requests:  94%|| 7695/8192 [00:14<00:00, 551.29it/s]
Adding requests:  95%|| 7751/8192 [00:14<00:00, 538.67it/s]
Adding requests:  95%|| 7806/8192 [00:14<00:00, 540.81it/s]
Adding requests:  96%|| 7861/8192 [00:15<00:00, 535.11it/s]
Adding requests:  97%|| 7915/8192 [00:15<00:00, 533.73it/s]
Adding requests:  97%|| 7969/8192 [00:15<00:00, 519.40it/s]
Adding requests:  98%|| 8022/8192 [00:15<00:00, 518.64it/s]
Adding requests:  99%|| 8074/8192 [00:15<00:00, 510.60it/s]
Adding requests:  99%|| 8127/8192 [00:15<00:00, 515.14it/s]
Adding requests: 100%|| 8179/8192 [00:15<00:00, 509.44it/s]
Adding requests: 100%|| 8192/8192 [00:15<00:00, 521.91it/s]

Processed prompts:   0%|          | 0/8192 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 130/8192 [00:01<01:07, 119.09it/s, est. speed input: 121944.80 toks/s, output: 119.09 toks/s]
Processed prompts:   2%|         | 194/8192 [00:06<05:23, 24.74it/s, est. speed input: 30132.47 toks/s, output: 29.43 toks/s]   
Processed prompts:   3%|         | 258/8192 [00:12<07:35, 17.43it/s, est. speed input: 21828.51 toks/s, output: 21.32 toks/s]
Processed prompts:   4%|         | 322/8192 [00:17<08:47, 14.91it/s, est. speed input: 18768.57 toks/s, output: 18.33 toks/s]
Processed prompts:   5%|         | 386/8192 [00:23<09:33, 13.62it/s, est. speed input: 17120.29 toks/s, output: 16.72 toks/s]
Processed prompts:   5%|         | 450/8192 [00:28<09:57, 12.95it/s, est. speed input: 16143.04 toks/s, output: 15.76 toks/s]
Processed prompts:   6%|         | 514/8192 [00:34<10:14, 12.49it/s, est. speed input: 15448.74 toks/s, output: 15.09 toks/s]
Processed prompts:   7%|         | 578/8192 [00:39<10:24, 12.19it/s, est. speed input: 14945.27 toks/s, output: 14.59 toks/s]
Processed prompts:   8%|         | 642/8192 [00:45<10:29, 11.99it/s, est. speed input: 14564.90 toks/s, output: 14.22 toks/s]
Processed prompts:   9%|         | 706/8192 [00:50<10:31, 11.85it/s, est. speed input: 14265.27 toks/s, output: 13.93 toks/s]
Processed prompts:   9%|         | 770/8192 [00:56<10:30, 11.76it/s, est. speed input: 14027.28 toks/s, output: 13.70 toks/s]
Processed prompts:  10%|         | 834/8192 [01:01<10:28, 11.70it/s, est. speed input: 13831.73 toks/s, output: 13.51 toks/s]
Processed prompts:  11%|         | 898/8192 [01:07<10:22, 11.71it/s, est. speed input: 13684.70 toks/s, output: 13.36 toks/s]
Processed prompts:  12%|        | 962/8192 [01:12<10:16, 11.72it/s, est. speed input: 13560.24 toks/s, output: 13.24 toks/s]
Processed prompts:  13%|        | 1026/8192 [01:18<10:13, 11.68it/s, est. speed input: 13438.92 toks/s, output: 13.12 toks/s]
Processed prompts:  13%|        | 1090/8192 [01:23<10:10, 11.64it/s, est. speed input: 13331.60 toks/s, output: 13.02 toks/s]
Processed prompts:  14%|        | 1154/8192 [01:29<10:03, 11.66it/s, est. speed input: 13251.01 toks/s, output: 12.94 toks/s]
Processed prompts:  15%|        | 1218/8192 [01:34<09:56, 11.69it/s, est. speed input: 13180.29 toks/s, output: 12.87 toks/s]
Processed prompts:  16%|        | 1282/8192 [01:40<09:52, 11.65it/s, est. speed input: 13107.00 toks/s, output: 12.80 toks/s]
Processed prompts:  16%|        | 1346/8192 [01:45<09:48, 11.62it/s, est. speed input: 13040.44 toks/s, output: 12.73 toks/s]
Processed prompts:  17%|        | 1410/8192 [01:51<09:44, 11.61it/s, est. speed input: 12981.30 toks/s, output: 12.68 toks/s]
Processed prompts:  18%|        | 1474/8192 [01:56<09:39, 11.59it/s, est. speed input: 12926.82 toks/s, output: 12.62 toks/s]
Processed prompts:  19%|        | 1538/8192 [02:02<09:31, 11.63it/s, est. speed input: 12886.06 toks/s, output: 12.58 toks/s]
Processed prompts:  20%|        | 1602/8192 [02:07<09:27, 11.61it/s, est. speed input: 12840.48 toks/s, output: 12.54 toks/s]
Processed prompts:  20%|        | 1666/8192 [02:13<09:22, 11.60it/s, est. speed input: 12798.81 toks/s, output: 12.50 toks/s]
Processed prompts:  21%|        | 1730/8192 [02:18<09:17, 11.59it/s, est. speed input: 12760.72 toks/s, output: 12.46 toks/s]
Processed prompts:  22%|       | 1794/8192 [02:24<09:12, 11.58it/s, est. speed input: 12725.64 toks/s, output: 12.43 toks/s]
Processed prompts:  23%|       | 1858/8192 [02:29<09:05, 11.62it/s, est. speed input: 12699.05 toks/s, output: 12.40 toks/s]
Processed prompts:  23%|       | 1922/8192 [02:35<08:57, 11.65it/s, est. speed input: 12675.03 toks/s, output: 12.38 toks/s]
Processed prompts:  24%|       | 1986/8192 [02:40<08:53, 11.63it/s, est. speed input: 12646.18 toks/s, output: 12.35 toks/s]
Processed prompts:  25%|       | 2050/8192 [02:46<08:49, 11.61it/s, est. speed input: 12619.44 toks/s, output: 12.32 toks/s]
Processed prompts:  26%|       | 2114/8192 [02:51<08:44, 11.59it/s, est. speed input: 12594.39 toks/s, output: 12.30 toks/s]
Processed prompts:  27%|       | 2178/8192 [02:57<08:35, 11.68it/s, est. speed input: 12581.11 toks/s, output: 12.29 toks/s]
Processed prompts:  27%|       | 2242/8192 [03:02<08:28, 11.69it/s, est. speed input: 12564.04 toks/s, output: 12.27 toks/s]
Processed prompts:  28%|       | 2306/8192 [03:08<08:23, 11.70it/s, est. speed input: 12547.72 toks/s, output: 12.25 toks/s]
Processed prompts:  29%|       | 2370/8192 [03:13<08:15, 11.76it/s, est. speed input: 12537.39 toks/s, output: 12.24 toks/s]
Processed prompts:  30%|       | 2434/8192 [03:19<08:12, 11.70it/s, est. speed input: 12517.86 toks/s, output: 12.22 toks/s]
Processed prompts:  30%|       | 2498/8192 [03:24<08:06, 11.71it/s, est. speed input: 12504.52 toks/s, output: 12.21 toks/s]
Processed prompts:  31%|      | 2562/8192 [03:30<08:00, 11.71it/s, est. speed input: 12491.68 toks/s, output: 12.20 toks/s]
Processed prompts:  32%|      | 2626/8192 [03:35<07:57, 11.67it/s, est. speed input: 12474.85 toks/s, output: 12.18 toks/s]
Processed prompts:  33%|      | 2690/8192 [03:41<07:52, 11.63it/s, est. speed input: 12458.81 toks/s, output: 12.17 toks/s]
Processed prompts:  34%|      | 2754/8192 [03:46<07:48, 11.61it/s, est. speed input: 12443.37 toks/s, output: 12.15 toks/s]
Processed prompts:  34%|      | 2818/8192 [03:52<07:43, 11.60it/s, est. speed input: 12429.12 toks/s, output: 12.14 toks/s]
Processed prompts:  35%|      | 2882/8192 [03:57<07:38, 11.58it/s, est. speed input: 12415.25 toks/s, output: 12.12 toks/s]
Processed prompts:  36%|      | 2946/8192 [04:03<07:33, 11.58it/s, est. speed input: 12402.09 toks/s, output: 12.11 toks/s]
Processed prompts:  37%|      | 3010/8192 [04:08<07:27, 11.57it/s, est. speed input: 12389.54 toks/s, output: 12.10 toks/s]
Processed prompts:  38%|      | 3074/8192 [04:14<07:22, 11.56it/s, est. speed input: 12376.99 toks/s, output: 12.09 toks/s]
Processed prompts:  38%|      | 3138/8192 [04:19<07:15, 11.61it/s, est. speed input: 12369.26 toks/s, output: 12.08 toks/s]
Processed prompts:  39%|      | 3202/8192 [04:25<07:10, 11.60it/s, est. speed input: 12358.21 toks/s, output: 12.07 toks/s]
Processed prompts:  40%|      | 3266/8192 [04:30<07:05, 11.59it/s, est. speed input: 12347.55 toks/s, output: 12.06 toks/s]
Processed prompts:  41%|      | 3330/8192 [04:36<06:59, 11.58it/s, est. speed input: 12337.31 toks/s, output: 12.05 toks/s]
Processed prompts:  41%|     | 3394/8192 [04:41<06:54, 11.57it/s, est. speed input: 12327.19 toks/s, output: 12.04 toks/s]
Processed prompts:  42%|     | 3458/8192 [04:47<06:45, 11.67it/s, est. speed input: 12324.64 toks/s, output: 12.04 toks/s]
Processed prompts:  43%|     | 3522/8192 [04:52<06:41, 11.63it/s, est. speed input: 12315.24 toks/s, output: 12.03 toks/s]
Processed prompts:  44%|     | 3586/8192 [04:58<06:36, 11.61it/s, est. speed input: 12306.44 toks/s, output: 12.02 toks/s]
Processed prompts:  45%|     | 3650/8192 [05:03<06:31, 11.60it/s, est. speed input: 12297.94 toks/s, output: 12.01 toks/s]
Processed prompts:  45%|     | 3714/8192 [05:09<06:24, 11.63it/s, est. speed input: 12292.74 toks/s, output: 12.00 toks/s]
Processed prompts:  46%|     | 3778/8192 [05:14<06:20, 11.61it/s, est. speed input: 12284.73 toks/s, output: 12.00 toks/s]
Processed prompts:  47%|     | 3842/8192 [05:20<06:15, 11.59it/s, est. speed input: 12276.56 toks/s, output: 11.99 toks/s]
Processed prompts:  48%|     | 3906/8192 [05:25<06:10, 11.58it/s, est. speed input: 12269.17 toks/s, output: 11.98 toks/s]
Processed prompts:  48%|     | 3970/8192 [05:31<06:04, 11.57it/s, est. speed input: 12261.95 toks/s, output: 11.97 toks/s]
Processed prompts:  49%|     | 4034/8192 [05:36<05:57, 11.62it/s, est. speed input: 12257.92 toks/s, output: 11.97 toks/s]
Processed prompts:  50%|     | 4098/8192 [05:42<05:52, 11.60it/s, est. speed input: 12251.18 toks/s, output: 11.96 toks/s]
Processed prompts:  51%|     | 4162/8192 [05:48<05:47, 11.59it/s, est. speed input: 12244.41 toks/s, output: 11.96 toks/s]
Processed prompts:  52%|    | 4226/8192 [05:53<05:39, 11.68it/s, est. speed input: 12243.32 toks/s, output: 11.96 toks/s]
Processed prompts:  52%|    | 4290/8192 [05:58<05:33, 11.69it/s, est. speed input: 12239.75 toks/s, output: 11.95 toks/s]
Processed prompts:  53%|    | 4354/8192 [06:04<05:29, 11.65it/s, est. speed input: 12233.58 toks/s, output: 11.95 toks/s]
Processed prompts:  54%|    | 4418/8192 [06:09<05:24, 11.62it/s, est. speed input: 12227.72 toks/s, output: 11.94 toks/s]
Processed prompts:  55%|    | 4482/8192 [06:15<05:19, 11.60it/s, est. speed input: 12221.74 toks/s, output: 11.94 toks/s]
Processed prompts:  55%|    | 4546/8192 [06:21<05:14, 11.58it/s, est. speed input: 12215.91 toks/s, output: 11.93 toks/s]
Processed prompts:  56%|    | 4610/8192 [06:26<05:09, 11.58it/s, est. speed input: 12210.49 toks/s, output: 11.92 toks/s]
Processed prompts:  57%|    | 4674/8192 [06:32<05:04, 11.57it/s, est. speed input: 12205.19 toks/s, output: 11.92 toks/s]
Processed prompts:  58%|    | 4738/8192 [06:37<04:57, 11.62it/s, est. speed input: 12202.41 toks/s, output: 11.92 toks/s]
Processed prompts:  59%|    | 4802/8192 [06:43<04:51, 11.65it/s, est. speed input: 12199.77 toks/s, output: 11.91 toks/s]
Processed prompts:  59%|    | 4866/8192 [06:48<04:46, 11.62it/s, est. speed input: 12194.76 toks/s, output: 11.91 toks/s]
Processed prompts:  60%|    | 4930/8192 [06:54<04:41, 11.60it/s, est. speed input: 12189.98 toks/s, output: 11.90 toks/s]
Processed prompts:  61%|    | 4994/8192 [06:59<04:33, 11.69it/s, est. speed input: 12189.77 toks/s, output: 11.90 toks/s]
Processed prompts:  62%|   | 5058/8192 [07:05<04:29, 11.65it/s, est. speed input: 12185.16 toks/s, output: 11.90 toks/s]
Processed prompts:  63%|   | 5122/8192 [07:10<04:24, 11.62it/s, est. speed input: 12180.83 toks/s, output: 11.90 toks/s]
Processed prompts:  63%|   | 5186/8192 [07:16<04:17, 11.65it/s, est. speed input: 12178.62 toks/s, output: 11.89 toks/s]
Processed prompts:  64%|   | 5250/8192 [07:21<04:13, 11.62it/s, est. speed input: 12174.32 toks/s, output: 11.89 toks/s]
Processed prompts:  65%|   | 5314/8192 [07:27<04:06, 11.65it/s, est. speed input: 12172.20 toks/s, output: 11.89 toks/s]
Processed prompts:  66%|   | 5378/8192 [07:32<04:01, 11.67it/s, est. speed input: 12170.12 toks/s, output: 11.88 toks/s]
Processed prompts:  66%|   | 5442/8192 [07:38<03:56, 11.64it/s, est. speed input: 12165.97 toks/s, output: 11.88 toks/s]
Processed prompts:  67%|   | 5506/8192 [07:43<03:50, 11.66it/s, est. speed input: 12164.07 toks/s, output: 11.88 toks/s]
Processed prompts:  68%|   | 5570/8192 [07:49<03:45, 11.63it/s, est. speed input: 12160.20 toks/s, output: 11.88 toks/s]
Processed prompts:  69%|   | 5634/8192 [07:54<03:39, 11.66it/s, est. speed input: 12158.50 toks/s, output: 11.87 toks/s]
Processed prompts:  70%|   | 5698/8192 [08:00<03:34, 11.63it/s, est. speed input: 12154.69 toks/s, output: 11.87 toks/s]
Processed prompts:  70%|   | 5762/8192 [08:05<03:29, 11.61it/s, est. speed input: 12150.99 toks/s, output: 11.87 toks/s]
Processed prompts:  71%|   | 5826/8192 [08:11<03:24, 11.59it/s, est. speed input: 12147.46 toks/s, output: 11.86 toks/s]
Processed prompts:  72%|  | 5890/8192 [08:16<03:18, 11.58it/s, est. speed input: 12143.93 toks/s, output: 11.86 toks/s]
Processed prompts:  73%|  | 5954/8192 [08:22<03:13, 11.57it/s, est. speed input: 12140.49 toks/s, output: 11.86 toks/s]
Processed prompts:  73%|  | 6018/8192 [08:27<03:07, 11.57it/s, est. speed input: 12137.10 toks/s, output: 11.85 toks/s]
Processed prompts:  74%|  | 6082/8192 [08:33<03:02, 11.56it/s, est. speed input: 12133.74 toks/s, output: 11.85 toks/s]
Processed prompts:  75%|  | 6146/8192 [08:38<02:57, 11.56it/s, est. speed input: 12130.48 toks/s, output: 11.85 toks/s]
Processed prompts:  76%|  | 6210/8192 [08:44<02:51, 11.56it/s, est. speed input: 12127.32 toks/s, output: 11.84 toks/s]
Processed prompts:  77%|  | 6274/8192 [08:49<02:45, 11.56it/s, est. speed input: 12124.26 toks/s, output: 11.84 toks/s]
Processed prompts:  77%|  | 6338/8192 [08:55<02:40, 11.55it/s, est. speed input: 12121.14 toks/s, output: 11.84 toks/s]
Processed prompts:  78%|  | 6402/8192 [09:00<02:34, 11.55it/s, est. speed input: 12118.05 toks/s, output: 11.83 toks/s]
Processed prompts:  79%|  | 6466/8192 [09:06<02:29, 11.55it/s, est. speed input: 12115.19 toks/s, output: 11.83 toks/s]
Processed prompts:  80%|  | 6530/8192 [09:12<02:23, 11.55it/s, est. speed input: 12112.28 toks/s, output: 11.83 toks/s]
Processed prompts:  80%|  | 6594/8192 [09:17<02:17, 11.60it/s, est. speed input: 12111.26 toks/s, output: 11.83 toks/s]
Processed prompts:  81%| | 6658/8192 [09:22<02:11, 11.64it/s, est. speed input: 12110.30 toks/s, output: 11.83 toks/s]
Processed prompts:  82%| | 6722/8192 [09:28<02:06, 11.62it/s, est. speed input: 12107.66 toks/s, output: 11.82 toks/s]
Processed prompts:  83%| | 6786/8192 [09:34<02:01, 11.60it/s, est. speed input: 12104.91 toks/s, output: 11.82 toks/s]
Processed prompts:  84%| | 6850/8192 [09:39<01:55, 11.58it/s, est. speed input: 12102.24 toks/s, output: 11.82 toks/s]
Processed prompts:  84%| | 6914/8192 [09:45<01:50, 11.57it/s, est. speed input: 12099.73 toks/s, output: 11.82 toks/s]
Processed prompts:  85%| | 6978/8192 [09:50<01:44, 11.57it/s, est. speed input: 12097.25 toks/s, output: 11.81 toks/s]
Processed prompts:  86%| | 7042/8192 [09:56<01:39, 11.56it/s, est. speed input: 12094.73 toks/s, output: 11.81 toks/s]
Processed prompts:  87%| | 7106/8192 [10:01<01:33, 11.61it/s, est. speed input: 12093.78 toks/s, output: 11.81 toks/s]
Processed prompts:  88%| | 7170/8192 [10:07<01:28, 11.59it/s, est. speed input: 12091.46 toks/s, output: 11.81 toks/s]
Processed prompts:  88%| | 7234/8192 [10:12<01:22, 11.63it/s, est. speed input: 12090.72 toks/s, output: 11.81 toks/s]
Processed prompts:  89%| | 7298/8192 [10:18<01:17, 11.61it/s, est. speed input: 12088.41 toks/s, output: 11.81 toks/s]
Processed prompts:  90%| | 7362/8192 [10:23<01:11, 11.60it/s, est. speed input: 12086.19 toks/s, output: 11.80 toks/s]
Processed prompts:  91%| | 7426/8192 [10:29<01:05, 11.63it/s, est. speed input: 12085.43 toks/s, output: 11.80 toks/s]
Processed prompts:  91%|| 7490/8192 [10:34<01:00, 11.61it/s, est. speed input: 12083.21 toks/s, output: 11.80 toks/s]
Processed prompts:  92%|| 7554/8192 [10:40<00:54, 11.69it/s, est. speed input: 12083.98 toks/s, output: 11.80 toks/s]
Processed prompts:  93%|| 7618/8192 [10:45<00:49, 11.65it/s, est. speed input: 12081.74 toks/s, output: 11.80 toks/s]
Processed prompts:  94%|| 7682/8192 [10:51<00:43, 11.67it/s, est. speed input: 12081.11 toks/s, output: 11.80 toks/s]
Processed prompts:  95%|| 7746/8192 [10:56<00:38, 11.63it/s, est. speed input: 12078.92 toks/s, output: 11.80 toks/s]
Processed prompts:  95%|| 7810/8192 [11:02<00:32, 11.61it/s, est. speed input: 12076.92 toks/s, output: 11.79 toks/s]
Processed prompts:  96%|| 7874/8192 [11:07<00:27, 11.59it/s, est. speed input: 12074.68 toks/s, output: 11.79 toks/s]
Processed prompts:  97%|| 7938/8192 [11:13<00:21, 11.63it/s, est. speed input: 12074.08 toks/s, output: 11.79 toks/s]
Processed prompts:  98%|| 8002/8192 [11:18<00:16, 11.61it/s, est. speed input: 12072.15 toks/s, output: 11.79 toks/s]
Processed prompts:  98%|| 8066/8192 [11:24<00:10, 11.64it/s, est. speed input: 12071.50 toks/s, output: 11.79 toks/s]
Processed prompts:  99%|| 8130/8192 [11:29<00:05, 11.71it/s, est. speed input: 12072.39 toks/s, output: 11.79 toks/s]
Processed prompts: 100%|| 8192/8192 [11:29<00:00, 11.71it/s, est. speed input: 12164.45 toks/s, output: 11.88 toks/s]
Processed prompts: 100%|| 8192/8192 [11:29<00:00, 11.88it/s, est. speed input: 12164.45 toks/s, output: 11.88 toks/s]
[rank0]:[W126 13:52:19.398397088 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-26 19:51:56
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Qwen2.5-7B-FP8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 19:51:59 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 19:51:59 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1672365) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1672365) WARNING 01-26 19:53:28 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 10.20 requests/s, 5230.07 total tokens/s, 10.20 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-26 19:51:59] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 19:51:59] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 19:51:59] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 19:51:59] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:51:59] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:51:59] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:51:59] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:51:59] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:51:59] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 19:51:59] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 19:51:59] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 19:51:59] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 19:51:59] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 19:51:59] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 19:52:03] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 19:52:03] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 19:52:03] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 19:52:03] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:52:03] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:52:03] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:52:03] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:52:03] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:52:03] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 19:52:03] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 19:52:03] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 19:52:03] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 19:52:03] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 19:52:03] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1672365) [2026-01-26 19:52:04] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1672365) [2026-01-26 19:52:04] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1672365) [2026-01-26 19:52:04] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1672365) [2026-01-26 19:52:04] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1672365) [2026-01-26 19:52:04] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1672365) [2026-01-26 19:52:04] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1672365) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1672365) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:28<00:28, 28.15s/it]
(EngineCore_DP0 pid=1672365) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:05<00:00, 33.50s/it]
(EngineCore_DP0 pid=1672365) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:05<00:00, 32.70s/it]
(EngineCore_DP0 pid=1672365) 
(EngineCore_DP0 pid=1672365) [2026-01-26 19:53:10] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=1672365) [2026-01-26 19:53:10] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16588800 bytes
(EngineCore_DP0 pid=1672365) [2026-01-26 19:53:10] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=1672365) [2026-01-26 19:53:10] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 12902400 bytes
(EngineCore_DP0 pid=1672365) [2026-01-26 19:53:10] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=1672365) [2026-01-26 19:53:10] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 136396800 bytes
(EngineCore_DP0 pid=1672365) [2026-01-26 19:53:10] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=1672365) [2026-01-26 19:53:10] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 67952640 bytes
(EngineCore_DP0 pid=1672365) 2026-01-26 19:53:19,572 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1672365) 2026-01-26 19:53:19,876 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:   1%|          | 1/128 [00:00<01:29,  1.41it/s]
Adding requests:   2%|         | 2/128 [00:00<00:52,  2.40it/s]
Adding requests:   2%|         | 3/128 [00:01<00:34,  3.60it/s]
Adding requests:   4%|         | 5/128 [00:01<00:20,  6.03it/s]
Adding requests:   5%|         | 7/128 [00:01<00:14,  8.51it/s]
Adding requests:   8%|         | 10/128 [00:01<00:09, 13.04it/s]
Adding requests:  10%|         | 13/128 [00:01<00:07, 16.01it/s]
Adding requests:  13%|        | 17/128 [00:01<00:05, 21.66it/s]
Adding requests:  16%|        | 20/128 [00:01<00:04, 23.02it/s]
Adding requests:  21%|        | 27/128 [00:01<00:02, 33.91it/s]
Adding requests:  34%|      | 43/128 [00:01<00:01, 67.06it/s]
Adding requests:  62%|   | 80/128 [00:02<00:00, 148.63it/s]
Adding requests: 100%|| 128/128 [00:02<00:00, 58.99it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  12%|        | 16/128 [00:00<00:01, 95.71it/s, est. speed input: 49008.12 toks/s, output: 95.71 toks/s]
Processed prompts:  20%|        | 26/128 [00:01<00:04, 20.70it/s, est. speed input: 12391.69 toks/s, output: 24.20 toks/s]
Processed prompts:  24%|       | 31/128 [00:01<00:05, 17.02it/s, est. speed input: 10422.35 toks/s, output: 20.36 toks/s]
Processed prompts:  27%|       | 35/128 [00:01<00:06, 15.19it/s, est. speed input: 9508.43 toks/s, output: 18.57 toks/s] 
Processed prompts:  30%|       | 38/128 [00:02<00:06, 14.17it/s, est. speed input: 9023.98 toks/s, output: 17.62 toks/s]
Processed prompts:  31%|      | 40/128 [00:02<00:06, 13.59it/s, est. speed input: 8767.91 toks/s, output: 17.12 toks/s]
Processed prompts:  33%|      | 42/128 [00:02<00:06, 13.09it/s, est. speed input: 8554.73 toks/s, output: 16.71 toks/s]
Processed prompts:  34%|      | 44/128 [00:02<00:06, 12.51it/s, est. speed input: 8341.20 toks/s, output: 16.29 toks/s]
Processed prompts:  36%|      | 46/128 [00:02<00:06, 12.18it/s, est. speed input: 8179.09 toks/s, output: 15.97 toks/s]
Processed prompts:  38%|      | 48/128 [00:03<00:06, 11.87it/s, est. speed input: 8028.04 toks/s, output: 15.68 toks/s]
Processed prompts:  39%|      | 50/128 [00:03<00:06, 11.64it/s, est. speed input: 7894.64 toks/s, output: 15.42 toks/s]
Processed prompts:  41%|      | 52/128 [00:03<00:06, 11.53it/s, est. speed input: 7783.82 toks/s, output: 15.20 toks/s]
Processed prompts:  42%|     | 54/128 [00:03<00:06, 11.35it/s, est. speed input: 7671.29 toks/s, output: 14.98 toks/s]
Processed prompts:  44%|     | 56/128 [00:03<00:06, 11.24it/s, est. speed input: 7573.25 toks/s, output: 14.79 toks/s]
Processed prompts:  45%|     | 58/128 [00:03<00:06, 11.22it/s, est. speed input: 7489.57 toks/s, output: 14.63 toks/s]
Processed prompts:  47%|     | 60/128 [00:04<00:06, 11.19it/s, est. speed input: 7411.27 toks/s, output: 14.48 toks/s]
Processed prompts:  48%|     | 62/128 [00:04<00:05, 11.17it/s, est. speed input: 7340.26 toks/s, output: 14.34 toks/s]
Processed prompts:  50%|     | 64/128 [00:04<00:05, 11.15it/s, est. speed input: 7274.28 toks/s, output: 14.21 toks/s]
Processed prompts:  52%|    | 66/128 [00:04<00:05, 11.07it/s, est. speed input: 7207.15 toks/s, output: 14.08 toks/s]
Processed prompts:  53%|    | 68/128 [00:04<00:05, 11.09it/s, est. speed input: 7151.99 toks/s, output: 13.97 toks/s]
Processed prompts:  55%|    | 70/128 [00:05<00:05, 11.15it/s, est. speed input: 7103.48 toks/s, output: 13.87 toks/s]
Processed prompts:  56%|    | 72/128 [00:05<00:05, 11.12it/s, est. speed input: 7053.60 toks/s, output: 13.78 toks/s]
Processed prompts:  58%|    | 74/128 [00:05<00:04, 11.09it/s, est. speed input: 7006.43 toks/s, output: 13.68 toks/s]
Processed prompts:  59%|    | 76/128 [00:05<00:04, 11.07it/s, est. speed input: 6962.40 toks/s, output: 13.60 toks/s]
Processed prompts:  61%|    | 78/128 [00:05<00:04, 11.00it/s, est. speed input: 6917.36 toks/s, output: 13.51 toks/s]
Processed prompts:  62%|   | 80/128 [00:05<00:04, 11.02it/s, est. speed input: 6878.92 toks/s, output: 13.44 toks/s]
Processed prompts:  64%|   | 82/128 [00:06<00:04, 11.09it/s, est. speed input: 6846.63 toks/s, output: 13.37 toks/s]
Processed prompts:  66%|   | 84/128 [00:06<00:03, 11.13it/s, est. speed input: 6815.72 toks/s, output: 13.31 toks/s]
Processed prompts:  67%|   | 86/128 [00:06<00:03, 11.11it/s, est. speed input: 6783.62 toks/s, output: 13.25 toks/s]
Processed prompts:  69%|   | 88/128 [00:06<00:03, 11.15it/s, est. speed input: 6756.07 toks/s, output: 13.20 toks/s]
Processed prompts:  70%|   | 90/128 [00:06<00:03, 11.04it/s, est. speed input: 6723.17 toks/s, output: 13.13 toks/s]
Processed prompts:  72%|  | 92/128 [00:07<00:03, 11.09it/s, est. speed input: 6697.93 toks/s, output: 13.08 toks/s]
Processed prompts:  73%|  | 94/128 [00:07<00:03, 11.14it/s, est. speed input: 6675.12 toks/s, output: 13.04 toks/s]
Processed prompts:  75%|  | 96/128 [00:07<00:02, 11.11it/s, est. speed input: 6650.00 toks/s, output: 12.99 toks/s]
Processed prompts:  77%|  | 98/128 [00:07<00:02, 11.11it/s, est. speed input: 6627.11 toks/s, output: 12.94 toks/s]
Processed prompts:  78%|  | 100/128 [00:07<00:02, 11.17it/s, est. speed input: 6608.01 toks/s, output: 12.91 toks/s]
Processed prompts:  80%|  | 102/128 [00:07<00:02, 11.06it/s, est. speed input: 6582.86 toks/s, output: 12.86 toks/s]
Processed prompts:  81%| | 104/128 [00:08<00:02, 11.07it/s, est. speed input: 6562.82 toks/s, output: 12.82 toks/s]
Processed prompts:  83%| | 106/128 [00:08<00:01, 11.06it/s, est. speed input: 6542.89 toks/s, output: 12.78 toks/s]
Processed prompts:  84%| | 108/128 [00:08<00:01, 11.04it/s, est. speed input: 6523.27 toks/s, output: 12.74 toks/s]
Processed prompts:  86%| | 110/128 [00:08<00:01, 11.06it/s, est. speed input: 6506.04 toks/s, output: 12.71 toks/s]
Processed prompts:  88%| | 112/128 [00:08<00:01, 11.09it/s, est. speed input: 6489.97 toks/s, output: 12.68 toks/s]
Processed prompts:  89%| | 114/128 [00:09<00:01, 10.97it/s, est. speed input: 6469.11 toks/s, output: 12.63 toks/s]
Processed prompts:  91%| | 116/128 [00:09<00:01, 11.03it/s, est. speed input: 6454.53 toks/s, output: 12.61 toks/s]
Processed prompts:  92%|| 118/128 [00:09<00:00, 11.05it/s, est. speed input: 6439.76 toks/s, output: 12.58 toks/s]
Processed prompts:  94%|| 120/128 [00:09<00:00, 11.06it/s, est. speed input: 6425.30 toks/s, output: 12.55 toks/s]
Processed prompts:  95%|| 122/128 [00:09<00:00, 11.03it/s, est. speed input: 6410.05 toks/s, output: 12.52 toks/s]
Processed prompts:  97%|| 124/128 [00:09<00:00, 11.01it/s, est. speed input: 6395.23 toks/s, output: 12.49 toks/s]
Processed prompts:  98%|| 126/128 [00:10<00:00, 10.96it/s, est. speed input: 6380.01 toks/s, output: 12.46 toks/s]
Processed prompts: 100%|| 128/128 [00:10<00:00, 10.98it/s, est. speed input: 6366.96 toks/s, output: 12.44 toks/s]
Processed prompts: 100%|| 128/128 [00:10<00:00, 10.98it/s, est. speed input: 6366.96 toks/s, output: 12.44 toks/s]
Processed prompts: 100%|| 128/128 [00:10<00:00, 12.44it/s, est. speed input: 6366.96 toks/s, output: 12.44 toks/s]
[rank0]:[W126 19:53:42.365909034 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-26 19:53:57
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Qwen2.5-7B-FP8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 19:54:04 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 19:54:05 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1674286) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1674286) WARNING 01-26 19:55:25 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 5.62 requests/s, 5765.21 total tokens/s, 5.62 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-26 19:54:04] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 19:54:04] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 19:54:04] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 19:54:04] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:54:04] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:54:04] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:54:04] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:54:04] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:54:04] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 19:54:04] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 19:54:04] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 19:54:04] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 19:54:04] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 19:54:04] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 19:54:08] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 19:54:08] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 19:54:08] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 19:54:08] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:54:08] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:54:08] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:54:08] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:54:08] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:54:08] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 19:54:08] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 19:54:08] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 19:54:08] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 19:54:08] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 19:54:08] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1674286) [2026-01-26 19:54:09] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1674286) [2026-01-26 19:54:09] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1674286) [2026-01-26 19:54:09] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1674286) [2026-01-26 19:54:09] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1674286) [2026-01-26 19:54:09] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1674286) [2026-01-26 19:54:09] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1674286) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1674286) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:29<00:29, 29.06s/it]
(EngineCore_DP0 pid=1674286) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:07<00:00, 34.71s/it]
(EngineCore_DP0 pid=1674286) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:07<00:00, 33.86s/it]
(EngineCore_DP0 pid=1674286) 
(EngineCore_DP0 pid=1674286) [2026-01-26 19:55:18] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=1674286) [2026-01-26 19:55:18] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16588800 bytes
(EngineCore_DP0 pid=1674286) [2026-01-26 19:55:18] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=1674286) [2026-01-26 19:55:18] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 12902400 bytes
(EngineCore_DP0 pid=1674286) [2026-01-26 19:55:18] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=1674286) [2026-01-26 19:55:18] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 136396800 bytes
(EngineCore_DP0 pid=1674286) [2026-01-26 19:55:18] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=1674286) [2026-01-26 19:55:18] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 67952640 bytes
(EngineCore_DP0 pid=1674286) 2026-01-26 19:55:25,216 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1674286) 2026-01-26 19:55:25,282 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  26%|       | 33/128 [00:00<00:00, 325.04it/s]
Adding requests:  56%|    | 72/128 [00:00<00:00, 356.79it/s]
Adding requests:  88%| | 112/128 [00:00<00:00, 372.48it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 367.67it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 3/128 [00:00<00:11, 10.85it/s, est. speed input: 11107.86 toks/s, output: 10.85 toks/s]
Processed prompts:   4%|         | 5/128 [00:00<00:16,  7.49it/s, est. speed input: 8121.46 toks/s, output: 7.93 toks/s]  
Processed prompts:   5%|         | 6/128 [00:00<00:17,  6.92it/s, est. speed input: 7616.89 toks/s, output: 7.44 toks/s]
Processed prompts:   5%|         | 7/128 [00:00<00:18,  6.54it/s, est. speed input: 7295.22 toks/s, output: 7.12 toks/s]
Processed prompts:   6%|         | 8/128 [00:01<00:19,  6.30it/s, est. speed input: 7084.28 toks/s, output: 6.92 toks/s]
Processed prompts:   7%|         | 9/128 [00:01<00:19,  6.11it/s, est. speed input: 6917.89 toks/s, output: 6.76 toks/s]
Processed prompts:   8%|         | 10/128 [00:01<00:19,  5.94it/s, est. speed input: 6773.41 toks/s, output: 6.61 toks/s]
Processed prompts:   9%|         | 11/128 [00:01<00:19,  5.88it/s, est. speed input: 6679.86 toks/s, output: 6.52 toks/s]
Processed prompts:   9%|         | 12/128 [00:01<00:19,  5.81it/s, est. speed input: 6594.05 toks/s, output: 6.44 toks/s]
Processed prompts:  10%|         | 13/128 [00:02<00:19,  5.81it/s, est. speed input: 6539.48 toks/s, output: 6.39 toks/s]
Processed prompts:  11%|         | 14/128 [00:02<00:19,  5.77it/s, est. speed input: 6483.18 toks/s, output: 6.33 toks/s]
Processed prompts:  12%|        | 15/128 [00:02<00:19,  5.74it/s, est. speed input: 6432.05 toks/s, output: 6.28 toks/s]
Processed prompts:  12%|        | 16/128 [00:02<00:19,  5.70it/s, est. speed input: 6385.72 toks/s, output: 6.24 toks/s]
Processed prompts:  13%|        | 17/128 [00:02<00:19,  5.72it/s, est. speed input: 6355.39 toks/s, output: 6.21 toks/s]
Processed prompts:  14%|        | 18/128 [00:02<00:19,  5.71it/s, est. speed input: 6323.06 toks/s, output: 6.17 toks/s]
Processed prompts:  15%|        | 19/128 [00:03<00:19,  5.69it/s, est. speed input: 6291.29 toks/s, output: 6.14 toks/s]
Processed prompts:  16%|        | 20/128 [00:03<00:18,  5.70it/s, est. speed input: 6268.65 toks/s, output: 6.12 toks/s]
Processed prompts:  16%|        | 21/128 [00:03<00:18,  5.70it/s, est. speed input: 6246.35 toks/s, output: 6.10 toks/s]
Processed prompts:  17%|        | 22/128 [00:03<00:18,  5.65it/s, est. speed input: 6218.12 toks/s, output: 6.07 toks/s]
Processed prompts:  18%|        | 23/128 [00:03<00:18,  5.65it/s, est. speed input: 6198.53 toks/s, output: 6.05 toks/s]
Processed prompts:  19%|        | 24/128 [00:03<00:18,  5.64it/s, est. speed input: 6178.40 toks/s, output: 6.03 toks/s]
Processed prompts:  20%|        | 25/128 [00:04<00:18,  5.66it/s, est. speed input: 6163.79 toks/s, output: 6.02 toks/s]
Processed prompts:  20%|        | 26/128 [00:04<00:17,  5.70it/s, est. speed input: 6154.25 toks/s, output: 6.01 toks/s]
Processed prompts:  21%|        | 27/128 [00:04<00:17,  5.72it/s, est. speed input: 6144.75 toks/s, output: 6.00 toks/s]
Processed prompts:  22%|       | 28/128 [00:04<00:17,  5.65it/s, est. speed input: 6124.97 toks/s, output: 5.98 toks/s]
Processed prompts:  23%|       | 29/128 [00:04<00:17,  5.65it/s, est. speed input: 6112.99 toks/s, output: 5.97 toks/s]
Processed prompts:  23%|       | 30/128 [00:05<00:17,  5.69it/s, est. speed input: 6106.57 toks/s, output: 5.96 toks/s]
Processed prompts:  24%|       | 31/128 [00:05<00:17,  5.69it/s, est. speed input: 6096.38 toks/s, output: 5.95 toks/s]
Processed prompts:  25%|       | 32/128 [00:05<00:16,  5.70it/s, est. speed input: 6089.59 toks/s, output: 5.95 toks/s]
Processed prompts:  26%|       | 33/128 [00:05<00:16,  5.71it/s, est. speed input: 6082.29 toks/s, output: 5.94 toks/s]
Processed prompts:  27%|       | 34/128 [00:05<00:16,  5.68it/s, est. speed input: 6072.05 toks/s, output: 5.93 toks/s]
Processed prompts:  27%|       | 35/128 [00:05<00:16,  5.67it/s, est. speed input: 6062.74 toks/s, output: 5.92 toks/s]
Processed prompts:  28%|       | 36/128 [00:06<00:16,  5.66it/s, est. speed input: 6054.68 toks/s, output: 5.91 toks/s]
Processed prompts:  29%|       | 37/128 [00:06<00:16,  5.68it/s, est. speed input: 6049.43 toks/s, output: 5.91 toks/s]
Processed prompts:  30%|       | 38/128 [00:06<00:15,  5.68it/s, est. speed input: 6043.05 toks/s, output: 5.90 toks/s]
Processed prompts:  30%|       | 39/128 [00:06<00:15,  5.70it/s, est. speed input: 6039.04 toks/s, output: 5.90 toks/s]
Processed prompts:  31%|      | 40/128 [00:06<00:15,  5.64it/s, est. speed input: 6028.09 toks/s, output: 5.89 toks/s]
Processed prompts:  32%|      | 41/128 [00:06<00:15,  5.64it/s, est. speed input: 6022.08 toks/s, output: 5.88 toks/s]
Processed prompts:  33%|      | 42/128 [00:07<00:15,  5.64it/s, est. speed input: 6015.45 toks/s, output: 5.87 toks/s]
Processed prompts:  34%|      | 43/128 [00:07<00:15,  5.64it/s, est. speed input: 6010.20 toks/s, output: 5.87 toks/s]
Processed prompts:  34%|      | 44/128 [00:07<00:14,  5.66it/s, est. speed input: 6006.07 toks/s, output: 5.87 toks/s]
Processed prompts:  35%|      | 45/128 [00:07<00:14,  5.67it/s, est. speed input: 6002.35 toks/s, output: 5.86 toks/s]
Processed prompts:  36%|      | 46/128 [00:07<00:14,  5.62it/s, est. speed input: 5993.95 toks/s, output: 5.85 toks/s]
Processed prompts:  37%|      | 47/128 [00:08<00:14,  5.64it/s, est. speed input: 5989.91 toks/s, output: 5.85 toks/s]
Processed prompts:  38%|      | 48/128 [00:08<00:14,  5.64it/s, est. speed input: 5985.15 toks/s, output: 5.84 toks/s]
Processed prompts:  38%|      | 49/128 [00:08<00:13,  5.65it/s, est. speed input: 5981.54 toks/s, output: 5.84 toks/s]
Processed prompts:  39%|      | 50/128 [00:08<00:13,  5.64it/s, est. speed input: 5977.06 toks/s, output: 5.84 toks/s]
Processed prompts:  40%|      | 51/128 [00:08<00:13,  5.67it/s, est. speed input: 5975.11 toks/s, output: 5.84 toks/s]
Processed prompts:  41%|      | 52/128 [00:08<00:13,  5.64it/s, est. speed input: 5969.48 toks/s, output: 5.83 toks/s]
Processed prompts:  41%|     | 53/128 [00:09<00:13,  5.65it/s, est. speed input: 5966.42 toks/s, output: 5.83 toks/s]
Processed prompts:  42%|     | 54/128 [00:09<00:13,  5.69it/s, est. speed input: 5965.60 toks/s, output: 5.83 toks/s]
Processed prompts:  43%|     | 55/128 [00:09<00:12,  5.68it/s, est. speed input: 5962.35 toks/s, output: 5.82 toks/s]
Processed prompts:  44%|     | 56/128 [00:09<00:12,  5.67it/s, est. speed input: 5959.17 toks/s, output: 5.82 toks/s]
Processed prompts:  45%|     | 57/128 [00:09<00:12,  5.68it/s, est. speed input: 5956.95 toks/s, output: 5.82 toks/s]
Processed prompts:  45%|     | 58/128 [00:09<00:12,  5.65it/s, est. speed input: 5952.38 toks/s, output: 5.81 toks/s]
Processed prompts:  46%|     | 59/128 [00:10<00:12,  5.65it/s, est. speed input: 5949.40 toks/s, output: 5.81 toks/s]
Processed prompts:  47%|     | 60/128 [00:10<00:12,  5.66it/s, est. speed input: 5947.09 toks/s, output: 5.81 toks/s]
Processed prompts:  48%|     | 61/128 [00:10<00:11,  5.65it/s, est. speed input: 5944.35 toks/s, output: 5.81 toks/s]
Processed prompts:  48%|     | 62/128 [00:10<00:11,  5.67it/s, est. speed input: 5942.73 toks/s, output: 5.80 toks/s]
Processed prompts:  49%|     | 63/128 [00:10<00:11,  5.67it/s, est. speed input: 5940.61 toks/s, output: 5.80 toks/s]
Processed prompts:  50%|     | 64/128 [00:11<00:11,  5.63it/s, est. speed input: 5936.36 toks/s, output: 5.80 toks/s]
Processed prompts:  51%|     | 65/128 [00:11<00:11,  5.64it/s, est. speed input: 5934.27 toks/s, output: 5.80 toks/s]
Processed prompts:  52%|    | 66/128 [00:11<00:10,  5.67it/s, est. speed input: 5933.43 toks/s, output: 5.79 toks/s]
Processed prompts:  52%|    | 67/128 [00:11<00:10,  5.70it/s, est. speed input: 5932.75 toks/s, output: 5.79 toks/s]
Processed prompts:  53%|    | 68/128 [00:11<00:10,  5.67it/s, est. speed input: 5930.15 toks/s, output: 5.79 toks/s]
Processed prompts:  54%|    | 69/128 [00:11<00:10,  5.67it/s, est. speed input: 5928.28 toks/s, output: 5.79 toks/s]
Processed prompts:  55%|    | 70/128 [00:12<00:10,  5.64it/s, est. speed input: 5924.63 toks/s, output: 5.79 toks/s]
Processed prompts:  55%|    | 71/128 [00:12<00:10,  5.65it/s, est. speed input: 5923.14 toks/s, output: 5.78 toks/s]
Processed prompts:  56%|    | 72/128 [00:12<00:09,  5.66it/s, est. speed input: 5921.71 toks/s, output: 5.78 toks/s]
Processed prompts:  57%|    | 73/128 [00:12<00:09,  5.67it/s, est. speed input: 5920.24 toks/s, output: 5.78 toks/s]
Processed prompts:  58%|    | 74/128 [00:12<00:09,  5.66it/s, est. speed input: 5918.43 toks/s, output: 5.78 toks/s]
Processed prompts:  59%|    | 75/128 [00:12<00:09,  5.68it/s, est. speed input: 5917.47 toks/s, output: 5.78 toks/s]
Processed prompts:  59%|    | 76/128 [00:13<00:09,  5.61it/s, est. speed input: 5913.12 toks/s, output: 5.77 toks/s]
Processed prompts:  60%|    | 77/128 [00:13<00:09,  5.62it/s, est. speed input: 5911.03 toks/s, output: 5.77 toks/s]
Processed prompts:  61%|    | 78/128 [00:13<00:08,  5.65it/s, est. speed input: 5910.50 toks/s, output: 5.77 toks/s]
Processed prompts:  62%|   | 79/128 [00:13<00:08,  5.64it/s, est. speed input: 5908.63 toks/s, output: 5.77 toks/s]
Processed prompts:  62%|   | 80/128 [00:13<00:08,  5.64it/s, est. speed input: 5906.59 toks/s, output: 5.77 toks/s]
Processed prompts:  63%|   | 81/128 [00:14<00:08,  5.64it/s, est. speed input: 5905.15 toks/s, output: 5.77 toks/s]
Processed prompts:  64%|   | 82/128 [00:14<00:08,  5.60it/s, est. speed input: 5901.65 toks/s, output: 5.76 toks/s]
Processed prompts:  65%|   | 83/128 [00:14<00:07,  5.63it/s, est. speed input: 5901.10 toks/s, output: 5.76 toks/s]
Processed prompts:  66%|   | 84/128 [00:14<00:07,  5.64it/s, est. speed input: 5899.95 toks/s, output: 5.76 toks/s]
Processed prompts:  66%|   | 85/128 [00:14<00:07,  5.64it/s, est. speed input: 5898.37 toks/s, output: 5.76 toks/s]
Processed prompts:  67%|   | 86/128 [00:14<00:07,  5.65it/s, est. speed input: 5897.29 toks/s, output: 5.76 toks/s]
Processed prompts:  68%|   | 87/128 [00:15<00:07,  5.66it/s, est. speed input: 5896.47 toks/s, output: 5.76 toks/s]
Processed prompts:  69%|   | 88/128 [00:15<00:07,  5.61it/s, est. speed input: 5893.04 toks/s, output: 5.75 toks/s]
Processed prompts:  70%|   | 89/128 [00:15<00:06,  5.62it/s, est. speed input: 5891.82 toks/s, output: 5.75 toks/s]
Processed prompts:  70%|   | 90/128 [00:15<00:06,  5.64it/s, est. speed input: 5890.97 toks/s, output: 5.75 toks/s]
Processed prompts:  71%|   | 91/128 [00:15<00:06,  5.66it/s, est. speed input: 5890.56 toks/s, output: 5.75 toks/s]
Processed prompts:  72%|  | 92/128 [00:15<00:06,  5.64it/s, est. speed input: 5888.88 toks/s, output: 5.75 toks/s]
Processed prompts:  73%|  | 93/128 [00:16<00:06,  5.67it/s, est. speed input: 5888.82 toks/s, output: 5.75 toks/s]
Processed prompts:  73%|  | 94/128 [00:16<00:06,  5.63it/s, est. speed input: 5886.38 toks/s, output: 5.75 toks/s]
Processed prompts:  74%|  | 95/128 [00:16<00:05,  5.63it/s, est. speed input: 5885.02 toks/s, output: 5.75 toks/s]
Processed prompts:  75%|  | 96/128 [00:16<00:05,  5.64it/s, est. speed input: 5884.18 toks/s, output: 5.75 toks/s]
Processed prompts:  76%|  | 97/128 [00:16<00:05,  5.63it/s, est. speed input: 5882.56 toks/s, output: 5.74 toks/s]
Processed prompts:  77%|  | 98/128 [00:17<00:05,  5.63it/s, est. speed input: 5881.41 toks/s, output: 5.74 toks/s]
Processed prompts:  77%|  | 99/128 [00:17<00:05,  5.63it/s, est. speed input: 5880.16 toks/s, output: 5.74 toks/s]
Processed prompts:  78%|  | 100/128 [00:17<00:05,  5.59it/s, est. speed input: 5877.47 toks/s, output: 5.74 toks/s]
Processed prompts:  79%|  | 101/128 [00:17<00:04,  5.58it/s, est. speed input: 5875.79 toks/s, output: 5.74 toks/s]
Processed prompts:  80%|  | 102/128 [00:17<00:04,  5.60it/s, est. speed input: 5874.72 toks/s, output: 5.74 toks/s]
Processed prompts:  80%|  | 103/128 [00:17<00:04,  5.60it/s, est. speed input: 5873.29 toks/s, output: 5.74 toks/s]
Processed prompts:  81%| | 104/128 [00:18<00:04,  5.59it/s, est. speed input: 5871.75 toks/s, output: 5.73 toks/s]
Processed prompts:  82%| | 105/128 [00:18<00:04,  5.59it/s, est. speed input: 5870.29 toks/s, output: 5.73 toks/s]
Processed prompts:  83%| | 106/128 [00:18<00:03,  5.57it/s, est. speed input: 5868.10 toks/s, output: 5.73 toks/s]
Processed prompts:  84%| | 107/128 [00:18<00:03,  5.59it/s, est. speed input: 5867.28 toks/s, output: 5.73 toks/s]
Processed prompts:  84%| | 108/128 [00:18<00:03,  5.61it/s, est. speed input: 5866.45 toks/s, output: 5.73 toks/s]
Processed prompts:  85%| | 109/128 [00:19<00:03,  5.62it/s, est. speed input: 5865.62 toks/s, output: 5.73 toks/s]
Processed prompts:  86%| | 110/128 [00:19<00:03,  5.63it/s, est. speed input: 5865.07 toks/s, output: 5.73 toks/s]
Processed prompts:  87%| | 111/128 [00:19<00:03,  5.62it/s, est. speed input: 5863.61 toks/s, output: 5.73 toks/s]
Processed prompts:  88%| | 112/128 [00:19<00:02,  5.58it/s, est. speed input: 5861.57 toks/s, output: 5.72 toks/s]
Processed prompts:  88%| | 113/128 [00:19<00:02,  5.61it/s, est. speed input: 5861.15 toks/s, output: 5.72 toks/s]
Processed prompts:  89%| | 114/128 [00:19<00:02,  5.62it/s, est. speed input: 5860.36 toks/s, output: 5.72 toks/s]
Processed prompts:  90%| | 115/128 [00:20<00:02,  5.63it/s, est. speed input: 5859.85 toks/s, output: 5.72 toks/s]
Processed prompts:  91%| | 116/128 [00:20<00:02,  5.63it/s, est. speed input: 5858.88 toks/s, output: 5.72 toks/s]
Processed prompts:  91%|| 117/128 [00:20<00:01,  5.61it/s, est. speed input: 5857.62 toks/s, output: 5.72 toks/s]
Processed prompts:  92%|| 118/128 [00:20<00:01,  5.58it/s, est. speed input: 5855.80 toks/s, output: 5.72 toks/s]
Processed prompts:  93%|| 119/128 [00:20<00:01,  5.61it/s, est. speed input: 5855.28 toks/s, output: 5.72 toks/s]
Processed prompts:  94%|| 120/128 [00:20<00:01,  5.62it/s, est. speed input: 5854.68 toks/s, output: 5.72 toks/s]
Processed prompts:  95%|| 121/128 [00:21<00:01,  5.65it/s, est. speed input: 5854.71 toks/s, output: 5.72 toks/s]
Processed prompts:  95%|| 122/128 [00:21<00:01,  5.65it/s, est. speed input: 5854.29 toks/s, output: 5.72 toks/s]
Processed prompts:  96%|| 123/128 [00:21<00:00,  5.62it/s, est. speed input: 5852.75 toks/s, output: 5.72 toks/s]
Processed prompts:  97%|| 124/128 [00:21<00:00,  5.60it/s, est. speed input: 5851.33 toks/s, output: 5.71 toks/s]
Processed prompts:  98%|| 125/128 [00:21<00:00,  5.61it/s, est. speed input: 5850.60 toks/s, output: 5.71 toks/s]
Processed prompts:  98%|| 126/128 [00:22<00:00,  5.61it/s, est. speed input: 5849.74 toks/s, output: 5.71 toks/s]
Processed prompts:  99%|| 127/128 [00:22<00:00,  5.63it/s, est. speed input: 5849.42 toks/s, output: 5.71 toks/s]
Processed prompts: 100%|| 128/128 [00:22<00:00,  5.65it/s, est. speed input: 5849.45 toks/s, output: 5.71 toks/s]
Processed prompts: 100%|| 128/128 [00:22<00:00,  5.65it/s, est. speed input: 5849.45 toks/s, output: 5.71 toks/s]
Processed prompts: 100%|| 128/128 [00:22<00:00,  5.71it/s, est. speed input: 5849.45 toks/s, output: 5.71 toks/s]
[rank0]:[W126 19:55:48.140137527 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-26 19:55:51
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Qwen2.5-7B-FP8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 19:55:58 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 19:55:58 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1676097) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1676097) WARNING 01-26 19:57:18 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 5.60 requests/s, 5738.76 total tokens/s, 5.60 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-26 19:55:58] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 19:55:58] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 19:55:58] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 19:55:58] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:55:58] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:55:58] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:55:58] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:55:58] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:55:58] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 19:55:58] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 19:55:58] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 19:55:58] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 19:55:58] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 19:55:58] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 19:56:01] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 19:56:01] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 19:56:01] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 19:56:01] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:56:01] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:56:01] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:56:01] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:56:01] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:56:01] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 19:56:01] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 19:56:01] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 19:56:01] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 19:56:01] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 19:56:01] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1676097) [2026-01-26 19:56:02] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1676097) [2026-01-26 19:56:02] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1676097) [2026-01-26 19:56:02] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1676097) [2026-01-26 19:56:02] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1676097) [2026-01-26 19:56:02] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1676097) [2026-01-26 19:56:02] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1676097) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1676097) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:28<00:28, 28.62s/it]
(EngineCore_DP0 pid=1676097) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:06<00:00, 34.02s/it]
(EngineCore_DP0 pid=1676097) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:06<00:00, 33.21s/it]
(EngineCore_DP0 pid=1676097) 
(EngineCore_DP0 pid=1676097) [2026-01-26 19:57:10] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=1676097) [2026-01-26 19:57:10] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16588800 bytes
(EngineCore_DP0 pid=1676097) [2026-01-26 19:57:10] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=1676097) [2026-01-26 19:57:10] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 12902400 bytes
(EngineCore_DP0 pid=1676097) [2026-01-26 19:57:10] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=1676097) [2026-01-26 19:57:10] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 136396800 bytes
(EngineCore_DP0 pid=1676097) [2026-01-26 19:57:10] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=1676097) [2026-01-26 19:57:10] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 67952640 bytes
(EngineCore_DP0 pid=1676097) 2026-01-26 19:57:17,240 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1676097) 2026-01-26 19:57:17,365 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  18%|        | 46/256 [00:00<00:00, 453.72it/s]
Adding requests:  36%|      | 92/256 [00:00<00:00, 373.16it/s]
Adding requests:  52%|    | 133/256 [00:00<00:00, 385.86it/s]
Adding requests:  68%|   | 174/256 [00:00<00:00, 392.83it/s]
Adding requests:  84%| | 215/256 [00:00<00:00, 398.59it/s]
Adding requests: 100%|| 256/256 [00:00<00:00, 396.14it/s]
Adding requests: 100%|| 256/256 [00:00<00:00, 395.17it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 2/256 [00:00<00:15, 16.36it/s, est. speed input: 16753.95 toks/s, output: 16.36 toks/s]
Processed prompts:   2%|         | 4/256 [00:00<00:42,  5.86it/s, est. speed input: 6642.67 toks/s, output: 6.49 toks/s]  
Processed prompts:   2%|         | 6/256 [00:01<00:53,  4.69it/s, est. speed input: 5372.58 toks/s, output: 5.25 toks/s]
Processed prompts:   3%|         | 8/256 [00:01<00:49,  5.05it/s, est. speed input: 5486.09 toks/s, output: 5.36 toks/s]
Processed prompts:   4%|         | 10/256 [00:01<00:46,  5.27it/s, est. speed input: 5556.91 toks/s, output: 5.43 toks/s]
Processed prompts:   5%|         | 12/256 [00:02<00:45,  5.41it/s, est. speed input: 5598.54 toks/s, output: 5.47 toks/s]
Processed prompts:   5%|         | 14/256 [00:02<00:43,  5.50it/s, est. speed input: 5632.51 toks/s, output: 5.50 toks/s]
Processed prompts:   6%|         | 16/256 [00:02<00:43,  5.56it/s, est. speed input: 5656.87 toks/s, output: 5.52 toks/s]
Processed prompts:   7%|         | 18/256 [00:03<00:42,  5.58it/s, est. speed input: 5666.85 toks/s, output: 5.53 toks/s]
Processed prompts:   8%|         | 20/256 [00:03<00:41,  5.63it/s, est. speed input: 5688.11 toks/s, output: 5.55 toks/s]
Processed prompts:   9%|         | 22/256 [00:03<00:41,  5.66it/s, est. speed input: 5703.50 toks/s, output: 5.57 toks/s]
Processed prompts:   9%|         | 24/256 [00:04<00:41,  5.66it/s, est. speed input: 5710.78 toks/s, output: 5.58 toks/s]
Processed prompts:  10%|         | 26/256 [00:04<00:40,  5.67it/s, est. speed input: 5719.00 toks/s, output: 5.58 toks/s]
Processed prompts:  11%|         | 28/256 [00:05<00:40,  5.67it/s, est. speed input: 5726.67 toks/s, output: 5.59 toks/s]
Processed prompts:  12%|        | 30/256 [00:05<00:39,  5.66it/s, est. speed input: 5729.36 toks/s, output: 5.60 toks/s]
Processed prompts:  12%|        | 32/256 [00:05<00:39,  5.68it/s, est. speed input: 5737.91 toks/s, output: 5.60 toks/s]
Processed prompts:  13%|        | 34/256 [00:06<00:38,  5.70it/s, est. speed input: 5745.59 toks/s, output: 5.61 toks/s]
Processed prompts:  14%|        | 36/256 [00:06<00:38,  5.67it/s, est. speed input: 5746.18 toks/s, output: 5.61 toks/s]
Processed prompts:  15%|        | 38/256 [00:06<00:38,  5.69it/s, est. speed input: 5751.43 toks/s, output: 5.62 toks/s]
Processed prompts:  16%|        | 40/256 [00:07<00:37,  5.69it/s, est. speed input: 5756.32 toks/s, output: 5.62 toks/s]
Processed prompts:  16%|        | 42/256 [00:07<00:37,  5.68it/s, est. speed input: 5758.26 toks/s, output: 5.62 toks/s]
Processed prompts:  17%|        | 44/256 [00:07<00:37,  5.71it/s, est. speed input: 5764.95 toks/s, output: 5.63 toks/s]
Processed prompts:  18%|        | 46/256 [00:08<00:36,  5.70it/s, est. speed input: 5767.20 toks/s, output: 5.63 toks/s]
Processed prompts:  19%|        | 48/256 [00:08<00:36,  5.67it/s, est. speed input: 5765.79 toks/s, output: 5.63 toks/s]
Processed prompts:  20%|        | 50/256 [00:08<00:36,  5.68it/s, est. speed input: 5768.97 toks/s, output: 5.63 toks/s]
Processed prompts:  20%|        | 52/256 [00:09<00:35,  5.69it/s, est. speed input: 5771.84 toks/s, output: 5.64 toks/s]
Processed prompts:  21%|        | 54/256 [00:09<00:35,  5.66it/s, est. speed input: 5769.88 toks/s, output: 5.63 toks/s]
Processed prompts:  22%|       | 56/256 [00:09<00:35,  5.68it/s, est. speed input: 5772.87 toks/s, output: 5.64 toks/s]
Processed prompts:  23%|       | 58/256 [00:10<00:34,  5.69it/s, est. speed input: 5775.68 toks/s, output: 5.64 toks/s]
Processed prompts:  23%|       | 60/256 [00:10<00:34,  5.67it/s, est. speed input: 5774.81 toks/s, output: 5.64 toks/s]
Processed prompts:  24%|       | 62/256 [00:10<00:34,  5.67it/s, est. speed input: 5776.09 toks/s, output: 5.64 toks/s]
Processed prompts:  25%|       | 64/256 [00:11<00:33,  5.68it/s, est. speed input: 5778.37 toks/s, output: 5.64 toks/s]
Processed prompts:  26%|       | 66/256 [00:11<00:33,  5.66it/s, est. speed input: 5777.62 toks/s, output: 5.64 toks/s]
Processed prompts:  27%|       | 68/256 [00:12<00:33,  5.66it/s, est. speed input: 5777.60 toks/s, output: 5.64 toks/s]
Processed prompts:  27%|       | 70/256 [00:12<00:32,  5.66it/s, est. speed input: 5778.11 toks/s, output: 5.64 toks/s]
Processed prompts:  28%|       | 72/256 [00:12<00:32,  5.66it/s, est. speed input: 5778.44 toks/s, output: 5.64 toks/s]
Processed prompts:  29%|       | 74/256 [00:13<00:32,  5.66it/s, est. speed input: 5779.45 toks/s, output: 5.64 toks/s]
Processed prompts:  30%|       | 76/256 [00:13<00:31,  5.66it/s, est. speed input: 5779.65 toks/s, output: 5.64 toks/s]
Processed prompts:  30%|       | 78/256 [00:13<00:31,  5.65it/s, est. speed input: 5779.36 toks/s, output: 5.64 toks/s]
Processed prompts:  31%|      | 80/256 [00:14<00:31,  5.65it/s, est. speed input: 5779.49 toks/s, output: 5.64 toks/s]
Processed prompts:  32%|      | 82/256 [00:14<00:30,  5.65it/s, est. speed input: 5779.80 toks/s, output: 5.64 toks/s]
Processed prompts:  33%|      | 84/256 [00:14<00:30,  5.64it/s, est. speed input: 5779.35 toks/s, output: 5.64 toks/s]
Processed prompts:  34%|      | 86/256 [00:15<00:30,  5.66it/s, est. speed input: 5780.46 toks/s, output: 5.64 toks/s]
Processed prompts:  34%|      | 88/256 [00:15<00:29,  5.66it/s, est. speed input: 5781.06 toks/s, output: 5.65 toks/s]
Processed prompts:  35%|      | 90/256 [00:15<00:29,  5.66it/s, est. speed input: 5781.07 toks/s, output: 5.65 toks/s]
Processed prompts:  36%|      | 92/256 [00:16<00:28,  5.67it/s, est. speed input: 5782.01 toks/s, output: 5.65 toks/s]
Processed prompts:  37%|      | 94/256 [00:16<00:28,  5.66it/s, est. speed input: 5782.32 toks/s, output: 5.65 toks/s]
Processed prompts:  38%|      | 96/256 [00:17<00:28,  5.64it/s, est. speed input: 5781.10 toks/s, output: 5.65 toks/s]
Processed prompts:  38%|      | 98/256 [00:17<00:27,  5.65it/s, est. speed input: 5781.92 toks/s, output: 5.65 toks/s]
Processed prompts:  39%|      | 100/256 [00:17<00:27,  5.66it/s, est. speed input: 5782.21 toks/s, output: 5.65 toks/s]
Processed prompts:  40%|      | 102/256 [00:18<00:27,  5.64it/s, est. speed input: 5781.09 toks/s, output: 5.65 toks/s]
Processed prompts:  41%|      | 104/256 [00:18<00:26,  5.64it/s, est. speed input: 5781.35 toks/s, output: 5.65 toks/s]
Processed prompts:  41%|     | 106/256 [00:18<00:26,  5.65it/s, est. speed input: 5781.90 toks/s, output: 5.65 toks/s]
Processed prompts:  42%|     | 108/256 [00:19<00:26,  5.64it/s, est. speed input: 5781.21 toks/s, output: 5.65 toks/s]
Processed prompts:  43%|     | 110/256 [00:19<00:25,  5.65it/s, est. speed input: 5781.45 toks/s, output: 5.65 toks/s]
Processed prompts:  44%|     | 112/256 [00:19<00:25,  5.66it/s, est. speed input: 5782.04 toks/s, output: 5.65 toks/s]
Processed prompts:  45%|     | 114/256 [00:20<00:25,  5.63it/s, est. speed input: 5780.73 toks/s, output: 5.65 toks/s]
Processed prompts:  45%|     | 116/256 [00:20<00:24,  5.64it/s, est. speed input: 5781.03 toks/s, output: 5.65 toks/s]
Processed prompts:  46%|     | 118/256 [00:20<00:24,  5.65it/s, est. speed input: 5781.44 toks/s, output: 5.65 toks/s]
Processed prompts:  47%|     | 120/256 [00:21<00:24,  5.63it/s, est. speed input: 5780.61 toks/s, output: 5.65 toks/s]
Processed prompts:  48%|     | 122/256 [00:21<00:23,  5.64it/s, est. speed input: 5780.90 toks/s, output: 5.65 toks/s]
Processed prompts:  48%|     | 124/256 [00:21<00:23,  5.64it/s, est. speed input: 5780.98 toks/s, output: 5.65 toks/s]
Processed prompts:  49%|     | 126/256 [00:22<00:23,  5.63it/s, est. speed input: 5780.38 toks/s, output: 5.64 toks/s]
Processed prompts:  50%|     | 128/256 [00:22<00:22,  5.65it/s, est. speed input: 5781.06 toks/s, output: 5.65 toks/s]
Processed prompts:  51%|     | 130/256 [00:23<00:22,  5.65it/s, est. speed input: 5780.89 toks/s, output: 5.65 toks/s]
Processed prompts:  52%|    | 132/256 [00:23<00:22,  5.63it/s, est. speed input: 5780.24 toks/s, output: 5.64 toks/s]
Processed prompts:  52%|    | 134/256 [00:23<00:21,  5.64it/s, est. speed input: 5780.58 toks/s, output: 5.65 toks/s]
Processed prompts:  53%|    | 136/256 [00:24<00:21,  5.65it/s, est. speed input: 5780.88 toks/s, output: 5.65 toks/s]
Processed prompts:  54%|    | 138/256 [00:24<00:20,  5.64it/s, est. speed input: 5780.23 toks/s, output: 5.64 toks/s]
Processed prompts:  55%|    | 140/256 [00:24<00:20,  5.65it/s, est. speed input: 5780.68 toks/s, output: 5.65 toks/s]
Processed prompts:  55%|    | 142/256 [00:25<00:20,  5.65it/s, est. speed input: 5780.95 toks/s, output: 5.65 toks/s]
Processed prompts:  56%|    | 144/256 [00:25<00:19,  5.64it/s, est. speed input: 5780.23 toks/s, output: 5.64 toks/s]
Processed prompts:  57%|    | 146/256 [00:25<00:19,  5.64it/s, est. speed input: 5780.36 toks/s, output: 5.64 toks/s]
Processed prompts:  58%|    | 148/256 [00:26<00:19,  5.65it/s, est. speed input: 5780.62 toks/s, output: 5.65 toks/s]
Processed prompts:  59%|    | 150/256 [00:26<00:18,  5.63it/s, est. speed input: 5780.03 toks/s, output: 5.64 toks/s]
Processed prompts:  59%|    | 152/256 [00:26<00:18,  5.64it/s, est. speed input: 5780.10 toks/s, output: 5.64 toks/s]
Processed prompts:  60%|    | 154/256 [00:27<00:18,  5.65it/s, est. speed input: 5780.44 toks/s, output: 5.64 toks/s]
Processed prompts:  61%|    | 156/256 [00:27<00:17,  5.64it/s, est. speed input: 5779.96 toks/s, output: 5.64 toks/s]
Processed prompts:  62%|   | 158/256 [00:27<00:17,  5.64it/s, est. speed input: 5779.94 toks/s, output: 5.64 toks/s]
Processed prompts:  62%|   | 160/256 [00:28<00:16,  5.65it/s, est. speed input: 5780.57 toks/s, output: 5.65 toks/s]
Processed prompts:  63%|   | 162/256 [00:28<00:16,  5.63it/s, est. speed input: 5779.57 toks/s, output: 5.64 toks/s]
Processed prompts:  64%|   | 164/256 [00:29<00:16,  5.65it/s, est. speed input: 5780.13 toks/s, output: 5.64 toks/s]
Processed prompts:  65%|   | 166/256 [00:29<00:15,  5.65it/s, est. speed input: 5780.48 toks/s, output: 5.64 toks/s]
Processed prompts:  66%|   | 168/256 [00:29<00:15,  5.63it/s, est. speed input: 5779.59 toks/s, output: 5.64 toks/s]
Processed prompts:  66%|   | 170/256 [00:30<00:15,  5.64it/s, est. speed input: 5779.95 toks/s, output: 5.64 toks/s]
Processed prompts:  67%|   | 172/256 [00:30<00:14,  5.65it/s, est. speed input: 5780.17 toks/s, output: 5.64 toks/s]
Processed prompts:  68%|   | 174/256 [00:30<00:14,  5.63it/s, est. speed input: 5779.54 toks/s, output: 5.64 toks/s]
Processed prompts:  69%|   | 176/256 [00:31<00:14,  5.64it/s, est. speed input: 5779.71 toks/s, output: 5.64 toks/s]
Processed prompts:  70%|   | 178/256 [00:31<00:13,  5.65it/s, est. speed input: 5780.16 toks/s, output: 5.64 toks/s]
Processed prompts:  70%|   | 180/256 [00:31<00:13,  5.63it/s, est. speed input: 5779.55 toks/s, output: 5.64 toks/s]
Processed prompts:  71%|   | 182/256 [00:32<00:13,  5.64it/s, est. speed input: 5779.69 toks/s, output: 5.64 toks/s]
Processed prompts:  72%|  | 184/256 [00:32<00:12,  5.65it/s, est. speed input: 5780.05 toks/s, output: 5.64 toks/s]
Processed prompts:  73%|  | 186/256 [00:32<00:12,  5.63it/s, est. speed input: 5779.39 toks/s, output: 5.64 toks/s]
Processed prompts:  73%|  | 188/256 [00:33<00:12,  5.61it/s, est. speed input: 5778.29 toks/s, output: 5.64 toks/s]
Processed prompts:  74%|  | 190/256 [00:33<00:11,  5.60it/s, est. speed input: 5777.74 toks/s, output: 5.64 toks/s]
Processed prompts:  75%|  | 192/256 [00:34<00:11,  5.60it/s, est. speed input: 5777.24 toks/s, output: 5.64 toks/s]
Processed prompts:  76%|  | 194/256 [00:34<00:11,  5.61it/s, est. speed input: 5777.34 toks/s, output: 5.64 toks/s]
Processed prompts:  77%|  | 196/256 [00:34<00:10,  5.64it/s, est. speed input: 5777.78 toks/s, output: 5.64 toks/s]
Processed prompts:  77%|  | 198/256 [00:35<00:10,  5.62it/s, est. speed input: 5777.14 toks/s, output: 5.64 toks/s]
Processed prompts:  78%|  | 200/256 [00:35<00:09,  5.63it/s, est. speed input: 5777.33 toks/s, output: 5.64 toks/s]
Processed prompts:  79%|  | 202/256 [00:35<00:08,  6.36it/s, est. speed input: 5799.22 toks/s, output: 5.66 toks/s]
Processed prompts:  80%|  | 204/256 [00:36<00:08,  6.10it/s, est. speed input: 5798.34 toks/s, output: 5.66 toks/s]
Processed prompts:  80%|  | 206/256 [00:36<00:08,  5.97it/s, est. speed input: 5798.54 toks/s, output: 5.66 toks/s]
Processed prompts:  81%| | 208/256 [00:36<00:08,  5.88it/s, est. speed input: 5798.55 toks/s, output: 5.66 toks/s]
Processed prompts:  82%| | 210/256 [00:37<00:07,  5.79it/s, est. speed input: 5797.82 toks/s, output: 5.66 toks/s]
Processed prompts:  83%| | 212/256 [00:37<00:07,  5.75it/s, est. speed input: 5797.82 toks/s, output: 5.66 toks/s]
Processed prompts:  84%| | 214/256 [00:37<00:07,  5.74it/s, est. speed input: 5798.22 toks/s, output: 5.66 toks/s]
Processed prompts:  84%| | 216/256 [00:38<00:07,  5.69it/s, est. speed input: 5797.43 toks/s, output: 5.66 toks/s]
Processed prompts:  85%| | 218/256 [00:38<00:06,  5.68it/s, est. speed input: 5797.43 toks/s, output: 5.66 toks/s]
Processed prompts:  86%| | 220/256 [00:38<00:06,  5.68it/s, est. speed input: 5797.45 toks/s, output: 5.66 toks/s]
Processed prompts:  87%| | 222/256 [00:39<00:06,  5.64it/s, est. speed input: 5796.47 toks/s, output: 5.66 toks/s]
Processed prompts:  88%| | 224/256 [00:39<00:05,  5.64it/s, est. speed input: 5796.31 toks/s, output: 5.66 toks/s]
Processed prompts:  88%| | 226/256 [00:39<00:05,  5.64it/s, est. speed input: 5796.10 toks/s, output: 5.66 toks/s]
Processed prompts:  89%| | 228/256 [00:40<00:04,  5.63it/s, est. speed input: 5795.60 toks/s, output: 5.66 toks/s]
Processed prompts:  90%| | 230/256 [00:40<00:04,  5.64it/s, est. speed input: 5795.58 toks/s, output: 5.66 toks/s]
Processed prompts:  91%| | 232/256 [00:40<00:04,  5.65it/s, est. speed input: 5795.87 toks/s, output: 5.66 toks/s]
Processed prompts:  91%|| 234/256 [00:41<00:03,  5.63it/s, est. speed input: 5795.20 toks/s, output: 5.66 toks/s]
Processed prompts:  92%|| 236/256 [00:41<00:03,  5.63it/s, est. speed input: 5794.88 toks/s, output: 5.66 toks/s]
Processed prompts:  93%|| 238/256 [00:42<00:03,  5.63it/s, est. speed input: 5794.71 toks/s, output: 5.66 toks/s]
Processed prompts:  94%|| 240/256 [00:42<00:02,  5.62it/s, est. speed input: 5794.16 toks/s, output: 5.66 toks/s]
Processed prompts:  95%|| 242/256 [00:42<00:02,  5.63it/s, est. speed input: 5794.07 toks/s, output: 5.66 toks/s]
Processed prompts:  95%|| 244/256 [00:43<00:02,  5.63it/s, est. speed input: 5793.89 toks/s, output: 5.66 toks/s]
Processed prompts:  96%|| 246/256 [00:43<00:01,  5.61it/s, est. speed input: 5793.13 toks/s, output: 5.66 toks/s]
Processed prompts:  97%|| 248/256 [00:43<00:01,  5.63it/s, est. speed input: 5793.32 toks/s, output: 5.66 toks/s]
Processed prompts:  98%|| 250/256 [00:44<00:01,  5.64it/s, est. speed input: 5793.31 toks/s, output: 5.66 toks/s]
Processed prompts:  98%|| 252/256 [00:44<00:00,  5.63it/s, est. speed input: 5792.86 toks/s, output: 5.66 toks/s]
Processed prompts:  99%|| 254/256 [00:44<00:00,  5.64it/s, est. speed input: 5793.06 toks/s, output: 5.66 toks/s]
Processed prompts: 100%|| 256/256 [00:45<00:00,  6.64it/s, est. speed input: 5815.68 toks/s, output: 5.68 toks/s]
Processed prompts: 100%|| 256/256 [00:45<00:00,  6.64it/s, est. speed input: 5815.68 toks/s, output: 5.68 toks/s]
Processed prompts: 100%|| 256/256 [00:45<00:00,  5.68it/s, est. speed input: 5815.68 toks/s, output: 5.68 toks/s]
[rank0]:[W126 19:58:04.711062121 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-26 19:58:07
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Qwen2.5-7B-FP8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 19:58:14 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 19:58:14 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1678161) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1678161) WARNING 01-26 19:59:37 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 5.46 requests/s, 5593.37 total tokens/s, 5.46 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-26 19:58:14] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 19:58:14] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 19:58:14] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 19:58:14] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:58:14] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:58:14] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:58:14] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:58:14] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:58:14] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 19:58:14] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 19:58:14] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 19:58:14] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 19:58:14] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 19:58:14] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 19:58:18] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 19:58:18] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 19:58:18] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 19:58:18] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:58:18] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:58:18] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:58:18] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:58:18] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:58:18] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 19:58:18] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 19:58:18] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 19:58:18] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 19:58:18] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 19:58:18] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1678161) [2026-01-26 19:58:19] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1678161) [2026-01-26 19:58:19] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1678161) [2026-01-26 19:58:19] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1678161) [2026-01-26 19:58:19] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1678161) [2026-01-26 19:58:19] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1678161) [2026-01-26 19:58:19] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1678161) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1678161) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:29<00:29, 29.25s/it]
(EngineCore_DP0 pid=1678161) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:07<00:00, 34.80s/it]
(EngineCore_DP0 pid=1678161) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:07<00:00, 33.97s/it]
(EngineCore_DP0 pid=1678161) 
(EngineCore_DP0 pid=1678161) [2026-01-26 19:59:28] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=1678161) [2026-01-26 19:59:28] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16588800 bytes
(EngineCore_DP0 pid=1678161) [2026-01-26 19:59:28] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=1678161) [2026-01-26 19:59:28] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 12902400 bytes
(EngineCore_DP0 pid=1678161) [2026-01-26 19:59:28] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=1678161) [2026-01-26 19:59:28] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 136396800 bytes
(EngineCore_DP0 pid=1678161) [2026-01-26 19:59:28] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=1678161) [2026-01-26 19:59:28] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 67952640 bytes
(EngineCore_DP0 pid=1678161) 2026-01-26 19:59:35,813 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1678161) 2026-01-26 19:59:36,020 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   0%|          | 1/512 [00:01<10:08,  1.19s/it]
Adding requests:   0%|          | 2/512 [00:01<05:43,  1.49it/s]
Adding requests:   1%|          | 3/512 [00:01<03:42,  2.29it/s]
Adding requests:   1%|          | 4/512 [00:01<02:34,  3.28it/s]
Adding requests:   1%|          | 6/512 [00:01<01:34,  5.35it/s]
Adding requests:   2%|         | 8/512 [00:02<01:04,  7.77it/s]
Adding requests:   2%|         | 11/512 [00:02<00:42, 11.80it/s]
Adding requests:   3%|         | 14/512 [00:02<00:33, 14.75it/s]
Adding requests:   5%|         | 24/512 [00:02<00:14, 33.47it/s]
Adding requests:   8%|         | 39/512 [00:02<00:07, 60.59it/s]
Adding requests:  11%|         | 57/512 [00:02<00:05, 89.44it/s]
Adding requests:  15%|        | 75/512 [00:02<00:03, 112.65it/s]
Adding requests:  19%|        | 99/512 [00:02<00:02, 147.03it/s]
Adding requests:  25%|       | 128/512 [00:02<00:02, 184.95it/s]
Adding requests:  32%|      | 163/512 [00:02<00:01, 230.96it/s]
Adding requests:  38%|      | 196/512 [00:03<00:01, 259.13it/s]
Adding requests:  45%|     | 229/512 [00:03<00:01, 278.80it/s]
Adding requests:  54%|    | 276/512 [00:03<00:00, 329.49it/s]
Adding requests:  62%|   | 316/512 [00:03<00:00, 348.41it/s]
Adding requests:  69%|   | 355/512 [00:03<00:00, 360.52it/s]
Adding requests:  77%|  | 394/512 [00:03<00:00, 367.15it/s]
Adding requests:  85%| | 435/512 [00:03<00:00, 379.60it/s]
Adding requests:  93%|| 478/512 [00:03<00:00, 392.28it/s]
Adding requests: 100%|| 512/512 [00:03<00:00, 132.02it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 12/512 [00:00<00:10, 49.15it/s, est. speed input: 50331.06 toks/s, output: 49.15 toks/s]
Processed prompts:   3%|         | 17/512 [00:00<00:32, 15.12it/s, est. speed input: 18139.40 toks/s, output: 17.71 toks/s]
Processed prompts:   4%|         | 20/512 [00:01<00:53,  9.23it/s, est. speed input: 12190.54 toks/s, output: 11.90 toks/s]
Processed prompts:   5%|         | 24/512 [00:02<01:04,  7.62it/s, est. speed input: 10228.67 toks/s, output: 9.99 toks/s] 
Processed prompts:   5%|         | 28/512 [00:03<01:10,  6.85it/s, est. speed input: 9196.51 toks/s, output: 8.98 toks/s] 
Processed prompts:   6%|         | 32/512 [00:03<01:15,  6.39it/s, est. speed input: 8537.21 toks/s, output: 8.34 toks/s]
Processed prompts:   7%|         | 36/512 [00:04<01:17,  6.10it/s, est. speed input: 8083.50 toks/s, output: 7.89 toks/s]
Processed prompts:   8%|         | 40/512 [00:05<01:19,  5.94it/s, est. speed input: 7762.21 toks/s, output: 7.58 toks/s]
Processed prompts:   9%|         | 44/512 [00:05<01:20,  5.81it/s, est. speed input: 7511.95 toks/s, output: 7.34 toks/s]
Processed prompts:   9%|         | 48/512 [00:06<01:20,  5.73it/s, est. speed input: 7315.51 toks/s, output: 7.14 toks/s]
Processed prompts:  10%|         | 52/512 [00:07<01:20,  5.68it/s, est. speed input: 7159.93 toks/s, output: 6.99 toks/s]
Processed prompts:  11%|         | 56/512 [00:08<01:20,  5.63it/s, est. speed input: 7026.07 toks/s, output: 6.86 toks/s]
Processed prompts:  12%|        | 60/512 [00:08<01:20,  5.61it/s, est. speed input: 6916.67 toks/s, output: 6.75 toks/s]
Processed prompts:  12%|        | 64/512 [00:09<01:20,  5.60it/s, est. speed input: 6826.97 toks/s, output: 6.67 toks/s]
Processed prompts:  13%|        | 68/512 [00:10<01:19,  5.58it/s, est. speed input: 6746.14 toks/s, output: 6.59 toks/s]
Processed prompts:  14%|        | 72/512 [00:11<01:19,  5.56it/s, est. speed input: 6673.29 toks/s, output: 6.52 toks/s]
Processed prompts:  15%|        | 76/512 [00:11<01:18,  5.56it/s, est. speed input: 6614.15 toks/s, output: 6.46 toks/s]
Processed prompts:  16%|        | 80/512 [00:12<01:17,  5.55it/s, est. speed input: 6557.59 toks/s, output: 6.40 toks/s]
Processed prompts:  16%|        | 84/512 [00:13<01:17,  5.54it/s, est. speed input: 6508.52 toks/s, output: 6.36 toks/s]
Processed prompts:  17%|        | 88/512 [00:13<01:16,  5.55it/s, est. speed input: 6466.20 toks/s, output: 6.31 toks/s]
Processed prompts:  18%|        | 92/512 [00:14<01:15,  5.54it/s, est. speed input: 6426.15 toks/s, output: 6.28 toks/s]
Processed prompts:  19%|        | 96/512 [00:15<01:15,  5.54it/s, est. speed input: 6390.30 toks/s, output: 6.24 toks/s]
Processed prompts:  20%|        | 100/512 [00:16<01:14,  5.54it/s, est. speed input: 6358.27 toks/s, output: 6.21 toks/s]
Processed prompts:  20%|        | 104/512 [00:16<01:13,  5.55it/s, est. speed input: 6330.04 toks/s, output: 6.18 toks/s]
Processed prompts:  21%|        | 108/512 [00:17<01:12,  5.54it/s, est. speed input: 6302.41 toks/s, output: 6.15 toks/s]
Processed prompts:  22%|       | 112/512 [00:18<01:12,  5.52it/s, est. speed input: 6275.14 toks/s, output: 6.13 toks/s]
Processed prompts:  23%|       | 116/512 [00:18<01:11,  5.54it/s, est. speed input: 6253.13 toks/s, output: 6.11 toks/s]
Processed prompts:  23%|       | 120/512 [00:19<01:10,  5.53it/s, est. speed input: 6231.23 toks/s, output: 6.09 toks/s]
Processed prompts:  24%|       | 124/512 [00:20<01:10,  5.52it/s, est. speed input: 6209.55 toks/s, output: 6.06 toks/s]
Processed prompts:  25%|       | 128/512 [00:21<01:09,  5.53it/s, est. speed input: 6191.98 toks/s, output: 6.05 toks/s]
Processed prompts:  26%|       | 132/512 [00:21<01:08,  5.53it/s, est. speed input: 6174.35 toks/s, output: 6.03 toks/s]
Processed prompts:  27%|       | 136/512 [00:22<01:08,  5.53it/s, est. speed input: 6157.64 toks/s, output: 6.01 toks/s]
Processed prompts:  27%|       | 140/512 [00:23<01:07,  5.53it/s, est. speed input: 6142.48 toks/s, output: 6.00 toks/s]
Processed prompts:  28%|       | 144/512 [00:24<01:06,  5.52it/s, est. speed input: 6126.67 toks/s, output: 5.98 toks/s]
Processed prompts:  29%|       | 148/512 [00:24<01:06,  5.51it/s, est. speed input: 6112.24 toks/s, output: 5.97 toks/s]
Processed prompts:  30%|       | 152/512 [00:25<01:05,  5.52it/s, est. speed input: 6099.91 toks/s, output: 5.96 toks/s]
Processed prompts:  30%|       | 156/512 [00:26<01:04,  5.53it/s, est. speed input: 6088.08 toks/s, output: 5.95 toks/s]
Processed prompts:  31%|      | 160/512 [00:26<01:03,  5.52it/s, est. speed input: 6075.91 toks/s, output: 5.93 toks/s]
Processed prompts:  32%|      | 164/512 [00:27<01:02,  5.53it/s, est. speed input: 6065.63 toks/s, output: 5.92 toks/s]
Processed prompts:  33%|      | 168/512 [00:28<01:02,  5.53it/s, est. speed input: 6055.57 toks/s, output: 5.91 toks/s]
Processed prompts:  34%|      | 172/512 [00:29<01:01,  5.53it/s, est. speed input: 6045.58 toks/s, output: 5.90 toks/s]
Processed prompts:  34%|      | 176/512 [00:29<01:00,  5.53it/s, est. speed input: 6036.42 toks/s, output: 5.89 toks/s]
Processed prompts:  35%|      | 180/512 [00:30<01:00,  5.53it/s, est. speed input: 6027.23 toks/s, output: 5.89 toks/s]
Processed prompts:  36%|      | 184/512 [00:31<00:59,  5.52it/s, est. speed input: 6018.39 toks/s, output: 5.88 toks/s]
Processed prompts:  37%|      | 188/512 [00:32<00:58,  5.49it/s, est. speed input: 6007.83 toks/s, output: 5.87 toks/s]
Processed prompts:  38%|      | 192/512 [00:32<00:58,  5.51it/s, est. speed input: 6000.92 toks/s, output: 5.86 toks/s]
Processed prompts:  38%|      | 196/512 [00:33<00:57,  5.52it/s, est. speed input: 5993.41 toks/s, output: 5.85 toks/s]
Processed prompts:  39%|      | 200/512 [00:34<00:52,  5.91it/s, est. speed input: 6014.36 toks/s, output: 5.87 toks/s]
Processed prompts:  40%|      | 204/512 [00:34<00:53,  5.78it/s, est. speed input: 6006.69 toks/s, output: 5.87 toks/s]
Processed prompts:  41%|      | 208/512 [00:35<00:53,  5.69it/s, est. speed input: 5998.60 toks/s, output: 5.86 toks/s]
Processed prompts:  41%|     | 212/512 [00:36<00:53,  5.65it/s, est. speed input: 5992.57 toks/s, output: 5.85 toks/s]
Processed prompts:  42%|     | 216/512 [00:36<00:52,  5.61it/s, est. speed input: 5985.54 toks/s, output: 5.85 toks/s]
Processed prompts:  43%|     | 220/512 [00:37<00:52,  5.58it/s, est. speed input: 5978.81 toks/s, output: 5.84 toks/s]
Processed prompts:  44%|     | 224/512 [00:38<00:51,  5.57it/s, est. speed input: 5973.18 toks/s, output: 5.83 toks/s]
Processed prompts:  45%|     | 228/512 [00:39<00:51,  5.55it/s, est. speed input: 5967.04 toks/s, output: 5.83 toks/s]
Processed prompts:  45%|     | 232/512 [00:39<00:50,  5.52it/s, est. speed input: 5959.92 toks/s, output: 5.82 toks/s]
Processed prompts:  46%|     | 236/512 [00:40<00:50,  5.51it/s, est. speed input: 5953.68 toks/s, output: 5.81 toks/s]
Processed prompts:  47%|     | 240/512 [00:41<00:49,  5.52it/s, est. speed input: 5948.63 toks/s, output: 5.81 toks/s]
Processed prompts:  48%|     | 244/512 [00:42<00:48,  5.50it/s, est. speed input: 5942.71 toks/s, output: 5.80 toks/s]
Processed prompts:  48%|     | 248/512 [00:42<00:47,  5.50it/s, est. speed input: 5937.54 toks/s, output: 5.80 toks/s]
Processed prompts:  49%|     | 252/512 [00:43<00:47,  5.51it/s, est. speed input: 5932.99 toks/s, output: 5.79 toks/s]
Processed prompts:  50%|     | 256/512 [00:44<00:46,  5.51it/s, est. speed input: 5928.24 toks/s, output: 5.79 toks/s]
Processed prompts:  51%|     | 260/512 [00:44<00:45,  5.51it/s, est. speed input: 5923.36 toks/s, output: 5.78 toks/s]
Processed prompts:  52%|    | 264/512 [00:45<00:44,  5.52it/s, est. speed input: 5919.49 toks/s, output: 5.78 toks/s]
Processed prompts:  52%|    | 268/512 [00:46<00:44,  5.51it/s, est. speed input: 5914.88 toks/s, output: 5.78 toks/s]
Processed prompts:  53%|    | 272/512 [00:47<00:43,  5.51it/s, est. speed input: 5910.52 toks/s, output: 5.77 toks/s]
Processed prompts:  54%|    | 276/512 [00:47<00:42,  5.52it/s, est. speed input: 5907.19 toks/s, output: 5.77 toks/s]
Processed prompts:  55%|    | 280/512 [00:48<00:42,  5.52it/s, est. speed input: 5903.11 toks/s, output: 5.76 toks/s]
Processed prompts:  55%|    | 284/512 [00:49<00:41,  5.51it/s, est. speed input: 5899.11 toks/s, output: 5.76 toks/s]
Processed prompts:  56%|    | 288/512 [00:50<00:40,  5.51it/s, est. speed input: 5895.38 toks/s, output: 5.76 toks/s]
Processed prompts:  57%|    | 292/512 [00:50<00:39,  5.51it/s, est. speed input: 5891.56 toks/s, output: 5.75 toks/s]
Processed prompts:  58%|    | 296/512 [00:51<00:39,  5.50it/s, est. speed input: 5887.85 toks/s, output: 5.75 toks/s]
Processed prompts:  59%|    | 300/512 [00:52<00:38,  5.51it/s, est. speed input: 5884.81 toks/s, output: 5.75 toks/s]
Processed prompts:  59%|    | 304/512 [00:52<00:35,  5.93it/s, est. speed input: 5900.50 toks/s, output: 5.76 toks/s]
Processed prompts:  60%|    | 308/512 [00:53<00:35,  5.80it/s, est. speed input: 5896.87 toks/s, output: 5.76 toks/s]
Processed prompts:  61%|    | 312/512 [00:54<00:35,  5.71it/s, est. speed input: 5893.74 toks/s, output: 5.76 toks/s]
Processed prompts:  62%|   | 316/512 [00:54<00:34,  5.64it/s, est. speed input: 5890.15 toks/s, output: 5.75 toks/s]
Processed prompts:  62%|   | 320/512 [00:55<00:34,  5.60it/s, est. speed input: 5886.61 toks/s, output: 5.75 toks/s]
Processed prompts:  63%|   | 324/512 [00:56<00:33,  5.58it/s, est. speed input: 5884.11 toks/s, output: 5.75 toks/s]
Processed prompts:  64%|   | 328/512 [00:57<00:33,  5.55it/s, est. speed input: 5880.70 toks/s, output: 5.74 toks/s]
Processed prompts:  65%|   | 332/512 [00:57<00:32,  5.54it/s, est. speed input: 5877.55 toks/s, output: 5.74 toks/s]
Processed prompts:  66%|   | 336/512 [00:58<00:31,  5.53it/s, est. speed input: 5874.73 toks/s, output: 5.74 toks/s]
Processed prompts:  66%|   | 340/512 [00:59<00:31,  5.52it/s, est. speed input: 5871.84 toks/s, output: 5.73 toks/s]
Processed prompts:  67%|   | 344/512 [01:00<00:30,  5.51it/s, est. speed input: 5868.81 toks/s, output: 5.73 toks/s]
Processed prompts:  68%|   | 348/512 [01:00<00:29,  5.52it/s, est. speed input: 5866.45 toks/s, output: 5.73 toks/s]
Processed prompts:  69%|   | 352/512 [01:01<00:29,  5.51it/s, est. speed input: 5863.52 toks/s, output: 5.73 toks/s]
Processed prompts:  70%|   | 356/512 [01:02<00:28,  5.50it/s, est. speed input: 5860.58 toks/s, output: 5.72 toks/s]
Processed prompts:  70%|   | 360/512 [01:02<00:27,  5.50it/s, est. speed input: 5857.94 toks/s, output: 5.72 toks/s]
Processed prompts:  71%|   | 364/512 [01:03<00:26,  5.51it/s, est. speed input: 5855.67 toks/s, output: 5.72 toks/s]
Processed prompts:  72%|  | 368/512 [01:04<00:26,  5.50it/s, est. speed input: 5852.92 toks/s, output: 5.72 toks/s]
Processed prompts:  73%|  | 372/512 [01:05<00:25,  5.50it/s, est. speed input: 5850.36 toks/s, output: 5.71 toks/s]
Processed prompts:  73%|  | 376/512 [01:05<00:24,  5.50it/s, est. speed input: 5848.10 toks/s, output: 5.71 toks/s]
Processed prompts:  74%|  | 380/512 [01:06<00:24,  5.50it/s, est. speed input: 5845.66 toks/s, output: 5.71 toks/s]
Processed prompts:  75%|  | 384/512 [01:07<00:23,  5.50it/s, est. speed input: 5843.18 toks/s, output: 5.71 toks/s]
Processed prompts:  76%|  | 388/512 [01:08<00:22,  5.51it/s, est. speed input: 5841.54 toks/s, output: 5.70 toks/s]
Processed prompts:  77%|  | 392/512 [01:08<00:21,  5.50it/s, est. speed input: 5839.11 toks/s, output: 5.70 toks/s]
Processed prompts:  77%|  | 396/512 [01:09<00:21,  5.49it/s, est. speed input: 5836.48 toks/s, output: 5.70 toks/s]
Processed prompts:  78%|  | 400/512 [01:10<00:20,  5.51it/s, est. speed input: 5834.91 toks/s, output: 5.70 toks/s]
Processed prompts:  79%|  | 404/512 [01:10<00:19,  5.49it/s, est. speed input: 5832.38 toks/s, output: 5.70 toks/s]
Processed prompts:  80%|  | 408/512 [01:11<00:18,  5.50it/s, est. speed input: 5830.54 toks/s, output: 5.69 toks/s]
Processed prompts:  80%|  | 412/512 [01:12<00:18,  5.51it/s, est. speed input: 5828.72 toks/s, output: 5.69 toks/s]
Processed prompts:  81%| | 416/512 [01:13<00:17,  5.50it/s, est. speed input: 5826.62 toks/s, output: 5.69 toks/s]
Processed prompts:  82%| | 420/512 [01:13<00:16,  5.49it/s, est. speed input: 5824.53 toks/s, output: 5.69 toks/s]
Processed prompts:  83%| | 424/512 [01:14<00:15,  5.51it/s, est. speed input: 5823.11 toks/s, output: 5.69 toks/s]
Processed prompts:  84%| | 428/512 [01:15<00:15,  5.51it/s, est. speed input: 5821.23 toks/s, output: 5.68 toks/s]
Processed prompts:  84%| | 432/512 [01:16<00:14,  5.50it/s, est. speed input: 5819.25 toks/s, output: 5.68 toks/s]
Processed prompts:  85%| | 436/512 [01:16<00:12,  5.94it/s, est. speed input: 5831.18 toks/s, output: 5.69 toks/s]
Processed prompts:  86%| | 440/512 [01:17<00:12,  5.79it/s, est. speed input: 5828.95 toks/s, output: 5.69 toks/s]
Processed prompts:  87%| | 444/512 [01:18<00:11,  5.69it/s, est. speed input: 5826.71 toks/s, output: 5.69 toks/s]
Processed prompts:  88%| | 448/512 [01:18<00:11,  5.63it/s, est. speed input: 5824.96 toks/s, output: 5.69 toks/s]
Processed prompts:  88%| | 452/512 [01:19<00:10,  5.58it/s, est. speed input: 5822.75 toks/s, output: 5.69 toks/s]
Processed prompts:  89%| | 456/512 [01:20<00:10,  5.55it/s, est. speed input: 5821.06 toks/s, output: 5.68 toks/s]
Processed prompts:  90%| | 460/512 [01:20<00:09,  5.54it/s, est. speed input: 5819.40 toks/s, output: 5.68 toks/s]
Processed prompts:  91%| | 464/512 [01:21<00:08,  5.53it/s, est. speed input: 5817.67 toks/s, output: 5.68 toks/s]
Processed prompts:  91%|| 468/512 [01:22<00:07,  5.51it/s, est. speed input: 5815.91 toks/s, output: 5.68 toks/s]
Processed prompts:  92%|| 472/512 [01:23<00:07,  5.51it/s, est. speed input: 5814.38 toks/s, output: 5.68 toks/s]
Processed prompts:  93%|| 476/512 [01:23<00:06,  5.51it/s, est. speed input: 5812.76 toks/s, output: 5.68 toks/s]
Processed prompts:  94%|| 480/512 [01:24<00:05,  5.50it/s, est. speed input: 5811.07 toks/s, output: 5.67 toks/s]
Processed prompts:  95%|| 484/512 [01:25<00:05,  5.50it/s, est. speed input: 5809.58 toks/s, output: 5.67 toks/s]
Processed prompts:  95%|| 488/512 [01:26<00:04,  5.51it/s, est. speed input: 5808.30 toks/s, output: 5.67 toks/s]
Processed prompts:  96%|| 492/512 [01:26<00:03,  5.51it/s, est. speed input: 5806.81 toks/s, output: 5.67 toks/s]
Processed prompts:  97%|| 496/512 [01:27<00:02,  5.50it/s, est. speed input: 5805.29 toks/s, output: 5.67 toks/s]
Processed prompts:  98%|| 500/512 [01:28<00:02,  5.51it/s, est. speed input: 5804.01 toks/s, output: 5.67 toks/s]
Processed prompts:  98%|| 504/512 [01:28<00:01,  5.50it/s, est. speed input: 5802.60 toks/s, output: 5.67 toks/s]
Processed prompts:  99%|| 508/512 [01:29<00:00,  5.50it/s, est. speed input: 5801.13 toks/s, output: 5.67 toks/s]
Processed prompts: 100%|| 512/512 [01:29<00:00,  7.10it/s, est. speed input: 5834.97 toks/s, output: 5.70 toks/s]
Processed prompts: 100%|| 512/512 [01:29<00:00,  7.10it/s, est. speed input: 5834.97 toks/s, output: 5.70 toks/s]
Processed prompts: 100%|| 512/512 [01:29<00:00,  5.70it/s, est. speed input: 5834.97 toks/s, output: 5.70 toks/s]
[rank0]:[W126 20:01:11.025078347 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-26 20:01:24
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Qwen2.5-7B-FP8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 20:01:31 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 20:01:31 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1681062) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1681062) WARNING 01-26 20:02:54 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 5.62 requests/s, 5758.16 total tokens/s, 5.62 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-26 20:01:31] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 20:01:31] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 20:01:31] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 20:01:31] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:01:31] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:01:31] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:01:31] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:01:31] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:01:31] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 20:01:31] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 20:01:31] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 20:01:31] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 20:01:31] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 20:01:31] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 20:01:34] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 20:01:34] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 20:01:34] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 20:01:34] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:01:34] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:01:34] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:01:34] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:01:34] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:01:34] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 20:01:34] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 20:01:34] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 20:01:34] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 20:01:34] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 20:01:34] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1681062) [2026-01-26 20:01:35] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1681062) [2026-01-26 20:01:35] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1681062) [2026-01-26 20:01:35] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1681062) [2026-01-26 20:01:35] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1681062) [2026-01-26 20:01:35] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1681062) [2026-01-26 20:01:35] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1681062) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1681062) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:29<00:29, 29.17s/it]
(EngineCore_DP0 pid=1681062) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:07<00:00, 34.73s/it]
(EngineCore_DP0 pid=1681062) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:07<00:00, 33.90s/it]
(EngineCore_DP0 pid=1681062) 
(EngineCore_DP0 pid=1681062) [2026-01-26 20:02:44] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=1681062) [2026-01-26 20:02:44] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16588800 bytes
(EngineCore_DP0 pid=1681062) [2026-01-26 20:02:44] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=1681062) [2026-01-26 20:02:44] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 12902400 bytes
(EngineCore_DP0 pid=1681062) [2026-01-26 20:02:44] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=1681062) [2026-01-26 20:02:44] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 136396800 bytes
(EngineCore_DP0 pid=1681062) [2026-01-26 20:02:44] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=1681062) [2026-01-26 20:02:44] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 67952640 bytes
(EngineCore_DP0 pid=1681062) 2026-01-26 20:02:51,578 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1681062) 2026-01-26 20:02:52,093 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   4%|         | 44/1024 [00:00<00:02, 436.32it/s]
Adding requests:   9%|         | 88/1024 [00:00<00:02, 376.71it/s]
Adding requests:  13%|        | 129/1024 [00:00<00:02, 390.30it/s]
Adding requests:  17%|        | 169/1024 [00:00<00:02, 388.12it/s]
Adding requests:  21%|        | 214/1024 [00:00<00:01, 409.10it/s]
Adding requests:  25%|       | 256/1024 [00:00<00:01, 411.60it/s]
Adding requests:  29%|       | 301/1024 [00:00<00:01, 422.41it/s]
Adding requests:  34%|      | 346/1024 [00:00<00:01, 429.46it/s]
Adding requests:  38%|      | 392/1024 [00:00<00:01, 438.60it/s]
Adding requests:  43%|     | 437/1024 [00:01<00:01, 440.55it/s]
Adding requests:  47%|     | 482/1024 [00:01<00:01, 428.46it/s]
Adding requests:  52%|    | 528/1024 [00:01<00:01, 437.51it/s]
Adding requests:  56%|    | 572/1024 [00:01<00:01, 413.68it/s]
Adding requests:  60%|    | 614/1024 [00:01<00:01, 408.66it/s]
Adding requests:  64%|   | 656/1024 [00:01<00:00, 399.02it/s]
Adding requests:  68%|   | 699/1024 [00:01<00:00, 406.35it/s]
Adding requests:  72%|  | 740/1024 [00:01<00:00, 403.00it/s]
Adding requests:  76%|  | 781/1024 [00:01<00:00, 398.06it/s]
Adding requests:  80%|  | 823/1024 [00:01<00:00, 402.03it/s]
Adding requests:  84%| | 864/1024 [00:02<00:00, 397.04it/s]
Adding requests:  89%| | 907/1024 [00:02<00:00, 402.49it/s]
Adding requests:  93%|| 948/1024 [00:02<00:00, 398.57it/s]
Adding requests:  97%|| 990/1024 [00:02<00:00, 404.69it/s]
Adding requests: 100%|| 1024/1024 [00:02<00:00, 410.31it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 10/1024 [00:00<01:03, 15.92it/s, est. speed input: 16304.17 toks/s, output: 15.92 toks/s]
Processed prompts:   2%|         | 18/1024 [00:02<02:04,  8.11it/s, est. speed input: 9039.95 toks/s, output: 8.83 toks/s]  
Processed prompts:   3%|         | 26/1024 [00:03<02:26,  6.83it/s, est. speed input: 7716.48 toks/s, output: 7.54 toks/s]
Processed prompts:   3%|         | 34/1024 [00:04<02:36,  6.33it/s, est. speed input: 7152.63 toks/s, output: 6.98 toks/s]
Processed prompts:   4%|         | 42/1024 [00:06<02:41,  6.07it/s, est. speed input: 6847.44 toks/s, output: 6.69 toks/s]
Processed prompts:   5%|         | 50/1024 [00:07<02:44,  5.93it/s, est. speed input: 6656.04 toks/s, output: 6.50 toks/s]
Processed prompts:   6%|         | 58/1024 [00:09<02:45,  5.84it/s, est. speed input: 6520.67 toks/s, output: 6.37 toks/s]
Processed prompts:   6%|         | 66/1024 [00:10<02:45,  5.78it/s, est. speed input: 6424.04 toks/s, output: 6.27 toks/s]
Processed prompts:   7%|         | 74/1024 [00:11<02:45,  5.74it/s, est. speed input: 6349.97 toks/s, output: 6.20 toks/s]
Processed prompts:   8%|         | 82/1024 [00:13<02:45,  5.71it/s, est. speed input: 6287.67 toks/s, output: 6.14 toks/s]
Processed prompts:   9%|         | 90/1024 [00:14<02:44,  5.69it/s, est. speed input: 6240.58 toks/s, output: 6.09 toks/s]
Processed prompts:  10%|         | 98/1024 [00:16<02:42,  5.69it/s, est. speed input: 6202.45 toks/s, output: 6.06 toks/s]
Processed prompts:  10%|         | 106/1024 [00:17<02:41,  5.68it/s, est. speed input: 6169.42 toks/s, output: 6.02 toks/s]
Processed prompts:  11%|         | 114/1024 [00:19<02:40,  5.67it/s, est. speed input: 6141.68 toks/s, output: 6.00 toks/s]
Processed prompts:  12%|        | 122/1024 [00:20<02:39,  5.66it/s, est. speed input: 6116.95 toks/s, output: 5.97 toks/s]
Processed prompts:  13%|        | 130/1024 [00:21<02:38,  5.65it/s, est. speed input: 6093.92 toks/s, output: 5.95 toks/s]
Processed prompts:  13%|        | 138/1024 [00:23<02:36,  5.65it/s, est. speed input: 6075.59 toks/s, output: 5.93 toks/s]
Processed prompts:  14%|        | 146/1024 [00:24<02:35,  5.64it/s, est. speed input: 6056.68 toks/s, output: 5.91 toks/s]
Processed prompts:  15%|        | 154/1024 [00:26<02:34,  5.62it/s, est. speed input: 6037.33 toks/s, output: 5.90 toks/s]
Processed prompts:  16%|        | 162/1024 [00:27<02:33,  5.62it/s, est. speed input: 6022.84 toks/s, output: 5.88 toks/s]
Processed prompts:  17%|        | 170/1024 [00:28<02:31,  5.63it/s, est. speed input: 6010.59 toks/s, output: 5.87 toks/s]
Processed prompts:  17%|        | 178/1024 [00:30<02:32,  5.54it/s, est. speed input: 5984.04 toks/s, output: 5.84 toks/s]
Processed prompts:  18%|        | 186/1024 [00:31<02:30,  5.56it/s, est. speed input: 5973.84 toks/s, output: 5.83 toks/s]
Processed prompts:  19%|        | 194/1024 [00:33<02:28,  5.58it/s, est. speed input: 5964.58 toks/s, output: 5.82 toks/s]
Processed prompts:  20%|        | 202/1024 [00:34<02:22,  5.76it/s, est. speed input: 5980.30 toks/s, output: 5.84 toks/s]
Processed prompts:  21%|        | 210/1024 [00:36<02:22,  5.72it/s, est. speed input: 5971.68 toks/s, output: 5.83 toks/s]
Processed prompts:  21%|       | 218/1024 [00:37<02:21,  5.69it/s, est. speed input: 5963.78 toks/s, output: 5.82 toks/s]
Processed prompts:  22%|       | 226/1024 [00:38<02:20,  5.66it/s, est. speed input: 5955.06 toks/s, output: 5.82 toks/s]
Processed prompts:  23%|       | 234/1024 [00:40<02:19,  5.65it/s, est. speed input: 5948.37 toks/s, output: 5.81 toks/s]
Processed prompts:  24%|       | 242/1024 [00:41<02:18,  5.64it/s, est. speed input: 5941.89 toks/s, output: 5.80 toks/s]
Processed prompts:  24%|       | 250/1024 [00:43<02:17,  5.63it/s, est. speed input: 5934.88 toks/s, output: 5.80 toks/s]
Processed prompts:  25%|       | 258/1024 [00:44<02:16,  5.62it/s, est. speed input: 5928.79 toks/s, output: 5.79 toks/s]
Processed prompts:  26%|       | 266/1024 [00:45<02:14,  5.62it/s, est. speed input: 5923.08 toks/s, output: 5.78 toks/s]
Processed prompts:  27%|       | 274/1024 [00:47<02:13,  5.61it/s, est. speed input: 5917.26 toks/s, output: 5.78 toks/s]
Processed prompts:  28%|       | 282/1024 [00:48<02:12,  5.61it/s, est. speed input: 5912.04 toks/s, output: 5.77 toks/s]
Processed prompts:  28%|       | 290/1024 [00:50<02:10,  5.61it/s, est. speed input: 5907.35 toks/s, output: 5.77 toks/s]
Processed prompts:  29%|       | 298/1024 [00:51<02:09,  5.61it/s, est. speed input: 5902.36 toks/s, output: 5.76 toks/s]
Processed prompts:  30%|       | 306/1024 [00:52<02:04,  5.79it/s, est. speed input: 5914.53 toks/s, output: 5.78 toks/s]
Processed prompts:  31%|       | 314/1024 [00:54<02:03,  5.73it/s, est. speed input: 5910.25 toks/s, output: 5.77 toks/s]
Processed prompts:  31%|      | 322/1024 [00:55<02:03,  5.69it/s, est. speed input: 5905.38 toks/s, output: 5.77 toks/s]
Processed prompts:  32%|      | 330/1024 [00:57<02:02,  5.67it/s, est. speed input: 5901.53 toks/s, output: 5.76 toks/s]
Processed prompts:  33%|      | 338/1024 [00:58<02:01,  5.65it/s, est. speed input: 5897.63 toks/s, output: 5.76 toks/s]
Processed prompts:  34%|      | 346/1024 [01:00<02:00,  5.63it/s, est. speed input: 5893.31 toks/s, output: 5.76 toks/s]
Processed prompts:  35%|      | 354/1024 [01:01<01:59,  5.62it/s, est. speed input: 5889.99 toks/s, output: 5.75 toks/s]
Processed prompts:  35%|      | 362/1024 [01:02<01:58,  5.61it/s, est. speed input: 5885.75 toks/s, output: 5.75 toks/s]
Processed prompts:  36%|      | 370/1024 [01:04<01:56,  5.60it/s, est. speed input: 5882.03 toks/s, output: 5.74 toks/s]
Processed prompts:  37%|      | 378/1024 [01:05<01:55,  5.61it/s, est. speed input: 5879.48 toks/s, output: 5.74 toks/s]
Processed prompts:  38%|      | 386/1024 [01:07<01:53,  5.61it/s, est. speed input: 5876.39 toks/s, output: 5.74 toks/s]
Processed prompts:  38%|      | 394/1024 [01:08<01:52,  5.60it/s, est. speed input: 5873.16 toks/s, output: 5.74 toks/s]
Processed prompts:  39%|      | 402/1024 [01:10<01:50,  5.60it/s, est. speed input: 5870.56 toks/s, output: 5.73 toks/s]
Processed prompts:  40%|      | 410/1024 [01:11<01:49,  5.60it/s, est. speed input: 5867.98 toks/s, output: 5.73 toks/s]
Processed prompts:  41%|      | 418/1024 [01:12<01:48,  5.60it/s, est. speed input: 5865.27 toks/s, output: 5.73 toks/s]
Processed prompts:  42%|     | 426/1024 [01:14<01:46,  5.60it/s, est. speed input: 5862.81 toks/s, output: 5.73 toks/s]
Processed prompts:  42%|     | 434/1024 [01:15<01:41,  5.79it/s, est. speed input: 5872.57 toks/s, output: 5.73 toks/s]
Processed prompts:  43%|     | 442/1024 [01:17<01:41,  5.73it/s, est. speed input: 5869.63 toks/s, output: 5.73 toks/s]
Processed prompts:  44%|     | 450/1024 [01:18<01:40,  5.69it/s, est. speed input: 5867.29 toks/s, output: 5.73 toks/s]
Processed prompts:  45%|     | 458/1024 [01:19<01:39,  5.67it/s, est. speed input: 5865.04 toks/s, output: 5.73 toks/s]
Processed prompts:  46%|     | 466/1024 [01:21<01:38,  5.64it/s, est. speed input: 5862.64 toks/s, output: 5.73 toks/s]
Processed prompts:  46%|     | 474/1024 [01:22<01:37,  5.64it/s, est. speed input: 5860.79 toks/s, output: 5.72 toks/s]
Processed prompts:  47%|     | 482/1024 [01:24<01:36,  5.62it/s, est. speed input: 5858.58 toks/s, output: 5.72 toks/s]
Processed prompts:  48%|     | 490/1024 [01:25<01:35,  5.61it/s, est. speed input: 5856.26 toks/s, output: 5.72 toks/s]
Processed prompts:  49%|     | 498/1024 [01:27<01:33,  5.61it/s, est. speed input: 5854.30 toks/s, output: 5.72 toks/s]
Processed prompts:  49%|     | 506/1024 [01:28<01:32,  5.61it/s, est. speed input: 5852.49 toks/s, output: 5.72 toks/s]
Processed prompts:  50%|     | 514/1024 [01:29<01:30,  5.61it/s, est. speed input: 5850.61 toks/s, output: 5.71 toks/s]
Processed prompts:  51%|     | 522/1024 [01:31<01:29,  5.60it/s, est. speed input: 5848.76 toks/s, output: 5.71 toks/s]
Processed prompts:  52%|    | 530/1024 [01:32<01:28,  5.60it/s, est. speed input: 5847.11 toks/s, output: 5.71 toks/s]
Processed prompts:  53%|    | 538/1024 [01:34<01:26,  5.60it/s, est. speed input: 5845.01 toks/s, output: 5.71 toks/s]
Processed prompts:  53%|    | 546/1024 [01:35<01:25,  5.59it/s, est. speed input: 5842.75 toks/s, output: 5.71 toks/s]
Processed prompts:  54%|    | 554/1024 [01:37<01:24,  5.59it/s, est. speed input: 5841.04 toks/s, output: 5.70 toks/s]
Processed prompts:  55%|    | 562/1024 [01:38<01:22,  5.59it/s, est. speed input: 5839.43 toks/s, output: 5.70 toks/s]
Processed prompts:  56%|    | 570/1024 [01:39<01:21,  5.59it/s, est. speed input: 5837.96 toks/s, output: 5.70 toks/s]
Processed prompts:  56%|    | 578/1024 [01:41<01:19,  5.59it/s, est. speed input: 5836.31 toks/s, output: 5.70 toks/s]
Processed prompts:  57%|    | 586/1024 [01:42<01:18,  5.60it/s, est. speed input: 5834.95 toks/s, output: 5.70 toks/s]
Processed prompts:  58%|    | 594/1024 [01:44<01:16,  5.60it/s, est. speed input: 5833.57 toks/s, output: 5.70 toks/s]
Processed prompts:  59%|    | 602/1024 [01:45<01:15,  5.59it/s, est. speed input: 5832.07 toks/s, output: 5.70 toks/s]
Processed prompts:  60%|    | 610/1024 [01:47<01:13,  5.60it/s, est. speed input: 5830.75 toks/s, output: 5.69 toks/s]
Processed prompts:  60%|    | 618/1024 [01:48<01:12,  5.60it/s, est. speed input: 5829.47 toks/s, output: 5.69 toks/s]
Processed prompts:  61%|    | 626/1024 [01:49<01:11,  5.59it/s, est. speed input: 5828.07 toks/s, output: 5.69 toks/s]
Processed prompts:  62%|   | 634/1024 [01:51<01:09,  5.59it/s, est. speed input: 5826.79 toks/s, output: 5.69 toks/s]
Processed prompts:  63%|   | 642/1024 [01:52<01:08,  5.60it/s, est. speed input: 5825.75 toks/s, output: 5.69 toks/s]
Processed prompts:  63%|   | 650/1024 [01:54<01:06,  5.60it/s, est. speed input: 5824.60 toks/s, output: 5.69 toks/s]
Processed prompts:  64%|   | 658/1024 [01:55<01:05,  5.60it/s, est. speed input: 5823.53 toks/s, output: 5.69 toks/s]
Processed prompts:  65%|   | 666/1024 [01:57<01:03,  5.60it/s, est. speed input: 5822.41 toks/s, output: 5.69 toks/s]
Processed prompts:  66%|   | 674/1024 [01:58<01:02,  5.60it/s, est. speed input: 5821.27 toks/s, output: 5.68 toks/s]
Processed prompts:  67%|   | 682/1024 [01:59<01:01,  5.60it/s, est. speed input: 5820.23 toks/s, output: 5.68 toks/s]
Processed prompts:  67%|   | 690/1024 [02:01<00:59,  5.60it/s, est. speed input: 5819.24 toks/s, output: 5.68 toks/s]
Processed prompts:  68%|   | 698/1024 [02:02<00:58,  5.59it/s, est. speed input: 5817.99 toks/s, output: 5.68 toks/s]
Processed prompts:  69%|   | 706/1024 [02:04<00:56,  5.60it/s, est. speed input: 5817.09 toks/s, output: 5.68 toks/s]
Processed prompts:  70%|   | 714/1024 [02:05<00:55,  5.60it/s, est. speed input: 5816.14 toks/s, output: 5.68 toks/s]
Processed prompts:  71%|   | 722/1024 [02:07<00:54,  5.58it/s, est. speed input: 5814.70 toks/s, output: 5.68 toks/s]
Processed prompts:  71%|  | 730/1024 [02:08<00:52,  5.59it/s, est. speed input: 5813.72 toks/s, output: 5.68 toks/s]
Processed prompts:  72%|  | 738/1024 [02:10<00:51,  5.59it/s, est. speed input: 5812.83 toks/s, output: 5.68 toks/s]
Processed prompts:  73%|  | 746/1024 [02:11<00:49,  5.59it/s, est. speed input: 5811.84 toks/s, output: 5.68 toks/s]
Processed prompts:  74%|  | 754/1024 [02:12<00:48,  5.59it/s, est. speed input: 5811.05 toks/s, output: 5.67 toks/s]
Processed prompts:  74%|  | 762/1024 [02:14<00:46,  5.60it/s, est. speed input: 5810.30 toks/s, output: 5.67 toks/s]
Processed prompts:  75%|  | 770/1024 [02:15<00:45,  5.59it/s, est. speed input: 5809.22 toks/s, output: 5.67 toks/s]
Processed prompts:  76%|  | 778/1024 [02:17<00:43,  5.60it/s, est. speed input: 5808.51 toks/s, output: 5.67 toks/s]
Processed prompts:  77%|  | 786/1024 [02:18<00:41,  5.79it/s, est. speed input: 5814.26 toks/s, output: 5.68 toks/s]
Processed prompts:  78%|  | 794/1024 [02:19<00:40,  5.72it/s, est. speed input: 5813.08 toks/s, output: 5.68 toks/s]
Processed prompts:  78%|  | 802/1024 [02:21<00:39,  5.68it/s, est. speed input: 5812.36 toks/s, output: 5.68 toks/s]
Processed prompts:  79%|  | 810/1024 [02:22<00:37,  5.66it/s, est. speed input: 5811.50 toks/s, output: 5.68 toks/s]
Processed prompts:  80%|  | 818/1024 [02:24<00:36,  5.63it/s, est. speed input: 5810.45 toks/s, output: 5.67 toks/s]
Processed prompts:  81%|  | 826/1024 [02:25<00:35,  5.62it/s, est. speed input: 5809.55 toks/s, output: 5.67 toks/s]
Processed prompts:  81%| | 834/1024 [02:27<00:33,  5.61it/s, est. speed input: 5808.83 toks/s, output: 5.67 toks/s]
Processed prompts:  82%| | 842/1024 [02:28<00:32,  5.60it/s, est. speed input: 5807.90 toks/s, output: 5.67 toks/s]
Processed prompts:  83%| | 850/1024 [02:29<00:31,  5.60it/s, est. speed input: 5807.07 toks/s, output: 5.67 toks/s]
Processed prompts:  84%| | 858/1024 [02:31<00:29,  5.59it/s, est. speed input: 5806.25 toks/s, output: 5.67 toks/s]
Processed prompts:  85%| | 866/1024 [02:32<00:28,  5.59it/s, est. speed input: 5805.34 toks/s, output: 5.67 toks/s]
Processed prompts:  85%| | 874/1024 [02:34<00:26,  5.59it/s, est. speed input: 5804.63 toks/s, output: 5.67 toks/s]
Processed prompts:  86%| | 882/1024 [02:35<00:25,  5.59it/s, est. speed input: 5803.87 toks/s, output: 5.67 toks/s]
Processed prompts:  87%| | 890/1024 [02:37<00:23,  5.59it/s, est. speed input: 5803.15 toks/s, output: 5.67 toks/s]
Processed prompts:  88%| | 898/1024 [02:38<00:22,  5.59it/s, est. speed input: 5802.41 toks/s, output: 5.67 toks/s]
Processed prompts:  88%| | 906/1024 [02:39<00:21,  5.58it/s, est. speed input: 5801.46 toks/s, output: 5.67 toks/s]
Processed prompts:  89%| | 914/1024 [02:41<00:19,  5.59it/s, est. speed input: 5800.83 toks/s, output: 5.66 toks/s]
Processed prompts:  90%| | 922/1024 [02:42<00:18,  5.59it/s, est. speed input: 5800.29 toks/s, output: 5.66 toks/s]
Processed prompts:  91%| | 930/1024 [02:44<00:16,  5.59it/s, est. speed input: 5799.56 toks/s, output: 5.66 toks/s]
Processed prompts:  92%|| 938/1024 [02:45<00:15,  5.59it/s, est. speed input: 5798.95 toks/s, output: 5.66 toks/s]
Processed prompts:  92%|| 946/1024 [02:47<00:13,  5.59it/s, est. speed input: 5798.28 toks/s, output: 5.66 toks/s]
Processed prompts:  93%|| 954/1024 [02:48<00:12,  5.59it/s, est. speed input: 5797.59 toks/s, output: 5.66 toks/s]
Processed prompts:  94%|| 962/1024 [02:49<00:11,  5.59it/s, est. speed input: 5796.96 toks/s, output: 5.66 toks/s]
Processed prompts:  95%|| 970/1024 [02:51<00:09,  5.59it/s, est. speed input: 5796.37 toks/s, output: 5.66 toks/s]
Processed prompts:  96%|| 978/1024 [02:52<00:08,  5.59it/s, est. speed input: 5795.67 toks/s, output: 5.66 toks/s]
Processed prompts:  96%|| 986/1024 [02:54<00:06,  5.58it/s, est. speed input: 5795.02 toks/s, output: 5.66 toks/s]
Processed prompts:  97%|| 994/1024 [02:55<00:05,  5.59it/s, est. speed input: 5794.46 toks/s, output: 5.66 toks/s]
Processed prompts:  98%|| 1002/1024 [02:57<00:03,  5.59it/s, est. speed input: 5793.81 toks/s, output: 5.66 toks/s]
Processed prompts:  99%|| 1010/1024 [02:58<00:02,  5.59it/s, est. speed input: 5793.32 toks/s, output: 5.66 toks/s]
Processed prompts:  99%|| 1018/1024 [02:59<00:01,  5.80it/s, est. speed input: 5798.29 toks/s, output: 5.66 toks/s]
Processed prompts: 100%|| 1024/1024 [02:59<00:00,  5.80it/s, est. speed input: 5832.46 toks/s, output: 5.70 toks/s]
Processed prompts: 100%|| 1024/1024 [02:59<00:00,  5.70it/s, est. speed input: 5832.46 toks/s, output: 5.70 toks/s]
[rank0]:[W126 20:05:57.650075174 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-26 20:06:00
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Qwen2.5-7B-FP8_M16384.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 20:06:13 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 20:06:13 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1685129) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1685129) WARNING 01-26 20:07:40 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 5.61 requests/s, 5748.03 total tokens/s, 5.61 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-26 20:06:13] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 20:06:13] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 20:06:13] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 20:06:13] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:06:13] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:06:13] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:06:13] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:06:13] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:06:13] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 20:06:13] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 20:06:13] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 20:06:13] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 20:06:13] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 20:06:13] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 20:06:17] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 20:06:17] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 20:06:17] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 20:06:17] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:06:17] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:06:17] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:06:17] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:06:17] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:06:17] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 20:06:17] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 20:06:17] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 20:06:17] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 20:06:17] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 20:06:17] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1685129) [2026-01-26 20:06:18] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1685129) [2026-01-26 20:06:18] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1685129) [2026-01-26 20:06:18] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1685129) [2026-01-26 20:06:18] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1685129) [2026-01-26 20:06:18] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1685129) [2026-01-26 20:06:18] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1685129) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1685129) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:29<00:29, 29.57s/it]
(EngineCore_DP0 pid=1685129) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:08<00:00, 34.85s/it]
(EngineCore_DP0 pid=1685129) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:08<00:00, 34.06s/it]
(EngineCore_DP0 pid=1685129) 
(EngineCore_DP0 pid=1685129) [2026-01-26 20:07:27] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=1685129) [2026-01-26 20:07:27] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16588800 bytes
(EngineCore_DP0 pid=1685129) [2026-01-26 20:07:27] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=1685129) [2026-01-26 20:07:27] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 12902400 bytes
(EngineCore_DP0 pid=1685129) [2026-01-26 20:07:27] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=1685129) [2026-01-26 20:07:27] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 136396800 bytes
(EngineCore_DP0 pid=1685129) [2026-01-26 20:07:27] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=1685129) [2026-01-26 20:07:27] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 67952640 bytes
(EngineCore_DP0 pid=1685129) 2026-01-26 20:07:36,064 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1685129) 2026-01-26 20:07:36,640 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   2%|         | 33/2048 [00:00<00:06, 325.83it/s]
Adding requests:   3%|         | 67/2048 [00:00<00:05, 331.07it/s]
Adding requests:   5%|         | 110/2048 [00:00<00:05, 373.48it/s]
Adding requests:   7%|         | 148/2048 [00:00<00:05, 375.26it/s]
Adding requests:   9%|         | 191/2048 [00:00<00:04, 393.33it/s]
Adding requests:  11%|        | 234/2048 [00:00<00:04, 404.33it/s]
Adding requests:  13%|        | 276/2048 [00:00<00:04, 408.45it/s]
Adding requests:  16%|        | 322/2048 [00:00<00:04, 422.68it/s]
Adding requests:  18%|        | 369/2048 [00:00<00:03, 434.27it/s]
Adding requests:  20%|        | 413/2048 [00:01<00:03, 435.01it/s]
Adding requests:  22%|       | 457/2048 [00:01<00:03, 427.89it/s]
Adding requests:  25%|       | 502/2048 [00:01<00:03, 433.67it/s]
Adding requests:  27%|       | 550/2048 [00:01<00:03, 445.19it/s]
Adding requests:  29%|       | 595/2048 [00:01<00:03, 438.00it/s]
Adding requests:  31%|       | 639/2048 [00:01<00:03, 431.97it/s]
Adding requests:  33%|      | 683/2048 [00:01<00:03, 423.33it/s]
Adding requests:  35%|      | 726/2048 [00:01<00:03, 425.14it/s]
Adding requests:  38%|      | 769/2048 [00:01<00:03, 425.27it/s]
Adding requests:  40%|      | 813/2048 [00:01<00:02, 426.04it/s]
Adding requests:  42%|     | 856/2048 [00:02<00:02, 423.47it/s]
Adding requests:  44%|     | 899/2048 [00:02<00:02, 423.99it/s]
Adding requests:  46%|     | 942/2048 [00:02<00:02, 417.48it/s]
Adding requests:  48%|     | 984/2048 [00:02<00:06, 152.88it/s]
Adding requests:  50%|     | 1024/2048 [00:03<00:05, 185.03it/s]
Adding requests:  52%|    | 1063/2048 [00:03<00:04, 216.87it/s]
Adding requests:  54%|    | 1103/2048 [00:03<00:03, 249.71it/s]
Adding requests:  56%|    | 1146/2048 [00:03<00:03, 285.88it/s]
Adding requests:  58%|    | 1188/2048 [00:03<00:02, 316.15it/s]
Adding requests:  60%|    | 1232/2048 [00:03<00:02, 345.35it/s]
Adding requests:  62%|   | 1274/2048 [00:03<00:02, 362.49it/s]
Adding requests:  64%|   | 1318/2048 [00:03<00:01, 382.49it/s]
Adding requests:  67%|   | 1363/2048 [00:03<00:01, 398.39it/s]
Adding requests:  69%|   | 1406/2048 [00:03<00:01, 405.59it/s]
Adding requests:  71%|   | 1449/2048 [00:04<00:01, 411.94it/s]
Adding requests:  73%|  | 1495/2048 [00:04<00:01, 424.64it/s]
Adding requests:  75%|  | 1539/2048 [00:04<00:01, 417.60it/s]
Adding requests:  77%|  | 1582/2048 [00:04<00:01, 414.49it/s]
Adding requests:  79%|  | 1624/2048 [00:04<00:01, 412.67it/s]
Adding requests:  81%| | 1666/2048 [00:04<00:00, 402.44it/s]
Adding requests:  84%| | 1711/2048 [00:04<00:00, 415.32it/s]
Adding requests:  86%| | 1754/2048 [00:04<00:00, 417.92it/s]
Adding requests:  88%| | 1798/2048 [00:04<00:00, 423.07it/s]
Adding requests:  90%| | 1842/2048 [00:05<00:00, 425.11it/s]
Adding requests:  92%|| 1887/2048 [00:05<00:00, 431.23it/s]
Adding requests:  94%|| 1931/2048 [00:05<00:00, 432.38it/s]
Adding requests:  96%|| 1975/2048 [00:05<00:00, 423.69it/s]
Adding requests:  99%|| 2018/2048 [00:05<00:00, 418.82it/s]
Adding requests: 100%|| 2048/2048 [00:05<00:00, 372.90it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 18/2048 [00:00<01:01, 33.25it/s, est. speed input: 34053.95 toks/s, output: 33.25 toks/s]
Processed prompts:   2%|         | 34/2048 [00:03<03:47,  8.87it/s, est. speed input: 10276.41 toks/s, output: 10.04 toks/s]
Processed prompts:   2%|         | 50/2048 [00:06<04:43,  7.06it/s, est. speed input: 8213.42 toks/s, output: 8.02 toks/s]  
Processed prompts:   3%|         | 66/2048 [00:09<05:09,  6.41it/s, est. speed input: 7435.61 toks/s, output: 7.26 toks/s]
Processed prompts:   4%|         | 82/2048 [00:11<05:22,  6.10it/s, est. speed input: 7028.36 toks/s, output: 6.86 toks/s]
Processed prompts:   5%|         | 98/2048 [00:14<05:29,  5.92it/s, est. speed input: 6779.91 toks/s, output: 6.62 toks/s]
Processed prompts:   6%|         | 114/2048 [00:17<05:33,  5.81it/s, est. speed input: 6607.67 toks/s, output: 6.45 toks/s]
Processed prompts:   6%|         | 130/2048 [00:20<05:34,  5.73it/s, est. speed input: 6482.64 toks/s, output: 6.33 toks/s]
Processed prompts:   7%|         | 146/2048 [00:23<05:34,  5.68it/s, est. speed input: 6387.63 toks/s, output: 6.24 toks/s]
Processed prompts:   8%|         | 162/2048 [00:26<05:33,  5.65it/s, est. speed input: 6314.31 toks/s, output: 6.17 toks/s]
Processed prompts:   9%|         | 178/2048 [00:29<05:32,  5.63it/s, est. speed input: 6255.01 toks/s, output: 6.11 toks/s]
Processed prompts:   9%|         | 194/2048 [00:31<05:24,  5.71it/s, est. speed input: 6238.38 toks/s, output: 6.09 toks/s]
Processed prompts:  10%|         | 210/2048 [00:34<05:24,  5.67it/s, est. speed input: 6194.38 toks/s, output: 6.05 toks/s]
Processed prompts:  11%|         | 226/2048 [00:37<05:23,  5.63it/s, est. speed input: 6155.70 toks/s, output: 6.01 toks/s]
Processed prompts:  12%|        | 242/2048 [00:40<05:21,  5.61it/s, est. speed input: 6122.22 toks/s, output: 5.98 toks/s]
Processed prompts:  13%|        | 258/2048 [00:43<05:20,  5.59it/s, est. speed input: 6093.35 toks/s, output: 5.95 toks/s]
Processed prompts:  13%|        | 274/2048 [00:46<05:17,  5.58it/s, est. speed input: 6067.48 toks/s, output: 5.93 toks/s]
Processed prompts:  14%|        | 290/2048 [00:49<05:16,  5.56it/s, est. speed input: 6042.94 toks/s, output: 5.90 toks/s]
Processed prompts:  15%|        | 306/2048 [00:51<05:07,  5.66it/s, est. speed input: 6042.61 toks/s, output: 5.90 toks/s]
Processed prompts:  16%|        | 322/2048 [00:54<05:07,  5.61it/s, est. speed input: 6021.59 toks/s, output: 5.88 toks/s]
Processed prompts:  17%|        | 338/2048 [00:57<05:05,  5.59it/s, est. speed input: 6004.73 toks/s, output: 5.86 toks/s]
Processed prompts:  17%|        | 354/2048 [01:00<05:03,  5.58it/s, est. speed input: 5989.33 toks/s, output: 5.85 toks/s]
Processed prompts:  18%|        | 370/2048 [01:03<05:01,  5.57it/s, est. speed input: 5974.48 toks/s, output: 5.83 toks/s]
Processed prompts:  19%|        | 386/2048 [01:06<04:58,  5.56it/s, est. speed input: 5961.72 toks/s, output: 5.82 toks/s]
Processed prompts:  20%|        | 402/2048 [01:09<04:56,  5.56it/s, est. speed input: 5950.23 toks/s, output: 5.81 toks/s]
Processed prompts:  20%|        | 418/2048 [01:12<04:53,  5.55it/s, est. speed input: 5939.38 toks/s, output: 5.80 toks/s]
Processed prompts:  21%|        | 434/2048 [01:14<04:44,  5.67it/s, est. speed input: 5944.69 toks/s, output: 5.81 toks/s]
Processed prompts:  22%|       | 450/2048 [01:17<04:43,  5.63it/s, est. speed input: 5935.08 toks/s, output: 5.80 toks/s]
Processed prompts:  23%|       | 466/2048 [01:20<04:42,  5.61it/s, est. speed input: 5926.42 toks/s, output: 5.79 toks/s]
Processed prompts:  24%|       | 482/2048 [01:23<04:40,  5.59it/s, est. speed input: 5917.65 toks/s, output: 5.78 toks/s]
Processed prompts:  24%|       | 498/2048 [01:26<04:37,  5.58it/s, est. speed input: 5909.68 toks/s, output: 5.77 toks/s]
Processed prompts:  25%|       | 514/2048 [01:29<04:35,  5.57it/s, est. speed input: 5902.24 toks/s, output: 5.76 toks/s]
Processed prompts:  26%|       | 530/2048 [01:32<04:32,  5.56it/s, est. speed input: 5895.29 toks/s, output: 5.76 toks/s]
Processed prompts:  27%|       | 546/2048 [01:34<04:30,  5.56it/s, est. speed input: 5888.79 toks/s, output: 5.75 toks/s]
Processed prompts:  27%|       | 562/2048 [01:37<04:27,  5.55it/s, est. speed input: 5882.59 toks/s, output: 5.74 toks/s]
Processed prompts:  28%|       | 578/2048 [01:40<04:24,  5.55it/s, est. speed input: 5876.80 toks/s, output: 5.74 toks/s]
Processed prompts:  29%|       | 594/2048 [01:43<04:22,  5.55it/s, est. speed input: 5871.22 toks/s, output: 5.73 toks/s]
Processed prompts:  30%|       | 610/2048 [01:46<04:19,  5.55it/s, est. speed input: 5865.85 toks/s, output: 5.73 toks/s]
Processed prompts:  31%|       | 626/2048 [01:49<04:16,  5.54it/s, est. speed input: 5860.79 toks/s, output: 5.72 toks/s]
Processed prompts:  31%|      | 642/2048 [01:52<04:13,  5.54it/s, est. speed input: 5855.92 toks/s, output: 5.72 toks/s]
Processed prompts:  32%|      | 658/2048 [01:55<04:10,  5.54it/s, est. speed input: 5851.52 toks/s, output: 5.71 toks/s]
Processed prompts:  33%|      | 674/2048 [01:58<04:07,  5.54it/s, est. speed input: 5847.08 toks/s, output: 5.71 toks/s]
Processed prompts:  34%|      | 690/2048 [02:00<04:04,  5.55it/s, est. speed input: 5843.35 toks/s, output: 5.71 toks/s]
Processed prompts:  34%|      | 706/2048 [02:03<04:01,  5.55it/s, est. speed input: 5839.58 toks/s, output: 5.70 toks/s]
Processed prompts:  35%|      | 722/2048 [02:06<03:59,  5.55it/s, est. speed input: 5835.96 toks/s, output: 5.70 toks/s]
Processed prompts:  36%|      | 738/2048 [02:09<03:56,  5.55it/s, est. speed input: 5832.62 toks/s, output: 5.70 toks/s]
Processed prompts:  37%|      | 754/2048 [02:12<03:53,  5.55it/s, est. speed input: 5829.49 toks/s, output: 5.69 toks/s]
Processed prompts:  38%|      | 770/2048 [02:15<03:50,  5.55it/s, est. speed input: 5826.23 toks/s, output: 5.69 toks/s]
Processed prompts:  38%|      | 786/2048 [02:18<03:42,  5.67it/s, est. speed input: 5831.58 toks/s, output: 5.69 toks/s]
Processed prompts:  39%|      | 802/2048 [02:20<03:41,  5.63it/s, est. speed input: 5828.72 toks/s, output: 5.69 toks/s]
Processed prompts:  40%|      | 818/2048 [02:23<03:39,  5.61it/s, est. speed input: 5825.95 toks/s, output: 5.69 toks/s]
Processed prompts:  41%|      | 834/2048 [02:26<03:37,  5.59it/s, est. speed input: 5823.25 toks/s, output: 5.69 toks/s]
Processed prompts:  42%|     | 850/2048 [02:29<03:34,  5.58it/s, est. speed input: 5820.61 toks/s, output: 5.68 toks/s]
Processed prompts:  42%|     | 866/2048 [02:32<03:32,  5.57it/s, est. speed input: 5817.86 toks/s, output: 5.68 toks/s]
Processed prompts:  43%|     | 882/2048 [02:35<03:29,  5.57it/s, est. speed input: 5815.55 toks/s, output: 5.68 toks/s]
Processed prompts:  44%|     | 898/2048 [02:38<03:26,  5.56it/s, est. speed input: 5813.05 toks/s, output: 5.68 toks/s]
Processed prompts:  45%|     | 914/2048 [02:41<03:23,  5.56it/s, est. speed input: 5810.94 toks/s, output: 5.67 toks/s]
Processed prompts:  45%|     | 930/2048 [02:43<03:21,  5.56it/s, est. speed input: 5808.83 toks/s, output: 5.67 toks/s]
Processed prompts:  46%|     | 946/2048 [02:46<03:18,  5.56it/s, est. speed input: 5806.73 toks/s, output: 5.67 toks/s]
Processed prompts:  47%|     | 962/2048 [02:49<03:15,  5.56it/s, est. speed input: 5804.94 toks/s, output: 5.67 toks/s]
Processed prompts:  48%|     | 978/2048 [02:52<03:12,  5.56it/s, est. speed input: 5803.03 toks/s, output: 5.67 toks/s]
Processed prompts:  49%|     | 994/2048 [02:55<03:09,  5.56it/s, est. speed input: 5801.09 toks/s, output: 5.67 toks/s]
Processed prompts:  49%|     | 1010/2048 [02:58<03:06,  5.56it/s, est. speed input: 5799.34 toks/s, output: 5.66 toks/s]
Processed prompts:  50%|     | 1026/2048 [03:01<03:03,  5.56it/s, est. speed input: 5797.68 toks/s, output: 5.66 toks/s]
Processed prompts:  51%|     | 1042/2048 [03:04<03:00,  5.56it/s, est. speed input: 5796.11 toks/s, output: 5.66 toks/s]
Processed prompts:  52%|    | 1058/2048 [03:06<02:58,  5.56it/s, est. speed input: 5794.51 toks/s, output: 5.66 toks/s]
Processed prompts:  52%|    | 1074/2048 [03:09<02:55,  5.56it/s, est. speed input: 5793.02 toks/s, output: 5.66 toks/s]
Processed prompts:  53%|    | 1090/2048 [03:12<02:52,  5.56it/s, est. speed input: 5791.48 toks/s, output: 5.66 toks/s]
Processed prompts:  54%|    | 1106/2048 [03:15<02:49,  5.56it/s, est. speed input: 5789.94 toks/s, output: 5.65 toks/s]
Processed prompts:  55%|    | 1122/2048 [03:18<02:46,  5.56it/s, est. speed input: 5788.54 toks/s, output: 5.65 toks/s]
Processed prompts:  56%|    | 1138/2048 [03:21<02:43,  5.56it/s, est. speed input: 5787.21 toks/s, output: 5.65 toks/s]
Processed prompts:  56%|    | 1154/2048 [03:24<02:40,  5.56it/s, est. speed input: 5785.81 toks/s, output: 5.65 toks/s]
Processed prompts:  57%|    | 1170/2048 [03:27<02:37,  5.56it/s, est. speed input: 5784.47 toks/s, output: 5.65 toks/s]
Processed prompts:  58%|    | 1186/2048 [03:29<02:35,  5.56it/s, est. speed input: 5783.32 toks/s, output: 5.65 toks/s]
Processed prompts:  59%|    | 1202/2048 [03:32<02:29,  5.68it/s, est. speed input: 5787.42 toks/s, output: 5.65 toks/s]
Processed prompts:  59%|    | 1218/2048 [03:35<02:27,  5.64it/s, est. speed input: 5786.27 toks/s, output: 5.65 toks/s]
Processed prompts:  60%|    | 1234/2048 [03:38<02:21,  5.74it/s, est. speed input: 5790.36 toks/s, output: 5.65 toks/s]
Processed prompts:  61%|    | 1250/2048 [03:41<02:20,  5.68it/s, est. speed input: 5789.07 toks/s, output: 5.65 toks/s]
Processed prompts:  62%|   | 1266/2048 [03:43<02:18,  5.65it/s, est. speed input: 5787.88 toks/s, output: 5.65 toks/s]
Processed prompts:  63%|   | 1282/2048 [03:46<02:16,  5.62it/s, est. speed input: 5786.77 toks/s, output: 5.65 toks/s]
Processed prompts:  63%|   | 1298/2048 [03:49<02:13,  5.60it/s, est. speed input: 5785.56 toks/s, output: 5.65 toks/s]
Processed prompts:  64%|   | 1314/2048 [03:52<02:11,  5.59it/s, est. speed input: 5784.30 toks/s, output: 5.65 toks/s]
Processed prompts:  65%|   | 1330/2048 [03:55<02:06,  5.70it/s, est. speed input: 5788.11 toks/s, output: 5.65 toks/s]
Processed prompts:  66%|   | 1346/2048 [03:58<02:04,  5.66it/s, est. speed input: 5786.95 toks/s, output: 5.65 toks/s]
Processed prompts:  67%|   | 1362/2048 [04:01<02:01,  5.63it/s, est. speed input: 5785.81 toks/s, output: 5.65 toks/s]
Processed prompts:  67%|   | 1378/2048 [04:03<01:59,  5.61it/s, est. speed input: 5784.82 toks/s, output: 5.65 toks/s]
Processed prompts:  68%|   | 1394/2048 [04:06<01:56,  5.59it/s, est. speed input: 5783.63 toks/s, output: 5.65 toks/s]
Processed prompts:  69%|   | 1410/2048 [04:09<01:54,  5.58it/s, est. speed input: 5782.67 toks/s, output: 5.65 toks/s]
Processed prompts:  70%|   | 1426/2048 [04:12<01:51,  5.58it/s, est. speed input: 5781.67 toks/s, output: 5.65 toks/s]
Processed prompts:  70%|   | 1442/2048 [04:15<01:46,  5.69it/s, est. speed input: 5785.07 toks/s, output: 5.65 toks/s]
Processed prompts:  71%|   | 1458/2048 [04:17<01:42,  5.77it/s, est. speed input: 5788.50 toks/s, output: 5.65 toks/s]
Processed prompts:  72%|  | 1474/2048 [04:20<01:40,  5.71it/s, est. speed input: 5787.54 toks/s, output: 5.65 toks/s]
Processed prompts:  73%|  | 1490/2048 [04:23<01:38,  5.67it/s, est. speed input: 5786.64 toks/s, output: 5.65 toks/s]
Processed prompts:  74%|  | 1506/2048 [04:26<01:36,  5.64it/s, est. speed input: 5785.69 toks/s, output: 5.65 toks/s]
Processed prompts:  74%|  | 1522/2048 [04:29<01:31,  5.73it/s, est. speed input: 5789.02 toks/s, output: 5.65 toks/s]
Processed prompts:  75%|  | 1538/2048 [04:32<01:29,  5.68it/s, est. speed input: 5788.03 toks/s, output: 5.65 toks/s]
Processed prompts:  76%|  | 1554/2048 [04:34<01:25,  5.77it/s, est. speed input: 5791.28 toks/s, output: 5.66 toks/s]
Processed prompts:  77%|  | 1570/2048 [04:37<01:23,  5.71it/s, est. speed input: 5790.32 toks/s, output: 5.65 toks/s]
Processed prompts:  77%|  | 1586/2048 [04:40<01:21,  5.66it/s, est. speed input: 5789.27 toks/s, output: 5.65 toks/s]
Processed prompts:  78%|  | 1602/2048 [04:43<01:19,  5.63it/s, est. speed input: 5788.31 toks/s, output: 5.65 toks/s]
Processed prompts:  79%|  | 1618/2048 [04:46<01:15,  5.73it/s, est. speed input: 5791.43 toks/s, output: 5.66 toks/s]
Processed prompts:  80%|  | 1634/2048 [04:48<01:12,  5.68it/s, est. speed input: 5790.39 toks/s, output: 5.65 toks/s]
Processed prompts:  81%|  | 1650/2048 [04:51<01:10,  5.64it/s, est. speed input: 5789.50 toks/s, output: 5.65 toks/s]
Processed prompts:  81%| | 1666/2048 [04:54<01:07,  5.62it/s, est. speed input: 5788.69 toks/s, output: 5.65 toks/s]
Processed prompts:  82%| | 1682/2048 [04:57<01:05,  5.60it/s, est. speed input: 5787.71 toks/s, output: 5.65 toks/s]
Processed prompts:  83%| | 1698/2048 [05:00<01:02,  5.59it/s, est. speed input: 5786.81 toks/s, output: 5.65 toks/s]
Processed prompts:  84%| | 1714/2048 [05:03<00:59,  5.58it/s, est. speed input: 5785.99 toks/s, output: 5.65 toks/s]
Processed prompts:  84%| | 1730/2048 [05:06<00:55,  5.69it/s, est. speed input: 5788.83 toks/s, output: 5.65 toks/s]
Processed prompts:  85%| | 1746/2048 [05:08<00:51,  5.87it/s, est. speed input: 5794.47 toks/s, output: 5.66 toks/s]
Processed prompts:  86%| | 1762/2048 [05:11<00:49,  5.77it/s, est. speed input: 5793.59 toks/s, output: 5.66 toks/s]
Processed prompts:  87%| | 1778/2048 [05:14<00:47,  5.71it/s, est. speed input: 5792.69 toks/s, output: 5.66 toks/s]
Processed prompts:  88%| | 1794/2048 [05:17<00:44,  5.66it/s, est. speed input: 5791.84 toks/s, output: 5.66 toks/s]
Processed prompts:  88%| | 1810/2048 [05:20<00:42,  5.63it/s, est. speed input: 5791.01 toks/s, output: 5.66 toks/s]
Processed prompts:  89%| | 1826/2048 [05:22<00:39,  5.61it/s, est. speed input: 5790.11 toks/s, output: 5.65 toks/s]
Processed prompts:  90%| | 1842/2048 [05:25<00:36,  5.60it/s, est. speed input: 5789.33 toks/s, output: 5.65 toks/s]
Processed prompts:  91%| | 1858/2048 [05:28<00:34,  5.59it/s, est. speed input: 5788.51 toks/s, output: 5.65 toks/s]
Processed prompts:  92%|| 1874/2048 [05:31<00:31,  5.58it/s, est. speed input: 5787.69 toks/s, output: 5.65 toks/s]
Processed prompts:  92%|| 1890/2048 [05:34<00:27,  5.69it/s, est. speed input: 5790.39 toks/s, output: 5.65 toks/s]
Processed prompts:  93%|| 1906/2048 [05:37<00:25,  5.65it/s, est. speed input: 5789.58 toks/s, output: 5.65 toks/s]
Processed prompts:  94%|| 1922/2048 [05:39<00:22,  5.63it/s, est. speed input: 5788.78 toks/s, output: 5.65 toks/s]
Processed prompts:  95%|| 1938/2048 [05:42<00:19,  5.61it/s, est. speed input: 5788.02 toks/s, output: 5.65 toks/s]
Processed prompts:  95%|| 1954/2048 [05:45<00:16,  5.60it/s, est. speed input: 5787.32 toks/s, output: 5.65 toks/s]
Processed prompts:  96%|| 1970/2048 [05:48<00:13,  5.59it/s, est. speed input: 5786.57 toks/s, output: 5.65 toks/s]
Processed prompts:  97%|| 1986/2048 [05:51<00:10,  5.69it/s, est. speed input: 5789.02 toks/s, output: 5.65 toks/s]
Processed prompts:  98%|| 2002/2048 [05:54<00:08,  5.66it/s, est. speed input: 5788.32 toks/s, output: 5.65 toks/s]
Processed prompts:  99%|| 2018/2048 [05:57<00:05,  5.63it/s, est. speed input: 5787.57 toks/s, output: 5.65 toks/s]
Processed prompts:  99%|| 2034/2048 [05:59<00:02,  5.74it/s, est. speed input: 5790.27 toks/s, output: 5.65 toks/s]
Processed prompts: 100%|| 2048/2048 [05:59<00:00,  5.74it/s, est. speed input: 5830.12 toks/s, output: 5.69 toks/s]
Processed prompts: 100%|| 2048/2048 [05:59<00:00,  5.69it/s, est. speed input: 5830.12 toks/s, output: 5.69 toks/s]
[rank0]:[W126 20:13:46.183753696 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-26 20:13:48
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Qwen2.5-7B-FP8_M32768.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 20:14:08 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 20:14:08 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1691885) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1691885) WARNING 01-26 20:15:39 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 5.63 requests/s, 5772.71 total tokens/s, 5.63 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-26 20:14:08] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 20:14:08] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 20:14:08] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 20:14:08] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:14:08] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:14:08] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:14:08] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:14:08] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:14:08] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 20:14:08] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 20:14:08] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 20:14:08] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 20:14:08] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 20:14:08] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 20:14:12] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 20:14:12] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 20:14:12] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 20:14:12] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:14:12] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:14:12] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:14:12] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:14:12] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:14:12] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 20:14:12] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 20:14:12] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 20:14:12] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 20:14:12] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 20:14:12] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1691885) [2026-01-26 20:14:13] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1691885) [2026-01-26 20:14:13] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1691885) [2026-01-26 20:14:13] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1691885) [2026-01-26 20:14:13] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1691885) [2026-01-26 20:14:13] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1691885) [2026-01-26 20:14:13] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1691885) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1691885) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:28<00:28, 28.87s/it]
(EngineCore_DP0 pid=1691885) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:07<00:00, 34.38s/it]
(EngineCore_DP0 pid=1691885) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:07<00:00, 33.55s/it]
(EngineCore_DP0 pid=1691885) 
(EngineCore_DP0 pid=1691885) [2026-01-26 20:15:21] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=1691885) [2026-01-26 20:15:21] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16588800 bytes
(EngineCore_DP0 pid=1691885) [2026-01-26 20:15:21] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=1691885) [2026-01-26 20:15:21] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 12902400 bytes
(EngineCore_DP0 pid=1691885) [2026-01-26 20:15:21] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=1691885) [2026-01-26 20:15:21] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 136396800 bytes
(EngineCore_DP0 pid=1691885) [2026-01-26 20:15:21] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=1691885) [2026-01-26 20:15:21] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 67952640 bytes
(EngineCore_DP0 pid=1691885) 2026-01-26 20:15:32,465 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1691885) 2026-01-26 20:15:33,637 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   0%|          | 17/4096 [00:00<00:24, 167.10it/s]
Adding requests:   1%|         | 53/4096 [00:00<00:14, 275.70it/s]
Adding requests:   2%|         | 92/4096 [00:00<00:12, 325.99it/s]
Adding requests:   3%|         | 131/4096 [00:00<00:11, 351.01it/s]
Adding requests:   4%|         | 169/4096 [00:00<00:10, 361.21it/s]
Adding requests:   5%|         | 214/4096 [00:00<00:09, 389.43it/s]
Adding requests:   6%|         | 253/4096 [00:00<00:09, 388.76it/s]
Adding requests:   7%|         | 295/4096 [00:00<00:09, 396.43it/s]
Adding requests:   8%|         | 335/4096 [00:00<00:09, 395.13it/s]
Adding requests:   9%|         | 378/4096 [00:01<00:09, 404.85it/s]
Adding requests:  10%|         | 419/4096 [00:01<00:09, 405.83it/s]
Adding requests:  11%|        | 462/4096 [00:01<00:08, 411.28it/s]
Adding requests:  12%|        | 506/4096 [00:01<00:08, 419.31it/s]
Adding requests:  13%|        | 552/4096 [00:01<00:08, 430.99it/s]
Adding requests:  15%|        | 596/4096 [00:01<00:08, 423.36it/s]
Adding requests:  16%|        | 639/4096 [00:01<00:08, 425.28it/s]
Adding requests:  17%|        | 682/4096 [00:01<00:08, 414.48it/s]
Adding requests:  18%|        | 726/4096 [00:01<00:08, 419.77it/s]
Adding requests:  19%|        | 769/4096 [00:01<00:08, 403.92it/s]
Adding requests:  20%|        | 815/4096 [00:02<00:07, 417.75it/s]
Adding requests:  21%|        | 857/4096 [00:02<00:07, 408.49it/s]
Adding requests:  22%|       | 905/4096 [00:02<00:07, 426.84it/s]
Adding requests:  23%|       | 948/4096 [00:02<00:07, 405.13it/s]
Adding requests:  24%|       | 993/4096 [00:02<00:07, 414.67it/s]
Adding requests:  25%|       | 1035/4096 [00:02<00:07, 404.12it/s]
Adding requests:  26%|       | 1078/4096 [00:02<00:07, 409.45it/s]
Adding requests:  27%|       | 1120/4096 [00:02<00:07, 401.42it/s]
Adding requests:  28%|       | 1163/4096 [00:02<00:07, 408.80it/s]
Adding requests:  29%|       | 1205/4096 [00:03<00:07, 390.92it/s]
Adding requests:  30%|       | 1246/4096 [00:03<00:07, 393.70it/s]
Adding requests:  31%|      | 1287/4096 [00:03<00:07, 397.28it/s]
Adding requests:  32%|      | 1329/4096 [00:03<00:06, 402.15it/s]
Adding requests:  33%|      | 1372/4096 [00:03<00:06, 408.53it/s]
Adding requests:  34%|      | 1413/4096 [00:03<00:06, 406.78it/s]
Adding requests:  36%|      | 1456/4096 [00:03<00:06, 411.62it/s]
Adding requests:  37%|      | 1498/4096 [00:03<00:06, 410.28it/s]
Adding requests:  38%|      | 1540/4096 [00:03<00:06, 406.93it/s]
Adding requests:  39%|      | 1581/4096 [00:03<00:06, 404.23it/s]
Adding requests:  40%|      | 1622/4096 [00:04<00:06, 396.07it/s]
Adding requests:  41%|      | 1662/4096 [00:04<00:06, 393.38it/s]
Adding requests:  42%|     | 1705/4096 [00:04<00:05, 403.68it/s]
Adding requests:  43%|     | 1747/4096 [00:04<00:05, 407.31it/s]
Adding requests:  44%|     | 1791/4096 [00:04<00:05, 416.43it/s]
Adding requests:  45%|     | 1833/4096 [00:04<00:05, 413.41it/s]
Adding requests:  46%|     | 1876/4096 [00:04<00:05, 418.14it/s]
Adding requests:  47%|     | 1918/4096 [00:04<00:05, 416.53it/s]
Adding requests:  48%|     | 1962/4096 [00:04<00:05, 423.26it/s]
Adding requests:  49%|     | 2005/4096 [00:04<00:05, 401.94it/s]
Adding requests:  50%|     | 2047/4096 [00:05<00:05, 405.80it/s]
Adding requests:  51%|     | 2088/4096 [00:05<00:05, 388.88it/s]
Adding requests:  52%|    | 2135/4096 [00:05<00:04, 410.27it/s]
Adding requests:  53%|    | 2177/4096 [00:05<00:04, 396.71it/s]
Adding requests:  54%|    | 2222/4096 [00:05<00:04, 410.29it/s]
Adding requests:  55%|    | 2264/4096 [00:05<00:04, 397.61it/s]
Adding requests:  56%|    | 2310/4096 [00:05<00:04, 411.93it/s]
Adding requests:  57%|    | 2352/4096 [00:05<00:04, 412.67it/s]
Adding requests:  59%|    | 2398/4096 [00:05<00:04, 421.73it/s]
Adding requests:  60%|    | 2441/4096 [00:06<00:04, 387.62it/s]
Adding requests:  61%|    | 2482/4096 [00:06<00:04, 393.38it/s]
Adding requests:  62%|   | 2523/4096 [00:06<00:03, 396.75it/s]
Adding requests:  63%|   | 2571/4096 [00:06<00:03, 420.55it/s]
Adding requests:  64%|   | 2614/4096 [00:06<00:03, 412.27it/s]
Adding requests:  65%|   | 2658/4096 [00:06<00:03, 418.16it/s]
Adding requests:  66%|   | 2701/4096 [00:06<00:03, 411.08it/s]
Adding requests:  67%|   | 2745/4096 [00:06<00:03, 419.19it/s]
Adding requests:  68%|   | 2788/4096 [00:06<00:03, 419.40it/s]
Adding requests:  69%|   | 2833/4096 [00:06<00:02, 427.15it/s]
Adding requests:  70%|   | 2876/4096 [00:07<00:02, 415.94it/s]
Adding requests:  71%|   | 2918/4096 [00:07<00:02, 413.17it/s]
Adding requests:  72%|  | 2962/4096 [00:07<00:02, 419.61it/s]
Adding requests:  73%|  | 3006/4096 [00:07<00:02, 423.17it/s]
Adding requests:  74%|  | 3049/4096 [00:07<00:02, 419.51it/s]
Adding requests:  76%|  | 3094/4096 [00:07<00:02, 426.43it/s]
Adding requests:  77%|  | 3138/4096 [00:07<00:02, 429.98it/s]
Adding requests:  78%|  | 3182/4096 [00:07<00:02, 421.02it/s]
Adding requests:  79%|  | 3226/4096 [00:07<00:02, 426.34it/s]
Adding requests:  80%|  | 3269/4096 [00:08<00:01, 416.11it/s]
Adding requests:  81%|  | 3311/4096 [00:08<00:01, 404.97it/s]
Adding requests:  82%| | 3352/4096 [00:08<00:01, 398.73it/s]
Adding requests:  83%| | 3397/4096 [00:08<00:01, 411.48it/s]
Adding requests:  84%| | 3439/4096 [00:08<00:01, 409.57it/s]
Adding requests:  85%| | 3485/4096 [00:08<00:01, 421.09it/s]
Adding requests:  86%| | 3528/4096 [00:08<00:01, 419.62it/s]
Adding requests:  87%| | 3575/4096 [00:08<00:01, 433.58it/s]
Adding requests:  88%| | 3619/4096 [00:08<00:01, 418.55it/s]
Adding requests:  90%| | 3666/4096 [00:08<00:00, 433.10it/s]
Adding requests:  91%| | 3710/4096 [00:09<00:00, 410.26it/s]
Adding requests:  92%|| 3754/4096 [00:09<00:00, 418.10it/s]
Adding requests:  93%|| 3797/4096 [00:09<00:00, 406.94it/s]
Adding requests:  94%|| 3838/4096 [00:09<00:00, 397.16it/s]
Adding requests:  95%|| 3879/4096 [00:09<00:00, 399.37it/s]
Adding requests:  96%|| 3921/4096 [00:09<00:00, 405.14it/s]
Adding requests:  97%|| 3962/4096 [00:09<00:00, 406.09it/s]
Adding requests:  98%|| 4006/4096 [00:09<00:00, 413.76it/s]
Adding requests:  99%|| 4048/4096 [00:09<00:00, 404.85it/s]
Adding requests: 100%|| 4092/4096 [00:10<00:00, 414.21it/s]
Adding requests: 100%|| 4096/4096 [00:10<00:00, 407.60it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 34/4096 [00:01<03:20, 20.22it/s, est. speed input: 20706.25 toks/s, output: 20.22 toks/s]
Processed prompts:   2%|         | 66/4096 [00:07<08:15,  8.13it/s, est. speed input: 9168.49 toks/s, output: 8.95 toks/s]  
Processed prompts:   2%|         | 98/4096 [00:13<09:50,  6.77it/s, est. speed input: 7685.10 toks/s, output: 7.50 toks/s]
Processed prompts:   3%|         | 130/4096 [00:18<10:32,  6.27it/s, est. speed input: 7098.43 toks/s, output: 6.93 toks/s]
Processed prompts:   4%|         | 162/4096 [00:24<10:54,  6.01it/s, est. speed input: 6782.06 toks/s, output: 6.62 toks/s]
Processed prompts:   5%|         | 194/4096 [00:30<10:58,  5.93it/s, est. speed input: 6618.54 toks/s, output: 6.46 toks/s]
Processed prompts:   6%|         | 226/4096 [00:35<11:05,  5.81it/s, est. speed input: 6476.16 toks/s, output: 6.32 toks/s]
Processed prompts:   6%|         | 258/4096 [00:41<11:08,  5.74it/s, est. speed input: 6372.07 toks/s, output: 6.22 toks/s]
Processed prompts:   7%|         | 290/4096 [00:47<11:02,  5.75it/s, est. speed input: 6315.93 toks/s, output: 6.17 toks/s]
Processed prompts:   8%|         | 322/4096 [00:52<11:02,  5.70it/s, est. speed input: 6251.69 toks/s, output: 6.11 toks/s]
Processed prompts:   9%|         | 354/4096 [00:58<11:00,  5.66it/s, est. speed input: 6200.44 toks/s, output: 6.06 toks/s]
Processed prompts:   9%|         | 386/4096 [01:04<10:57,  5.64it/s, est. speed input: 6157.65 toks/s, output: 6.01 toks/s]
Processed prompts:  10%|         | 418/4096 [01:09<10:48,  5.68it/s, est. speed input: 6136.62 toks/s, output: 5.99 toks/s]
Processed prompts:  11%|         | 450/4096 [01:15<10:45,  5.65it/s, est. speed input: 6105.40 toks/s, output: 5.96 toks/s]
Processed prompts:  12%|        | 482/4096 [01:21<10:42,  5.63it/s, est. speed input: 6077.50 toks/s, output: 5.94 toks/s]
Processed prompts:  13%|        | 514/4096 [01:26<10:38,  5.61it/s, est. speed input: 6053.32 toks/s, output: 5.91 toks/s]
Processed prompts:  13%|        | 546/4096 [01:32<10:33,  5.60it/s, est. speed input: 6032.24 toks/s, output: 5.89 toks/s]
Processed prompts:  14%|        | 578/4096 [01:38<10:28,  5.60it/s, est. speed input: 6013.62 toks/s, output: 5.87 toks/s]
Processed prompts:  15%|        | 610/4096 [01:44<10:23,  5.59it/s, est. speed input: 5997.09 toks/s, output: 5.86 toks/s]
Processed prompts:  16%|        | 642/4096 [01:49<10:17,  5.59it/s, est. speed input: 5982.67 toks/s, output: 5.84 toks/s]
Processed prompts:  16%|        | 674/4096 [01:55<10:12,  5.59it/s, est. speed input: 5969.62 toks/s, output: 5.83 toks/s]
Processed prompts:  17%|        | 706/4096 [02:01<10:06,  5.59it/s, est. speed input: 5957.47 toks/s, output: 5.82 toks/s]
Processed prompts:  18%|        | 738/4096 [02:07<10:01,  5.58it/s, est. speed input: 5946.07 toks/s, output: 5.81 toks/s]
Processed prompts:  19%|        | 770/4096 [02:12<09:50,  5.63it/s, est. speed input: 5943.22 toks/s, output: 5.80 toks/s]
Processed prompts:  20%|        | 802/4096 [02:18<09:46,  5.61it/s, est. speed input: 5933.77 toks/s, output: 5.79 toks/s]
Processed prompts:  20%|        | 834/4096 [02:24<09:42,  5.60it/s, est. speed input: 5925.09 toks/s, output: 5.79 toks/s]
Processed prompts:  21%|        | 866/4096 [02:29<09:37,  5.60it/s, est. speed input: 5916.92 toks/s, output: 5.78 toks/s]
Processed prompts:  22%|       | 898/4096 [02:35<09:32,  5.59it/s, est. speed input: 5909.26 toks/s, output: 5.77 toks/s]
Processed prompts:  23%|       | 930/4096 [02:41<09:26,  5.58it/s, est. speed input: 5902.01 toks/s, output: 5.76 toks/s]
Processed prompts:  23%|       | 962/4096 [02:47<09:21,  5.58it/s, est. speed input: 5895.45 toks/s, output: 5.76 toks/s]
Processed prompts:  24%|       | 994/4096 [02:52<09:15,  5.58it/s, est. speed input: 5889.50 toks/s, output: 5.75 toks/s]
Processed prompts:  25%|       | 1026/4096 [02:58<09:09,  5.58it/s, est. speed input: 5883.98 toks/s, output: 5.75 toks/s]
Processed prompts:  26%|       | 1058/4096 [03:04<09:04,  5.58it/s, est. speed input: 5878.55 toks/s, output: 5.74 toks/s]
Processed prompts:  27%|       | 1090/4096 [03:10<08:58,  5.58it/s, est. speed input: 5873.49 toks/s, output: 5.74 toks/s]
Processed prompts:  27%|       | 1122/4096 [03:15<08:53,  5.58it/s, est. speed input: 5868.59 toks/s, output: 5.73 toks/s]
Processed prompts:  28%|       | 1154/4096 [03:21<08:47,  5.58it/s, est. speed input: 5863.99 toks/s, output: 5.73 toks/s]
Processed prompts:  29%|       | 1186/4096 [03:27<08:37,  5.63it/s, est. speed input: 5864.44 toks/s, output: 5.73 toks/s]
Processed prompts:  30%|       | 1218/4096 [03:32<08:28,  5.66it/s, est. speed input: 5864.99 toks/s, output: 5.73 toks/s]
Processed prompts:  31%|       | 1250/4096 [03:38<08:25,  5.63it/s, est. speed input: 5860.84 toks/s, output: 5.72 toks/s]
Processed prompts:  31%|      | 1282/4096 [03:44<08:21,  5.62it/s, est. speed input: 5856.95 toks/s, output: 5.72 toks/s]
Processed prompts:  32%|      | 1314/4096 [03:49<08:12,  5.65it/s, est. speed input: 5857.43 toks/s, output: 5.72 toks/s]
Processed prompts:  33%|      | 1346/4096 [03:55<08:08,  5.63it/s, est. speed input: 5853.58 toks/s, output: 5.72 toks/s]
Processed prompts:  34%|      | 1378/4096 [04:01<08:04,  5.61it/s, est. speed input: 5849.97 toks/s, output: 5.71 toks/s]
Processed prompts:  34%|      | 1410/4096 [04:06<07:59,  5.60it/s, est. speed input: 5846.63 toks/s, output: 5.71 toks/s]
Processed prompts:  35%|      | 1442/4096 [04:12<07:48,  5.66it/s, est. speed input: 5849.04 toks/s, output: 5.71 toks/s]
Processed prompts:  36%|      | 1474/4096 [04:18<07:45,  5.63it/s, est. speed input: 5845.59 toks/s, output: 5.71 toks/s]
Processed prompts:  37%|      | 1506/4096 [04:23<07:37,  5.66it/s, est. speed input: 5846.16 toks/s, output: 5.71 toks/s]
Processed prompts:  38%|      | 1538/4096 [04:29<07:30,  5.68it/s, est. speed input: 5846.35 toks/s, output: 5.71 toks/s]
Processed prompts:  38%|      | 1570/4096 [04:35<07:27,  5.64it/s, est. speed input: 5843.12 toks/s, output: 5.71 toks/s]
Processed prompts:  39%|      | 1602/4096 [04:40<07:19,  5.67it/s, est. speed input: 5843.62 toks/s, output: 5.71 toks/s]
Processed prompts:  40%|      | 1634/4096 [04:46<07:16,  5.64it/s, est. speed input: 5840.61 toks/s, output: 5.70 toks/s]
Processed prompts:  41%|      | 1666/4096 [04:52<07:12,  5.62it/s, est. speed input: 5837.98 toks/s, output: 5.70 toks/s]
Processed prompts:  41%|     | 1698/4096 [04:57<07:07,  5.60it/s, est. speed input: 5835.45 toks/s, output: 5.70 toks/s]
Processed prompts:  42%|     | 1730/4096 [05:03<06:51,  5.75it/s, est. speed input: 5842.99 toks/s, output: 5.71 toks/s]
Processed prompts:  43%|     | 1762/4096 [05:08<06:49,  5.70it/s, est. speed input: 5840.48 toks/s, output: 5.70 toks/s]
Processed prompts:  44%|     | 1794/4096 [05:14<06:46,  5.66it/s, est. speed input: 5838.20 toks/s, output: 5.70 toks/s]
Processed prompts:  45%|     | 1826/4096 [05:20<06:42,  5.64it/s, est. speed input: 5835.99 toks/s, output: 5.70 toks/s]
Processed prompts:  45%|     | 1858/4096 [05:26<06:38,  5.62it/s, est. speed input: 5833.95 toks/s, output: 5.70 toks/s]
Processed prompts:  46%|     | 1890/4096 [05:31<06:29,  5.66it/s, est. speed input: 5834.83 toks/s, output: 5.70 toks/s]
Processed prompts:  47%|     | 1922/4096 [05:37<06:25,  5.64it/s, est. speed input: 5832.92 toks/s, output: 5.70 toks/s]
Processed prompts:  48%|     | 1954/4096 [05:43<06:20,  5.62it/s, est. speed input: 5831.04 toks/s, output: 5.69 toks/s]
Processed prompts:  48%|     | 1986/4096 [05:48<06:12,  5.66it/s, est. speed input: 5831.92 toks/s, output: 5.70 toks/s]
Processed prompts:  49%|     | 2018/4096 [05:54<06:08,  5.64it/s, est. speed input: 5830.10 toks/s, output: 5.69 toks/s]
Processed prompts:  50%|     | 2050/4096 [06:00<06:00,  5.67it/s, est. speed input: 5831.04 toks/s, output: 5.69 toks/s]
Processed prompts:  51%|     | 2082/4096 [06:05<05:56,  5.64it/s, est. speed input: 5829.19 toks/s, output: 5.69 toks/s]
Processed prompts:  52%|    | 2114/4096 [06:11<05:52,  5.63it/s, est. speed input: 5827.53 toks/s, output: 5.69 toks/s]
Processed prompts:  52%|    | 2146/4096 [06:17<05:47,  5.61it/s, est. speed input: 5825.81 toks/s, output: 5.69 toks/s]
Processed prompts:  53%|    | 2178/4096 [06:22<05:39,  5.65it/s, est. speed input: 5826.79 toks/s, output: 5.69 toks/s]
Processed prompts:  54%|    | 2210/4096 [06:28<05:34,  5.64it/s, est. speed input: 5825.31 toks/s, output: 5.69 toks/s]
Processed prompts:  55%|    | 2242/4096 [06:34<05:29,  5.62it/s, est. speed input: 5823.71 toks/s, output: 5.69 toks/s]
Processed prompts:  56%|    | 2274/4096 [06:39<05:24,  5.61it/s, est. speed input: 5822.29 toks/s, output: 5.69 toks/s]
Processed prompts:  56%|    | 2306/4096 [06:45<05:19,  5.61it/s, est. speed input: 5820.97 toks/s, output: 5.68 toks/s]
Processed prompts:  57%|    | 2338/4096 [06:51<05:11,  5.65it/s, est. speed input: 5821.97 toks/s, output: 5.69 toks/s]
Processed prompts:  58%|    | 2370/4096 [06:56<05:06,  5.63it/s, est. speed input: 5820.69 toks/s, output: 5.68 toks/s]
Processed prompts:  59%|    | 2402/4096 [07:02<05:01,  5.62it/s, est. speed input: 5819.28 toks/s, output: 5.68 toks/s]
Processed prompts:  59%|    | 2434/4096 [07:08<04:56,  5.61it/s, est. speed input: 5817.96 toks/s, output: 5.68 toks/s]
Processed prompts:  60%|    | 2466/4096 [07:14<04:50,  5.60it/s, est. speed input: 5816.71 toks/s, output: 5.68 toks/s]
Processed prompts:  61%|    | 2498/4096 [07:19<04:45,  5.60it/s, est. speed input: 5815.47 toks/s, output: 5.68 toks/s]
Processed prompts:  62%|   | 2530/4096 [07:25<04:37,  5.65it/s, est. speed input: 5816.50 toks/s, output: 5.68 toks/s]
Processed prompts:  63%|   | 2562/4096 [07:31<04:32,  5.63it/s, est. speed input: 5815.28 toks/s, output: 5.68 toks/s]
Processed prompts:  63%|   | 2594/4096 [07:36<04:25,  5.66it/s, est. speed input: 5816.17 toks/s, output: 5.68 toks/s]
Processed prompts:  64%|   | 2626/4096 [07:42<04:20,  5.64it/s, est. speed input: 5814.96 toks/s, output: 5.68 toks/s]
Processed prompts:  65%|   | 2658/4096 [07:47<04:13,  5.68it/s, est. speed input: 5815.94 toks/s, output: 5.68 toks/s]
Processed prompts:  66%|   | 2690/4096 [07:53<04:08,  5.65it/s, est. speed input: 5814.73 toks/s, output: 5.68 toks/s]
Processed prompts:  66%|   | 2722/4096 [07:59<04:01,  5.68it/s, est. speed input: 5815.72 toks/s, output: 5.68 toks/s]
Processed prompts:  67%|   | 2754/4096 [08:04<03:57,  5.65it/s, est. speed input: 5814.70 toks/s, output: 5.68 toks/s]
Processed prompts:  68%|   | 2786/4096 [08:10<03:52,  5.64it/s, est. speed input: 5813.72 toks/s, output: 5.68 toks/s]
Processed prompts:  69%|   | 2818/4096 [08:16<03:47,  5.62it/s, est. speed input: 5812.73 toks/s, output: 5.68 toks/s]
Processed prompts:  70%|   | 2850/4096 [08:22<03:41,  5.61it/s, est. speed input: 5811.68 toks/s, output: 5.68 toks/s]
Processed prompts:  70%|   | 2882/4096 [08:27<03:33,  5.69it/s, est. speed input: 5813.75 toks/s, output: 5.68 toks/s]
Processed prompts:  71%|   | 2914/4096 [08:33<03:27,  5.71it/s, est. speed input: 5814.61 toks/s, output: 5.68 toks/s]
Processed prompts:  72%|  | 2946/4096 [08:38<03:22,  5.67it/s, est. speed input: 5813.61 toks/s, output: 5.68 toks/s]
Processed prompts:  73%|  | 2978/4096 [08:44<03:16,  5.70it/s, est. speed input: 5814.57 toks/s, output: 5.68 toks/s]
Processed prompts:  73%|  | 3010/4096 [08:50<03:11,  5.67it/s, est. speed input: 5813.59 toks/s, output: 5.68 toks/s]
Processed prompts:  74%|  | 3042/4096 [08:55<03:06,  5.64it/s, est. speed input: 5812.65 toks/s, output: 5.68 toks/s]
Processed prompts:  75%|  | 3074/4096 [09:01<03:01,  5.63it/s, est. speed input: 5811.72 toks/s, output: 5.68 toks/s]
Processed prompts:  76%|  | 3106/4096 [09:07<02:56,  5.62it/s, est. speed input: 5810.91 toks/s, output: 5.67 toks/s]
Processed prompts:  77%|  | 3138/4096 [09:13<02:50,  5.61it/s, est. speed input: 5810.03 toks/s, output: 5.67 toks/s]
Processed prompts:  77%|  | 3170/4096 [09:18<02:43,  5.66it/s, est. speed input: 5810.92 toks/s, output: 5.67 toks/s]
Processed prompts:  78%|  | 3202/4096 [09:24<02:38,  5.63it/s, est. speed input: 5810.00 toks/s, output: 5.67 toks/s]
Processed prompts:  79%|  | 3234/4096 [09:30<02:33,  5.62it/s, est. speed input: 5809.11 toks/s, output: 5.67 toks/s]
Processed prompts:  80%|  | 3266/4096 [09:35<02:27,  5.61it/s, est. speed input: 5808.29 toks/s, output: 5.67 toks/s]
Processed prompts:  81%|  | 3298/4096 [09:41<02:22,  5.60it/s, est. speed input: 5807.42 toks/s, output: 5.67 toks/s]
Processed prompts:  81%| | 3330/4096 [09:47<02:16,  5.60it/s, est. speed input: 5806.64 toks/s, output: 5.67 toks/s]
Processed prompts:  82%| | 3362/4096 [09:52<02:11,  5.60it/s, est. speed input: 5805.83 toks/s, output: 5.67 toks/s]
Processed prompts:  83%| | 3394/4096 [09:58<02:04,  5.65it/s, est. speed input: 5806.72 toks/s, output: 5.67 toks/s]
Processed prompts:  84%| | 3426/4096 [10:04<01:58,  5.63it/s, est. speed input: 5806.05 toks/s, output: 5.67 toks/s]
Processed prompts:  84%| | 3458/4096 [10:09<01:53,  5.62it/s, est. speed input: 5805.29 toks/s, output: 5.67 toks/s]
Processed prompts:  85%| | 3490/4096 [10:15<01:48,  5.61it/s, est. speed input: 5804.53 toks/s, output: 5.67 toks/s]
Processed prompts:  86%| | 3522/4096 [10:21<01:42,  5.60it/s, est. speed input: 5803.80 toks/s, output: 5.67 toks/s]
Processed prompts:  87%| | 3554/4096 [10:26<01:35,  5.65it/s, est. speed input: 5804.60 toks/s, output: 5.67 toks/s]
Processed prompts:  88%| | 3586/4096 [10:32<01:30,  5.63it/s, est. speed input: 5803.86 toks/s, output: 5.67 toks/s]
Processed prompts:  88%| | 3618/4096 [10:38<01:24,  5.67it/s, est. speed input: 5804.67 toks/s, output: 5.67 toks/s]
Processed prompts:  89%| | 3650/4096 [10:43<01:19,  5.64it/s, est. speed input: 5803.91 toks/s, output: 5.67 toks/s]
Processed prompts:  90%| | 3682/4096 [10:49<01:12,  5.71it/s, est. speed input: 5805.52 toks/s, output: 5.67 toks/s]
Processed prompts:  91%| | 3714/4096 [10:55<01:07,  5.67it/s, est. speed input: 5804.74 toks/s, output: 5.67 toks/s]
Processed prompts:  91%|| 3746/4096 [11:00<01:02,  5.64it/s, est. speed input: 5804.01 toks/s, output: 5.67 toks/s]
Processed prompts:  92%|| 3778/4096 [11:06<00:56,  5.63it/s, est. speed input: 5803.39 toks/s, output: 5.67 toks/s]
Processed prompts:  93%|| 3810/4096 [11:12<00:50,  5.62it/s, est. speed input: 5802.72 toks/s, output: 5.67 toks/s]
Processed prompts:  94%|| 3842/4096 [11:18<00:45,  5.61it/s, est. speed input: 5801.99 toks/s, output: 5.67 toks/s]
Processed prompts:  95%|| 3874/4096 [11:23<00:39,  5.60it/s, est. speed input: 5801.35 toks/s, output: 5.67 toks/s]
Processed prompts:  95%|| 3906/4096 [11:29<00:33,  5.65it/s, est. speed input: 5802.13 toks/s, output: 5.67 toks/s]
Processed prompts:  96%|| 3938/4096 [11:34<00:27,  5.68it/s, est. speed input: 5802.81 toks/s, output: 5.67 toks/s]
Processed prompts:  97%|| 3970/4096 [11:40<00:22,  5.65it/s, est. speed input: 5802.21 toks/s, output: 5.67 toks/s]
Processed prompts:  98%|| 4002/4096 [11:46<00:16,  5.68it/s, est. speed input: 5802.96 toks/s, output: 5.67 toks/s]
Processed prompts:  98%|| 4034/4096 [11:51<00:10,  5.70it/s, est. speed input: 5803.64 toks/s, output: 5.67 toks/s]
Processed prompts:  99%|| 4066/4096 [11:57<00:05,  5.75it/s, est. speed input: 5805.08 toks/s, output: 5.67 toks/s]
Processed prompts: 100%|| 4096/4096 [11:57<00:00,  5.75it/s, est. speed input: 5847.91 toks/s, output: 5.71 toks/s]
Processed prompts: 100%|| 4096/4096 [11:57<00:00,  5.71it/s, est. speed input: 5847.91 toks/s, output: 5.71 toks/s]
[rank0]:[W126 20:27:50.858829905 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-26 20:27:54
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Qwen2.5-7B-FP8_M65536.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 20:28:27 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 20:28:27 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1703877) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 303, in forward
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]     hidden_states = self.mlp(hidden_states)
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 108, in forward
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]     x, _ = self.down_proj(x)
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]            ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 1405, in forward
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]     output_parallel = self.quant_method.apply(self, input_parallel, bias_)
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 243, in quant_slide_fp8_triton
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]     out = torch.zeros(M_padded, K_out_padded, dtype=torch.float8_e4m3fn, device=x.device)
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866]           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866] torch.AcceleratorError: CUDA error: an illegal memory access was encountered
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866] Search for `cudaErrorIllegalAddress' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866] CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866] For debugging consider passing CUDA_LAUNCH_BLOCKING=1
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866] Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
(EngineCore_DP0 pid=1703877) ERROR 01-26 20:29:42 [core.py:866] 

STDERR:
[2026-01-26 20:28:27] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 20:28:27] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 20:28:27] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 20:28:27] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:28:27] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:28:27] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:28:27] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:28:27] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:28:27] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 20:28:27] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 20:28:27] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 20:28:27] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 20:28:27] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 20:28:27] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 20:28:30] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 20:28:30] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 20:28:30] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 20:28:30] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:28:30] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:28:30] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:28:30] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:28:30] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:28:30] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 20:28:30] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 20:28:30] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 20:28:30] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 20:28:30] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 20:28:30] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1703877) [2026-01-26 20:28:31] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1703877) [2026-01-26 20:28:31] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1703877) [2026-01-26 20:28:31] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1703877) [2026-01-26 20:28:31] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1703877) [2026-01-26 20:28:31] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1703877) [2026-01-26 20:28:31] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1703877) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1703877) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:29<00:29, 29.24s/it]
(EngineCore_DP0 pid=1703877) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:07<00:00, 34.76s/it]
(EngineCore_DP0 pid=1703877) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:07<00:00, 33.93s/it]
(EngineCore_DP0 pid=1703877) 
(EngineCore_DP0 pid=1703877) [2026-01-26 20:29:40] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=1703877) [2026-01-26 20:29:40] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16588800 bytes
(EngineCore_DP0 pid=1703877) [2026-01-26 20:29:40] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=1703877) [2026-01-26 20:29:40] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 12902400 bytes
(EngineCore_DP0 pid=1703877) [2026-01-26 20:29:40] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=1703877) [2026-01-26 20:29:40] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 136396800 bytes
(EngineCore_DP0 pid=1703877) [2026-01-26 20:29:40] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=1703877) [2026-01-26 20:29:40] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 67952640 bytes
(EngineCore_DP0 pid=1703877) Process EngineCore_DP0:
(EngineCore_DP0 pid=1703877) Traceback (most recent call last):
(EngineCore_DP0 pid=1703877)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=1703877)     self.run()
(EngineCore_DP0 pid=1703877)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=1703877)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=1703877)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=1703877)     raise e
(EngineCore_DP0 pid=1703877)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1703877)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1703877)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1703877)     super().__init__(
(EngineCore_DP0 pid=1703877)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=1703877)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=1703877)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=1703877)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=1703877)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=1703877)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=1703877)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=1703877)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=1703877)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=1703877)     return func(*args, **kwargs)
(EngineCore_DP0 pid=1703877)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=1703877)     return func(*args, **kwargs)
(EngineCore_DP0 pid=1703877)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=1703877)     self.model_runner.profile_run()
(EngineCore_DP0 pid=1703877)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=1703877)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=1703877)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=1703877)     return func(*args, **kwargs)
(EngineCore_DP0 pid=1703877)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=1703877)     outputs = self.model(
(EngineCore_DP0 pid=1703877)               ^^^^^^^^^^^
(EngineCore_DP0 pid=1703877)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1703877)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1703877)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1703877)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1703877)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=1703877)     hidden_states = self.model(
(EngineCore_DP0 pid=1703877)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=1703877)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=1703877)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=1703877)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=1703877)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=1703877)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1703877)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1703877)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1703877)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1703877)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 303, in forward
(EngineCore_DP0 pid=1703877)     hidden_states = self.mlp(hidden_states)
(EngineCore_DP0 pid=1703877)                     ^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1703877)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1703877)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1703877)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1703877)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 108, in forward
(EngineCore_DP0 pid=1703877)     x, _ = self.down_proj(x)
(EngineCore_DP0 pid=1703877)            ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1703877)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1703877)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1703877)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1703877)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 1405, in forward
(EngineCore_DP0 pid=1703877)     output_parallel = self.quant_method.apply(self, input_parallel, bias_)
(EngineCore_DP0 pid=1703877)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=1703877)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=1703877)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=1703877)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=1703877)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=1703877)     return self._linear_fn(
(EngineCore_DP0 pid=1703877)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=1703877)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=1703877)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=1703877)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=1703877)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=1703877)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=1703877)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=1703877)     return fn(input, L)
(EngineCore_DP0 pid=1703877)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 243, in quant_slide_fp8_triton
(EngineCore_DP0 pid=1703877)     out = torch.zeros(M_padded, K_out_padded, dtype=torch.float8_e4m3fn, device=x.device)
(EngineCore_DP0 pid=1703877)           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1703877) torch.AcceleratorError: CUDA error: an illegal memory access was encountered
(EngineCore_DP0 pid=1703877) Search for `cudaErrorIllegalAddress' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
(EngineCore_DP0 pid=1703877) CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
(EngineCore_DP0 pid=1703877) For debugging consider passing CUDA_LAUNCH_BLOCKING=1
(EngineCore_DP0 pid=1703877) Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
(EngineCore_DP0 pid=1703877) 
[rank0]:[W126 20:29:42.764946913 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=65536

========== M=512 ==========
Time: 2026-01-27 13:23:51
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Qwen2.5-14B-FP8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-27 13:23:58 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-27 13:23:58 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=2656516) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2656516) WARNING 01-27 13:26:21 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 5.98 requests/s, 3069.90 total tokens/s, 5.98 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-27 13:23:58] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 13:23:58] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 13:23:58] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 13:23:58] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:23:58] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:23:58] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:23:58] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:23:58] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:23:58] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 13:23:58] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 13:23:58] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 13:23:58] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 13:23:58] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 13:23:58] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-27 13:24:02] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 13:24:02] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 13:24:02] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 13:24:02] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:24:02] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:24:02] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:24:02] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:24:02] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:24:02] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 13:24:02] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 13:24:02] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 13:24:02] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 13:24:02] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 13:24:02] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=2656516) [2026-01-27 13:24:03] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=2656516) [2026-01-27 13:24:03] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2656516) [2026-01-27 13:24:03] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=2656516) [2026-01-27 13:24:03] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=2656516) [2026-01-27 13:24:03] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=2656516) [2026-01-27 13:24:03] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=2656516) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=2656516) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:26,  8.70s/it]
(EngineCore_DP0 pid=2656516) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:40<00:44, 22.19s/it]
(EngineCore_DP0 pid=2656516) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [01:16<00:28, 28.58s/it]
(EngineCore_DP0 pid=2656516) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:57<00:00, 33.46s/it]
(EngineCore_DP0 pid=2656516) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:57<00:00, 29.36s/it]
(EngineCore_DP0 pid=2656516) 
(EngineCore_DP0 pid=2656516) [2026-01-27 13:26:02] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 8192] -> 1D uint8
(EngineCore_DP0 pid=2656516) [2026-01-27 13:26:02] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 36700160 bytes
(EngineCore_DP0 pid=2656516) [2026-01-27 13:26:02] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 8192] -> 1D uint8
(EngineCore_DP0 pid=2656516) [2026-01-27 13:26:02] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 26214400 bytes
(EngineCore_DP0 pid=2656516) [2026-01-27 13:26:02] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 8192] -> 1D uint8
(EngineCore_DP0 pid=2656516) [2026-01-27 13:26:02] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 141557760 bytes
(EngineCore_DP0 pid=2656516) [2026-01-27 13:26:02] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 22144] -> 1D uint8
(EngineCore_DP0 pid=2656516) [2026-01-27 13:26:02] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 70860800 bytes
(EngineCore_DP0 pid=2656516) 2026-01-27 13:26:11,379 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=2656516) 2026-01-27 13:26:11,731 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:   1%|          | 1/128 [00:00<01:51,  1.14it/s]
Adding requests:   2%|         | 2/128 [00:01<01:04,  1.95it/s]
Adding requests:   2%|         | 3/128 [00:01<00:42,  2.91it/s]
Adding requests:   3%|         | 4/128 [00:01<00:30,  4.00it/s]
Adding requests:   5%|         | 6/128 [00:01<00:19,  6.18it/s]
Adding requests:   6%|         | 8/128 [00:01<00:14,  8.53it/s]
Adding requests:   9%|         | 11/128 [00:01<00:09, 12.24it/s]
Adding requests:  11%|         | 14/128 [00:01<00:07, 15.31it/s]
Adding requests:  15%|        | 19/128 [00:02<00:04, 22.79it/s]
Adding requests:  20%|        | 25/128 [00:02<00:03, 31.24it/s]
Adding requests:  27%|       | 35/128 [00:02<00:01, 48.22it/s]
Adding requests:  56%|    | 72/128 [00:02<00:00, 132.90it/s]
Adding requests:  92%|| 118/128 [00:02<00:00, 222.11it/s]
Adding requests: 100%|| 128/128 [00:02<00:00, 51.98it/s] 

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   8%|         | 10/128 [00:00<00:02, 40.94it/s, est. speed input: 20964.80 toks/s, output: 40.94 toks/s]
Processed prompts:  12%|        | 15/128 [00:01<00:08, 12.56it/s, est. speed input: 7464.41 toks/s, output: 14.58 toks/s] 
Processed prompts:  14%|        | 18/128 [00:01<00:11,  9.97it/s, est. speed input: 6132.48 toks/s, output: 11.98 toks/s]
Processed prompts:  16%|        | 20/128 [00:01<00:11,  9.02it/s, est. speed input: 5660.06 toks/s, output: 11.05 toks/s]
Processed prompts:  17%|        | 22/128 [00:02<00:12,  8.26it/s, est. speed input: 5307.43 toks/s, output: 10.37 toks/s]
Processed prompts:  18%|        | 23/128 [00:02<00:13,  7.95it/s, est. speed input: 5170.46 toks/s, output: 10.10 toks/s]
Processed prompts:  19%|        | 24/128 [00:02<00:13,  7.62it/s, est. speed input: 5043.44 toks/s, output: 9.85 toks/s] 
Processed prompts:  20%|        | 25/128 [00:02<00:14,  7.32it/s, est. speed input: 4929.95 toks/s, output: 9.63 toks/s]
Processed prompts:  20%|        | 26/128 [00:02<00:14,  7.13it/s, est. speed input: 4839.99 toks/s, output: 9.45 toks/s]
Processed prompts:  21%|        | 27/128 [00:02<00:14,  6.95it/s, est. speed input: 4756.61 toks/s, output: 9.29 toks/s]
Processed prompts:  22%|       | 28/128 [00:03<00:14,  6.84it/s, est. speed input: 4685.81 toks/s, output: 9.15 toks/s]
Processed prompts:  23%|       | 29/128 [00:03<00:14,  6.72it/s, est. speed input: 4617.35 toks/s, output: 9.02 toks/s]
Processed prompts:  23%|       | 30/128 [00:03<00:14,  6.63it/s, est. speed input: 4556.00 toks/s, output: 8.90 toks/s]
Processed prompts:  24%|       | 31/128 [00:03<00:14,  6.56it/s, est. speed input: 4498.94 toks/s, output: 8.79 toks/s]
Processed prompts:  25%|       | 32/128 [00:03<00:14,  6.43it/s, est. speed input: 4438.69 toks/s, output: 8.67 toks/s]
Processed prompts:  26%|       | 33/128 [00:03<00:14,  6.45it/s, est. speed input: 4393.91 toks/s, output: 8.58 toks/s]
Processed prompts:  27%|       | 34/128 [00:04<00:14,  6.43it/s, est. speed input: 4350.40 toks/s, output: 8.50 toks/s]
Processed prompts:  27%|       | 35/128 [00:04<00:14,  6.40it/s, est. speed input: 4308.27 toks/s, output: 8.41 toks/s]
Processed prompts:  28%|       | 36/128 [00:04<00:14,  6.42it/s, est. speed input: 4272.29 toks/s, output: 8.34 toks/s]
Processed prompts:  29%|       | 37/128 [00:04<00:14,  6.40it/s, est. speed input: 4236.82 toks/s, output: 8.28 toks/s]
Processed prompts:  30%|       | 38/128 [00:04<00:14,  6.42it/s, est. speed input: 4205.96 toks/s, output: 8.21 toks/s]
Processed prompts:  30%|       | 39/128 [00:04<00:14,  6.35it/s, est. speed input: 4170.47 toks/s, output: 8.15 toks/s]
Processed prompts:  31%|      | 40/128 [00:04<00:13,  6.37it/s, est. speed input: 4143.08 toks/s, output: 8.09 toks/s]
Processed prompts:  32%|      | 41/128 [00:05<00:13,  6.39it/s, est. speed input: 4117.29 toks/s, output: 8.04 toks/s]
Processed prompts:  33%|      | 42/128 [00:05<00:13,  6.42it/s, est. speed input: 4094.03 toks/s, output: 8.00 toks/s]
Processed prompts:  34%|      | 43/128 [00:05<00:13,  6.45it/s, est. speed input: 4072.32 toks/s, output: 7.95 toks/s]
Processed prompts:  34%|      | 44/128 [00:05<00:13,  6.43it/s, est. speed input: 4049.58 toks/s, output: 7.91 toks/s]
Processed prompts:  35%|      | 45/128 [00:05<00:13,  6.36it/s, est. speed input: 4025.35 toks/s, output: 7.86 toks/s]
Processed prompts:  36%|      | 46/128 [00:05<00:12,  6.33it/s, est. speed input: 4002.91 toks/s, output: 7.82 toks/s]
Processed prompts:  37%|      | 47/128 [00:06<00:12,  6.36it/s, est. speed input: 3984.53 toks/s, output: 7.78 toks/s]
Processed prompts:  38%|      | 48/128 [00:06<00:12,  6.34it/s, est. speed input: 3964.91 toks/s, output: 7.74 toks/s]
Processed prompts:  38%|      | 49/128 [00:06<00:12,  6.35it/s, est. speed input: 3947.83 toks/s, output: 7.71 toks/s]
Processed prompts:  39%|      | 50/128 [00:06<00:12,  6.34it/s, est. speed input: 3930.59 toks/s, output: 7.68 toks/s]
Processed prompts:  40%|      | 51/128 [00:06<00:12,  6.35it/s, est. speed input: 3914.88 toks/s, output: 7.65 toks/s]
Processed prompts:  41%|      | 52/128 [00:06<00:12,  6.28it/s, est. speed input: 3896.25 toks/s, output: 7.61 toks/s]
Processed prompts:  41%|     | 53/128 [00:06<00:11,  6.32it/s, est. speed input: 3882.73 toks/s, output: 7.58 toks/s]
Processed prompts:  42%|     | 54/128 [00:07<00:11,  6.31it/s, est. speed input: 3867.71 toks/s, output: 7.55 toks/s]
Processed prompts:  43%|     | 55/128 [00:07<00:11,  6.33it/s, est. speed input: 3854.99 toks/s, output: 7.53 toks/s]
Processed prompts:  44%|     | 56/128 [00:07<00:11,  6.37it/s, est. speed input: 3843.46 toks/s, output: 7.51 toks/s]
Processed prompts:  45%|     | 57/128 [00:07<00:11,  6.39it/s, est. speed input: 3832.41 toks/s, output: 7.49 toks/s]
Processed prompts:  45%|     | 58/128 [00:07<00:10,  6.39it/s, est. speed input: 3820.92 toks/s, output: 7.46 toks/s]
Processed prompts:  46%|     | 59/128 [00:07<00:10,  6.31it/s, est. speed input: 3807.04 toks/s, output: 7.44 toks/s]
Processed prompts:  47%|     | 60/128 [00:08<00:10,  6.36it/s, est. speed input: 3797.80 toks/s, output: 7.42 toks/s]
Processed prompts:  48%|     | 61/128 [00:08<00:10,  6.37it/s, est. speed input: 3787.69 toks/s, output: 7.40 toks/s]
Processed prompts:  48%|     | 62/128 [00:08<00:10,  6.34it/s, est. speed input: 3776.98 toks/s, output: 7.38 toks/s]
Processed prompts:  49%|     | 63/128 [00:08<00:10,  6.34it/s, est. speed input: 3767.12 toks/s, output: 7.36 toks/s]
Processed prompts:  50%|     | 64/128 [00:08<00:10,  6.36it/s, est. speed input: 3758.36 toks/s, output: 7.34 toks/s]
Processed prompts:  51%|     | 65/128 [00:08<00:09,  6.34it/s, est. speed input: 3748.62 toks/s, output: 7.32 toks/s]
Processed prompts:  52%|    | 66/128 [00:09<00:09,  6.30it/s, est. speed input: 3738.50 toks/s, output: 7.30 toks/s]
Processed prompts:  52%|    | 67/128 [00:09<00:09,  6.33it/s, est. speed input: 3730.72 toks/s, output: 7.29 toks/s]
Processed prompts:  53%|    | 68/128 [00:09<00:09,  6.32it/s, est. speed input: 3722.00 toks/s, output: 7.27 toks/s]
Processed prompts:  54%|    | 69/128 [00:09<00:09,  6.34it/s, est. speed input: 3714.49 toks/s, output: 7.25 toks/s]
Processed prompts:  55%|    | 70/128 [00:09<00:09,  6.39it/s, est. speed input: 3708.57 toks/s, output: 7.24 toks/s]
Processed prompts:  55%|    | 71/128 [00:09<00:08,  6.40it/s, est. speed input: 3701.74 toks/s, output: 7.23 toks/s]
Processed prompts:  56%|    | 72/128 [00:09<00:08,  6.30it/s, est. speed input: 3692.24 toks/s, output: 7.21 toks/s]
Processed prompts:  57%|    | 73/128 [00:10<00:08,  6.34it/s, est. speed input: 3686.05 toks/s, output: 7.20 toks/s]
Processed prompts:  58%|    | 74/128 [00:10<00:08,  6.34it/s, est. speed input: 3679.41 toks/s, output: 7.19 toks/s]
Processed prompts:  59%|    | 75/128 [00:10<00:08,  6.34it/s, est. speed input: 3672.92 toks/s, output: 7.17 toks/s]
Processed prompts:  59%|    | 76/128 [00:10<00:08,  6.36it/s, est. speed input: 3666.96 toks/s, output: 7.16 toks/s]
Processed prompts:  60%|    | 77/128 [00:10<00:07,  6.39it/s, est. speed input: 3661.90 toks/s, output: 7.15 toks/s]
Processed prompts:  61%|    | 78/128 [00:10<00:07,  6.39it/s, est. speed input: 3656.25 toks/s, output: 7.14 toks/s]
Processed prompts:  62%|   | 79/128 [00:11<00:07,  6.31it/s, est. speed input: 3648.56 toks/s, output: 7.13 toks/s]
Processed prompts:  62%|   | 80/128 [00:11<00:07,  6.34it/s, est. speed input: 3643.57 toks/s, output: 7.12 toks/s]
Processed prompts:  63%|   | 81/128 [00:11<00:07,  6.34it/s, est. speed input: 3638.09 toks/s, output: 7.11 toks/s]
Processed prompts:  64%|   | 82/128 [00:11<00:07,  6.35it/s, est. speed input: 3633.05 toks/s, output: 7.10 toks/s]
Processed prompts:  65%|   | 83/128 [00:11<00:07,  6.37it/s, est. speed input: 3628.36 toks/s, output: 7.09 toks/s]
Processed prompts:  66%|   | 84/128 [00:11<00:06,  6.38it/s, est. speed input: 3623.82 toks/s, output: 7.08 toks/s]
Processed prompts:  66%|   | 85/128 [00:12<00:06,  6.38it/s, est. speed input: 3619.06 toks/s, output: 7.07 toks/s]
Processed prompts:  67%|   | 86/128 [00:12<00:06,  6.32it/s, est. speed input: 3613.08 toks/s, output: 7.06 toks/s]
Processed prompts:  68%|   | 87/128 [00:12<00:06,  6.33it/s, est. speed input: 3608.52 toks/s, output: 7.05 toks/s]
Processed prompts:  69%|   | 88/128 [00:12<00:06,  6.34it/s, est. speed input: 3604.15 toks/s, output: 7.04 toks/s]
Processed prompts:  70%|   | 89/128 [00:12<00:06,  6.35it/s, est. speed input: 3599.86 toks/s, output: 7.03 toks/s]
Processed prompts:  70%|   | 90/128 [00:12<00:05,  6.37it/s, est. speed input: 3596.17 toks/s, output: 7.02 toks/s]
Processed prompts:  71%|   | 91/128 [00:12<00:05,  6.35it/s, est. speed input: 3591.67 toks/s, output: 7.01 toks/s]
Processed prompts:  72%|  | 92/128 [00:13<00:05,  6.30it/s, est. speed input: 3586.43 toks/s, output: 7.00 toks/s]
Processed prompts:  73%|  | 93/128 [00:13<00:05,  6.31it/s, est. speed input: 3582.21 toks/s, output: 7.00 toks/s]
Processed prompts:  73%|  | 94/128 [00:13<00:05,  6.32it/s, est. speed input: 3578.27 toks/s, output: 6.99 toks/s]
Processed prompts:  74%|  | 95/128 [00:13<00:05,  6.34it/s, est. speed input: 3574.87 toks/s, output: 6.98 toks/s]
Processed prompts:  75%|  | 96/128 [00:13<00:05,  6.35it/s, est. speed input: 3571.37 toks/s, output: 6.98 toks/s]
Processed prompts:  76%|  | 97/128 [00:13<00:04,  6.36it/s, est. speed input: 3567.87 toks/s, output: 6.97 toks/s]
Processed prompts:  77%|  | 98/128 [00:14<00:04,  6.39it/s, est. speed input: 3564.95 toks/s, output: 6.96 toks/s]
Processed prompts:  77%|  | 99/128 [00:14<00:04,  6.29it/s, est. speed input: 3559.76 toks/s, output: 6.95 toks/s]
Processed prompts:  78%|  | 100/128 [00:14<00:04,  6.31it/s, est. speed input: 3556.34 toks/s, output: 6.95 toks/s]
Processed prompts:  79%|  | 101/128 [00:14<00:04,  6.34it/s, est. speed input: 3553.43 toks/s, output: 6.94 toks/s]
Processed prompts:  80%|  | 102/128 [00:14<00:04,  6.35it/s, est. speed input: 3550.24 toks/s, output: 6.93 toks/s]
Processed prompts:  80%|  | 103/128 [00:14<00:03,  6.37it/s, est. speed input: 3547.48 toks/s, output: 6.93 toks/s]
Processed prompts:  81%| | 104/128 [00:15<00:03,  6.39it/s, est. speed input: 3544.96 toks/s, output: 6.92 toks/s]
Processed prompts:  82%| | 105/128 [00:15<00:03,  6.38it/s, est. speed input: 3541.98 toks/s, output: 6.92 toks/s]
Processed prompts:  83%| | 106/128 [00:15<00:03,  6.30it/s, est. speed input: 3537.56 toks/s, output: 6.91 toks/s]
Processed prompts:  84%| | 107/128 [00:15<00:03,  6.33it/s, est. speed input: 3535.05 toks/s, output: 6.90 toks/s]
Processed prompts:  84%| | 108/128 [00:15<00:03,  6.34it/s, est. speed input: 3532.29 toks/s, output: 6.90 toks/s]
Processed prompts:  85%| | 109/128 [00:15<00:02,  6.35it/s, est. speed input: 3529.60 toks/s, output: 6.89 toks/s]
Processed prompts:  86%| | 110/128 [00:15<00:02,  6.36it/s, est. speed input: 3526.93 toks/s, output: 6.89 toks/s]
Processed prompts:  87%| | 111/128 [00:16<00:02,  6.36it/s, est. speed input: 3524.30 toks/s, output: 6.88 toks/s]
Processed prompts:  88%| | 112/128 [00:16<00:02,  6.28it/s, est. speed input: 3520.33 toks/s, output: 6.88 toks/s]
Processed prompts:  88%| | 113/128 [00:16<00:02,  6.29it/s, est. speed input: 3517.55 toks/s, output: 6.87 toks/s]
Processed prompts:  89%| | 114/128 [00:16<00:02,  6.34it/s, est. speed input: 3515.64 toks/s, output: 6.87 toks/s]
Processed prompts:  90%| | 115/128 [00:16<00:02,  6.34it/s, est. speed input: 3512.99 toks/s, output: 6.86 toks/s]
Processed prompts:  91%| | 116/128 [00:16<00:01,  6.33it/s, est. speed input: 3510.34 toks/s, output: 6.86 toks/s]
Processed prompts:  91%|| 117/128 [00:17<00:01,  6.35it/s, est. speed input: 3508.14 toks/s, output: 6.85 toks/s]
Processed prompts:  92%|| 118/128 [00:17<00:01,  6.34it/s, est. speed input: 3505.70 toks/s, output: 6.85 toks/s]
Processed prompts:  93%|| 119/128 [00:17<00:01,  6.27it/s, est. speed input: 3502.06 toks/s, output: 6.84 toks/s]
Processed prompts:  94%|| 120/128 [00:17<00:01,  6.29it/s, est. speed input: 3499.87 toks/s, output: 6.84 toks/s]
Processed prompts:  95%|| 121/128 [00:17<00:01,  6.33it/s, est. speed input: 3497.91 toks/s, output: 6.83 toks/s]
Processed prompts:  95%|| 122/128 [00:17<00:00,  6.31it/s, est. speed input: 3495.35 toks/s, output: 6.83 toks/s]
Processed prompts:  96%|| 123/128 [00:18<00:00,  6.33it/s, est. speed input: 3493.34 toks/s, output: 6.82 toks/s]
Processed prompts:  97%|| 124/128 [00:18<00:00,  6.36it/s, est. speed input: 3491.67 toks/s, output: 6.82 toks/s]
Processed prompts:  98%|| 125/128 [00:18<00:00,  6.36it/s, est. speed input: 3489.57 toks/s, output: 6.82 toks/s]
Processed prompts:  98%|| 126/128 [00:18<00:00,  6.28it/s, est. speed input: 3486.36 toks/s, output: 6.81 toks/s]
Processed prompts:  99%|| 127/128 [00:18<00:00,  6.31it/s, est. speed input: 3484.54 toks/s, output: 6.81 toks/s]
Processed prompts: 100%|| 128/128 [00:18<00:00,  6.30it/s, est. speed input: 3482.28 toks/s, output: 6.80 toks/s]
Processed prompts: 100%|| 128/128 [00:18<00:00,  6.30it/s, est. speed input: 3482.28 toks/s, output: 6.80 toks/s]
Processed prompts: 100%|| 128/128 [00:18<00:00,  6.80it/s, est. speed input: 3482.28 toks/s, output: 6.80 toks/s]
[rank0]:[W127 13:26:43.979520523 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-27 13:26:59
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Qwen2.5-14B-FP8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-27 13:27:07 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-27 13:27:07 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=2659327) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2659327) WARNING 01-27 13:29:27 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 3.05 requests/s, 3121.94 total tokens/s, 3.05 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-27 13:27:07] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 13:27:07] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 13:27:07] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 13:27:07] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:27:07] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:27:07] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:27:07] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:27:07] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:27:07] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 13:27:07] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 13:27:07] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 13:27:07] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 13:27:07] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 13:27:07] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-27 13:27:10] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 13:27:10] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 13:27:10] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 13:27:10] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:27:10] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:27:10] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:27:10] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:27:10] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:27:10] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 13:27:10] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 13:27:10] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 13:27:10] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 13:27:10] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 13:27:10] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=2659327) [2026-01-27 13:27:11] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=2659327) [2026-01-27 13:27:11] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2659327) [2026-01-27 13:27:11] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=2659327) [2026-01-27 13:27:11] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=2659327) [2026-01-27 13:27:11] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=2659327) [2026-01-27 13:27:11] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=2659327) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=2659327) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:25,  8.54s/it]
(EngineCore_DP0 pid=2659327) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:41<00:45, 22.81s/it]
(EngineCore_DP0 pid=2659327) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [01:17<00:29, 29.06s/it]
(EngineCore_DP0 pid=2659327) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:58<00:00, 33.81s/it]
(EngineCore_DP0 pid=2659327) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:58<00:00, 29.73s/it]
(EngineCore_DP0 pid=2659327) 
(EngineCore_DP0 pid=2659327) [2026-01-27 13:29:12] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 8192] -> 1D uint8
(EngineCore_DP0 pid=2659327) [2026-01-27 13:29:12] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 36700160 bytes
(EngineCore_DP0 pid=2659327) [2026-01-27 13:29:12] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 8192] -> 1D uint8
(EngineCore_DP0 pid=2659327) [2026-01-27 13:29:12] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 26214400 bytes
(EngineCore_DP0 pid=2659327) [2026-01-27 13:29:12] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 8192] -> 1D uint8
(EngineCore_DP0 pid=2659327) [2026-01-27 13:29:12] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 141557760 bytes
(EngineCore_DP0 pid=2659327) [2026-01-27 13:29:12] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 22144] -> 1D uint8
(EngineCore_DP0 pid=2659327) [2026-01-27 13:29:12] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 70860800 bytes
(EngineCore_DP0 pid=2659327) 2026-01-27 13:29:21,747 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=2659327) 2026-01-27 13:29:21,992 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:   1%|          | 1/128 [00:00<01:42,  1.24it/s]
Adding requests:   2%|         | 2/128 [00:01<00:58,  2.17it/s]
Adding requests:   3%|         | 4/128 [00:01<00:27,  4.49it/s]
Adding requests:   5%|         | 7/128 [00:01<00:14,  8.34it/s]
Adding requests:   9%|         | 12/128 [00:01<00:07, 15.15it/s]
Adding requests:  18%|        | 23/128 [00:01<00:03, 34.08it/s]
Adding requests:  36%|      | 46/128 [00:01<00:01, 77.34it/s]
Adding requests:  55%|    | 70/128 [00:01<00:00, 115.00it/s]
Adding requests:  80%|  | 102/128 [00:01<00:00, 166.48it/s]
Adding requests: 100%|| 128/128 [00:01<00:00, 65.93it/s] 

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 3/128 [00:00<00:08, 14.42it/s, est. speed input: 14772.11 toks/s, output: 14.42 toks/s]
Processed prompts:   4%|         | 5/128 [00:00<00:23,  5.29it/s, est. speed input: 6109.28 toks/s, output: 5.97 toks/s]  
Processed prompts:   5%|         | 6/128 [00:01<00:26,  4.52it/s, est. speed input: 5336.83 toks/s, output: 5.21 toks/s]
Processed prompts:   5%|         | 7/128 [00:01<00:29,  4.06it/s, est. speed input: 4893.56 toks/s, output: 4.78 toks/s]
Processed prompts:   6%|         | 8/128 [00:01<00:32,  3.74it/s, est. speed input: 4584.61 toks/s, output: 4.48 toks/s]
Processed prompts:   7%|         | 9/128 [00:02<00:33,  3.57it/s, est. speed input: 4391.93 toks/s, output: 4.29 toks/s]
Processed prompts:   8%|         | 10/128 [00:02<00:34,  3.45it/s, est. speed input: 4245.47 toks/s, output: 4.15 toks/s]
Processed prompts:   9%|         | 11/128 [00:02<00:34,  3.36it/s, est. speed input: 4127.49 toks/s, output: 4.03 toks/s]
Processed prompts:   9%|         | 12/128 [00:03<00:35,  3.31it/s, est. speed input: 4041.25 toks/s, output: 3.95 toks/s]
Processed prompts:  10%|         | 13/128 [00:03<00:35,  3.27it/s, est. speed input: 3964.76 toks/s, output: 3.87 toks/s]
Processed prompts:  11%|         | 14/128 [00:03<00:35,  3.24it/s, est. speed input: 3905.08 toks/s, output: 3.81 toks/s]
Processed prompts:  12%|        | 15/128 [00:03<00:35,  3.20it/s, est. speed input: 3847.65 toks/s, output: 3.76 toks/s]
Processed prompts:  12%|        | 16/128 [00:04<00:35,  3.20it/s, est. speed input: 3804.48 toks/s, output: 3.72 toks/s]
Processed prompts:  13%|        | 17/128 [00:04<00:34,  3.19it/s, est. speed input: 3766.84 toks/s, output: 3.68 toks/s]
Processed prompts:  14%|        | 18/128 [00:04<00:34,  3.17it/s, est. speed input: 3730.02 toks/s, output: 3.64 toks/s]
Processed prompts:  15%|        | 19/128 [00:05<00:34,  3.18it/s, est. speed input: 3702.24 toks/s, output: 3.62 toks/s]
Processed prompts:  16%|        | 20/128 [00:05<00:34,  3.18it/s, est. speed input: 3676.71 toks/s, output: 3.59 toks/s]
Processed prompts:  16%|        | 21/128 [00:05<00:33,  3.16it/s, est. speed input: 3650.72 toks/s, output: 3.57 toks/s]
Processed prompts:  17%|        | 22/128 [00:06<00:33,  3.16it/s, est. speed input: 3629.45 toks/s, output: 3.54 toks/s]
Processed prompts:  18%|        | 23/128 [00:06<00:33,  3.16it/s, est. speed input: 3610.51 toks/s, output: 3.53 toks/s]
Processed prompts:  19%|        | 24/128 [00:06<00:32,  3.17it/s, est. speed input: 3594.23 toks/s, output: 3.51 toks/s]
Processed prompts:  20%|        | 25/128 [00:07<00:32,  3.16it/s, est. speed input: 3577.04 toks/s, output: 3.49 toks/s]
Processed prompts:  20%|        | 26/128 [00:07<00:32,  3.16it/s, est. speed input: 3562.96 toks/s, output: 3.48 toks/s]
Processed prompts:  21%|        | 27/128 [00:07<00:31,  3.16it/s, est. speed input: 3549.97 toks/s, output: 3.47 toks/s]
Processed prompts:  22%|       | 28/128 [00:08<00:31,  3.15it/s, est. speed input: 3536.26 toks/s, output: 3.45 toks/s]
Processed prompts:  23%|       | 29/128 [00:08<00:31,  3.16it/s, est. speed input: 3525.47 toks/s, output: 3.44 toks/s]
Processed prompts:  23%|       | 30/128 [00:08<00:30,  3.17it/s, est. speed input: 3517.00 toks/s, output: 3.43 toks/s]
Processed prompts:  24%|       | 31/128 [00:09<00:30,  3.16it/s, est. speed input: 3505.52 toks/s, output: 3.42 toks/s]
Processed prompts:  25%|       | 32/128 [00:09<00:30,  3.16it/s, est. speed input: 3496.51 toks/s, output: 3.41 toks/s]
Processed prompts:  26%|       | 33/128 [00:09<00:29,  3.17it/s, est. speed input: 3489.22 toks/s, output: 3.41 toks/s]
Processed prompts:  27%|       | 34/128 [00:10<00:29,  3.17it/s, est. speed input: 3481.36 toks/s, output: 3.40 toks/s]
Processed prompts:  27%|       | 35/128 [00:10<00:29,  3.15it/s, est. speed input: 3471.57 toks/s, output: 3.39 toks/s]
Processed prompts:  28%|       | 36/128 [00:10<00:29,  3.15it/s, est. speed input: 3464.73 toks/s, output: 3.38 toks/s]
Processed prompts:  29%|       | 37/128 [00:10<00:28,  3.15it/s, est. speed input: 3458.17 toks/s, output: 3.38 toks/s]
Processed prompts:  30%|       | 38/128 [00:11<00:28,  3.14it/s, est. speed input: 3449.78 toks/s, output: 3.37 toks/s]
Processed prompts:  30%|       | 39/128 [00:11<00:28,  3.14it/s, est. speed input: 3444.04 toks/s, output: 3.36 toks/s]
Processed prompts:  31%|      | 40/128 [00:11<00:27,  3.15it/s, est. speed input: 3438.94 toks/s, output: 3.36 toks/s]
Processed prompts:  32%|      | 41/128 [00:12<00:27,  3.14it/s, est. speed input: 3432.24 toks/s, output: 3.35 toks/s]
Processed prompts:  33%|      | 42/128 [00:12<00:27,  3.15it/s, est. speed input: 3427.29 toks/s, output: 3.35 toks/s]
Processed prompts:  34%|      | 43/128 [00:12<00:26,  3.15it/s, est. speed input: 3422.61 toks/s, output: 3.34 toks/s]
Processed prompts:  34%|      | 44/128 [00:13<00:26,  3.16it/s, est. speed input: 3418.48 toks/s, output: 3.34 toks/s]
Processed prompts:  35%|      | 45/128 [00:13<00:26,  3.15it/s, est. speed input: 3413.39 toks/s, output: 3.33 toks/s]
Processed prompts:  36%|      | 46/128 [00:13<00:26,  3.15it/s, est. speed input: 3409.09 toks/s, output: 3.33 toks/s]
Processed prompts:  37%|      | 47/128 [00:14<00:25,  3.16it/s, est. speed input: 3406.17 toks/s, output: 3.33 toks/s]
Processed prompts:  38%|      | 48/128 [00:14<00:25,  3.15it/s, est. speed input: 3401.30 toks/s, output: 3.32 toks/s]
Processed prompts:  38%|      | 49/128 [00:14<00:25,  3.15it/s, est. speed input: 3397.71 toks/s, output: 3.32 toks/s]
Processed prompts:  39%|      | 50/128 [00:15<00:24,  3.16it/s, est. speed input: 3394.48 toks/s, output: 3.31 toks/s]
Processed prompts:  40%|      | 51/128 [00:15<00:24,  3.14it/s, est. speed input: 3389.92 toks/s, output: 3.31 toks/s]
Processed prompts:  41%|      | 52/128 [00:15<00:24,  3.15it/s, est. speed input: 3387.17 toks/s, output: 3.31 toks/s]
Processed prompts:  41%|     | 53/128 [00:16<00:23,  3.15it/s, est. speed input: 3383.90 toks/s, output: 3.30 toks/s]
Processed prompts:  42%|     | 54/128 [00:16<00:23,  3.15it/s, est. speed input: 3380.93 toks/s, output: 3.30 toks/s]
Processed prompts:  43%|     | 55/128 [00:16<00:23,  3.14it/s, est. speed input: 3377.12 toks/s, output: 3.30 toks/s]
Processed prompts:  44%|     | 56/128 [00:16<00:22,  3.14it/s, est. speed input: 3374.50 toks/s, output: 3.30 toks/s]
Processed prompts:  45%|     | 57/128 [00:17<00:22,  3.14it/s, est. speed input: 3371.56 toks/s, output: 3.29 toks/s]
Processed prompts:  45%|     | 58/128 [00:17<00:22,  3.13it/s, est. speed input: 3368.02 toks/s, output: 3.29 toks/s]
Processed prompts:  46%|     | 59/128 [00:17<00:22,  3.14it/s, est. speed input: 3365.45 toks/s, output: 3.29 toks/s]
Processed prompts:  47%|     | 60/128 [00:18<00:21,  3.14it/s, est. speed input: 3363.21 toks/s, output: 3.28 toks/s]
Processed prompts:  48%|     | 61/128 [00:18<00:21,  3.13it/s, est. speed input: 3360.18 toks/s, output: 3.28 toks/s]
Processed prompts:  48%|     | 62/128 [00:18<00:21,  3.14it/s, est. speed input: 3358.07 toks/s, output: 3.28 toks/s]
Processed prompts:  49%|     | 63/128 [00:19<00:20,  3.14it/s, est. speed input: 3355.80 toks/s, output: 3.28 toks/s]
Processed prompts:  50%|     | 64/128 [00:19<00:20,  3.15it/s, est. speed input: 3353.77 toks/s, output: 3.28 toks/s]
Processed prompts:  51%|     | 65/128 [00:19<00:20,  3.13it/s, est. speed input: 3350.74 toks/s, output: 3.27 toks/s]
Processed prompts:  52%|    | 66/128 [00:20<00:19,  3.14it/s, est. speed input: 3348.82 toks/s, output: 3.27 toks/s]
Processed prompts:  52%|    | 67/128 [00:20<00:19,  3.14it/s, est. speed input: 3346.62 toks/s, output: 3.27 toks/s]
Processed prompts:  53%|    | 68/128 [00:20<00:19,  3.13it/s, est. speed input: 3344.08 toks/s, output: 3.27 toks/s]
Processed prompts:  54%|    | 69/128 [00:21<00:18,  3.14it/s, est. speed input: 3342.63 toks/s, output: 3.26 toks/s]
Processed prompts:  55%|    | 70/128 [00:21<00:18,  3.15it/s, est. speed input: 3341.04 toks/s, output: 3.26 toks/s]
Processed prompts:  55%|    | 71/128 [00:21<00:18,  3.12it/s, est. speed input: 3337.92 toks/s, output: 3.26 toks/s]
Processed prompts:  56%|    | 72/128 [00:22<00:17,  3.14it/s, est. speed input: 3336.71 toks/s, output: 3.26 toks/s]
Processed prompts:  57%|    | 73/128 [00:22<00:17,  3.14it/s, est. speed input: 3335.07 toks/s, output: 3.26 toks/s]
Processed prompts:  58%|    | 74/128 [00:22<00:17,  3.14it/s, est. speed input: 3333.58 toks/s, output: 3.26 toks/s]
Processed prompts:  59%|    | 75/128 [00:23<00:16,  3.13it/s, est. speed input: 3331.29 toks/s, output: 3.25 toks/s]
Processed prompts:  59%|    | 76/128 [00:23<00:16,  3.13it/s, est. speed input: 3329.74 toks/s, output: 3.25 toks/s]
Processed prompts:  60%|    | 77/128 [00:23<00:16,  3.14it/s, est. speed input: 3328.36 toks/s, output: 3.25 toks/s]
Processed prompts:  61%|    | 78/128 [00:24<00:15,  3.13it/s, est. speed input: 3326.23 toks/s, output: 3.25 toks/s]
Processed prompts:  62%|   | 79/128 [00:24<00:15,  3.13it/s, est. speed input: 3324.88 toks/s, output: 3.25 toks/s]
Processed prompts:  62%|   | 80/128 [00:24<00:15,  3.13it/s, est. speed input: 3323.47 toks/s, output: 3.25 toks/s]
Processed prompts:  63%|   | 81/128 [00:24<00:15,  3.13it/s, est. speed input: 3321.71 toks/s, output: 3.24 toks/s]
Processed prompts:  64%|   | 82/128 [00:25<00:14,  3.13it/s, est. speed input: 3320.52 toks/s, output: 3.24 toks/s]
Processed prompts:  65%|   | 83/128 [00:25<00:14,  3.15it/s, est. speed input: 3319.82 toks/s, output: 3.24 toks/s]
Processed prompts:  66%|   | 84/128 [00:25<00:13,  3.15it/s, est. speed input: 3318.52 toks/s, output: 3.24 toks/s]
Processed prompts:  66%|   | 85/128 [00:26<00:13,  3.14it/s, est. speed input: 3317.03 toks/s, output: 3.24 toks/s]
Processed prompts:  67%|   | 86/128 [00:26<00:13,  3.14it/s, est. speed input: 3315.81 toks/s, output: 3.24 toks/s]
Processed prompts:  68%|   | 87/128 [00:26<00:13,  3.14it/s, est. speed input: 3314.59 toks/s, output: 3.24 toks/s]
Processed prompts:  69%|   | 88/128 [00:27<00:12,  3.13it/s, est. speed input: 3313.18 toks/s, output: 3.24 toks/s]
Processed prompts:  70%|   | 89/128 [00:27<00:12,  3.13it/s, est. speed input: 3311.92 toks/s, output: 3.23 toks/s]
Processed prompts:  70%|   | 90/128 [00:27<00:12,  3.14it/s, est. speed input: 3310.88 toks/s, output: 3.23 toks/s]
Processed prompts:  71%|   | 91/128 [00:28<00:11,  3.13it/s, est. speed input: 3309.32 toks/s, output: 3.23 toks/s]
Processed prompts:  72%|  | 92/128 [00:28<00:11,  3.13it/s, est. speed input: 3308.40 toks/s, output: 3.23 toks/s]
Processed prompts:  73%|  | 93/128 [00:28<00:11,  3.13it/s, est. speed input: 3307.35 toks/s, output: 3.23 toks/s]
Processed prompts:  73%|  | 94/128 [00:29<00:10,  3.13it/s, est. speed input: 3306.11 toks/s, output: 3.23 toks/s]
Processed prompts:  74%|  | 95/128 [00:29<00:10,  3.13it/s, est. speed input: 3305.08 toks/s, output: 3.23 toks/s]
Processed prompts:  75%|  | 96/128 [00:29<00:10,  3.14it/s, est. speed input: 3304.22 toks/s, output: 3.23 toks/s]
Processed prompts:  76%|  | 97/128 [00:30<00:09,  3.14it/s, est. speed input: 3303.30 toks/s, output: 3.23 toks/s]
Processed prompts:  77%|  | 98/128 [00:30<00:09,  3.12it/s, est. speed input: 3301.51 toks/s, output: 3.22 toks/s]
Processed prompts:  77%|  | 99/128 [00:30<00:09,  3.12it/s, est. speed input: 3300.68 toks/s, output: 3.22 toks/s]
Processed prompts:  78%|  | 100/128 [00:31<00:08,  3.13it/s, est. speed input: 3299.68 toks/s, output: 3.22 toks/s]
Processed prompts:  79%|  | 101/128 [00:31<00:08,  3.11it/s, est. speed input: 3297.95 toks/s, output: 3.22 toks/s]
Processed prompts:  80%|  | 102/128 [00:31<00:08,  3.12it/s, est. speed input: 3297.41 toks/s, output: 3.22 toks/s]
Processed prompts:  80%|  | 103/128 [00:31<00:07,  3.13it/s, est. speed input: 3296.71 toks/s, output: 3.22 toks/s]
Processed prompts:  81%| | 104/128 [00:32<00:07,  3.12it/s, est. speed input: 3295.55 toks/s, output: 3.22 toks/s]
Processed prompts:  82%| | 105/128 [00:32<00:07,  3.13it/s, est. speed input: 3294.75 toks/s, output: 3.22 toks/s]
Processed prompts:  83%| | 106/128 [00:32<00:07,  3.12it/s, est. speed input: 3293.68 toks/s, output: 3.22 toks/s]
Processed prompts:  84%| | 107/128 [00:33<00:06,  3.12it/s, est. speed input: 3292.77 toks/s, output: 3.22 toks/s]
Processed prompts:  84%| | 108/128 [00:33<00:06,  3.12it/s, est. speed input: 3291.80 toks/s, output: 3.21 toks/s]
Processed prompts:  85%| | 109/128 [00:33<00:06,  3.13it/s, est. speed input: 3291.08 toks/s, output: 3.21 toks/s]
Processed prompts:  86%| | 110/128 [00:34<00:05,  3.13it/s, est. speed input: 3290.27 toks/s, output: 3.21 toks/s]
Processed prompts:  87%| | 111/128 [00:34<00:05,  3.12it/s, est. speed input: 3289.15 toks/s, output: 3.21 toks/s]
Processed prompts:  88%| | 112/128 [00:34<00:05,  3.12it/s, est. speed input: 3288.45 toks/s, output: 3.21 toks/s]
Processed prompts:  88%| | 113/128 [00:35<00:04,  3.13it/s, est. speed input: 3287.70 toks/s, output: 3.21 toks/s]
Processed prompts:  89%| | 114/128 [00:35<00:04,  3.12it/s, est. speed input: 3286.60 toks/s, output: 3.21 toks/s]
Processed prompts:  90%| | 115/128 [00:35<00:04,  3.13it/s, est. speed input: 3286.04 toks/s, output: 3.21 toks/s]
Processed prompts:  91%| | 116/128 [00:36<00:03,  3.13it/s, est. speed input: 3285.51 toks/s, output: 3.21 toks/s]
Processed prompts:  91%|| 117/128 [00:36<00:03,  3.13it/s, est. speed input: 3284.70 toks/s, output: 3.21 toks/s]
Processed prompts:  92%|| 118/128 [00:36<00:03,  3.12it/s, est. speed input: 3283.60 toks/s, output: 3.21 toks/s]
Processed prompts:  93%|| 119/128 [00:37<00:02,  3.12it/s, est. speed input: 3282.92 toks/s, output: 3.21 toks/s]
Processed prompts:  94%|| 120/128 [00:37<00:02,  3.12it/s, est. speed input: 3282.31 toks/s, output: 3.21 toks/s]
Processed prompts:  95%|| 121/128 [00:37<00:02,  3.11it/s, est. speed input: 3281.05 toks/s, output: 3.20 toks/s]
Processed prompts:  95%|| 122/128 [00:38<00:01,  3.12it/s, est. speed input: 3280.57 toks/s, output: 3.20 toks/s]
Processed prompts:  96%|| 123/128 [00:38<00:01,  3.12it/s, est. speed input: 3279.85 toks/s, output: 3.20 toks/s]
Processed prompts:  97%|| 124/128 [00:38<00:01,  3.10it/s, est. speed input: 3278.65 toks/s, output: 3.20 toks/s]
Processed prompts:  98%|| 125/128 [00:39<00:00,  3.11it/s, est. speed input: 3278.13 toks/s, output: 3.20 toks/s]
Processed prompts:  98%|| 126/128 [00:39<00:00,  3.12it/s, est. speed input: 3277.60 toks/s, output: 3.20 toks/s]
Processed prompts:  99%|| 127/128 [00:39<00:00,  3.12it/s, est. speed input: 3276.80 toks/s, output: 3.20 toks/s]
Processed prompts: 100%|| 128/128 [00:40<00:00,  3.11it/s, est. speed input: 3276.08 toks/s, output: 3.20 toks/s]
Processed prompts: 100%|| 128/128 [00:40<00:00,  3.11it/s, est. speed input: 3276.08 toks/s, output: 3.20 toks/s]
Processed prompts: 100%|| 128/128 [00:40<00:00,  3.20it/s, est. speed input: 3276.08 toks/s, output: 3.20 toks/s]
[rank0]:[W127 13:30:10.472448876 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-27 13:30:24
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Qwen2.5-14B-FP8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-27 13:30:32 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-27 13:30:33 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=2662396) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2662396) WARNING 01-27 13:32:59 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 2.99 requests/s, 3068.69 total tokens/s, 2.99 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-27 13:30:32] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 13:30:32] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 13:30:32] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 13:30:32] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:30:32] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:30:32] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:30:32] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:30:32] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:30:32] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 13:30:32] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 13:30:32] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 13:30:32] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 13:30:32] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 13:30:32] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-27 13:30:36] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 13:30:36] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 13:30:36] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 13:30:36] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:30:36] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:30:36] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:30:36] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:30:36] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:30:36] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 13:30:36] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 13:30:36] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 13:30:36] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 13:30:36] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 13:30:36] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=2662396) [2026-01-27 13:30:37] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=2662396) [2026-01-27 13:30:37] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2662396) [2026-01-27 13:30:37] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=2662396) [2026-01-27 13:30:37] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=2662396) [2026-01-27 13:30:37] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=2662396) [2026-01-27 13:30:37] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=2662396) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=2662396) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:26,  8.73s/it]
(EngineCore_DP0 pid=2662396) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:41<00:45, 22.94s/it]
(EngineCore_DP0 pid=2662396) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [01:17<00:28, 28.99s/it]
(EngineCore_DP0 pid=2662396) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:59<00:00, 33.90s/it]
(EngineCore_DP0 pid=2662396) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:59<00:00, 29.81s/it]
(EngineCore_DP0 pid=2662396) 
(EngineCore_DP0 pid=2662396) [2026-01-27 13:32:38] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 8192] -> 1D uint8
(EngineCore_DP0 pid=2662396) [2026-01-27 13:32:38] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 36700160 bytes
(EngineCore_DP0 pid=2662396) [2026-01-27 13:32:38] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 8192] -> 1D uint8
(EngineCore_DP0 pid=2662396) [2026-01-27 13:32:38] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 26214400 bytes
(EngineCore_DP0 pid=2662396) [2026-01-27 13:32:38] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 8192] -> 1D uint8
(EngineCore_DP0 pid=2662396) [2026-01-27 13:32:38] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 141557760 bytes
(EngineCore_DP0 pid=2662396) [2026-01-27 13:32:38] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 22144] -> 1D uint8
(EngineCore_DP0 pid=2662396) [2026-01-27 13:32:38] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 70860800 bytes
(EngineCore_DP0 pid=2662396) 2026-01-27 13:32:49,254 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=2662396) 2026-01-27 13:32:49,741 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:   0%|          | 1/256 [00:01<05:39,  1.33s/it]
Adding requests:   1%|          | 2/256 [00:01<03:09,  1.34it/s]
Adding requests:   1%|          | 3/256 [00:01<02:03,  2.05it/s]
Adding requests:   2%|         | 4/256 [00:01<01:25,  2.93it/s]
Adding requests:   2%|         | 5/256 [00:02<01:04,  3.91it/s]
Adding requests:   3%|         | 7/256 [00:02<00:39,  6.23it/s]
Adding requests:   4%|         | 9/256 [00:02<00:28,  8.69it/s]
Adding requests:   5%|         | 12/256 [00:02<00:19, 12.50it/s]
Adding requests:   6%|         | 16/256 [00:02<00:13, 18.10it/s]
Adding requests:  11%|        | 29/256 [00:02<00:05, 44.08it/s]
Adding requests:  20%|        | 52/256 [00:02<00:02, 89.22it/s]
Adding requests:  30%|       | 76/256 [00:02<00:01, 127.91it/s]
Adding requests:  41%|      | 105/256 [00:02<00:00, 171.55it/s]
Adding requests:  53%|    | 135/256 [00:03<00:00, 207.16it/s]
Adding requests:  65%|   | 167/256 [00:03<00:00, 239.15it/s]
Adding requests:  80%|  | 204/256 [00:03<00:00, 180.62it/s]
Adding requests:  91%|| 234/256 [00:03<00:00, 204.12it/s]
Adding requests: 100%|| 256/256 [00:03<00:00, 70.97it/s] 

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   3%|         | 7/256 [00:00<00:16, 15.48it/s, est. speed input: 15848.35 toks/s, output: 15.48 toks/s]
Processed prompts:   4%|         | 9/256 [00:01<00:34,  7.13it/s, est. speed input: 8349.04 toks/s, output: 8.15 toks/s]  
Processed prompts:   4%|         | 11/256 [00:01<00:47,  5.16it/s, est. speed input: 6439.84 toks/s, output: 6.29 toks/s]
Processed prompts:   5%|         | 13/256 [00:02<00:56,  4.30it/s, est. speed input: 5548.11 toks/s, output: 5.42 toks/s]
Processed prompts:   6%|         | 15/256 [00:03<01:02,  3.85it/s, est. speed input: 5041.00 toks/s, output: 4.92 toks/s]
Processed prompts:   7%|         | 17/256 [00:03<01:06,  3.58it/s, est. speed input: 4707.60 toks/s, output: 4.60 toks/s]
Processed prompts:   7%|         | 19/256 [00:04<01:09,  3.41it/s, est. speed input: 4472.65 toks/s, output: 4.37 toks/s]
Processed prompts:   8%|         | 21/256 [00:04<01:10,  3.31it/s, est. speed input: 4304.75 toks/s, output: 4.20 toks/s]
Processed prompts:   9%|         | 23/256 [00:05<01:12,  3.23it/s, est. speed input: 4169.21 toks/s, output: 4.07 toks/s]
Processed prompts:  10%|         | 25/256 [00:06<01:12,  3.18it/s, est. speed input: 4064.27 toks/s, output: 3.97 toks/s]
Processed prompts:  11%|         | 27/256 [00:06<01:12,  3.15it/s, est. speed input: 3978.11 toks/s, output: 3.88 toks/s]
Processed prompts:  11%|        | 29/256 [00:07<01:12,  3.12it/s, est. speed input: 3903.39 toks/s, output: 3.81 toks/s]
Processed prompts:  12%|        | 31/256 [00:08<01:12,  3.10it/s, est. speed input: 3843.59 toks/s, output: 3.75 toks/s]
Processed prompts:  13%|        | 33/256 [00:08<01:12,  3.09it/s, est. speed input: 3790.58 toks/s, output: 3.70 toks/s]
Processed prompts:  14%|        | 35/256 [00:09<01:11,  3.08it/s, est. speed input: 3745.29 toks/s, output: 3.66 toks/s]
Processed prompts:  14%|        | 37/256 [00:10<01:11,  3.08it/s, est. speed input: 3707.43 toks/s, output: 3.62 toks/s]
Processed prompts:  15%|        | 39/256 [00:10<01:10,  3.07it/s, est. speed input: 3672.34 toks/s, output: 3.59 toks/s]
Processed prompts:  16%|        | 41/256 [00:11<01:09,  3.07it/s, est. speed input: 3643.66 toks/s, output: 3.56 toks/s]
Processed prompts:  17%|        | 43/256 [00:12<01:09,  3.07it/s, est. speed input: 3615.58 toks/s, output: 3.53 toks/s]
Processed prompts:  18%|        | 45/256 [00:12<01:08,  3.06it/s, est. speed input: 3589.89 toks/s, output: 3.51 toks/s]
Processed prompts:  18%|        | 47/256 [00:13<01:08,  3.06it/s, est. speed input: 3568.38 toks/s, output: 3.48 toks/s]
Processed prompts:  19%|        | 49/256 [00:14<01:07,  3.06it/s, est. speed input: 3547.74 toks/s, output: 3.46 toks/s]
Processed prompts:  20%|        | 51/256 [00:14<01:07,  3.06it/s, est. speed input: 3529.41 toks/s, output: 3.45 toks/s]
Processed prompts:  21%|        | 53/256 [00:15<01:06,  3.06it/s, est. speed input: 3512.40 toks/s, output: 3.43 toks/s]
Processed prompts:  21%|       | 55/256 [00:16<01:05,  3.06it/s, est. speed input: 3497.31 toks/s, output: 3.42 toks/s]
Processed prompts:  22%|       | 57/256 [00:16<01:04,  3.07it/s, est. speed input: 3484.05 toks/s, output: 3.40 toks/s]
Processed prompts:  23%|       | 59/256 [00:17<01:04,  3.06it/s, est. speed input: 3470.26 toks/s, output: 3.39 toks/s]
Processed prompts:  24%|       | 61/256 [00:18<01:03,  3.05it/s, est. speed input: 3457.34 toks/s, output: 3.38 toks/s]
Processed prompts:  25%|       | 63/256 [00:18<01:03,  3.05it/s, est. speed input: 3445.76 toks/s, output: 3.36 toks/s]
Processed prompts:  25%|       | 65/256 [00:19<01:02,  3.05it/s, est. speed input: 3434.36 toks/s, output: 3.35 toks/s]
Processed prompts:  26%|       | 67/256 [00:20<01:01,  3.06it/s, est. speed input: 3424.87 toks/s, output: 3.34 toks/s]
Processed prompts:  27%|       | 69/256 [00:20<01:01,  3.05it/s, est. speed input: 3414.31 toks/s, output: 3.33 toks/s]
Processed prompts:  28%|       | 71/256 [00:21<01:00,  3.04it/s, est. speed input: 3404.65 toks/s, output: 3.32 toks/s]
Processed prompts:  29%|       | 73/256 [00:22<01:00,  3.04it/s, est. speed input: 3396.34 toks/s, output: 3.32 toks/s]
Processed prompts:  29%|       | 75/256 [00:22<00:59,  3.04it/s, est. speed input: 3388.10 toks/s, output: 3.31 toks/s]
Processed prompts:  30%|       | 77/256 [00:23<00:58,  3.05it/s, est. speed input: 3381.56 toks/s, output: 3.30 toks/s]
Processed prompts:  31%|       | 79/256 [00:23<00:58,  3.04it/s, est. speed input: 3373.62 toks/s, output: 3.29 toks/s]
Processed prompts:  32%|      | 81/256 [00:24<00:57,  3.05it/s, est. speed input: 3366.99 toks/s, output: 3.29 toks/s]
Processed prompts:  32%|      | 83/256 [00:25<00:56,  3.05it/s, est. speed input: 3361.29 toks/s, output: 3.28 toks/s]
Processed prompts:  33%|      | 85/256 [00:25<00:56,  3.04it/s, est. speed input: 3354.53 toks/s, output: 3.28 toks/s]
Processed prompts:  34%|      | 87/256 [00:26<00:55,  3.04it/s, est. speed input: 3348.48 toks/s, output: 3.27 toks/s]
Processed prompts:  35%|      | 89/256 [00:27<00:54,  3.05it/s, est. speed input: 3343.47 toks/s, output: 3.27 toks/s]
Processed prompts:  36%|      | 91/256 [00:27<00:54,  3.05it/s, est. speed input: 3337.91 toks/s, output: 3.26 toks/s]
Processed prompts:  36%|      | 93/256 [00:28<00:53,  3.05it/s, est. speed input: 3332.98 toks/s, output: 3.25 toks/s]
Processed prompts:  37%|      | 95/256 [00:29<00:52,  3.04it/s, est. speed input: 3327.98 toks/s, output: 3.25 toks/s]
Processed prompts:  38%|      | 97/256 [00:29<00:52,  3.03it/s, est. speed input: 3322.61 toks/s, output: 3.24 toks/s]
Processed prompts:  39%|      | 99/256 [00:30<00:51,  3.04it/s, est. speed input: 3318.72 toks/s, output: 3.24 toks/s]
Processed prompts:  39%|      | 101/256 [00:31<00:50,  3.04it/s, est. speed input: 3314.13 toks/s, output: 3.24 toks/s]
Processed prompts:  40%|      | 103/256 [00:31<00:50,  3.04it/s, est. speed input: 3309.86 toks/s, output: 3.23 toks/s]
Processed prompts:  41%|      | 105/256 [00:32<00:49,  3.05it/s, est. speed input: 3306.69 toks/s, output: 3.23 toks/s]
Processed prompts:  42%|     | 107/256 [00:33<00:48,  3.05it/s, est. speed input: 3302.76 toks/s, output: 3.23 toks/s]
Processed prompts:  43%|     | 109/256 [00:33<00:48,  3.05it/s, est. speed input: 3299.46 toks/s, output: 3.22 toks/s]
Processed prompts:  43%|     | 111/256 [00:34<00:47,  3.04it/s, est. speed input: 3295.58 toks/s, output: 3.22 toks/s]
Processed prompts:  44%|     | 113/256 [00:35<00:47,  3.04it/s, est. speed input: 3291.81 toks/s, output: 3.21 toks/s]
Processed prompts:  45%|     | 115/256 [00:35<00:46,  3.04it/s, est. speed input: 3288.55 toks/s, output: 3.21 toks/s]
Processed prompts:  46%|     | 117/256 [00:36<00:45,  3.04it/s, est. speed input: 3285.41 toks/s, output: 3.21 toks/s]
Processed prompts:  46%|     | 119/256 [00:37<00:45,  3.04it/s, est. speed input: 3282.56 toks/s, output: 3.21 toks/s]
Processed prompts:  47%|     | 121/256 [00:37<00:44,  3.03it/s, est. speed input: 3279.14 toks/s, output: 3.20 toks/s]
Processed prompts:  48%|     | 123/256 [00:38<00:43,  3.03it/s, est. speed input: 3275.99 toks/s, output: 3.20 toks/s]
Processed prompts:  49%|     | 125/256 [00:39<00:43,  3.03it/s, est. speed input: 3273.30 toks/s, output: 3.20 toks/s]
Processed prompts:  50%|     | 127/256 [00:39<00:42,  3.04it/s, est. speed input: 3270.61 toks/s, output: 3.19 toks/s]
Processed prompts:  50%|     | 129/256 [00:40<00:41,  3.03it/s, est. speed input: 3267.64 toks/s, output: 3.19 toks/s]
Processed prompts:  51%|     | 131/256 [00:41<00:41,  3.04it/s, est. speed input: 3265.43 toks/s, output: 3.19 toks/s]
Processed prompts:  52%|    | 133/256 [00:41<00:40,  3.04it/s, est. speed input: 3262.89 toks/s, output: 3.19 toks/s]
Processed prompts:  53%|    | 135/256 [00:42<00:39,  3.04it/s, est. speed input: 3260.47 toks/s, output: 3.18 toks/s]
Processed prompts:  54%|    | 137/256 [00:43<00:39,  3.03it/s, est. speed input: 3258.04 toks/s, output: 3.18 toks/s]
Processed prompts:  54%|    | 139/256 [00:43<00:38,  3.03it/s, est. speed input: 3255.58 toks/s, output: 3.18 toks/s]
Processed prompts:  55%|    | 141/256 [00:44<00:37,  3.03it/s, est. speed input: 3253.39 toks/s, output: 3.18 toks/s]
Processed prompts:  56%|    | 143/256 [00:45<00:37,  3.03it/s, est. speed input: 3251.16 toks/s, output: 3.17 toks/s]
Processed prompts:  57%|    | 145/256 [00:45<00:36,  3.03it/s, est. speed input: 3248.85 toks/s, output: 3.17 toks/s]
Processed prompts:  57%|    | 147/256 [00:46<00:35,  3.03it/s, est. speed input: 3246.90 toks/s, output: 3.17 toks/s]
Processed prompts:  58%|    | 149/256 [00:47<00:35,  3.03it/s, est. speed input: 3244.94 toks/s, output: 3.17 toks/s]
Processed prompts:  59%|    | 151/256 [00:47<00:34,  3.03it/s, est. speed input: 3243.08 toks/s, output: 3.17 toks/s]
Processed prompts:  60%|    | 153/256 [00:48<00:33,  3.03it/s, est. speed input: 3241.02 toks/s, output: 3.17 toks/s]
Processed prompts:  61%|    | 155/256 [00:49<00:33,  3.03it/s, est. speed input: 3239.09 toks/s, output: 3.16 toks/s]
Processed prompts:  61%|   | 157/256 [00:49<00:32,  3.04it/s, est. speed input: 3237.75 toks/s, output: 3.16 toks/s]
Processed prompts:  62%|   | 159/256 [00:50<00:31,  3.03it/s, est. speed input: 3235.79 toks/s, output: 3.16 toks/s]
Processed prompts:  63%|   | 161/256 [00:50<00:31,  3.03it/s, est. speed input: 3234.01 toks/s, output: 3.16 toks/s]
Processed prompts:  64%|   | 163/256 [00:51<00:30,  3.04it/s, est. speed input: 3232.61 toks/s, output: 3.16 toks/s]
Processed prompts:  64%|   | 165/256 [00:52<00:30,  3.03it/s, est. speed input: 3230.71 toks/s, output: 3.15 toks/s]
Processed prompts:  65%|   | 167/256 [00:52<00:29,  3.04it/s, est. speed input: 3229.50 toks/s, output: 3.15 toks/s]
Processed prompts:  66%|   | 169/256 [00:53<00:28,  3.04it/s, est. speed input: 3227.94 toks/s, output: 3.15 toks/s]
Processed prompts:  67%|   | 171/256 [00:54<00:28,  3.03it/s, est. speed input: 3226.39 toks/s, output: 3.15 toks/s]
Processed prompts:  68%|   | 173/256 [00:54<00:27,  3.04it/s, est. speed input: 3225.14 toks/s, output: 3.15 toks/s]
Processed prompts:  68%|   | 175/256 [00:55<00:26,  3.03it/s, est. speed input: 3223.45 toks/s, output: 3.15 toks/s]
Processed prompts:  69%|   | 177/256 [00:56<00:26,  3.03it/s, est. speed input: 3221.83 toks/s, output: 3.15 toks/s]
Processed prompts:  70%|   | 179/256 [00:56<00:25,  3.03it/s, est. speed input: 3220.50 toks/s, output: 3.15 toks/s]
Processed prompts:  71%|   | 181/256 [00:57<00:24,  3.03it/s, est. speed input: 3219.14 toks/s, output: 3.14 toks/s]
Processed prompts:  71%|  | 183/256 [00:58<00:24,  3.04it/s, est. speed input: 3218.08 toks/s, output: 3.14 toks/s]
Processed prompts:  72%|  | 185/256 [00:58<00:23,  3.03it/s, est. speed input: 3216.63 toks/s, output: 3.14 toks/s]
Processed prompts:  73%|  | 187/256 [00:59<00:22,  3.03it/s, est. speed input: 3215.20 toks/s, output: 3.14 toks/s]
Processed prompts:  74%|  | 189/256 [01:00<00:22,  3.04it/s, est. speed input: 3214.32 toks/s, output: 3.14 toks/s]
Processed prompts:  75%|  | 191/256 [01:00<00:21,  3.03it/s, est. speed input: 3213.01 toks/s, output: 3.14 toks/s]
Processed prompts:  75%|  | 193/256 [01:01<00:20,  3.03it/s, est. speed input: 3211.95 toks/s, output: 3.14 toks/s]
Processed prompts:  76%|  | 195/256 [01:02<00:20,  3.03it/s, est. speed input: 3210.79 toks/s, output: 3.14 toks/s]
Processed prompts:  77%|  | 197/256 [01:02<00:19,  3.03it/s, est. speed input: 3209.56 toks/s, output: 3.13 toks/s]
Processed prompts:  78%|  | 199/256 [01:03<00:18,  3.03it/s, est. speed input: 3208.31 toks/s, output: 3.13 toks/s]
Processed prompts:  79%|  | 201/256 [01:03<00:16,  3.43it/s, est. speed input: 3220.32 toks/s, output: 3.14 toks/s]
Processed prompts:  79%|  | 203/256 [01:04<00:16,  3.30it/s, est. speed input: 3219.20 toks/s, output: 3.14 toks/s]
Processed prompts:  80%|  | 205/256 [01:05<00:15,  3.21it/s, est. speed input: 3217.95 toks/s, output: 3.14 toks/s]
Processed prompts:  81%|  | 207/256 [01:05<00:15,  3.15it/s, est. speed input: 3216.54 toks/s, output: 3.14 toks/s]
Processed prompts:  82%| | 209/256 [01:06<00:15,  3.11it/s, est. speed input: 3215.32 toks/s, output: 3.14 toks/s]
Processed prompts:  82%| | 211/256 [01:07<00:14,  3.08it/s, est. speed input: 3214.16 toks/s, output: 3.14 toks/s]
Processed prompts:  83%| | 213/256 [01:07<00:14,  3.07it/s, est. speed input: 3213.21 toks/s, output: 3.14 toks/s]
Processed prompts:  84%| | 215/256 [01:08<00:13,  3.06it/s, est. speed input: 3212.19 toks/s, output: 3.14 toks/s]
Processed prompts:  85%| | 217/256 [01:09<00:12,  3.05it/s, est. speed input: 3211.02 toks/s, output: 3.14 toks/s]
Processed prompts:  86%| | 219/256 [01:09<00:12,  3.04it/s, est. speed input: 3210.05 toks/s, output: 3.13 toks/s]
Processed prompts:  86%| | 221/256 [01:10<00:11,  3.03it/s, est. speed input: 3208.85 toks/s, output: 3.13 toks/s]
Processed prompts:  87%| | 223/256 [01:11<00:10,  3.03it/s, est. speed input: 3207.86 toks/s, output: 3.13 toks/s]
Processed prompts:  88%| | 225/256 [01:11<00:10,  3.03it/s, est. speed input: 3206.94 toks/s, output: 3.13 toks/s]
Processed prompts:  89%| | 227/256 [01:12<00:09,  3.03it/s, est. speed input: 3205.91 toks/s, output: 3.13 toks/s]
Processed prompts:  89%| | 229/256 [01:13<00:08,  3.03it/s, est. speed input: 3205.14 toks/s, output: 3.13 toks/s]
Processed prompts:  90%| | 231/256 [01:13<00:08,  3.03it/s, est. speed input: 3203.99 toks/s, output: 3.13 toks/s]
Processed prompts:  91%| | 233/256 [01:14<00:07,  3.02it/s, est. speed input: 3202.91 toks/s, output: 3.13 toks/s]
Processed prompts:  92%|| 235/256 [01:15<00:06,  3.02it/s, est. speed input: 3202.04 toks/s, output: 3.13 toks/s]
Processed prompts:  93%|| 237/256 [01:15<00:06,  3.02it/s, est. speed input: 3200.97 toks/s, output: 3.13 toks/s]
Processed prompts:  93%|| 239/256 [01:16<00:05,  3.02it/s, est. speed input: 3200.04 toks/s, output: 3.13 toks/s]
Processed prompts:  94%|| 241/256 [01:17<00:04,  3.02it/s, est. speed input: 3199.22 toks/s, output: 3.12 toks/s]
Processed prompts:  95%|| 243/256 [01:17<00:04,  3.02it/s, est. speed input: 3198.21 toks/s, output: 3.12 toks/s]
Processed prompts:  96%|| 245/256 [01:18<00:03,  3.02it/s, est. speed input: 3197.47 toks/s, output: 3.12 toks/s]
Processed prompts:  96%|| 247/256 [01:19<00:02,  3.01it/s, est. speed input: 3196.19 toks/s, output: 3.12 toks/s]
Processed prompts:  97%|| 249/256 [01:19<00:02,  3.01it/s, est. speed input: 3195.25 toks/s, output: 3.12 toks/s]
Processed prompts:  98%|| 251/256 [01:20<00:01,  3.01it/s, est. speed input: 3194.35 toks/s, output: 3.12 toks/s]
Processed prompts:  99%|| 253/256 [01:21<00:00,  3.01it/s, est. speed input: 3193.34 toks/s, output: 3.12 toks/s]
Processed prompts: 100%|| 255/256 [01:21<00:00,  3.01it/s, est. speed input: 3192.43 toks/s, output: 3.12 toks/s]
Processed prompts: 100%|| 256/256 [01:21<00:00,  3.01it/s, est. speed input: 3204.95 toks/s, output: 3.13 toks/s]
Processed prompts: 100%|| 256/256 [01:21<00:00,  3.13it/s, est. speed input: 3204.95 toks/s, output: 3.13 toks/s]
[rank0]:[W127 13:34:26.572705400 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-27 13:34:42
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Qwen2.5-14B-FP8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-27 13:34:50 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-27 13:34:50 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=2666142) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2666142) WARNING 01-27 13:36:58 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 3.01 requests/s, 3086.43 total tokens/s, 3.01 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-27 13:34:50] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 13:34:50] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 13:34:50] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 13:34:50] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:34:50] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:34:50] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:34:50] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:34:50] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:34:50] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 13:34:50] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 13:34:50] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 13:34:50] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 13:34:50] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 13:34:50] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-27 13:34:54] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 13:34:54] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 13:34:54] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 13:34:54] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:34:54] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:34:54] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:34:54] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:34:54] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:34:54] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 13:34:54] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 13:34:54] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 13:34:54] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 13:34:54] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 13:34:54] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=2666142) [2026-01-27 13:34:55] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=2666142) [2026-01-27 13:34:55] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2666142) [2026-01-27 13:34:55] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=2666142) [2026-01-27 13:34:55] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=2666142) [2026-01-27 13:34:55] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=2666142) [2026-01-27 13:34:55] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=2666142) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=2666142) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:25,  8.50s/it]
(EngineCore_DP0 pid=2666142) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:41<00:45, 22.89s/it]
(EngineCore_DP0 pid=2666142) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [01:10<00:25, 25.48s/it]
(EngineCore_DP0 pid=2666142) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:51<00:00, 31.61s/it]
(EngineCore_DP0 pid=2666142) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:51<00:00, 27.76s/it]
(EngineCore_DP0 pid=2666142) 
(EngineCore_DP0 pid=2666142) [2026-01-27 13:36:47] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 8192] -> 1D uint8
(EngineCore_DP0 pid=2666142) [2026-01-27 13:36:47] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 36700160 bytes
(EngineCore_DP0 pid=2666142) [2026-01-27 13:36:47] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 8192] -> 1D uint8
(EngineCore_DP0 pid=2666142) [2026-01-27 13:36:47] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 26214400 bytes
(EngineCore_DP0 pid=2666142) [2026-01-27 13:36:47] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 8192] -> 1D uint8
(EngineCore_DP0 pid=2666142) [2026-01-27 13:36:47] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 141557760 bytes
(EngineCore_DP0 pid=2666142) [2026-01-27 13:36:47] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 22144] -> 1D uint8
(EngineCore_DP0 pid=2666142) [2026-01-27 13:36:47] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 70860800 bytes
(EngineCore_DP0 pid=2666142) 2026-01-27 13:36:56,385 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=2666142) 2026-01-27 13:36:57,028 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   6%|         | 33/512 [00:00<00:01, 328.47it/s]
Adding requests:  14%|        | 71/512 [00:00<00:01, 353.45it/s]
Adding requests:  21%|        | 107/512 [00:00<00:01, 341.55it/s]
Adding requests:  29%|       | 149/512 [00:00<00:00, 371.42it/s]
Adding requests:  38%|      | 193/512 [00:00<00:00, 394.92it/s]
Adding requests:  46%|     | 235/512 [00:00<00:00, 402.50it/s]
Adding requests:  54%|    | 277/512 [00:00<00:00, 407.19it/s]
Adding requests:  63%|   | 322/512 [00:00<00:00, 420.50it/s]
Adding requests:  71%|  | 366/512 [00:00<00:00, 424.37it/s]
Adding requests:  80%|  | 412/512 [00:01<00:00, 432.81it/s]
Adding requests:  89%| | 456/512 [00:01<00:00, 430.94it/s]
Adding requests:  98%|| 502/512 [00:01<00:00, 438.56it/s]
Adding requests: 100%|| 512/512 [00:01<00:00, 411.19it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 2/512 [00:00<02:09,  3.93it/s, est. speed input: 4021.88 toks/s, output: 3.93 toks/s]
Processed prompts:   1%|          | 6/512 [00:01<02:36,  3.23it/s, est. speed input: 3368.07 toks/s, output: 3.29 toks/s]
Processed prompts:   2%|         | 10/512 [00:03<02:40,  3.14it/s, est. speed input: 3266.66 toks/s, output: 3.19 toks/s]
Processed prompts:   3%|         | 14/512 [00:04<02:40,  3.10it/s, est. speed input: 3222.16 toks/s, output: 3.15 toks/s]
Processed prompts:   4%|         | 18/512 [00:05<02:40,  3.08it/s, est. speed input: 3198.33 toks/s, output: 3.12 toks/s]
Processed prompts:   4%|         | 22/512 [00:07<02:40,  3.06it/s, est. speed input: 3181.34 toks/s, output: 3.11 toks/s]
Processed prompts:   5%|         | 26/512 [00:08<02:39,  3.05it/s, est. speed input: 3169.01 toks/s, output: 3.09 toks/s]
Processed prompts:   6%|         | 30/512 [00:09<02:38,  3.05it/s, est. speed input: 3160.66 toks/s, output: 3.09 toks/s]
Processed prompts:   7%|         | 34/512 [00:11<02:37,  3.04it/s, est. speed input: 3155.09 toks/s, output: 3.08 toks/s]
Processed prompts:   7%|         | 38/512 [00:12<02:36,  3.03it/s, est. speed input: 3147.75 toks/s, output: 3.07 toks/s]
Processed prompts:   8%|         | 42/512 [00:13<02:34,  3.04it/s, est. speed input: 3144.18 toks/s, output: 3.07 toks/s]
Processed prompts:   9%|         | 46/512 [00:14<02:33,  3.03it/s, est. speed input: 3140.74 toks/s, output: 3.07 toks/s]
Processed prompts:  10%|         | 50/512 [00:16<02:32,  3.03it/s, est. speed input: 3137.78 toks/s, output: 3.06 toks/s]
Processed prompts:  11%|         | 54/512 [00:17<02:31,  3.03it/s, est. speed input: 3134.15 toks/s, output: 3.06 toks/s]
Processed prompts:  11%|        | 58/512 [00:18<02:30,  3.02it/s, est. speed input: 3130.94 toks/s, output: 3.06 toks/s]
Processed prompts:  12%|        | 62/512 [00:20<02:28,  3.02it/s, est. speed input: 3128.14 toks/s, output: 3.05 toks/s]
Processed prompts:  13%|        | 66/512 [00:21<02:27,  3.02it/s, est. speed input: 3126.28 toks/s, output: 3.05 toks/s]
Processed prompts:  14%|        | 70/512 [00:22<02:26,  3.02it/s, est. speed input: 3124.08 toks/s, output: 3.05 toks/s]
Processed prompts:  14%|        | 74/512 [00:24<02:25,  3.02it/s, est. speed input: 3122.02 toks/s, output: 3.05 toks/s]
Processed prompts:  15%|        | 78/512 [00:25<02:23,  3.02it/s, est. speed input: 3120.12 toks/s, output: 3.05 toks/s]
Processed prompts:  16%|        | 82/512 [00:26<02:22,  3.02it/s, est. speed input: 3118.60 toks/s, output: 3.05 toks/s]
Processed prompts:  17%|        | 86/512 [00:28<02:21,  3.01it/s, est. speed input: 3116.44 toks/s, output: 3.04 toks/s]
Processed prompts:  18%|        | 90/512 [00:29<02:20,  3.01it/s, est. speed input: 3115.10 toks/s, output: 3.04 toks/s]
Processed prompts:  18%|        | 94/512 [00:30<02:18,  3.01it/s, est. speed input: 3113.83 toks/s, output: 3.04 toks/s]
Processed prompts:  19%|        | 98/512 [00:32<02:17,  3.01it/s, est. speed input: 3112.93 toks/s, output: 3.04 toks/s]
Processed prompts:  20%|        | 102/512 [00:33<02:16,  3.01it/s, est. speed input: 3111.84 toks/s, output: 3.04 toks/s]
Processed prompts:  21%|        | 106/512 [00:34<02:14,  3.01it/s, est. speed input: 3110.65 toks/s, output: 3.04 toks/s]
Processed prompts:  21%|       | 110/512 [00:36<02:13,  3.01it/s, est. speed input: 3109.63 toks/s, output: 3.04 toks/s]
Processed prompts:  22%|       | 114/512 [00:37<02:12,  3.01it/s, est. speed input: 3108.55 toks/s, output: 3.04 toks/s]
Processed prompts:  23%|       | 118/512 [00:38<02:11,  3.01it/s, est. speed input: 3107.30 toks/s, output: 3.03 toks/s]
Processed prompts:  24%|       | 122/512 [00:40<02:09,  3.01it/s, est. speed input: 3106.65 toks/s, output: 3.03 toks/s]
Processed prompts:  25%|       | 126/512 [00:41<02:08,  3.01it/s, est. speed input: 3105.82 toks/s, output: 3.03 toks/s]
Processed prompts:  25%|       | 130/512 [00:42<02:06,  3.01it/s, est. speed input: 3105.21 toks/s, output: 3.03 toks/s]
Processed prompts:  26%|       | 134/512 [00:44<02:05,  3.01it/s, est. speed input: 3104.22 toks/s, output: 3.03 toks/s]
Processed prompts:  27%|       | 138/512 [00:45<02:04,  3.01it/s, est. speed input: 3103.39 toks/s, output: 3.03 toks/s]
Processed prompts:  28%|       | 142/512 [00:46<02:03,  3.01it/s, est. speed input: 3102.58 toks/s, output: 3.03 toks/s]
Processed prompts:  29%|       | 146/512 [00:48<02:01,  3.01it/s, est. speed input: 3101.98 toks/s, output: 3.03 toks/s]
Processed prompts:  29%|       | 150/512 [00:49<02:00,  3.00it/s, est. speed input: 3100.86 toks/s, output: 3.03 toks/s]
Processed prompts:  30%|       | 154/512 [00:50<01:59,  3.00it/s, est. speed input: 3100.21 toks/s, output: 3.03 toks/s]
Processed prompts:  31%|       | 158/512 [00:52<01:58,  3.00it/s, est. speed input: 3099.35 toks/s, output: 3.03 toks/s]
Processed prompts:  32%|      | 162/512 [00:53<01:56,  3.00it/s, est. speed input: 3098.58 toks/s, output: 3.03 toks/s]
Processed prompts:  32%|      | 166/512 [00:54<01:55,  3.00it/s, est. speed input: 3097.99 toks/s, output: 3.03 toks/s]
Processed prompts:  33%|      | 170/512 [00:56<01:54,  2.99it/s, est. speed input: 3096.95 toks/s, output: 3.02 toks/s]
Processed prompts:  34%|      | 174/512 [00:57<01:52,  3.00it/s, est. speed input: 3096.27 toks/s, output: 3.02 toks/s]
Processed prompts:  35%|      | 178/512 [00:58<01:51,  3.00it/s, est. speed input: 3095.71 toks/s, output: 3.02 toks/s]
Processed prompts:  36%|      | 182/512 [01:00<01:50,  2.99it/s, est. speed input: 3094.77 toks/s, output: 3.02 toks/s]
Processed prompts:  36%|      | 186/512 [01:01<01:48,  2.99it/s, est. speed input: 3094.05 toks/s, output: 3.02 toks/s]
Processed prompts:  37%|      | 190/512 [01:02<01:47,  2.99it/s, est. speed input: 3093.43 toks/s, output: 3.02 toks/s]
Processed prompts:  38%|      | 194/512 [01:04<01:46,  2.99it/s, est. speed input: 3092.79 toks/s, output: 3.02 toks/s]
Processed prompts:  39%|      | 198/512 [01:05<01:44,  2.99it/s, est. speed input: 3092.28 toks/s, output: 3.02 toks/s]
Processed prompts:  39%|      | 202/512 [01:06<01:36,  3.21it/s, est. speed input: 3105.65 toks/s, output: 3.03 toks/s]
Processed prompts:  40%|      | 206/512 [01:07<01:37,  3.14it/s, est. speed input: 3104.86 toks/s, output: 3.03 toks/s]
Processed prompts:  41%|      | 210/512 [01:09<01:37,  3.10it/s, est. speed input: 3104.09 toks/s, output: 3.03 toks/s]
Processed prompts:  42%|     | 214/512 [01:10<01:37,  3.06it/s, est. speed input: 3103.00 toks/s, output: 3.03 toks/s]
Processed prompts:  43%|     | 218/512 [01:11<01:36,  3.04it/s, est. speed input: 3102.27 toks/s, output: 3.03 toks/s]
Processed prompts:  43%|     | 222/512 [01:13<01:35,  3.03it/s, est. speed input: 3101.64 toks/s, output: 3.03 toks/s]
Processed prompts:  44%|     | 226/512 [01:14<01:34,  3.01it/s, est. speed input: 3100.92 toks/s, output: 3.03 toks/s]
Processed prompts:  45%|     | 230/512 [01:15<01:33,  3.01it/s, est. speed input: 3100.19 toks/s, output: 3.03 toks/s]
Processed prompts:  46%|     | 234/512 [01:17<01:32,  3.00it/s, est. speed input: 3099.56 toks/s, output: 3.03 toks/s]
Processed prompts:  46%|     | 238/512 [01:18<01:31,  3.00it/s, est. speed input: 3098.98 toks/s, output: 3.03 toks/s]
Processed prompts:  47%|     | 242/512 [01:19<01:30,  3.00it/s, est. speed input: 3098.34 toks/s, output: 3.03 toks/s]
Processed prompts:  48%|     | 246/512 [01:21<01:28,  2.99it/s, est. speed input: 3097.49 toks/s, output: 3.02 toks/s]
Processed prompts:  49%|     | 250/512 [01:22<01:27,  2.99it/s, est. speed input: 3096.94 toks/s, output: 3.02 toks/s]
Processed prompts:  50%|     | 254/512 [01:24<01:26,  2.99it/s, est. speed input: 3096.37 toks/s, output: 3.02 toks/s]
Processed prompts:  50%|     | 258/512 [01:25<01:24,  2.99it/s, est. speed input: 3095.77 toks/s, output: 3.02 toks/s]
Processed prompts:  51%|     | 262/512 [01:26<01:23,  2.99it/s, est. speed input: 3095.05 toks/s, output: 3.02 toks/s]
Processed prompts:  52%|    | 266/512 [01:28<01:22,  2.99it/s, est. speed input: 3094.48 toks/s, output: 3.02 toks/s]
Processed prompts:  53%|    | 270/512 [01:29<01:21,  2.99it/s, est. speed input: 3093.93 toks/s, output: 3.02 toks/s]
Processed prompts:  54%|    | 274/512 [01:30<01:19,  2.98it/s, est. speed input: 3093.32 toks/s, output: 3.02 toks/s]
Processed prompts:  54%|    | 278/512 [01:32<01:18,  2.99it/s, est. speed input: 3092.85 toks/s, output: 3.02 toks/s]
Processed prompts:  55%|    | 282/512 [01:33<01:17,  2.98it/s, est. speed input: 3092.30 toks/s, output: 3.02 toks/s]
Processed prompts:  56%|    | 286/512 [01:34<01:15,  2.99it/s, est. speed input: 3091.90 toks/s, output: 3.02 toks/s]
Processed prompts:  57%|    | 290/512 [01:36<01:14,  2.98it/s, est. speed input: 3091.21 toks/s, output: 3.02 toks/s]
Processed prompts:  57%|    | 294/512 [01:37<01:13,  2.99it/s, est. speed input: 3090.83 toks/s, output: 3.02 toks/s]
Processed prompts:  58%|    | 298/512 [01:38<01:11,  2.98it/s, est. speed input: 3090.35 toks/s, output: 3.02 toks/s]
Processed prompts:  59%|    | 302/512 [01:40<01:10,  2.98it/s, est. speed input: 3089.85 toks/s, output: 3.02 toks/s]
Processed prompts:  60%|    | 306/512 [01:41<01:03,  3.22it/s, est. speed input: 3099.39 toks/s, output: 3.03 toks/s]
Processed prompts:  61%|    | 310/512 [01:42<01:04,  3.14it/s, est. speed input: 3098.70 toks/s, output: 3.03 toks/s]
Processed prompts:  61%|   | 314/512 [01:43<01:03,  3.10it/s, est. speed input: 3098.23 toks/s, output: 3.03 toks/s]
Processed prompts:  62%|   | 318/512 [01:45<01:03,  3.06it/s, est. speed input: 3097.64 toks/s, output: 3.03 toks/s]
Processed prompts:  63%|   | 322/512 [01:46<01:02,  3.04it/s, est. speed input: 3097.10 toks/s, output: 3.02 toks/s]
Processed prompts:  64%|   | 326/512 [01:47<01:01,  3.02it/s, est. speed input: 3096.46 toks/s, output: 3.02 toks/s]
Processed prompts:  64%|   | 330/512 [01:49<01:00,  3.01it/s, est. speed input: 3096.03 toks/s, output: 3.02 toks/s]
Processed prompts:  65%|   | 334/512 [01:50<00:59,  3.01it/s, est. speed input: 3095.77 toks/s, output: 3.02 toks/s]
Processed prompts:  66%|   | 338/512 [01:51<00:58,  3.00it/s, est. speed input: 3095.26 toks/s, output: 3.02 toks/s]
Processed prompts:  67%|   | 342/512 [01:53<00:56,  2.99it/s, est. speed input: 3094.71 toks/s, output: 3.02 toks/s]
Processed prompts:  68%|   | 346/512 [01:54<00:55,  2.99it/s, est. speed input: 3094.18 toks/s, output: 3.02 toks/s]
Processed prompts:  68%|   | 350/512 [01:55<00:54,  2.99it/s, est. speed input: 3093.84 toks/s, output: 3.02 toks/s]
Processed prompts:  69%|   | 354/512 [01:57<00:52,  2.99it/s, est. speed input: 3093.43 toks/s, output: 3.02 toks/s]
Processed prompts:  70%|   | 358/512 [01:58<00:51,  2.98it/s, est. speed input: 3092.85 toks/s, output: 3.02 toks/s]
Processed prompts:  71%|   | 362/512 [01:59<00:50,  2.98it/s, est. speed input: 3092.48 toks/s, output: 3.02 toks/s]
Processed prompts:  71%|  | 366/512 [02:01<00:48,  2.99it/s, est. speed input: 3092.10 toks/s, output: 3.02 toks/s]
Processed prompts:  72%|  | 370/512 [02:02<00:47,  2.98it/s, est. speed input: 3091.70 toks/s, output: 3.02 toks/s]
Processed prompts:  73%|  | 374/512 [02:03<00:46,  2.99it/s, est. speed input: 3091.43 toks/s, output: 3.02 toks/s]
Processed prompts:  74%|  | 378/512 [02:05<00:44,  2.99it/s, est. speed input: 3091.07 toks/s, output: 3.02 toks/s]
Processed prompts:  75%|  | 382/512 [02:06<00:43,  2.99it/s, est. speed input: 3090.72 toks/s, output: 3.02 toks/s]
Processed prompts:  75%|  | 386/512 [02:07<00:42,  2.98it/s, est. speed input: 3090.25 toks/s, output: 3.02 toks/s]
Processed prompts:  76%|  | 390/512 [02:09<00:40,  2.98it/s, est. speed input: 3089.94 toks/s, output: 3.02 toks/s]
Processed prompts:  77%|  | 394/512 [02:10<00:39,  2.99it/s, est. speed input: 3089.60 toks/s, output: 3.02 toks/s]
Processed prompts:  78%|  | 398/512 [02:11<00:38,  2.99it/s, est. speed input: 3089.37 toks/s, output: 3.02 toks/s]
Processed prompts:  79%|  | 402/512 [02:13<00:36,  2.98it/s, est. speed input: 3088.94 toks/s, output: 3.02 toks/s]
Processed prompts:  79%|  | 406/512 [02:14<00:35,  2.99it/s, est. speed input: 3088.67 toks/s, output: 3.02 toks/s]
Processed prompts:  80%|  | 410/512 [02:15<00:34,  2.99it/s, est. speed input: 3088.36 toks/s, output: 3.02 toks/s]
Processed prompts:  81%|  | 414/512 [02:17<00:32,  2.99it/s, est. speed input: 3088.12 toks/s, output: 3.02 toks/s]
Processed prompts:  82%| | 418/512 [02:18<00:31,  2.98it/s, est. speed input: 3087.73 toks/s, output: 3.02 toks/s]
Processed prompts:  82%| | 422/512 [02:19<00:30,  2.99it/s, est. speed input: 3087.45 toks/s, output: 3.02 toks/s]
Processed prompts:  83%| | 426/512 [02:21<00:28,  2.99it/s, est. speed input: 3087.16 toks/s, output: 3.01 toks/s]
Processed prompts:  84%| | 430/512 [02:22<00:27,  2.98it/s, est. speed input: 3086.86 toks/s, output: 3.01 toks/s]
Processed prompts:  85%| | 434/512 [02:23<00:24,  3.22it/s, est. speed input: 3093.58 toks/s, output: 3.02 toks/s]
Processed prompts:  86%| | 438/512 [02:25<00:23,  3.14it/s, est. speed input: 3093.14 toks/s, output: 3.02 toks/s]
Processed prompts:  86%| | 442/512 [02:26<00:22,  3.09it/s, est. speed input: 3092.76 toks/s, output: 3.02 toks/s]
Processed prompts:  87%| | 446/512 [02:27<00:21,  3.06it/s, est. speed input: 3092.46 toks/s, output: 3.02 toks/s]
Processed prompts:  88%| | 450/512 [02:29<00:20,  3.04it/s, est. speed input: 3092.17 toks/s, output: 3.02 toks/s]
Processed prompts:  89%| | 454/512 [02:30<00:19,  3.02it/s, est. speed input: 3091.75 toks/s, output: 3.02 toks/s]
Processed prompts:  89%| | 458/512 [02:31<00:17,  3.01it/s, est. speed input: 3091.45 toks/s, output: 3.02 toks/s]
Processed prompts:  90%| | 462/512 [02:33<00:16,  3.00it/s, est. speed input: 3091.16 toks/s, output: 3.02 toks/s]
Processed prompts:  91%| | 466/512 [02:34<00:15,  2.99it/s, est. speed input: 3090.80 toks/s, output: 3.02 toks/s]
Processed prompts:  92%|| 470/512 [02:35<00:14,  2.99it/s, est. speed input: 3090.55 toks/s, output: 3.02 toks/s]
Processed prompts:  93%|| 474/512 [02:37<00:12,  2.99it/s, est. speed input: 3090.24 toks/s, output: 3.02 toks/s]
Processed prompts:  93%|| 478/512 [02:38<00:11,  2.99it/s, est. speed input: 3090.00 toks/s, output: 3.02 toks/s]
Processed prompts:  94%|| 482/512 [02:39<00:10,  2.99it/s, est. speed input: 3089.74 toks/s, output: 3.02 toks/s]
Processed prompts:  95%|| 486/512 [02:41<00:08,  2.99it/s, est. speed input: 3089.47 toks/s, output: 3.02 toks/s]
Processed prompts:  96%|| 490/512 [02:42<00:07,  2.99it/s, est. speed input: 3089.21 toks/s, output: 3.02 toks/s]
Processed prompts:  96%|| 494/512 [02:43<00:06,  2.99it/s, est. speed input: 3088.98 toks/s, output: 3.02 toks/s]
Processed prompts:  97%|| 498/512 [02:45<00:04,  2.98it/s, est. speed input: 3088.64 toks/s, output: 3.02 toks/s]
Processed prompts:  98%|| 502/512 [02:46<00:03,  2.99it/s, est. speed input: 3088.43 toks/s, output: 3.02 toks/s]
Processed prompts:  99%|| 506/512 [02:47<00:02,  2.99it/s, est. speed input: 3088.16 toks/s, output: 3.02 toks/s]
Processed prompts: 100%|| 510/512 [02:48<00:00,  3.23it/s, est. speed input: 3094.06 toks/s, output: 3.02 toks/s]
Processed prompts: 100%|| 512/512 [02:48<00:00,  3.23it/s, est. speed input: 3106.19 toks/s, output: 3.03 toks/s]
Processed prompts: 100%|| 512/512 [02:48<00:00,  3.03it/s, est. speed input: 3106.19 toks/s, output: 3.03 toks/s]
[rank0]:[W127 13:39:48.839998981 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-27 13:39:51
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Qwen2.5-14B-FP8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-27 13:40:02 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-27 13:40:02 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=2670592) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2670592) WARNING 01-27 13:42:22 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 3.03 requests/s, 3102.66 total tokens/s, 3.03 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-27 13:40:01] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 13:40:02] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 13:40:02] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 13:40:02] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:40:02] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:40:02] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:40:02] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:40:02] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:40:02] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 13:40:02] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 13:40:02] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 13:40:02] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 13:40:02] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 13:40:02] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-27 13:40:05] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 13:40:05] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 13:40:05] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 13:40:05] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:40:05] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:40:05] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:40:05] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:40:05] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:40:05] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 13:40:05] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 13:40:05] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 13:40:05] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 13:40:05] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 13:40:05] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=2670592) [2026-01-27 13:40:06] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=2670592) [2026-01-27 13:40:06] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2670592) [2026-01-27 13:40:06] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=2670592) [2026-01-27 13:40:06] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=2670592) [2026-01-27 13:40:06] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=2670592) [2026-01-27 13:40:06] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=2670592) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=2670592) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:26,  8.89s/it]
(EngineCore_DP0 pid=2670592) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:42<00:46, 23.25s/it]
(EngineCore_DP0 pid=2670592) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [01:18<00:29, 29.03s/it]
(EngineCore_DP0 pid=2670592) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:59<00:00, 33.98s/it]
(EngineCore_DP0 pid=2670592) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:59<00:00, 29.92s/it]
(EngineCore_DP0 pid=2670592) 
(EngineCore_DP0 pid=2670592) [2026-01-27 13:42:08] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 8192] -> 1D uint8
(EngineCore_DP0 pid=2670592) [2026-01-27 13:42:08] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 36700160 bytes
(EngineCore_DP0 pid=2670592) [2026-01-27 13:42:08] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 8192] -> 1D uint8
(EngineCore_DP0 pid=2670592) [2026-01-27 13:42:08] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 26214400 bytes
(EngineCore_DP0 pid=2670592) [2026-01-27 13:42:08] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 8192] -> 1D uint8
(EngineCore_DP0 pid=2670592) [2026-01-27 13:42:08] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 141557760 bytes
(EngineCore_DP0 pid=2670592) [2026-01-27 13:42:08] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 22144] -> 1D uint8
(EngineCore_DP0 pid=2670592) [2026-01-27 13:42:08] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 70860800 bytes
(EngineCore_DP0 pid=2670592) 2026-01-27 13:42:18,556 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=2670592) 2026-01-27 13:42:19,664 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   0%|          | 1/1024 [00:01<20:16,  1.19s/it]
Adding requests:   0%|          | 2/1024 [00:01<10:43,  1.59it/s]
Adding requests:   0%|          | 3/1024 [00:01<06:56,  2.45it/s]
Adding requests:   0%|          | 5/1024 [00:01<03:51,  4.41it/s]
Adding requests:   1%|          | 7/1024 [00:01<02:32,  6.66it/s]
Adding requests:   1%|          | 10/1024 [00:01<01:35, 10.65it/s]
Adding requests:   1%|         | 13/1024 [00:02<01:11, 14.13it/s]
Adding requests:   2%|         | 20/1024 [00:02<00:38, 26.21it/s]
Adding requests:   4%|         | 38/1024 [00:02<00:15, 61.91it/s]
Adding requests:   6%|         | 57/1024 [00:02<00:10, 93.03it/s]
Adding requests:   8%|         | 78/1024 [00:02<00:07, 123.36it/s]
Adding requests:  11%|         | 113/1024 [00:02<00:04, 184.51it/s]
Adding requests:  15%|        | 150/1024 [00:02<00:03, 236.02it/s]
Adding requests:  19%|        | 193/1024 [00:02<00:02, 290.33it/s]
Adding requests:  23%|       | 236/1024 [00:02<00:02, 329.30it/s]
Adding requests:  27%|       | 275/1024 [00:02<00:02, 345.95it/s]
Adding requests:  31%|      | 320/1024 [00:03<00:01, 374.22it/s]
Adding requests:  35%|      | 359/1024 [00:03<00:01, 374.72it/s]
Adding requests:  39%|      | 399/1024 [00:03<00:01, 380.50it/s]
Adding requests:  43%|     | 444/1024 [00:03<00:01, 399.08it/s]
Adding requests:  48%|     | 490/1024 [00:03<00:01, 416.90it/s]
Adding requests:  52%|    | 534/1024 [00:03<00:01, 423.28it/s]
Adding requests:  56%|    | 577/1024 [00:03<00:01, 416.30it/s]
Adding requests:  60%|    | 619/1024 [00:03<00:00, 415.41it/s]
Adding requests:  65%|   | 661/1024 [00:03<00:00, 410.85it/s]
Adding requests:  69%|   | 704/1024 [00:04<00:00, 414.96it/s]
Adding requests:  73%|  | 746/1024 [00:04<00:00, 412.86it/s]
Adding requests:  77%|  | 792/1024 [00:04<00:00, 423.07it/s]
Adding requests:  82%| | 837/1024 [00:04<00:00, 430.36it/s]
Adding requests:  86%| | 881/1024 [00:04<00:00, 426.11it/s]
Adding requests:  90%| | 925/1024 [00:04<00:00, 427.72it/s]
Adding requests:  95%|| 968/1024 [00:04<00:00, 426.89it/s]
Adding requests:  99%|| 1011/1024 [00:04<00:00, 422.09it/s]
Adding requests: 100%|| 1024/1024 [00:04<00:00, 214.80it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 4/1024 [00:00<00:45, 22.21it/s, est. speed input: 22746.63 toks/s, output: 22.21 toks/s]
Processed prompts:   1%|          | 12/1024 [00:02<04:15,  3.97it/s, est. speed input: 4426.09 toks/s, output: 4.32 toks/s] 
Processed prompts:   2%|         | 20/1024 [00:05<04:51,  3.45it/s, est. speed input: 3804.27 toks/s, output: 3.72 toks/s]
Processed prompts:   3%|         | 28/1024 [00:07<05:04,  3.28it/s, est. speed input: 3587.22 toks/s, output: 3.50 toks/s]
Processed prompts:   4%|         | 36/1024 [00:10<05:09,  3.19it/s, est. speed input: 3474.89 toks/s, output: 3.39 toks/s]
Processed prompts:   4%|         | 44/1024 [00:13<05:11,  3.14it/s, est. speed input: 3407.21 toks/s, output: 3.33 toks/s]
Processed prompts:   5%|         | 52/1024 [00:15<05:11,  3.12it/s, est. speed input: 3362.66 toks/s, output: 3.28 toks/s]
Processed prompts:   6%|         | 60/1024 [00:18<05:11,  3.09it/s, est. speed input: 3327.90 toks/s, output: 3.25 toks/s]
Processed prompts:   7%|         | 68/1024 [00:21<05:10,  3.08it/s, est. speed input: 3303.46 toks/s, output: 3.23 toks/s]
Processed prompts:   7%|         | 76/1024 [00:23<05:08,  3.07it/s, est. speed input: 3282.96 toks/s, output: 3.21 toks/s]
Processed prompts:   8%|         | 84/1024 [00:26<05:06,  3.06it/s, est. speed input: 3266.68 toks/s, output: 3.19 toks/s]
Processed prompts:   9%|         | 92/1024 [00:28<05:05,  3.06it/s, est. speed input: 3252.62 toks/s, output: 3.18 toks/s]
Processed prompts:  10%|         | 100/1024 [00:31<05:02,  3.05it/s, est. speed input: 3241.29 toks/s, output: 3.17 toks/s]
Processed prompts:  11%|         | 108/1024 [00:34<05:00,  3.05it/s, est. speed input: 3231.17 toks/s, output: 3.16 toks/s]
Processed prompts:  11%|        | 116/1024 [00:36<04:58,  3.04it/s, est. speed input: 3222.39 toks/s, output: 3.15 toks/s]
Processed prompts:  12%|        | 124/1024 [00:39<04:55,  3.04it/s, est. speed input: 3214.64 toks/s, output: 3.14 toks/s]
Processed prompts:  13%|        | 132/1024 [00:42<04:53,  3.04it/s, est. speed input: 3208.21 toks/s, output: 3.13 toks/s]
Processed prompts:  14%|        | 140/1024 [00:44<04:51,  3.04it/s, est. speed input: 3201.87 toks/s, output: 3.13 toks/s]
Processed prompts:  14%|        | 148/1024 [00:47<04:48,  3.03it/s, est. speed input: 3196.20 toks/s, output: 3.12 toks/s]
Processed prompts:  15%|        | 156/1024 [00:50<04:46,  3.03it/s, est. speed input: 3191.32 toks/s, output: 3.12 toks/s]
Processed prompts:  16%|        | 164/1024 [00:52<04:43,  3.03it/s, est. speed input: 3186.87 toks/s, output: 3.11 toks/s]
Processed prompts:  17%|        | 172/1024 [00:55<04:41,  3.03it/s, est. speed input: 3182.51 toks/s, output: 3.11 toks/s]
Processed prompts:  18%|        | 180/1024 [00:57<04:38,  3.03it/s, est. speed input: 3178.53 toks/s, output: 3.10 toks/s]
Processed prompts:  18%|        | 188/1024 [01:00<04:36,  3.03it/s, est. speed input: 3174.99 toks/s, output: 3.10 toks/s]
Processed prompts:  19%|        | 196/1024 [01:03<04:26,  3.11it/s, est. speed input: 3183.95 toks/s, output: 3.11 toks/s]
Processed prompts:  20%|        | 204/1024 [01:05<04:25,  3.08it/s, est. speed input: 3180.29 toks/s, output: 3.11 toks/s]
Processed prompts:  21%|        | 212/1024 [01:08<04:24,  3.07it/s, est. speed input: 3177.08 toks/s, output: 3.10 toks/s]
Processed prompts:  21%|       | 220/1024 [01:10<04:23,  3.05it/s, est. speed input: 3174.14 toks/s, output: 3.10 toks/s]
Processed prompts:  22%|       | 228/1024 [01:13<04:21,  3.04it/s, est. speed input: 3171.33 toks/s, output: 3.10 toks/s]
Processed prompts:  23%|       | 236/1024 [01:16<04:19,  3.04it/s, est. speed input: 3168.82 toks/s, output: 3.09 toks/s]
Processed prompts:  24%|       | 244/1024 [01:18<04:17,  3.03it/s, est. speed input: 3166.29 toks/s, output: 3.09 toks/s]
Processed prompts:  25%|       | 252/1024 [01:21<04:14,  3.03it/s, est. speed input: 3164.34 toks/s, output: 3.09 toks/s]
Processed prompts:  25%|       | 260/1024 [01:24<04:12,  3.03it/s, est. speed input: 3162.19 toks/s, output: 3.09 toks/s]
Processed prompts:  26%|       | 268/1024 [01:26<04:09,  3.03it/s, est. speed input: 3160.30 toks/s, output: 3.09 toks/s]
Processed prompts:  27%|       | 276/1024 [01:29<04:06,  3.03it/s, est. speed input: 3158.54 toks/s, output: 3.08 toks/s]
Processed prompts:  28%|       | 284/1024 [01:32<04:04,  3.03it/s, est. speed input: 3157.00 toks/s, output: 3.08 toks/s]
Processed prompts:  29%|       | 292/1024 [01:34<04:01,  3.03it/s, est. speed input: 3155.58 toks/s, output: 3.08 toks/s]
Processed prompts:  29%|       | 300/1024 [01:37<03:52,  3.12it/s, est. speed input: 3162.07 toks/s, output: 3.09 toks/s]
Processed prompts:  30%|       | 308/1024 [01:39<03:51,  3.09it/s, est. speed input: 3160.55 toks/s, output: 3.09 toks/s]
Processed prompts:  31%|       | 316/1024 [01:42<03:50,  3.07it/s, est. speed input: 3159.05 toks/s, output: 3.09 toks/s]
Processed prompts:  32%|      | 324/1024 [01:45<03:48,  3.06it/s, est. speed input: 3157.62 toks/s, output: 3.08 toks/s]
Processed prompts:  32%|      | 332/1024 [01:47<03:46,  3.05it/s, est. speed input: 3156.45 toks/s, output: 3.08 toks/s]
Processed prompts:  33%|      | 340/1024 [01:50<03:44,  3.05it/s, est. speed input: 3155.29 toks/s, output: 3.08 toks/s]
Processed prompts:  34%|      | 348/1024 [01:52<03:42,  3.04it/s, est. speed input: 3154.12 toks/s, output: 3.08 toks/s]
Processed prompts:  35%|      | 356/1024 [01:55<03:39,  3.04it/s, est. speed input: 3152.99 toks/s, output: 3.08 toks/s]
Processed prompts:  36%|      | 364/1024 [01:58<03:37,  3.04it/s, est. speed input: 3151.93 toks/s, output: 3.08 toks/s]
Processed prompts:  36%|      | 372/1024 [02:00<03:34,  3.03it/s, est. speed input: 3150.72 toks/s, output: 3.08 toks/s]
Processed prompts:  37%|      | 380/1024 [02:03<03:32,  3.03it/s, est. speed input: 3149.73 toks/s, output: 3.08 toks/s]
Processed prompts:  38%|      | 388/1024 [02:06<03:29,  3.03it/s, est. speed input: 3148.70 toks/s, output: 3.07 toks/s]
Processed prompts:  39%|      | 396/1024 [02:08<03:27,  3.03it/s, est. speed input: 3147.81 toks/s, output: 3.07 toks/s]
Processed prompts:  39%|      | 404/1024 [02:11<03:24,  3.03it/s, est. speed input: 3147.12 toks/s, output: 3.07 toks/s]
Processed prompts:  40%|      | 412/1024 [02:14<03:21,  3.03it/s, est. speed input: 3146.23 toks/s, output: 3.07 toks/s]
Processed prompts:  41%|      | 420/1024 [02:16<03:19,  3.03it/s, est. speed input: 3145.49 toks/s, output: 3.07 toks/s]
Processed prompts:  42%|     | 428/1024 [02:19<03:16,  3.03it/s, est. speed input: 3144.61 toks/s, output: 3.07 toks/s]
Processed prompts:  43%|     | 436/1024 [02:21<03:08,  3.12it/s, est. speed input: 3149.17 toks/s, output: 3.08 toks/s]
Processed prompts:  43%|     | 444/1024 [02:24<03:07,  3.09it/s, est. speed input: 3148.24 toks/s, output: 3.07 toks/s]
Processed prompts:  44%|     | 452/1024 [02:27<03:06,  3.07it/s, est. speed input: 3147.56 toks/s, output: 3.07 toks/s]
Processed prompts:  45%|     | 460/1024 [02:29<03:04,  3.06it/s, est. speed input: 3146.78 toks/s, output: 3.07 toks/s]
Processed prompts:  46%|     | 468/1024 [02:32<03:02,  3.05it/s, est. speed input: 3146.02 toks/s, output: 3.07 toks/s]
Processed prompts:  46%|     | 476/1024 [02:34<03:00,  3.04it/s, est. speed input: 3145.24 toks/s, output: 3.07 toks/s]
Processed prompts:  47%|     | 484/1024 [02:37<02:57,  3.04it/s, est. speed input: 3144.69 toks/s, output: 3.07 toks/s]
Processed prompts:  48%|     | 492/1024 [02:40<02:55,  3.04it/s, est. speed input: 3143.87 toks/s, output: 3.07 toks/s]
Processed prompts:  49%|     | 500/1024 [02:42<02:52,  3.04it/s, est. speed input: 3143.29 toks/s, output: 3.07 toks/s]
Processed prompts:  50%|     | 508/1024 [02:45<02:50,  3.03it/s, est. speed input: 3142.57 toks/s, output: 3.07 toks/s]
Processed prompts:  50%|     | 516/1024 [02:48<02:47,  3.03it/s, est. speed input: 3141.99 toks/s, output: 3.07 toks/s]
Processed prompts:  51%|     | 524/1024 [02:50<02:44,  3.03it/s, est. speed input: 3141.34 toks/s, output: 3.07 toks/s]
Processed prompts:  52%|    | 532/1024 [02:53<02:42,  3.03it/s, est. speed input: 3140.86 toks/s, output: 3.07 toks/s]
Processed prompts:  53%|    | 540/1024 [02:56<02:39,  3.03it/s, est. speed input: 3140.26 toks/s, output: 3.07 toks/s]
Processed prompts:  54%|    | 548/1024 [02:58<02:37,  3.03it/s, est. speed input: 3139.72 toks/s, output: 3.07 toks/s]
Processed prompts:  54%|    | 556/1024 [03:01<02:34,  3.03it/s, est. speed input: 3139.32 toks/s, output: 3.07 toks/s]
Processed prompts:  55%|    | 564/1024 [03:03<02:31,  3.03it/s, est. speed input: 3138.79 toks/s, output: 3.07 toks/s]
Processed prompts:  56%|    | 572/1024 [03:06<02:29,  3.03it/s, est. speed input: 3138.14 toks/s, output: 3.06 toks/s]
Processed prompts:  57%|    | 580/1024 [03:09<02:26,  3.03it/s, est. speed input: 3137.65 toks/s, output: 3.06 toks/s]
Processed prompts:  57%|    | 588/1024 [03:11<02:23,  3.03it/s, est. speed input: 3137.18 toks/s, output: 3.06 toks/s]
Processed prompts:  58%|    | 596/1024 [03:14<02:21,  3.03it/s, est. speed input: 3136.76 toks/s, output: 3.06 toks/s]
Processed prompts:  59%|    | 604/1024 [03:17<02:18,  3.03it/s, est. speed input: 3136.42 toks/s, output: 3.06 toks/s]
Processed prompts:  60%|    | 612/1024 [03:19<02:15,  3.03it/s, est. speed input: 3135.99 toks/s, output: 3.06 toks/s]
Processed prompts:  61%|    | 620/1024 [03:22<02:13,  3.03it/s, est. speed input: 3135.56 toks/s, output: 3.06 toks/s]
Processed prompts:  61%|   | 628/1024 [03:25<02:10,  3.03it/s, est. speed input: 3135.14 toks/s, output: 3.06 toks/s]
Processed prompts:  62%|   | 636/1024 [03:27<02:08,  3.03it/s, est. speed input: 3134.70 toks/s, output: 3.06 toks/s]
Processed prompts:  63%|   | 644/1024 [03:30<02:05,  3.03it/s, est. speed input: 3134.23 toks/s, output: 3.06 toks/s]
Processed prompts:  64%|   | 652/1024 [03:33<02:02,  3.03it/s, est. speed input: 3133.88 toks/s, output: 3.06 toks/s]
Processed prompts:  64%|   | 660/1024 [03:35<02:00,  3.03it/s, est. speed input: 3133.46 toks/s, output: 3.06 toks/s]
Processed prompts:  65%|   | 668/1024 [03:38<01:57,  3.03it/s, est. speed input: 3133.12 toks/s, output: 3.06 toks/s]
Processed prompts:  66%|   | 676/1024 [03:40<01:54,  3.03it/s, est. speed input: 3132.76 toks/s, output: 3.06 toks/s]
Processed prompts:  67%|   | 684/1024 [03:43<01:52,  3.03it/s, est. speed input: 3132.41 toks/s, output: 3.06 toks/s]
Processed prompts:  68%|   | 692/1024 [03:46<01:49,  3.03it/s, est. speed input: 3131.99 toks/s, output: 3.06 toks/s]
Processed prompts:  68%|   | 700/1024 [03:48<01:46,  3.03it/s, est. speed input: 3131.64 toks/s, output: 3.06 toks/s]
Processed prompts:  69%|   | 708/1024 [03:51<01:44,  3.03it/s, est. speed input: 3131.22 toks/s, output: 3.06 toks/s]
Processed prompts:  70%|   | 716/1024 [03:54<01:41,  3.03it/s, est. speed input: 3130.93 toks/s, output: 3.06 toks/s]
Processed prompts:  71%|   | 724/1024 [03:56<01:39,  3.03it/s, est. speed input: 3130.54 toks/s, output: 3.06 toks/s]
Processed prompts:  71%|  | 732/1024 [03:59<01:36,  3.03it/s, est. speed input: 3130.22 toks/s, output: 3.06 toks/s]
Processed prompts:  72%|  | 740/1024 [04:02<01:33,  3.03it/s, est. speed input: 3129.90 toks/s, output: 3.06 toks/s]
Processed prompts:  73%|  | 748/1024 [04:04<01:31,  3.03it/s, est. speed input: 3129.68 toks/s, output: 3.06 toks/s]
Processed prompts:  74%|  | 756/1024 [04:07<01:28,  3.03it/s, est. speed input: 3129.29 toks/s, output: 3.06 toks/s]
Processed prompts:  75%|  | 764/1024 [04:10<01:25,  3.03it/s, est. speed input: 3129.01 toks/s, output: 3.06 toks/s]
Processed prompts:  75%|  | 772/1024 [04:12<01:23,  3.03it/s, est. speed input: 3128.70 toks/s, output: 3.06 toks/s]
Processed prompts:  76%|  | 780/1024 [04:15<01:18,  3.11it/s, est. speed input: 3131.39 toks/s, output: 3.06 toks/s]
Processed prompts:  77%|  | 788/1024 [04:17<01:16,  3.09it/s, est. speed input: 3131.07 toks/s, output: 3.06 toks/s]
Processed prompts:  78%|  | 796/1024 [04:20<01:14,  3.07it/s, est. speed input: 3130.77 toks/s, output: 3.06 toks/s]
Processed prompts:  79%|  | 804/1024 [04:22<01:11,  3.06it/s, est. speed input: 3130.43 toks/s, output: 3.06 toks/s]
Processed prompts:  79%|  | 812/1024 [04:25<01:09,  3.05it/s, est. speed input: 3130.10 toks/s, output: 3.06 toks/s]
Processed prompts:  80%|  | 820/1024 [04:28<01:07,  3.04it/s, est. speed input: 3129.78 toks/s, output: 3.06 toks/s]
Processed prompts:  81%|  | 828/1024 [04:30<01:04,  3.04it/s, est. speed input: 3129.46 toks/s, output: 3.06 toks/s]
Processed prompts:  82%| | 836/1024 [04:33<01:01,  3.03it/s, est. speed input: 3129.19 toks/s, output: 3.06 toks/s]
Processed prompts:  82%| | 844/1024 [04:36<00:59,  3.03it/s, est. speed input: 3128.82 toks/s, output: 3.06 toks/s]
Processed prompts:  83%| | 852/1024 [04:38<00:56,  3.03it/s, est. speed input: 3128.60 toks/s, output: 3.06 toks/s]
Processed prompts:  84%| | 860/1024 [04:41<00:54,  3.03it/s, est. speed input: 3128.34 toks/s, output: 3.06 toks/s]
Processed prompts:  85%| | 868/1024 [04:44<00:51,  3.03it/s, est. speed input: 3128.08 toks/s, output: 3.05 toks/s]
Processed prompts:  86%| | 876/1024 [04:46<00:48,  3.03it/s, est. speed input: 3127.84 toks/s, output: 3.05 toks/s]
Processed prompts:  86%| | 884/1024 [04:49<00:46,  3.03it/s, est. speed input: 3127.62 toks/s, output: 3.05 toks/s]
Processed prompts:  87%| | 892/1024 [04:52<00:43,  3.03it/s, est. speed input: 3127.35 toks/s, output: 3.05 toks/s]
Processed prompts:  88%| | 900/1024 [04:54<00:40,  3.03it/s, est. speed input: 3127.14 toks/s, output: 3.05 toks/s]
Processed prompts:  89%| | 908/1024 [04:57<00:38,  3.03it/s, est. speed input: 3126.90 toks/s, output: 3.05 toks/s]
Processed prompts:  89%| | 916/1024 [04:59<00:35,  3.03it/s, est. speed input: 3126.69 toks/s, output: 3.05 toks/s]
Processed prompts:  90%| | 924/1024 [05:02<00:33,  3.03it/s, est. speed input: 3126.40 toks/s, output: 3.05 toks/s]
Processed prompts:  91%| | 932/1024 [05:05<00:30,  3.03it/s, est. speed input: 3126.21 toks/s, output: 3.05 toks/s]
Processed prompts:  92%|| 940/1024 [05:07<00:27,  3.02it/s, est. speed input: 3125.88 toks/s, output: 3.05 toks/s]
Processed prompts:  93%|| 948/1024 [05:10<00:25,  3.03it/s, est. speed input: 3125.68 toks/s, output: 3.05 toks/s]
Processed prompts:  93%|| 956/1024 [05:13<00:22,  3.03it/s, est. speed input: 3125.48 toks/s, output: 3.05 toks/s]
Processed prompts:  94%|| 964/1024 [05:15<00:19,  3.03it/s, est. speed input: 3125.26 toks/s, output: 3.05 toks/s]
Processed prompts:  95%|| 972/1024 [05:18<00:17,  3.03it/s, est. speed input: 3125.00 toks/s, output: 3.05 toks/s]
Processed prompts:  96%|| 980/1024 [05:21<00:14,  3.03it/s, est. speed input: 3124.82 toks/s, output: 3.05 toks/s]
Processed prompts:  96%|| 988/1024 [05:23<00:11,  3.03it/s, est. speed input: 3124.65 toks/s, output: 3.05 toks/s]
Processed prompts:  97%|| 996/1024 [05:26<00:09,  3.03it/s, est. speed input: 3124.48 toks/s, output: 3.05 toks/s]
Processed prompts:  98%|| 1004/1024 [05:29<00:06,  3.03it/s, est. speed input: 3124.29 toks/s, output: 3.05 toks/s]
Processed prompts:  99%|| 1012/1024 [05:31<00:03,  3.03it/s, est. speed input: 3124.09 toks/s, output: 3.05 toks/s]
Processed prompts: 100%|| 1020/1024 [05:33<00:01,  3.39it/s, est. speed input: 3132.68 toks/s, output: 3.06 toks/s]
Processed prompts: 100%|| 1024/1024 [05:33<00:00,  3.39it/s, est. speed input: 3144.96 toks/s, output: 3.07 toks/s]
Processed prompts: 100%|| 1024/1024 [05:33<00:00,  3.07it/s, est. speed input: 3144.96 toks/s, output: 3.07 toks/s]
[rank0]:[W127 13:48:01.541446688 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-27 13:48:15
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Qwen2.5-14B-FP8_M16384.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-27 13:48:30 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-27 13:48:30 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=2677780) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2677780) WARNING 01-27 13:50:55 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 3.00 requests/s, 3074.94 total tokens/s, 3.00 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-27 13:48:30] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 13:48:30] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 13:48:30] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 13:48:30] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:48:30] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:48:30] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:48:30] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:48:30] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:48:30] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 13:48:30] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 13:48:30] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 13:48:30] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 13:48:30] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 13:48:30] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-27 13:48:33] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 13:48:33] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 13:48:33] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 13:48:33] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:48:33] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:48:33] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:48:33] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:48:33] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 13:48:33] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 13:48:33] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 13:48:33] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 13:48:33] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 13:48:33] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 13:48:33] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=2677780) [2026-01-27 13:48:35] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=2677780) [2026-01-27 13:48:35] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2677780) [2026-01-27 13:48:35] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=2677780) [2026-01-27 13:48:35] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=2677780) [2026-01-27 13:48:35] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=2677780) [2026-01-27 13:48:35] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=2677780) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=2677780) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:25,  8.44s/it]
(EngineCore_DP0 pid=2677780) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:41<00:45, 22.78s/it]
(EngineCore_DP0 pid=2677780) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [01:17<00:28, 28.88s/it]
(EngineCore_DP0 pid=2677780) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:58<00:00, 33.79s/it]
(EngineCore_DP0 pid=2677780) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:58<00:00, 29.68s/it]
(EngineCore_DP0 pid=2677780) 
(EngineCore_DP0 pid=2677780) [2026-01-27 13:50:35] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 8192] -> 1D uint8
(EngineCore_DP0 pid=2677780) [2026-01-27 13:50:35] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 36700160 bytes
(EngineCore_DP0 pid=2677780) [2026-01-27 13:50:35] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 8192] -> 1D uint8
(EngineCore_DP0 pid=2677780) [2026-01-27 13:50:35] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 26214400 bytes
(EngineCore_DP0 pid=2677780) [2026-01-27 13:50:35] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 8192] -> 1D uint8
(EngineCore_DP0 pid=2677780) [2026-01-27 13:50:35] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 141557760 bytes
(EngineCore_DP0 pid=2677780) [2026-01-27 13:50:35] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 22144] -> 1D uint8
(EngineCore_DP0 pid=2677780) [2026-01-27 13:50:35] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 70860800 bytes
(EngineCore_DP0 pid=2677780) 2026-01-27 13:50:48,669 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=2677780) 2026-01-27 13:50:50,438 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   0%|          | 1/2048 [00:00<33:01,  1.03it/s]
Adding requests:   0%|          | 2/2048 [00:01<17:32,  1.94it/s]
Adding requests:   0%|          | 3/2048 [00:01<11:32,  2.95it/s]
Adding requests:   0%|          | 4/2048 [00:01<08:24,  4.05it/s]
Adding requests:   0%|          | 6/2048 [00:01<05:19,  6.39it/s]
Adding requests:   0%|          | 8/2048 [00:01<03:48,  8.93it/s]
Adding requests:   1%|          | 11/2048 [00:01<02:32, 13.34it/s]
Adding requests:   1%|          | 15/2048 [00:01<01:46, 19.14it/s]
Adding requests:   1%|         | 27/2048 [00:01<00:46, 43.58it/s]
Adding requests:   2%|         | 46/2048 [00:02<00:24, 81.20it/s]
Adding requests:   3%|         | 66/2048 [00:02<00:17, 112.62it/s]
Adding requests:   5%|         | 98/2048 [00:02<00:11, 168.84it/s]
Adding requests:   7%|         | 139/2048 [00:02<00:08, 235.64it/s]
Adding requests:   9%|         | 180/2048 [00:02<00:06, 284.05it/s]
Adding requests:  11%|         | 224/2048 [00:02<00:05, 328.78it/s]
Adding requests:  13%|        | 267/2048 [00:02<00:04, 357.17it/s]
Adding requests:  15%|        | 306/2048 [00:02<00:04, 365.73it/s]
Adding requests:  17%|        | 347/2048 [00:02<00:04, 376.97it/s]
Adding requests:  19%|        | 391/2048 [00:02<00:04, 393.76it/s]
Adding requests:  21%|       | 436/2048 [00:03<00:03, 408.02it/s]
Adding requests:  23%|       | 479/2048 [00:03<00:03, 411.52it/s]
Adding requests:  26%|       | 529/2048 [00:03<00:03, 435.09it/s]
Adding requests:  28%|       | 574/2048 [00:03<00:03, 436.90it/s]
Adding requests:  30%|       | 619/2048 [00:03<00:03, 438.36it/s]
Adding requests:  32%|      | 663/2048 [00:03<00:03, 430.51it/s]
Adding requests:  35%|      | 707/2048 [00:03<00:03, 429.93it/s]
Adding requests:  37%|      | 751/2048 [00:03<00:03, 422.32it/s]
Adding requests:  39%|      | 794/2048 [00:03<00:02, 421.93it/s]
Adding requests:  41%|      | 841/2048 [00:04<00:02, 435.33it/s]
Adding requests:  43%|     | 885/2048 [00:04<00:02, 413.79it/s]
Adding requests:  45%|     | 928/2048 [00:04<00:02, 416.98it/s]
Adding requests:  47%|     | 970/2048 [00:11<00:55, 19.43it/s] 
Adding requests:  49%|     | 1010/2048 [00:11<00:39, 26.58it/s]
Adding requests:  51%|    | 1051/2048 [00:11<00:27, 36.58it/s]
Adding requests:  53%|    | 1093/2048 [00:11<00:18, 50.35it/s]
Adding requests:  56%|    | 1137/2048 [00:11<00:13, 69.35it/s]
Adding requests:  58%|    | 1179/2048 [00:11<00:09, 92.15it/s]
Adding requests:  60%|    | 1222/2048 [00:12<00:06, 120.77it/s]
Adding requests:  62%|   | 1263/2048 [00:12<00:05, 152.02it/s]
Adding requests:  64%|   | 1304/2048 [00:12<00:04, 185.45it/s]
Adding requests:  66%|   | 1345/2048 [00:12<00:03, 220.80it/s]
Adding requests:  68%|   | 1389/2048 [00:12<00:02, 260.83it/s]
Adding requests:  70%|   | 1432/2048 [00:12<00:02, 292.26it/s]
Adding requests:  72%|  | 1474/2048 [00:12<00:01, 320.63it/s]
Adding requests:  74%|  | 1519/2048 [00:12<00:01, 352.15it/s]
Adding requests:  76%|  | 1562/2048 [00:12<00:01, 368.85it/s]
Adding requests:  78%|  | 1605/2048 [00:12<00:01, 377.69it/s]
Adding requests:  80%|  | 1647/2048 [00:13<00:01, 379.13it/s]
Adding requests:  83%| | 1690/2048 [00:13<00:00, 391.01it/s]
Adding requests:  85%| | 1735/2048 [00:13<00:00, 405.89it/s]
Adding requests:  87%| | 1781/2048 [00:13<00:00, 419.01it/s]
Adding requests:  89%| | 1824/2048 [00:13<00:00, 417.85it/s]
Adding requests:  91%| | 1867/2048 [00:13<00:00, 416.35it/s]
Adding requests:  93%|| 1911/2048 [00:13<00:00, 421.45it/s]
Adding requests:  95%|| 1954/2048 [00:13<00:00, 423.50it/s]
Adding requests:  98%|| 1997/2048 [00:13<00:00, 420.69it/s]
Adding requests: 100%|| 2040/2048 [00:14<00:00, 419.99it/s]
Adding requests: 100%|| 2048/2048 [00:14<00:00, 145.79it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 37/2048 [00:04<03:51,  8.70it/s, est. speed input: 8907.77 toks/s, output: 8.70 toks/s]
Processed prompts:   3%|         | 53/2048 [00:09<06:34,  5.06it/s, est. speed input: 5680.68 toks/s, output: 5.55 toks/s]
Processed prompts:   3%|         | 69/2048 [00:14<08:04,  4.08it/s, est. speed input: 4755.67 toks/s, output: 4.64 toks/s]
Processed prompts:   4%|         | 85/2048 [00:20<08:58,  3.65it/s, est. speed input: 4314.79 toks/s, output: 4.21 toks/s]
Processed prompts:   5%|         | 101/2048 [00:25<09:30,  3.41it/s, est. speed input: 4057.55 toks/s, output: 3.96 toks/s]
Processed prompts:   6%|         | 117/2048 [00:30<09:50,  3.27it/s, est. speed input: 3888.18 toks/s, output: 3.80 toks/s]
Processed prompts:   6%|         | 133/2048 [00:36<10:01,  3.18it/s, est. speed input: 3768.63 toks/s, output: 3.68 toks/s]
Processed prompts:   7%|         | 149/2048 [00:41<10:07,  3.13it/s, est. speed input: 3679.31 toks/s, output: 3.59 toks/s]
Processed prompts:   8%|         | 165/2048 [00:46<10:10,  3.09it/s, est. speed input: 3610.25 toks/s, output: 3.53 toks/s]
Processed prompts:   9%|         | 181/2048 [00:52<10:10,  3.06it/s, est. speed input: 3554.61 toks/s, output: 3.47 toks/s]
Processed prompts:  10%|         | 197/2048 [00:57<09:59,  3.09it/s, est. speed input: 3525.75 toks/s, output: 3.44 toks/s]
Processed prompts:  10%|         | 213/2048 [01:02<09:59,  3.06it/s, est. speed input: 3487.05 toks/s, output: 3.41 toks/s]
Processed prompts:  11%|         | 229/2048 [01:07<09:58,  3.04it/s, est. speed input: 3454.19 toks/s, output: 3.37 toks/s]
Processed prompts:  12%|        | 245/2048 [01:13<09:55,  3.03it/s, est. speed input: 3425.93 toks/s, output: 3.35 toks/s]
Processed prompts:  13%|        | 261/2048 [01:18<09:51,  3.02it/s, est. speed input: 3402.02 toks/s, output: 3.32 toks/s]
Processed prompts:  14%|        | 277/2048 [01:23<09:48,  3.01it/s, est. speed input: 3380.63 toks/s, output: 3.30 toks/s]
Processed prompts:  14%|        | 293/2048 [01:28<09:34,  3.05it/s, est. speed input: 3372.33 toks/s, output: 3.29 toks/s]
Processed prompts:  15%|        | 309/2048 [01:34<09:32,  3.04it/s, est. speed input: 3354.97 toks/s, output: 3.28 toks/s]
Processed prompts:  16%|        | 325/2048 [01:39<09:29,  3.03it/s, est. speed input: 3339.86 toks/s, output: 3.26 toks/s]
Processed prompts:  17%|        | 341/2048 [01:44<09:25,  3.02it/s, est. speed input: 3326.20 toks/s, output: 3.25 toks/s]
Processed prompts:  17%|        | 357/2048 [01:50<09:21,  3.01it/s, est. speed input: 3313.71 toks/s, output: 3.24 toks/s]
Processed prompts:  18%|        | 373/2048 [01:55<09:17,  3.01it/s, est. speed input: 3302.46 toks/s, output: 3.23 toks/s]
Processed prompts:  19%|        | 389/2048 [02:00<09:12,  3.00it/s, est. speed input: 3292.25 toks/s, output: 3.22 toks/s]
Processed prompts:  20%|        | 405/2048 [02:06<09:07,  3.00it/s, est. speed input: 3282.75 toks/s, output: 3.21 toks/s]
Processed prompts:  21%|        | 421/2048 [02:11<08:53,  3.05it/s, est. speed input: 3280.91 toks/s, output: 3.20 toks/s]
Processed prompts:  21%|       | 437/2048 [02:16<08:51,  3.03it/s, est. speed input: 3272.69 toks/s, output: 3.20 toks/s]
Processed prompts:  22%|       | 453/2048 [02:22<08:47,  3.02it/s, est. speed input: 3265.10 toks/s, output: 3.19 toks/s]
Processed prompts:  23%|       | 469/2048 [02:27<08:43,  3.02it/s, est. speed input: 3258.08 toks/s, output: 3.18 toks/s]
Processed prompts:  24%|       | 485/2048 [02:32<08:39,  3.01it/s, est. speed input: 3251.35 toks/s, output: 3.18 toks/s]
Processed prompts:  24%|       | 501/2048 [02:38<08:34,  3.01it/s, est. speed input: 3245.34 toks/s, output: 3.17 toks/s]
Processed prompts:  25%|       | 517/2048 [02:43<08:29,  3.00it/s, est. speed input: 3239.66 toks/s, output: 3.16 toks/s]
Processed prompts:  26%|       | 533/2048 [02:48<08:24,  3.00it/s, est. speed input: 3234.27 toks/s, output: 3.16 toks/s]
Processed prompts:  27%|       | 549/2048 [02:54<08:19,  3.00it/s, est. speed input: 3229.21 toks/s, output: 3.15 toks/s]
Processed prompts:  28%|       | 565/2048 [02:59<08:14,  3.00it/s, est. speed input: 3224.42 toks/s, output: 3.15 toks/s]
Processed prompts:  28%|       | 581/2048 [03:04<08:09,  3.00it/s, est. speed input: 3219.94 toks/s, output: 3.14 toks/s]
Processed prompts:  29%|       | 597/2048 [03:10<08:04,  3.00it/s, est. speed input: 3215.61 toks/s, output: 3.14 toks/s]
Processed prompts:  30%|       | 613/2048 [03:15<07:58,  3.00it/s, est. speed input: 3211.68 toks/s, output: 3.14 toks/s]
Processed prompts:  31%|       | 629/2048 [03:20<07:53,  3.00it/s, est. speed input: 3207.86 toks/s, output: 3.13 toks/s]
Processed prompts:  31%|      | 645/2048 [03:26<07:47,  3.00it/s, est. speed input: 3204.36 toks/s, output: 3.13 toks/s]
Processed prompts:  32%|      | 661/2048 [03:31<07:42,  3.00it/s, est. speed input: 3200.92 toks/s, output: 3.13 toks/s]
Processed prompts:  33%|      | 677/2048 [03:36<07:37,  3.00it/s, est. speed input: 3197.67 toks/s, output: 3.12 toks/s]
Processed prompts:  34%|      | 693/2048 [03:42<07:32,  3.00it/s, est. speed input: 3194.44 toks/s, output: 3.12 toks/s]
Processed prompts:  35%|      | 709/2048 [03:47<07:26,  3.00it/s, est. speed input: 3191.51 toks/s, output: 3.12 toks/s]
Processed prompts:  35%|      | 725/2048 [03:52<07:21,  3.00it/s, est. speed input: 3188.66 toks/s, output: 3.11 toks/s]
Processed prompts:  36%|      | 741/2048 [03:58<07:16,  3.00it/s, est. speed input: 3185.88 toks/s, output: 3.11 toks/s]
Processed prompts:  37%|      | 757/2048 [04:03<07:11,  2.99it/s, est. speed input: 3183.20 toks/s, output: 3.11 toks/s]
Processed prompts:  38%|      | 773/2048 [04:08<06:59,  3.04it/s, est. speed input: 3184.24 toks/s, output: 3.11 toks/s]
Processed prompts:  39%|      | 789/2048 [04:13<06:55,  3.03it/s, est. speed input: 3181.77 toks/s, output: 3.11 toks/s]
Processed prompts:  39%|      | 805/2048 [04:19<06:51,  3.02it/s, est. speed input: 3179.38 toks/s, output: 3.10 toks/s]
Processed prompts:  40%|      | 821/2048 [04:24<06:47,  3.01it/s, est. speed input: 3177.09 toks/s, output: 3.10 toks/s]
Processed prompts:  41%|      | 837/2048 [04:29<06:42,  3.01it/s, est. speed input: 3174.91 toks/s, output: 3.10 toks/s]
Processed prompts:  42%|     | 853/2048 [04:35<06:38,  3.00it/s, est. speed input: 3172.81 toks/s, output: 3.10 toks/s]
Processed prompts:  42%|     | 869/2048 [04:40<06:32,  3.00it/s, est. speed input: 3170.79 toks/s, output: 3.10 toks/s]
Processed prompts:  43%|     | 885/2048 [04:45<06:27,  3.00it/s, est. speed input: 3168.83 toks/s, output: 3.09 toks/s]
Processed prompts:  44%|     | 901/2048 [04:51<06:22,  3.00it/s, est. speed input: 3166.97 toks/s, output: 3.09 toks/s]
Processed prompts:  45%|     | 917/2048 [04:56<06:17,  3.00it/s, est. speed input: 3165.15 toks/s, output: 3.09 toks/s]
Processed prompts:  46%|     | 933/2048 [05:02<06:12,  3.00it/s, est. speed input: 3163.45 toks/s, output: 3.09 toks/s]
Processed prompts:  46%|     | 949/2048 [05:07<06:06,  3.00it/s, est. speed input: 3161.74 toks/s, output: 3.09 toks/s]
Processed prompts:  47%|     | 965/2048 [05:12<06:01,  3.00it/s, est. speed input: 3160.10 toks/s, output: 3.09 toks/s]
Processed prompts:  48%|     | 981/2048 [05:18<05:56,  2.99it/s, est. speed input: 3158.50 toks/s, output: 3.08 toks/s]
Processed prompts:  49%|     | 997/2048 [05:23<05:51,  2.99it/s, est. speed input: 3156.91 toks/s, output: 3.08 toks/s]
Processed prompts:  49%|     | 1013/2048 [05:28<05:45,  2.99it/s, est. speed input: 3155.43 toks/s, output: 3.08 toks/s]
Processed prompts:  50%|     | 1029/2048 [05:34<05:40,  2.99it/s, est. speed input: 3154.01 toks/s, output: 3.08 toks/s]
Processed prompts:  51%|     | 1045/2048 [05:39<05:34,  2.99it/s, est. speed input: 3152.63 toks/s, output: 3.08 toks/s]
Processed prompts:  52%|    | 1061/2048 [05:44<05:29,  2.99it/s, est. speed input: 3151.28 toks/s, output: 3.08 toks/s]
Processed prompts:  53%|    | 1077/2048 [05:50<05:24,  2.99it/s, est. speed input: 3149.97 toks/s, output: 3.08 toks/s]
Processed prompts:  53%|    | 1093/2048 [05:55<05:19,  2.99it/s, est. speed input: 3148.67 toks/s, output: 3.07 toks/s]
Processed prompts:  54%|    | 1109/2048 [06:00<05:13,  2.99it/s, est. speed input: 3147.43 toks/s, output: 3.07 toks/s]
Processed prompts:  55%|    | 1125/2048 [06:06<05:08,  2.99it/s, est. speed input: 3146.25 toks/s, output: 3.07 toks/s]
Processed prompts:  56%|    | 1141/2048 [06:11<05:03,  2.99it/s, est. speed input: 3145.06 toks/s, output: 3.07 toks/s]
Processed prompts:  56%|    | 1157/2048 [06:16<04:57,  2.99it/s, est. speed input: 3143.92 toks/s, output: 3.07 toks/s]
Processed prompts:  57%|    | 1173/2048 [06:22<04:52,  2.99it/s, est. speed input: 3142.79 toks/s, output: 3.07 toks/s]
Processed prompts:  58%|    | 1189/2048 [06:27<04:47,  2.99it/s, est. speed input: 3141.69 toks/s, output: 3.07 toks/s]
Processed prompts:  59%|    | 1205/2048 [06:32<04:37,  3.04it/s, est. speed input: 3142.81 toks/s, output: 3.07 toks/s]
Processed prompts:  60%|    | 1221/2048 [06:37<04:33,  3.02it/s, est. speed input: 3141.76 toks/s, output: 3.07 toks/s]
Processed prompts:  60%|    | 1237/2048 [06:43<04:28,  3.01it/s, est. speed input: 3140.73 toks/s, output: 3.07 toks/s]
Processed prompts:  61%|    | 1253/2048 [06:48<04:24,  3.01it/s, est. speed input: 3139.74 toks/s, output: 3.07 toks/s]
Processed prompts:  62%|   | 1269/2048 [06:54<04:19,  3.00it/s, est. speed input: 3138.77 toks/s, output: 3.07 toks/s]
Processed prompts:  63%|   | 1285/2048 [06:59<04:14,  3.00it/s, est. speed input: 3137.72 toks/s, output: 3.06 toks/s]
Processed prompts:  64%|   | 1301/2048 [07:04<04:09,  3.00it/s, est. speed input: 3136.83 toks/s, output: 3.06 toks/s]
Processed prompts:  64%|   | 1317/2048 [07:10<04:04,  3.00it/s, est. speed input: 3135.93 toks/s, output: 3.06 toks/s]
Processed prompts:  65%|   | 1333/2048 [07:15<03:58,  3.00it/s, est. speed input: 3135.10 toks/s, output: 3.06 toks/s]
Processed prompts:  66%|   | 1349/2048 [07:20<03:53,  2.99it/s, est. speed input: 3134.24 toks/s, output: 3.06 toks/s]
Processed prompts:  67%|   | 1365/2048 [07:26<03:48,  3.00it/s, est. speed input: 3133.44 toks/s, output: 3.06 toks/s]
Processed prompts:  67%|   | 1381/2048 [07:31<03:42,  2.99it/s, est. speed input: 3132.62 toks/s, output: 3.06 toks/s]
Processed prompts:  68%|   | 1397/2048 [07:36<03:37,  2.99it/s, est. speed input: 3131.86 toks/s, output: 3.06 toks/s]
Processed prompts:  69%|   | 1413/2048 [07:42<03:32,  2.99it/s, est. speed input: 3131.05 toks/s, output: 3.06 toks/s]
Processed prompts:  70%|   | 1429/2048 [07:47<03:26,  2.99it/s, est. speed input: 3130.28 toks/s, output: 3.06 toks/s]
Processed prompts:  71%|   | 1445/2048 [07:52<03:21,  2.99it/s, est. speed input: 3129.55 toks/s, output: 3.06 toks/s]
Processed prompts:  71%|  | 1461/2048 [07:58<03:16,  2.99it/s, est. speed input: 3128.84 toks/s, output: 3.06 toks/s]
Processed prompts:  72%|  | 1477/2048 [08:03<03:10,  2.99it/s, est. speed input: 3128.13 toks/s, output: 3.05 toks/s]
Processed prompts:  73%|  | 1493/2048 [08:08<03:05,  2.99it/s, est. speed input: 3127.47 toks/s, output: 3.05 toks/s]
Processed prompts:  74%|  | 1509/2048 [08:14<03:00,  2.99it/s, est. speed input: 3126.77 toks/s, output: 3.05 toks/s]
Processed prompts:  74%|  | 1525/2048 [08:19<02:54,  2.99it/s, est. speed input: 3126.09 toks/s, output: 3.05 toks/s]
Processed prompts:  75%|  | 1541/2048 [08:24<02:49,  2.99it/s, est. speed input: 3125.41 toks/s, output: 3.05 toks/s]
Processed prompts:  76%|  | 1557/2048 [08:29<02:41,  3.04it/s, est. speed input: 3126.49 toks/s, output: 3.05 toks/s]
Processed prompts:  77%|  | 1573/2048 [08:35<02:36,  3.03it/s, est. speed input: 3125.85 toks/s, output: 3.05 toks/s]
Processed prompts:  78%|  | 1589/2048 [08:40<02:32,  3.02it/s, est. speed input: 3125.25 toks/s, output: 3.05 toks/s]
Processed prompts:  78%|  | 1605/2048 [08:45<02:27,  3.01it/s, est. speed input: 3124.60 toks/s, output: 3.05 toks/s]
Processed prompts:  79%|  | 1621/2048 [08:51<02:19,  3.05it/s, est. speed input: 3125.59 toks/s, output: 3.05 toks/s]
Processed prompts:  80%|  | 1637/2048 [08:56<02:15,  3.03it/s, est. speed input: 3124.97 toks/s, output: 3.05 toks/s]
Processed prompts:  81%|  | 1653/2048 [09:01<02:10,  3.02it/s, est. speed input: 3124.35 toks/s, output: 3.05 toks/s]
Processed prompts:  81%| | 1669/2048 [09:07<02:05,  3.01it/s, est. speed input: 3123.75 toks/s, output: 3.05 toks/s]
Processed prompts:  82%| | 1685/2048 [09:12<02:00,  3.00it/s, est. speed input: 3123.07 toks/s, output: 3.05 toks/s]
Processed prompts:  83%| | 1701/2048 [09:17<01:55,  3.00it/s, est. speed input: 3122.46 toks/s, output: 3.05 toks/s]
Processed prompts:  84%| | 1717/2048 [09:23<01:50,  3.00it/s, est. speed input: 3121.87 toks/s, output: 3.05 toks/s]
Processed prompts:  85%| | 1733/2048 [09:28<01:45,  2.99it/s, est. speed input: 3121.33 toks/s, output: 3.05 toks/s]
Processed prompts:  85%| | 1749/2048 [09:33<01:38,  3.04it/s, est. speed input: 3122.29 toks/s, output: 3.05 toks/s]
Processed prompts:  86%| | 1765/2048 [09:38<01:33,  3.03it/s, est. speed input: 3121.75 toks/s, output: 3.05 toks/s]
Processed prompts:  87%| | 1781/2048 [09:44<01:28,  3.02it/s, est. speed input: 3121.23 toks/s, output: 3.05 toks/s]
Processed prompts:  88%| | 1797/2048 [09:49<01:23,  3.01it/s, est. speed input: 3120.71 toks/s, output: 3.05 toks/s]
Processed prompts:  89%| | 1813/2048 [09:54<01:18,  3.00it/s, est. speed input: 3120.19 toks/s, output: 3.05 toks/s]
Processed prompts:  89%| | 1829/2048 [10:00<01:12,  3.00it/s, est. speed input: 3119.71 toks/s, output: 3.05 toks/s]
Processed prompts:  90%| | 1845/2048 [10:05<01:07,  3.00it/s, est. speed input: 3119.22 toks/s, output: 3.05 toks/s]
Processed prompts:  91%| | 1861/2048 [10:11<01:02,  3.00it/s, est. speed input: 3118.72 toks/s, output: 3.05 toks/s]
Processed prompts:  92%|| 1877/2048 [10:16<00:57,  2.99it/s, est. speed input: 3118.24 toks/s, output: 3.05 toks/s]
Processed prompts:  92%|| 1893/2048 [10:21<00:51,  2.99it/s, est. speed input: 3117.78 toks/s, output: 3.04 toks/s]
Processed prompts:  93%|| 1909/2048 [10:27<00:46,  2.99it/s, est. speed input: 3117.33 toks/s, output: 3.04 toks/s]
Processed prompts:  94%|| 1925/2048 [10:32<00:41,  2.99it/s, est. speed input: 3116.88 toks/s, output: 3.04 toks/s]
Processed prompts:  95%|| 1941/2048 [10:37<00:35,  2.99it/s, est. speed input: 3116.43 toks/s, output: 3.04 toks/s]
Processed prompts:  96%|| 1957/2048 [10:43<00:30,  2.99it/s, est. speed input: 3115.97 toks/s, output: 3.04 toks/s]
Processed prompts:  96%|| 1973/2048 [10:48<00:25,  2.99it/s, est. speed input: 3115.59 toks/s, output: 3.04 toks/s]
Processed prompts:  97%|| 1989/2048 [10:53<00:19,  2.99it/s, est. speed input: 3115.16 toks/s, output: 3.04 toks/s]
Processed prompts:  98%|| 2005/2048 [10:59<00:14,  2.99it/s, est. speed input: 3114.71 toks/s, output: 3.04 toks/s]
Processed prompts:  99%|| 2021/2048 [11:04<00:09,  2.99it/s, est. speed input: 3114.27 toks/s, output: 3.04 toks/s]
Processed prompts:  99%|| 2037/2048 [11:08<00:03,  3.23it/s, est. speed input: 3120.02 toks/s, output: 3.05 toks/s]
Processed prompts: 100%|| 2048/2048 [11:08<00:00,  3.23it/s, est. speed input: 3136.87 toks/s, output: 3.06 toks/s]
Processed prompts: 100%|| 2048/2048 [11:08<00:00,  3.06it/s, est. speed input: 3136.87 toks/s, output: 3.06 toks/s]
[rank0]:[W127 14:02:19.139218646 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-27 14:02:25
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Qwen2.5-14B-FP8_M32768.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-27 14:02:46 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-27 14:02:46 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=2689727) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2689727) WARNING 01-27 14:05:31 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 2.95 requests/s, 3026.51 total tokens/s, 2.95 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-27 14:02:46] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 14:02:46] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 14:02:46] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 14:02:46] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 14:02:46] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 14:02:46] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 14:02:46] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 14:02:46] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 14:02:46] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 14:02:46] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 14:02:46] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 14:02:46] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 14:02:46] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 14:02:46] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-27 14:02:50] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 14:02:50] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 14:02:50] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 14:02:50] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 14:02:50] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 14:02:50] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 14:02:50] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 14:02:50] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 14:02:50] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 14:02:50] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 14:02:50] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 14:02:50] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 14:02:50] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 14:02:50] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=2689727) [2026-01-27 14:02:51] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=2689727) [2026-01-27 14:02:51] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2689727) [2026-01-27 14:02:51] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=2689727) [2026-01-27 14:02:51] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=2689727) [2026-01-27 14:02:51] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=2689727) [2026-01-27 14:02:51] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=2689727) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=2689727) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:26,  8.78s/it]
(EngineCore_DP0 pid=2689727) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:41<00:46, 23.15s/it]
(EngineCore_DP0 pid=2689727) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [01:18<00:29, 29.18s/it]
(EngineCore_DP0 pid=2689727) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [02:00<00:00, 34.17s/it]
(EngineCore_DP0 pid=2689727) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [02:00<00:00, 30.04s/it]
(EngineCore_DP0 pid=2689727) 
(EngineCore_DP0 pid=2689727) [2026-01-27 14:04:53] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 8192] -> 1D uint8
(EngineCore_DP0 pid=2689727) [2026-01-27 14:04:53] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 36700160 bytes
(EngineCore_DP0 pid=2689727) [2026-01-27 14:04:53] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 8192] -> 1D uint8
(EngineCore_DP0 pid=2689727) [2026-01-27 14:04:53] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 26214400 bytes
(EngineCore_DP0 pid=2689727) [2026-01-27 14:04:53] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 8192] -> 1D uint8
(EngineCore_DP0 pid=2689727) [2026-01-27 14:04:53] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 141557760 bytes
(EngineCore_DP0 pid=2689727) [2026-01-27 14:04:53] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 22144] -> 1D uint8
(EngineCore_DP0 pid=2689727) [2026-01-27 14:04:53] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 70860800 bytes
(EngineCore_DP0 pid=2689727) 2026-01-27 14:05:10,700 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=2689727) 2026-01-27 14:05:16,678 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   0%|          | 1/4096 [00:00<59:48,  1.14it/s]
Adding requests:   0%|          | 2/4096 [00:01<33:56,  2.01it/s]
Adding requests:   0%|          | 3/4096 [00:01<23:09,  2.95it/s]
Adding requests:   0%|          | 5/4096 [00:01<13:20,  5.11it/s]
Adding requests:   0%|          | 7/4096 [00:01<09:17,  7.34it/s]
Adding requests:   0%|          | 10/4096 [00:01<06:00, 11.35it/s]
Adding requests:   0%|          | 14/4096 [00:01<04:02, 16.84it/s]
Adding requests:   1%|          | 24/4096 [00:01<01:54, 35.41it/s]
Adding requests:   1%|          | 49/4096 [00:01<00:46, 87.05it/s]
Adding requests:   2%|         | 78/4096 [00:02<00:28, 138.78it/s]
Adding requests:   3%|         | 111/4096 [00:02<00:21, 188.76it/s]
Adding requests:   4%|         | 145/4096 [00:02<00:17, 229.37it/s]
Adding requests:   5%|         | 192/4096 [00:02<00:13, 296.89it/s]
Adding requests:   6%|         | 230/4096 [00:02<00:12, 319.96it/s]
Adding requests:   7%|         | 271/4096 [00:02<00:11, 345.32it/s]
Adding requests:   8%|         | 310/4096 [00:02<00:10, 356.22it/s]
Adding requests:   9%|         | 353/4096 [00:02<00:09, 375.80it/s]
Adding requests:  10%|         | 399/4096 [00:02<00:09, 397.85it/s]
Adding requests:  11%|         | 441/4096 [00:03<00:09, 403.18it/s]
Adding requests:  12%|        | 486/4096 [00:03<00:08, 416.02it/s]
Adding requests:  13%|        | 530/4096 [00:03<00:08, 421.98it/s]
Adding requests:  14%|        | 575/4096 [00:03<00:08, 430.12it/s]
Adding requests:  15%|        | 619/4096 [00:03<00:08, 424.10it/s]
Adding requests:  16%|        | 662/4096 [00:03<00:08, 413.53it/s]
Adding requests:  17%|        | 704/4096 [00:03<00:08, 413.88it/s]
Adding requests:  18%|        | 749/4096 [00:03<00:07, 422.66it/s]
Adding requests:  19%|        | 792/4096 [00:03<00:07, 413.83it/s]
Adding requests:  20%|        | 839/4096 [00:03<00:07, 427.41it/s]
Adding requests:  22%|       | 882/4096 [00:04<00:07, 424.55it/s]
Adding requests:  23%|       | 925/4096 [00:04<00:07, 419.98it/s]
Adding requests:  24%|       | 969/4096 [00:04<00:07, 423.92it/s]
Adding requests:  25%|       | 1012/4096 [00:04<00:07, 416.35it/s]
Adding requests:  26%|       | 1054/4096 [00:04<00:07, 414.38it/s]
Adding requests:  27%|       | 1096/4096 [00:04<00:07, 409.76it/s]
Adding requests:  28%|       | 1139/4096 [00:04<00:07, 412.86it/s]
Adding requests:  29%|       | 1181/4096 [00:04<00:07, 397.31it/s]
Adding requests:  30%|       | 1222/4096 [00:04<00:07, 399.66it/s]
Adding requests:  31%|       | 1263/4096 [00:04<00:07, 391.04it/s]
Adding requests:  32%|      | 1303/4096 [00:05<00:07, 385.89it/s]
Adding requests:  33%|      | 1342/4096 [00:05<00:07, 386.76it/s]
Adding requests:  34%|      | 1390/4096 [00:05<00:06, 413.47it/s]
Adding requests:  35%|      | 1432/4096 [00:05<00:06, 399.55it/s]
Adding requests:  36%|      | 1478/4096 [00:05<00:06, 414.83it/s]
Adding requests:  37%|      | 1520/4096 [00:05<00:06, 413.78it/s]
Adding requests:  38%|      | 1565/4096 [00:05<00:05, 423.85it/s]
Adding requests:  39%|      | 1608/4096 [00:05<00:06, 414.09it/s]
Adding requests:  40%|      | 1650/4096 [00:05<00:05, 411.11it/s]
Adding requests:  41%|     | 1692/4096 [00:06<00:05, 409.91it/s]
Adding requests:  42%|     | 1735/4096 [00:06<00:05, 413.10it/s]
Adding requests:  43%|     | 1781/4096 [00:06<00:05, 425.61it/s]
Adding requests:  45%|     | 1824/4096 [00:06<00:05, 418.47it/s]
Adding requests:  46%|     | 1868/4096 [00:06<00:05, 422.87it/s]
Adding requests:  47%|     | 1911/4096 [00:06<00:05, 417.54it/s]
Adding requests:  48%|     | 1960/4096 [00:06<00:04, 436.57it/s]
Adding requests:  49%|     | 2004/4096 [00:06<00:05, 411.30it/s]
Adding requests:  50%|     | 2050/4096 [00:06<00:04, 421.02it/s]
Adding requests:  51%|     | 2093/4096 [00:06<00:04, 409.03it/s]
Adding requests:  52%|    | 2139/4096 [00:07<00:04, 423.40it/s]
Adding requests:  53%|    | 2182/4096 [00:07<00:04, 404.89it/s]
Adding requests:  54%|    | 2227/4096 [00:07<00:04, 415.15it/s]
Adding requests:  55%|    | 2269/4096 [00:07<00:04, 407.36it/s]
Adding requests:  56%|    | 2314/4096 [00:07<00:04, 418.42it/s]
Adding requests:  58%|    | 2357/4096 [00:07<00:04, 412.60it/s]
Adding requests:  59%|    | 2402/4096 [00:07<00:04, 423.27it/s]
Adding requests:  60%|    | 2445/4096 [00:07<00:03, 424.92it/s]
Adding requests:  61%|    | 2488/4096 [00:07<00:03, 418.98it/s]
Adding requests:  62%|   | 2536/4096 [00:08<00:03, 436.25it/s]
Adding requests:  63%|   | 2580/4096 [00:08<00:03, 404.87it/s]
Adding requests:  64%|   | 2625/4096 [00:08<00:03, 416.98it/s]
Adding requests:  65%|   | 2668/4096 [00:08<00:03, 412.00it/s]
Adding requests:  66%|   | 2712/4096 [00:08<00:03, 417.27it/s]
Adding requests:  67%|   | 2754/4096 [00:08<00:03, 417.71it/s]
Adding requests:  68%|   | 2804/4096 [00:08<00:02, 439.62it/s]
Adding requests:  70%|   | 2849/4096 [00:08<00:02, 432.30it/s]
Adding requests:  71%|   | 2896/4096 [00:08<00:02, 441.33it/s]
Adding requests:  72%|  | 2941/4096 [00:08<00:02, 431.84it/s]
Adding requests:  73%|  | 2989/4096 [00:09<00:02, 444.65it/s]
Adding requests:  74%|  | 3034/4096 [00:09<00:02, 425.89it/s]
Adding requests:  75%|  | 3079/4096 [00:09<00:02, 431.12it/s]
Adding requests:  76%|  | 3123/4096 [00:09<00:02, 426.62it/s]
Adding requests:  77%|  | 3166/4096 [00:09<00:02, 416.17it/s]
Adding requests:  78%|  | 3208/4096 [00:09<00:02, 412.35it/s]
Adding requests:  79%|  | 3253/4096 [00:09<00:02, 420.63it/s]
Adding requests:  80%|  | 3296/4096 [00:09<00:01, 419.25it/s]
Adding requests:  81%| | 3338/4096 [00:09<00:01, 416.69it/s]
Adding requests:  83%| | 3383/4096 [00:10<00:01, 425.89it/s]
Adding requests:  84%| | 3426/4096 [00:10<00:01, 421.84it/s]
Adding requests:  85%| | 3475/4096 [00:10<00:01, 440.99it/s]
Adding requests:  86%| | 3520/4096 [00:10<00:01, 427.67it/s]
Adding requests:  87%| | 3568/4096 [00:10<00:01, 440.61it/s]
Adding requests:  88%| | 3613/4096 [00:10<00:01, 426.74it/s]
Adding requests:  89%| | 3658/4096 [00:10<00:01, 431.55it/s]
Adding requests:  90%| | 3702/4096 [00:10<00:00, 426.13it/s]
Adding requests:  91%|| 3745/4096 [00:10<00:00, 426.47it/s]
Adding requests:  92%|| 3788/4096 [00:10<00:00, 419.35it/s]
Adding requests:  94%|| 3830/4096 [00:11<00:00, 406.24it/s]
Adding requests:  95%|| 3875/4096 [00:11<00:00, 416.50it/s]
Adding requests:  96%|| 3917/4096 [00:11<00:00, 399.90it/s]
Adding requests:  97%|| 3958/4096 [00:11<00:00, 395.97it/s]
Adding requests:  98%|| 4000/4096 [00:11<00:00, 401.67it/s]
Adding requests:  99%|| 4044/4096 [00:11<00:00, 410.74it/s]
Adding requests: 100%|| 4086/4096 [00:11<00:00, 399.16it/s]
Adding requests: 100%|| 4096/4096 [00:11<00:00, 348.37it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 4/4096 [00:01<18:19,  3.72it/s, est. speed input: 3812.00 toks/s, output: 3.72 toks/s]
Processed prompts:   1%|          | 36/4096 [00:11<22:26,  3.02it/s, est. speed input: 3107.33 toks/s, output: 3.03 toks/s]
Processed prompts:   2%|         | 68/4096 [00:22<22:28,  2.99it/s, est. speed input: 3073.52 toks/s, output: 3.00 toks/s]
Processed prompts:   2%|         | 100/4096 [00:33<22:24,  2.97it/s, est. speed input: 3058.59 toks/s, output: 2.99 toks/s]
Processed prompts:   3%|         | 132/4096 [00:44<22:16,  2.97it/s, est. speed input: 3051.10 toks/s, output: 2.98 toks/s]
Processed prompts:   4%|         | 164/4096 [00:55<22:07,  2.96it/s, est. speed input: 3045.84 toks/s, output: 2.97 toks/s]
Processed prompts:   5%|         | 196/4096 [01:05<21:49,  2.98it/s, est. speed input: 3051.99 toks/s, output: 2.98 toks/s]
Processed prompts:   6%|         | 228/4096 [01:16<21:42,  2.97it/s, est. speed input: 3047.28 toks/s, output: 2.98 toks/s]
Processed prompts:   6%|         | 260/4096 [01:27<21:35,  2.96it/s, est. speed input: 3043.74 toks/s, output: 2.97 toks/s]
Processed prompts:   7%|         | 292/4096 [01:38<21:17,  2.98it/s, est. speed input: 3048.63 toks/s, output: 2.98 toks/s]
Processed prompts:   8%|         | 324/4096 [01:48<21:10,  2.97it/s, est. speed input: 3045.84 toks/s, output: 2.97 toks/s]
Processed prompts:   9%|         | 356/4096 [01:59<21:01,  2.96it/s, est. speed input: 3043.80 toks/s, output: 2.97 toks/s]
Processed prompts:   9%|         | 388/4096 [02:10<20:52,  2.96it/s, est. speed input: 3041.92 toks/s, output: 2.97 toks/s]
Processed prompts:  10%|         | 420/4096 [02:21<20:34,  2.98it/s, est. speed input: 3045.71 toks/s, output: 2.97 toks/s]
Processed prompts:  11%|         | 452/4096 [02:32<20:27,  2.97it/s, est. speed input: 3043.86 toks/s, output: 2.97 toks/s]
Processed prompts:  12%|        | 484/4096 [02:42<20:19,  2.96it/s, est. speed input: 3042.22 toks/s, output: 2.97 toks/s]
Processed prompts:  13%|        | 516/4096 [02:53<20:09,  2.96it/s, est. speed input: 3040.96 toks/s, output: 2.97 toks/s]
Processed prompts:  13%|        | 548/4096 [03:04<19:59,  2.96it/s, est. speed input: 3039.88 toks/s, output: 2.97 toks/s]
Processed prompts:  14%|        | 580/4096 [03:15<19:49,  2.95it/s, est. speed input: 3038.79 toks/s, output: 2.97 toks/s]
Processed prompts:  15%|        | 612/4096 [03:26<19:40,  2.95it/s, est. speed input: 3037.65 toks/s, output: 2.97 toks/s]
Processed prompts:  16%|        | 644/4096 [03:37<19:29,  2.95it/s, est. speed input: 3036.68 toks/s, output: 2.97 toks/s]
Processed prompts:  17%|        | 676/4096 [03:48<19:19,  2.95it/s, est. speed input: 3035.84 toks/s, output: 2.96 toks/s]
Processed prompts:  17%|        | 708/4096 [03:58<19:08,  2.95it/s, est. speed input: 3035.11 toks/s, output: 2.96 toks/s]
Processed prompts:  18%|        | 740/4096 [04:09<18:58,  2.95it/s, est. speed input: 3034.36 toks/s, output: 2.96 toks/s]
Processed prompts:  19%|        | 772/4096 [04:20<18:39,  2.97it/s, est. speed input: 3036.71 toks/s, output: 2.97 toks/s]
Processed prompts:  20%|        | 804/4096 [04:31<18:30,  2.96it/s, est. speed input: 3036.01 toks/s, output: 2.96 toks/s]
Processed prompts:  20%|        | 836/4096 [04:42<18:21,  2.96it/s, est. speed input: 3035.44 toks/s, output: 2.96 toks/s]
Processed prompts:  21%|        | 868/4096 [04:52<18:11,  2.96it/s, est. speed input: 3034.88 toks/s, output: 2.96 toks/s]
Processed prompts:  22%|       | 900/4096 [05:03<18:02,  2.95it/s, est. speed input: 3034.28 toks/s, output: 2.96 toks/s]
Processed prompts:  23%|       | 932/4096 [05:14<17:51,  2.95it/s, est. speed input: 3033.71 toks/s, output: 2.96 toks/s]
Processed prompts:  24%|       | 964/4096 [05:25<17:41,  2.95it/s, est. speed input: 3033.07 toks/s, output: 2.96 toks/s]
Processed prompts:  24%|       | 996/4096 [05:36<17:31,  2.95it/s, est. speed input: 3032.56 toks/s, output: 2.96 toks/s]
Processed prompts:  25%|       | 1028/4096 [05:47<17:20,  2.95it/s, est. speed input: 3032.09 toks/s, output: 2.96 toks/s]
Processed prompts:  26%|       | 1060/4096 [05:58<17:09,  2.95it/s, est. speed input: 3031.71 toks/s, output: 2.96 toks/s]
Processed prompts:  27%|       | 1092/4096 [06:08<16:58,  2.95it/s, est. speed input: 3031.33 toks/s, output: 2.96 toks/s]
Processed prompts:  27%|       | 1124/4096 [06:19<16:48,  2.95it/s, est. speed input: 3030.81 toks/s, output: 2.96 toks/s]
Processed prompts:  28%|       | 1156/4096 [06:30<16:37,  2.95it/s, est. speed input: 3030.43 toks/s, output: 2.96 toks/s]
Processed prompts:  29%|       | 1188/4096 [06:41<16:20,  2.97it/s, est. speed input: 3031.92 toks/s, output: 2.96 toks/s]
Processed prompts:  30%|       | 1220/4096 [06:52<16:11,  2.96it/s, est. speed input: 3031.59 toks/s, output: 2.96 toks/s]
Processed prompts:  31%|       | 1252/4096 [07:02<16:01,  2.96it/s, est. speed input: 3031.24 toks/s, output: 2.96 toks/s]
Processed prompts:  31%|      | 1284/4096 [07:13<15:51,  2.95it/s, est. speed input: 3030.90 toks/s, output: 2.96 toks/s]
Processed prompts:  32%|      | 1316/4096 [07:24<15:42,  2.95it/s, est. speed input: 3030.52 toks/s, output: 2.96 toks/s]
Processed prompts:  33%|      | 1348/4096 [07:35<15:31,  2.95it/s, est. speed input: 3030.19 toks/s, output: 2.96 toks/s]
Processed prompts:  34%|      | 1380/4096 [07:46<15:21,  2.95it/s, est. speed input: 3029.83 toks/s, output: 2.96 toks/s]
Processed prompts:  34%|      | 1412/4096 [07:57<15:10,  2.95it/s, est. speed input: 3029.56 toks/s, output: 2.96 toks/s]
Processed prompts:  35%|      | 1444/4096 [08:08<15:00,  2.95it/s, est. speed input: 3029.21 toks/s, output: 2.96 toks/s]
Processed prompts:  36%|      | 1476/4096 [08:19<14:49,  2.95it/s, est. speed input: 3028.90 toks/s, output: 2.96 toks/s]
Processed prompts:  37%|      | 1508/4096 [08:29<14:38,  2.95it/s, est. speed input: 3028.66 toks/s, output: 2.96 toks/s]
Processed prompts:  38%|      | 1540/4096 [08:40<14:21,  2.97it/s, est. speed input: 3029.85 toks/s, output: 2.96 toks/s]
Processed prompts:  38%|      | 1572/4096 [08:51<14:12,  2.96it/s, est. speed input: 3029.55 toks/s, output: 2.96 toks/s]
Processed prompts:  39%|      | 1604/4096 [09:01<13:57,  2.98it/s, est. speed input: 3030.72 toks/s, output: 2.96 toks/s]
Processed prompts:  40%|      | 1636/4096 [09:12<13:48,  2.97it/s, est. speed input: 3030.45 toks/s, output: 2.96 toks/s]
Processed prompts:  41%|      | 1668/4096 [09:23<13:40,  2.96it/s, est. speed input: 3030.13 toks/s, output: 2.96 toks/s]
Processed prompts:  42%|     | 1700/4096 [09:34<13:30,  2.96it/s, est. speed input: 3029.84 toks/s, output: 2.96 toks/s]
Processed prompts:  42%|     | 1732/4096 [09:45<13:15,  2.97it/s, est. speed input: 3030.87 toks/s, output: 2.96 toks/s]
Processed prompts:  43%|     | 1764/4096 [09:56<13:06,  2.96it/s, est. speed input: 3030.55 toks/s, output: 2.96 toks/s]
Processed prompts:  44%|     | 1796/4096 [10:06<12:57,  2.96it/s, est. speed input: 3030.29 toks/s, output: 2.96 toks/s]
Processed prompts:  45%|     | 1828/4096 [10:17<12:47,  2.95it/s, est. speed input: 3030.00 toks/s, output: 2.96 toks/s]
Processed prompts:  45%|     | 1860/4096 [10:28<12:37,  2.95it/s, est. speed input: 3029.73 toks/s, output: 2.96 toks/s]
Processed prompts:  46%|     | 1892/4096 [10:39<12:27,  2.95it/s, est. speed input: 3029.56 toks/s, output: 2.96 toks/s]
Processed prompts:  47%|     | 1924/4096 [10:50<12:16,  2.95it/s, est. speed input: 3029.29 toks/s, output: 2.96 toks/s]
Processed prompts:  48%|     | 1956/4096 [11:01<12:06,  2.95it/s, est. speed input: 3029.10 toks/s, output: 2.96 toks/s]
Processed prompts:  49%|     | 1988/4096 [11:12<11:55,  2.95it/s, est. speed input: 3028.85 toks/s, output: 2.96 toks/s]
Processed prompts:  49%|     | 2020/4096 [11:22<11:44,  2.95it/s, est. speed input: 3028.59 toks/s, output: 2.96 toks/s]
Processed prompts:  50%|     | 2052/4096 [11:33<11:34,  2.94it/s, est. speed input: 3028.36 toks/s, output: 2.96 toks/s]
Processed prompts:  51%|     | 2084/4096 [11:44<11:23,  2.94it/s, est. speed input: 3028.15 toks/s, output: 2.96 toks/s]
Processed prompts:  52%|    | 2116/4096 [11:55<11:12,  2.94it/s, est. speed input: 3027.98 toks/s, output: 2.96 toks/s]
Processed prompts:  52%|    | 2148/4096 [12:06<11:01,  2.94it/s, est. speed input: 3027.78 toks/s, output: 2.96 toks/s]
Processed prompts:  53%|    | 2180/4096 [12:17<10:46,  2.97it/s, est. speed input: 3028.65 toks/s, output: 2.96 toks/s]
Processed prompts:  54%|    | 2212/4096 [12:27<10:36,  2.96it/s, est. speed input: 3028.49 toks/s, output: 2.96 toks/s]
Processed prompts:  55%|    | 2244/4096 [12:38<10:26,  2.96it/s, est. speed input: 3028.32 toks/s, output: 2.96 toks/s]
Processed prompts:  56%|    | 2276/4096 [12:49<10:16,  2.95it/s, est. speed input: 3028.15 toks/s, output: 2.96 toks/s]
Processed prompts:  56%|    | 2308/4096 [13:00<10:06,  2.95it/s, est. speed input: 3027.96 toks/s, output: 2.96 toks/s]
Processed prompts:  57%|    | 2340/4096 [13:11<09:55,  2.95it/s, est. speed input: 3027.79 toks/s, output: 2.96 toks/s]
Processed prompts:  58%|    | 2372/4096 [13:22<09:44,  2.95it/s, est. speed input: 3027.61 toks/s, output: 2.96 toks/s]
Processed prompts:  59%|    | 2404/4096 [13:33<09:34,  2.95it/s, est. speed input: 3027.42 toks/s, output: 2.96 toks/s]
Processed prompts:  59%|    | 2436/4096 [13:44<09:23,  2.95it/s, est. speed input: 3027.25 toks/s, output: 2.96 toks/s]
Processed prompts:  60%|    | 2468/4096 [13:54<09:12,  2.95it/s, est. speed input: 3027.13 toks/s, output: 2.96 toks/s]
Processed prompts:  61%|    | 2500/4096 [14:05<09:01,  2.94it/s, est. speed input: 3026.95 toks/s, output: 2.96 toks/s]
Processed prompts:  62%|   | 2532/4096 [14:16<08:51,  2.94it/s, est. speed input: 3026.77 toks/s, output: 2.96 toks/s]
Processed prompts:  63%|   | 2564/4096 [14:27<08:40,  2.94it/s, est. speed input: 3026.63 toks/s, output: 2.96 toks/s]
Processed prompts:  63%|   | 2596/4096 [14:38<08:25,  2.96it/s, est. speed input: 3027.35 toks/s, output: 2.96 toks/s]
Processed prompts:  64%|   | 2628/4096 [14:48<08:16,  2.96it/s, est. speed input: 3027.20 toks/s, output: 2.96 toks/s]
Processed prompts:  65%|   | 2660/4096 [14:59<08:06,  2.95it/s, est. speed input: 3026.99 toks/s, output: 2.96 toks/s]
Processed prompts:  66%|   | 2692/4096 [15:10<07:55,  2.95it/s, est. speed input: 3026.88 toks/s, output: 2.96 toks/s]
Processed prompts:  67%|   | 2724/4096 [15:21<07:42,  2.97it/s, est. speed input: 3027.55 toks/s, output: 2.96 toks/s]
Processed prompts:  67%|   | 2756/4096 [15:32<07:32,  2.96it/s, est. speed input: 3027.43 toks/s, output: 2.96 toks/s]
Processed prompts:  68%|   | 2788/4096 [15:43<07:22,  2.96it/s, est. speed input: 3027.30 toks/s, output: 2.96 toks/s]
Processed prompts:  69%|   | 2820/4096 [15:53<07:12,  2.95it/s, est. speed input: 3027.11 toks/s, output: 2.96 toks/s]
Processed prompts:  70%|   | 2852/4096 [16:04<07:01,  2.95it/s, est. speed input: 3026.96 toks/s, output: 2.96 toks/s]
Processed prompts:  70%|   | 2884/4096 [16:15<06:48,  2.97it/s, est. speed input: 3027.61 toks/s, output: 2.96 toks/s]
Processed prompts:  71%|   | 2916/4096 [16:26<06:35,  2.98it/s, est. speed input: 3028.21 toks/s, output: 2.96 toks/s]
Processed prompts:  72%|  | 2948/4096 [16:36<06:26,  2.97it/s, est. speed input: 3028.05 toks/s, output: 2.96 toks/s]
Processed prompts:  73%|  | 2980/4096 [16:47<06:16,  2.96it/s, est. speed input: 3027.91 toks/s, output: 2.96 toks/s]
Processed prompts:  74%|  | 3012/4096 [16:58<06:06,  2.96it/s, est. speed input: 3027.78 toks/s, output: 2.96 toks/s]
Processed prompts:  74%|  | 3044/4096 [17:09<05:56,  2.95it/s, est. speed input: 3027.62 toks/s, output: 2.96 toks/s]
Processed prompts:  75%|  | 3076/4096 [17:20<05:45,  2.95it/s, est. speed input: 3027.47 toks/s, output: 2.96 toks/s]
Processed prompts:  76%|  | 3108/4096 [17:31<05:35,  2.95it/s, est. speed input: 3027.35 toks/s, output: 2.96 toks/s]
Processed prompts:  77%|  | 3140/4096 [17:42<05:24,  2.95it/s, est. speed input: 3027.22 toks/s, output: 2.96 toks/s]
Processed prompts:  77%|  | 3172/4096 [17:53<05:13,  2.95it/s, est. speed input: 3027.09 toks/s, output: 2.96 toks/s]
Processed prompts:  78%|  | 3204/4096 [18:03<05:02,  2.95it/s, est. speed input: 3026.98 toks/s, output: 2.96 toks/s]
Processed prompts:  79%|  | 3236/4096 [18:14<04:51,  2.95it/s, est. speed input: 3026.86 toks/s, output: 2.96 toks/s]
Processed prompts:  80%|  | 3268/4096 [18:25<04:41,  2.94it/s, est. speed input: 3026.73 toks/s, output: 2.96 toks/s]
Processed prompts:  81%|  | 3300/4096 [18:36<04:30,  2.95it/s, est. speed input: 3026.64 toks/s, output: 2.96 toks/s]
Processed prompts:  81%| | 3332/4096 [18:47<04:19,  2.94it/s, est. speed input: 3026.52 toks/s, output: 2.96 toks/s]
Processed prompts:  82%| | 3364/4096 [18:58<04:08,  2.95it/s, est. speed input: 3026.43 toks/s, output: 2.96 toks/s]
Processed prompts:  83%| | 3396/4096 [19:09<03:57,  2.95it/s, est. speed input: 3026.34 toks/s, output: 2.96 toks/s]
Processed prompts:  84%| | 3428/4096 [19:19<03:46,  2.94it/s, est. speed input: 3026.23 toks/s, output: 2.96 toks/s]
Processed prompts:  84%| | 3460/4096 [19:30<03:36,  2.94it/s, est. speed input: 3026.11 toks/s, output: 2.96 toks/s]
Processed prompts:  85%| | 3492/4096 [19:41<03:25,  2.94it/s, est. speed input: 3026.00 toks/s, output: 2.96 toks/s]
Processed prompts:  86%| | 3524/4096 [19:52<03:14,  2.94it/s, est. speed input: 3025.91 toks/s, output: 2.95 toks/s]
Processed prompts:  87%| | 3556/4096 [20:03<03:03,  2.94it/s, est. speed input: 3025.82 toks/s, output: 2.95 toks/s]
Processed prompts:  88%| | 3588/4096 [20:14<02:52,  2.94it/s, est. speed input: 3025.70 toks/s, output: 2.95 toks/s]
Processed prompts:  88%| | 3620/4096 [20:25<02:41,  2.94it/s, est. speed input: 3025.61 toks/s, output: 2.95 toks/s]
Processed prompts:  89%| | 3652/4096 [20:36<02:30,  2.94it/s, est. speed input: 3025.52 toks/s, output: 2.95 toks/s]
Processed prompts:  90%| | 3684/4096 [20:46<02:18,  2.97it/s, est. speed input: 3026.10 toks/s, output: 2.96 toks/s]
Processed prompts:  91%| | 3716/4096 [20:57<02:08,  2.96it/s, est. speed input: 3026.01 toks/s, output: 2.96 toks/s]
Processed prompts:  92%|| 3748/4096 [21:08<01:57,  2.96it/s, est. speed input: 3025.91 toks/s, output: 2.95 toks/s]
Processed prompts:  92%|| 3780/4096 [21:19<01:47,  2.95it/s, est. speed input: 3025.82 toks/s, output: 2.95 toks/s]
Processed prompts:  93%|| 3812/4096 [21:30<01:36,  2.95it/s, est. speed input: 3025.75 toks/s, output: 2.95 toks/s]
Processed prompts:  94%|| 3844/4096 [21:40<01:25,  2.95it/s, est. speed input: 3025.66 toks/s, output: 2.95 toks/s]
Processed prompts:  95%|| 3876/4096 [21:51<01:14,  2.95it/s, est. speed input: 3025.56 toks/s, output: 2.95 toks/s]
Processed prompts:  95%|| 3908/4096 [22:02<01:03,  2.97it/s, est. speed input: 3026.05 toks/s, output: 2.96 toks/s]
Processed prompts:  96%|| 3940/4096 [22:13<00:52,  2.96it/s, est. speed input: 3025.93 toks/s, output: 2.96 toks/s]
Processed prompts:  97%|| 3972/4096 [22:24<00:41,  2.96it/s, est. speed input: 3025.85 toks/s, output: 2.95 toks/s]
Processed prompts:  98%|| 4004/4096 [22:34<00:30,  2.97it/s, est. speed input: 3026.34 toks/s, output: 2.96 toks/s]
Processed prompts:  99%|| 4036/4096 [22:45<00:20,  2.96it/s, est. speed input: 3026.25 toks/s, output: 2.96 toks/s]
Processed prompts:  99%|| 4068/4096 [22:55<00:09,  3.05it/s, est. speed input: 3028.57 toks/s, output: 2.96 toks/s]
Processed prompts: 100%|| 4096/4096 [22:55<00:00,  3.05it/s, est. speed input: 3049.41 toks/s, output: 2.98 toks/s]
Processed prompts: 100%|| 4096/4096 [22:55<00:00,  2.98it/s, est. speed input: 3049.41 toks/s, output: 2.98 toks/s]
[rank0]:[W127 14:28:47.876395271 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-27 14:28:55
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_10/json/Qwen2.5-14B-FP8_M65536.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-27 14:29:30 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-27 14:29:30 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=2711921) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2711921) WARNING 01-27 14:33:26 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 1.01 requests/s, 1034.33 total tokens/s, 1.01 output tokens/s
Total num prompt tokens:  8388608
Total num output tokens:  8192

STDERR:
[2026-01-27 14:29:30] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 14:29:30] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 14:29:30] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 14:29:30] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 14:29:30] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 14:29:30] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 14:29:30] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 14:29:30] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 14:29:30] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 14:29:30] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 14:29:30] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 14:29:30] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 14:29:30] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 14:29:30] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-27 14:29:34] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 14:29:34] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 14:29:34] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 14:29:34] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 14:29:34] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 14:29:34] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 14:29:34] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 14:29:34] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 14:29:34] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 14:29:34] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 14:29:34] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 14:29:34] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 14:29:34] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 14:29:34] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=2711921) [2026-01-27 14:29:35] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=2711921) [2026-01-27 14:29:35] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2711921) [2026-01-27 14:29:35] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=2711921) [2026-01-27 14:29:35] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=2711921) [2026-01-27 14:29:35] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=2711921) [2026-01-27 14:29:35] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=2711921) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=2711921) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:25,  8.54s/it]
(EngineCore_DP0 pid=2711921) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:41<00:45, 22.89s/it]
(EngineCore_DP0 pid=2711921) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [01:18<00:29, 29.21s/it]
(EngineCore_DP0 pid=2711921) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:59<00:00, 34.15s/it]
(EngineCore_DP0 pid=2711921) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:59<00:00, 29.98s/it]
(EngineCore_DP0 pid=2711921) 
(EngineCore_DP0 pid=2711921) [2026-01-27 14:31:36] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 8192] -> 1D uint8
(EngineCore_DP0 pid=2711921) [2026-01-27 14:31:36] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 36700160 bytes
(EngineCore_DP0 pid=2711921) [2026-01-27 14:31:36] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 8192] -> 1D uint8
(EngineCore_DP0 pid=2711921) [2026-01-27 14:31:36] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 26214400 bytes
(EngineCore_DP0 pid=2711921) [2026-01-27 14:31:36] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 8192] -> 1D uint8
(EngineCore_DP0 pid=2711921) [2026-01-27 14:31:36] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 141557760 bytes
(EngineCore_DP0 pid=2711921) [2026-01-27 14:31:36] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 22144] -> 1D uint8
(EngineCore_DP0 pid=2711921) [2026-01-27 14:31:37] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 70860800 bytes
(EngineCore_DP0 pid=2711921) 2026-01-27 14:32:04,800 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=2711921) 2026-01-27 14:32:34,455 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/8192 [00:00<?, ?it/s]
Adding requests:   0%|          | 1/8192 [00:00<1:27:36,  1.56it/s]
Adding requests:   0%|          | 2/8192 [00:00<48:53,  2.79it/s]  
Adding requests:   0%|          | 3/8192 [00:00<33:25,  4.08it/s]
Adding requests:   0%|          | 5/8192 [00:01<19:47,  6.89it/s]
Adding requests:   0%|          | 7/8192 [00:01<14:18,  9.54it/s]
Adding requests:   0%|          | 9/8192 [00:01<11:32, 11.82it/s]
Adding requests:   0%|          | 12/8192 [00:01<08:23, 16.25it/s]
Adding requests:   0%|          | 17/8192 [00:01<05:34, 24.45it/s]
Adding requests:   0%|          | 28/8192 [00:01<02:56, 46.36it/s]
Adding requests:   1%|          | 44/8192 [00:01<01:47, 76.03it/s]
Adding requests:   1%|          | 62/8192 [00:01<01:18, 103.98it/s]
Adding requests:   1%|          | 78/8192 [00:01<01:08, 118.52it/s]
Adding requests:   1%|         | 103/8192 [00:01<00:52, 155.47it/s]
Adding requests:   2%|         | 132/8192 [00:02<00:41, 193.88it/s]
Adding requests:   2%|         | 162/8192 [00:02<00:35, 224.21it/s]
Adding requests:   2%|         | 194/8192 [00:02<00:31, 251.29it/s]
Adding requests:   3%|         | 224/8192 [00:02<00:30, 262.23it/s]
Adding requests:   3%|         | 255/8192 [00:02<00:28, 274.16it/s]
Adding requests:   4%|         | 290/8192 [00:02<00:26, 294.00it/s]
Adding requests:   4%|         | 338/8192 [00:02<00:22, 346.99it/s]
Adding requests:   5%|         | 392/8192 [00:02<00:19, 401.55it/s]
Adding requests:   5%|         | 446/8192 [00:02<00:17, 441.55it/s]
Adding requests:   6%|         | 504/8192 [00:03<00:15, 482.19it/s]
Adding requests:   7%|         | 564/8192 [00:03<00:14, 516.46it/s]
Adding requests:   8%|         | 616/8192 [00:03<00:14, 516.74it/s]
Adding requests:   8%|         | 669/8192 [00:03<00:14, 517.40it/s]
Adding requests:   9%|         | 721/8192 [00:03<00:14, 500.98it/s]
Adding requests:   9%|         | 772/8192 [00:03<00:14, 500.39it/s]
Adding requests:  10%|         | 827/8192 [00:03<00:14, 514.23it/s]
Adding requests:  11%|         | 879/8192 [00:03<00:15, 472.07it/s]
Adding requests:  11%|        | 927/8192 [00:03<00:16, 444.34it/s]
Adding requests:  12%|        | 973/8192 [00:03<00:16, 437.46it/s]
Adding requests:  12%|        | 1023/8192 [00:04<00:15, 452.99it/s]
Adding requests:  13%|        | 1075/8192 [00:04<00:15, 469.40it/s]
Adding requests:  14%|        | 1127/8192 [00:04<00:14, 482.89it/s]
Adding requests:  14%|        | 1180/8192 [00:04<00:14, 495.07it/s]
Adding requests:  15%|        | 1234/8192 [00:04<00:13, 506.04it/s]
Adding requests:  16%|        | 1285/8192 [00:04<00:13, 496.08it/s]
Adding requests:  16%|        | 1337/8192 [00:04<00:13, 494.88it/s]
Adding requests:  17%|        | 1391/8192 [00:04<00:13, 505.53it/s]
Adding requests:  18%|        | 1442/8192 [00:04<00:13, 499.46it/s]
Adding requests:  18%|        | 1493/8192 [00:05<00:13, 483.82it/s]
Adding requests:  19%|        | 1542/8192 [00:05<00:14, 458.53it/s]
Adding requests:  19%|        | 1589/8192 [00:05<00:14, 447.59it/s]
Adding requests:  20%|        | 1635/8192 [00:05<00:14, 450.73it/s]
Adding requests:  21%|        | 1685/8192 [00:05<00:14, 462.58it/s]
Adding requests:  21%|        | 1736/8192 [00:05<00:13, 476.13it/s]
Adding requests:  22%|       | 1791/8192 [00:05<00:12, 495.71it/s]
Adding requests:  23%|       | 1844/8192 [00:05<00:12, 504.04it/s]
Adding requests:  23%|       | 1895/8192 [00:05<00:12, 499.11it/s]
Adding requests:  24%|       | 1950/8192 [00:05<00:12, 513.52it/s]
Adding requests:  24%|       | 2002/8192 [00:06<00:12, 511.57it/s]
Adding requests:  25%|       | 2054/8192 [00:06<00:11, 513.63it/s]
Adding requests:  26%|       | 2106/8192 [00:06<00:12, 489.82it/s]
Adding requests:  26%|       | 2156/8192 [00:06<00:13, 458.95it/s]
Adding requests:  27%|       | 2203/8192 [00:06<00:13, 435.38it/s]
Adding requests:  27%|       | 2250/8192 [00:06<00:13, 443.00it/s]
Adding requests:  28%|       | 2304/8192 [00:06<00:12, 468.00it/s]
Adding requests:  29%|       | 2359/8192 [00:06<00:11, 491.17it/s]
Adding requests:  30%|       | 2417/8192 [00:06<00:11, 514.58it/s]
Adding requests:  30%|       | 2469/8192 [00:07<00:11, 513.31it/s]
Adding requests:  31%|       | 2522/8192 [00:07<00:11, 514.79it/s]
Adding requests:  31%|      | 2580/8192 [00:07<00:10, 531.93it/s]
Adding requests:  32%|      | 2634/8192 [00:07<00:10, 529.41it/s]
Adding requests:  33%|      | 2688/8192 [00:07<00:10, 529.47it/s]
Adding requests:  33%|      | 2742/8192 [00:07<00:10, 531.45it/s]
Adding requests:  34%|      | 2796/8192 [00:07<00:11, 488.21it/s]
Adding requests:  35%|      | 2846/8192 [00:07<00:11, 452.30it/s]
Adding requests:  35%|      | 2893/8192 [00:07<00:11, 444.89it/s]
Adding requests:  36%|      | 2947/8192 [00:08<00:11, 470.05it/s]
Adding requests:  37%|      | 2998/8192 [00:08<00:10, 481.06it/s]
Adding requests:  37%|      | 3055/8192 [00:08<00:10, 504.26it/s]
Adding requests:  38%|      | 3109/8192 [00:08<00:09, 513.10it/s]
Adding requests:  39%|      | 3167/8192 [00:08<00:09, 529.61it/s]
Adding requests:  39%|      | 3223/8192 [00:08<00:09, 536.00it/s]
Adding requests:  40%|      | 3277/8192 [00:08<00:09, 525.36it/s]
Adding requests:  41%|      | 3330/8192 [00:08<00:09, 518.26it/s]
Adding requests:  41%|     | 3387/8192 [00:08<00:09, 532.18it/s]
Adding requests:  42%|     | 3441/8192 [00:08<00:09, 494.16it/s]
Adding requests:  43%|     | 3492/8192 [00:09<00:10, 468.69it/s]
Adding requests:  43%|     | 3541/8192 [00:09<00:09, 473.96it/s]
Adding requests:  44%|     | 3592/8192 [00:09<00:09, 481.76it/s]
Adding requests:  45%|     | 3648/8192 [00:09<00:09, 502.96it/s]
Adding requests:  45%|     | 3700/8192 [00:09<00:08, 505.33it/s]
Adding requests:  46%|     | 3753/8192 [00:09<00:08, 512.08it/s]
Adding requests:  46%|     | 3805/8192 [00:09<00:08, 502.22it/s]
Adding requests:  47%|     | 3857/8192 [00:09<00:08, 507.37it/s]
Adding requests:  48%|     | 3909/8192 [00:09<00:08, 508.89it/s]
Adding requests:  48%|     | 3960/8192 [00:10<00:08, 504.91it/s]
Adding requests:  49%|     | 4013/8192 [00:10<00:08, 511.58it/s]
Adding requests:  50%|     | 4065/8192 [00:10<00:08, 483.16it/s]
Adding requests:  50%|     | 4114/8192 [00:10<00:08, 465.42it/s]
Adding requests:  51%|     | 4161/8192 [00:10<00:09, 442.43it/s]
Adding requests:  51%|    | 4209/8192 [00:10<00:08, 450.39it/s]
Adding requests:  52%|    | 4262/8192 [00:10<00:08, 472.37it/s]
Adding requests:  53%|    | 4312/8192 [00:10<00:08, 480.16it/s]
Adding requests:  53%|    | 4365/8192 [00:10<00:07, 493.11it/s]
Adding requests:  54%|    | 4417/8192 [00:10<00:07, 498.97it/s]
Adding requests:  55%|    | 4472/8192 [00:11<00:07, 513.31it/s]
Adding requests:  55%|    | 4526/8192 [00:11<00:07, 519.87it/s]
Adding requests:  56%|    | 4580/8192 [00:11<00:06, 524.18it/s]
Adding requests:  57%|    | 4633/8192 [00:11<00:06, 516.95it/s]
Adding requests:  57%|    | 4685/8192 [00:11<00:06, 510.13it/s]
Adding requests:  58%|    | 4737/8192 [00:11<00:07, 483.30it/s]
Adding requests:  58%|    | 4786/8192 [00:11<00:07, 463.97it/s]
Adding requests:  59%|    | 4833/8192 [00:11<00:07, 458.52it/s]
Adding requests:  60%|    | 4885/8192 [00:11<00:06, 474.75it/s]
Adding requests:  60%|    | 4943/8192 [00:12<00:06, 503.01it/s]
Adding requests:  61%|    | 4997/8192 [00:12<00:06, 513.59it/s]
Adding requests:  62%|   | 5055/8192 [00:12<00:05, 532.71it/s]
Adding requests:  62%|   | 5111/8192 [00:12<00:05, 540.55it/s]
Adding requests:  63%|   | 5167/8192 [00:12<00:05, 543.04it/s]
Adding requests:  64%|   | 5222/8192 [00:12<00:05, 544.16it/s]
Adding requests:  64%|   | 5277/8192 [00:12<00:05, 524.54it/s]
Adding requests:  65%|   | 5330/8192 [00:12<00:05, 520.97it/s]
Adding requests:  66%|   | 5383/8192 [00:12<00:05, 487.91it/s]
Adding requests:  66%|   | 5433/8192 [00:13<00:06, 455.73it/s]
Adding requests:  67%|   | 5480/8192 [00:13<00:06, 450.97it/s]
Adding requests:  67%|   | 5529/8192 [00:13<00:05, 460.82it/s]
Adding requests:  68%|   | 5581/8192 [00:13<00:05, 474.69it/s]
Adding requests:  69%|   | 5637/8192 [00:13<00:05, 498.04it/s]
Adding requests:  69%|   | 5688/8192 [00:13<00:05, 490.97it/s]
Adding requests:  70%|   | 5741/8192 [00:13<00:04, 499.58it/s]
Adding requests:  71%|   | 5796/8192 [00:13<00:04, 513.78it/s]
Adding requests:  71%|  | 5850/8192 [00:13<00:04, 517.35it/s]
Adding requests:  72%|  | 5904/8192 [00:13<00:04, 523.47it/s]
Adding requests:  73%|  | 5960/8192 [00:14<00:04, 531.71it/s]
Adding requests:  73%|  | 6014/8192 [00:14<00:04, 455.11it/s]
Adding requests:  74%|  | 6062/8192 [00:14<00:04, 438.27it/s]
Adding requests:  75%|  | 6108/8192 [00:14<00:04, 431.32it/s]
Adding requests:  75%|  | 6160/8192 [00:14<00:04, 453.66it/s]
Adding requests:  76%|  | 6209/8192 [00:14<00:04, 461.70it/s]
Adding requests:  76%|  | 6262/8192 [00:14<00:04, 478.62it/s]
Adding requests:  77%|  | 6316/8192 [00:14<00:03, 494.33it/s]
Adding requests:  78%|  | 6370/8192 [00:14<00:03, 506.16it/s]
Adding requests:  78%|  | 6421/8192 [00:15<00:03, 506.84it/s]
Adding requests:  79%|  | 6472/8192 [00:15<00:03, 503.52it/s]
Adding requests:  80%|  | 6525/8192 [00:15<00:03, 509.07it/s]
Adding requests:  80%|  | 6577/8192 [00:15<00:03, 509.83it/s]
Adding requests:  81%|  | 6629/8192 [00:15<00:03, 495.79it/s]
Adding requests:  82%| | 6679/8192 [00:15<00:03, 469.86it/s]
Adding requests:  82%| | 6727/8192 [00:15<00:03, 445.88it/s]
Adding requests:  83%| | 6778/8192 [00:15<00:03, 462.95it/s]
Adding requests:  83%| | 6827/8192 [00:15<00:02, 468.74it/s]
Adding requests:  84%| | 6884/8192 [00:15<00:02, 497.43it/s]
Adding requests:  85%| | 6940/8192 [00:16<00:02, 514.19it/s]
Adding requests:  85%| | 6996/8192 [00:16<00:02, 525.95it/s]
Adding requests:  86%| | 7052/8192 [00:16<00:02, 532.47it/s]
Adding requests:  87%| | 7106/8192 [00:16<00:02, 530.83it/s]
Adding requests:  87%| | 7162/8192 [00:16<00:01, 538.95it/s]
Adding requests:  88%| | 7216/8192 [00:16<00:01, 519.09it/s]
Adding requests:  89%| | 7270/8192 [00:16<00:01, 523.18it/s]
Adding requests:  89%| | 7323/8192 [00:16<00:01, 480.83it/s]
Adding requests:  90%| | 7372/8192 [00:16<00:01, 463.25it/s]
Adding requests:  91%| | 7419/8192 [00:17<00:01, 434.67it/s]
Adding requests:  91%| | 7466/8192 [00:17<00:01, 442.01it/s]
Adding requests:  92%|| 7519/8192 [00:17<00:01, 466.27it/s]
Adding requests:  92%|| 7572/8192 [00:17<00:01, 481.42it/s]
Adding requests:  93%|| 7624/8192 [00:17<00:01, 490.82it/s]
Adding requests:  94%|| 7682/8192 [00:17<00:00, 515.40it/s]
Adding requests:  94%|| 7734/8192 [00:17<00:00, 516.44it/s]
Adding requests:  95%|| 7786/8192 [00:17<00:00, 513.08it/s]
Adding requests:  96%|| 7839/8192 [00:17<00:00, 515.61it/s]
Adding requests:  96%|| 7893/8192 [00:18<00:00, 522.80it/s]
Adding requests:  97%|| 7946/8192 [00:18<00:00, 482.64it/s]
Adding requests:  98%|| 7995/8192 [00:18<00:00, 455.98it/s]
Adding requests:  98%|| 8042/8192 [00:18<00:00, 447.09it/s]
Adding requests:  99%|| 8094/8192 [00:18<00:00, 465.80it/s]
Adding requests:  99%|| 8146/8192 [00:18<00:00, 478.91it/s]
Adding requests: 100%|| 8192/8192 [00:18<00:00, 439.03it/s]

Processed prompts:   0%|          | 0/8192 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 6/8192 [00:46<17:38:50,  7.76s/it, est. speed input: 131.94 toks/s, output: 0.13 toks/s]
Processed prompts:   1%|          | 70/8192 [01:49<3:09:18,  1.40s/it, est. speed input: 655.53 toks/s, output: 0.64 toks/s]
Processed prompts:   2%|         | 134/8192 [02:52<2:35:43,  1.16s/it, est. speed input: 797.11 toks/s, output: 0.78 toks/s]
Processed prompts:   2%|         | 198/8192 [03:58<2:27:33,  1.11s/it, est. speed input: 848.47 toks/s, output: 0.83 toks/s]
Processed prompts:   3%|         | 262/8192 [05:05<2:23:04,  1.08s/it, est. speed input: 877.46 toks/s, output: 0.86 toks/s]
Processed prompts:   4%|         | 326/8192 [06:08<2:17:08,  1.05s/it, est. speed input: 905.83 toks/s, output: 0.88 toks/s]
Processed prompts:   5%|         | 390/8192 [07:15<2:15:53,  1.05s/it, est. speed input: 917.45 toks/s, output: 0.90 toks/s]
Processed prompts:   6%|         | 454/8192 [08:18<2:12:03,  1.02s/it, est. speed input: 933.46 toks/s, output: 0.91 toks/s]
Processed prompts:   6%|         | 518/8192 [09:20<2:09:11,  1.01s/it, est. speed input: 945.90 toks/s, output: 0.92 toks/s]
Processed prompts:   7%|         | 582/8192 [10:23<2:06:56,  1.00s/it, est. speed input: 955.82 toks/s, output: 0.93 toks/s]
Processed prompts:   8%|         | 646/8192 [11:26<2:05:04,  1.01it/s, est. speed input: 963.95 toks/s, output: 0.94 toks/s]
Processed prompts:   9%|         | 710/8192 [12:28<2:03:27,  1.01it/s, est. speed input: 970.74 toks/s, output: 0.95 toks/s]
Processed prompts:   9%|         | 774/8192 [13:35<2:04:21,  1.01s/it, est. speed input: 971.69 toks/s, output: 0.95 toks/s]
Processed prompts:  10%|         | 838/8192 [14:38<2:02:18,  1.00it/s, est. speed input: 976.95 toks/s, output: 0.95 toks/s]
Processed prompts:  11%|         | 902/8192 [15:41<2:00:34,  1.01it/s, est. speed input: 981.51 toks/s, output: 0.96 toks/s]
Processed prompts:  12%|        | 966/8192 [16:43<1:59:03,  1.01it/s, est. speed input: 985.50 toks/s, output: 0.96 toks/s]
Processed prompts:  13%|        | 1030/8192 [17:46<1:57:40,  1.01it/s, est. speed input: 989.02 toks/s, output: 0.97 toks/s]
Processed prompts:  13%|        | 1094/8192 [18:49<1:56:24,  1.02it/s, est. speed input: 992.14 toks/s, output: 0.97 toks/s]
Processed prompts:  14%|        | 1158/8192 [19:55<1:57:22,  1.00s/it, est. speed input: 991.64 toks/s, output: 0.97 toks/s]
Processed prompts:  15%|        | 1222/8192 [20:58<1:55:33,  1.01it/s, est. speed input: 994.32 toks/s, output: 0.97 toks/s]
Processed prompts:  16%|        | 1286/8192 [22:01<1:53:58,  1.01it/s, est. speed input: 996.74 toks/s, output: 0.97 toks/s]
Processed prompts:  16%|        | 1350/8192 [23:03<1:52:33,  1.01it/s, est. speed input: 998.94 toks/s, output: 0.98 toks/s]
Processed prompts:  17%|        | 1414/8192 [24:06<1:51:14,  1.02it/s, est. speed input: 1000.96 toks/s, output: 0.98 toks/s]
Processed prompts:  18%|        | 1478/8192 [25:09<1:50:01,  1.02it/s, est. speed input: 1002.79 toks/s, output: 0.98 toks/s]
Processed prompts:  19%|        | 1542/8192 [26:15<1:50:55,  1.00s/it, est. speed input: 1001.95 toks/s, output: 0.98 toks/s]
Processed prompts:  20%|        | 1606/8192 [27:22<1:51:10,  1.01s/it, est. speed input: 1001.21 toks/s, output: 0.98 toks/s]
Processed prompts:  20%|        | 1670/8192 [28:25<1:49:00,  1.00s/it, est. speed input: 1002.85 toks/s, output: 0.98 toks/s]
Processed prompts:  21%|        | 1734/8192 [29:27<1:47:10,  1.00it/s, est. speed input: 1004.37 toks/s, output: 0.98 toks/s]
Processed prompts:  22%|       | 1798/8192 [30:30<1:45:35,  1.01it/s, est. speed input: 1005.78 toks/s, output: 0.98 toks/s]
Processed prompts:  23%|       | 1862/8192 [31:33<1:44:10,  1.01it/s, est. speed input: 1007.09 toks/s, output: 0.98 toks/s]
Processed prompts:  24%|       | 1926/8192 [32:35<1:42:52,  1.02it/s, est. speed input: 1008.32 toks/s, output: 0.98 toks/s]
Processed prompts:  24%|       | 1990/8192 [33:38<1:41:39,  1.02it/s, est. speed input: 1009.47 toks/s, output: 0.99 toks/s]
Processed prompts:  25%|       | 2054/8192 [34:41<1:40:29,  1.02it/s, est. speed input: 1010.55 toks/s, output: 0.99 toks/s]
Processed prompts:  26%|       | 2118/8192 [35:44<1:39:21,  1.02it/s, est. speed input: 1011.57 toks/s, output: 0.99 toks/s]
Processed prompts:  27%|       | 2182/8192 [36:50<1:40:07,  1.00it/s, est. speed input: 1010.71 toks/s, output: 0.99 toks/s]
Processed prompts:  27%|       | 2246/8192 [37:53<1:38:26,  1.01it/s, est. speed input: 1011.67 toks/s, output: 0.99 toks/s]
Processed prompts:  28%|       | 2310/8192 [38:56<1:36:58,  1.01it/s, est. speed input: 1012.58 toks/s, output: 0.99 toks/s]
Processed prompts:  29%|       | 2374/8192 [39:58<1:35:38,  1.01it/s, est. speed input: 1013.44 toks/s, output: 0.99 toks/s]
Processed prompts:  30%|       | 2438/8192 [41:01<1:34:23,  1.02it/s, est. speed input: 1014.25 toks/s, output: 0.99 toks/s]
Processed prompts:  31%|       | 2502/8192 [42:04<1:33:12,  1.02it/s, est. speed input: 1015.03 toks/s, output: 0.99 toks/s]
Processed prompts:  31%|      | 2566/8192 [43:10<1:33:48,  1.00s/it, est. speed input: 1014.21 toks/s, output: 0.99 toks/s]
Processed prompts:  32%|      | 2630/8192 [44:13<1:32:08,  1.01it/s, est. speed input: 1014.96 toks/s, output: 0.99 toks/s]
Processed prompts:  33%|      | 2694/8192 [45:20<1:32:23,  1.01s/it, est. speed input: 1014.18 toks/s, output: 0.99 toks/s]
Processed prompts:  34%|      | 2758/8192 [46:22<1:30:31,  1.00it/s, est. speed input: 1014.88 toks/s, output: 0.99 toks/s]
Processed prompts:  34%|      | 2822/8192 [47:25<1:28:55,  1.01it/s, est. speed input: 1015.55 toks/s, output: 0.99 toks/s]
Processed prompts:  35%|      | 2886/8192 [48:31<1:28:44,  1.00s/it, est. speed input: 1015.15 toks/s, output: 0.99 toks/s]
Processed prompts:  36%|      | 2950/8192 [49:33<1:27:02,  1.00it/s, est. speed input: 1015.79 toks/s, output: 0.99 toks/s]
Processed prompts:  37%|      | 3014/8192 [50:36<1:25:32,  1.01it/s, est. speed input: 1016.40 toks/s, output: 0.99 toks/s]
Processed prompts:  38%|      | 3078/8192 [51:39<1:24:11,  1.01it/s, est. speed input: 1016.98 toks/s, output: 0.99 toks/s]
Processed prompts:  38%|      | 3142/8192 [52:41<1:22:55,  1.01it/s, est. speed input: 1017.55 toks/s, output: 0.99 toks/s]
Processed prompts:  39%|      | 3206/8192 [53:44<1:21:44,  1.02it/s, est. speed input: 1018.08 toks/s, output: 0.99 toks/s]
Processed prompts:  40%|      | 3270/8192 [54:47<1:20:35,  1.02it/s, est. speed input: 1018.60 toks/s, output: 0.99 toks/s]
Processed prompts:  41%|      | 3334/8192 [55:50<1:19:28,  1.02it/s, est. speed input: 1019.10 toks/s, output: 1.00 toks/s]
Processed prompts:  41%|     | 3398/8192 [56:52<1:18:22,  1.02it/s, est. speed input: 1019.58 toks/s, output: 1.00 toks/s]
Processed prompts:  42%|     | 3462/8192 [57:55<1:17:17,  1.02it/s, est. speed input: 1020.05 toks/s, output: 1.00 toks/s]
Processed prompts:  43%|     | 3526/8192 [58:58<1:16:13,  1.02it/s, est. speed input: 1020.50 toks/s, output: 1.00 toks/s]
Processed prompts:  44%|     | 3590/8192 [1:00:00<1:15:10,  1.02it/s, est. speed input: 1020.92 toks/s, output: 1.00 toks/s]
Processed prompts:  45%|     | 3654/8192 [1:01:07<1:15:31,  1.00it/s, est. speed input: 1020.24 toks/s, output: 1.00 toks/s]
Processed prompts:  45%|     | 3718/8192 [1:02:10<1:14:01,  1.01it/s, est. speed input: 1020.67 toks/s, output: 1.00 toks/s]
Processed prompts:  46%|     | 3782/8192 [1:03:12<1:12:40,  1.01it/s, est. speed input: 1021.08 toks/s, output: 1.00 toks/s]
Processed prompts:  47%|     | 3846/8192 [1:04:15<1:11:25,  1.01it/s, est. speed input: 1021.47 toks/s, output: 1.00 toks/s]
Processed prompts:  48%|     | 3910/8192 [1:05:22<1:11:33,  1.00s/it, est. speed input: 1020.82 toks/s, output: 1.00 toks/s]
Processed prompts:  49%|     | 3974/8192 [1:06:24<1:09:59,  1.00it/s, est. speed input: 1021.21 toks/s, output: 1.00 toks/s]
Processed prompts:  49%|     | 4038/8192 [1:07:31<1:09:52,  1.01s/it, est. speed input: 1020.59 toks/s, output: 1.00 toks/s]
Processed prompts:  50%|     | 4102/8192 [1:08:34<1:08:10,  1.00s/it, est. speed input: 1020.98 toks/s, output: 1.00 toks/s]
Processed prompts:  51%|     | 4166/8192 [1:09:36<1:06:41,  1.01it/s, est. speed input: 1021.35 toks/s, output: 1.00 toks/s]
Processed prompts:  52%|    | 4230/8192 [1:10:39<1:05:20,  1.01it/s, est. speed input: 1021.71 toks/s, output: 1.00 toks/s]
Processed prompts:  52%|    | 4294/8192 [1:11:42<1:04:05,  1.01it/s, est. speed input: 1022.05 toks/s, output: 1.00 toks/s]
Processed prompts:  53%|    | 4358/8192 [1:12:44<1:02:54,  1.02it/s, est. speed input: 1022.39 toks/s, output: 1.00 toks/s]
Processed prompts:  54%|    | 4422/8192 [1:13:51<1:02:56,  1.00s/it, est. speed input: 1021.80 toks/s, output: 1.00 toks/s]
Processed prompts:  55%|    | 4486/8192 [1:14:54<1:01:26,  1.01it/s, est. speed input: 1022.13 toks/s, output: 1.00 toks/s]
Processed prompts:  56%|    | 4550/8192 [1:16:00<1:01:14,  1.01s/it, est. speed input: 1021.56 toks/s, output: 1.00 toks/s]
Processed prompts:  56%|    | 4614/8192 [1:17:03<59:37,  1.00it/s, est. speed input: 1021.89 toks/s, output: 1.00 toks/s]  
Processed prompts:  57%|    | 4678/8192 [1:18:06<58:11,  1.01it/s, est. speed input: 1022.21 toks/s, output: 1.00 toks/s]
Processed prompts:  58%|    | 4742/8192 [1:19:08<56:53,  1.01it/s, est. speed input: 1022.52 toks/s, output: 1.00 toks/s]
Processed prompts:  59%|    | 4806/8192 [1:20:11<55:40,  1.01it/s, est. speed input: 1022.81 toks/s, output: 1.00 toks/s]
Processed prompts:  59%|    | 4870/8192 [1:21:14<54:30,  1.02it/s, est. speed input: 1023.10 toks/s, output: 1.00 toks/s]
Processed prompts:  60%|    | 4934/8192 [1:22:20<54:23,  1.00s/it, est. speed input: 1022.56 toks/s, output: 1.00 toks/s]
Processed prompts:  61%|    | 4998/8192 [1:23:23<52:57,  1.01it/s, est. speed input: 1022.85 toks/s, output: 1.00 toks/s]
Processed prompts:  62%|   | 5062/8192 [1:24:26<51:39,  1.01it/s, est. speed input: 1023.13 toks/s, output: 1.00 toks/s]
Processed prompts:  63%|   | 5126/8192 [1:25:29<50:26,  1.01it/s, est. speed input: 1023.40 toks/s, output: 1.00 toks/s]
Processed prompts:  63%|   | 5190/8192 [1:26:35<50:12,  1.00s/it, est. speed input: 1022.88 toks/s, output: 1.00 toks/s]
Processed prompts:  64%|   | 5254/8192 [1:27:42<49:41,  1.01s/it, est. speed input: 1022.38 toks/s, output: 1.00 toks/s]
Processed prompts:  65%|   | 5318/8192 [1:28:44<48:05,  1.00s/it, est. speed input: 1022.66 toks/s, output: 1.00 toks/s]
Processed prompts:  66%|   | 5382/8192 [1:29:47<46:40,  1.00it/s, est. speed input: 1022.93 toks/s, output: 1.00 toks/s]
Processed prompts:  66%|   | 5446/8192 [1:30:50<45:22,  1.01it/s, est. speed input: 1023.19 toks/s, output: 1.00 toks/s]
Processed prompts:  67%|   | 5510/8192 [1:31:56<44:59,  1.01s/it, est. speed input: 1022.70 toks/s, output: 1.00 toks/s]
Processed prompts:  68%|   | 5574/8192 [1:33:03<44:22,  1.02s/it, est. speed input: 1022.23 toks/s, output: 1.00 toks/s]
Processed prompts:  69%|   | 5638/8192 [1:34:06<42:48,  1.01s/it, est. speed input: 1022.50 toks/s, output: 1.00 toks/s]
Processed prompts:  70%|   | 5702/8192 [1:35:08<41:24,  1.00it/s, est. speed input: 1022.75 toks/s, output: 1.00 toks/s]
Processed prompts:  70%|   | 5766/8192 [1:36:11<40:07,  1.01it/s, est. speed input: 1022.99 toks/s, output: 1.00 toks/s]
Processed prompts:  71%|   | 5830/8192 [1:37:14<38:54,  1.01it/s, est. speed input: 1023.23 toks/s, output: 1.00 toks/s]
Processed prompts:  72%|  | 5894/8192 [1:38:21<38:28,  1.00s/it, est. speed input: 1022.78 toks/s, output: 1.00 toks/s]
Processed prompts:  73%|  | 5958/8192 [1:39:27<37:48,  1.02s/it, est. speed input: 1022.34 toks/s, output: 1.00 toks/s]
Processed prompts:  74%|  | 6022/8192 [1:40:30<36:19,  1.00s/it, est. speed input: 1022.59 toks/s, output: 1.00 toks/s]
Processed prompts:  74%|  | 6086/8192 [1:41:33<34:59,  1.00it/s, est. speed input: 1022.82 toks/s, output: 1.00 toks/s]
Processed prompts:  75%|  | 6150/8192 [1:42:35<33:45,  1.01it/s, est. speed input: 1023.05 toks/s, output: 1.00 toks/s]
Processed prompts:  76%|  | 6214/8192 [1:43:38<32:34,  1.01it/s, est. speed input: 1023.28 toks/s, output: 1.00 toks/s]
Processed prompts:  77%|  | 6278/8192 [1:44:41<31:26,  1.01it/s, est. speed input: 1023.50 toks/s, output: 1.00 toks/s]
Processed prompts:  77%|  | 6342/8192 [1:45:43<30:19,  1.02it/s, est. speed input: 1023.71 toks/s, output: 1.00 toks/s]
Processed prompts:  78%|  | 6406/8192 [1:46:46<29:14,  1.02it/s, est. speed input: 1023.92 toks/s, output: 1.00 toks/s]
Processed prompts:  79%|  | 6470/8192 [1:47:49<28:10,  1.02it/s, est. speed input: 1024.13 toks/s, output: 1.00 toks/s]
Processed prompts:  80%|  | 6534/8192 [1:48:51<27:06,  1.02it/s, est. speed input: 1024.33 toks/s, output: 1.00 toks/s]
Processed prompts:  81%|  | 6598/8192 [1:49:54<26:03,  1.02it/s, est. speed input: 1024.53 toks/s, output: 1.00 toks/s]
Processed prompts:  81%| | 6662/8192 [1:50:57<25:00,  1.02it/s, est. speed input: 1024.72 toks/s, output: 1.00 toks/s]
Processed prompts:  82%| | 6726/8192 [1:52:00<23:57,  1.02it/s, est. speed input: 1024.91 toks/s, output: 1.00 toks/s]
Processed prompts:  83%| | 6790/8192 [1:53:02<22:54,  1.02it/s, est. speed input: 1025.10 toks/s, output: 1.00 toks/s]
Processed prompts:  84%| | 6854/8192 [1:54:05<21:51,  1.02it/s, est. speed input: 1025.28 toks/s, output: 1.00 toks/s]
Processed prompts:  84%| | 6918/8192 [1:55:08<20:48,  1.02it/s, est. speed input: 1025.46 toks/s, output: 1.00 toks/s]
Processed prompts:  85%| | 6982/8192 [1:56:10<19:45,  1.02it/s, est. speed input: 1025.64 toks/s, output: 1.00 toks/s]
Processed prompts:  86%| | 7046/8192 [1:57:13<18:42,  1.02it/s, est. speed input: 1025.81 toks/s, output: 1.00 toks/s]
Processed prompts:  87%| | 7110/8192 [1:58:16<17:40,  1.02it/s, est. speed input: 1025.98 toks/s, output: 1.00 toks/s]
Processed prompts:  88%| | 7174/8192 [1:59:18<16:37,  1.02it/s, est. speed input: 1026.15 toks/s, output: 1.00 toks/s]
Processed prompts:  88%| | 7238/8192 [2:00:21<15:34,  1.02it/s, est. speed input: 1026.31 toks/s, output: 1.00 toks/s]
Processed prompts:  89%| | 7302/8192 [2:01:24<14:32,  1.02it/s, est. speed input: 1026.48 toks/s, output: 1.00 toks/s]
Processed prompts:  90%| | 7366/8192 [2:02:27<13:29,  1.02it/s, est. speed input: 1026.63 toks/s, output: 1.00 toks/s]
Processed prompts:  91%| | 7430/8192 [2:03:29<12:26,  1.02it/s, est. speed input: 1026.79 toks/s, output: 1.00 toks/s]
Processed prompts:  91%|| 7494/8192 [2:04:32<11:23,  1.02it/s, est. speed input: 1026.94 toks/s, output: 1.00 toks/s]
Processed prompts:  92%|| 7558/8192 [2:05:35<10:21,  1.02it/s, est. speed input: 1027.09 toks/s, output: 1.00 toks/s]
Processed prompts:  93%|| 7622/8192 [2:06:37<09:18,  1.02it/s, est. speed input: 1027.24 toks/s, output: 1.00 toks/s]
Processed prompts:  94%|| 7686/8192 [2:07:40<08:15,  1.02it/s, est. speed input: 1027.38 toks/s, output: 1.00 toks/s]
Processed prompts:  95%|| 7750/8192 [2:08:43<07:13,  1.02it/s, est. speed input: 1027.53 toks/s, output: 1.00 toks/s]
Processed prompts:  95%|| 7814/8192 [2:09:46<06:10,  1.02it/s, est. speed input: 1027.67 toks/s, output: 1.00 toks/s]
Processed prompts:  96%|| 7878/8192 [2:10:48<05:07,  1.02it/s, est. speed input: 1027.81 toks/s, output: 1.00 toks/s]
Processed prompts:  97%|| 7942/8192 [2:11:51<04:04,  1.02it/s, est. speed input: 1027.94 toks/s, output: 1.00 toks/s]
Processed prompts:  98%|| 8006/8192 [2:12:54<03:02,  1.02it/s, est. speed input: 1028.08 toks/s, output: 1.00 toks/s]
Processed prompts:  99%|| 8070/8192 [2:13:56<01:59,  1.02it/s, est. speed input: 1028.21 toks/s, output: 1.00 toks/s]
Processed prompts:  99%|| 8134/8192 [2:14:59<00:56,  1.02it/s, est. speed input: 1028.37 toks/s, output: 1.00 toks/s]
Processed prompts: 100%|| 8192/8192 [2:14:59<00:00,  1.02it/s, est. speed input: 1035.70 toks/s, output: 1.01 toks/s]
Processed prompts: 100%|| 8192/8192 [2:14:59<00:00,  1.01it/s, est. speed input: 1035.70 toks/s, output: 1.01 toks/s]
[rank0]:[W127 16:48:54.588162084 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

