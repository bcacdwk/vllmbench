
========== M=16 ==========
Time: 2026-01-25 18:47:54
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6
Params: prompt_len=16, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6 --dataset-name random --input-len 16 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 17 --max-num-batched-tokens 17 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-FP8_M16.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 18:47:58 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 18:47:58 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=300590) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=300590) 
(EngineCore_DP0 pid=300590) 
(EngineCore_DP0 pid=300590) ================================================================
(EngineCore_DP0 pid=300590) Internal Triton PTX codegen error
(EngineCore_DP0 pid=300590) `ptxas` stderr:
(EngineCore_DP0 pid=300590) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=300590) 
(EngineCore_DP0 pid=300590) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpncqp1k_7.ptx -o /tmp/tmpncqp1k_7.ptx.o
(EngineCore_DP0 pid=300590) 
(EngineCore_DP0 pid=300590) 
(EngineCore_DP0 pid=300590) //
(EngineCore_DP0 pid=300590) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=300590) //
(EngineCore_DP0 pid=300590) 
(EngineCore_DP0 pid=300590) .version 8.7
(EngineCore_DP0 pid=300590) .target sm_121a
(EngineCore_DP0 pid=300590) .address_size 64
(EngineCore_DP0 pid=300590) 
(EngineCore_DP0 pid=300590) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=300590) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=300590)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=300590) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=300590) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=300590) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=300590) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=300590) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=300590) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=300590) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=300590) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=300590) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=300590) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=300590) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=300590) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=300590) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=300590) )
(EngineCore_DP0 pid=300590) .reqntid 512
(EngineCore_DP0 pid=300590) {
(EngineCore_DP0 pid=300590) 	.reg .pred 	%p<20>;
(EngineCore_DP0 pid=300590) 	.reg .b16 	%rs<37>;
(EngineCore_DP0 pid=300590) 	.reg .b32 	%r<117>;
(EngineCore_DP0 pid=300590) 	.reg .b64 	%rd<13>;
(EngineCore_DP0 pid=300590) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=300590) $L__func_begin0:
(EngineCore_DP0 pid=300590) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=300590) 
(EngineCore_DP0 pid=300590) // %bb.0:
(EngineCore_DP0 pid=300590) 	ld.param.b32 	%r20, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=300590) 	ld.param.b32 	%r19, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=300590) 	ld.param.b32 	%r18, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=300590) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=300590) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=300590) $L__tmp0:
(EngineCore_DP0 pid=300590) 	.loc	1 177 24                        // quant_slide_tuned_Llama3.2-1B.py:177:24
(EngineCore_DP0 pid=300590) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=300590) 	ld.param.b32 	%r22, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=300590) 	.loc	1 182 26                        // quant_slide_tuned_Llama3.2-1B.py:182:26
(EngineCore_DP0 pid=300590) 	mul.lo.s32 	%r23, %r22, %r1;
(EngineCore_DP0 pid=300590) 	.loc	1 182 20                        // quant_slide_tuned_Llama3.2-1B.py:182:20
(EngineCore_DP0 pid=300590) 	mad.wide.s32 	%rd1, %r23, 2, %rd4;
(EngineCore_DP0 pid=300590) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=300590) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=300590) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=300590) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=300590) 	setp.lt.s32 	%p1, %r19, 1;
(EngineCore_DP0 pid=300590) 	mov.b32 	%r115, 0f2B8CBCCC;
(EngineCore_DP0 pid=300590) 	setp.eq.b32 	%p19, %r2, 0;
(EngineCore_DP0 pid=300590) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=300590) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=300590) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=300590) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=300590) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=300590) 	shr.u32 	%r32, %r2, 3;
(EngineCore_DP0 pid=300590) 	and.b32 	%r33, %r32, 60;
(EngineCore_DP0 pid=300590) 	mov.b32 	%r34, global_smem;
(EngineCore_DP0 pid=300590) 	add.s32 	%r44, %r34, %r33;
(EngineCore_DP0 pid=300590) 	shl.b32 	%r35, %r2, 2;
(EngineCore_DP0 pid=300590) 	add.s32 	%r47, %r34, %r35;
(EngineCore_DP0 pid=300590) 	mov.b32 	%r40, 0;
(EngineCore_DP0 pid=300590) 	mov.b32 	%r113, 0f00000000;
(EngineCore_DP0 pid=300590) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=300590) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=300590) 	mov.b32 	%r114, %r40;
(EngineCore_DP0 pid=300590) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=300590) 	.loc	1 189 22                        // quant_slide_tuned_Llama3.2-1B.py:189:22
(EngineCore_DP0 pid=300590) 	add.s32 	%r50, %r4, %r114;
(EngineCore_DP0 pid=300590) 	setp.lt.s32 	%p2, %r50, %r18;
(EngineCore_DP0 pid=300590) 	.loc	1 190 29                        // quant_slide_tuned_Llama3.2-1B.py:190:29
(EngineCore_DP0 pid=300590) 	mad.wide.s32 	%rd6, %r50, 2, %rd1;
(EngineCore_DP0 pid=300590) 	.loc	1 190 21                        // quant_slide_tuned_Llama3.2-1B.py:190:21
(EngineCore_DP0 pid=300590) 	// begin inline asm
(EngineCore_DP0 pid=300590) 	mov.u32 %r36, %r40;
(EngineCore_DP0 pid=300590) 	mov.u32 %r37, %r40;
(EngineCore_DP0 pid=300590) 	mov.u32 %r38, %r40;
(EngineCore_DP0 pid=300590) 	mov.u32 %r39, %r40;
(EngineCore_DP0 pid=300590) 	@%p2 ld.global.v4.b32 { %r36, %r37, %r38, %r39 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=300590) 	// end inline asm
(EngineCore_DP0 pid=300590) 	mov.b32 	{%rs1, %rs2}, %r36;
(EngineCore_DP0 pid=300590) 	mov.b32 	{%rs3, %rs4}, %r37;
(EngineCore_DP0 pid=300590) 	mov.b32 	{%rs5, %rs6}, %r38;
(EngineCore_DP0 pid=300590) 	mov.b32 	{%rs7, %rs8}, %r39;
(EngineCore_DP0 pid=300590) 	.loc	1 191 50                        // quant_slide_tuned_Llama3.2-1B.py:191:50
(EngineCore_DP0 pid=300590) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=300590) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=300590) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=300590) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=300590) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=300590) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=300590) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=300590) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=300590) $L__tmp1:
(EngineCore_DP0 pid=300590) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=300590) 	bar.sync 	0;
(EngineCore_DP0 pid=300590) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=300590) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=300590) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=300590) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=300590) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=300590) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=300590) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=300590) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=300590) 	cvt.f32.bf16 	%r51, %rs23;
(EngineCore_DP0 pid=300590) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=300590) 	shfl.sync.bfly.b32 	%r52, %r51, 16, 31, -1;
(EngineCore_DP0 pid=300590) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=300590) 	max.f32 	%r53, %r51, %r52;
(EngineCore_DP0 pid=300590) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=300590) 	shfl.sync.bfly.b32 	%r54, %r53, 8, 31, -1;
(EngineCore_DP0 pid=300590) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=300590) 	max.f32 	%r55, %r53, %r54;
(EngineCore_DP0 pid=300590) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=300590) 	shfl.sync.bfly.b32 	%r56, %r55, 4, 31, -1;
(EngineCore_DP0 pid=300590) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=300590) 	max.f32 	%r57, %r55, %r56;
(EngineCore_DP0 pid=300590) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=300590) 	shfl.sync.bfly.b32 	%r58, %r57, 2, 31, -1;
(EngineCore_DP0 pid=300590) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=300590) 	max.f32 	%r59, %r57, %r58;
(EngineCore_DP0 pid=300590) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=300590) 	shfl.sync.bfly.b32 	%r60, %r59, 1, 31, -1;
(EngineCore_DP0 pid=300590) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=300590) 	max.f32 	%r45, %r59, %r60;
(EngineCore_DP0 pid=300590) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=300590) 	// begin inline asm
(EngineCore_DP0 pid=300590) 	@%p3 st.shared.b32 [ %r44 + 0 ], %r45;
(EngineCore_DP0 pid=300590) 	// end inline asm
(EngineCore_DP0 pid=300590) 	bar.sync 	0;
(EngineCore_DP0 pid=300590) 	// begin inline asm
(EngineCore_DP0 pid=300590) 	@%p4 ld.shared.b32 %r46, [ %r47 + 0 ];
(EngineCore_DP0 pid=300590) 	// end inline asm
(EngineCore_DP0 pid=300590) 	shfl.sync.bfly.b32 	%r61, %r46, 8, 31, -1;
(EngineCore_DP0 pid=300590) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=300590) 	max.f32 	%r62, %r46, %r61;
(EngineCore_DP0 pid=300590) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=300590) 	shfl.sync.bfly.b32 	%r63, %r62, 4, 31, -1;
(EngineCore_DP0 pid=300590) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=300590) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=300590) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=300590) 	shfl.sync.bfly.b32 	%r65, %r64, 2, 31, -1;
(EngineCore_DP0 pid=300590) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=300590) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=300590) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=300590) 	shfl.sync.bfly.b32 	%r67, %r66, 1, 31, -1;
(EngineCore_DP0 pid=300590) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=300590) 	max.f32 	%r49, %r66, %r67;
(EngineCore_DP0 pid=300590) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=300590) 	// begin inline asm
(EngineCore_DP0 pid=300590) 	@%p19 st.shared.b32 [ %r47 + 0 ], %r49;
(EngineCore_DP0 pid=300590) 	// end inline asm
(EngineCore_DP0 pid=300590) 	bar.sync 	0;
(EngineCore_DP0 pid=300590) 	ld.shared.b32 	%r68, [global_smem];
(EngineCore_DP0 pid=300590) $L__tmp2:
(EngineCore_DP0 pid=300590) 	.loc	1 191 36                        // quant_slide_tuned_Llama3.2-1B.py:191:36
(EngineCore_DP0 pid=300590) 	max.f32 	%r113, %r113, %r68;
(EngineCore_DP0 pid=300590) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=300590) 	add.s32 	%r114, %r114, 4096;
(EngineCore_DP0 pid=300590) 	setp.lt.s32 	%p6, %r114, %r19;
(EngineCore_DP0 pid=300590) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=300590) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=300590) 	.loc	1 193 32                        // quant_slide_tuned_Llama3.2-1B.py:193:32
(EngineCore_DP0 pid=300590) 	max.f32 	%r115, %r113, 0f2B8CBCCC;
(EngineCore_DP0 pid=300590) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=300590) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=300590) 	mov.b32 	%r70, 0f43E00000;
(EngineCore_DP0 pid=300590) 	.loc	1 194 32                        // quant_slide_tuned_Llama3.2-1B.py:194:32
(EngineCore_DP0 pid=300590) 	div.full.f32 	%r71, %r115, %r70;
(EngineCore_DP0 pid=300590) 	.loc	1 194 41                        // quant_slide_tuned_Llama3.2-1B.py:194:41
(EngineCore_DP0 pid=300590) 	max.f32 	%r69, %r71, 0f36924925;
(EngineCore_DP0 pid=300590) 	.loc	1 196 25                        // quant_slide_tuned_Llama3.2-1B.py:196:25
(EngineCore_DP0 pid=300590) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=300590) 	.loc	1 196 30                        // quant_slide_tuned_Llama3.2-1B.py:196:30
(EngineCore_DP0 pid=300590) 	// begin inline asm
(EngineCore_DP0 pid=300590) 	@%p19 st.global.b32 [ %rd7 + 0 ], { %r69 };
(EngineCore_DP0 pid=300590) 	// end inline asm
(EngineCore_DP0 pid=300590) 	.loc	1 199 29                        // quant_slide_tuned_Llama3.2-1B.py:199:29
(EngineCore_DP0 pid=300590) 	shl.b32 	%r15, %r20, 1;
(EngineCore_DP0 pid=300590) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=300590) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=300590) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=300590) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=300590) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=300590) 	ld.param.b32 	%r24, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=300590) 	shr.s32 	%r25, %r24, 31;
(EngineCore_DP0 pid=300590) 	shr.u32 	%r26, %r25, 30;
(EngineCore_DP0 pid=300590) 	add.s32 	%r27, %r24, %r26;
(EngineCore_DP0 pid=300590) 	shr.s32 	%r28, %r27, 2;
(EngineCore_DP0 pid=300590) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=300590) 	mul.lo.s32 	%r29, %r28, %r1;
(EngineCore_DP0 pid=300590) 	mad.wide.s32 	%rd2, %r29, 4, %rd5;
(EngineCore_DP0 pid=300590) 	div.full.f32 	%r14, %r70, %r115;
(EngineCore_DP0 pid=300590) 	mov.b32 	%r116, 0;
(EngineCore_DP0 pid=300590) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=300590)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=300590) 	.loc	1 203 30                        // quant_slide_tuned_Llama3.2-1B.py:203:30
(EngineCore_DP0 pid=300590) 	add.s32 	%r83, %r3, %r116;
(EngineCore_DP0 pid=300590) 	setp.lt.s32 	%p13, %r83, %r15;
(EngineCore_DP0 pid=300590) 	.loc	1 206 24                        // quant_slide_tuned_Llama3.2-1B.py:206:24
(EngineCore_DP0 pid=300590) 	shr.u32 	%r84, %r83, 31;
(EngineCore_DP0 pid=300590) 	add.s32 	%r85, %r83, %r84;
(EngineCore_DP0 pid=300590) 	shr.u32 	%r86, %r85, 1;
(EngineCore_DP0 pid=300590) 	.loc	1 207 23                        // quant_slide_tuned_Llama3.2-1B.py:207:23
(EngineCore_DP0 pid=300590) 	and.b32 	%r87, %r85, 2147483646;
(EngineCore_DP0 pid=300590) 	sub.s32 	%r88, %r83, %r87;
(EngineCore_DP0 pid=300590) 	.loc	1 208 30                        // quant_slide_tuned_Llama3.2-1B.py:208:30
(EngineCore_DP0 pid=300590) 	shl.b32 	%r89, %r88, 1;
(EngineCore_DP0 pid=300590) 	.loc	1 208 26                        // quant_slide_tuned_Llama3.2-1B.py:208:26
(EngineCore_DP0 pid=300590) 	mad.lo.s32 	%r90, %r86, 6, %r89;
(EngineCore_DP0 pid=300590) 	.loc	1 211 53                        // quant_slide_tuned_Llama3.2-1B.py:211:53
(EngineCore_DP0 pid=300590) 	setp.lt.s32 	%p14, %r90, %r18;
(EngineCore_DP0 pid=300590) 	.loc	1 211 37                        // quant_slide_tuned_Llama3.2-1B.py:211:37
(EngineCore_DP0 pid=300590) 	and.pred 	%p9, %p13, %p14;
(EngineCore_DP0 pid=300590) 	.loc	1 210 29                        // quant_slide_tuned_Llama3.2-1B.py:210:29
(EngineCore_DP0 pid=300590) 	mad.wide.s32 	%rd8, %r90, 2, %rd1;
(EngineCore_DP0 pid=300590) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=300590) 	.loc	1 210 21                        // quant_slide_tuned_Llama3.2-1B.py:210:21
(EngineCore_DP0 pid=300590) 	// begin inline asm
(EngineCore_DP0 pid=300590) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=300590) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=300590) 	// end inline asm
(EngineCore_DP0 pid=300590) 	.loc	1 211 79                        // quant_slide_tuned_Llama3.2-1B.py:211:79
(EngineCore_DP0 pid=300590) 	cvt.f32.bf16 	%r91, %rs24;
(EngineCore_DP0 pid=300590) 	.loc	1 213 48                        // quant_slide_tuned_Llama3.2-1B.py:213:48
(EngineCore_DP0 pid=300590) 	or.b32 	%r92, %r90, 1;
(EngineCore_DP0 pid=300590) 	.loc	1 213 53                        // quant_slide_tuned_Llama3.2-1B.py:213:53
(EngineCore_DP0 pid=300590) 	setp.lt.s32 	%p15, %r92, %r18;
(EngineCore_DP0 pid=300590) 	.loc	1 213 37                        // quant_slide_tuned_Llama3.2-1B.py:213:37
(EngineCore_DP0 pid=300590) 	and.pred 	%p10, %p13, %p15;
(EngineCore_DP0 pid=300590) 	.loc	1 212 39                        // quant_slide_tuned_Llama3.2-1B.py:212:39
(EngineCore_DP0 pid=300590) 	add.s64 	%rd9, %rd8, 2;
(EngineCore_DP0 pid=300590) 	.loc	1 212 21                        // quant_slide_tuned_Llama3.2-1B.py:212:21
(EngineCore_DP0 pid=300590) 	// begin inline asm
(EngineCore_DP0 pid=300590) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=300590) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=300590) 	// end inline asm
(EngineCore_DP0 pid=300590) 	.loc	1 213 79                        // quant_slide_tuned_Llama3.2-1B.py:213:79
(EngineCore_DP0 pid=300590) 	cvt.f32.bf16 	%r93, %rs26;
(EngineCore_DP0 pid=300590) 	.loc	1 215 48                        // quant_slide_tuned_Llama3.2-1B.py:215:48
(EngineCore_DP0 pid=300590) 	add.s32 	%r94, %r90, 2;
(EngineCore_DP0 pid=300590) 	.loc	1 215 53                        // quant_slide_tuned_Llama3.2-1B.py:215:53
(EngineCore_DP0 pid=300590) 	setp.lt.s32 	%p16, %r94, %r18;
(EngineCore_DP0 pid=300590) 	.loc	1 215 37                        // quant_slide_tuned_Llama3.2-1B.py:215:37
(EngineCore_DP0 pid=300590) 	and.pred 	%p11, %p13, %p16;
(EngineCore_DP0 pid=300590) 	.loc	1 214 39                        // quant_slide_tuned_Llama3.2-1B.py:214:39
(EngineCore_DP0 pid=300590) 	add.s64 	%rd10, %rd8, 4;
(EngineCore_DP0 pid=300590) 	.loc	1 214 21                        // quant_slide_tuned_Llama3.2-1B.py:214:21
(EngineCore_DP0 pid=300590) 	// begin inline asm
(EngineCore_DP0 pid=300590) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=300590) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=300590) 	// end inline asm
(EngineCore_DP0 pid=300590) 	.loc	1 215 79                        // quant_slide_tuned_Llama3.2-1B.py:215:79
(EngineCore_DP0 pid=300590) 	cvt.f32.bf16 	%r95, %rs28;
(EngineCore_DP0 pid=300590) 	.loc	1 217 48                        // quant_slide_tuned_Llama3.2-1B.py:217:48
(EngineCore_DP0 pid=300590) 	add.s32 	%r96, %r90, 3;
(EngineCore_DP0 pid=300590) 	.loc	1 217 53                        // quant_slide_tuned_Llama3.2-1B.py:217:53
(EngineCore_DP0 pid=300590) 	setp.lt.s32 	%p17, %r96, %r18;
(EngineCore_DP0 pid=300590) 	.loc	1 217 37                        // quant_slide_tuned_Llama3.2-1B.py:217:37
(EngineCore_DP0 pid=300590) 	and.pred 	%p12, %p13, %p17;
(EngineCore_DP0 pid=300590) 	.loc	1 216 39                        // quant_slide_tuned_Llama3.2-1B.py:216:39
(EngineCore_DP0 pid=300590) 	add.s64 	%rd11, %rd8, 6;
(EngineCore_DP0 pid=300590) 	.loc	1 216 21                        // quant_slide_tuned_Llama3.2-1B.py:216:21
(EngineCore_DP0 pid=300590) 	// begin inline asm
(EngineCore_DP0 pid=300590) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=300590) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=300590) 	// end inline asm
(EngineCore_DP0 pid=300590) 	.loc	1 217 79                        // quant_slide_tuned_Llama3.2-1B.py:217:79
(EngineCore_DP0 pid=300590) 	cvt.f32.bf16 	%r97, %rs30;
(EngineCore_DP0 pid=300590) 	.loc	1 219 27                        // quant_slide_tuned_Llama3.2-1B.py:219:27
(EngineCore_DP0 pid=300590) 	mul.f32 	%r98, %r14, %r91;
(EngineCore_DP0 pid=300590) 	mov.b32 	%r99, 0f43E00000;
(EngineCore_DP0 pid=300590) 	.loc	1 219 48                        // quant_slide_tuned_Llama3.2-1B.py:219:48
(EngineCore_DP0 pid=300590) 	min.xorsign.abs.f32 	%r73, %r98, %r99;
(EngineCore_DP0 pid=300590) 	.loc	1 219 60                        // quant_slide_tuned_Llama3.2-1B.py:219:60
(EngineCore_DP0 pid=300590) 	// begin inline asm
(EngineCore_DP0 pid=300590) 	cvt.rn.satfinite.e4m3x2.f32  %rs32, %r74, %r73; 
(EngineCore_DP0 pid=300590) 
(EngineCore_DP0 pid=300590) 	// end inline asm
(EngineCore_DP0 pid=300590) 	.loc	1 220 27                        // quant_slide_tuned_Llama3.2-1B.py:220:27
(EngineCore_DP0 pid=300590) 	mul.f32 	%r100, %r14, %r93;
(EngineCore_DP0 pid=300590) 	.loc	1 220 48                        // quant_slide_tuned_Llama3.2-1B.py:220:48
(EngineCore_DP0 pid=300590) 	min.xorsign.abs.f32 	%r75, %r100, %r99;
(EngineCore_DP0 pid=300590) 	.loc	1 220 60                        // quant_slide_tuned_Llama3.2-1B.py:220:60
(EngineCore_DP0 pid=300590) 	// begin inline asm
(EngineCore_DP0 pid=300590) 	cvt.rn.satfinite.e4m3x2.f32  %rs33, %r76, %r75; 
(EngineCore_DP0 pid=300590) 
(EngineCore_DP0 pid=300590) 	// end inline asm
(EngineCore_DP0 pid=300590) 	.loc	1 221 27                        // quant_slide_tuned_Llama3.2-1B.py:221:27
(EngineCore_DP0 pid=300590) 	mul.f32 	%r101, %r14, %r95;
(EngineCore_DP0 pid=300590) 	.loc	1 221 48                        // quant_slide_tuned_Llama3.2-1B.py:221:48
(EngineCore_DP0 pid=300590) 	min.xorsign.abs.f32 	%r77, %r101, %r99;
(EngineCore_DP0 pid=300590) 	.loc	1 221 60                        // quant_slide_tuned_Llama3.2-1B.py:221:60
(EngineCore_DP0 pid=300590) 	// begin inline asm
(EngineCore_DP0 pid=300590) 	cvt.rn.satfinite.e4m3x2.f32  %rs34, %r78, %r77; 
(EngineCore_DP0 pid=300590) 
(EngineCore_DP0 pid=300590) 	// end inline asm
(EngineCore_DP0 pid=300590) 	.loc	1 222 27                        // quant_slide_tuned_Llama3.2-1B.py:222:27
(EngineCore_DP0 pid=300590) 	mul.f32 	%r102, %r14, %r97;
(EngineCore_DP0 pid=300590) 	.loc	1 222 48                        // quant_slide_tuned_Llama3.2-1B.py:222:48
(EngineCore_DP0 pid=300590) 	min.xorsign.abs.f32 	%r79, %r102, %r99;
(EngineCore_DP0 pid=300590) 	.loc	1 222 60                        // quant_slide_tuned_Llama3.2-1B.py:222:60
(EngineCore_DP0 pid=300590) 	// begin inline asm
(EngineCore_DP0 pid=300590) 	cvt.rn.satfinite.e4m3x2.f32  %rs35, %r80, %r79; 
(EngineCore_DP0 pid=300590) 
(EngineCore_DP0 pid=300590) 	// end inline asm
(EngineCore_DP0 pid=300590) 	.loc	1 224 45                        // quant_slide_tuned_Llama3.2-1B.py:224:45
(EngineCore_DP0 pid=300590) 	cvt.u32.u16 	%r103, %rs32;
(EngineCore_DP0 pid=300590) 	and.b32 	%r104, %r103, 255;
(EngineCore_DP0 pid=300590) 	.loc	1 226 45                        // quant_slide_tuned_Llama3.2-1B.py:226:45
(EngineCore_DP0 pid=300590) 	cvt.u32.u16 	%r105, %rs34;
(EngineCore_DP0 pid=300590) 	and.b32 	%r106, %r105, 255;
(EngineCore_DP0 pid=300590) 	.loc	1 227 45                        // quant_slide_tuned_Llama3.2-1B.py:227:45
(EngineCore_DP0 pid=300590) 	cvt.u32.u16 	%r107, %rs35;
(EngineCore_DP0 pid=300590) 	.loc	1 229 30                        // quant_slide_tuned_Llama3.2-1B.py:229:30
(EngineCore_DP0 pid=300590) 	and.b16 	%rs36, %rs33, 255;
(EngineCore_DP0 pid=300590) 	mul.wide.u16 	%r108, %rs36, 256;
(EngineCore_DP0 pid=300590) 	.loc	1 229 24                        // quant_slide_tuned_Llama3.2-1B.py:229:24
(EngineCore_DP0 pid=300590) 	or.b32 	%r109, %r108, %r104;
(EngineCore_DP0 pid=300590) 	.loc	1 229 42                        // quant_slide_tuned_Llama3.2-1B.py:229:42
(EngineCore_DP0 pid=300590) 	shl.b32 	%r110, %r106, 16;
(EngineCore_DP0 pid=300590) 	.loc	1 229 36                        // quant_slide_tuned_Llama3.2-1B.py:229:36
(EngineCore_DP0 pid=300590) 	or.b32 	%r111, %r109, %r110;
(EngineCore_DP0 pid=300590) 	.loc	1 229 55                        // quant_slide_tuned_Llama3.2-1B.py:229:55
(EngineCore_DP0 pid=300590) 	shl.b32 	%r112, %r107, 24;
(EngineCore_DP0 pid=300590) 	.loc	1 229 49                        // quant_slide_tuned_Llama3.2-1B.py:229:49
(EngineCore_DP0 pid=300590) 	or.b32 	%r81, %r111, %r112;
(EngineCore_DP0 pid=300590) 	.loc	1 230 29                        // quant_slide_tuned_Llama3.2-1B.py:230:29
(EngineCore_DP0 pid=300590) 	mad.wide.s32 	%rd12, %r83, 4, %rd2;
(EngineCore_DP0 pid=300590) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-1B.py:230:39
(EngineCore_DP0 pid=300590) 	// begin inline asm
(EngineCore_DP0 pid=300590) 	@%p13 st.global.b32 [ %rd12 + 0 ], { %r81 };
(EngineCore_DP0 pid=300590) 	// end inline asm
(EngineCore_DP0 pid=300590) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=300590) 	add.s32 	%r116, %r116, 512;
(EngineCore_DP0 pid=300590) 	setp.lt.s32 	%p18, %r116, %r15;
(EngineCore_DP0 pid=300590) 	@%p18 bra 	$L__BB0_6;
(EngineCore_DP0 pid=300590) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=300590) 	.loc	1 201 4                         // quant_slide_tuned_Llama3.2-1B.py:201:4
(EngineCore_DP0 pid=300590) 	ret;
(EngineCore_DP0 pid=300590) $L__tmp3:
(EngineCore_DP0 pid=300590) $L__func_end0:
(EngineCore_DP0 pid=300590)                                         // -- End function
(EngineCore_DP0 pid=300590) }
(EngineCore_DP0 pid=300590) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=300590) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=300590) 	.section	.debug_abbrev
(EngineCore_DP0 pid=300590) 	{
(EngineCore_DP0 pid=300590) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=300590) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=300590) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=300590) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=300590) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=300590) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=300590) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=300590) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=300590) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=300590) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=300590) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=300590) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=300590) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=300590) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=300590) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=300590) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=300590) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=300590) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=300590) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=300590) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=300590) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=300590) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=300590) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=300590) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=300590) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=300590) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=300590) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=300590) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=300590) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=300590) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=300590) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=300590) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=300590) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=300590) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=300590) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=300590) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=300590) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=300590) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=300590) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=300590) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=300590) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=300590) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=300590) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=300590) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=300590) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=300590) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=300590) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=300590) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=300590) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=300590) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=300590) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=300590) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=300590) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=300590) 	}
(EngineCore_DP0 pid=300590) 	.section	.debug_info
(EngineCore_DP0 pid=300590) 	{
(EngineCore_DP0 pid=300590) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=300590) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=300590) .b8 0
(EngineCore_DP0 pid=300590) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=300590) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=300590) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=300590) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=300590) .b8 114
(EngineCore_DP0 pid=300590) .b8 105
(EngineCore_DP0 pid=300590) .b8 116
(EngineCore_DP0 pid=300590) .b8 111
(EngineCore_DP0 pid=300590) .b8 110
(EngineCore_DP0 pid=300590) .b8 0
(EngineCore_DP0 pid=300590) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=300590) .b8 0
(EngineCore_DP0 pid=300590) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=300590) .b8 117
(EngineCore_DP0 pid=300590) .b8 97
(EngineCore_DP0 pid=300590) .b8 110
(EngineCore_DP0 pid=300590) .b8 116
(EngineCore_DP0 pid=300590) .b8 95
(EngineCore_DP0 pid=300590) .b8 115
(EngineCore_DP0 pid=300590) .b8 108
(EngineCore_DP0 pid=300590) .b8 105
(EngineCore_DP0 pid=300590) .b8 100
(EngineCore_DP0 pid=300590) .b8 101
(EngineCore_DP0 pid=300590) .b8 95
(EngineCore_DP0 pid=300590) .b8 116
(EngineCore_DP0 pid=300590) .b8 117
(EngineCore_DP0 pid=300590) .b8 110
(EngineCore_DP0 pid=300590) .b8 101
(EngineCore_DP0 pid=300590) .b8 100
(EngineCore_DP0 pid=300590) .b8 95
(EngineCore_DP0 pid=300590) .b8 76
(EngineCore_DP0 pid=300590) .b8 108
(EngineCore_DP0 pid=300590) .b8 97
(EngineCore_DP0 pid=300590) .b8 109
(EngineCore_DP0 pid=300590) .b8 97
(EngineCore_DP0 pid=300590) .b8 51
(EngineCore_DP0 pid=300590) .b8 46
(EngineCore_DP0 pid=300590) .b8 50
(EngineCore_DP0 pid=300590) .b8 45
(EngineCore_DP0 pid=300590) .b8 49
(EngineCore_DP0 pid=300590) .b8 66
(EngineCore_DP0 pid=300590) .b8 46
(EngineCore_DP0 pid=300590) .b8 112
(EngineCore_DP0 pid=300590) .b8 121
(EngineCore_DP0 pid=300590) .b8 0
(EngineCore_DP0 pid=300590) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=300590) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=300590) .b8 114
(EngineCore_DP0 pid=300590) .b8 111
(EngineCore_DP0 pid=300590) .b8 111
(EngineCore_DP0 pid=300590) .b8 116
(EngineCore_DP0 pid=300590) .b8 47
(EngineCore_DP0 pid=300590) .b8 118
(EngineCore_DP0 pid=300590) .b8 108
(EngineCore_DP0 pid=300590) .b8 108
(EngineCore_DP0 pid=300590) .b8 109
(EngineCore_DP0 pid=300590) .b8 98
(EngineCore_DP0 pid=300590) .b8 101
(EngineCore_DP0 pid=300590) .b8 110
(EngineCore_DP0 pid=300590) .b8 99
(EngineCore_DP0 pid=300590) .b8 104
(EngineCore_DP0 pid=300590) .b8 47
(EngineCore_DP0 pid=300590) .b8 115
(EngineCore_DP0 pid=300590) .b8 108
(EngineCore_DP0 pid=300590) .b8 105
(EngineCore_DP0 pid=300590) .b8 100
(EngineCore_DP0 pid=300590) .b8 101
(EngineCore_DP0 pid=300590) .b8 115
(EngineCore_DP0 pid=300590) .b8 112
(EngineCore_DP0 pid=300590) .b8 97
(EngineCore_DP0 pid=300590) .b8 114
(EngineCore_DP0 pid=300590) .b8 115
(EngineCore_DP0 pid=300590) .b8 101
(EngineCore_DP0 pid=300590) .b8 47
(EngineCore_DP0 pid=300590) .b8 99
(EngineCore_DP0 pid=300590) .b8 115
(EngineCore_DP0 pid=300590) .b8 114
(EngineCore_DP0 pid=300590) .b8 99
(EngineCore_DP0 pid=300590) .b8 47
(EngineCore_DP0 pid=300590) .b8 102
(EngineCore_DP0 pid=300590) .b8 117
(EngineCore_DP0 pid=300590) .b8 115
(EngineCore_DP0 pid=300590) .b8 101
(EngineCore_DP0 pid=300590) .b8 100
(EngineCore_DP0 pid=300590) .b8 95
(EngineCore_DP0 pid=300590) .b8 113
(EngineCore_DP0 pid=300590) .b8 117
(EngineCore_DP0 pid=300590) .b8 97
(EngineCore_DP0 pid=300590) .b8 110
(EngineCore_DP0 pid=300590) .b8 116
(EngineCore_DP0 pid=300590) .b8 95
(EngineCore_DP0 pid=300590) .b8 115
(EngineCore_DP0 pid=300590) .b8 108
(EngineCore_DP0 pid=300590) .b8 105
(EngineCore_DP0 pid=300590) .b8 100
(EngineCore_DP0 pid=300590) .b8 101
(EngineCore_DP0 pid=300590) .b8 95
(EngineCore_DP0 pid=300590) .b8 116
(EngineCore_DP0 pid=300590) .b8 114
(EngineCore_DP0 pid=300590) .b8 105
(EngineCore_DP0 pid=300590) .b8 116
(EngineCore_DP0 pid=300590) .b8 111
(EngineCore_DP0 pid=300590) .b8 110
(EngineCore_DP0 pid=300590) .b8 47
(EngineCore_DP0 pid=300590) .b8 98
(EngineCore_DP0 pid=300590) .b8 117
(EngineCore_DP0 pid=300590) .b8 105
(EngineCore_DP0 pid=300590) .b8 108
(EngineCore_DP0 pid=300590) .b8 100
(EngineCore_DP0 pid=300590) .b8 47
(EngineCore_DP0 pid=300590) .b8 71
(EngineCore_DP0 pid=300590) .b8 66
(EngineCore_DP0 pid=300590) .b8 49
(EngineCore_DP0 pid=300590) .b8 48
(EngineCore_DP0 pid=300590) .b8 95
(EngineCore_DP0 pid=300590) .b8 99
(EngineCore_DP0 pid=300590) .b8 99
(EngineCore_DP0 pid=300590) .b8 49
(EngineCore_DP0 pid=300590) .b8 50
(EngineCore_DP0 pid=300590) .b8 49
(EngineCore_DP0 pid=300590) .b8 95
(EngineCore_DP0 pid=300590) .b8 112
(EngineCore_DP0 pid=300590) .b8 121
(EngineCore_DP0 pid=300590) .b8 51
(EngineCore_DP0 pid=300590) .b8 49
(EngineCore_DP0 pid=300590) .b8 50
(EngineCore_DP0 pid=300590) .b8 95
(EngineCore_DP0 pid=300590) .b8 99
(EngineCore_DP0 pid=300590) .b8 117
(EngineCore_DP0 pid=300590) .b8 49
(EngineCore_DP0 pid=300590) .b8 50
(EngineCore_DP0 pid=300590) .b8 57
(EngineCore_DP0 pid=300590) .b8 95
(EngineCore_DP0 pid=300590) .b8 97
(EngineCore_DP0 pid=300590) .b8 97
(EngineCore_DP0 pid=300590) .b8 114
(EngineCore_DP0 pid=300590) .b8 99
(EngineCore_DP0 pid=300590) .b8 104
(EngineCore_DP0 pid=300590) .b8 54
(EngineCore_DP0 pid=300590) .b8 52
(EngineCore_DP0 pid=300590) .b8 0
(EngineCore_DP0 pid=300590) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=300590) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=300590) .b8 113
(EngineCore_DP0 pid=300590) .b8 117
(EngineCore_DP0 pid=300590) .b8 97
(EngineCore_DP0 pid=300590) .b8 110
(EngineCore_DP0 pid=300590) .b8 116
(EngineCore_DP0 pid=300590) .b8 95
(EngineCore_DP0 pid=300590) .b8 115
(EngineCore_DP0 pid=300590) .b8 108
(EngineCore_DP0 pid=300590) .b8 105
(EngineCore_DP0 pid=300590) .b8 100
(EngineCore_DP0 pid=300590) .b8 101
(EngineCore_DP0 pid=300590) .b8 95
(EngineCore_DP0 pid=300590) .b8 102
(EngineCore_DP0 pid=300590) .b8 112
(EngineCore_DP0 pid=300590) .b8 56
(EngineCore_DP0 pid=300590) .b8 95
(EngineCore_DP0 pid=300590) .b8 107
(EngineCore_DP0 pid=300590) .b8 101
(EngineCore_DP0 pid=300590) .b8 114
(EngineCore_DP0 pid=300590) .b8 110
(EngineCore_DP0 pid=300590) .b8 101
(EngineCore_DP0 pid=300590) .b8 108
(EngineCore_DP0 pid=300590) .b8 0
(EngineCore_DP0 pid=300590) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=300590) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=300590) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=300590) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=300590) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=300590) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=300590) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=300590) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=300590) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=300590) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=300590) .b8 191                                 // DW_AT_call_line
(EngineCore_DP0 pid=300590) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=300590) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=300590) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=300590) 	}
(EngineCore_DP0 pid=300590) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=300590) 
(EngineCore_DP0 pid=300590) ================================================================
(EngineCore_DP0 pid=300590) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=300590) 
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpncqp1k_7.ptx', '-o', '/tmp/tmpncqp1k_7.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866] 
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866] 
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866] 
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpncqp1k_7.ptx -o /tmp/tmpncqp1k_7.ptx.o
(EngineCore_DP0 pid=300590) ERROR 01-25 18:48:13 [core.py:866] 

STDERR:
[2026-01-25 18:47:58] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 18:47:58] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 18:47:58] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 18:47:58] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:47:58] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:47:58] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:47:58] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:47:58] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:47:58] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 18:47:58] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 18:47:58] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 18:47:58] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 18:47:58] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 18:47:58] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 18:48:01] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 18:48:02] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 18:48:02] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 18:48:02] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:48:02] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:48:02] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:48:02] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:48:02] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:48:02] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 18:48:02] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 18:48:02] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 18:48:02] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 18:48:02] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 18:48:02] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=300590) [2026-01-25 18:48:02] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=300590) [2026-01-25 18:48:02] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=300590) [2026-01-25 18:48:02] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=300590) [2026-01-25 18:48:02] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=300590) [2026-01-25 18:48:02] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=300590) [2026-01-25 18:48:02] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=300590) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=300590) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.35s/it]
(EngineCore_DP0 pid=300590) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.35s/it]
(EngineCore_DP0 pid=300590) 
(EngineCore_DP0 pid=300590) [2026-01-25 18:48:12] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=300590) [2026-01-25 18:48:12] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5308416 bytes
(EngineCore_DP0 pid=300590) [2026-01-25 18:48:12] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=300590) [2026-01-25 18:48:12] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3538944 bytes
(EngineCore_DP0 pid=300590) [2026-01-25 18:48:12] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=300590) [2026-01-25 18:48:12] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 28311552 bytes
(EngineCore_DP0 pid=300590) [2026-01-25 18:48:12] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=300590) [2026-01-25 18:48:12] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14024704 bytes
(EngineCore_DP0 pid=300590) Process EngineCore_DP0:
(EngineCore_DP0 pid=300590) Traceback (most recent call last):
(EngineCore_DP0 pid=300590)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=300590)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=300590)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=300590)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=300590) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpncqp1k_7.ptx', '-o', '/tmp/tmpncqp1k_7.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=300590) 
(EngineCore_DP0 pid=300590) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=300590) 
(EngineCore_DP0 pid=300590) Traceback (most recent call last):
(EngineCore_DP0 pid=300590)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=300590)     self.run()
(EngineCore_DP0 pid=300590)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=300590)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=300590)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=300590)     raise e
(EngineCore_DP0 pid=300590)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=300590)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=300590)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=300590)     super().__init__(
(EngineCore_DP0 pid=300590)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=300590)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=300590)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=300590)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=300590)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=300590)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=300590)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=300590)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=300590)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=300590)     return func(*args, **kwargs)
(EngineCore_DP0 pid=300590)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=300590)     return func(*args, **kwargs)
(EngineCore_DP0 pid=300590)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=300590)     self.model_runner.profile_run()
(EngineCore_DP0 pid=300590)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=300590)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=300590)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=300590)     return func(*args, **kwargs)
(EngineCore_DP0 pid=300590)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=300590)     outputs = self.model(
(EngineCore_DP0 pid=300590)               ^^^^^^^^^^^
(EngineCore_DP0 pid=300590)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=300590)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=300590)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=300590)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=300590)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=300590)     model_output = self.model(
(EngineCore_DP0 pid=300590)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=300590)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=300590)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=300590)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=300590)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=300590)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=300590)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=300590)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=300590)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=300590)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=300590)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=300590)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=300590)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=300590)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=300590)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=300590)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=300590)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=300590)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=300590)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=300590)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=300590)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=300590)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=300590)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=300590)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=300590)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=300590)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=300590)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=300590)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=300590)     return self._linear_fn(
(EngineCore_DP0 pid=300590)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=300590)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=300590)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=300590)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=300590)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=300590)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=300590)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=300590)     return fn(input, L)
(EngineCore_DP0 pid=300590)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=300590)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=300590)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=300590)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=300590)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=300590)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=300590)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=300590)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=300590)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=300590)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=300590)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=300590)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=300590)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=300590)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=300590)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=300590)     raise PTXASError(error)
(EngineCore_DP0 pid=300590) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=300590) `ptxas` stderr:
(EngineCore_DP0 pid=300590) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=300590) 
(EngineCore_DP0 pid=300590) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpncqp1k_7.ptx -o /tmp/tmpncqp1k_7.ptx.o
(EngineCore_DP0 pid=300590) 
[rank0]:[W125 18:48:13.165299773 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=16

========== M=128 ==========
Time: 2026-01-25 18:48:15
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6
Params: prompt_len=128, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6 --dataset-name random --input-len 128 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 129 --max-num-batched-tokens 129 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-FP8_M128.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 18:48:19 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 18:48:19 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=301063) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=301063) 
(EngineCore_DP0 pid=301063) 
(EngineCore_DP0 pid=301063) ================================================================
(EngineCore_DP0 pid=301063) Internal Triton PTX codegen error
(EngineCore_DP0 pid=301063) `ptxas` stderr:
(EngineCore_DP0 pid=301063) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=301063) 
(EngineCore_DP0 pid=301063) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpg8rl0772.ptx -o /tmp/tmpg8rl0772.ptx.o
(EngineCore_DP0 pid=301063) 
(EngineCore_DP0 pid=301063) 
(EngineCore_DP0 pid=301063) //
(EngineCore_DP0 pid=301063) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=301063) //
(EngineCore_DP0 pid=301063) 
(EngineCore_DP0 pid=301063) .version 8.7
(EngineCore_DP0 pid=301063) .target sm_121a
(EngineCore_DP0 pid=301063) .address_size 64
(EngineCore_DP0 pid=301063) 
(EngineCore_DP0 pid=301063) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=301063) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=301063)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=301063) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=301063) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=301063) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=301063) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=301063) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=301063) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=301063) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=301063) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=301063) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=301063) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=301063) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=301063) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=301063) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=301063) )
(EngineCore_DP0 pid=301063) .reqntid 128
(EngineCore_DP0 pid=301063) {
(EngineCore_DP0 pid=301063) 	.reg .pred 	%p<29>;
(EngineCore_DP0 pid=301063) 	.reg .b16 	%rs<73>;
(EngineCore_DP0 pid=301063) 	.reg .b32 	%r<144>;
(EngineCore_DP0 pid=301063) 	.reg .b64 	%rd<18>;
(EngineCore_DP0 pid=301063) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=301063) $L__func_begin0:
(EngineCore_DP0 pid=301063) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=301063) 
(EngineCore_DP0 pid=301063) // %bb.0:
(EngineCore_DP0 pid=301063) 	ld.param.b32 	%r21, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=301063) 	ld.param.b32 	%r20, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=301063) 	ld.param.b32 	%r19, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=301063) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=301063) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=301063) $L__tmp0:
(EngineCore_DP0 pid=301063) 	.loc	1 177 24                        // quant_slide_tuned_Llama3.2-1B.py:177:24
(EngineCore_DP0 pid=301063) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=301063) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=301063) 	.loc	1 182 26                        // quant_slide_tuned_Llama3.2-1B.py:182:26
(EngineCore_DP0 pid=301063) 	mul.lo.s32 	%r24, %r23, %r1;
(EngineCore_DP0 pid=301063) 	.loc	1 182 20                        // quant_slide_tuned_Llama3.2-1B.py:182:20
(EngineCore_DP0 pid=301063) 	mad.wide.s32 	%rd1, %r24, 2, %rd4;
(EngineCore_DP0 pid=301063) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=301063) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=301063) 	and.b32 	%r3, %r2, 127;
(EngineCore_DP0 pid=301063) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=301063) 	setp.lt.s32 	%p1, %r20, 1;
(EngineCore_DP0 pid=301063) 	mov.b32 	%r142, 0f2B8CBCCC;
(EngineCore_DP0 pid=301063) 	setp.eq.b32 	%p28, %r2, 0;
(EngineCore_DP0 pid=301063) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=301063) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=301063) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=301063) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=301063) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=301063) 	shr.u32 	%r33, %r2, 3;
(EngineCore_DP0 pid=301063) 	and.b32 	%r34, %r33, 12;
(EngineCore_DP0 pid=301063) 	mov.b32 	%r35, global_smem;
(EngineCore_DP0 pid=301063) 	add.s32 	%r53, %r35, %r34;
(EngineCore_DP0 pid=301063) 	shl.b32 	%r36, %r2, 2;
(EngineCore_DP0 pid=301063) 	add.s32 	%r56, %r35, %r36;
(EngineCore_DP0 pid=301063) 	mov.b32 	%r41, 0;
(EngineCore_DP0 pid=301063) 	mov.b32 	%r140, 0f00000000;
(EngineCore_DP0 pid=301063) 	setp.lt.u32 	%p5, %r2, 4;
(EngineCore_DP0 pid=301063) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=301063) 	mov.b32 	%r141, %r41;
(EngineCore_DP0 pid=301063) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=301063) 	.loc	1 188 19                        // quant_slide_tuned_Llama3.2-1B.py:188:19
(EngineCore_DP0 pid=301063) 	add.s32 	%r59, %r4, %r141;
(EngineCore_DP0 pid=301063) 	.loc	1 189 22                        // quant_slide_tuned_Llama3.2-1B.py:189:22
(EngineCore_DP0 pid=301063) 	add.s32 	%r60, %r59, 1024;
(EngineCore_DP0 pid=301063) 	setp.lt.s32 	%p2, %r59, %r19;
(EngineCore_DP0 pid=301063) 	setp.lt.s32 	%p3, %r60, %r19;
(EngineCore_DP0 pid=301063) 	.loc	1 190 29                        // quant_slide_tuned_Llama3.2-1B.py:190:29
(EngineCore_DP0 pid=301063) 	mad.wide.s32 	%rd6, %r59, 2, %rd1;
(EngineCore_DP0 pid=301063) 	add.s64 	%rd7, %rd6, 2048;
(EngineCore_DP0 pid=301063) 	.loc	1 190 21                        // quant_slide_tuned_Llama3.2-1B.py:190:21
(EngineCore_DP0 pid=301063) 	// begin inline asm
(EngineCore_DP0 pid=301063) 	mov.u32 %r37, %r41;
(EngineCore_DP0 pid=301063) 	mov.u32 %r38, %r41;
(EngineCore_DP0 pid=301063) 	mov.u32 %r39, %r41;
(EngineCore_DP0 pid=301063) 	mov.u32 %r40, %r41;
(EngineCore_DP0 pid=301063) 	@%p2 ld.global.v4.b32 { %r37, %r38, %r39, %r40 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=301063) 	// end inline asm
(EngineCore_DP0 pid=301063) 	mov.b32 	{%rs1, %rs2}, %r37;
(EngineCore_DP0 pid=301063) 	mov.b32 	{%rs3, %rs4}, %r38;
(EngineCore_DP0 pid=301063) 	mov.b32 	{%rs5, %rs6}, %r39;
(EngineCore_DP0 pid=301063) 	mov.b32 	{%rs7, %rs8}, %r40;
(EngineCore_DP0 pid=301063) 	// begin inline asm
(EngineCore_DP0 pid=301063) 	mov.u32 %r45, %r41;
(EngineCore_DP0 pid=301063) 	mov.u32 %r46, %r41;
(EngineCore_DP0 pid=301063) 	mov.u32 %r47, %r41;
(EngineCore_DP0 pid=301063) 	mov.u32 %r48, %r41;
(EngineCore_DP0 pid=301063) 	@%p3 ld.global.v4.b32 { %r45, %r46, %r47, %r48 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=301063) 	// end inline asm
(EngineCore_DP0 pid=301063) 	mov.b32 	{%rs9, %rs10}, %r45;
(EngineCore_DP0 pid=301063) 	mov.b32 	{%rs11, %rs12}, %r46;
(EngineCore_DP0 pid=301063) 	mov.b32 	{%rs13, %rs14}, %r47;
(EngineCore_DP0 pid=301063) 	mov.b32 	{%rs15, %rs16}, %r48;
(EngineCore_DP0 pid=301063) 	.loc	1 191 50                        // quant_slide_tuned_Llama3.2-1B.py:191:50
(EngineCore_DP0 pid=301063) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=301063) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=301063) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=301063) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=301063) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=301063) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=301063) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=301063) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=301063) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=301063) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=301063) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=301063) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=301063) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=301063) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=301063) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=301063) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=301063) $L__tmp1:
(EngineCore_DP0 pid=301063) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=301063) 	bar.sync 	0;
(EngineCore_DP0 pid=301063) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=301063) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=301063) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=301063) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=301063) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=301063) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=301063) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=301063) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=301063) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=301063) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=301063) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=301063) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=301063) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=301063) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=301063) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=301063) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=301063) 	cvt.f32.bf16 	%r61, %rs47;
(EngineCore_DP0 pid=301063) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=301063) 	shfl.sync.bfly.b32 	%r62, %r61, 16, 31, -1;
(EngineCore_DP0 pid=301063) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=301063) 	max.f32 	%r63, %r61, %r62;
(EngineCore_DP0 pid=301063) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=301063) 	shfl.sync.bfly.b32 	%r64, %r63, 8, 31, -1;
(EngineCore_DP0 pid=301063) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=301063) 	max.f32 	%r65, %r63, %r64;
(EngineCore_DP0 pid=301063) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=301063) 	shfl.sync.bfly.b32 	%r66, %r65, 4, 31, -1;
(EngineCore_DP0 pid=301063) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=301063) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=301063) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=301063) 	shfl.sync.bfly.b32 	%r68, %r67, 2, 31, -1;
(EngineCore_DP0 pid=301063) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=301063) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=301063) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=301063) 	shfl.sync.bfly.b32 	%r70, %r69, 1, 31, -1;
(EngineCore_DP0 pid=301063) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=301063) 	max.f32 	%r54, %r69, %r70;
(EngineCore_DP0 pid=301063) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=301063) 	// begin inline asm
(EngineCore_DP0 pid=301063) 	@%p4 st.shared.b32 [ %r53 + 0 ], %r54;
(EngineCore_DP0 pid=301063) 	// end inline asm
(EngineCore_DP0 pid=301063) 	bar.sync 	0;
(EngineCore_DP0 pid=301063) 	// begin inline asm
(EngineCore_DP0 pid=301063) 	@%p5 ld.shared.b32 %r55, [ %r56 + 0 ];
(EngineCore_DP0 pid=301063) 	// end inline asm
(EngineCore_DP0 pid=301063) 	shfl.sync.bfly.b32 	%r71, %r55, 2, 31, -1;
(EngineCore_DP0 pid=301063) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=301063) 	max.f32 	%r72, %r55, %r71;
(EngineCore_DP0 pid=301063) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=301063) 	shfl.sync.bfly.b32 	%r73, %r72, 1, 31, -1;
(EngineCore_DP0 pid=301063) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=301063) 	max.f32 	%r58, %r72, %r73;
(EngineCore_DP0 pid=301063) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=301063) 	// begin inline asm
(EngineCore_DP0 pid=301063) 	@%p28 st.shared.b32 [ %r56 + 0 ], %r58;
(EngineCore_DP0 pid=301063) 	// end inline asm
(EngineCore_DP0 pid=301063) 	bar.sync 	0;
(EngineCore_DP0 pid=301063) 	ld.shared.b32 	%r74, [global_smem];
(EngineCore_DP0 pid=301063) $L__tmp2:
(EngineCore_DP0 pid=301063) 	.loc	1 191 36                        // quant_slide_tuned_Llama3.2-1B.py:191:36
(EngineCore_DP0 pid=301063) 	max.f32 	%r140, %r140, %r74;
(EngineCore_DP0 pid=301063) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=301063) 	add.s32 	%r141, %r141, 2048;
(EngineCore_DP0 pid=301063) 	setp.lt.s32 	%p7, %r141, %r20;
(EngineCore_DP0 pid=301063) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=301063) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=301063) 	.loc	1 193 32                        // quant_slide_tuned_Llama3.2-1B.py:193:32
(EngineCore_DP0 pid=301063) 	max.f32 	%r142, %r140, 0f2B8CBCCC;
(EngineCore_DP0 pid=301063) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=301063) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=301063) 	mov.b32 	%r76, 0f43E00000;
(EngineCore_DP0 pid=301063) 	.loc	1 194 32                        // quant_slide_tuned_Llama3.2-1B.py:194:32
(EngineCore_DP0 pid=301063) 	div.full.f32 	%r77, %r142, %r76;
(EngineCore_DP0 pid=301063) 	.loc	1 194 41                        // quant_slide_tuned_Llama3.2-1B.py:194:41
(EngineCore_DP0 pid=301063) 	max.f32 	%r75, %r77, 0f36924925;
(EngineCore_DP0 pid=301063) 	.loc	1 196 25                        // quant_slide_tuned_Llama3.2-1B.py:196:25
(EngineCore_DP0 pid=301063) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=301063) 	.loc	1 196 30                        // quant_slide_tuned_Llama3.2-1B.py:196:30
(EngineCore_DP0 pid=301063) 	// begin inline asm
(EngineCore_DP0 pid=301063) 	@%p28 st.global.b32 [ %rd8 + 0 ], { %r75 };
(EngineCore_DP0 pid=301063) 	// end inline asm
(EngineCore_DP0 pid=301063) 	.loc	1 199 29                        // quant_slide_tuned_Llama3.2-1B.py:199:29
(EngineCore_DP0 pid=301063) 	shl.b32 	%r15, %r21, 1;
(EngineCore_DP0 pid=301063) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=301063) 	setp.lt.s32 	%p9, %r15, 1;
(EngineCore_DP0 pid=301063) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=301063) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=301063) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=301063) 	ld.param.b32 	%r25, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=301063) 	shr.s32 	%r26, %r25, 31;
(EngineCore_DP0 pid=301063) 	shr.u32 	%r27, %r26, 30;
(EngineCore_DP0 pid=301063) 	add.s32 	%r28, %r25, %r27;
(EngineCore_DP0 pid=301063) 	shr.s32 	%r29, %r28, 2;
(EngineCore_DP0 pid=301063) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=301063) 	mul.lo.s32 	%r30, %r29, %r1;
(EngineCore_DP0 pid=301063) 	mad.wide.s32 	%rd2, %r30, 4, %rd5;
(EngineCore_DP0 pid=301063) 	div.full.f32 	%r14, %r76, %r142;
(EngineCore_DP0 pid=301063) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=301063) 	mov.b32 	%r143, 0;
(EngineCore_DP0 pid=301063) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=301063)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=301063) 	.loc	1 202 31                        // quant_slide_tuned_Llama3.2-1B.py:202:31
(EngineCore_DP0 pid=301063) 	add.s32 	%r89, %r16, %r143;
(EngineCore_DP0 pid=301063) 	.loc	1 203 30                        // quant_slide_tuned_Llama3.2-1B.py:203:30
(EngineCore_DP0 pid=301063) 	add.s32 	%r90, %r143, 1;
(EngineCore_DP0 pid=301063) 	setp.lt.s32 	%p18, %r89, %r15;
(EngineCore_DP0 pid=301063) 	.loc	1 206 24                        // quant_slide_tuned_Llama3.2-1B.py:206:24
(EngineCore_DP0 pid=301063) 	shr.u32 	%r91, %r89, 1;
(EngineCore_DP0 pid=301063) 	.loc	1 207 23                        // quant_slide_tuned_Llama3.2-1B.py:207:23
(EngineCore_DP0 pid=301063) 	shr.u32 	%r92, %r90, 31;
(EngineCore_DP0 pid=301063) 	add.s32 	%r93, %r90, %r92;
(EngineCore_DP0 pid=301063) 	and.b32 	%r94, %r93, 2147483646;
(EngineCore_DP0 pid=301063) 	sub.s32 	%r95, %r90, %r94;
(EngineCore_DP0 pid=301063) 	.loc	1 208 22                        // quant_slide_tuned_Llama3.2-1B.py:208:22
(EngineCore_DP0 pid=301063) 	mul.lo.s32 	%r96, %r91, 6;
(EngineCore_DP0 pid=301063) 	.loc	1 208 30                        // quant_slide_tuned_Llama3.2-1B.py:208:30
(EngineCore_DP0 pid=301063) 	shl.b32 	%r97, %r95, 1;
(EngineCore_DP0 pid=301063) 	.loc	1 208 26                        // quant_slide_tuned_Llama3.2-1B.py:208:26
(EngineCore_DP0 pid=301063) 	add.s32 	%r98, %r96, %r97;
(EngineCore_DP0 pid=301063) 	.loc	1 211 53                        // quant_slide_tuned_Llama3.2-1B.py:211:53
(EngineCore_DP0 pid=301063) 	setp.lt.s32 	%p19, %r96, %r19;
(EngineCore_DP0 pid=301063) 	setp.lt.s32 	%p20, %r98, %r19;
(EngineCore_DP0 pid=301063) 	.loc	1 211 37                        // quant_slide_tuned_Llama3.2-1B.py:211:37
(EngineCore_DP0 pid=301063) 	and.pred 	%p10, %p18, %p19;
(EngineCore_DP0 pid=301063) 	and.pred 	%p11, %p18, %p20;
(EngineCore_DP0 pid=301063) 	.loc	1 210 29                        // quant_slide_tuned_Llama3.2-1B.py:210:29
(EngineCore_DP0 pid=301063) 	mad.wide.s32 	%rd9, %r96, 2, %rd1;
(EngineCore_DP0 pid=301063) 	mad.wide.s32 	%rd10, %r98, 2, %rd1;
(EngineCore_DP0 pid=301063) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=301063) 	.loc	1 210 21                        // quant_slide_tuned_Llama3.2-1B.py:210:21
(EngineCore_DP0 pid=301063) 	// begin inline asm
(EngineCore_DP0 pid=301063) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=301063) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=301063) 	// end inline asm
(EngineCore_DP0 pid=301063) 	// begin inline asm
(EngineCore_DP0 pid=301063) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=301063) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=301063) 	// end inline asm
(EngineCore_DP0 pid=301063) 	.loc	1 211 79                        // quant_slide_tuned_Llama3.2-1B.py:211:79
(EngineCore_DP0 pid=301063) 	cvt.f32.bf16 	%r99, %rs48;
(EngineCore_DP0 pid=301063) 	cvt.f32.bf16 	%r100, %rs50;
(EngineCore_DP0 pid=301063) 	.loc	1 213 48                        // quant_slide_tuned_Llama3.2-1B.py:213:48
(EngineCore_DP0 pid=301063) 	or.b32 	%r101, %r96, 1;
(EngineCore_DP0 pid=301063) 	or.b32 	%r102, %r98, 1;
(EngineCore_DP0 pid=301063) 	.loc	1 213 53                        // quant_slide_tuned_Llama3.2-1B.py:213:53
(EngineCore_DP0 pid=301063) 	setp.lt.s32 	%p21, %r101, %r19;
(EngineCore_DP0 pid=301063) 	setp.lt.s32 	%p22, %r102, %r19;
(EngineCore_DP0 pid=301063) 	.loc	1 213 37                        // quant_slide_tuned_Llama3.2-1B.py:213:37
(EngineCore_DP0 pid=301063) 	and.pred 	%p12, %p18, %p21;
(EngineCore_DP0 pid=301063) 	and.pred 	%p13, %p18, %p22;
(EngineCore_DP0 pid=301063) 	.loc	1 212 39                        // quant_slide_tuned_Llama3.2-1B.py:212:39
(EngineCore_DP0 pid=301063) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=301063) 	add.s64 	%rd12, %rd10, 2;
(EngineCore_DP0 pid=301063) 	.loc	1 212 21                        // quant_slide_tuned_Llama3.2-1B.py:212:21
(EngineCore_DP0 pid=301063) 	// begin inline asm
(EngineCore_DP0 pid=301063) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=301063) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=301063) 	// end inline asm
(EngineCore_DP0 pid=301063) 	// begin inline asm
(EngineCore_DP0 pid=301063) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=301063) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=301063) 	// end inline asm
(EngineCore_DP0 pid=301063) 	.loc	1 213 79                        // quant_slide_tuned_Llama3.2-1B.py:213:79
(EngineCore_DP0 pid=301063) 	cvt.f32.bf16 	%r103, %rs52;
(EngineCore_DP0 pid=301063) 	cvt.f32.bf16 	%r104, %rs54;
(EngineCore_DP0 pid=301063) 	.loc	1 215 48                        // quant_slide_tuned_Llama3.2-1B.py:215:48
(EngineCore_DP0 pid=301063) 	add.s32 	%r105, %r96, 2;
(EngineCore_DP0 pid=301063) 	add.s32 	%r106, %r98, 2;
(EngineCore_DP0 pid=301063) 	.loc	1 215 53                        // quant_slide_tuned_Llama3.2-1B.py:215:53
(EngineCore_DP0 pid=301063) 	setp.lt.s32 	%p23, %r105, %r19;
(EngineCore_DP0 pid=301063) 	setp.lt.s32 	%p24, %r106, %r19;
(EngineCore_DP0 pid=301063) 	.loc	1 215 37                        // quant_slide_tuned_Llama3.2-1B.py:215:37
(EngineCore_DP0 pid=301063) 	and.pred 	%p14, %p18, %p23;
(EngineCore_DP0 pid=301063) 	and.pred 	%p15, %p18, %p24;
(EngineCore_DP0 pid=301063) 	.loc	1 214 39                        // quant_slide_tuned_Llama3.2-1B.py:214:39
(EngineCore_DP0 pid=301063) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=301063) 	add.s64 	%rd14, %rd10, 4;
(EngineCore_DP0 pid=301063) 	.loc	1 214 21                        // quant_slide_tuned_Llama3.2-1B.py:214:21
(EngineCore_DP0 pid=301063) 	// begin inline asm
(EngineCore_DP0 pid=301063) 	mov.u16 %rs56, %rs49;
(EngineCore_DP0 pid=301063) 	@%p14 ld.global.b16 { %rs56 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=301063) 	// end inline asm
(EngineCore_DP0 pid=301063) 	// begin inline asm
(EngineCore_DP0 pid=301063) 	mov.u16 %rs58, %rs49;
(EngineCore_DP0 pid=301063) 	@%p15 ld.global.b16 { %rs58 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=301063) 	// end inline asm
(EngineCore_DP0 pid=301063) 	.loc	1 215 79                        // quant_slide_tuned_Llama3.2-1B.py:215:79
(EngineCore_DP0 pid=301063) 	cvt.f32.bf16 	%r107, %rs56;
(EngineCore_DP0 pid=301063) 	cvt.f32.bf16 	%r108, %rs58;
(EngineCore_DP0 pid=301063) 	.loc	1 217 48                        // quant_slide_tuned_Llama3.2-1B.py:217:48
(EngineCore_DP0 pid=301063) 	add.s32 	%r109, %r96, 3;
(EngineCore_DP0 pid=301063) 	add.s32 	%r110, %r98, 3;
(EngineCore_DP0 pid=301063) 	.loc	1 217 53                        // quant_slide_tuned_Llama3.2-1B.py:217:53
(EngineCore_DP0 pid=301063) 	setp.lt.s32 	%p25, %r109, %r19;
(EngineCore_DP0 pid=301063) 	setp.lt.s32 	%p26, %r110, %r19;
(EngineCore_DP0 pid=301063) 	.loc	1 217 37                        // quant_slide_tuned_Llama3.2-1B.py:217:37
(EngineCore_DP0 pid=301063) 	and.pred 	%p16, %p18, %p25;
(EngineCore_DP0 pid=301063) 	and.pred 	%p17, %p18, %p26;
(EngineCore_DP0 pid=301063) 	.loc	1 216 39                        // quant_slide_tuned_Llama3.2-1B.py:216:39
(EngineCore_DP0 pid=301063) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=301063) 	add.s64 	%rd16, %rd10, 6;
(EngineCore_DP0 pid=301063) 	.loc	1 216 21                        // quant_slide_tuned_Llama3.2-1B.py:216:21
(EngineCore_DP0 pid=301063) 	// begin inline asm
(EngineCore_DP0 pid=301063) 	mov.u16 %rs60, %rs49;
(EngineCore_DP0 pid=301063) 	@%p16 ld.global.b16 { %rs60 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=301063) 	// end inline asm
(EngineCore_DP0 pid=301063) 	// begin inline asm
(EngineCore_DP0 pid=301063) 	mov.u16 %rs62, %rs49;
(EngineCore_DP0 pid=301063) 	@%p17 ld.global.b16 { %rs62 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=301063) 	// end inline asm
(EngineCore_DP0 pid=301063) 	.loc	1 217 79                        // quant_slide_tuned_Llama3.2-1B.py:217:79
(EngineCore_DP0 pid=301063) 	cvt.f32.bf16 	%r111, %rs60;
(EngineCore_DP0 pid=301063) 	cvt.f32.bf16 	%r112, %rs62;
(EngineCore_DP0 pid=301063) 	.loc	1 219 27                        // quant_slide_tuned_Llama3.2-1B.py:219:27
(EngineCore_DP0 pid=301063) 	mul.f32 	%r113, %r14, %r99;
(EngineCore_DP0 pid=301063) 	mul.f32 	%r114, %r14, %r100;
(EngineCore_DP0 pid=301063) 	mov.b32 	%r115, 0f43E00000;
(EngineCore_DP0 pid=301063) 	.loc	1 219 48                        // quant_slide_tuned_Llama3.2-1B.py:219:48
(EngineCore_DP0 pid=301063) 	min.xorsign.abs.f32 	%r79, %r113, %r115;
(EngineCore_DP0 pid=301063) 	min.xorsign.abs.f32 	%r80, %r114, %r115;
(EngineCore_DP0 pid=301063) 	.loc	1 219 60                        // quant_slide_tuned_Llama3.2-1B.py:219:60
(EngineCore_DP0 pid=301063) 	// begin inline asm
(EngineCore_DP0 pid=301063) 	cvt.rn.satfinite.e4m3x2.f32  %rs64, %r80, %r79; 
(EngineCore_DP0 pid=301063) 
(EngineCore_DP0 pid=301063) 	// end inline asm
(EngineCore_DP0 pid=301063) 	shr.u16 	%rs68, %rs64, 8;
(EngineCore_DP0 pid=301063) 	.loc	1 220 27                        // quant_slide_tuned_Llama3.2-1B.py:220:27
(EngineCore_DP0 pid=301063) 	mul.f32 	%r116, %r14, %r103;
(EngineCore_DP0 pid=301063) 	mul.f32 	%r117, %r14, %r104;
(EngineCore_DP0 pid=301063) 	.loc	1 220 48                        // quant_slide_tuned_Llama3.2-1B.py:220:48
(EngineCore_DP0 pid=301063) 	min.xorsign.abs.f32 	%r81, %r116, %r115;
(EngineCore_DP0 pid=301063) 	min.xorsign.abs.f32 	%r82, %r117, %r115;
(EngineCore_DP0 pid=301063) 	.loc	1 220 60                        // quant_slide_tuned_Llama3.2-1B.py:220:60
(EngineCore_DP0 pid=301063) 	// begin inline asm
(EngineCore_DP0 pid=301063) 	cvt.rn.satfinite.e4m3x2.f32  %rs65, %r82, %r81; 
(EngineCore_DP0 pid=301063) 
(EngineCore_DP0 pid=301063) 	// end inline asm
(EngineCore_DP0 pid=301063) 	shr.u16 	%rs69, %rs65, 8;
(EngineCore_DP0 pid=301063) 	.loc	1 221 27                        // quant_slide_tuned_Llama3.2-1B.py:221:27
(EngineCore_DP0 pid=301063) 	mul.f32 	%r118, %r14, %r107;
(EngineCore_DP0 pid=301063) 	mul.f32 	%r119, %r14, %r108;
(EngineCore_DP0 pid=301063) 	.loc	1 221 48                        // quant_slide_tuned_Llama3.2-1B.py:221:48
(EngineCore_DP0 pid=301063) 	min.xorsign.abs.f32 	%r83, %r118, %r115;
(EngineCore_DP0 pid=301063) 	min.xorsign.abs.f32 	%r84, %r119, %r115;
(EngineCore_DP0 pid=301063) 	.loc	1 221 60                        // quant_slide_tuned_Llama3.2-1B.py:221:60
(EngineCore_DP0 pid=301063) 	// begin inline asm
(EngineCore_DP0 pid=301063) 	cvt.rn.satfinite.e4m3x2.f32  %rs66, %r84, %r83; 
(EngineCore_DP0 pid=301063) 
(EngineCore_DP0 pid=301063) 	// end inline asm
(EngineCore_DP0 pid=301063) 	shr.u16 	%rs70, %rs66, 8;
(EngineCore_DP0 pid=301063) 	.loc	1 222 27                        // quant_slide_tuned_Llama3.2-1B.py:222:27
(EngineCore_DP0 pid=301063) 	mul.f32 	%r120, %r14, %r111;
(EngineCore_DP0 pid=301063) 	mul.f32 	%r121, %r14, %r112;
(EngineCore_DP0 pid=301063) 	.loc	1 222 48                        // quant_slide_tuned_Llama3.2-1B.py:222:48
(EngineCore_DP0 pid=301063) 	min.xorsign.abs.f32 	%r85, %r120, %r115;
(EngineCore_DP0 pid=301063) 	min.xorsign.abs.f32 	%r86, %r121, %r115;
(EngineCore_DP0 pid=301063) 	.loc	1 222 60                        // quant_slide_tuned_Llama3.2-1B.py:222:60
(EngineCore_DP0 pid=301063) 	// begin inline asm
(EngineCore_DP0 pid=301063) 	cvt.rn.satfinite.e4m3x2.f32  %rs67, %r86, %r85; 
(EngineCore_DP0 pid=301063) 
(EngineCore_DP0 pid=301063) 	// end inline asm
(EngineCore_DP0 pid=301063) 	shr.u16 	%rs71, %rs67, 8;
(EngineCore_DP0 pid=301063) 	.loc	1 224 45                        // quant_slide_tuned_Llama3.2-1B.py:224:45
(EngineCore_DP0 pid=301063) 	cvt.u32.u16 	%r122, %rs64;
(EngineCore_DP0 pid=301063) 	and.b32 	%r123, %r122, 255;
(EngineCore_DP0 pid=301063) 	cvt.u32.u16 	%r124, %rs68;
(EngineCore_DP0 pid=301063) 	.loc	1 226 45                        // quant_slide_tuned_Llama3.2-1B.py:226:45
(EngineCore_DP0 pid=301063) 	cvt.u32.u16 	%r125, %rs66;
(EngineCore_DP0 pid=301063) 	and.b32 	%r126, %r125, 255;
(EngineCore_DP0 pid=301063) 	cvt.u32.u16 	%r127, %rs70;
(EngineCore_DP0 pid=301063) 	.loc	1 227 45                        // quant_slide_tuned_Llama3.2-1B.py:227:45
(EngineCore_DP0 pid=301063) 	cvt.u32.u16 	%r128, %rs67;
(EngineCore_DP0 pid=301063) 	cvt.u32.u16 	%r129, %rs71;
(EngineCore_DP0 pid=301063) 	.loc	1 229 30                        // quant_slide_tuned_Llama3.2-1B.py:229:30
(EngineCore_DP0 pid=301063) 	and.b16 	%rs72, %rs65, 255;
(EngineCore_DP0 pid=301063) 	mul.wide.u16 	%r130, %rs72, 256;
(EngineCore_DP0 pid=301063) 	mul.wide.u16 	%r131, %rs69, 256;
(EngineCore_DP0 pid=301063) 	.loc	1 229 24                        // quant_slide_tuned_Llama3.2-1B.py:229:24
(EngineCore_DP0 pid=301063) 	or.b32 	%r132, %r130, %r123;
(EngineCore_DP0 pid=301063) 	or.b32 	%r133, %r131, %r124;
(EngineCore_DP0 pid=301063) 	.loc	1 229 42                        // quant_slide_tuned_Llama3.2-1B.py:229:42
(EngineCore_DP0 pid=301063) 	shl.b32 	%r134, %r126, 16;
(EngineCore_DP0 pid=301063) 	shl.b32 	%r135, %r127, 16;
(EngineCore_DP0 pid=301063) 	.loc	1 229 36                        // quant_slide_tuned_Llama3.2-1B.py:229:36
(EngineCore_DP0 pid=301063) 	or.b32 	%r136, %r132, %r134;
(EngineCore_DP0 pid=301063) 	or.b32 	%r137, %r133, %r135;
(EngineCore_DP0 pid=301063) 	.loc	1 229 55                        // quant_slide_tuned_Llama3.2-1B.py:229:55
(EngineCore_DP0 pid=301063) 	shl.b32 	%r138, %r128, 24;
(EngineCore_DP0 pid=301063) 	shl.b32 	%r139, %r129, 24;
(EngineCore_DP0 pid=301063) 	.loc	1 229 49                        // quant_slide_tuned_Llama3.2-1B.py:229:49
(EngineCore_DP0 pid=301063) 	or.b32 	%r87, %r136, %r138;
(EngineCore_DP0 pid=301063) 	or.b32 	%r88, %r137, %r139;
(EngineCore_DP0 pid=301063) 	.loc	1 230 29                        // quant_slide_tuned_Llama3.2-1B.py:230:29
(EngineCore_DP0 pid=301063) 	mad.wide.s32 	%rd17, %r89, 4, %rd2;
(EngineCore_DP0 pid=301063) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-1B.py:230:39
(EngineCore_DP0 pid=301063) 	// begin inline asm
(EngineCore_DP0 pid=301063) 	@%p18 st.global.v2.b32 [ %rd17 + 0 ], { %r87, %r88 };
(EngineCore_DP0 pid=301063) 	// end inline asm
(EngineCore_DP0 pid=301063) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=301063) 	add.s32 	%r143, %r143, 256;
(EngineCore_DP0 pid=301063) 	setp.lt.s32 	%p27, %r143, %r15;
(EngineCore_DP0 pid=301063) 	@%p27 bra 	$L__BB0_6;
(EngineCore_DP0 pid=301063) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=301063) 	.loc	1 201 4                         // quant_slide_tuned_Llama3.2-1B.py:201:4
(EngineCore_DP0 pid=301063) 	ret;
(EngineCore_DP0 pid=301063) $L__tmp3:
(EngineCore_DP0 pid=301063) $L__func_end0:
(EngineCore_DP0 pid=301063)                                         // -- End function
(EngineCore_DP0 pid=301063) }
(EngineCore_DP0 pid=301063) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=301063) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=301063) 	.section	.debug_abbrev
(EngineCore_DP0 pid=301063) 	{
(EngineCore_DP0 pid=301063) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=301063) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=301063) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=301063) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=301063) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=301063) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=301063) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=301063) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=301063) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=301063) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=301063) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=301063) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=301063) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=301063) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=301063) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=301063) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=301063) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=301063) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=301063) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=301063) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=301063) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=301063) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=301063) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=301063) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=301063) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=301063) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=301063) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=301063) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=301063) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=301063) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=301063) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=301063) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=301063) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=301063) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=301063) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=301063) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=301063) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=301063) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=301063) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=301063) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=301063) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=301063) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=301063) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=301063) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=301063) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=301063) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=301063) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=301063) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=301063) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=301063) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=301063) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=301063) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=301063) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=301063) 	}
(EngineCore_DP0 pid=301063) 	.section	.debug_info
(EngineCore_DP0 pid=301063) 	{
(EngineCore_DP0 pid=301063) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=301063) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=301063) .b8 0
(EngineCore_DP0 pid=301063) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=301063) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=301063) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=301063) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=301063) .b8 114
(EngineCore_DP0 pid=301063) .b8 105
(EngineCore_DP0 pid=301063) .b8 116
(EngineCore_DP0 pid=301063) .b8 111
(EngineCore_DP0 pid=301063) .b8 110
(EngineCore_DP0 pid=301063) .b8 0
(EngineCore_DP0 pid=301063) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=301063) .b8 0
(EngineCore_DP0 pid=301063) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=301063) .b8 117
(EngineCore_DP0 pid=301063) .b8 97
(EngineCore_DP0 pid=301063) .b8 110
(EngineCore_DP0 pid=301063) .b8 116
(EngineCore_DP0 pid=301063) .b8 95
(EngineCore_DP0 pid=301063) .b8 115
(EngineCore_DP0 pid=301063) .b8 108
(EngineCore_DP0 pid=301063) .b8 105
(EngineCore_DP0 pid=301063) .b8 100
(EngineCore_DP0 pid=301063) .b8 101
(EngineCore_DP0 pid=301063) .b8 95
(EngineCore_DP0 pid=301063) .b8 116
(EngineCore_DP0 pid=301063) .b8 117
(EngineCore_DP0 pid=301063) .b8 110
(EngineCore_DP0 pid=301063) .b8 101
(EngineCore_DP0 pid=301063) .b8 100
(EngineCore_DP0 pid=301063) .b8 95
(EngineCore_DP0 pid=301063) .b8 76
(EngineCore_DP0 pid=301063) .b8 108
(EngineCore_DP0 pid=301063) .b8 97
(EngineCore_DP0 pid=301063) .b8 109
(EngineCore_DP0 pid=301063) .b8 97
(EngineCore_DP0 pid=301063) .b8 51
(EngineCore_DP0 pid=301063) .b8 46
(EngineCore_DP0 pid=301063) .b8 50
(EngineCore_DP0 pid=301063) .b8 45
(EngineCore_DP0 pid=301063) .b8 49
(EngineCore_DP0 pid=301063) .b8 66
(EngineCore_DP0 pid=301063) .b8 46
(EngineCore_DP0 pid=301063) .b8 112
(EngineCore_DP0 pid=301063) .b8 121
(EngineCore_DP0 pid=301063) .b8 0
(EngineCore_DP0 pid=301063) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=301063) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=301063) .b8 114
(EngineCore_DP0 pid=301063) .b8 111
(EngineCore_DP0 pid=301063) .b8 111
(EngineCore_DP0 pid=301063) .b8 116
(EngineCore_DP0 pid=301063) .b8 47
(EngineCore_DP0 pid=301063) .b8 118
(EngineCore_DP0 pid=301063) .b8 108
(EngineCore_DP0 pid=301063) .b8 108
(EngineCore_DP0 pid=301063) .b8 109
(EngineCore_DP0 pid=301063) .b8 98
(EngineCore_DP0 pid=301063) .b8 101
(EngineCore_DP0 pid=301063) .b8 110
(EngineCore_DP0 pid=301063) .b8 99
(EngineCore_DP0 pid=301063) .b8 104
(EngineCore_DP0 pid=301063) .b8 47
(EngineCore_DP0 pid=301063) .b8 115
(EngineCore_DP0 pid=301063) .b8 108
(EngineCore_DP0 pid=301063) .b8 105
(EngineCore_DP0 pid=301063) .b8 100
(EngineCore_DP0 pid=301063) .b8 101
(EngineCore_DP0 pid=301063) .b8 115
(EngineCore_DP0 pid=301063) .b8 112
(EngineCore_DP0 pid=301063) .b8 97
(EngineCore_DP0 pid=301063) .b8 114
(EngineCore_DP0 pid=301063) .b8 115
(EngineCore_DP0 pid=301063) .b8 101
(EngineCore_DP0 pid=301063) .b8 47
(EngineCore_DP0 pid=301063) .b8 99
(EngineCore_DP0 pid=301063) .b8 115
(EngineCore_DP0 pid=301063) .b8 114
(EngineCore_DP0 pid=301063) .b8 99
(EngineCore_DP0 pid=301063) .b8 47
(EngineCore_DP0 pid=301063) .b8 102
(EngineCore_DP0 pid=301063) .b8 117
(EngineCore_DP0 pid=301063) .b8 115
(EngineCore_DP0 pid=301063) .b8 101
(EngineCore_DP0 pid=301063) .b8 100
(EngineCore_DP0 pid=301063) .b8 95
(EngineCore_DP0 pid=301063) .b8 113
(EngineCore_DP0 pid=301063) .b8 117
(EngineCore_DP0 pid=301063) .b8 97
(EngineCore_DP0 pid=301063) .b8 110
(EngineCore_DP0 pid=301063) .b8 116
(EngineCore_DP0 pid=301063) .b8 95
(EngineCore_DP0 pid=301063) .b8 115
(EngineCore_DP0 pid=301063) .b8 108
(EngineCore_DP0 pid=301063) .b8 105
(EngineCore_DP0 pid=301063) .b8 100
(EngineCore_DP0 pid=301063) .b8 101
(EngineCore_DP0 pid=301063) .b8 95
(EngineCore_DP0 pid=301063) .b8 116
(EngineCore_DP0 pid=301063) .b8 114
(EngineCore_DP0 pid=301063) .b8 105
(EngineCore_DP0 pid=301063) .b8 116
(EngineCore_DP0 pid=301063) .b8 111
(EngineCore_DP0 pid=301063) .b8 110
(EngineCore_DP0 pid=301063) .b8 47
(EngineCore_DP0 pid=301063) .b8 98
(EngineCore_DP0 pid=301063) .b8 117
(EngineCore_DP0 pid=301063) .b8 105
(EngineCore_DP0 pid=301063) .b8 108
(EngineCore_DP0 pid=301063) .b8 100
(EngineCore_DP0 pid=301063) .b8 47
(EngineCore_DP0 pid=301063) .b8 71
(EngineCore_DP0 pid=301063) .b8 66
(EngineCore_DP0 pid=301063) .b8 49
(EngineCore_DP0 pid=301063) .b8 48
(EngineCore_DP0 pid=301063) .b8 95
(EngineCore_DP0 pid=301063) .b8 99
(EngineCore_DP0 pid=301063) .b8 99
(EngineCore_DP0 pid=301063) .b8 49
(EngineCore_DP0 pid=301063) .b8 50
(EngineCore_DP0 pid=301063) .b8 49
(EngineCore_DP0 pid=301063) .b8 95
(EngineCore_DP0 pid=301063) .b8 112
(EngineCore_DP0 pid=301063) .b8 121
(EngineCore_DP0 pid=301063) .b8 51
(EngineCore_DP0 pid=301063) .b8 49
(EngineCore_DP0 pid=301063) .b8 50
(EngineCore_DP0 pid=301063) .b8 95
(EngineCore_DP0 pid=301063) .b8 99
(EngineCore_DP0 pid=301063) .b8 117
(EngineCore_DP0 pid=301063) .b8 49
(EngineCore_DP0 pid=301063) .b8 50
(EngineCore_DP0 pid=301063) .b8 57
(EngineCore_DP0 pid=301063) .b8 95
(EngineCore_DP0 pid=301063) .b8 97
(EngineCore_DP0 pid=301063) .b8 97
(EngineCore_DP0 pid=301063) .b8 114
(EngineCore_DP0 pid=301063) .b8 99
(EngineCore_DP0 pid=301063) .b8 104
(EngineCore_DP0 pid=301063) .b8 54
(EngineCore_DP0 pid=301063) .b8 52
(EngineCore_DP0 pid=301063) .b8 0
(EngineCore_DP0 pid=301063) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=301063) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=301063) .b8 113
(EngineCore_DP0 pid=301063) .b8 117
(EngineCore_DP0 pid=301063) .b8 97
(EngineCore_DP0 pid=301063) .b8 110
(EngineCore_DP0 pid=301063) .b8 116
(EngineCore_DP0 pid=301063) .b8 95
(EngineCore_DP0 pid=301063) .b8 115
(EngineCore_DP0 pid=301063) .b8 108
(EngineCore_DP0 pid=301063) .b8 105
(EngineCore_DP0 pid=301063) .b8 100
(EngineCore_DP0 pid=301063) .b8 101
(EngineCore_DP0 pid=301063) .b8 95
(EngineCore_DP0 pid=301063) .b8 102
(EngineCore_DP0 pid=301063) .b8 112
(EngineCore_DP0 pid=301063) .b8 56
(EngineCore_DP0 pid=301063) .b8 95
(EngineCore_DP0 pid=301063) .b8 107
(EngineCore_DP0 pid=301063) .b8 101
(EngineCore_DP0 pid=301063) .b8 114
(EngineCore_DP0 pid=301063) .b8 110
(EngineCore_DP0 pid=301063) .b8 101
(EngineCore_DP0 pid=301063) .b8 108
(EngineCore_DP0 pid=301063) .b8 0
(EngineCore_DP0 pid=301063) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=301063) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=301063) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=301063) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=301063) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=301063) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=301063) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=301063) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=301063) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=301063) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=301063) .b8 191                                 // DW_AT_call_line
(EngineCore_DP0 pid=301063) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=301063) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=301063) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=301063) 	}
(EngineCore_DP0 pid=301063) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=301063) 
(EngineCore_DP0 pid=301063) ================================================================
(EngineCore_DP0 pid=301063) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=301063) 
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpg8rl0772.ptx', '-o', '/tmp/tmpg8rl0772.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866] 
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866] 
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866] 
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpg8rl0772.ptx -o /tmp/tmpg8rl0772.ptx.o
(EngineCore_DP0 pid=301063) ERROR 01-25 18:48:34 [core.py:866] 

STDERR:
[2026-01-25 18:48:19] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 18:48:19] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 18:48:19] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 18:48:19] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:48:19] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:48:19] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:48:19] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:48:19] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:48:19] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 18:48:19] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 18:48:19] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 18:48:19] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 18:48:19] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 18:48:19] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 18:48:22] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 18:48:22] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 18:48:22] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 18:48:22] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:48:22] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:48:22] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:48:22] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:48:22] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:48:22] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 18:48:22] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 18:48:22] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 18:48:22] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 18:48:22] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 18:48:22] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=301063) [2026-01-25 18:48:23] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=301063) [2026-01-25 18:48:23] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=301063) [2026-01-25 18:48:23] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=301063) [2026-01-25 18:48:23] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=301063) [2026-01-25 18:48:23] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=301063) [2026-01-25 18:48:23] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=301063) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=301063) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.27s/it]
(EngineCore_DP0 pid=301063) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.27s/it]
(EngineCore_DP0 pid=301063) 
(EngineCore_DP0 pid=301063) [2026-01-25 18:48:33] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=301063) [2026-01-25 18:48:33] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5308416 bytes
(EngineCore_DP0 pid=301063) [2026-01-25 18:48:33] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=301063) [2026-01-25 18:48:33] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3538944 bytes
(EngineCore_DP0 pid=301063) [2026-01-25 18:48:33] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=301063) [2026-01-25 18:48:33] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 28311552 bytes
(EngineCore_DP0 pid=301063) [2026-01-25 18:48:33] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=301063) [2026-01-25 18:48:33] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14024704 bytes
(EngineCore_DP0 pid=301063) Process EngineCore_DP0:
(EngineCore_DP0 pid=301063) Traceback (most recent call last):
(EngineCore_DP0 pid=301063)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=301063)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=301063)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=301063)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=301063) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpg8rl0772.ptx', '-o', '/tmp/tmpg8rl0772.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=301063) 
(EngineCore_DP0 pid=301063) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=301063) 
(EngineCore_DP0 pid=301063) Traceback (most recent call last):
(EngineCore_DP0 pid=301063)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=301063)     self.run()
(EngineCore_DP0 pid=301063)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=301063)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=301063)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=301063)     raise e
(EngineCore_DP0 pid=301063)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=301063)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=301063)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=301063)     super().__init__(
(EngineCore_DP0 pid=301063)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=301063)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=301063)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=301063)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=301063)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=301063)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=301063)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=301063)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=301063)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=301063)     return func(*args, **kwargs)
(EngineCore_DP0 pid=301063)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=301063)     return func(*args, **kwargs)
(EngineCore_DP0 pid=301063)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=301063)     self.model_runner.profile_run()
(EngineCore_DP0 pid=301063)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=301063)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=301063)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=301063)     return func(*args, **kwargs)
(EngineCore_DP0 pid=301063)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=301063)     outputs = self.model(
(EngineCore_DP0 pid=301063)               ^^^^^^^^^^^
(EngineCore_DP0 pid=301063)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=301063)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=301063)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=301063)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=301063)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=301063)     model_output = self.model(
(EngineCore_DP0 pid=301063)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=301063)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=301063)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=301063)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=301063)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=301063)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=301063)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=301063)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=301063)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=301063)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=301063)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=301063)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=301063)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=301063)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=301063)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=301063)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=301063)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=301063)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=301063)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=301063)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=301063)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=301063)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=301063)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=301063)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=301063)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=301063)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=301063)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=301063)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=301063)     return self._linear_fn(
(EngineCore_DP0 pid=301063)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=301063)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=301063)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=301063)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=301063)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=301063)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=301063)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=301063)     return fn(input, L)
(EngineCore_DP0 pid=301063)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=301063)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=301063)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=301063)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=301063)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=301063)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=301063)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=301063)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=301063)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=301063)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=301063)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=301063)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=301063)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=301063)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301063)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=301063)     raise PTXASError(error)
(EngineCore_DP0 pid=301063) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=301063) `ptxas` stderr:
(EngineCore_DP0 pid=301063) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=301063) 
(EngineCore_DP0 pid=301063) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpg8rl0772.ptx -o /tmp/tmpg8rl0772.ptx.o
(EngineCore_DP0 pid=301063) 
[rank0]:[W125 18:48:34.648215329 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=128

========== M=256 ==========
Time: 2026-01-25 18:48:36
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6
Params: prompt_len=256, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6 --dataset-name random --input-len 256 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 257 --max-num-batched-tokens 257 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-FP8_M256.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 18:48:39 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 18:48:39 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=301537) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=301537) 
(EngineCore_DP0 pid=301537) 
(EngineCore_DP0 pid=301537) ================================================================
(EngineCore_DP0 pid=301537) Internal Triton PTX codegen error
(EngineCore_DP0 pid=301537) `ptxas` stderr:
(EngineCore_DP0 pid=301537) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=301537) 
(EngineCore_DP0 pid=301537) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp9olzu8yn.ptx -o /tmp/tmp9olzu8yn.ptx.o
(EngineCore_DP0 pid=301537) 
(EngineCore_DP0 pid=301537) 
(EngineCore_DP0 pid=301537) //
(EngineCore_DP0 pid=301537) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=301537) //
(EngineCore_DP0 pid=301537) 
(EngineCore_DP0 pid=301537) .version 8.7
(EngineCore_DP0 pid=301537) .target sm_121a
(EngineCore_DP0 pid=301537) .address_size 64
(EngineCore_DP0 pid=301537) 
(EngineCore_DP0 pid=301537) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=301537) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=301537)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=301537) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=301537) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=301537) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=301537) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=301537) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=301537) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=301537) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=301537) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=301537) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=301537) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=301537) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=301537) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=301537) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=301537) )
(EngineCore_DP0 pid=301537) .reqntid 1024
(EngineCore_DP0 pid=301537) {
(EngineCore_DP0 pid=301537) 	.reg .pred 	%p<20>;
(EngineCore_DP0 pid=301537) 	.reg .b16 	%rs<25>;
(EngineCore_DP0 pid=301537) 	.reg .b32 	%r<114>;
(EngineCore_DP0 pid=301537) 	.reg .b64 	%rd<13>;
(EngineCore_DP0 pid=301537) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=301537) $L__func_begin0:
(EngineCore_DP0 pid=301537) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=301537) 
(EngineCore_DP0 pid=301537) // %bb.0:
(EngineCore_DP0 pid=301537) 	ld.param.b32 	%r19, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=301537) 	ld.param.b32 	%r18, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=301537) 	ld.param.b32 	%r17, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=301537) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=301537) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=301537) $L__tmp0:
(EngineCore_DP0 pid=301537) 	.loc	1 177 24                        // quant_slide_tuned_Llama3.2-1B.py:177:24
(EngineCore_DP0 pid=301537) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=301537) 	ld.param.b32 	%r21, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=301537) 	.loc	1 182 26                        // quant_slide_tuned_Llama3.2-1B.py:182:26
(EngineCore_DP0 pid=301537) 	mul.lo.s32 	%r22, %r21, %r1;
(EngineCore_DP0 pid=301537) 	.loc	1 182 20                        // quant_slide_tuned_Llama3.2-1B.py:182:20
(EngineCore_DP0 pid=301537) 	mad.wide.s32 	%rd1, %r22, 2, %rd4;
(EngineCore_DP0 pid=301537) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=301537) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=301537) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=301537) 	setp.lt.s32 	%p1, %r18, 1;
(EngineCore_DP0 pid=301537) 	mov.b32 	%r112, 0f2B8CBCCC;
(EngineCore_DP0 pid=301537) 	setp.eq.b32 	%p19, %r2, 0;
(EngineCore_DP0 pid=301537) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=301537) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=301537) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=301537) 	shl.b32 	%r3, %r2, 2;
(EngineCore_DP0 pid=301537) 	and.b32 	%r4, %r2, 31;
(EngineCore_DP0 pid=301537) 	shr.u32 	%r31, %r2, 3;
(EngineCore_DP0 pid=301537) 	and.b32 	%r32, %r31, 124;
(EngineCore_DP0 pid=301537) 	mov.b32 	%r33, global_smem;
(EngineCore_DP0 pid=301537) 	add.s32 	%r39, %r33, %r32;
(EngineCore_DP0 pid=301537) 	add.s32 	%r42, %r33, %r3;
(EngineCore_DP0 pid=301537) 	mov.b32 	%r37, 0;
(EngineCore_DP0 pid=301537) 	mov.b32 	%r110, 0f00000000;
(EngineCore_DP0 pid=301537) 	setp.lt.u32 	%p4, %r2, 32;
(EngineCore_DP0 pid=301537) 	setp.eq.b32 	%p3, %r4, 0;
(EngineCore_DP0 pid=301537) 	mov.b32 	%r111, %r37;
(EngineCore_DP0 pid=301537) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=301537) 	.loc	1 189 22                        // quant_slide_tuned_Llama3.2-1B.py:189:22
(EngineCore_DP0 pid=301537) 	add.s32 	%r45, %r3, %r111;
(EngineCore_DP0 pid=301537) 	setp.lt.s32 	%p2, %r45, %r17;
(EngineCore_DP0 pid=301537) 	.loc	1 190 29                        // quant_slide_tuned_Llama3.2-1B.py:190:29
(EngineCore_DP0 pid=301537) 	mad.wide.s32 	%rd6, %r45, 2, %rd1;
(EngineCore_DP0 pid=301537) 	.loc	1 190 21                        // quant_slide_tuned_Llama3.2-1B.py:190:21
(EngineCore_DP0 pid=301537) 	// begin inline asm
(EngineCore_DP0 pid=301537) 	mov.u32 %r35, %r37;
(EngineCore_DP0 pid=301537) 	mov.u32 %r36, %r37;
(EngineCore_DP0 pid=301537) 	@%p2 ld.global.v2.b32 { %r35, %r36 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=301537) 	// end inline asm
(EngineCore_DP0 pid=301537) 	mov.b32 	{%rs1, %rs2}, %r35;
(EngineCore_DP0 pid=301537) 	mov.b32 	{%rs3, %rs4}, %r36;
(EngineCore_DP0 pid=301537) 	.loc	1 191 50                        // quant_slide_tuned_Llama3.2-1B.py:191:50
(EngineCore_DP0 pid=301537) 	abs.bf16 	%rs5, %rs1;
(EngineCore_DP0 pid=301537) 	abs.bf16 	%rs6, %rs2;
(EngineCore_DP0 pid=301537) 	abs.bf16 	%rs7, %rs3;
(EngineCore_DP0 pid=301537) 	abs.bf16 	%rs8, %rs4;
(EngineCore_DP0 pid=301537) $L__tmp1:
(EngineCore_DP0 pid=301537) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=301537) 	bar.sync 	0;
(EngineCore_DP0 pid=301537) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=301537) 	max.bf16 	%rs9, %rs5, %rs6;
(EngineCore_DP0 pid=301537) 	max.bf16 	%rs10, %rs9, %rs7;
(EngineCore_DP0 pid=301537) 	max.bf16 	%rs11, %rs10, %rs8;
(EngineCore_DP0 pid=301537) 	cvt.f32.bf16 	%r46, %rs11;
(EngineCore_DP0 pid=301537) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=301537) 	shfl.sync.bfly.b32 	%r47, %r46, 16, 31, -1;
(EngineCore_DP0 pid=301537) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=301537) 	max.f32 	%r48, %r46, %r47;
(EngineCore_DP0 pid=301537) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=301537) 	shfl.sync.bfly.b32 	%r49, %r48, 8, 31, -1;
(EngineCore_DP0 pid=301537) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=301537) 	max.f32 	%r50, %r48, %r49;
(EngineCore_DP0 pid=301537) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=301537) 	shfl.sync.bfly.b32 	%r51, %r50, 4, 31, -1;
(EngineCore_DP0 pid=301537) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=301537) 	max.f32 	%r52, %r50, %r51;
(EngineCore_DP0 pid=301537) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=301537) 	shfl.sync.bfly.b32 	%r53, %r52, 2, 31, -1;
(EngineCore_DP0 pid=301537) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=301537) 	max.f32 	%r54, %r52, %r53;
(EngineCore_DP0 pid=301537) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=301537) 	shfl.sync.bfly.b32 	%r55, %r54, 1, 31, -1;
(EngineCore_DP0 pid=301537) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=301537) 	max.f32 	%r40, %r54, %r55;
(EngineCore_DP0 pid=301537) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=301537) 	// begin inline asm
(EngineCore_DP0 pid=301537) 	@%p3 st.shared.b32 [ %r39 + 0 ], %r40;
(EngineCore_DP0 pid=301537) 	// end inline asm
(EngineCore_DP0 pid=301537) 	bar.sync 	0;
(EngineCore_DP0 pid=301537) 	// begin inline asm
(EngineCore_DP0 pid=301537) 	@%p4 ld.shared.b32 %r41, [ %r42 + 0 ];
(EngineCore_DP0 pid=301537) 	// end inline asm
(EngineCore_DP0 pid=301537) 	shfl.sync.bfly.b32 	%r56, %r41, 16, 31, -1;
(EngineCore_DP0 pid=301537) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=301537) 	max.f32 	%r57, %r41, %r56;
(EngineCore_DP0 pid=301537) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=301537) 	shfl.sync.bfly.b32 	%r58, %r57, 8, 31, -1;
(EngineCore_DP0 pid=301537) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=301537) 	max.f32 	%r59, %r57, %r58;
(EngineCore_DP0 pid=301537) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=301537) 	shfl.sync.bfly.b32 	%r60, %r59, 4, 31, -1;
(EngineCore_DP0 pid=301537) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=301537) 	max.f32 	%r61, %r59, %r60;
(EngineCore_DP0 pid=301537) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=301537) 	shfl.sync.bfly.b32 	%r62, %r61, 2, 31, -1;
(EngineCore_DP0 pid=301537) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=301537) 	max.f32 	%r63, %r61, %r62;
(EngineCore_DP0 pid=301537) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=301537) 	shfl.sync.bfly.b32 	%r64, %r63, 1, 31, -1;
(EngineCore_DP0 pid=301537) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=301537) 	max.f32 	%r44, %r63, %r64;
(EngineCore_DP0 pid=301537) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=301537) 	// begin inline asm
(EngineCore_DP0 pid=301537) 	@%p19 st.shared.b32 [ %r42 + 0 ], %r44;
(EngineCore_DP0 pid=301537) 	// end inline asm
(EngineCore_DP0 pid=301537) 	bar.sync 	0;
(EngineCore_DP0 pid=301537) 	ld.shared.b32 	%r65, [global_smem];
(EngineCore_DP0 pid=301537) $L__tmp2:
(EngineCore_DP0 pid=301537) 	.loc	1 191 36                        // quant_slide_tuned_Llama3.2-1B.py:191:36
(EngineCore_DP0 pid=301537) 	max.f32 	%r110, %r110, %r65;
(EngineCore_DP0 pid=301537) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=301537) 	add.s32 	%r111, %r111, 4096;
(EngineCore_DP0 pid=301537) 	setp.lt.s32 	%p6, %r111, %r18;
(EngineCore_DP0 pid=301537) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=301537) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=301537) 	.loc	1 193 32                        // quant_slide_tuned_Llama3.2-1B.py:193:32
(EngineCore_DP0 pid=301537) 	max.f32 	%r112, %r110, 0f2B8CBCCC;
(EngineCore_DP0 pid=301537) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=301537) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=301537) 	mov.b32 	%r67, 0f43E00000;
(EngineCore_DP0 pid=301537) 	.loc	1 194 32                        // quant_slide_tuned_Llama3.2-1B.py:194:32
(EngineCore_DP0 pid=301537) 	div.full.f32 	%r68, %r112, %r67;
(EngineCore_DP0 pid=301537) 	.loc	1 194 41                        // quant_slide_tuned_Llama3.2-1B.py:194:41
(EngineCore_DP0 pid=301537) 	max.f32 	%r66, %r68, 0f36924925;
(EngineCore_DP0 pid=301537) 	.loc	1 196 25                        // quant_slide_tuned_Llama3.2-1B.py:196:25
(EngineCore_DP0 pid=301537) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=301537) 	.loc	1 196 30                        // quant_slide_tuned_Llama3.2-1B.py:196:30
(EngineCore_DP0 pid=301537) 	// begin inline asm
(EngineCore_DP0 pid=301537) 	@%p19 st.global.b32 [ %rd7 + 0 ], { %r66 };
(EngineCore_DP0 pid=301537) 	// end inline asm
(EngineCore_DP0 pid=301537) 	.loc	1 199 29                        // quant_slide_tuned_Llama3.2-1B.py:199:29
(EngineCore_DP0 pid=301537) 	shl.b32 	%r14, %r19, 1;
(EngineCore_DP0 pid=301537) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=301537) 	setp.lt.s32 	%p8, %r14, 1;
(EngineCore_DP0 pid=301537) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=301537) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=301537) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=301537) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=301537) 	shr.s32 	%r24, %r23, 31;
(EngineCore_DP0 pid=301537) 	shr.u32 	%r25, %r24, 30;
(EngineCore_DP0 pid=301537) 	add.s32 	%r26, %r23, %r25;
(EngineCore_DP0 pid=301537) 	shr.s32 	%r27, %r26, 2;
(EngineCore_DP0 pid=301537) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=301537) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=301537) 	mad.wide.s32 	%rd2, %r28, 4, %rd5;
(EngineCore_DP0 pid=301537) 	div.full.f32 	%r13, %r67, %r112;
(EngineCore_DP0 pid=301537) 	mov.b32 	%r113, 0;
(EngineCore_DP0 pid=301537) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=301537)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=301537) 	.loc	1 203 30                        // quant_slide_tuned_Llama3.2-1B.py:203:30
(EngineCore_DP0 pid=301537) 	add.s32 	%r80, %r2, %r113;
(EngineCore_DP0 pid=301537) 	setp.lt.s32 	%p13, %r80, %r14;
(EngineCore_DP0 pid=301537) 	.loc	1 206 24                        // quant_slide_tuned_Llama3.2-1B.py:206:24
(EngineCore_DP0 pid=301537) 	shr.u32 	%r81, %r80, 31;
(EngineCore_DP0 pid=301537) 	add.s32 	%r82, %r80, %r81;
(EngineCore_DP0 pid=301537) 	shr.u32 	%r83, %r82, 1;
(EngineCore_DP0 pid=301537) 	.loc	1 207 23                        // quant_slide_tuned_Llama3.2-1B.py:207:23
(EngineCore_DP0 pid=301537) 	and.b32 	%r84, %r82, 2147483646;
(EngineCore_DP0 pid=301537) 	sub.s32 	%r85, %r80, %r84;
(EngineCore_DP0 pid=301537) 	.loc	1 208 30                        // quant_slide_tuned_Llama3.2-1B.py:208:30
(EngineCore_DP0 pid=301537) 	shl.b32 	%r86, %r85, 1;
(EngineCore_DP0 pid=301537) 	.loc	1 208 26                        // quant_slide_tuned_Llama3.2-1B.py:208:26
(EngineCore_DP0 pid=301537) 	mad.lo.s32 	%r87, %r83, 6, %r86;
(EngineCore_DP0 pid=301537) 	.loc	1 211 53                        // quant_slide_tuned_Llama3.2-1B.py:211:53
(EngineCore_DP0 pid=301537) 	setp.lt.s32 	%p14, %r87, %r17;
(EngineCore_DP0 pid=301537) 	.loc	1 211 37                        // quant_slide_tuned_Llama3.2-1B.py:211:37
(EngineCore_DP0 pid=301537) 	and.pred 	%p9, %p13, %p14;
(EngineCore_DP0 pid=301537) 	.loc	1 210 29                        // quant_slide_tuned_Llama3.2-1B.py:210:29
(EngineCore_DP0 pid=301537) 	mad.wide.s32 	%rd8, %r87, 2, %rd1;
(EngineCore_DP0 pid=301537) 	mov.b16 	%rs13, 0;
(EngineCore_DP0 pid=301537) 	.loc	1 210 21                        // quant_slide_tuned_Llama3.2-1B.py:210:21
(EngineCore_DP0 pid=301537) 	// begin inline asm
(EngineCore_DP0 pid=301537) 	mov.u16 %rs12, %rs13;
(EngineCore_DP0 pid=301537) 	@%p9 ld.global.b16 { %rs12 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=301537) 	// end inline asm
(EngineCore_DP0 pid=301537) 	.loc	1 211 79                        // quant_slide_tuned_Llama3.2-1B.py:211:79
(EngineCore_DP0 pid=301537) 	cvt.f32.bf16 	%r88, %rs12;
(EngineCore_DP0 pid=301537) 	.loc	1 213 48                        // quant_slide_tuned_Llama3.2-1B.py:213:48
(EngineCore_DP0 pid=301537) 	or.b32 	%r89, %r87, 1;
(EngineCore_DP0 pid=301537) 	.loc	1 213 53                        // quant_slide_tuned_Llama3.2-1B.py:213:53
(EngineCore_DP0 pid=301537) 	setp.lt.s32 	%p15, %r89, %r17;
(EngineCore_DP0 pid=301537) 	.loc	1 213 37                        // quant_slide_tuned_Llama3.2-1B.py:213:37
(EngineCore_DP0 pid=301537) 	and.pred 	%p10, %p13, %p15;
(EngineCore_DP0 pid=301537) 	.loc	1 212 39                        // quant_slide_tuned_Llama3.2-1B.py:212:39
(EngineCore_DP0 pid=301537) 	add.s64 	%rd9, %rd8, 2;
(EngineCore_DP0 pid=301537) 	.loc	1 212 21                        // quant_slide_tuned_Llama3.2-1B.py:212:21
(EngineCore_DP0 pid=301537) 	// begin inline asm
(EngineCore_DP0 pid=301537) 	mov.u16 %rs14, %rs13;
(EngineCore_DP0 pid=301537) 	@%p10 ld.global.b16 { %rs14 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=301537) 	// end inline asm
(EngineCore_DP0 pid=301537) 	.loc	1 213 79                        // quant_slide_tuned_Llama3.2-1B.py:213:79
(EngineCore_DP0 pid=301537) 	cvt.f32.bf16 	%r90, %rs14;
(EngineCore_DP0 pid=301537) 	.loc	1 215 48                        // quant_slide_tuned_Llama3.2-1B.py:215:48
(EngineCore_DP0 pid=301537) 	add.s32 	%r91, %r87, 2;
(EngineCore_DP0 pid=301537) 	.loc	1 215 53                        // quant_slide_tuned_Llama3.2-1B.py:215:53
(EngineCore_DP0 pid=301537) 	setp.lt.s32 	%p16, %r91, %r17;
(EngineCore_DP0 pid=301537) 	.loc	1 215 37                        // quant_slide_tuned_Llama3.2-1B.py:215:37
(EngineCore_DP0 pid=301537) 	and.pred 	%p11, %p13, %p16;
(EngineCore_DP0 pid=301537) 	.loc	1 214 39                        // quant_slide_tuned_Llama3.2-1B.py:214:39
(EngineCore_DP0 pid=301537) 	add.s64 	%rd10, %rd8, 4;
(EngineCore_DP0 pid=301537) 	.loc	1 214 21                        // quant_slide_tuned_Llama3.2-1B.py:214:21
(EngineCore_DP0 pid=301537) 	// begin inline asm
(EngineCore_DP0 pid=301537) 	mov.u16 %rs16, %rs13;
(EngineCore_DP0 pid=301537) 	@%p11 ld.global.b16 { %rs16 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=301537) 	// end inline asm
(EngineCore_DP0 pid=301537) 	.loc	1 215 79                        // quant_slide_tuned_Llama3.2-1B.py:215:79
(EngineCore_DP0 pid=301537) 	cvt.f32.bf16 	%r92, %rs16;
(EngineCore_DP0 pid=301537) 	.loc	1 217 48                        // quant_slide_tuned_Llama3.2-1B.py:217:48
(EngineCore_DP0 pid=301537) 	add.s32 	%r93, %r87, 3;
(EngineCore_DP0 pid=301537) 	.loc	1 217 53                        // quant_slide_tuned_Llama3.2-1B.py:217:53
(EngineCore_DP0 pid=301537) 	setp.lt.s32 	%p17, %r93, %r17;
(EngineCore_DP0 pid=301537) 	.loc	1 217 37                        // quant_slide_tuned_Llama3.2-1B.py:217:37
(EngineCore_DP0 pid=301537) 	and.pred 	%p12, %p13, %p17;
(EngineCore_DP0 pid=301537) 	.loc	1 216 39                        // quant_slide_tuned_Llama3.2-1B.py:216:39
(EngineCore_DP0 pid=301537) 	add.s64 	%rd11, %rd8, 6;
(EngineCore_DP0 pid=301537) 	.loc	1 216 21                        // quant_slide_tuned_Llama3.2-1B.py:216:21
(EngineCore_DP0 pid=301537) 	// begin inline asm
(EngineCore_DP0 pid=301537) 	mov.u16 %rs18, %rs13;
(EngineCore_DP0 pid=301537) 	@%p12 ld.global.b16 { %rs18 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=301537) 	// end inline asm
(EngineCore_DP0 pid=301537) 	.loc	1 217 79                        // quant_slide_tuned_Llama3.2-1B.py:217:79
(EngineCore_DP0 pid=301537) 	cvt.f32.bf16 	%r94, %rs18;
(EngineCore_DP0 pid=301537) 	.loc	1 219 27                        // quant_slide_tuned_Llama3.2-1B.py:219:27
(EngineCore_DP0 pid=301537) 	mul.f32 	%r95, %r13, %r88;
(EngineCore_DP0 pid=301537) 	mov.b32 	%r96, 0f43E00000;
(EngineCore_DP0 pid=301537) 	.loc	1 219 48                        // quant_slide_tuned_Llama3.2-1B.py:219:48
(EngineCore_DP0 pid=301537) 	min.xorsign.abs.f32 	%r70, %r95, %r96;
(EngineCore_DP0 pid=301537) 	.loc	1 219 60                        // quant_slide_tuned_Llama3.2-1B.py:219:60
(EngineCore_DP0 pid=301537) 	// begin inline asm
(EngineCore_DP0 pid=301537) 	cvt.rn.satfinite.e4m3x2.f32  %rs20, %r71, %r70; 
(EngineCore_DP0 pid=301537) 
(EngineCore_DP0 pid=301537) 	// end inline asm
(EngineCore_DP0 pid=301537) 	.loc	1 220 27                        // quant_slide_tuned_Llama3.2-1B.py:220:27
(EngineCore_DP0 pid=301537) 	mul.f32 	%r97, %r13, %r90;
(EngineCore_DP0 pid=301537) 	.loc	1 220 48                        // quant_slide_tuned_Llama3.2-1B.py:220:48
(EngineCore_DP0 pid=301537) 	min.xorsign.abs.f32 	%r72, %r97, %r96;
(EngineCore_DP0 pid=301537) 	.loc	1 220 60                        // quant_slide_tuned_Llama3.2-1B.py:220:60
(EngineCore_DP0 pid=301537) 	// begin inline asm
(EngineCore_DP0 pid=301537) 	cvt.rn.satfinite.e4m3x2.f32  %rs21, %r73, %r72; 
(EngineCore_DP0 pid=301537) 
(EngineCore_DP0 pid=301537) 	// end inline asm
(EngineCore_DP0 pid=301537) 	.loc	1 221 27                        // quant_slide_tuned_Llama3.2-1B.py:221:27
(EngineCore_DP0 pid=301537) 	mul.f32 	%r98, %r13, %r92;
(EngineCore_DP0 pid=301537) 	.loc	1 221 48                        // quant_slide_tuned_Llama3.2-1B.py:221:48
(EngineCore_DP0 pid=301537) 	min.xorsign.abs.f32 	%r74, %r98, %r96;
(EngineCore_DP0 pid=301537) 	.loc	1 221 60                        // quant_slide_tuned_Llama3.2-1B.py:221:60
(EngineCore_DP0 pid=301537) 	// begin inline asm
(EngineCore_DP0 pid=301537) 	cvt.rn.satfinite.e4m3x2.f32  %rs22, %r75, %r74; 
(EngineCore_DP0 pid=301537) 
(EngineCore_DP0 pid=301537) 	// end inline asm
(EngineCore_DP0 pid=301537) 	.loc	1 222 27                        // quant_slide_tuned_Llama3.2-1B.py:222:27
(EngineCore_DP0 pid=301537) 	mul.f32 	%r99, %r13, %r94;
(EngineCore_DP0 pid=301537) 	.loc	1 222 48                        // quant_slide_tuned_Llama3.2-1B.py:222:48
(EngineCore_DP0 pid=301537) 	min.xorsign.abs.f32 	%r76, %r99, %r96;
(EngineCore_DP0 pid=301537) 	.loc	1 222 60                        // quant_slide_tuned_Llama3.2-1B.py:222:60
(EngineCore_DP0 pid=301537) 	// begin inline asm
(EngineCore_DP0 pid=301537) 	cvt.rn.satfinite.e4m3x2.f32  %rs23, %r77, %r76; 
(EngineCore_DP0 pid=301537) 
(EngineCore_DP0 pid=301537) 	// end inline asm
(EngineCore_DP0 pid=301537) 	.loc	1 224 45                        // quant_slide_tuned_Llama3.2-1B.py:224:45
(EngineCore_DP0 pid=301537) 	cvt.u32.u16 	%r100, %rs20;
(EngineCore_DP0 pid=301537) 	and.b32 	%r101, %r100, 255;
(EngineCore_DP0 pid=301537) 	.loc	1 226 45                        // quant_slide_tuned_Llama3.2-1B.py:226:45
(EngineCore_DP0 pid=301537) 	cvt.u32.u16 	%r102, %rs22;
(EngineCore_DP0 pid=301537) 	and.b32 	%r103, %r102, 255;
(EngineCore_DP0 pid=301537) 	.loc	1 227 45                        // quant_slide_tuned_Llama3.2-1B.py:227:45
(EngineCore_DP0 pid=301537) 	cvt.u32.u16 	%r104, %rs23;
(EngineCore_DP0 pid=301537) 	.loc	1 229 30                        // quant_slide_tuned_Llama3.2-1B.py:229:30
(EngineCore_DP0 pid=301537) 	and.b16 	%rs24, %rs21, 255;
(EngineCore_DP0 pid=301537) 	mul.wide.u16 	%r105, %rs24, 256;
(EngineCore_DP0 pid=301537) 	.loc	1 229 24                        // quant_slide_tuned_Llama3.2-1B.py:229:24
(EngineCore_DP0 pid=301537) 	or.b32 	%r106, %r105, %r101;
(EngineCore_DP0 pid=301537) 	.loc	1 229 42                        // quant_slide_tuned_Llama3.2-1B.py:229:42
(EngineCore_DP0 pid=301537) 	shl.b32 	%r107, %r103, 16;
(EngineCore_DP0 pid=301537) 	.loc	1 229 36                        // quant_slide_tuned_Llama3.2-1B.py:229:36
(EngineCore_DP0 pid=301537) 	or.b32 	%r108, %r106, %r107;
(EngineCore_DP0 pid=301537) 	.loc	1 229 55                        // quant_slide_tuned_Llama3.2-1B.py:229:55
(EngineCore_DP0 pid=301537) 	shl.b32 	%r109, %r104, 24;
(EngineCore_DP0 pid=301537) 	.loc	1 229 49                        // quant_slide_tuned_Llama3.2-1B.py:229:49
(EngineCore_DP0 pid=301537) 	or.b32 	%r78, %r108, %r109;
(EngineCore_DP0 pid=301537) 	.loc	1 230 29                        // quant_slide_tuned_Llama3.2-1B.py:230:29
(EngineCore_DP0 pid=301537) 	mad.wide.s32 	%rd12, %r80, 4, %rd2;
(EngineCore_DP0 pid=301537) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-1B.py:230:39
(EngineCore_DP0 pid=301537) 	// begin inline asm
(EngineCore_DP0 pid=301537) 	@%p13 st.global.b32 [ %rd12 + 0 ], { %r78 };
(EngineCore_DP0 pid=301537) 	// end inline asm
(EngineCore_DP0 pid=301537) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=301537) 	add.s32 	%r113, %r113, 1024;
(EngineCore_DP0 pid=301537) 	setp.lt.s32 	%p18, %r113, %r14;
(EngineCore_DP0 pid=301537) 	@%p18 bra 	$L__BB0_6;
(EngineCore_DP0 pid=301537) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=301537) 	.loc	1 201 4                         // quant_slide_tuned_Llama3.2-1B.py:201:4
(EngineCore_DP0 pid=301537) 	ret;
(EngineCore_DP0 pid=301537) $L__tmp3:
(EngineCore_DP0 pid=301537) $L__func_end0:
(EngineCore_DP0 pid=301537)                                         // -- End function
(EngineCore_DP0 pid=301537) }
(EngineCore_DP0 pid=301537) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=301537) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=301537) 	.section	.debug_abbrev
(EngineCore_DP0 pid=301537) 	{
(EngineCore_DP0 pid=301537) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=301537) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=301537) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=301537) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=301537) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=301537) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=301537) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=301537) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=301537) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=301537) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=301537) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=301537) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=301537) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=301537) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=301537) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=301537) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=301537) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=301537) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=301537) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=301537) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=301537) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=301537) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=301537) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=301537) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=301537) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=301537) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=301537) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=301537) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=301537) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=301537) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=301537) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=301537) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=301537) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=301537) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=301537) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=301537) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=301537) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=301537) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=301537) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=301537) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=301537) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=301537) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=301537) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=301537) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=301537) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=301537) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=301537) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=301537) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=301537) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=301537) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=301537) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=301537) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=301537) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=301537) 	}
(EngineCore_DP0 pid=301537) 	.section	.debug_info
(EngineCore_DP0 pid=301537) 	{
(EngineCore_DP0 pid=301537) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=301537) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=301537) .b8 0
(EngineCore_DP0 pid=301537) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=301537) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=301537) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=301537) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=301537) .b8 114
(EngineCore_DP0 pid=301537) .b8 105
(EngineCore_DP0 pid=301537) .b8 116
(EngineCore_DP0 pid=301537) .b8 111
(EngineCore_DP0 pid=301537) .b8 110
(EngineCore_DP0 pid=301537) .b8 0
(EngineCore_DP0 pid=301537) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=301537) .b8 0
(EngineCore_DP0 pid=301537) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=301537) .b8 117
(EngineCore_DP0 pid=301537) .b8 97
(EngineCore_DP0 pid=301537) .b8 110
(EngineCore_DP0 pid=301537) .b8 116
(EngineCore_DP0 pid=301537) .b8 95
(EngineCore_DP0 pid=301537) .b8 115
(EngineCore_DP0 pid=301537) .b8 108
(EngineCore_DP0 pid=301537) .b8 105
(EngineCore_DP0 pid=301537) .b8 100
(EngineCore_DP0 pid=301537) .b8 101
(EngineCore_DP0 pid=301537) .b8 95
(EngineCore_DP0 pid=301537) .b8 116
(EngineCore_DP0 pid=301537) .b8 117
(EngineCore_DP0 pid=301537) .b8 110
(EngineCore_DP0 pid=301537) .b8 101
(EngineCore_DP0 pid=301537) .b8 100
(EngineCore_DP0 pid=301537) .b8 95
(EngineCore_DP0 pid=301537) .b8 76
(EngineCore_DP0 pid=301537) .b8 108
(EngineCore_DP0 pid=301537) .b8 97
(EngineCore_DP0 pid=301537) .b8 109
(EngineCore_DP0 pid=301537) .b8 97
(EngineCore_DP0 pid=301537) .b8 51
(EngineCore_DP0 pid=301537) .b8 46
(EngineCore_DP0 pid=301537) .b8 50
(EngineCore_DP0 pid=301537) .b8 45
(EngineCore_DP0 pid=301537) .b8 49
(EngineCore_DP0 pid=301537) .b8 66
(EngineCore_DP0 pid=301537) .b8 46
(EngineCore_DP0 pid=301537) .b8 112
(EngineCore_DP0 pid=301537) .b8 121
(EngineCore_DP0 pid=301537) .b8 0
(EngineCore_DP0 pid=301537) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=301537) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=301537) .b8 114
(EngineCore_DP0 pid=301537) .b8 111
(EngineCore_DP0 pid=301537) .b8 111
(EngineCore_DP0 pid=301537) .b8 116
(EngineCore_DP0 pid=301537) .b8 47
(EngineCore_DP0 pid=301537) .b8 118
(EngineCore_DP0 pid=301537) .b8 108
(EngineCore_DP0 pid=301537) .b8 108
(EngineCore_DP0 pid=301537) .b8 109
(EngineCore_DP0 pid=301537) .b8 98
(EngineCore_DP0 pid=301537) .b8 101
(EngineCore_DP0 pid=301537) .b8 110
(EngineCore_DP0 pid=301537) .b8 99
(EngineCore_DP0 pid=301537) .b8 104
(EngineCore_DP0 pid=301537) .b8 47
(EngineCore_DP0 pid=301537) .b8 115
(EngineCore_DP0 pid=301537) .b8 108
(EngineCore_DP0 pid=301537) .b8 105
(EngineCore_DP0 pid=301537) .b8 100
(EngineCore_DP0 pid=301537) .b8 101
(EngineCore_DP0 pid=301537) .b8 115
(EngineCore_DP0 pid=301537) .b8 112
(EngineCore_DP0 pid=301537) .b8 97
(EngineCore_DP0 pid=301537) .b8 114
(EngineCore_DP0 pid=301537) .b8 115
(EngineCore_DP0 pid=301537) .b8 101
(EngineCore_DP0 pid=301537) .b8 47
(EngineCore_DP0 pid=301537) .b8 99
(EngineCore_DP0 pid=301537) .b8 115
(EngineCore_DP0 pid=301537) .b8 114
(EngineCore_DP0 pid=301537) .b8 99
(EngineCore_DP0 pid=301537) .b8 47
(EngineCore_DP0 pid=301537) .b8 102
(EngineCore_DP0 pid=301537) .b8 117
(EngineCore_DP0 pid=301537) .b8 115
(EngineCore_DP0 pid=301537) .b8 101
(EngineCore_DP0 pid=301537) .b8 100
(EngineCore_DP0 pid=301537) .b8 95
(EngineCore_DP0 pid=301537) .b8 113
(EngineCore_DP0 pid=301537) .b8 117
(EngineCore_DP0 pid=301537) .b8 97
(EngineCore_DP0 pid=301537) .b8 110
(EngineCore_DP0 pid=301537) .b8 116
(EngineCore_DP0 pid=301537) .b8 95
(EngineCore_DP0 pid=301537) .b8 115
(EngineCore_DP0 pid=301537) .b8 108
(EngineCore_DP0 pid=301537) .b8 105
(EngineCore_DP0 pid=301537) .b8 100
(EngineCore_DP0 pid=301537) .b8 101
(EngineCore_DP0 pid=301537) .b8 95
(EngineCore_DP0 pid=301537) .b8 116
(EngineCore_DP0 pid=301537) .b8 114
(EngineCore_DP0 pid=301537) .b8 105
(EngineCore_DP0 pid=301537) .b8 116
(EngineCore_DP0 pid=301537) .b8 111
(EngineCore_DP0 pid=301537) .b8 110
(EngineCore_DP0 pid=301537) .b8 47
(EngineCore_DP0 pid=301537) .b8 98
(EngineCore_DP0 pid=301537) .b8 117
(EngineCore_DP0 pid=301537) .b8 105
(EngineCore_DP0 pid=301537) .b8 108
(EngineCore_DP0 pid=301537) .b8 100
(EngineCore_DP0 pid=301537) .b8 47
(EngineCore_DP0 pid=301537) .b8 71
(EngineCore_DP0 pid=301537) .b8 66
(EngineCore_DP0 pid=301537) .b8 49
(EngineCore_DP0 pid=301537) .b8 48
(EngineCore_DP0 pid=301537) .b8 95
(EngineCore_DP0 pid=301537) .b8 99
(EngineCore_DP0 pid=301537) .b8 99
(EngineCore_DP0 pid=301537) .b8 49
(EngineCore_DP0 pid=301537) .b8 50
(EngineCore_DP0 pid=301537) .b8 49
(EngineCore_DP0 pid=301537) .b8 95
(EngineCore_DP0 pid=301537) .b8 112
(EngineCore_DP0 pid=301537) .b8 121
(EngineCore_DP0 pid=301537) .b8 51
(EngineCore_DP0 pid=301537) .b8 49
(EngineCore_DP0 pid=301537) .b8 50
(EngineCore_DP0 pid=301537) .b8 95
(EngineCore_DP0 pid=301537) .b8 99
(EngineCore_DP0 pid=301537) .b8 117
(EngineCore_DP0 pid=301537) .b8 49
(EngineCore_DP0 pid=301537) .b8 50
(EngineCore_DP0 pid=301537) .b8 57
(EngineCore_DP0 pid=301537) .b8 95
(EngineCore_DP0 pid=301537) .b8 97
(EngineCore_DP0 pid=301537) .b8 97
(EngineCore_DP0 pid=301537) .b8 114
(EngineCore_DP0 pid=301537) .b8 99
(EngineCore_DP0 pid=301537) .b8 104
(EngineCore_DP0 pid=301537) .b8 54
(EngineCore_DP0 pid=301537) .b8 52
(EngineCore_DP0 pid=301537) .b8 0
(EngineCore_DP0 pid=301537) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=301537) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=301537) .b8 113
(EngineCore_DP0 pid=301537) .b8 117
(EngineCore_DP0 pid=301537) .b8 97
(EngineCore_DP0 pid=301537) .b8 110
(EngineCore_DP0 pid=301537) .b8 116
(EngineCore_DP0 pid=301537) .b8 95
(EngineCore_DP0 pid=301537) .b8 115
(EngineCore_DP0 pid=301537) .b8 108
(EngineCore_DP0 pid=301537) .b8 105
(EngineCore_DP0 pid=301537) .b8 100
(EngineCore_DP0 pid=301537) .b8 101
(EngineCore_DP0 pid=301537) .b8 95
(EngineCore_DP0 pid=301537) .b8 102
(EngineCore_DP0 pid=301537) .b8 112
(EngineCore_DP0 pid=301537) .b8 56
(EngineCore_DP0 pid=301537) .b8 95
(EngineCore_DP0 pid=301537) .b8 107
(EngineCore_DP0 pid=301537) .b8 101
(EngineCore_DP0 pid=301537) .b8 114
(EngineCore_DP0 pid=301537) .b8 110
(EngineCore_DP0 pid=301537) .b8 101
(EngineCore_DP0 pid=301537) .b8 108
(EngineCore_DP0 pid=301537) .b8 0
(EngineCore_DP0 pid=301537) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=301537) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=301537) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=301537) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=301537) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=301537) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=301537) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=301537) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=301537) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=301537) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=301537) .b8 191                                 // DW_AT_call_line
(EngineCore_DP0 pid=301537) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=301537) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=301537) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=301537) 	}
(EngineCore_DP0 pid=301537) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=301537) 
(EngineCore_DP0 pid=301537) ================================================================
(EngineCore_DP0 pid=301537) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=301537) 
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp9olzu8yn.ptx', '-o', '/tmp/tmp9olzu8yn.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866] 
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866] 
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866] 
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp9olzu8yn.ptx -o /tmp/tmp9olzu8yn.ptx.o
(EngineCore_DP0 pid=301537) ERROR 01-25 18:48:54 [core.py:866] 

STDERR:
[2026-01-25 18:48:39] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 18:48:39] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 18:48:39] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 18:48:39] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:48:39] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:48:39] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:48:39] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:48:39] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:48:39] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 18:48:39] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 18:48:39] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 18:48:39] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 18:48:39] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 18:48:39] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 18:48:43] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 18:48:43] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 18:48:43] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 18:48:43] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:48:43] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:48:43] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:48:43] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:48:43] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:48:43] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 18:48:43] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 18:48:43] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 18:48:43] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 18:48:43] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 18:48:43] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=301537) [2026-01-25 18:48:44] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=301537) [2026-01-25 18:48:44] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=301537) [2026-01-25 18:48:44] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=301537) [2026-01-25 18:48:44] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=301537) [2026-01-25 18:48:44] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=301537) [2026-01-25 18:48:44] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=301537) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=301537) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.40s/it]
(EngineCore_DP0 pid=301537) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.40s/it]
(EngineCore_DP0 pid=301537) 
(EngineCore_DP0 pid=301537) [2026-01-25 18:48:53] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=301537) [2026-01-25 18:48:54] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5308416 bytes
(EngineCore_DP0 pid=301537) [2026-01-25 18:48:54] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=301537) [2026-01-25 18:48:54] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3538944 bytes
(EngineCore_DP0 pid=301537) [2026-01-25 18:48:54] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=301537) [2026-01-25 18:48:54] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 28311552 bytes
(EngineCore_DP0 pid=301537) [2026-01-25 18:48:54] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=301537) [2026-01-25 18:48:54] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14024704 bytes
(EngineCore_DP0 pid=301537) Process EngineCore_DP0:
(EngineCore_DP0 pid=301537) Traceback (most recent call last):
(EngineCore_DP0 pid=301537)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=301537)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=301537)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=301537)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=301537) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp9olzu8yn.ptx', '-o', '/tmp/tmp9olzu8yn.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=301537) 
(EngineCore_DP0 pid=301537) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=301537) 
(EngineCore_DP0 pid=301537) Traceback (most recent call last):
(EngineCore_DP0 pid=301537)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=301537)     self.run()
(EngineCore_DP0 pid=301537)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=301537)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=301537)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=301537)     raise e
(EngineCore_DP0 pid=301537)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=301537)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=301537)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=301537)     super().__init__(
(EngineCore_DP0 pid=301537)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=301537)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=301537)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=301537)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=301537)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=301537)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=301537)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=301537)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=301537)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=301537)     return func(*args, **kwargs)
(EngineCore_DP0 pid=301537)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=301537)     return func(*args, **kwargs)
(EngineCore_DP0 pid=301537)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=301537)     self.model_runner.profile_run()
(EngineCore_DP0 pid=301537)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=301537)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=301537)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=301537)     return func(*args, **kwargs)
(EngineCore_DP0 pid=301537)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=301537)     outputs = self.model(
(EngineCore_DP0 pid=301537)               ^^^^^^^^^^^
(EngineCore_DP0 pid=301537)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=301537)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=301537)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=301537)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=301537)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=301537)     model_output = self.model(
(EngineCore_DP0 pid=301537)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=301537)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=301537)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=301537)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=301537)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=301537)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=301537)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=301537)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=301537)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=301537)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=301537)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=301537)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=301537)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=301537)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=301537)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=301537)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=301537)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=301537)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=301537)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=301537)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=301537)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=301537)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=301537)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=301537)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=301537)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=301537)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=301537)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=301537)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=301537)     return self._linear_fn(
(EngineCore_DP0 pid=301537)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=301537)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=301537)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=301537)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=301537)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=301537)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=301537)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=301537)     return fn(input, L)
(EngineCore_DP0 pid=301537)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=301537)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=301537)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=301537)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=301537)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=301537)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=301537)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=301537)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=301537)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=301537)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=301537)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=301537)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=301537)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=301537)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=301537)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=301537)     raise PTXASError(error)
(EngineCore_DP0 pid=301537) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=301537) `ptxas` stderr:
(EngineCore_DP0 pid=301537) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=301537) 
(EngineCore_DP0 pid=301537) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp9olzu8yn.ptx -o /tmp/tmp9olzu8yn.ptx.o
(EngineCore_DP0 pid=301537) 
[rank0]:[W125 18:48:55.317626277 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=256

========== M=512 ==========
Time: 2026-01-25 19:16:33
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-FP8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:16:36 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:16:36 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=337430) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=337430) 
(EngineCore_DP0 pid=337430) 
(EngineCore_DP0 pid=337430) ================================================================
(EngineCore_DP0 pid=337430) Internal Triton PTX codegen error
(EngineCore_DP0 pid=337430) `ptxas` stderr:
(EngineCore_DP0 pid=337430) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=337430) 
(EngineCore_DP0 pid=337430) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpul_r_3wb.ptx -o /tmp/tmpul_r_3wb.ptx.o
(EngineCore_DP0 pid=337430) 
(EngineCore_DP0 pid=337430) 
(EngineCore_DP0 pid=337430) //
(EngineCore_DP0 pid=337430) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=337430) //
(EngineCore_DP0 pid=337430) 
(EngineCore_DP0 pid=337430) .version 8.7
(EngineCore_DP0 pid=337430) .target sm_121a
(EngineCore_DP0 pid=337430) .address_size 64
(EngineCore_DP0 pid=337430) 
(EngineCore_DP0 pid=337430) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=337430) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=337430)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=337430) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=337430) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=337430) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=337430) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=337430) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=337430) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=337430) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=337430) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=337430) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=337430) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=337430) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=337430) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=337430) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=337430) )
(EngineCore_DP0 pid=337430) .reqntid 1024
(EngineCore_DP0 pid=337430) {
(EngineCore_DP0 pid=337430) 	.reg .pred 	%p<20>;
(EngineCore_DP0 pid=337430) 	.reg .b16 	%rs<25>;
(EngineCore_DP0 pid=337430) 	.reg .b32 	%r<114>;
(EngineCore_DP0 pid=337430) 	.reg .b64 	%rd<13>;
(EngineCore_DP0 pid=337430) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=337430) $L__func_begin0:
(EngineCore_DP0 pid=337430) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=337430) 
(EngineCore_DP0 pid=337430) // %bb.0:
(EngineCore_DP0 pid=337430) 	ld.param.b32 	%r19, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=337430) 	ld.param.b32 	%r18, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=337430) 	ld.param.b32 	%r17, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=337430) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=337430) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=337430) $L__tmp0:
(EngineCore_DP0 pid=337430) 	.loc	1 177 24                        // quant_slide_tuned_Llama3.2-1B.py:177:24
(EngineCore_DP0 pid=337430) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=337430) 	ld.param.b32 	%r21, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=337430) 	.loc	1 182 26                        // quant_slide_tuned_Llama3.2-1B.py:182:26
(EngineCore_DP0 pid=337430) 	mul.lo.s32 	%r22, %r21, %r1;
(EngineCore_DP0 pid=337430) 	.loc	1 182 20                        // quant_slide_tuned_Llama3.2-1B.py:182:20
(EngineCore_DP0 pid=337430) 	mad.wide.s32 	%rd1, %r22, 2, %rd4;
(EngineCore_DP0 pid=337430) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=337430) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=337430) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=337430) 	setp.lt.s32 	%p1, %r18, 1;
(EngineCore_DP0 pid=337430) 	mov.b32 	%r112, 0f2B8CBCCC;
(EngineCore_DP0 pid=337430) 	setp.eq.b32 	%p19, %r2, 0;
(EngineCore_DP0 pid=337430) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=337430) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=337430) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=337430) 	shl.b32 	%r3, %r2, 2;
(EngineCore_DP0 pid=337430) 	and.b32 	%r4, %r2, 31;
(EngineCore_DP0 pid=337430) 	shr.u32 	%r31, %r2, 3;
(EngineCore_DP0 pid=337430) 	and.b32 	%r32, %r31, 124;
(EngineCore_DP0 pid=337430) 	mov.b32 	%r33, global_smem;
(EngineCore_DP0 pid=337430) 	add.s32 	%r39, %r33, %r32;
(EngineCore_DP0 pid=337430) 	add.s32 	%r42, %r33, %r3;
(EngineCore_DP0 pid=337430) 	mov.b32 	%r37, 0;
(EngineCore_DP0 pid=337430) 	mov.b32 	%r110, 0f00000000;
(EngineCore_DP0 pid=337430) 	setp.lt.u32 	%p4, %r2, 32;
(EngineCore_DP0 pid=337430) 	setp.eq.b32 	%p3, %r4, 0;
(EngineCore_DP0 pid=337430) 	mov.b32 	%r111, %r37;
(EngineCore_DP0 pid=337430) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=337430) 	.loc	1 189 22                        // quant_slide_tuned_Llama3.2-1B.py:189:22
(EngineCore_DP0 pid=337430) 	add.s32 	%r45, %r3, %r111;
(EngineCore_DP0 pid=337430) 	setp.lt.s32 	%p2, %r45, %r17;
(EngineCore_DP0 pid=337430) 	.loc	1 190 29                        // quant_slide_tuned_Llama3.2-1B.py:190:29
(EngineCore_DP0 pid=337430) 	mad.wide.s32 	%rd6, %r45, 2, %rd1;
(EngineCore_DP0 pid=337430) 	.loc	1 190 21                        // quant_slide_tuned_Llama3.2-1B.py:190:21
(EngineCore_DP0 pid=337430) 	// begin inline asm
(EngineCore_DP0 pid=337430) 	mov.u32 %r35, %r37;
(EngineCore_DP0 pid=337430) 	mov.u32 %r36, %r37;
(EngineCore_DP0 pid=337430) 	@%p2 ld.global.v2.b32 { %r35, %r36 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=337430) 	// end inline asm
(EngineCore_DP0 pid=337430) 	mov.b32 	{%rs1, %rs2}, %r35;
(EngineCore_DP0 pid=337430) 	mov.b32 	{%rs3, %rs4}, %r36;
(EngineCore_DP0 pid=337430) 	.loc	1 191 50                        // quant_slide_tuned_Llama3.2-1B.py:191:50
(EngineCore_DP0 pid=337430) 	abs.bf16 	%rs5, %rs1;
(EngineCore_DP0 pid=337430) 	abs.bf16 	%rs6, %rs2;
(EngineCore_DP0 pid=337430) 	abs.bf16 	%rs7, %rs3;
(EngineCore_DP0 pid=337430) 	abs.bf16 	%rs8, %rs4;
(EngineCore_DP0 pid=337430) $L__tmp1:
(EngineCore_DP0 pid=337430) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=337430) 	bar.sync 	0;
(EngineCore_DP0 pid=337430) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=337430) 	max.bf16 	%rs9, %rs5, %rs6;
(EngineCore_DP0 pid=337430) 	max.bf16 	%rs10, %rs9, %rs7;
(EngineCore_DP0 pid=337430) 	max.bf16 	%rs11, %rs10, %rs8;
(EngineCore_DP0 pid=337430) 	cvt.f32.bf16 	%r46, %rs11;
(EngineCore_DP0 pid=337430) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=337430) 	shfl.sync.bfly.b32 	%r47, %r46, 16, 31, -1;
(EngineCore_DP0 pid=337430) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=337430) 	max.f32 	%r48, %r46, %r47;
(EngineCore_DP0 pid=337430) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=337430) 	shfl.sync.bfly.b32 	%r49, %r48, 8, 31, -1;
(EngineCore_DP0 pid=337430) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=337430) 	max.f32 	%r50, %r48, %r49;
(EngineCore_DP0 pid=337430) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=337430) 	shfl.sync.bfly.b32 	%r51, %r50, 4, 31, -1;
(EngineCore_DP0 pid=337430) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=337430) 	max.f32 	%r52, %r50, %r51;
(EngineCore_DP0 pid=337430) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=337430) 	shfl.sync.bfly.b32 	%r53, %r52, 2, 31, -1;
(EngineCore_DP0 pid=337430) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=337430) 	max.f32 	%r54, %r52, %r53;
(EngineCore_DP0 pid=337430) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=337430) 	shfl.sync.bfly.b32 	%r55, %r54, 1, 31, -1;
(EngineCore_DP0 pid=337430) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=337430) 	max.f32 	%r40, %r54, %r55;
(EngineCore_DP0 pid=337430) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=337430) 	// begin inline asm
(EngineCore_DP0 pid=337430) 	@%p3 st.shared.b32 [ %r39 + 0 ], %r40;
(EngineCore_DP0 pid=337430) 	// end inline asm
(EngineCore_DP0 pid=337430) 	bar.sync 	0;
(EngineCore_DP0 pid=337430) 	// begin inline asm
(EngineCore_DP0 pid=337430) 	@%p4 ld.shared.b32 %r41, [ %r42 + 0 ];
(EngineCore_DP0 pid=337430) 	// end inline asm
(EngineCore_DP0 pid=337430) 	shfl.sync.bfly.b32 	%r56, %r41, 16, 31, -1;
(EngineCore_DP0 pid=337430) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=337430) 	max.f32 	%r57, %r41, %r56;
(EngineCore_DP0 pid=337430) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=337430) 	shfl.sync.bfly.b32 	%r58, %r57, 8, 31, -1;
(EngineCore_DP0 pid=337430) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=337430) 	max.f32 	%r59, %r57, %r58;
(EngineCore_DP0 pid=337430) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=337430) 	shfl.sync.bfly.b32 	%r60, %r59, 4, 31, -1;
(EngineCore_DP0 pid=337430) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=337430) 	max.f32 	%r61, %r59, %r60;
(EngineCore_DP0 pid=337430) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=337430) 	shfl.sync.bfly.b32 	%r62, %r61, 2, 31, -1;
(EngineCore_DP0 pid=337430) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=337430) 	max.f32 	%r63, %r61, %r62;
(EngineCore_DP0 pid=337430) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=337430) 	shfl.sync.bfly.b32 	%r64, %r63, 1, 31, -1;
(EngineCore_DP0 pid=337430) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=337430) 	max.f32 	%r44, %r63, %r64;
(EngineCore_DP0 pid=337430) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=337430) 	// begin inline asm
(EngineCore_DP0 pid=337430) 	@%p19 st.shared.b32 [ %r42 + 0 ], %r44;
(EngineCore_DP0 pid=337430) 	// end inline asm
(EngineCore_DP0 pid=337430) 	bar.sync 	0;
(EngineCore_DP0 pid=337430) 	ld.shared.b32 	%r65, [global_smem];
(EngineCore_DP0 pid=337430) $L__tmp2:
(EngineCore_DP0 pid=337430) 	.loc	1 191 36                        // quant_slide_tuned_Llama3.2-1B.py:191:36
(EngineCore_DP0 pid=337430) 	max.f32 	%r110, %r110, %r65;
(EngineCore_DP0 pid=337430) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=337430) 	add.s32 	%r111, %r111, 4096;
(EngineCore_DP0 pid=337430) 	setp.lt.s32 	%p6, %r111, %r18;
(EngineCore_DP0 pid=337430) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=337430) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=337430) 	.loc	1 193 32                        // quant_slide_tuned_Llama3.2-1B.py:193:32
(EngineCore_DP0 pid=337430) 	max.f32 	%r112, %r110, 0f2B8CBCCC;
(EngineCore_DP0 pid=337430) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=337430) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=337430) 	mov.b32 	%r67, 0f43E00000;
(EngineCore_DP0 pid=337430) 	.loc	1 194 32                        // quant_slide_tuned_Llama3.2-1B.py:194:32
(EngineCore_DP0 pid=337430) 	div.full.f32 	%r68, %r112, %r67;
(EngineCore_DP0 pid=337430) 	.loc	1 194 41                        // quant_slide_tuned_Llama3.2-1B.py:194:41
(EngineCore_DP0 pid=337430) 	max.f32 	%r66, %r68, 0f36924925;
(EngineCore_DP0 pid=337430) 	.loc	1 196 25                        // quant_slide_tuned_Llama3.2-1B.py:196:25
(EngineCore_DP0 pid=337430) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=337430) 	.loc	1 196 30                        // quant_slide_tuned_Llama3.2-1B.py:196:30
(EngineCore_DP0 pid=337430) 	// begin inline asm
(EngineCore_DP0 pid=337430) 	@%p19 st.global.b32 [ %rd7 + 0 ], { %r66 };
(EngineCore_DP0 pid=337430) 	// end inline asm
(EngineCore_DP0 pid=337430) 	.loc	1 199 29                        // quant_slide_tuned_Llama3.2-1B.py:199:29
(EngineCore_DP0 pid=337430) 	shl.b32 	%r14, %r19, 1;
(EngineCore_DP0 pid=337430) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=337430) 	setp.lt.s32 	%p8, %r14, 1;
(EngineCore_DP0 pid=337430) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=337430) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=337430) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=337430) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=337430) 	shr.s32 	%r24, %r23, 31;
(EngineCore_DP0 pid=337430) 	shr.u32 	%r25, %r24, 30;
(EngineCore_DP0 pid=337430) 	add.s32 	%r26, %r23, %r25;
(EngineCore_DP0 pid=337430) 	shr.s32 	%r27, %r26, 2;
(EngineCore_DP0 pid=337430) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=337430) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=337430) 	mad.wide.s32 	%rd2, %r28, 4, %rd5;
(EngineCore_DP0 pid=337430) 	div.full.f32 	%r13, %r67, %r112;
(EngineCore_DP0 pid=337430) 	mov.b32 	%r113, 0;
(EngineCore_DP0 pid=337430) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=337430)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=337430) 	.loc	1 203 30                        // quant_slide_tuned_Llama3.2-1B.py:203:30
(EngineCore_DP0 pid=337430) 	add.s32 	%r80, %r2, %r113;
(EngineCore_DP0 pid=337430) 	setp.lt.s32 	%p13, %r80, %r14;
(EngineCore_DP0 pid=337430) 	.loc	1 206 24                        // quant_slide_tuned_Llama3.2-1B.py:206:24
(EngineCore_DP0 pid=337430) 	shr.u32 	%r81, %r80, 31;
(EngineCore_DP0 pid=337430) 	add.s32 	%r82, %r80, %r81;
(EngineCore_DP0 pid=337430) 	shr.u32 	%r83, %r82, 1;
(EngineCore_DP0 pid=337430) 	.loc	1 207 23                        // quant_slide_tuned_Llama3.2-1B.py:207:23
(EngineCore_DP0 pid=337430) 	and.b32 	%r84, %r82, 2147483646;
(EngineCore_DP0 pid=337430) 	sub.s32 	%r85, %r80, %r84;
(EngineCore_DP0 pid=337430) 	.loc	1 208 30                        // quant_slide_tuned_Llama3.2-1B.py:208:30
(EngineCore_DP0 pid=337430) 	shl.b32 	%r86, %r85, 1;
(EngineCore_DP0 pid=337430) 	.loc	1 208 26                        // quant_slide_tuned_Llama3.2-1B.py:208:26
(EngineCore_DP0 pid=337430) 	mad.lo.s32 	%r87, %r83, 6, %r86;
(EngineCore_DP0 pid=337430) 	.loc	1 211 53                        // quant_slide_tuned_Llama3.2-1B.py:211:53
(EngineCore_DP0 pid=337430) 	setp.lt.s32 	%p14, %r87, %r17;
(EngineCore_DP0 pid=337430) 	.loc	1 211 37                        // quant_slide_tuned_Llama3.2-1B.py:211:37
(EngineCore_DP0 pid=337430) 	and.pred 	%p9, %p13, %p14;
(EngineCore_DP0 pid=337430) 	.loc	1 210 29                        // quant_slide_tuned_Llama3.2-1B.py:210:29
(EngineCore_DP0 pid=337430) 	mad.wide.s32 	%rd8, %r87, 2, %rd1;
(EngineCore_DP0 pid=337430) 	mov.b16 	%rs13, 0;
(EngineCore_DP0 pid=337430) 	.loc	1 210 21                        // quant_slide_tuned_Llama3.2-1B.py:210:21
(EngineCore_DP0 pid=337430) 	// begin inline asm
(EngineCore_DP0 pid=337430) 	mov.u16 %rs12, %rs13;
(EngineCore_DP0 pid=337430) 	@%p9 ld.global.b16 { %rs12 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=337430) 	// end inline asm
(EngineCore_DP0 pid=337430) 	.loc	1 211 79                        // quant_slide_tuned_Llama3.2-1B.py:211:79
(EngineCore_DP0 pid=337430) 	cvt.f32.bf16 	%r88, %rs12;
(EngineCore_DP0 pid=337430) 	.loc	1 213 48                        // quant_slide_tuned_Llama3.2-1B.py:213:48
(EngineCore_DP0 pid=337430) 	or.b32 	%r89, %r87, 1;
(EngineCore_DP0 pid=337430) 	.loc	1 213 53                        // quant_slide_tuned_Llama3.2-1B.py:213:53
(EngineCore_DP0 pid=337430) 	setp.lt.s32 	%p15, %r89, %r17;
(EngineCore_DP0 pid=337430) 	.loc	1 213 37                        // quant_slide_tuned_Llama3.2-1B.py:213:37
(EngineCore_DP0 pid=337430) 	and.pred 	%p10, %p13, %p15;
(EngineCore_DP0 pid=337430) 	.loc	1 212 39                        // quant_slide_tuned_Llama3.2-1B.py:212:39
(EngineCore_DP0 pid=337430) 	add.s64 	%rd9, %rd8, 2;
(EngineCore_DP0 pid=337430) 	.loc	1 212 21                        // quant_slide_tuned_Llama3.2-1B.py:212:21
(EngineCore_DP0 pid=337430) 	// begin inline asm
(EngineCore_DP0 pid=337430) 	mov.u16 %rs14, %rs13;
(EngineCore_DP0 pid=337430) 	@%p10 ld.global.b16 { %rs14 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=337430) 	// end inline asm
(EngineCore_DP0 pid=337430) 	.loc	1 213 79                        // quant_slide_tuned_Llama3.2-1B.py:213:79
(EngineCore_DP0 pid=337430) 	cvt.f32.bf16 	%r90, %rs14;
(EngineCore_DP0 pid=337430) 	.loc	1 215 48                        // quant_slide_tuned_Llama3.2-1B.py:215:48
(EngineCore_DP0 pid=337430) 	add.s32 	%r91, %r87, 2;
(EngineCore_DP0 pid=337430) 	.loc	1 215 53                        // quant_slide_tuned_Llama3.2-1B.py:215:53
(EngineCore_DP0 pid=337430) 	setp.lt.s32 	%p16, %r91, %r17;
(EngineCore_DP0 pid=337430) 	.loc	1 215 37                        // quant_slide_tuned_Llama3.2-1B.py:215:37
(EngineCore_DP0 pid=337430) 	and.pred 	%p11, %p13, %p16;
(EngineCore_DP0 pid=337430) 	.loc	1 214 39                        // quant_slide_tuned_Llama3.2-1B.py:214:39
(EngineCore_DP0 pid=337430) 	add.s64 	%rd10, %rd8, 4;
(EngineCore_DP0 pid=337430) 	.loc	1 214 21                        // quant_slide_tuned_Llama3.2-1B.py:214:21
(EngineCore_DP0 pid=337430) 	// begin inline asm
(EngineCore_DP0 pid=337430) 	mov.u16 %rs16, %rs13;
(EngineCore_DP0 pid=337430) 	@%p11 ld.global.b16 { %rs16 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=337430) 	// end inline asm
(EngineCore_DP0 pid=337430) 	.loc	1 215 79                        // quant_slide_tuned_Llama3.2-1B.py:215:79
(EngineCore_DP0 pid=337430) 	cvt.f32.bf16 	%r92, %rs16;
(EngineCore_DP0 pid=337430) 	.loc	1 217 48                        // quant_slide_tuned_Llama3.2-1B.py:217:48
(EngineCore_DP0 pid=337430) 	add.s32 	%r93, %r87, 3;
(EngineCore_DP0 pid=337430) 	.loc	1 217 53                        // quant_slide_tuned_Llama3.2-1B.py:217:53
(EngineCore_DP0 pid=337430) 	setp.lt.s32 	%p17, %r93, %r17;
(EngineCore_DP0 pid=337430) 	.loc	1 217 37                        // quant_slide_tuned_Llama3.2-1B.py:217:37
(EngineCore_DP0 pid=337430) 	and.pred 	%p12, %p13, %p17;
(EngineCore_DP0 pid=337430) 	.loc	1 216 39                        // quant_slide_tuned_Llama3.2-1B.py:216:39
(EngineCore_DP0 pid=337430) 	add.s64 	%rd11, %rd8, 6;
(EngineCore_DP0 pid=337430) 	.loc	1 216 21                        // quant_slide_tuned_Llama3.2-1B.py:216:21
(EngineCore_DP0 pid=337430) 	// begin inline asm
(EngineCore_DP0 pid=337430) 	mov.u16 %rs18, %rs13;
(EngineCore_DP0 pid=337430) 	@%p12 ld.global.b16 { %rs18 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=337430) 	// end inline asm
(EngineCore_DP0 pid=337430) 	.loc	1 217 79                        // quant_slide_tuned_Llama3.2-1B.py:217:79
(EngineCore_DP0 pid=337430) 	cvt.f32.bf16 	%r94, %rs18;
(EngineCore_DP0 pid=337430) 	.loc	1 219 27                        // quant_slide_tuned_Llama3.2-1B.py:219:27
(EngineCore_DP0 pid=337430) 	mul.f32 	%r95, %r13, %r88;
(EngineCore_DP0 pid=337430) 	mov.b32 	%r96, 0f43E00000;
(EngineCore_DP0 pid=337430) 	.loc	1 219 48                        // quant_slide_tuned_Llama3.2-1B.py:219:48
(EngineCore_DP0 pid=337430) 	min.xorsign.abs.f32 	%r70, %r95, %r96;
(EngineCore_DP0 pid=337430) 	.loc	1 219 60                        // quant_slide_tuned_Llama3.2-1B.py:219:60
(EngineCore_DP0 pid=337430) 	// begin inline asm
(EngineCore_DP0 pid=337430) 	cvt.rn.satfinite.e4m3x2.f32  %rs20, %r71, %r70; 
(EngineCore_DP0 pid=337430) 
(EngineCore_DP0 pid=337430) 	// end inline asm
(EngineCore_DP0 pid=337430) 	.loc	1 220 27                        // quant_slide_tuned_Llama3.2-1B.py:220:27
(EngineCore_DP0 pid=337430) 	mul.f32 	%r97, %r13, %r90;
(EngineCore_DP0 pid=337430) 	.loc	1 220 48                        // quant_slide_tuned_Llama3.2-1B.py:220:48
(EngineCore_DP0 pid=337430) 	min.xorsign.abs.f32 	%r72, %r97, %r96;
(EngineCore_DP0 pid=337430) 	.loc	1 220 60                        // quant_slide_tuned_Llama3.2-1B.py:220:60
(EngineCore_DP0 pid=337430) 	// begin inline asm
(EngineCore_DP0 pid=337430) 	cvt.rn.satfinite.e4m3x2.f32  %rs21, %r73, %r72; 
(EngineCore_DP0 pid=337430) 
(EngineCore_DP0 pid=337430) 	// end inline asm
(EngineCore_DP0 pid=337430) 	.loc	1 221 27                        // quant_slide_tuned_Llama3.2-1B.py:221:27
(EngineCore_DP0 pid=337430) 	mul.f32 	%r98, %r13, %r92;
(EngineCore_DP0 pid=337430) 	.loc	1 221 48                        // quant_slide_tuned_Llama3.2-1B.py:221:48
(EngineCore_DP0 pid=337430) 	min.xorsign.abs.f32 	%r74, %r98, %r96;
(EngineCore_DP0 pid=337430) 	.loc	1 221 60                        // quant_slide_tuned_Llama3.2-1B.py:221:60
(EngineCore_DP0 pid=337430) 	// begin inline asm
(EngineCore_DP0 pid=337430) 	cvt.rn.satfinite.e4m3x2.f32  %rs22, %r75, %r74; 
(EngineCore_DP0 pid=337430) 
(EngineCore_DP0 pid=337430) 	// end inline asm
(EngineCore_DP0 pid=337430) 	.loc	1 222 27                        // quant_slide_tuned_Llama3.2-1B.py:222:27
(EngineCore_DP0 pid=337430) 	mul.f32 	%r99, %r13, %r94;
(EngineCore_DP0 pid=337430) 	.loc	1 222 48                        // quant_slide_tuned_Llama3.2-1B.py:222:48
(EngineCore_DP0 pid=337430) 	min.xorsign.abs.f32 	%r76, %r99, %r96;
(EngineCore_DP0 pid=337430) 	.loc	1 222 60                        // quant_slide_tuned_Llama3.2-1B.py:222:60
(EngineCore_DP0 pid=337430) 	// begin inline asm
(EngineCore_DP0 pid=337430) 	cvt.rn.satfinite.e4m3x2.f32  %rs23, %r77, %r76; 
(EngineCore_DP0 pid=337430) 
(EngineCore_DP0 pid=337430) 	// end inline asm
(EngineCore_DP0 pid=337430) 	.loc	1 224 45                        // quant_slide_tuned_Llama3.2-1B.py:224:45
(EngineCore_DP0 pid=337430) 	cvt.u32.u16 	%r100, %rs20;
(EngineCore_DP0 pid=337430) 	and.b32 	%r101, %r100, 255;
(EngineCore_DP0 pid=337430) 	.loc	1 226 45                        // quant_slide_tuned_Llama3.2-1B.py:226:45
(EngineCore_DP0 pid=337430) 	cvt.u32.u16 	%r102, %rs22;
(EngineCore_DP0 pid=337430) 	and.b32 	%r103, %r102, 255;
(EngineCore_DP0 pid=337430) 	.loc	1 227 45                        // quant_slide_tuned_Llama3.2-1B.py:227:45
(EngineCore_DP0 pid=337430) 	cvt.u32.u16 	%r104, %rs23;
(EngineCore_DP0 pid=337430) 	.loc	1 229 30                        // quant_slide_tuned_Llama3.2-1B.py:229:30
(EngineCore_DP0 pid=337430) 	and.b16 	%rs24, %rs21, 255;
(EngineCore_DP0 pid=337430) 	mul.wide.u16 	%r105, %rs24, 256;
(EngineCore_DP0 pid=337430) 	.loc	1 229 24                        // quant_slide_tuned_Llama3.2-1B.py:229:24
(EngineCore_DP0 pid=337430) 	or.b32 	%r106, %r105, %r101;
(EngineCore_DP0 pid=337430) 	.loc	1 229 42                        // quant_slide_tuned_Llama3.2-1B.py:229:42
(EngineCore_DP0 pid=337430) 	shl.b32 	%r107, %r103, 16;
(EngineCore_DP0 pid=337430) 	.loc	1 229 36                        // quant_slide_tuned_Llama3.2-1B.py:229:36
(EngineCore_DP0 pid=337430) 	or.b32 	%r108, %r106, %r107;
(EngineCore_DP0 pid=337430) 	.loc	1 229 55                        // quant_slide_tuned_Llama3.2-1B.py:229:55
(EngineCore_DP0 pid=337430) 	shl.b32 	%r109, %r104, 24;
(EngineCore_DP0 pid=337430) 	.loc	1 229 49                        // quant_slide_tuned_Llama3.2-1B.py:229:49
(EngineCore_DP0 pid=337430) 	or.b32 	%r78, %r108, %r109;
(EngineCore_DP0 pid=337430) 	.loc	1 230 29                        // quant_slide_tuned_Llama3.2-1B.py:230:29
(EngineCore_DP0 pid=337430) 	mad.wide.s32 	%rd12, %r80, 4, %rd2;
(EngineCore_DP0 pid=337430) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-1B.py:230:39
(EngineCore_DP0 pid=337430) 	// begin inline asm
(EngineCore_DP0 pid=337430) 	@%p13 st.global.b32 [ %rd12 + 0 ], { %r78 };
(EngineCore_DP0 pid=337430) 	// end inline asm
(EngineCore_DP0 pid=337430) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=337430) 	add.s32 	%r113, %r113, 1024;
(EngineCore_DP0 pid=337430) 	setp.lt.s32 	%p18, %r113, %r14;
(EngineCore_DP0 pid=337430) 	@%p18 bra 	$L__BB0_6;
(EngineCore_DP0 pid=337430) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=337430) 	.loc	1 201 4                         // quant_slide_tuned_Llama3.2-1B.py:201:4
(EngineCore_DP0 pid=337430) 	ret;
(EngineCore_DP0 pid=337430) $L__tmp3:
(EngineCore_DP0 pid=337430) $L__func_end0:
(EngineCore_DP0 pid=337430)                                         // -- End function
(EngineCore_DP0 pid=337430) }
(EngineCore_DP0 pid=337430) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=337430) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=337430) 	.section	.debug_abbrev
(EngineCore_DP0 pid=337430) 	{
(EngineCore_DP0 pid=337430) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=337430) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=337430) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=337430) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=337430) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=337430) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=337430) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=337430) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=337430) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=337430) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=337430) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=337430) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=337430) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=337430) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=337430) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=337430) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=337430) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=337430) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=337430) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=337430) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=337430) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=337430) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=337430) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=337430) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=337430) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=337430) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=337430) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=337430) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=337430) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=337430) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=337430) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=337430) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=337430) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=337430) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=337430) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=337430) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=337430) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=337430) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=337430) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=337430) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=337430) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=337430) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=337430) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=337430) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=337430) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=337430) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=337430) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=337430) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=337430) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=337430) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=337430) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=337430) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=337430) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=337430) 	}
(EngineCore_DP0 pid=337430) 	.section	.debug_info
(EngineCore_DP0 pid=337430) 	{
(EngineCore_DP0 pid=337430) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=337430) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=337430) .b8 0
(EngineCore_DP0 pid=337430) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=337430) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=337430) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=337430) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=337430) .b8 114
(EngineCore_DP0 pid=337430) .b8 105
(EngineCore_DP0 pid=337430) .b8 116
(EngineCore_DP0 pid=337430) .b8 111
(EngineCore_DP0 pid=337430) .b8 110
(EngineCore_DP0 pid=337430) .b8 0
(EngineCore_DP0 pid=337430) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=337430) .b8 0
(EngineCore_DP0 pid=337430) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=337430) .b8 117
(EngineCore_DP0 pid=337430) .b8 97
(EngineCore_DP0 pid=337430) .b8 110
(EngineCore_DP0 pid=337430) .b8 116
(EngineCore_DP0 pid=337430) .b8 95
(EngineCore_DP0 pid=337430) .b8 115
(EngineCore_DP0 pid=337430) .b8 108
(EngineCore_DP0 pid=337430) .b8 105
(EngineCore_DP0 pid=337430) .b8 100
(EngineCore_DP0 pid=337430) .b8 101
(EngineCore_DP0 pid=337430) .b8 95
(EngineCore_DP0 pid=337430) .b8 116
(EngineCore_DP0 pid=337430) .b8 117
(EngineCore_DP0 pid=337430) .b8 110
(EngineCore_DP0 pid=337430) .b8 101
(EngineCore_DP0 pid=337430) .b8 100
(EngineCore_DP0 pid=337430) .b8 95
(EngineCore_DP0 pid=337430) .b8 76
(EngineCore_DP0 pid=337430) .b8 108
(EngineCore_DP0 pid=337430) .b8 97
(EngineCore_DP0 pid=337430) .b8 109
(EngineCore_DP0 pid=337430) .b8 97
(EngineCore_DP0 pid=337430) .b8 51
(EngineCore_DP0 pid=337430) .b8 46
(EngineCore_DP0 pid=337430) .b8 50
(EngineCore_DP0 pid=337430) .b8 45
(EngineCore_DP0 pid=337430) .b8 49
(EngineCore_DP0 pid=337430) .b8 66
(EngineCore_DP0 pid=337430) .b8 46
(EngineCore_DP0 pid=337430) .b8 112
(EngineCore_DP0 pid=337430) .b8 121
(EngineCore_DP0 pid=337430) .b8 0
(EngineCore_DP0 pid=337430) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=337430) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=337430) .b8 114
(EngineCore_DP0 pid=337430) .b8 111
(EngineCore_DP0 pid=337430) .b8 111
(EngineCore_DP0 pid=337430) .b8 116
(EngineCore_DP0 pid=337430) .b8 47
(EngineCore_DP0 pid=337430) .b8 118
(EngineCore_DP0 pid=337430) .b8 108
(EngineCore_DP0 pid=337430) .b8 108
(EngineCore_DP0 pid=337430) .b8 109
(EngineCore_DP0 pid=337430) .b8 98
(EngineCore_DP0 pid=337430) .b8 101
(EngineCore_DP0 pid=337430) .b8 110
(EngineCore_DP0 pid=337430) .b8 99
(EngineCore_DP0 pid=337430) .b8 104
(EngineCore_DP0 pid=337430) .b8 47
(EngineCore_DP0 pid=337430) .b8 115
(EngineCore_DP0 pid=337430) .b8 108
(EngineCore_DP0 pid=337430) .b8 105
(EngineCore_DP0 pid=337430) .b8 100
(EngineCore_DP0 pid=337430) .b8 101
(EngineCore_DP0 pid=337430) .b8 115
(EngineCore_DP0 pid=337430) .b8 112
(EngineCore_DP0 pid=337430) .b8 97
(EngineCore_DP0 pid=337430) .b8 114
(EngineCore_DP0 pid=337430) .b8 115
(EngineCore_DP0 pid=337430) .b8 101
(EngineCore_DP0 pid=337430) .b8 47
(EngineCore_DP0 pid=337430) .b8 99
(EngineCore_DP0 pid=337430) .b8 115
(EngineCore_DP0 pid=337430) .b8 114
(EngineCore_DP0 pid=337430) .b8 99
(EngineCore_DP0 pid=337430) .b8 47
(EngineCore_DP0 pid=337430) .b8 102
(EngineCore_DP0 pid=337430) .b8 117
(EngineCore_DP0 pid=337430) .b8 115
(EngineCore_DP0 pid=337430) .b8 101
(EngineCore_DP0 pid=337430) .b8 100
(EngineCore_DP0 pid=337430) .b8 95
(EngineCore_DP0 pid=337430) .b8 113
(EngineCore_DP0 pid=337430) .b8 117
(EngineCore_DP0 pid=337430) .b8 97
(EngineCore_DP0 pid=337430) .b8 110
(EngineCore_DP0 pid=337430) .b8 116
(EngineCore_DP0 pid=337430) .b8 95
(EngineCore_DP0 pid=337430) .b8 115
(EngineCore_DP0 pid=337430) .b8 108
(EngineCore_DP0 pid=337430) .b8 105
(EngineCore_DP0 pid=337430) .b8 100
(EngineCore_DP0 pid=337430) .b8 101
(EngineCore_DP0 pid=337430) .b8 95
(EngineCore_DP0 pid=337430) .b8 116
(EngineCore_DP0 pid=337430) .b8 114
(EngineCore_DP0 pid=337430) .b8 105
(EngineCore_DP0 pid=337430) .b8 116
(EngineCore_DP0 pid=337430) .b8 111
(EngineCore_DP0 pid=337430) .b8 110
(EngineCore_DP0 pid=337430) .b8 47
(EngineCore_DP0 pid=337430) .b8 98
(EngineCore_DP0 pid=337430) .b8 117
(EngineCore_DP0 pid=337430) .b8 105
(EngineCore_DP0 pid=337430) .b8 108
(EngineCore_DP0 pid=337430) .b8 100
(EngineCore_DP0 pid=337430) .b8 47
(EngineCore_DP0 pid=337430) .b8 71
(EngineCore_DP0 pid=337430) .b8 66
(EngineCore_DP0 pid=337430) .b8 49
(EngineCore_DP0 pid=337430) .b8 48
(EngineCore_DP0 pid=337430) .b8 95
(EngineCore_DP0 pid=337430) .b8 99
(EngineCore_DP0 pid=337430) .b8 99
(EngineCore_DP0 pid=337430) .b8 49
(EngineCore_DP0 pid=337430) .b8 50
(EngineCore_DP0 pid=337430) .b8 49
(EngineCore_DP0 pid=337430) .b8 95
(EngineCore_DP0 pid=337430) .b8 112
(EngineCore_DP0 pid=337430) .b8 121
(EngineCore_DP0 pid=337430) .b8 51
(EngineCore_DP0 pid=337430) .b8 49
(EngineCore_DP0 pid=337430) .b8 50
(EngineCore_DP0 pid=337430) .b8 95
(EngineCore_DP0 pid=337430) .b8 99
(EngineCore_DP0 pid=337430) .b8 117
(EngineCore_DP0 pid=337430) .b8 49
(EngineCore_DP0 pid=337430) .b8 50
(EngineCore_DP0 pid=337430) .b8 57
(EngineCore_DP0 pid=337430) .b8 95
(EngineCore_DP0 pid=337430) .b8 97
(EngineCore_DP0 pid=337430) .b8 97
(EngineCore_DP0 pid=337430) .b8 114
(EngineCore_DP0 pid=337430) .b8 99
(EngineCore_DP0 pid=337430) .b8 104
(EngineCore_DP0 pid=337430) .b8 54
(EngineCore_DP0 pid=337430) .b8 52
(EngineCore_DP0 pid=337430) .b8 0
(EngineCore_DP0 pid=337430) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=337430) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=337430) .b8 113
(EngineCore_DP0 pid=337430) .b8 117
(EngineCore_DP0 pid=337430) .b8 97
(EngineCore_DP0 pid=337430) .b8 110
(EngineCore_DP0 pid=337430) .b8 116
(EngineCore_DP0 pid=337430) .b8 95
(EngineCore_DP0 pid=337430) .b8 115
(EngineCore_DP0 pid=337430) .b8 108
(EngineCore_DP0 pid=337430) .b8 105
(EngineCore_DP0 pid=337430) .b8 100
(EngineCore_DP0 pid=337430) .b8 101
(EngineCore_DP0 pid=337430) .b8 95
(EngineCore_DP0 pid=337430) .b8 102
(EngineCore_DP0 pid=337430) .b8 112
(EngineCore_DP0 pid=337430) .b8 56
(EngineCore_DP0 pid=337430) .b8 95
(EngineCore_DP0 pid=337430) .b8 107
(EngineCore_DP0 pid=337430) .b8 101
(EngineCore_DP0 pid=337430) .b8 114
(EngineCore_DP0 pid=337430) .b8 110
(EngineCore_DP0 pid=337430) .b8 101
(EngineCore_DP0 pid=337430) .b8 108
(EngineCore_DP0 pid=337430) .b8 0
(EngineCore_DP0 pid=337430) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=337430) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=337430) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=337430) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=337430) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=337430) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=337430) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=337430) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=337430) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=337430) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=337430) .b8 191                                 // DW_AT_call_line
(EngineCore_DP0 pid=337430) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=337430) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=337430) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=337430) 	}
(EngineCore_DP0 pid=337430) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=337430) 
(EngineCore_DP0 pid=337430) ================================================================
(EngineCore_DP0 pid=337430) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=337430) 
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpul_r_3wb.ptx', '-o', '/tmp/tmpul_r_3wb.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866] 
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866] 
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866] 
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpul_r_3wb.ptx -o /tmp/tmpul_r_3wb.ptx.o
(EngineCore_DP0 pid=337430) ERROR 01-25 19:16:51 [core.py:866] 

STDERR:
[2026-01-25 19:16:36] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:16:36] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:16:36] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:16:36] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:16:36] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:16:36] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:16:36] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:16:36] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:16:36] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:16:36] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:16:36] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:16:36] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:16:36] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:16:36] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:16:40] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:16:40] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:16:40] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:16:40] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:16:40] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:16:40] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:16:40] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:16:40] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:16:40] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:16:40] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:16:40] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:16:40] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:16:40] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:16:40] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=337430) [2026-01-25 19:16:41] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=337430) [2026-01-25 19:16:41] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=337430) [2026-01-25 19:16:41] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=337430) [2026-01-25 19:16:41] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=337430) [2026-01-25 19:16:41] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=337430) [2026-01-25 19:16:41] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=337430) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=337430) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.18s/it]
(EngineCore_DP0 pid=337430) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.18s/it]
(EngineCore_DP0 pid=337430) 
(EngineCore_DP0 pid=337430) [2026-01-25 19:16:50] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=337430) [2026-01-25 19:16:50] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5308416 bytes
(EngineCore_DP0 pid=337430) [2026-01-25 19:16:50] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=337430) [2026-01-25 19:16:50] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3538944 bytes
(EngineCore_DP0 pid=337430) [2026-01-25 19:16:50] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=337430) [2026-01-25 19:16:50] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 28311552 bytes
(EngineCore_DP0 pid=337430) [2026-01-25 19:16:50] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=337430) [2026-01-25 19:16:51] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14024704 bytes
(EngineCore_DP0 pid=337430) Process EngineCore_DP0:
(EngineCore_DP0 pid=337430) Traceback (most recent call last):
(EngineCore_DP0 pid=337430)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=337430)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=337430)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=337430)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=337430) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpul_r_3wb.ptx', '-o', '/tmp/tmpul_r_3wb.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=337430) 
(EngineCore_DP0 pid=337430) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=337430) 
(EngineCore_DP0 pid=337430) Traceback (most recent call last):
(EngineCore_DP0 pid=337430)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=337430)     self.run()
(EngineCore_DP0 pid=337430)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=337430)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=337430)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=337430)     raise e
(EngineCore_DP0 pid=337430)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=337430)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=337430)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=337430)     super().__init__(
(EngineCore_DP0 pid=337430)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=337430)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=337430)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=337430)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=337430)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=337430)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=337430)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=337430)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=337430)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=337430)     return func(*args, **kwargs)
(EngineCore_DP0 pid=337430)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=337430)     return func(*args, **kwargs)
(EngineCore_DP0 pid=337430)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=337430)     self.model_runner.profile_run()
(EngineCore_DP0 pid=337430)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=337430)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=337430)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=337430)     return func(*args, **kwargs)
(EngineCore_DP0 pid=337430)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=337430)     outputs = self.model(
(EngineCore_DP0 pid=337430)               ^^^^^^^^^^^
(EngineCore_DP0 pid=337430)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=337430)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=337430)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=337430)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=337430)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=337430)     model_output = self.model(
(EngineCore_DP0 pid=337430)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=337430)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=337430)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=337430)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=337430)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=337430)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=337430)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=337430)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=337430)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=337430)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=337430)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=337430)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=337430)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=337430)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=337430)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=337430)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=337430)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=337430)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=337430)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=337430)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=337430)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=337430)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=337430)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=337430)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=337430)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=337430)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=337430)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=337430)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=337430)     return self._linear_fn(
(EngineCore_DP0 pid=337430)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=337430)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=337430)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=337430)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=337430)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=337430)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=337430)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=337430)     return fn(input, L)
(EngineCore_DP0 pid=337430)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=337430)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=337430)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=337430)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=337430)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=337430)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=337430)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=337430)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=337430)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=337430)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=337430)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=337430)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=337430)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=337430)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337430)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=337430)     raise PTXASError(error)
(EngineCore_DP0 pid=337430) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=337430) `ptxas` stderr:
(EngineCore_DP0 pid=337430) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=337430) 
(EngineCore_DP0 pid=337430) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpul_r_3wb.ptx -o /tmp/tmpul_r_3wb.ptx.o
(EngineCore_DP0 pid=337430) 
[rank0]:[W125 19:16:52.296904443 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=512

========== M=1024 ==========
Time: 2026-01-25 19:16:53
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-FP8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:16:57 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:16:57 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=337908) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=337908) 
(EngineCore_DP0 pid=337908) 
(EngineCore_DP0 pid=337908) ================================================================
(EngineCore_DP0 pid=337908) Internal Triton PTX codegen error
(EngineCore_DP0 pid=337908) `ptxas` stderr:
(EngineCore_DP0 pid=337908) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=337908) 
(EngineCore_DP0 pid=337908) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpiecwuw93.ptx -o /tmp/tmpiecwuw93.ptx.o
(EngineCore_DP0 pid=337908) 
(EngineCore_DP0 pid=337908) 
(EngineCore_DP0 pid=337908) //
(EngineCore_DP0 pid=337908) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=337908) //
(EngineCore_DP0 pid=337908) 
(EngineCore_DP0 pid=337908) .version 8.7
(EngineCore_DP0 pid=337908) .target sm_121a
(EngineCore_DP0 pid=337908) .address_size 64
(EngineCore_DP0 pid=337908) 
(EngineCore_DP0 pid=337908) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=337908) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=337908)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=337908) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=337908) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=337908) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=337908) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=337908) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=337908) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=337908) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=337908) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=337908) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=337908) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=337908) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=337908) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=337908) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=337908) )
(EngineCore_DP0 pid=337908) .reqntid 512
(EngineCore_DP0 pid=337908) {
(EngineCore_DP0 pid=337908) 	.reg .pred 	%p<21>;
(EngineCore_DP0 pid=337908) 	.reg .b16 	%rs<61>;
(EngineCore_DP0 pid=337908) 	.reg .b32 	%r<126>;
(EngineCore_DP0 pid=337908) 	.reg .b64 	%rd<14>;
(EngineCore_DP0 pid=337908) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=337908) $L__func_begin0:
(EngineCore_DP0 pid=337908) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=337908) 
(EngineCore_DP0 pid=337908) // %bb.0:
(EngineCore_DP0 pid=337908) 	ld.param.b32 	%r20, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=337908) 	ld.param.b32 	%r19, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=337908) 	ld.param.b32 	%r18, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=337908) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=337908) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=337908) $L__tmp0:
(EngineCore_DP0 pid=337908) 	.loc	1 177 24                        // quant_slide_tuned_Llama3.2-1B.py:177:24
(EngineCore_DP0 pid=337908) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=337908) 	ld.param.b32 	%r22, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=337908) 	.loc	1 182 26                        // quant_slide_tuned_Llama3.2-1B.py:182:26
(EngineCore_DP0 pid=337908) 	mul.lo.s32 	%r23, %r22, %r1;
(EngineCore_DP0 pid=337908) 	.loc	1 182 20                        // quant_slide_tuned_Llama3.2-1B.py:182:20
(EngineCore_DP0 pid=337908) 	mad.wide.s32 	%rd1, %r23, 2, %rd4;
(EngineCore_DP0 pid=337908) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=337908) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=337908) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=337908) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=337908) 	setp.lt.s32 	%p1, %r19, 1;
(EngineCore_DP0 pid=337908) 	mov.b32 	%r124, 0f2B8CBCCC;
(EngineCore_DP0 pid=337908) 	setp.eq.b32 	%p20, %r2, 0;
(EngineCore_DP0 pid=337908) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=337908) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=337908) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=337908) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=337908) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=337908) 	shr.u32 	%r32, %r2, 3;
(EngineCore_DP0 pid=337908) 	and.b32 	%r33, %r32, 60;
(EngineCore_DP0 pid=337908) 	mov.b32 	%r34, global_smem;
(EngineCore_DP0 pid=337908) 	add.s32 	%r52, %r34, %r33;
(EngineCore_DP0 pid=337908) 	shl.b32 	%r35, %r2, 2;
(EngineCore_DP0 pid=337908) 	add.s32 	%r55, %r34, %r35;
(EngineCore_DP0 pid=337908) 	mov.b32 	%r40, 0;
(EngineCore_DP0 pid=337908) 	mov.b32 	%r122, 0f00000000;
(EngineCore_DP0 pid=337908) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=337908) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=337908) 	mov.b32 	%r123, %r40;
(EngineCore_DP0 pid=337908) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=337908) 	.loc	1 188 19                        // quant_slide_tuned_Llama3.2-1B.py:188:19
(EngineCore_DP0 pid=337908) 	add.s32 	%r58, %r4, %r123;
(EngineCore_DP0 pid=337908) 	.loc	1 189 22                        // quant_slide_tuned_Llama3.2-1B.py:189:22
(EngineCore_DP0 pid=337908) 	add.s32 	%r59, %r58, 4096;
(EngineCore_DP0 pid=337908) 	setp.lt.s32 	%p2, %r58, %r18;
(EngineCore_DP0 pid=337908) 	setp.lt.s32 	%p3, %r59, %r18;
(EngineCore_DP0 pid=337908) 	.loc	1 190 29                        // quant_slide_tuned_Llama3.2-1B.py:190:29
(EngineCore_DP0 pid=337908) 	mad.wide.s32 	%rd6, %r58, 2, %rd1;
(EngineCore_DP0 pid=337908) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=337908) 	.loc	1 190 21                        // quant_slide_tuned_Llama3.2-1B.py:190:21
(EngineCore_DP0 pid=337908) 	// begin inline asm
(EngineCore_DP0 pid=337908) 	mov.u32 %r36, %r40;
(EngineCore_DP0 pid=337908) 	mov.u32 %r37, %r40;
(EngineCore_DP0 pid=337908) 	mov.u32 %r38, %r40;
(EngineCore_DP0 pid=337908) 	mov.u32 %r39, %r40;
(EngineCore_DP0 pid=337908) 	@%p2 ld.global.v4.b32 { %r36, %r37, %r38, %r39 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=337908) 	// end inline asm
(EngineCore_DP0 pid=337908) 	mov.b32 	{%rs1, %rs2}, %r36;
(EngineCore_DP0 pid=337908) 	mov.b32 	{%rs3, %rs4}, %r37;
(EngineCore_DP0 pid=337908) 	mov.b32 	{%rs5, %rs6}, %r38;
(EngineCore_DP0 pid=337908) 	mov.b32 	{%rs7, %rs8}, %r39;
(EngineCore_DP0 pid=337908) 	// begin inline asm
(EngineCore_DP0 pid=337908) 	mov.u32 %r44, %r40;
(EngineCore_DP0 pid=337908) 	mov.u32 %r45, %r40;
(EngineCore_DP0 pid=337908) 	mov.u32 %r46, %r40;
(EngineCore_DP0 pid=337908) 	mov.u32 %r47, %r40;
(EngineCore_DP0 pid=337908) 	@%p3 ld.global.v4.b32 { %r44, %r45, %r46, %r47 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=337908) 	// end inline asm
(EngineCore_DP0 pid=337908) 	mov.b32 	{%rs9, %rs10}, %r44;
(EngineCore_DP0 pid=337908) 	mov.b32 	{%rs11, %rs12}, %r45;
(EngineCore_DP0 pid=337908) 	mov.b32 	{%rs13, %rs14}, %r46;
(EngineCore_DP0 pid=337908) 	mov.b32 	{%rs15, %rs16}, %r47;
(EngineCore_DP0 pid=337908) 	.loc	1 191 50                        // quant_slide_tuned_Llama3.2-1B.py:191:50
(EngineCore_DP0 pid=337908) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=337908) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=337908) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=337908) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=337908) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=337908) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=337908) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=337908) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=337908) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=337908) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=337908) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=337908) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=337908) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=337908) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=337908) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=337908) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=337908) $L__tmp1:
(EngineCore_DP0 pid=337908) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=337908) 	bar.sync 	0;
(EngineCore_DP0 pid=337908) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=337908) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=337908) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=337908) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=337908) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=337908) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=337908) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=337908) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=337908) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=337908) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=337908) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=337908) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=337908) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=337908) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=337908) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=337908) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=337908) 	cvt.f32.bf16 	%r60, %rs47;
(EngineCore_DP0 pid=337908) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=337908) 	shfl.sync.bfly.b32 	%r61, %r60, 16, 31, -1;
(EngineCore_DP0 pid=337908) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=337908) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=337908) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=337908) 	shfl.sync.bfly.b32 	%r63, %r62, 8, 31, -1;
(EngineCore_DP0 pid=337908) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=337908) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=337908) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=337908) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=337908) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=337908) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=337908) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=337908) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=337908) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=337908) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=337908) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=337908) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=337908) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=337908) 	max.f32 	%r53, %r68, %r69;
(EngineCore_DP0 pid=337908) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=337908) 	// begin inline asm
(EngineCore_DP0 pid=337908) 	@%p4 st.shared.b32 [ %r52 + 0 ], %r53;
(EngineCore_DP0 pid=337908) 	// end inline asm
(EngineCore_DP0 pid=337908) 	bar.sync 	0;
(EngineCore_DP0 pid=337908) 	// begin inline asm
(EngineCore_DP0 pid=337908) 	@%p5 ld.shared.b32 %r54, [ %r55 + 0 ];
(EngineCore_DP0 pid=337908) 	// end inline asm
(EngineCore_DP0 pid=337908) 	shfl.sync.bfly.b32 	%r70, %r54, 8, 31, -1;
(EngineCore_DP0 pid=337908) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=337908) 	max.f32 	%r71, %r54, %r70;
(EngineCore_DP0 pid=337908) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=337908) 	shfl.sync.bfly.b32 	%r72, %r71, 4, 31, -1;
(EngineCore_DP0 pid=337908) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=337908) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=337908) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=337908) 	shfl.sync.bfly.b32 	%r74, %r73, 2, 31, -1;
(EngineCore_DP0 pid=337908) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=337908) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=337908) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=337908) 	shfl.sync.bfly.b32 	%r76, %r75, 1, 31, -1;
(EngineCore_DP0 pid=337908) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=337908) 	max.f32 	%r57, %r75, %r76;
(EngineCore_DP0 pid=337908) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=337908) 	// begin inline asm
(EngineCore_DP0 pid=337908) 	@%p20 st.shared.b32 [ %r55 + 0 ], %r57;
(EngineCore_DP0 pid=337908) 	// end inline asm
(EngineCore_DP0 pid=337908) 	bar.sync 	0;
(EngineCore_DP0 pid=337908) 	ld.shared.b32 	%r77, [global_smem];
(EngineCore_DP0 pid=337908) $L__tmp2:
(EngineCore_DP0 pid=337908) 	.loc	1 191 36                        // quant_slide_tuned_Llama3.2-1B.py:191:36
(EngineCore_DP0 pid=337908) 	max.f32 	%r122, %r122, %r77;
(EngineCore_DP0 pid=337908) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=337908) 	add.s32 	%r123, %r123, 8192;
(EngineCore_DP0 pid=337908) 	setp.lt.s32 	%p7, %r123, %r19;
(EngineCore_DP0 pid=337908) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=337908) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=337908) 	.loc	1 193 32                        // quant_slide_tuned_Llama3.2-1B.py:193:32
(EngineCore_DP0 pid=337908) 	max.f32 	%r124, %r122, 0f2B8CBCCC;
(EngineCore_DP0 pid=337908) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=337908) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=337908) 	mov.b32 	%r79, 0f43E00000;
(EngineCore_DP0 pid=337908) 	.loc	1 194 32                        // quant_slide_tuned_Llama3.2-1B.py:194:32
(EngineCore_DP0 pid=337908) 	div.full.f32 	%r80, %r124, %r79;
(EngineCore_DP0 pid=337908) 	.loc	1 194 41                        // quant_slide_tuned_Llama3.2-1B.py:194:41
(EngineCore_DP0 pid=337908) 	max.f32 	%r78, %r80, 0f36924925;
(EngineCore_DP0 pid=337908) 	.loc	1 196 25                        // quant_slide_tuned_Llama3.2-1B.py:196:25
(EngineCore_DP0 pid=337908) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=337908) 	.loc	1 196 30                        // quant_slide_tuned_Llama3.2-1B.py:196:30
(EngineCore_DP0 pid=337908) 	// begin inline asm
(EngineCore_DP0 pid=337908) 	@%p20 st.global.b32 [ %rd8 + 0 ], { %r78 };
(EngineCore_DP0 pid=337908) 	// end inline asm
(EngineCore_DP0 pid=337908) 	.loc	1 199 29                        // quant_slide_tuned_Llama3.2-1B.py:199:29
(EngineCore_DP0 pid=337908) 	shl.b32 	%r15, %r20, 1;
(EngineCore_DP0 pid=337908) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=337908) 	setp.lt.s32 	%p9, %r15, 1;
(EngineCore_DP0 pid=337908) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=337908) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=337908) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=337908) 	ld.param.b32 	%r24, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=337908) 	shr.s32 	%r25, %r24, 31;
(EngineCore_DP0 pid=337908) 	shr.u32 	%r26, %r25, 30;
(EngineCore_DP0 pid=337908) 	add.s32 	%r27, %r24, %r26;
(EngineCore_DP0 pid=337908) 	shr.s32 	%r28, %r27, 2;
(EngineCore_DP0 pid=337908) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=337908) 	mul.lo.s32 	%r29, %r28, %r1;
(EngineCore_DP0 pid=337908) 	mad.wide.s32 	%rd2, %r29, 4, %rd5;
(EngineCore_DP0 pid=337908) 	div.full.f32 	%r14, %r79, %r124;
(EngineCore_DP0 pid=337908) 	mov.b32 	%r125, 0;
(EngineCore_DP0 pid=337908) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=337908)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=337908) 	.loc	1 203 30                        // quant_slide_tuned_Llama3.2-1B.py:203:30
(EngineCore_DP0 pid=337908) 	add.s32 	%r92, %r3, %r125;
(EngineCore_DP0 pid=337908) 	setp.lt.s32 	%p14, %r92, %r15;
(EngineCore_DP0 pid=337908) 	.loc	1 206 24                        // quant_slide_tuned_Llama3.2-1B.py:206:24
(EngineCore_DP0 pid=337908) 	shr.u32 	%r93, %r92, 31;
(EngineCore_DP0 pid=337908) 	add.s32 	%r94, %r92, %r93;
(EngineCore_DP0 pid=337908) 	shr.u32 	%r95, %r94, 1;
(EngineCore_DP0 pid=337908) 	.loc	1 207 23                        // quant_slide_tuned_Llama3.2-1B.py:207:23
(EngineCore_DP0 pid=337908) 	and.b32 	%r96, %r94, 2147483646;
(EngineCore_DP0 pid=337908) 	sub.s32 	%r97, %r92, %r96;
(EngineCore_DP0 pid=337908) 	.loc	1 208 30                        // quant_slide_tuned_Llama3.2-1B.py:208:30
(EngineCore_DP0 pid=337908) 	shl.b32 	%r98, %r97, 1;
(EngineCore_DP0 pid=337908) 	.loc	1 208 26                        // quant_slide_tuned_Llama3.2-1B.py:208:26
(EngineCore_DP0 pid=337908) 	mad.lo.s32 	%r99, %r95, 6, %r98;
(EngineCore_DP0 pid=337908) 	.loc	1 211 53                        // quant_slide_tuned_Llama3.2-1B.py:211:53
(EngineCore_DP0 pid=337908) 	setp.lt.s32 	%p15, %r99, %r18;
(EngineCore_DP0 pid=337908) 	.loc	1 211 37                        // quant_slide_tuned_Llama3.2-1B.py:211:37
(EngineCore_DP0 pid=337908) 	and.pred 	%p10, %p14, %p15;
(EngineCore_DP0 pid=337908) 	.loc	1 210 29                        // quant_slide_tuned_Llama3.2-1B.py:210:29
(EngineCore_DP0 pid=337908) 	mad.wide.s32 	%rd9, %r99, 2, %rd1;
(EngineCore_DP0 pid=337908) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=337908) 	.loc	1 210 21                        // quant_slide_tuned_Llama3.2-1B.py:210:21
(EngineCore_DP0 pid=337908) 	// begin inline asm
(EngineCore_DP0 pid=337908) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=337908) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=337908) 	// end inline asm
(EngineCore_DP0 pid=337908) 	.loc	1 211 79                        // quant_slide_tuned_Llama3.2-1B.py:211:79
(EngineCore_DP0 pid=337908) 	cvt.f32.bf16 	%r100, %rs48;
(EngineCore_DP0 pid=337908) 	.loc	1 213 48                        // quant_slide_tuned_Llama3.2-1B.py:213:48
(EngineCore_DP0 pid=337908) 	or.b32 	%r101, %r99, 1;
(EngineCore_DP0 pid=337908) 	.loc	1 213 53                        // quant_slide_tuned_Llama3.2-1B.py:213:53
(EngineCore_DP0 pid=337908) 	setp.lt.s32 	%p16, %r101, %r18;
(EngineCore_DP0 pid=337908) 	.loc	1 213 37                        // quant_slide_tuned_Llama3.2-1B.py:213:37
(EngineCore_DP0 pid=337908) 	and.pred 	%p11, %p14, %p16;
(EngineCore_DP0 pid=337908) 	.loc	1 212 39                        // quant_slide_tuned_Llama3.2-1B.py:212:39
(EngineCore_DP0 pid=337908) 	add.s64 	%rd10, %rd9, 2;
(EngineCore_DP0 pid=337908) 	.loc	1 212 21                        // quant_slide_tuned_Llama3.2-1B.py:212:21
(EngineCore_DP0 pid=337908) 	// begin inline asm
(EngineCore_DP0 pid=337908) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=337908) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=337908) 	// end inline asm
(EngineCore_DP0 pid=337908) 	.loc	1 213 79                        // quant_slide_tuned_Llama3.2-1B.py:213:79
(EngineCore_DP0 pid=337908) 	cvt.f32.bf16 	%r102, %rs50;
(EngineCore_DP0 pid=337908) 	.loc	1 215 48                        // quant_slide_tuned_Llama3.2-1B.py:215:48
(EngineCore_DP0 pid=337908) 	add.s32 	%r103, %r99, 2;
(EngineCore_DP0 pid=337908) 	.loc	1 215 53                        // quant_slide_tuned_Llama3.2-1B.py:215:53
(EngineCore_DP0 pid=337908) 	setp.lt.s32 	%p17, %r103, %r18;
(EngineCore_DP0 pid=337908) 	.loc	1 215 37                        // quant_slide_tuned_Llama3.2-1B.py:215:37
(EngineCore_DP0 pid=337908) 	and.pred 	%p12, %p14, %p17;
(EngineCore_DP0 pid=337908) 	.loc	1 214 39                        // quant_slide_tuned_Llama3.2-1B.py:214:39
(EngineCore_DP0 pid=337908) 	add.s64 	%rd11, %rd9, 4;
(EngineCore_DP0 pid=337908) 	.loc	1 214 21                        // quant_slide_tuned_Llama3.2-1B.py:214:21
(EngineCore_DP0 pid=337908) 	// begin inline asm
(EngineCore_DP0 pid=337908) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=337908) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=337908) 	// end inline asm
(EngineCore_DP0 pid=337908) 	.loc	1 215 79                        // quant_slide_tuned_Llama3.2-1B.py:215:79
(EngineCore_DP0 pid=337908) 	cvt.f32.bf16 	%r104, %rs52;
(EngineCore_DP0 pid=337908) 	.loc	1 217 48                        // quant_slide_tuned_Llama3.2-1B.py:217:48
(EngineCore_DP0 pid=337908) 	add.s32 	%r105, %r99, 3;
(EngineCore_DP0 pid=337908) 	.loc	1 217 53                        // quant_slide_tuned_Llama3.2-1B.py:217:53
(EngineCore_DP0 pid=337908) 	setp.lt.s32 	%p18, %r105, %r18;
(EngineCore_DP0 pid=337908) 	.loc	1 217 37                        // quant_slide_tuned_Llama3.2-1B.py:217:37
(EngineCore_DP0 pid=337908) 	and.pred 	%p13, %p14, %p18;
(EngineCore_DP0 pid=337908) 	.loc	1 216 39                        // quant_slide_tuned_Llama3.2-1B.py:216:39
(EngineCore_DP0 pid=337908) 	add.s64 	%rd12, %rd9, 6;
(EngineCore_DP0 pid=337908) 	.loc	1 216 21                        // quant_slide_tuned_Llama3.2-1B.py:216:21
(EngineCore_DP0 pid=337908) 	// begin inline asm
(EngineCore_DP0 pid=337908) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=337908) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=337908) 	// end inline asm
(EngineCore_DP0 pid=337908) 	.loc	1 217 79                        // quant_slide_tuned_Llama3.2-1B.py:217:79
(EngineCore_DP0 pid=337908) 	cvt.f32.bf16 	%r106, %rs54;
(EngineCore_DP0 pid=337908) 	.loc	1 219 27                        // quant_slide_tuned_Llama3.2-1B.py:219:27
(EngineCore_DP0 pid=337908) 	mul.f32 	%r107, %r14, %r100;
(EngineCore_DP0 pid=337908) 	mov.b32 	%r108, 0f43E00000;
(EngineCore_DP0 pid=337908) 	.loc	1 219 48                        // quant_slide_tuned_Llama3.2-1B.py:219:48
(EngineCore_DP0 pid=337908) 	min.xorsign.abs.f32 	%r82, %r107, %r108;
(EngineCore_DP0 pid=337908) 	.loc	1 219 60                        // quant_slide_tuned_Llama3.2-1B.py:219:60
(EngineCore_DP0 pid=337908) 	// begin inline asm
(EngineCore_DP0 pid=337908) 	cvt.rn.satfinite.e4m3x2.f32  %rs56, %r83, %r82; 
(EngineCore_DP0 pid=337908) 
(EngineCore_DP0 pid=337908) 	// end inline asm
(EngineCore_DP0 pid=337908) 	.loc	1 220 27                        // quant_slide_tuned_Llama3.2-1B.py:220:27
(EngineCore_DP0 pid=337908) 	mul.f32 	%r109, %r14, %r102;
(EngineCore_DP0 pid=337908) 	.loc	1 220 48                        // quant_slide_tuned_Llama3.2-1B.py:220:48
(EngineCore_DP0 pid=337908) 	min.xorsign.abs.f32 	%r84, %r109, %r108;
(EngineCore_DP0 pid=337908) 	.loc	1 220 60                        // quant_slide_tuned_Llama3.2-1B.py:220:60
(EngineCore_DP0 pid=337908) 	// begin inline asm
(EngineCore_DP0 pid=337908) 	cvt.rn.satfinite.e4m3x2.f32  %rs57, %r85, %r84; 
(EngineCore_DP0 pid=337908) 
(EngineCore_DP0 pid=337908) 	// end inline asm
(EngineCore_DP0 pid=337908) 	.loc	1 221 27                        // quant_slide_tuned_Llama3.2-1B.py:221:27
(EngineCore_DP0 pid=337908) 	mul.f32 	%r110, %r14, %r104;
(EngineCore_DP0 pid=337908) 	.loc	1 221 48                        // quant_slide_tuned_Llama3.2-1B.py:221:48
(EngineCore_DP0 pid=337908) 	min.xorsign.abs.f32 	%r86, %r110, %r108;
(EngineCore_DP0 pid=337908) 	.loc	1 221 60                        // quant_slide_tuned_Llama3.2-1B.py:221:60
(EngineCore_DP0 pid=337908) 	// begin inline asm
(EngineCore_DP0 pid=337908) 	cvt.rn.satfinite.e4m3x2.f32  %rs58, %r87, %r86; 
(EngineCore_DP0 pid=337908) 
(EngineCore_DP0 pid=337908) 	// end inline asm
(EngineCore_DP0 pid=337908) 	.loc	1 222 27                        // quant_slide_tuned_Llama3.2-1B.py:222:27
(EngineCore_DP0 pid=337908) 	mul.f32 	%r111, %r14, %r106;
(EngineCore_DP0 pid=337908) 	.loc	1 222 48                        // quant_slide_tuned_Llama3.2-1B.py:222:48
(EngineCore_DP0 pid=337908) 	min.xorsign.abs.f32 	%r88, %r111, %r108;
(EngineCore_DP0 pid=337908) 	.loc	1 222 60                        // quant_slide_tuned_Llama3.2-1B.py:222:60
(EngineCore_DP0 pid=337908) 	// begin inline asm
(EngineCore_DP0 pid=337908) 	cvt.rn.satfinite.e4m3x2.f32  %rs59, %r89, %r88; 
(EngineCore_DP0 pid=337908) 
(EngineCore_DP0 pid=337908) 	// end inline asm
(EngineCore_DP0 pid=337908) 	.loc	1 224 45                        // quant_slide_tuned_Llama3.2-1B.py:224:45
(EngineCore_DP0 pid=337908) 	cvt.u32.u16 	%r112, %rs56;
(EngineCore_DP0 pid=337908) 	and.b32 	%r113, %r112, 255;
(EngineCore_DP0 pid=337908) 	.loc	1 226 45                        // quant_slide_tuned_Llama3.2-1B.py:226:45
(EngineCore_DP0 pid=337908) 	cvt.u32.u16 	%r114, %rs58;
(EngineCore_DP0 pid=337908) 	and.b32 	%r115, %r114, 255;
(EngineCore_DP0 pid=337908) 	.loc	1 227 45                        // quant_slide_tuned_Llama3.2-1B.py:227:45
(EngineCore_DP0 pid=337908) 	cvt.u32.u16 	%r116, %rs59;
(EngineCore_DP0 pid=337908) 	.loc	1 229 30                        // quant_slide_tuned_Llama3.2-1B.py:229:30
(EngineCore_DP0 pid=337908) 	and.b16 	%rs60, %rs57, 255;
(EngineCore_DP0 pid=337908) 	mul.wide.u16 	%r117, %rs60, 256;
(EngineCore_DP0 pid=337908) 	.loc	1 229 24                        // quant_slide_tuned_Llama3.2-1B.py:229:24
(EngineCore_DP0 pid=337908) 	or.b32 	%r118, %r117, %r113;
(EngineCore_DP0 pid=337908) 	.loc	1 229 42                        // quant_slide_tuned_Llama3.2-1B.py:229:42
(EngineCore_DP0 pid=337908) 	shl.b32 	%r119, %r115, 16;
(EngineCore_DP0 pid=337908) 	.loc	1 229 36                        // quant_slide_tuned_Llama3.2-1B.py:229:36
(EngineCore_DP0 pid=337908) 	or.b32 	%r120, %r118, %r119;
(EngineCore_DP0 pid=337908) 	.loc	1 229 55                        // quant_slide_tuned_Llama3.2-1B.py:229:55
(EngineCore_DP0 pid=337908) 	shl.b32 	%r121, %r116, 24;
(EngineCore_DP0 pid=337908) 	.loc	1 229 49                        // quant_slide_tuned_Llama3.2-1B.py:229:49
(EngineCore_DP0 pid=337908) 	or.b32 	%r90, %r120, %r121;
(EngineCore_DP0 pid=337908) 	.loc	1 230 29                        // quant_slide_tuned_Llama3.2-1B.py:230:29
(EngineCore_DP0 pid=337908) 	mad.wide.s32 	%rd13, %r92, 4, %rd2;
(EngineCore_DP0 pid=337908) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-1B.py:230:39
(EngineCore_DP0 pid=337908) 	// begin inline asm
(EngineCore_DP0 pid=337908) 	@%p14 st.global.b32 [ %rd13 + 0 ], { %r90 };
(EngineCore_DP0 pid=337908) 	// end inline asm
(EngineCore_DP0 pid=337908) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=337908) 	add.s32 	%r125, %r125, 512;
(EngineCore_DP0 pid=337908) 	setp.lt.s32 	%p19, %r125, %r15;
(EngineCore_DP0 pid=337908) 	@%p19 bra 	$L__BB0_6;
(EngineCore_DP0 pid=337908) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=337908) 	.loc	1 201 4                         // quant_slide_tuned_Llama3.2-1B.py:201:4
(EngineCore_DP0 pid=337908) 	ret;
(EngineCore_DP0 pid=337908) $L__tmp3:
(EngineCore_DP0 pid=337908) $L__func_end0:
(EngineCore_DP0 pid=337908)                                         // -- End function
(EngineCore_DP0 pid=337908) }
(EngineCore_DP0 pid=337908) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=337908) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=337908) 	.section	.debug_abbrev
(EngineCore_DP0 pid=337908) 	{
(EngineCore_DP0 pid=337908) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=337908) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=337908) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=337908) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=337908) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=337908) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=337908) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=337908) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=337908) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=337908) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=337908) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=337908) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=337908) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=337908) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=337908) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=337908) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=337908) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=337908) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=337908) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=337908) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=337908) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=337908) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=337908) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=337908) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=337908) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=337908) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=337908) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=337908) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=337908) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=337908) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=337908) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=337908) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=337908) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=337908) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=337908) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=337908) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=337908) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=337908) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=337908) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=337908) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=337908) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=337908) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=337908) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=337908) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=337908) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=337908) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=337908) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=337908) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=337908) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=337908) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=337908) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=337908) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=337908) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=337908) 	}
(EngineCore_DP0 pid=337908) 	.section	.debug_info
(EngineCore_DP0 pid=337908) 	{
(EngineCore_DP0 pid=337908) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=337908) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=337908) .b8 0
(EngineCore_DP0 pid=337908) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=337908) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=337908) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=337908) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=337908) .b8 114
(EngineCore_DP0 pid=337908) .b8 105
(EngineCore_DP0 pid=337908) .b8 116
(EngineCore_DP0 pid=337908) .b8 111
(EngineCore_DP0 pid=337908) .b8 110
(EngineCore_DP0 pid=337908) .b8 0
(EngineCore_DP0 pid=337908) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=337908) .b8 0
(EngineCore_DP0 pid=337908) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=337908) .b8 117
(EngineCore_DP0 pid=337908) .b8 97
(EngineCore_DP0 pid=337908) .b8 110
(EngineCore_DP0 pid=337908) .b8 116
(EngineCore_DP0 pid=337908) .b8 95
(EngineCore_DP0 pid=337908) .b8 115
(EngineCore_DP0 pid=337908) .b8 108
(EngineCore_DP0 pid=337908) .b8 105
(EngineCore_DP0 pid=337908) .b8 100
(EngineCore_DP0 pid=337908) .b8 101
(EngineCore_DP0 pid=337908) .b8 95
(EngineCore_DP0 pid=337908) .b8 116
(EngineCore_DP0 pid=337908) .b8 117
(EngineCore_DP0 pid=337908) .b8 110
(EngineCore_DP0 pid=337908) .b8 101
(EngineCore_DP0 pid=337908) .b8 100
(EngineCore_DP0 pid=337908) .b8 95
(EngineCore_DP0 pid=337908) .b8 76
(EngineCore_DP0 pid=337908) .b8 108
(EngineCore_DP0 pid=337908) .b8 97
(EngineCore_DP0 pid=337908) .b8 109
(EngineCore_DP0 pid=337908) .b8 97
(EngineCore_DP0 pid=337908) .b8 51
(EngineCore_DP0 pid=337908) .b8 46
(EngineCore_DP0 pid=337908) .b8 50
(EngineCore_DP0 pid=337908) .b8 45
(EngineCore_DP0 pid=337908) .b8 49
(EngineCore_DP0 pid=337908) .b8 66
(EngineCore_DP0 pid=337908) .b8 46
(EngineCore_DP0 pid=337908) .b8 112
(EngineCore_DP0 pid=337908) .b8 121
(EngineCore_DP0 pid=337908) .b8 0
(EngineCore_DP0 pid=337908) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=337908) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=337908) .b8 114
(EngineCore_DP0 pid=337908) .b8 111
(EngineCore_DP0 pid=337908) .b8 111
(EngineCore_DP0 pid=337908) .b8 116
(EngineCore_DP0 pid=337908) .b8 47
(EngineCore_DP0 pid=337908) .b8 118
(EngineCore_DP0 pid=337908) .b8 108
(EngineCore_DP0 pid=337908) .b8 108
(EngineCore_DP0 pid=337908) .b8 109
(EngineCore_DP0 pid=337908) .b8 98
(EngineCore_DP0 pid=337908) .b8 101
(EngineCore_DP0 pid=337908) .b8 110
(EngineCore_DP0 pid=337908) .b8 99
(EngineCore_DP0 pid=337908) .b8 104
(EngineCore_DP0 pid=337908) .b8 47
(EngineCore_DP0 pid=337908) .b8 115
(EngineCore_DP0 pid=337908) .b8 108
(EngineCore_DP0 pid=337908) .b8 105
(EngineCore_DP0 pid=337908) .b8 100
(EngineCore_DP0 pid=337908) .b8 101
(EngineCore_DP0 pid=337908) .b8 115
(EngineCore_DP0 pid=337908) .b8 112
(EngineCore_DP0 pid=337908) .b8 97
(EngineCore_DP0 pid=337908) .b8 114
(EngineCore_DP0 pid=337908) .b8 115
(EngineCore_DP0 pid=337908) .b8 101
(EngineCore_DP0 pid=337908) .b8 47
(EngineCore_DP0 pid=337908) .b8 99
(EngineCore_DP0 pid=337908) .b8 115
(EngineCore_DP0 pid=337908) .b8 114
(EngineCore_DP0 pid=337908) .b8 99
(EngineCore_DP0 pid=337908) .b8 47
(EngineCore_DP0 pid=337908) .b8 102
(EngineCore_DP0 pid=337908) .b8 117
(EngineCore_DP0 pid=337908) .b8 115
(EngineCore_DP0 pid=337908) .b8 101
(EngineCore_DP0 pid=337908) .b8 100
(EngineCore_DP0 pid=337908) .b8 95
(EngineCore_DP0 pid=337908) .b8 113
(EngineCore_DP0 pid=337908) .b8 117
(EngineCore_DP0 pid=337908) .b8 97
(EngineCore_DP0 pid=337908) .b8 110
(EngineCore_DP0 pid=337908) .b8 116
(EngineCore_DP0 pid=337908) .b8 95
(EngineCore_DP0 pid=337908) .b8 115
(EngineCore_DP0 pid=337908) .b8 108
(EngineCore_DP0 pid=337908) .b8 105
(EngineCore_DP0 pid=337908) .b8 100
(EngineCore_DP0 pid=337908) .b8 101
(EngineCore_DP0 pid=337908) .b8 95
(EngineCore_DP0 pid=337908) .b8 116
(EngineCore_DP0 pid=337908) .b8 114
(EngineCore_DP0 pid=337908) .b8 105
(EngineCore_DP0 pid=337908) .b8 116
(EngineCore_DP0 pid=337908) .b8 111
(EngineCore_DP0 pid=337908) .b8 110
(EngineCore_DP0 pid=337908) .b8 47
(EngineCore_DP0 pid=337908) .b8 98
(EngineCore_DP0 pid=337908) .b8 117
(EngineCore_DP0 pid=337908) .b8 105
(EngineCore_DP0 pid=337908) .b8 108
(EngineCore_DP0 pid=337908) .b8 100
(EngineCore_DP0 pid=337908) .b8 47
(EngineCore_DP0 pid=337908) .b8 71
(EngineCore_DP0 pid=337908) .b8 66
(EngineCore_DP0 pid=337908) .b8 49
(EngineCore_DP0 pid=337908) .b8 48
(EngineCore_DP0 pid=337908) .b8 95
(EngineCore_DP0 pid=337908) .b8 99
(EngineCore_DP0 pid=337908) .b8 99
(EngineCore_DP0 pid=337908) .b8 49
(EngineCore_DP0 pid=337908) .b8 50
(EngineCore_DP0 pid=337908) .b8 49
(EngineCore_DP0 pid=337908) .b8 95
(EngineCore_DP0 pid=337908) .b8 112
(EngineCore_DP0 pid=337908) .b8 121
(EngineCore_DP0 pid=337908) .b8 51
(EngineCore_DP0 pid=337908) .b8 49
(EngineCore_DP0 pid=337908) .b8 50
(EngineCore_DP0 pid=337908) .b8 95
(EngineCore_DP0 pid=337908) .b8 99
(EngineCore_DP0 pid=337908) .b8 117
(EngineCore_DP0 pid=337908) .b8 49
(EngineCore_DP0 pid=337908) .b8 50
(EngineCore_DP0 pid=337908) .b8 57
(EngineCore_DP0 pid=337908) .b8 95
(EngineCore_DP0 pid=337908) .b8 97
(EngineCore_DP0 pid=337908) .b8 97
(EngineCore_DP0 pid=337908) .b8 114
(EngineCore_DP0 pid=337908) .b8 99
(EngineCore_DP0 pid=337908) .b8 104
(EngineCore_DP0 pid=337908) .b8 54
(EngineCore_DP0 pid=337908) .b8 52
(EngineCore_DP0 pid=337908) .b8 0
(EngineCore_DP0 pid=337908) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=337908) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=337908) .b8 113
(EngineCore_DP0 pid=337908) .b8 117
(EngineCore_DP0 pid=337908) .b8 97
(EngineCore_DP0 pid=337908) .b8 110
(EngineCore_DP0 pid=337908) .b8 116
(EngineCore_DP0 pid=337908) .b8 95
(EngineCore_DP0 pid=337908) .b8 115
(EngineCore_DP0 pid=337908) .b8 108
(EngineCore_DP0 pid=337908) .b8 105
(EngineCore_DP0 pid=337908) .b8 100
(EngineCore_DP0 pid=337908) .b8 101
(EngineCore_DP0 pid=337908) .b8 95
(EngineCore_DP0 pid=337908) .b8 102
(EngineCore_DP0 pid=337908) .b8 112
(EngineCore_DP0 pid=337908) .b8 56
(EngineCore_DP0 pid=337908) .b8 95
(EngineCore_DP0 pid=337908) .b8 107
(EngineCore_DP0 pid=337908) .b8 101
(EngineCore_DP0 pid=337908) .b8 114
(EngineCore_DP0 pid=337908) .b8 110
(EngineCore_DP0 pid=337908) .b8 101
(EngineCore_DP0 pid=337908) .b8 108
(EngineCore_DP0 pid=337908) .b8 0
(EngineCore_DP0 pid=337908) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=337908) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=337908) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=337908) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=337908) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=337908) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=337908) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=337908) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=337908) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=337908) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=337908) .b8 191                                 // DW_AT_call_line
(EngineCore_DP0 pid=337908) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=337908) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=337908) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=337908) 	}
(EngineCore_DP0 pid=337908) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=337908) 
(EngineCore_DP0 pid=337908) ================================================================
(EngineCore_DP0 pid=337908) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=337908) 
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpiecwuw93.ptx', '-o', '/tmp/tmpiecwuw93.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866] 
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866] 
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866] 
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpiecwuw93.ptx -o /tmp/tmpiecwuw93.ptx.o
(EngineCore_DP0 pid=337908) ERROR 01-25 19:17:12 [core.py:866] 

STDERR:
[2026-01-25 19:16:57] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:16:57] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:16:57] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:16:57] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:16:57] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:16:57] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:16:57] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:16:57] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:16:57] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:16:57] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:16:57] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:16:57] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:16:57] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:16:57] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:17:01] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:17:01] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:17:01] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:17:01] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:17:01] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:17:01] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:17:01] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:17:01] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:17:01] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:17:01] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:17:01] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:17:01] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:17:01] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:17:01] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=337908) [2026-01-25 19:17:01] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=337908) [2026-01-25 19:17:01] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=337908) [2026-01-25 19:17:01] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=337908) [2026-01-25 19:17:01] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=337908) [2026-01-25 19:17:01] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=337908) [2026-01-25 19:17:01] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=337908) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=337908) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.26s/it]
(EngineCore_DP0 pid=337908) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.26s/it]
(EngineCore_DP0 pid=337908) 
(EngineCore_DP0 pid=337908) [2026-01-25 19:17:11] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=337908) [2026-01-25 19:17:11] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5308416 bytes
(EngineCore_DP0 pid=337908) [2026-01-25 19:17:11] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=337908) [2026-01-25 19:17:11] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3538944 bytes
(EngineCore_DP0 pid=337908) [2026-01-25 19:17:11] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=337908) [2026-01-25 19:17:11] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 28311552 bytes
(EngineCore_DP0 pid=337908) [2026-01-25 19:17:11] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=337908) [2026-01-25 19:17:11] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14024704 bytes
(EngineCore_DP0 pid=337908) Process EngineCore_DP0:
(EngineCore_DP0 pid=337908) Traceback (most recent call last):
(EngineCore_DP0 pid=337908)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=337908)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=337908)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=337908)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=337908) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpiecwuw93.ptx', '-o', '/tmp/tmpiecwuw93.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=337908) 
(EngineCore_DP0 pid=337908) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=337908) 
(EngineCore_DP0 pid=337908) Traceback (most recent call last):
(EngineCore_DP0 pid=337908)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=337908)     self.run()
(EngineCore_DP0 pid=337908)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=337908)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=337908)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=337908)     raise e
(EngineCore_DP0 pid=337908)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=337908)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=337908)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=337908)     super().__init__(
(EngineCore_DP0 pid=337908)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=337908)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=337908)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=337908)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=337908)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=337908)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=337908)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=337908)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=337908)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=337908)     return func(*args, **kwargs)
(EngineCore_DP0 pid=337908)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=337908)     return func(*args, **kwargs)
(EngineCore_DP0 pid=337908)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=337908)     self.model_runner.profile_run()
(EngineCore_DP0 pid=337908)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=337908)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=337908)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=337908)     return func(*args, **kwargs)
(EngineCore_DP0 pid=337908)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=337908)     outputs = self.model(
(EngineCore_DP0 pid=337908)               ^^^^^^^^^^^
(EngineCore_DP0 pid=337908)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=337908)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=337908)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=337908)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=337908)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=337908)     model_output = self.model(
(EngineCore_DP0 pid=337908)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=337908)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=337908)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=337908)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=337908)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=337908)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=337908)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=337908)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=337908)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=337908)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=337908)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=337908)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=337908)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=337908)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=337908)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=337908)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=337908)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=337908)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=337908)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=337908)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=337908)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=337908)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=337908)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=337908)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=337908)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=337908)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=337908)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=337908)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=337908)     return self._linear_fn(
(EngineCore_DP0 pid=337908)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=337908)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=337908)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=337908)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=337908)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=337908)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=337908)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=337908)     return fn(input, L)
(EngineCore_DP0 pid=337908)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=337908)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=337908)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=337908)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=337908)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=337908)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=337908)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=337908)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=337908)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=337908)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=337908)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=337908)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=337908)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=337908)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=337908)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=337908)     raise PTXASError(error)
(EngineCore_DP0 pid=337908) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=337908) `ptxas` stderr:
(EngineCore_DP0 pid=337908) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=337908) 
(EngineCore_DP0 pid=337908) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpiecwuw93.ptx -o /tmp/tmpiecwuw93.ptx.o
(EngineCore_DP0 pid=337908) 
[rank0]:[W125 19:17:12.048222525 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=1024

========== M=2048 ==========
Time: 2026-01-25 19:17:14
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-FP8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:17:18 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:17:18 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=338382) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=338382) 
(EngineCore_DP0 pid=338382) 
(EngineCore_DP0 pid=338382) ================================================================
(EngineCore_DP0 pid=338382) Internal Triton PTX codegen error
(EngineCore_DP0 pid=338382) `ptxas` stderr:
(EngineCore_DP0 pid=338382) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=338382) 
(EngineCore_DP0 pid=338382) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpa5f7fejv.ptx -o /tmp/tmpa5f7fejv.ptx.o
(EngineCore_DP0 pid=338382) 
(EngineCore_DP0 pid=338382) 
(EngineCore_DP0 pid=338382) //
(EngineCore_DP0 pid=338382) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=338382) //
(EngineCore_DP0 pid=338382) 
(EngineCore_DP0 pid=338382) .version 8.7
(EngineCore_DP0 pid=338382) .target sm_121a
(EngineCore_DP0 pid=338382) .address_size 64
(EngineCore_DP0 pid=338382) 
(EngineCore_DP0 pid=338382) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=338382) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=338382)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=338382) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=338382) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=338382) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=338382) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=338382) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=338382) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=338382) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=338382) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=338382) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=338382) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=338382) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=338382) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=338382) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=338382) )
(EngineCore_DP0 pid=338382) .reqntid 512
(EngineCore_DP0 pid=338382) {
(EngineCore_DP0 pid=338382) 	.reg .pred 	%p<21>;
(EngineCore_DP0 pid=338382) 	.reg .b16 	%rs<61>;
(EngineCore_DP0 pid=338382) 	.reg .b32 	%r<126>;
(EngineCore_DP0 pid=338382) 	.reg .b64 	%rd<14>;
(EngineCore_DP0 pid=338382) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=338382) $L__func_begin0:
(EngineCore_DP0 pid=338382) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=338382) 
(EngineCore_DP0 pid=338382) // %bb.0:
(EngineCore_DP0 pid=338382) 	ld.param.b32 	%r20, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=338382) 	ld.param.b32 	%r19, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=338382) 	ld.param.b32 	%r18, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=338382) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=338382) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=338382) $L__tmp0:
(EngineCore_DP0 pid=338382) 	.loc	1 177 24                        // quant_slide_tuned_Llama3.2-1B.py:177:24
(EngineCore_DP0 pid=338382) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=338382) 	ld.param.b32 	%r22, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=338382) 	.loc	1 182 26                        // quant_slide_tuned_Llama3.2-1B.py:182:26
(EngineCore_DP0 pid=338382) 	mul.lo.s32 	%r23, %r22, %r1;
(EngineCore_DP0 pid=338382) 	.loc	1 182 20                        // quant_slide_tuned_Llama3.2-1B.py:182:20
(EngineCore_DP0 pid=338382) 	mad.wide.s32 	%rd1, %r23, 2, %rd4;
(EngineCore_DP0 pid=338382) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=338382) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=338382) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=338382) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=338382) 	setp.lt.s32 	%p1, %r19, 1;
(EngineCore_DP0 pid=338382) 	mov.b32 	%r124, 0f2B8CBCCC;
(EngineCore_DP0 pid=338382) 	setp.eq.b32 	%p20, %r2, 0;
(EngineCore_DP0 pid=338382) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=338382) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=338382) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=338382) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=338382) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=338382) 	shr.u32 	%r32, %r2, 3;
(EngineCore_DP0 pid=338382) 	and.b32 	%r33, %r32, 60;
(EngineCore_DP0 pid=338382) 	mov.b32 	%r34, global_smem;
(EngineCore_DP0 pid=338382) 	add.s32 	%r52, %r34, %r33;
(EngineCore_DP0 pid=338382) 	shl.b32 	%r35, %r2, 2;
(EngineCore_DP0 pid=338382) 	add.s32 	%r55, %r34, %r35;
(EngineCore_DP0 pid=338382) 	mov.b32 	%r40, 0;
(EngineCore_DP0 pid=338382) 	mov.b32 	%r122, 0f00000000;
(EngineCore_DP0 pid=338382) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=338382) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=338382) 	mov.b32 	%r123, %r40;
(EngineCore_DP0 pid=338382) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=338382) 	.loc	1 188 19                        // quant_slide_tuned_Llama3.2-1B.py:188:19
(EngineCore_DP0 pid=338382) 	add.s32 	%r58, %r4, %r123;
(EngineCore_DP0 pid=338382) 	.loc	1 189 22                        // quant_slide_tuned_Llama3.2-1B.py:189:22
(EngineCore_DP0 pid=338382) 	add.s32 	%r59, %r58, 4096;
(EngineCore_DP0 pid=338382) 	setp.lt.s32 	%p2, %r58, %r18;
(EngineCore_DP0 pid=338382) 	setp.lt.s32 	%p3, %r59, %r18;
(EngineCore_DP0 pid=338382) 	.loc	1 190 29                        // quant_slide_tuned_Llama3.2-1B.py:190:29
(EngineCore_DP0 pid=338382) 	mad.wide.s32 	%rd6, %r58, 2, %rd1;
(EngineCore_DP0 pid=338382) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=338382) 	.loc	1 190 21                        // quant_slide_tuned_Llama3.2-1B.py:190:21
(EngineCore_DP0 pid=338382) 	// begin inline asm
(EngineCore_DP0 pid=338382) 	mov.u32 %r36, %r40;
(EngineCore_DP0 pid=338382) 	mov.u32 %r37, %r40;
(EngineCore_DP0 pid=338382) 	mov.u32 %r38, %r40;
(EngineCore_DP0 pid=338382) 	mov.u32 %r39, %r40;
(EngineCore_DP0 pid=338382) 	@%p2 ld.global.v4.b32 { %r36, %r37, %r38, %r39 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=338382) 	// end inline asm
(EngineCore_DP0 pid=338382) 	mov.b32 	{%rs1, %rs2}, %r36;
(EngineCore_DP0 pid=338382) 	mov.b32 	{%rs3, %rs4}, %r37;
(EngineCore_DP0 pid=338382) 	mov.b32 	{%rs5, %rs6}, %r38;
(EngineCore_DP0 pid=338382) 	mov.b32 	{%rs7, %rs8}, %r39;
(EngineCore_DP0 pid=338382) 	// begin inline asm
(EngineCore_DP0 pid=338382) 	mov.u32 %r44, %r40;
(EngineCore_DP0 pid=338382) 	mov.u32 %r45, %r40;
(EngineCore_DP0 pid=338382) 	mov.u32 %r46, %r40;
(EngineCore_DP0 pid=338382) 	mov.u32 %r47, %r40;
(EngineCore_DP0 pid=338382) 	@%p3 ld.global.v4.b32 { %r44, %r45, %r46, %r47 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=338382) 	// end inline asm
(EngineCore_DP0 pid=338382) 	mov.b32 	{%rs9, %rs10}, %r44;
(EngineCore_DP0 pid=338382) 	mov.b32 	{%rs11, %rs12}, %r45;
(EngineCore_DP0 pid=338382) 	mov.b32 	{%rs13, %rs14}, %r46;
(EngineCore_DP0 pid=338382) 	mov.b32 	{%rs15, %rs16}, %r47;
(EngineCore_DP0 pid=338382) 	.loc	1 191 50                        // quant_slide_tuned_Llama3.2-1B.py:191:50
(EngineCore_DP0 pid=338382) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=338382) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=338382) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=338382) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=338382) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=338382) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=338382) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=338382) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=338382) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=338382) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=338382) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=338382) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=338382) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=338382) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=338382) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=338382) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=338382) $L__tmp1:
(EngineCore_DP0 pid=338382) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=338382) 	bar.sync 	0;
(EngineCore_DP0 pid=338382) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=338382) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=338382) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=338382) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=338382) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=338382) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=338382) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=338382) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=338382) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=338382) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=338382) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=338382) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=338382) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=338382) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=338382) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=338382) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=338382) 	cvt.f32.bf16 	%r60, %rs47;
(EngineCore_DP0 pid=338382) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=338382) 	shfl.sync.bfly.b32 	%r61, %r60, 16, 31, -1;
(EngineCore_DP0 pid=338382) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=338382) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=338382) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=338382) 	shfl.sync.bfly.b32 	%r63, %r62, 8, 31, -1;
(EngineCore_DP0 pid=338382) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=338382) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=338382) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=338382) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=338382) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=338382) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=338382) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=338382) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=338382) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=338382) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=338382) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=338382) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=338382) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=338382) 	max.f32 	%r53, %r68, %r69;
(EngineCore_DP0 pid=338382) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=338382) 	// begin inline asm
(EngineCore_DP0 pid=338382) 	@%p4 st.shared.b32 [ %r52 + 0 ], %r53;
(EngineCore_DP0 pid=338382) 	// end inline asm
(EngineCore_DP0 pid=338382) 	bar.sync 	0;
(EngineCore_DP0 pid=338382) 	// begin inline asm
(EngineCore_DP0 pid=338382) 	@%p5 ld.shared.b32 %r54, [ %r55 + 0 ];
(EngineCore_DP0 pid=338382) 	// end inline asm
(EngineCore_DP0 pid=338382) 	shfl.sync.bfly.b32 	%r70, %r54, 8, 31, -1;
(EngineCore_DP0 pid=338382) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=338382) 	max.f32 	%r71, %r54, %r70;
(EngineCore_DP0 pid=338382) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=338382) 	shfl.sync.bfly.b32 	%r72, %r71, 4, 31, -1;
(EngineCore_DP0 pid=338382) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=338382) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=338382) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=338382) 	shfl.sync.bfly.b32 	%r74, %r73, 2, 31, -1;
(EngineCore_DP0 pid=338382) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=338382) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=338382) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=338382) 	shfl.sync.bfly.b32 	%r76, %r75, 1, 31, -1;
(EngineCore_DP0 pid=338382) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=338382) 	max.f32 	%r57, %r75, %r76;
(EngineCore_DP0 pid=338382) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=338382) 	// begin inline asm
(EngineCore_DP0 pid=338382) 	@%p20 st.shared.b32 [ %r55 + 0 ], %r57;
(EngineCore_DP0 pid=338382) 	// end inline asm
(EngineCore_DP0 pid=338382) 	bar.sync 	0;
(EngineCore_DP0 pid=338382) 	ld.shared.b32 	%r77, [global_smem];
(EngineCore_DP0 pid=338382) $L__tmp2:
(EngineCore_DP0 pid=338382) 	.loc	1 191 36                        // quant_slide_tuned_Llama3.2-1B.py:191:36
(EngineCore_DP0 pid=338382) 	max.f32 	%r122, %r122, %r77;
(EngineCore_DP0 pid=338382) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=338382) 	add.s32 	%r123, %r123, 8192;
(EngineCore_DP0 pid=338382) 	setp.lt.s32 	%p7, %r123, %r19;
(EngineCore_DP0 pid=338382) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=338382) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=338382) 	.loc	1 193 32                        // quant_slide_tuned_Llama3.2-1B.py:193:32
(EngineCore_DP0 pid=338382) 	max.f32 	%r124, %r122, 0f2B8CBCCC;
(EngineCore_DP0 pid=338382) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=338382) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=338382) 	mov.b32 	%r79, 0f43E00000;
(EngineCore_DP0 pid=338382) 	.loc	1 194 32                        // quant_slide_tuned_Llama3.2-1B.py:194:32
(EngineCore_DP0 pid=338382) 	div.full.f32 	%r80, %r124, %r79;
(EngineCore_DP0 pid=338382) 	.loc	1 194 41                        // quant_slide_tuned_Llama3.2-1B.py:194:41
(EngineCore_DP0 pid=338382) 	max.f32 	%r78, %r80, 0f36924925;
(EngineCore_DP0 pid=338382) 	.loc	1 196 25                        // quant_slide_tuned_Llama3.2-1B.py:196:25
(EngineCore_DP0 pid=338382) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=338382) 	.loc	1 196 30                        // quant_slide_tuned_Llama3.2-1B.py:196:30
(EngineCore_DP0 pid=338382) 	// begin inline asm
(EngineCore_DP0 pid=338382) 	@%p20 st.global.b32 [ %rd8 + 0 ], { %r78 };
(EngineCore_DP0 pid=338382) 	// end inline asm
(EngineCore_DP0 pid=338382) 	.loc	1 199 29                        // quant_slide_tuned_Llama3.2-1B.py:199:29
(EngineCore_DP0 pid=338382) 	shl.b32 	%r15, %r20, 1;
(EngineCore_DP0 pid=338382) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=338382) 	setp.lt.s32 	%p9, %r15, 1;
(EngineCore_DP0 pid=338382) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=338382) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=338382) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=338382) 	ld.param.b32 	%r24, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=338382) 	shr.s32 	%r25, %r24, 31;
(EngineCore_DP0 pid=338382) 	shr.u32 	%r26, %r25, 30;
(EngineCore_DP0 pid=338382) 	add.s32 	%r27, %r24, %r26;
(EngineCore_DP0 pid=338382) 	shr.s32 	%r28, %r27, 2;
(EngineCore_DP0 pid=338382) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=338382) 	mul.lo.s32 	%r29, %r28, %r1;
(EngineCore_DP0 pid=338382) 	mad.wide.s32 	%rd2, %r29, 4, %rd5;
(EngineCore_DP0 pid=338382) 	div.full.f32 	%r14, %r79, %r124;
(EngineCore_DP0 pid=338382) 	mov.b32 	%r125, 0;
(EngineCore_DP0 pid=338382) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=338382)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=338382) 	.loc	1 203 30                        // quant_slide_tuned_Llama3.2-1B.py:203:30
(EngineCore_DP0 pid=338382) 	add.s32 	%r92, %r3, %r125;
(EngineCore_DP0 pid=338382) 	setp.lt.s32 	%p14, %r92, %r15;
(EngineCore_DP0 pid=338382) 	.loc	1 206 24                        // quant_slide_tuned_Llama3.2-1B.py:206:24
(EngineCore_DP0 pid=338382) 	shr.u32 	%r93, %r92, 31;
(EngineCore_DP0 pid=338382) 	add.s32 	%r94, %r92, %r93;
(EngineCore_DP0 pid=338382) 	shr.u32 	%r95, %r94, 1;
(EngineCore_DP0 pid=338382) 	.loc	1 207 23                        // quant_slide_tuned_Llama3.2-1B.py:207:23
(EngineCore_DP0 pid=338382) 	and.b32 	%r96, %r94, 2147483646;
(EngineCore_DP0 pid=338382) 	sub.s32 	%r97, %r92, %r96;
(EngineCore_DP0 pid=338382) 	.loc	1 208 30                        // quant_slide_tuned_Llama3.2-1B.py:208:30
(EngineCore_DP0 pid=338382) 	shl.b32 	%r98, %r97, 1;
(EngineCore_DP0 pid=338382) 	.loc	1 208 26                        // quant_slide_tuned_Llama3.2-1B.py:208:26
(EngineCore_DP0 pid=338382) 	mad.lo.s32 	%r99, %r95, 6, %r98;
(EngineCore_DP0 pid=338382) 	.loc	1 211 53                        // quant_slide_tuned_Llama3.2-1B.py:211:53
(EngineCore_DP0 pid=338382) 	setp.lt.s32 	%p15, %r99, %r18;
(EngineCore_DP0 pid=338382) 	.loc	1 211 37                        // quant_slide_tuned_Llama3.2-1B.py:211:37
(EngineCore_DP0 pid=338382) 	and.pred 	%p10, %p14, %p15;
(EngineCore_DP0 pid=338382) 	.loc	1 210 29                        // quant_slide_tuned_Llama3.2-1B.py:210:29
(EngineCore_DP0 pid=338382) 	mad.wide.s32 	%rd9, %r99, 2, %rd1;
(EngineCore_DP0 pid=338382) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=338382) 	.loc	1 210 21                        // quant_slide_tuned_Llama3.2-1B.py:210:21
(EngineCore_DP0 pid=338382) 	// begin inline asm
(EngineCore_DP0 pid=338382) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=338382) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=338382) 	// end inline asm
(EngineCore_DP0 pid=338382) 	.loc	1 211 79                        // quant_slide_tuned_Llama3.2-1B.py:211:79
(EngineCore_DP0 pid=338382) 	cvt.f32.bf16 	%r100, %rs48;
(EngineCore_DP0 pid=338382) 	.loc	1 213 48                        // quant_slide_tuned_Llama3.2-1B.py:213:48
(EngineCore_DP0 pid=338382) 	or.b32 	%r101, %r99, 1;
(EngineCore_DP0 pid=338382) 	.loc	1 213 53                        // quant_slide_tuned_Llama3.2-1B.py:213:53
(EngineCore_DP0 pid=338382) 	setp.lt.s32 	%p16, %r101, %r18;
(EngineCore_DP0 pid=338382) 	.loc	1 213 37                        // quant_slide_tuned_Llama3.2-1B.py:213:37
(EngineCore_DP0 pid=338382) 	and.pred 	%p11, %p14, %p16;
(EngineCore_DP0 pid=338382) 	.loc	1 212 39                        // quant_slide_tuned_Llama3.2-1B.py:212:39
(EngineCore_DP0 pid=338382) 	add.s64 	%rd10, %rd9, 2;
(EngineCore_DP0 pid=338382) 	.loc	1 212 21                        // quant_slide_tuned_Llama3.2-1B.py:212:21
(EngineCore_DP0 pid=338382) 	// begin inline asm
(EngineCore_DP0 pid=338382) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=338382) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=338382) 	// end inline asm
(EngineCore_DP0 pid=338382) 	.loc	1 213 79                        // quant_slide_tuned_Llama3.2-1B.py:213:79
(EngineCore_DP0 pid=338382) 	cvt.f32.bf16 	%r102, %rs50;
(EngineCore_DP0 pid=338382) 	.loc	1 215 48                        // quant_slide_tuned_Llama3.2-1B.py:215:48
(EngineCore_DP0 pid=338382) 	add.s32 	%r103, %r99, 2;
(EngineCore_DP0 pid=338382) 	.loc	1 215 53                        // quant_slide_tuned_Llama3.2-1B.py:215:53
(EngineCore_DP0 pid=338382) 	setp.lt.s32 	%p17, %r103, %r18;
(EngineCore_DP0 pid=338382) 	.loc	1 215 37                        // quant_slide_tuned_Llama3.2-1B.py:215:37
(EngineCore_DP0 pid=338382) 	and.pred 	%p12, %p14, %p17;
(EngineCore_DP0 pid=338382) 	.loc	1 214 39                        // quant_slide_tuned_Llama3.2-1B.py:214:39
(EngineCore_DP0 pid=338382) 	add.s64 	%rd11, %rd9, 4;
(EngineCore_DP0 pid=338382) 	.loc	1 214 21                        // quant_slide_tuned_Llama3.2-1B.py:214:21
(EngineCore_DP0 pid=338382) 	// begin inline asm
(EngineCore_DP0 pid=338382) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=338382) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=338382) 	// end inline asm
(EngineCore_DP0 pid=338382) 	.loc	1 215 79                        // quant_slide_tuned_Llama3.2-1B.py:215:79
(EngineCore_DP0 pid=338382) 	cvt.f32.bf16 	%r104, %rs52;
(EngineCore_DP0 pid=338382) 	.loc	1 217 48                        // quant_slide_tuned_Llama3.2-1B.py:217:48
(EngineCore_DP0 pid=338382) 	add.s32 	%r105, %r99, 3;
(EngineCore_DP0 pid=338382) 	.loc	1 217 53                        // quant_slide_tuned_Llama3.2-1B.py:217:53
(EngineCore_DP0 pid=338382) 	setp.lt.s32 	%p18, %r105, %r18;
(EngineCore_DP0 pid=338382) 	.loc	1 217 37                        // quant_slide_tuned_Llama3.2-1B.py:217:37
(EngineCore_DP0 pid=338382) 	and.pred 	%p13, %p14, %p18;
(EngineCore_DP0 pid=338382) 	.loc	1 216 39                        // quant_slide_tuned_Llama3.2-1B.py:216:39
(EngineCore_DP0 pid=338382) 	add.s64 	%rd12, %rd9, 6;
(EngineCore_DP0 pid=338382) 	.loc	1 216 21                        // quant_slide_tuned_Llama3.2-1B.py:216:21
(EngineCore_DP0 pid=338382) 	// begin inline asm
(EngineCore_DP0 pid=338382) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=338382) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=338382) 	// end inline asm
(EngineCore_DP0 pid=338382) 	.loc	1 217 79                        // quant_slide_tuned_Llama3.2-1B.py:217:79
(EngineCore_DP0 pid=338382) 	cvt.f32.bf16 	%r106, %rs54;
(EngineCore_DP0 pid=338382) 	.loc	1 219 27                        // quant_slide_tuned_Llama3.2-1B.py:219:27
(EngineCore_DP0 pid=338382) 	mul.f32 	%r107, %r14, %r100;
(EngineCore_DP0 pid=338382) 	mov.b32 	%r108, 0f43E00000;
(EngineCore_DP0 pid=338382) 	.loc	1 219 48                        // quant_slide_tuned_Llama3.2-1B.py:219:48
(EngineCore_DP0 pid=338382) 	min.xorsign.abs.f32 	%r82, %r107, %r108;
(EngineCore_DP0 pid=338382) 	.loc	1 219 60                        // quant_slide_tuned_Llama3.2-1B.py:219:60
(EngineCore_DP0 pid=338382) 	// begin inline asm
(EngineCore_DP0 pid=338382) 	cvt.rn.satfinite.e4m3x2.f32  %rs56, %r83, %r82; 
(EngineCore_DP0 pid=338382) 
(EngineCore_DP0 pid=338382) 	// end inline asm
(EngineCore_DP0 pid=338382) 	.loc	1 220 27                        // quant_slide_tuned_Llama3.2-1B.py:220:27
(EngineCore_DP0 pid=338382) 	mul.f32 	%r109, %r14, %r102;
(EngineCore_DP0 pid=338382) 	.loc	1 220 48                        // quant_slide_tuned_Llama3.2-1B.py:220:48
(EngineCore_DP0 pid=338382) 	min.xorsign.abs.f32 	%r84, %r109, %r108;
(EngineCore_DP0 pid=338382) 	.loc	1 220 60                        // quant_slide_tuned_Llama3.2-1B.py:220:60
(EngineCore_DP0 pid=338382) 	// begin inline asm
(EngineCore_DP0 pid=338382) 	cvt.rn.satfinite.e4m3x2.f32  %rs57, %r85, %r84; 
(EngineCore_DP0 pid=338382) 
(EngineCore_DP0 pid=338382) 	// end inline asm
(EngineCore_DP0 pid=338382) 	.loc	1 221 27                        // quant_slide_tuned_Llama3.2-1B.py:221:27
(EngineCore_DP0 pid=338382) 	mul.f32 	%r110, %r14, %r104;
(EngineCore_DP0 pid=338382) 	.loc	1 221 48                        // quant_slide_tuned_Llama3.2-1B.py:221:48
(EngineCore_DP0 pid=338382) 	min.xorsign.abs.f32 	%r86, %r110, %r108;
(EngineCore_DP0 pid=338382) 	.loc	1 221 60                        // quant_slide_tuned_Llama3.2-1B.py:221:60
(EngineCore_DP0 pid=338382) 	// begin inline asm
(EngineCore_DP0 pid=338382) 	cvt.rn.satfinite.e4m3x2.f32  %rs58, %r87, %r86; 
(EngineCore_DP0 pid=338382) 
(EngineCore_DP0 pid=338382) 	// end inline asm
(EngineCore_DP0 pid=338382) 	.loc	1 222 27                        // quant_slide_tuned_Llama3.2-1B.py:222:27
(EngineCore_DP0 pid=338382) 	mul.f32 	%r111, %r14, %r106;
(EngineCore_DP0 pid=338382) 	.loc	1 222 48                        // quant_slide_tuned_Llama3.2-1B.py:222:48
(EngineCore_DP0 pid=338382) 	min.xorsign.abs.f32 	%r88, %r111, %r108;
(EngineCore_DP0 pid=338382) 	.loc	1 222 60                        // quant_slide_tuned_Llama3.2-1B.py:222:60
(EngineCore_DP0 pid=338382) 	// begin inline asm
(EngineCore_DP0 pid=338382) 	cvt.rn.satfinite.e4m3x2.f32  %rs59, %r89, %r88; 
(EngineCore_DP0 pid=338382) 
(EngineCore_DP0 pid=338382) 	// end inline asm
(EngineCore_DP0 pid=338382) 	.loc	1 224 45                        // quant_slide_tuned_Llama3.2-1B.py:224:45
(EngineCore_DP0 pid=338382) 	cvt.u32.u16 	%r112, %rs56;
(EngineCore_DP0 pid=338382) 	and.b32 	%r113, %r112, 255;
(EngineCore_DP0 pid=338382) 	.loc	1 226 45                        // quant_slide_tuned_Llama3.2-1B.py:226:45
(EngineCore_DP0 pid=338382) 	cvt.u32.u16 	%r114, %rs58;
(EngineCore_DP0 pid=338382) 	and.b32 	%r115, %r114, 255;
(EngineCore_DP0 pid=338382) 	.loc	1 227 45                        // quant_slide_tuned_Llama3.2-1B.py:227:45
(EngineCore_DP0 pid=338382) 	cvt.u32.u16 	%r116, %rs59;
(EngineCore_DP0 pid=338382) 	.loc	1 229 30                        // quant_slide_tuned_Llama3.2-1B.py:229:30
(EngineCore_DP0 pid=338382) 	and.b16 	%rs60, %rs57, 255;
(EngineCore_DP0 pid=338382) 	mul.wide.u16 	%r117, %rs60, 256;
(EngineCore_DP0 pid=338382) 	.loc	1 229 24                        // quant_slide_tuned_Llama3.2-1B.py:229:24
(EngineCore_DP0 pid=338382) 	or.b32 	%r118, %r117, %r113;
(EngineCore_DP0 pid=338382) 	.loc	1 229 42                        // quant_slide_tuned_Llama3.2-1B.py:229:42
(EngineCore_DP0 pid=338382) 	shl.b32 	%r119, %r115, 16;
(EngineCore_DP0 pid=338382) 	.loc	1 229 36                        // quant_slide_tuned_Llama3.2-1B.py:229:36
(EngineCore_DP0 pid=338382) 	or.b32 	%r120, %r118, %r119;
(EngineCore_DP0 pid=338382) 	.loc	1 229 55                        // quant_slide_tuned_Llama3.2-1B.py:229:55
(EngineCore_DP0 pid=338382) 	shl.b32 	%r121, %r116, 24;
(EngineCore_DP0 pid=338382) 	.loc	1 229 49                        // quant_slide_tuned_Llama3.2-1B.py:229:49
(EngineCore_DP0 pid=338382) 	or.b32 	%r90, %r120, %r121;
(EngineCore_DP0 pid=338382) 	.loc	1 230 29                        // quant_slide_tuned_Llama3.2-1B.py:230:29
(EngineCore_DP0 pid=338382) 	mad.wide.s32 	%rd13, %r92, 4, %rd2;
(EngineCore_DP0 pid=338382) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-1B.py:230:39
(EngineCore_DP0 pid=338382) 	// begin inline asm
(EngineCore_DP0 pid=338382) 	@%p14 st.global.b32 [ %rd13 + 0 ], { %r90 };
(EngineCore_DP0 pid=338382) 	// end inline asm
(EngineCore_DP0 pid=338382) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=338382) 	add.s32 	%r125, %r125, 512;
(EngineCore_DP0 pid=338382) 	setp.lt.s32 	%p19, %r125, %r15;
(EngineCore_DP0 pid=338382) 	@%p19 bra 	$L__BB0_6;
(EngineCore_DP0 pid=338382) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=338382) 	.loc	1 201 4                         // quant_slide_tuned_Llama3.2-1B.py:201:4
(EngineCore_DP0 pid=338382) 	ret;
(EngineCore_DP0 pid=338382) $L__tmp3:
(EngineCore_DP0 pid=338382) $L__func_end0:
(EngineCore_DP0 pid=338382)                                         // -- End function
(EngineCore_DP0 pid=338382) }
(EngineCore_DP0 pid=338382) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=338382) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=338382) 	.section	.debug_abbrev
(EngineCore_DP0 pid=338382) 	{
(EngineCore_DP0 pid=338382) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=338382) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=338382) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=338382) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=338382) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=338382) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=338382) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=338382) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=338382) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=338382) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=338382) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=338382) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=338382) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=338382) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=338382) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=338382) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=338382) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=338382) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=338382) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=338382) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=338382) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=338382) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=338382) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=338382) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=338382) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=338382) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=338382) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=338382) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=338382) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=338382) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=338382) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=338382) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=338382) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=338382) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=338382) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=338382) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=338382) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=338382) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=338382) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=338382) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=338382) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=338382) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=338382) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=338382) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=338382) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=338382) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=338382) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=338382) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=338382) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=338382) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=338382) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=338382) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=338382) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=338382) 	}
(EngineCore_DP0 pid=338382) 	.section	.debug_info
(EngineCore_DP0 pid=338382) 	{
(EngineCore_DP0 pid=338382) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=338382) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=338382) .b8 0
(EngineCore_DP0 pid=338382) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=338382) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=338382) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=338382) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=338382) .b8 114
(EngineCore_DP0 pid=338382) .b8 105
(EngineCore_DP0 pid=338382) .b8 116
(EngineCore_DP0 pid=338382) .b8 111
(EngineCore_DP0 pid=338382) .b8 110
(EngineCore_DP0 pid=338382) .b8 0
(EngineCore_DP0 pid=338382) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=338382) .b8 0
(EngineCore_DP0 pid=338382) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=338382) .b8 117
(EngineCore_DP0 pid=338382) .b8 97
(EngineCore_DP0 pid=338382) .b8 110
(EngineCore_DP0 pid=338382) .b8 116
(EngineCore_DP0 pid=338382) .b8 95
(EngineCore_DP0 pid=338382) .b8 115
(EngineCore_DP0 pid=338382) .b8 108
(EngineCore_DP0 pid=338382) .b8 105
(EngineCore_DP0 pid=338382) .b8 100
(EngineCore_DP0 pid=338382) .b8 101
(EngineCore_DP0 pid=338382) .b8 95
(EngineCore_DP0 pid=338382) .b8 116
(EngineCore_DP0 pid=338382) .b8 117
(EngineCore_DP0 pid=338382) .b8 110
(EngineCore_DP0 pid=338382) .b8 101
(EngineCore_DP0 pid=338382) .b8 100
(EngineCore_DP0 pid=338382) .b8 95
(EngineCore_DP0 pid=338382) .b8 76
(EngineCore_DP0 pid=338382) .b8 108
(EngineCore_DP0 pid=338382) .b8 97
(EngineCore_DP0 pid=338382) .b8 109
(EngineCore_DP0 pid=338382) .b8 97
(EngineCore_DP0 pid=338382) .b8 51
(EngineCore_DP0 pid=338382) .b8 46
(EngineCore_DP0 pid=338382) .b8 50
(EngineCore_DP0 pid=338382) .b8 45
(EngineCore_DP0 pid=338382) .b8 49
(EngineCore_DP0 pid=338382) .b8 66
(EngineCore_DP0 pid=338382) .b8 46
(EngineCore_DP0 pid=338382) .b8 112
(EngineCore_DP0 pid=338382) .b8 121
(EngineCore_DP0 pid=338382) .b8 0
(EngineCore_DP0 pid=338382) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=338382) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=338382) .b8 114
(EngineCore_DP0 pid=338382) .b8 111
(EngineCore_DP0 pid=338382) .b8 111
(EngineCore_DP0 pid=338382) .b8 116
(EngineCore_DP0 pid=338382) .b8 47
(EngineCore_DP0 pid=338382) .b8 118
(EngineCore_DP0 pid=338382) .b8 108
(EngineCore_DP0 pid=338382) .b8 108
(EngineCore_DP0 pid=338382) .b8 109
(EngineCore_DP0 pid=338382) .b8 98
(EngineCore_DP0 pid=338382) .b8 101
(EngineCore_DP0 pid=338382) .b8 110
(EngineCore_DP0 pid=338382) .b8 99
(EngineCore_DP0 pid=338382) .b8 104
(EngineCore_DP0 pid=338382) .b8 47
(EngineCore_DP0 pid=338382) .b8 115
(EngineCore_DP0 pid=338382) .b8 108
(EngineCore_DP0 pid=338382) .b8 105
(EngineCore_DP0 pid=338382) .b8 100
(EngineCore_DP0 pid=338382) .b8 101
(EngineCore_DP0 pid=338382) .b8 115
(EngineCore_DP0 pid=338382) .b8 112
(EngineCore_DP0 pid=338382) .b8 97
(EngineCore_DP0 pid=338382) .b8 114
(EngineCore_DP0 pid=338382) .b8 115
(EngineCore_DP0 pid=338382) .b8 101
(EngineCore_DP0 pid=338382) .b8 47
(EngineCore_DP0 pid=338382) .b8 99
(EngineCore_DP0 pid=338382) .b8 115
(EngineCore_DP0 pid=338382) .b8 114
(EngineCore_DP0 pid=338382) .b8 99
(EngineCore_DP0 pid=338382) .b8 47
(EngineCore_DP0 pid=338382) .b8 102
(EngineCore_DP0 pid=338382) .b8 117
(EngineCore_DP0 pid=338382) .b8 115
(EngineCore_DP0 pid=338382) .b8 101
(EngineCore_DP0 pid=338382) .b8 100
(EngineCore_DP0 pid=338382) .b8 95
(EngineCore_DP0 pid=338382) .b8 113
(EngineCore_DP0 pid=338382) .b8 117
(EngineCore_DP0 pid=338382) .b8 97
(EngineCore_DP0 pid=338382) .b8 110
(EngineCore_DP0 pid=338382) .b8 116
(EngineCore_DP0 pid=338382) .b8 95
(EngineCore_DP0 pid=338382) .b8 115
(EngineCore_DP0 pid=338382) .b8 108
(EngineCore_DP0 pid=338382) .b8 105
(EngineCore_DP0 pid=338382) .b8 100
(EngineCore_DP0 pid=338382) .b8 101
(EngineCore_DP0 pid=338382) .b8 95
(EngineCore_DP0 pid=338382) .b8 116
(EngineCore_DP0 pid=338382) .b8 114
(EngineCore_DP0 pid=338382) .b8 105
(EngineCore_DP0 pid=338382) .b8 116
(EngineCore_DP0 pid=338382) .b8 111
(EngineCore_DP0 pid=338382) .b8 110
(EngineCore_DP0 pid=338382) .b8 47
(EngineCore_DP0 pid=338382) .b8 98
(EngineCore_DP0 pid=338382) .b8 117
(EngineCore_DP0 pid=338382) .b8 105
(EngineCore_DP0 pid=338382) .b8 108
(EngineCore_DP0 pid=338382) .b8 100
(EngineCore_DP0 pid=338382) .b8 47
(EngineCore_DP0 pid=338382) .b8 71
(EngineCore_DP0 pid=338382) .b8 66
(EngineCore_DP0 pid=338382) .b8 49
(EngineCore_DP0 pid=338382) .b8 48
(EngineCore_DP0 pid=338382) .b8 95
(EngineCore_DP0 pid=338382) .b8 99
(EngineCore_DP0 pid=338382) .b8 99
(EngineCore_DP0 pid=338382) .b8 49
(EngineCore_DP0 pid=338382) .b8 50
(EngineCore_DP0 pid=338382) .b8 49
(EngineCore_DP0 pid=338382) .b8 95
(EngineCore_DP0 pid=338382) .b8 112
(EngineCore_DP0 pid=338382) .b8 121
(EngineCore_DP0 pid=338382) .b8 51
(EngineCore_DP0 pid=338382) .b8 49
(EngineCore_DP0 pid=338382) .b8 50
(EngineCore_DP0 pid=338382) .b8 95
(EngineCore_DP0 pid=338382) .b8 99
(EngineCore_DP0 pid=338382) .b8 117
(EngineCore_DP0 pid=338382) .b8 49
(EngineCore_DP0 pid=338382) .b8 50
(EngineCore_DP0 pid=338382) .b8 57
(EngineCore_DP0 pid=338382) .b8 95
(EngineCore_DP0 pid=338382) .b8 97
(EngineCore_DP0 pid=338382) .b8 97
(EngineCore_DP0 pid=338382) .b8 114
(EngineCore_DP0 pid=338382) .b8 99
(EngineCore_DP0 pid=338382) .b8 104
(EngineCore_DP0 pid=338382) .b8 54
(EngineCore_DP0 pid=338382) .b8 52
(EngineCore_DP0 pid=338382) .b8 0
(EngineCore_DP0 pid=338382) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=338382) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=338382) .b8 113
(EngineCore_DP0 pid=338382) .b8 117
(EngineCore_DP0 pid=338382) .b8 97
(EngineCore_DP0 pid=338382) .b8 110
(EngineCore_DP0 pid=338382) .b8 116
(EngineCore_DP0 pid=338382) .b8 95
(EngineCore_DP0 pid=338382) .b8 115
(EngineCore_DP0 pid=338382) .b8 108
(EngineCore_DP0 pid=338382) .b8 105
(EngineCore_DP0 pid=338382) .b8 100
(EngineCore_DP0 pid=338382) .b8 101
(EngineCore_DP0 pid=338382) .b8 95
(EngineCore_DP0 pid=338382) .b8 102
(EngineCore_DP0 pid=338382) .b8 112
(EngineCore_DP0 pid=338382) .b8 56
(EngineCore_DP0 pid=338382) .b8 95
(EngineCore_DP0 pid=338382) .b8 107
(EngineCore_DP0 pid=338382) .b8 101
(EngineCore_DP0 pid=338382) .b8 114
(EngineCore_DP0 pid=338382) .b8 110
(EngineCore_DP0 pid=338382) .b8 101
(EngineCore_DP0 pid=338382) .b8 108
(EngineCore_DP0 pid=338382) .b8 0
(EngineCore_DP0 pid=338382) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=338382) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=338382) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=338382) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=338382) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=338382) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=338382) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=338382) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=338382) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=338382) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=338382) .b8 191                                 // DW_AT_call_line
(EngineCore_DP0 pid=338382) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=338382) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=338382) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=338382) 	}
(EngineCore_DP0 pid=338382) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=338382) 
(EngineCore_DP0 pid=338382) ================================================================
(EngineCore_DP0 pid=338382) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=338382) 
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpa5f7fejv.ptx', '-o', '/tmp/tmpa5f7fejv.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866] 
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866] 
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866] 
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpa5f7fejv.ptx -o /tmp/tmpa5f7fejv.ptx.o
(EngineCore_DP0 pid=338382) ERROR 01-25 19:17:33 [core.py:866] 

STDERR:
[2026-01-25 19:17:18] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:17:18] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:17:18] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:17:18] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:17:18] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:17:18] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:17:18] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:17:18] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:17:18] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:17:18] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:17:18] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:17:18] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:17:18] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:17:18] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:17:22] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:17:22] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:17:22] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:17:22] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:17:22] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:17:22] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:17:22] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:17:22] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:17:22] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:17:22] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:17:22] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:17:22] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:17:22] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:17:22] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=338382) [2026-01-25 19:17:23] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=338382) [2026-01-25 19:17:23] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=338382) [2026-01-25 19:17:23] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=338382) [2026-01-25 19:17:23] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=338382) [2026-01-25 19:17:23] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=338382) [2026-01-25 19:17:23] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=338382) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=338382) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.30s/it]
(EngineCore_DP0 pid=338382) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.30s/it]
(EngineCore_DP0 pid=338382) 
(EngineCore_DP0 pid=338382) [2026-01-25 19:17:32] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=338382) [2026-01-25 19:17:32] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5308416 bytes
(EngineCore_DP0 pid=338382) [2026-01-25 19:17:32] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=338382) [2026-01-25 19:17:32] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3538944 bytes
(EngineCore_DP0 pid=338382) [2026-01-25 19:17:32] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=338382) [2026-01-25 19:17:32] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 28311552 bytes
(EngineCore_DP0 pid=338382) [2026-01-25 19:17:32] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=338382) [2026-01-25 19:17:32] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14024704 bytes
(EngineCore_DP0 pid=338382) Process EngineCore_DP0:
(EngineCore_DP0 pid=338382) Traceback (most recent call last):
(EngineCore_DP0 pid=338382)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=338382)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=338382)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=338382)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=338382) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpa5f7fejv.ptx', '-o', '/tmp/tmpa5f7fejv.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=338382) 
(EngineCore_DP0 pid=338382) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=338382) 
(EngineCore_DP0 pid=338382) Traceback (most recent call last):
(EngineCore_DP0 pid=338382)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=338382)     self.run()
(EngineCore_DP0 pid=338382)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=338382)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=338382)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=338382)     raise e
(EngineCore_DP0 pid=338382)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=338382)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=338382)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=338382)     super().__init__(
(EngineCore_DP0 pid=338382)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=338382)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=338382)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=338382)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=338382)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=338382)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=338382)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=338382)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=338382)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=338382)     return func(*args, **kwargs)
(EngineCore_DP0 pid=338382)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=338382)     return func(*args, **kwargs)
(EngineCore_DP0 pid=338382)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=338382)     self.model_runner.profile_run()
(EngineCore_DP0 pid=338382)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=338382)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=338382)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=338382)     return func(*args, **kwargs)
(EngineCore_DP0 pid=338382)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=338382)     outputs = self.model(
(EngineCore_DP0 pid=338382)               ^^^^^^^^^^^
(EngineCore_DP0 pid=338382)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=338382)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=338382)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=338382)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=338382)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=338382)     model_output = self.model(
(EngineCore_DP0 pid=338382)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=338382)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=338382)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=338382)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=338382)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=338382)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=338382)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=338382)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=338382)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=338382)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=338382)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=338382)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=338382)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=338382)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=338382)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=338382)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=338382)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=338382)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=338382)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=338382)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=338382)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=338382)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=338382)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=338382)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=338382)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=338382)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=338382)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=338382)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=338382)     return self._linear_fn(
(EngineCore_DP0 pid=338382)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=338382)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=338382)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=338382)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=338382)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=338382)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=338382)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=338382)     return fn(input, L)
(EngineCore_DP0 pid=338382)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=338382)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=338382)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=338382)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=338382)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=338382)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=338382)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=338382)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=338382)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=338382)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=338382)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=338382)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=338382)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=338382)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338382)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=338382)     raise PTXASError(error)
(EngineCore_DP0 pid=338382) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=338382) `ptxas` stderr:
(EngineCore_DP0 pid=338382) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=338382) 
(EngineCore_DP0 pid=338382) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpa5f7fejv.ptx -o /tmp/tmpa5f7fejv.ptx.o
(EngineCore_DP0 pid=338382) 
[rank0]:[W125 19:17:34.221855843 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=2048

========== M=4096 ==========
Time: 2026-01-25 19:17:35
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-FP8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:17:40 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:17:40 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=338867) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=338867) 
(EngineCore_DP0 pid=338867) 
(EngineCore_DP0 pid=338867) ================================================================
(EngineCore_DP0 pid=338867) Internal Triton PTX codegen error
(EngineCore_DP0 pid=338867) `ptxas` stderr:
(EngineCore_DP0 pid=338867) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=338867) 
(EngineCore_DP0 pid=338867) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpox1_0p11.ptx -o /tmp/tmpox1_0p11.ptx.o
(EngineCore_DP0 pid=338867) 
(EngineCore_DP0 pid=338867) 
(EngineCore_DP0 pid=338867) //
(EngineCore_DP0 pid=338867) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=338867) //
(EngineCore_DP0 pid=338867) 
(EngineCore_DP0 pid=338867) .version 8.7
(EngineCore_DP0 pid=338867) .target sm_121a
(EngineCore_DP0 pid=338867) .address_size 64
(EngineCore_DP0 pid=338867) 
(EngineCore_DP0 pid=338867) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=338867) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=338867)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=338867) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=338867) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=338867) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=338867) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=338867) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=338867) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=338867) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=338867) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=338867) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=338867) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=338867) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=338867) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=338867) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=338867) )
(EngineCore_DP0 pid=338867) .reqntid 512
(EngineCore_DP0 pid=338867) {
(EngineCore_DP0 pid=338867) 	.reg .pred 	%p<21>;
(EngineCore_DP0 pid=338867) 	.reg .b16 	%rs<61>;
(EngineCore_DP0 pid=338867) 	.reg .b32 	%r<126>;
(EngineCore_DP0 pid=338867) 	.reg .b64 	%rd<14>;
(EngineCore_DP0 pid=338867) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=338867) $L__func_begin0:
(EngineCore_DP0 pid=338867) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=338867) 
(EngineCore_DP0 pid=338867) // %bb.0:
(EngineCore_DP0 pid=338867) 	ld.param.b32 	%r20, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=338867) 	ld.param.b32 	%r19, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=338867) 	ld.param.b32 	%r18, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=338867) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=338867) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=338867) $L__tmp0:
(EngineCore_DP0 pid=338867) 	.loc	1 177 24                        // quant_slide_tuned_Llama3.2-1B.py:177:24
(EngineCore_DP0 pid=338867) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=338867) 	ld.param.b32 	%r22, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=338867) 	.loc	1 182 26                        // quant_slide_tuned_Llama3.2-1B.py:182:26
(EngineCore_DP0 pid=338867) 	mul.lo.s32 	%r23, %r22, %r1;
(EngineCore_DP0 pid=338867) 	.loc	1 182 20                        // quant_slide_tuned_Llama3.2-1B.py:182:20
(EngineCore_DP0 pid=338867) 	mad.wide.s32 	%rd1, %r23, 2, %rd4;
(EngineCore_DP0 pid=338867) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=338867) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=338867) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=338867) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=338867) 	setp.lt.s32 	%p1, %r19, 1;
(EngineCore_DP0 pid=338867) 	mov.b32 	%r124, 0f2B8CBCCC;
(EngineCore_DP0 pid=338867) 	setp.eq.b32 	%p20, %r2, 0;
(EngineCore_DP0 pid=338867) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=338867) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=338867) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=338867) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=338867) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=338867) 	shr.u32 	%r32, %r2, 3;
(EngineCore_DP0 pid=338867) 	and.b32 	%r33, %r32, 60;
(EngineCore_DP0 pid=338867) 	mov.b32 	%r34, global_smem;
(EngineCore_DP0 pid=338867) 	add.s32 	%r52, %r34, %r33;
(EngineCore_DP0 pid=338867) 	shl.b32 	%r35, %r2, 2;
(EngineCore_DP0 pid=338867) 	add.s32 	%r55, %r34, %r35;
(EngineCore_DP0 pid=338867) 	mov.b32 	%r40, 0;
(EngineCore_DP0 pid=338867) 	mov.b32 	%r122, 0f00000000;
(EngineCore_DP0 pid=338867) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=338867) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=338867) 	mov.b32 	%r123, %r40;
(EngineCore_DP0 pid=338867) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=338867) 	.loc	1 188 19                        // quant_slide_tuned_Llama3.2-1B.py:188:19
(EngineCore_DP0 pid=338867) 	add.s32 	%r58, %r4, %r123;
(EngineCore_DP0 pid=338867) 	.loc	1 189 22                        // quant_slide_tuned_Llama3.2-1B.py:189:22
(EngineCore_DP0 pid=338867) 	add.s32 	%r59, %r58, 4096;
(EngineCore_DP0 pid=338867) 	setp.lt.s32 	%p2, %r58, %r18;
(EngineCore_DP0 pid=338867) 	setp.lt.s32 	%p3, %r59, %r18;
(EngineCore_DP0 pid=338867) 	.loc	1 190 29                        // quant_slide_tuned_Llama3.2-1B.py:190:29
(EngineCore_DP0 pid=338867) 	mad.wide.s32 	%rd6, %r58, 2, %rd1;
(EngineCore_DP0 pid=338867) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=338867) 	.loc	1 190 21                        // quant_slide_tuned_Llama3.2-1B.py:190:21
(EngineCore_DP0 pid=338867) 	// begin inline asm
(EngineCore_DP0 pid=338867) 	mov.u32 %r36, %r40;
(EngineCore_DP0 pid=338867) 	mov.u32 %r37, %r40;
(EngineCore_DP0 pid=338867) 	mov.u32 %r38, %r40;
(EngineCore_DP0 pid=338867) 	mov.u32 %r39, %r40;
(EngineCore_DP0 pid=338867) 	@%p2 ld.global.v4.b32 { %r36, %r37, %r38, %r39 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=338867) 	// end inline asm
(EngineCore_DP0 pid=338867) 	mov.b32 	{%rs1, %rs2}, %r36;
(EngineCore_DP0 pid=338867) 	mov.b32 	{%rs3, %rs4}, %r37;
(EngineCore_DP0 pid=338867) 	mov.b32 	{%rs5, %rs6}, %r38;
(EngineCore_DP0 pid=338867) 	mov.b32 	{%rs7, %rs8}, %r39;
(EngineCore_DP0 pid=338867) 	// begin inline asm
(EngineCore_DP0 pid=338867) 	mov.u32 %r44, %r40;
(EngineCore_DP0 pid=338867) 	mov.u32 %r45, %r40;
(EngineCore_DP0 pid=338867) 	mov.u32 %r46, %r40;
(EngineCore_DP0 pid=338867) 	mov.u32 %r47, %r40;
(EngineCore_DP0 pid=338867) 	@%p3 ld.global.v4.b32 { %r44, %r45, %r46, %r47 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=338867) 	// end inline asm
(EngineCore_DP0 pid=338867) 	mov.b32 	{%rs9, %rs10}, %r44;
(EngineCore_DP0 pid=338867) 	mov.b32 	{%rs11, %rs12}, %r45;
(EngineCore_DP0 pid=338867) 	mov.b32 	{%rs13, %rs14}, %r46;
(EngineCore_DP0 pid=338867) 	mov.b32 	{%rs15, %rs16}, %r47;
(EngineCore_DP0 pid=338867) 	.loc	1 191 50                        // quant_slide_tuned_Llama3.2-1B.py:191:50
(EngineCore_DP0 pid=338867) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=338867) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=338867) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=338867) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=338867) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=338867) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=338867) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=338867) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=338867) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=338867) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=338867) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=338867) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=338867) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=338867) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=338867) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=338867) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=338867) $L__tmp1:
(EngineCore_DP0 pid=338867) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=338867) 	bar.sync 	0;
(EngineCore_DP0 pid=338867) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=338867) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=338867) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=338867) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=338867) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=338867) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=338867) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=338867) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=338867) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=338867) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=338867) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=338867) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=338867) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=338867) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=338867) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=338867) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=338867) 	cvt.f32.bf16 	%r60, %rs47;
(EngineCore_DP0 pid=338867) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=338867) 	shfl.sync.bfly.b32 	%r61, %r60, 16, 31, -1;
(EngineCore_DP0 pid=338867) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=338867) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=338867) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=338867) 	shfl.sync.bfly.b32 	%r63, %r62, 8, 31, -1;
(EngineCore_DP0 pid=338867) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=338867) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=338867) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=338867) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=338867) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=338867) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=338867) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=338867) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=338867) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=338867) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=338867) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=338867) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=338867) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=338867) 	max.f32 	%r53, %r68, %r69;
(EngineCore_DP0 pid=338867) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=338867) 	// begin inline asm
(EngineCore_DP0 pid=338867) 	@%p4 st.shared.b32 [ %r52 + 0 ], %r53;
(EngineCore_DP0 pid=338867) 	// end inline asm
(EngineCore_DP0 pid=338867) 	bar.sync 	0;
(EngineCore_DP0 pid=338867) 	// begin inline asm
(EngineCore_DP0 pid=338867) 	@%p5 ld.shared.b32 %r54, [ %r55 + 0 ];
(EngineCore_DP0 pid=338867) 	// end inline asm
(EngineCore_DP0 pid=338867) 	shfl.sync.bfly.b32 	%r70, %r54, 8, 31, -1;
(EngineCore_DP0 pid=338867) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=338867) 	max.f32 	%r71, %r54, %r70;
(EngineCore_DP0 pid=338867) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=338867) 	shfl.sync.bfly.b32 	%r72, %r71, 4, 31, -1;
(EngineCore_DP0 pid=338867) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=338867) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=338867) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=338867) 	shfl.sync.bfly.b32 	%r74, %r73, 2, 31, -1;
(EngineCore_DP0 pid=338867) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=338867) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=338867) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=338867) 	shfl.sync.bfly.b32 	%r76, %r75, 1, 31, -1;
(EngineCore_DP0 pid=338867) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=338867) 	max.f32 	%r57, %r75, %r76;
(EngineCore_DP0 pid=338867) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=338867) 	// begin inline asm
(EngineCore_DP0 pid=338867) 	@%p20 st.shared.b32 [ %r55 + 0 ], %r57;
(EngineCore_DP0 pid=338867) 	// end inline asm
(EngineCore_DP0 pid=338867) 	bar.sync 	0;
(EngineCore_DP0 pid=338867) 	ld.shared.b32 	%r77, [global_smem];
(EngineCore_DP0 pid=338867) $L__tmp2:
(EngineCore_DP0 pid=338867) 	.loc	1 191 36                        // quant_slide_tuned_Llama3.2-1B.py:191:36
(EngineCore_DP0 pid=338867) 	max.f32 	%r122, %r122, %r77;
(EngineCore_DP0 pid=338867) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=338867) 	add.s32 	%r123, %r123, 8192;
(EngineCore_DP0 pid=338867) 	setp.lt.s32 	%p7, %r123, %r19;
(EngineCore_DP0 pid=338867) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=338867) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=338867) 	.loc	1 193 32                        // quant_slide_tuned_Llama3.2-1B.py:193:32
(EngineCore_DP0 pid=338867) 	max.f32 	%r124, %r122, 0f2B8CBCCC;
(EngineCore_DP0 pid=338867) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=338867) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=338867) 	mov.b32 	%r79, 0f43E00000;
(EngineCore_DP0 pid=338867) 	.loc	1 194 32                        // quant_slide_tuned_Llama3.2-1B.py:194:32
(EngineCore_DP0 pid=338867) 	div.full.f32 	%r80, %r124, %r79;
(EngineCore_DP0 pid=338867) 	.loc	1 194 41                        // quant_slide_tuned_Llama3.2-1B.py:194:41
(EngineCore_DP0 pid=338867) 	max.f32 	%r78, %r80, 0f36924925;
(EngineCore_DP0 pid=338867) 	.loc	1 196 25                        // quant_slide_tuned_Llama3.2-1B.py:196:25
(EngineCore_DP0 pid=338867) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=338867) 	.loc	1 196 30                        // quant_slide_tuned_Llama3.2-1B.py:196:30
(EngineCore_DP0 pid=338867) 	// begin inline asm
(EngineCore_DP0 pid=338867) 	@%p20 st.global.b32 [ %rd8 + 0 ], { %r78 };
(EngineCore_DP0 pid=338867) 	// end inline asm
(EngineCore_DP0 pid=338867) 	.loc	1 199 29                        // quant_slide_tuned_Llama3.2-1B.py:199:29
(EngineCore_DP0 pid=338867) 	shl.b32 	%r15, %r20, 1;
(EngineCore_DP0 pid=338867) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=338867) 	setp.lt.s32 	%p9, %r15, 1;
(EngineCore_DP0 pid=338867) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=338867) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=338867) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=338867) 	ld.param.b32 	%r24, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=338867) 	shr.s32 	%r25, %r24, 31;
(EngineCore_DP0 pid=338867) 	shr.u32 	%r26, %r25, 30;
(EngineCore_DP0 pid=338867) 	add.s32 	%r27, %r24, %r26;
(EngineCore_DP0 pid=338867) 	shr.s32 	%r28, %r27, 2;
(EngineCore_DP0 pid=338867) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=338867) 	mul.lo.s32 	%r29, %r28, %r1;
(EngineCore_DP0 pid=338867) 	mad.wide.s32 	%rd2, %r29, 4, %rd5;
(EngineCore_DP0 pid=338867) 	div.full.f32 	%r14, %r79, %r124;
(EngineCore_DP0 pid=338867) 	mov.b32 	%r125, 0;
(EngineCore_DP0 pid=338867) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=338867)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=338867) 	.loc	1 203 30                        // quant_slide_tuned_Llama3.2-1B.py:203:30
(EngineCore_DP0 pid=338867) 	add.s32 	%r92, %r3, %r125;
(EngineCore_DP0 pid=338867) 	setp.lt.s32 	%p14, %r92, %r15;
(EngineCore_DP0 pid=338867) 	.loc	1 206 24                        // quant_slide_tuned_Llama3.2-1B.py:206:24
(EngineCore_DP0 pid=338867) 	shr.u32 	%r93, %r92, 31;
(EngineCore_DP0 pid=338867) 	add.s32 	%r94, %r92, %r93;
(EngineCore_DP0 pid=338867) 	shr.u32 	%r95, %r94, 1;
(EngineCore_DP0 pid=338867) 	.loc	1 207 23                        // quant_slide_tuned_Llama3.2-1B.py:207:23
(EngineCore_DP0 pid=338867) 	and.b32 	%r96, %r94, 2147483646;
(EngineCore_DP0 pid=338867) 	sub.s32 	%r97, %r92, %r96;
(EngineCore_DP0 pid=338867) 	.loc	1 208 30                        // quant_slide_tuned_Llama3.2-1B.py:208:30
(EngineCore_DP0 pid=338867) 	shl.b32 	%r98, %r97, 1;
(EngineCore_DP0 pid=338867) 	.loc	1 208 26                        // quant_slide_tuned_Llama3.2-1B.py:208:26
(EngineCore_DP0 pid=338867) 	mad.lo.s32 	%r99, %r95, 6, %r98;
(EngineCore_DP0 pid=338867) 	.loc	1 211 53                        // quant_slide_tuned_Llama3.2-1B.py:211:53
(EngineCore_DP0 pid=338867) 	setp.lt.s32 	%p15, %r99, %r18;
(EngineCore_DP0 pid=338867) 	.loc	1 211 37                        // quant_slide_tuned_Llama3.2-1B.py:211:37
(EngineCore_DP0 pid=338867) 	and.pred 	%p10, %p14, %p15;
(EngineCore_DP0 pid=338867) 	.loc	1 210 29                        // quant_slide_tuned_Llama3.2-1B.py:210:29
(EngineCore_DP0 pid=338867) 	mad.wide.s32 	%rd9, %r99, 2, %rd1;
(EngineCore_DP0 pid=338867) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=338867) 	.loc	1 210 21                        // quant_slide_tuned_Llama3.2-1B.py:210:21
(EngineCore_DP0 pid=338867) 	// begin inline asm
(EngineCore_DP0 pid=338867) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=338867) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=338867) 	// end inline asm
(EngineCore_DP0 pid=338867) 	.loc	1 211 79                        // quant_slide_tuned_Llama3.2-1B.py:211:79
(EngineCore_DP0 pid=338867) 	cvt.f32.bf16 	%r100, %rs48;
(EngineCore_DP0 pid=338867) 	.loc	1 213 48                        // quant_slide_tuned_Llama3.2-1B.py:213:48
(EngineCore_DP0 pid=338867) 	or.b32 	%r101, %r99, 1;
(EngineCore_DP0 pid=338867) 	.loc	1 213 53                        // quant_slide_tuned_Llama3.2-1B.py:213:53
(EngineCore_DP0 pid=338867) 	setp.lt.s32 	%p16, %r101, %r18;
(EngineCore_DP0 pid=338867) 	.loc	1 213 37                        // quant_slide_tuned_Llama3.2-1B.py:213:37
(EngineCore_DP0 pid=338867) 	and.pred 	%p11, %p14, %p16;
(EngineCore_DP0 pid=338867) 	.loc	1 212 39                        // quant_slide_tuned_Llama3.2-1B.py:212:39
(EngineCore_DP0 pid=338867) 	add.s64 	%rd10, %rd9, 2;
(EngineCore_DP0 pid=338867) 	.loc	1 212 21                        // quant_slide_tuned_Llama3.2-1B.py:212:21
(EngineCore_DP0 pid=338867) 	// begin inline asm
(EngineCore_DP0 pid=338867) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=338867) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=338867) 	// end inline asm
(EngineCore_DP0 pid=338867) 	.loc	1 213 79                        // quant_slide_tuned_Llama3.2-1B.py:213:79
(EngineCore_DP0 pid=338867) 	cvt.f32.bf16 	%r102, %rs50;
(EngineCore_DP0 pid=338867) 	.loc	1 215 48                        // quant_slide_tuned_Llama3.2-1B.py:215:48
(EngineCore_DP0 pid=338867) 	add.s32 	%r103, %r99, 2;
(EngineCore_DP0 pid=338867) 	.loc	1 215 53                        // quant_slide_tuned_Llama3.2-1B.py:215:53
(EngineCore_DP0 pid=338867) 	setp.lt.s32 	%p17, %r103, %r18;
(EngineCore_DP0 pid=338867) 	.loc	1 215 37                        // quant_slide_tuned_Llama3.2-1B.py:215:37
(EngineCore_DP0 pid=338867) 	and.pred 	%p12, %p14, %p17;
(EngineCore_DP0 pid=338867) 	.loc	1 214 39                        // quant_slide_tuned_Llama3.2-1B.py:214:39
(EngineCore_DP0 pid=338867) 	add.s64 	%rd11, %rd9, 4;
(EngineCore_DP0 pid=338867) 	.loc	1 214 21                        // quant_slide_tuned_Llama3.2-1B.py:214:21
(EngineCore_DP0 pid=338867) 	// begin inline asm
(EngineCore_DP0 pid=338867) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=338867) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=338867) 	// end inline asm
(EngineCore_DP0 pid=338867) 	.loc	1 215 79                        // quant_slide_tuned_Llama3.2-1B.py:215:79
(EngineCore_DP0 pid=338867) 	cvt.f32.bf16 	%r104, %rs52;
(EngineCore_DP0 pid=338867) 	.loc	1 217 48                        // quant_slide_tuned_Llama3.2-1B.py:217:48
(EngineCore_DP0 pid=338867) 	add.s32 	%r105, %r99, 3;
(EngineCore_DP0 pid=338867) 	.loc	1 217 53                        // quant_slide_tuned_Llama3.2-1B.py:217:53
(EngineCore_DP0 pid=338867) 	setp.lt.s32 	%p18, %r105, %r18;
(EngineCore_DP0 pid=338867) 	.loc	1 217 37                        // quant_slide_tuned_Llama3.2-1B.py:217:37
(EngineCore_DP0 pid=338867) 	and.pred 	%p13, %p14, %p18;
(EngineCore_DP0 pid=338867) 	.loc	1 216 39                        // quant_slide_tuned_Llama3.2-1B.py:216:39
(EngineCore_DP0 pid=338867) 	add.s64 	%rd12, %rd9, 6;
(EngineCore_DP0 pid=338867) 	.loc	1 216 21                        // quant_slide_tuned_Llama3.2-1B.py:216:21
(EngineCore_DP0 pid=338867) 	// begin inline asm
(EngineCore_DP0 pid=338867) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=338867) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=338867) 	// end inline asm
(EngineCore_DP0 pid=338867) 	.loc	1 217 79                        // quant_slide_tuned_Llama3.2-1B.py:217:79
(EngineCore_DP0 pid=338867) 	cvt.f32.bf16 	%r106, %rs54;
(EngineCore_DP0 pid=338867) 	.loc	1 219 27                        // quant_slide_tuned_Llama3.2-1B.py:219:27
(EngineCore_DP0 pid=338867) 	mul.f32 	%r107, %r14, %r100;
(EngineCore_DP0 pid=338867) 	mov.b32 	%r108, 0f43E00000;
(EngineCore_DP0 pid=338867) 	.loc	1 219 48                        // quant_slide_tuned_Llama3.2-1B.py:219:48
(EngineCore_DP0 pid=338867) 	min.xorsign.abs.f32 	%r82, %r107, %r108;
(EngineCore_DP0 pid=338867) 	.loc	1 219 60                        // quant_slide_tuned_Llama3.2-1B.py:219:60
(EngineCore_DP0 pid=338867) 	// begin inline asm
(EngineCore_DP0 pid=338867) 	cvt.rn.satfinite.e4m3x2.f32  %rs56, %r83, %r82; 
(EngineCore_DP0 pid=338867) 
(EngineCore_DP0 pid=338867) 	// end inline asm
(EngineCore_DP0 pid=338867) 	.loc	1 220 27                        // quant_slide_tuned_Llama3.2-1B.py:220:27
(EngineCore_DP0 pid=338867) 	mul.f32 	%r109, %r14, %r102;
(EngineCore_DP0 pid=338867) 	.loc	1 220 48                        // quant_slide_tuned_Llama3.2-1B.py:220:48
(EngineCore_DP0 pid=338867) 	min.xorsign.abs.f32 	%r84, %r109, %r108;
(EngineCore_DP0 pid=338867) 	.loc	1 220 60                        // quant_slide_tuned_Llama3.2-1B.py:220:60
(EngineCore_DP0 pid=338867) 	// begin inline asm
(EngineCore_DP0 pid=338867) 	cvt.rn.satfinite.e4m3x2.f32  %rs57, %r85, %r84; 
(EngineCore_DP0 pid=338867) 
(EngineCore_DP0 pid=338867) 	// end inline asm
(EngineCore_DP0 pid=338867) 	.loc	1 221 27                        // quant_slide_tuned_Llama3.2-1B.py:221:27
(EngineCore_DP0 pid=338867) 	mul.f32 	%r110, %r14, %r104;
(EngineCore_DP0 pid=338867) 	.loc	1 221 48                        // quant_slide_tuned_Llama3.2-1B.py:221:48
(EngineCore_DP0 pid=338867) 	min.xorsign.abs.f32 	%r86, %r110, %r108;
(EngineCore_DP0 pid=338867) 	.loc	1 221 60                        // quant_slide_tuned_Llama3.2-1B.py:221:60
(EngineCore_DP0 pid=338867) 	// begin inline asm
(EngineCore_DP0 pid=338867) 	cvt.rn.satfinite.e4m3x2.f32  %rs58, %r87, %r86; 
(EngineCore_DP0 pid=338867) 
(EngineCore_DP0 pid=338867) 	// end inline asm
(EngineCore_DP0 pid=338867) 	.loc	1 222 27                        // quant_slide_tuned_Llama3.2-1B.py:222:27
(EngineCore_DP0 pid=338867) 	mul.f32 	%r111, %r14, %r106;
(EngineCore_DP0 pid=338867) 	.loc	1 222 48                        // quant_slide_tuned_Llama3.2-1B.py:222:48
(EngineCore_DP0 pid=338867) 	min.xorsign.abs.f32 	%r88, %r111, %r108;
(EngineCore_DP0 pid=338867) 	.loc	1 222 60                        // quant_slide_tuned_Llama3.2-1B.py:222:60
(EngineCore_DP0 pid=338867) 	// begin inline asm
(EngineCore_DP0 pid=338867) 	cvt.rn.satfinite.e4m3x2.f32  %rs59, %r89, %r88; 
(EngineCore_DP0 pid=338867) 
(EngineCore_DP0 pid=338867) 	// end inline asm
(EngineCore_DP0 pid=338867) 	.loc	1 224 45                        // quant_slide_tuned_Llama3.2-1B.py:224:45
(EngineCore_DP0 pid=338867) 	cvt.u32.u16 	%r112, %rs56;
(EngineCore_DP0 pid=338867) 	and.b32 	%r113, %r112, 255;
(EngineCore_DP0 pid=338867) 	.loc	1 226 45                        // quant_slide_tuned_Llama3.2-1B.py:226:45
(EngineCore_DP0 pid=338867) 	cvt.u32.u16 	%r114, %rs58;
(EngineCore_DP0 pid=338867) 	and.b32 	%r115, %r114, 255;
(EngineCore_DP0 pid=338867) 	.loc	1 227 45                        // quant_slide_tuned_Llama3.2-1B.py:227:45
(EngineCore_DP0 pid=338867) 	cvt.u32.u16 	%r116, %rs59;
(EngineCore_DP0 pid=338867) 	.loc	1 229 30                        // quant_slide_tuned_Llama3.2-1B.py:229:30
(EngineCore_DP0 pid=338867) 	and.b16 	%rs60, %rs57, 255;
(EngineCore_DP0 pid=338867) 	mul.wide.u16 	%r117, %rs60, 256;
(EngineCore_DP0 pid=338867) 	.loc	1 229 24                        // quant_slide_tuned_Llama3.2-1B.py:229:24
(EngineCore_DP0 pid=338867) 	or.b32 	%r118, %r117, %r113;
(EngineCore_DP0 pid=338867) 	.loc	1 229 42                        // quant_slide_tuned_Llama3.2-1B.py:229:42
(EngineCore_DP0 pid=338867) 	shl.b32 	%r119, %r115, 16;
(EngineCore_DP0 pid=338867) 	.loc	1 229 36                        // quant_slide_tuned_Llama3.2-1B.py:229:36
(EngineCore_DP0 pid=338867) 	or.b32 	%r120, %r118, %r119;
(EngineCore_DP0 pid=338867) 	.loc	1 229 55                        // quant_slide_tuned_Llama3.2-1B.py:229:55
(EngineCore_DP0 pid=338867) 	shl.b32 	%r121, %r116, 24;
(EngineCore_DP0 pid=338867) 	.loc	1 229 49                        // quant_slide_tuned_Llama3.2-1B.py:229:49
(EngineCore_DP0 pid=338867) 	or.b32 	%r90, %r120, %r121;
(EngineCore_DP0 pid=338867) 	.loc	1 230 29                        // quant_slide_tuned_Llama3.2-1B.py:230:29
(EngineCore_DP0 pid=338867) 	mad.wide.s32 	%rd13, %r92, 4, %rd2;
(EngineCore_DP0 pid=338867) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-1B.py:230:39
(EngineCore_DP0 pid=338867) 	// begin inline asm
(EngineCore_DP0 pid=338867) 	@%p14 st.global.b32 [ %rd13 + 0 ], { %r90 };
(EngineCore_DP0 pid=338867) 	// end inline asm
(EngineCore_DP0 pid=338867) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=338867) 	add.s32 	%r125, %r125, 512;
(EngineCore_DP0 pid=338867) 	setp.lt.s32 	%p19, %r125, %r15;
(EngineCore_DP0 pid=338867) 	@%p19 bra 	$L__BB0_6;
(EngineCore_DP0 pid=338867) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=338867) 	.loc	1 201 4                         // quant_slide_tuned_Llama3.2-1B.py:201:4
(EngineCore_DP0 pid=338867) 	ret;
(EngineCore_DP0 pid=338867) $L__tmp3:
(EngineCore_DP0 pid=338867) $L__func_end0:
(EngineCore_DP0 pid=338867)                                         // -- End function
(EngineCore_DP0 pid=338867) }
(EngineCore_DP0 pid=338867) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=338867) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=338867) 	.section	.debug_abbrev
(EngineCore_DP0 pid=338867) 	{
(EngineCore_DP0 pid=338867) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=338867) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=338867) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=338867) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=338867) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=338867) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=338867) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=338867) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=338867) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=338867) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=338867) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=338867) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=338867) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=338867) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=338867) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=338867) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=338867) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=338867) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=338867) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=338867) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=338867) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=338867) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=338867) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=338867) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=338867) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=338867) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=338867) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=338867) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=338867) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=338867) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=338867) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=338867) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=338867) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=338867) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=338867) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=338867) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=338867) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=338867) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=338867) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=338867) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=338867) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=338867) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=338867) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=338867) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=338867) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=338867) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=338867) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=338867) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=338867) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=338867) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=338867) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=338867) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=338867) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=338867) 	}
(EngineCore_DP0 pid=338867) 	.section	.debug_info
(EngineCore_DP0 pid=338867) 	{
(EngineCore_DP0 pid=338867) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=338867) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=338867) .b8 0
(EngineCore_DP0 pid=338867) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=338867) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=338867) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=338867) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=338867) .b8 114
(EngineCore_DP0 pid=338867) .b8 105
(EngineCore_DP0 pid=338867) .b8 116
(EngineCore_DP0 pid=338867) .b8 111
(EngineCore_DP0 pid=338867) .b8 110
(EngineCore_DP0 pid=338867) .b8 0
(EngineCore_DP0 pid=338867) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=338867) .b8 0
(EngineCore_DP0 pid=338867) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=338867) .b8 117
(EngineCore_DP0 pid=338867) .b8 97
(EngineCore_DP0 pid=338867) .b8 110
(EngineCore_DP0 pid=338867) .b8 116
(EngineCore_DP0 pid=338867) .b8 95
(EngineCore_DP0 pid=338867) .b8 115
(EngineCore_DP0 pid=338867) .b8 108
(EngineCore_DP0 pid=338867) .b8 105
(EngineCore_DP0 pid=338867) .b8 100
(EngineCore_DP0 pid=338867) .b8 101
(EngineCore_DP0 pid=338867) .b8 95
(EngineCore_DP0 pid=338867) .b8 116
(EngineCore_DP0 pid=338867) .b8 117
(EngineCore_DP0 pid=338867) .b8 110
(EngineCore_DP0 pid=338867) .b8 101
(EngineCore_DP0 pid=338867) .b8 100
(EngineCore_DP0 pid=338867) .b8 95
(EngineCore_DP0 pid=338867) .b8 76
(EngineCore_DP0 pid=338867) .b8 108
(EngineCore_DP0 pid=338867) .b8 97
(EngineCore_DP0 pid=338867) .b8 109
(EngineCore_DP0 pid=338867) .b8 97
(EngineCore_DP0 pid=338867) .b8 51
(EngineCore_DP0 pid=338867) .b8 46
(EngineCore_DP0 pid=338867) .b8 50
(EngineCore_DP0 pid=338867) .b8 45
(EngineCore_DP0 pid=338867) .b8 49
(EngineCore_DP0 pid=338867) .b8 66
(EngineCore_DP0 pid=338867) .b8 46
(EngineCore_DP0 pid=338867) .b8 112
(EngineCore_DP0 pid=338867) .b8 121
(EngineCore_DP0 pid=338867) .b8 0
(EngineCore_DP0 pid=338867) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=338867) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=338867) .b8 114
(EngineCore_DP0 pid=338867) .b8 111
(EngineCore_DP0 pid=338867) .b8 111
(EngineCore_DP0 pid=338867) .b8 116
(EngineCore_DP0 pid=338867) .b8 47
(EngineCore_DP0 pid=338867) .b8 118
(EngineCore_DP0 pid=338867) .b8 108
(EngineCore_DP0 pid=338867) .b8 108
(EngineCore_DP0 pid=338867) .b8 109
(EngineCore_DP0 pid=338867) .b8 98
(EngineCore_DP0 pid=338867) .b8 101
(EngineCore_DP0 pid=338867) .b8 110
(EngineCore_DP0 pid=338867) .b8 99
(EngineCore_DP0 pid=338867) .b8 104
(EngineCore_DP0 pid=338867) .b8 47
(EngineCore_DP0 pid=338867) .b8 115
(EngineCore_DP0 pid=338867) .b8 108
(EngineCore_DP0 pid=338867) .b8 105
(EngineCore_DP0 pid=338867) .b8 100
(EngineCore_DP0 pid=338867) .b8 101
(EngineCore_DP0 pid=338867) .b8 115
(EngineCore_DP0 pid=338867) .b8 112
(EngineCore_DP0 pid=338867) .b8 97
(EngineCore_DP0 pid=338867) .b8 114
(EngineCore_DP0 pid=338867) .b8 115
(EngineCore_DP0 pid=338867) .b8 101
(EngineCore_DP0 pid=338867) .b8 47
(EngineCore_DP0 pid=338867) .b8 99
(EngineCore_DP0 pid=338867) .b8 115
(EngineCore_DP0 pid=338867) .b8 114
(EngineCore_DP0 pid=338867) .b8 99
(EngineCore_DP0 pid=338867) .b8 47
(EngineCore_DP0 pid=338867) .b8 102
(EngineCore_DP0 pid=338867) .b8 117
(EngineCore_DP0 pid=338867) .b8 115
(EngineCore_DP0 pid=338867) .b8 101
(EngineCore_DP0 pid=338867) .b8 100
(EngineCore_DP0 pid=338867) .b8 95
(EngineCore_DP0 pid=338867) .b8 113
(EngineCore_DP0 pid=338867) .b8 117
(EngineCore_DP0 pid=338867) .b8 97
(EngineCore_DP0 pid=338867) .b8 110
(EngineCore_DP0 pid=338867) .b8 116
(EngineCore_DP0 pid=338867) .b8 95
(EngineCore_DP0 pid=338867) .b8 115
(EngineCore_DP0 pid=338867) .b8 108
(EngineCore_DP0 pid=338867) .b8 105
(EngineCore_DP0 pid=338867) .b8 100
(EngineCore_DP0 pid=338867) .b8 101
(EngineCore_DP0 pid=338867) .b8 95
(EngineCore_DP0 pid=338867) .b8 116
(EngineCore_DP0 pid=338867) .b8 114
(EngineCore_DP0 pid=338867) .b8 105
(EngineCore_DP0 pid=338867) .b8 116
(EngineCore_DP0 pid=338867) .b8 111
(EngineCore_DP0 pid=338867) .b8 110
(EngineCore_DP0 pid=338867) .b8 47
(EngineCore_DP0 pid=338867) .b8 98
(EngineCore_DP0 pid=338867) .b8 117
(EngineCore_DP0 pid=338867) .b8 105
(EngineCore_DP0 pid=338867) .b8 108
(EngineCore_DP0 pid=338867) .b8 100
(EngineCore_DP0 pid=338867) .b8 47
(EngineCore_DP0 pid=338867) .b8 71
(EngineCore_DP0 pid=338867) .b8 66
(EngineCore_DP0 pid=338867) .b8 49
(EngineCore_DP0 pid=338867) .b8 48
(EngineCore_DP0 pid=338867) .b8 95
(EngineCore_DP0 pid=338867) .b8 99
(EngineCore_DP0 pid=338867) .b8 99
(EngineCore_DP0 pid=338867) .b8 49
(EngineCore_DP0 pid=338867) .b8 50
(EngineCore_DP0 pid=338867) .b8 49
(EngineCore_DP0 pid=338867) .b8 95
(EngineCore_DP0 pid=338867) .b8 112
(EngineCore_DP0 pid=338867) .b8 121
(EngineCore_DP0 pid=338867) .b8 51
(EngineCore_DP0 pid=338867) .b8 49
(EngineCore_DP0 pid=338867) .b8 50
(EngineCore_DP0 pid=338867) .b8 95
(EngineCore_DP0 pid=338867) .b8 99
(EngineCore_DP0 pid=338867) .b8 117
(EngineCore_DP0 pid=338867) .b8 49
(EngineCore_DP0 pid=338867) .b8 50
(EngineCore_DP0 pid=338867) .b8 57
(EngineCore_DP0 pid=338867) .b8 95
(EngineCore_DP0 pid=338867) .b8 97
(EngineCore_DP0 pid=338867) .b8 97
(EngineCore_DP0 pid=338867) .b8 114
(EngineCore_DP0 pid=338867) .b8 99
(EngineCore_DP0 pid=338867) .b8 104
(EngineCore_DP0 pid=338867) .b8 54
(EngineCore_DP0 pid=338867) .b8 52
(EngineCore_DP0 pid=338867) .b8 0
(EngineCore_DP0 pid=338867) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=338867) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=338867) .b8 113
(EngineCore_DP0 pid=338867) .b8 117
(EngineCore_DP0 pid=338867) .b8 97
(EngineCore_DP0 pid=338867) .b8 110
(EngineCore_DP0 pid=338867) .b8 116
(EngineCore_DP0 pid=338867) .b8 95
(EngineCore_DP0 pid=338867) .b8 115
(EngineCore_DP0 pid=338867) .b8 108
(EngineCore_DP0 pid=338867) .b8 105
(EngineCore_DP0 pid=338867) .b8 100
(EngineCore_DP0 pid=338867) .b8 101
(EngineCore_DP0 pid=338867) .b8 95
(EngineCore_DP0 pid=338867) .b8 102
(EngineCore_DP0 pid=338867) .b8 112
(EngineCore_DP0 pid=338867) .b8 56
(EngineCore_DP0 pid=338867) .b8 95
(EngineCore_DP0 pid=338867) .b8 107
(EngineCore_DP0 pid=338867) .b8 101
(EngineCore_DP0 pid=338867) .b8 114
(EngineCore_DP0 pid=338867) .b8 110
(EngineCore_DP0 pid=338867) .b8 101
(EngineCore_DP0 pid=338867) .b8 108
(EngineCore_DP0 pid=338867) .b8 0
(EngineCore_DP0 pid=338867) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=338867) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=338867) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=338867) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=338867) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=338867) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=338867) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=338867) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=338867) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=338867) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=338867) .b8 191                                 // DW_AT_call_line
(EngineCore_DP0 pid=338867) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=338867) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=338867) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=338867) 	}
(EngineCore_DP0 pid=338867) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=338867) 
(EngineCore_DP0 pid=338867) ================================================================
(EngineCore_DP0 pid=338867) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=338867) 
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpox1_0p11.ptx', '-o', '/tmp/tmpox1_0p11.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866] 
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866] 
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866] 
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpox1_0p11.ptx -o /tmp/tmpox1_0p11.ptx.o
(EngineCore_DP0 pid=338867) ERROR 01-25 19:17:55 [core.py:866] 

STDERR:
[2026-01-25 19:17:40] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:17:40] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:17:40] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:17:40] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:17:40] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:17:40] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:17:40] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:17:40] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:17:40] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:17:40] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:17:40] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:17:40] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:17:40] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:17:40] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:17:44] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:17:44] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:17:44] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:17:44] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:17:44] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:17:44] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:17:44] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:17:44] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:17:44] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:17:44] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:17:44] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:17:44] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:17:44] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:17:44] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=338867) [2026-01-25 19:17:44] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=338867) [2026-01-25 19:17:44] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=338867) [2026-01-25 19:17:44] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=338867) [2026-01-25 19:17:44] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=338867) [2026-01-25 19:17:44] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=338867) [2026-01-25 19:17:44] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=338867) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=338867) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.50s/it]
(EngineCore_DP0 pid=338867) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.50s/it]
(EngineCore_DP0 pid=338867) 
(EngineCore_DP0 pid=338867) [2026-01-25 19:17:54] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=338867) [2026-01-25 19:17:55] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5308416 bytes
(EngineCore_DP0 pid=338867) [2026-01-25 19:17:55] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=338867) [2026-01-25 19:17:55] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3538944 bytes
(EngineCore_DP0 pid=338867) [2026-01-25 19:17:55] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=338867) [2026-01-25 19:17:55] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 28311552 bytes
(EngineCore_DP0 pid=338867) [2026-01-25 19:17:55] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=338867) [2026-01-25 19:17:55] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14024704 bytes
(EngineCore_DP0 pid=338867) Process EngineCore_DP0:
(EngineCore_DP0 pid=338867) Traceback (most recent call last):
(EngineCore_DP0 pid=338867)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=338867)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=338867)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=338867)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=338867) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpox1_0p11.ptx', '-o', '/tmp/tmpox1_0p11.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=338867) 
(EngineCore_DP0 pid=338867) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=338867) 
(EngineCore_DP0 pid=338867) Traceback (most recent call last):
(EngineCore_DP0 pid=338867)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=338867)     self.run()
(EngineCore_DP0 pid=338867)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=338867)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=338867)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=338867)     raise e
(EngineCore_DP0 pid=338867)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=338867)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=338867)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=338867)     super().__init__(
(EngineCore_DP0 pid=338867)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=338867)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=338867)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=338867)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=338867)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=338867)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=338867)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=338867)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=338867)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=338867)     return func(*args, **kwargs)
(EngineCore_DP0 pid=338867)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=338867)     return func(*args, **kwargs)
(EngineCore_DP0 pid=338867)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=338867)     self.model_runner.profile_run()
(EngineCore_DP0 pid=338867)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=338867)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=338867)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=338867)     return func(*args, **kwargs)
(EngineCore_DP0 pid=338867)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=338867)     outputs = self.model(
(EngineCore_DP0 pid=338867)               ^^^^^^^^^^^
(EngineCore_DP0 pid=338867)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=338867)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=338867)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=338867)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=338867)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=338867)     model_output = self.model(
(EngineCore_DP0 pid=338867)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=338867)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=338867)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=338867)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=338867)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=338867)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=338867)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=338867)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=338867)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=338867)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=338867)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=338867)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=338867)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=338867)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=338867)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=338867)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=338867)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=338867)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=338867)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=338867)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=338867)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=338867)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=338867)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=338867)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=338867)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=338867)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=338867)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=338867)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=338867)     return self._linear_fn(
(EngineCore_DP0 pid=338867)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=338867)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=338867)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=338867)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=338867)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=338867)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=338867)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=338867)     return fn(input, L)
(EngineCore_DP0 pid=338867)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=338867)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=338867)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=338867)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=338867)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=338867)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=338867)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=338867)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=338867)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=338867)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=338867)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=338867)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=338867)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=338867)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=338867)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=338867)     raise PTXASError(error)
(EngineCore_DP0 pid=338867) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=338867) `ptxas` stderr:
(EngineCore_DP0 pid=338867) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=338867) 
(EngineCore_DP0 pid=338867) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpox1_0p11.ptx -o /tmp/tmpox1_0p11.ptx.o
(EngineCore_DP0 pid=338867) 
[rank0]:[W125 19:17:56.271732702 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=4096

========== M=8192 ==========
Time: 2026-01-25 19:17:57
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-FP8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:18:04 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:18:04 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=339398) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=339398) 
(EngineCore_DP0 pid=339398) 
(EngineCore_DP0 pid=339398) ================================================================
(EngineCore_DP0 pid=339398) Internal Triton PTX codegen error
(EngineCore_DP0 pid=339398) `ptxas` stderr:
(EngineCore_DP0 pid=339398) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=339398) 
(EngineCore_DP0 pid=339398) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpjy2wgnr8.ptx -o /tmp/tmpjy2wgnr8.ptx.o
(EngineCore_DP0 pid=339398) 
(EngineCore_DP0 pid=339398) 
(EngineCore_DP0 pid=339398) //
(EngineCore_DP0 pid=339398) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=339398) //
(EngineCore_DP0 pid=339398) 
(EngineCore_DP0 pid=339398) .version 8.7
(EngineCore_DP0 pid=339398) .target sm_121a
(EngineCore_DP0 pid=339398) .address_size 64
(EngineCore_DP0 pid=339398) 
(EngineCore_DP0 pid=339398) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=339398) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=339398)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=339398) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=339398) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=339398) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=339398) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=339398) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=339398) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=339398) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=339398) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=339398) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=339398) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=339398) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=339398) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=339398) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=339398) )
(EngineCore_DP0 pid=339398) .reqntid 512
(EngineCore_DP0 pid=339398) {
(EngineCore_DP0 pid=339398) 	.reg .pred 	%p<45>;
(EngineCore_DP0 pid=339398) 	.reg .b16 	%rs<74>;
(EngineCore_DP0 pid=339398) 	.reg .b32 	%r<201>;
(EngineCore_DP0 pid=339398) 	.reg .b64 	%rd<26>;
(EngineCore_DP0 pid=339398) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=339398) $L__func_begin0:
(EngineCore_DP0 pid=339398) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=339398) 
(EngineCore_DP0 pid=339398) // %bb.0:
(EngineCore_DP0 pid=339398) 	ld.param.b32 	%r29, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=339398) 	ld.param.b32 	%r28, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=339398) 	ld.param.b32 	%r27, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=339398) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=339398) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=339398) $L__tmp0:
(EngineCore_DP0 pid=339398) 	.loc	1 177 24                        // quant_slide_tuned_Llama3.2-1B.py:177:24
(EngineCore_DP0 pid=339398) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=339398) 	ld.param.b32 	%r31, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=339398) 	.loc	1 182 26                        // quant_slide_tuned_Llama3.2-1B.py:182:26
(EngineCore_DP0 pid=339398) 	mul.lo.s32 	%r32, %r31, %r1;
(EngineCore_DP0 pid=339398) 	.loc	1 182 20                        // quant_slide_tuned_Llama3.2-1B.py:182:20
(EngineCore_DP0 pid=339398) 	mad.wide.s32 	%rd1, %r32, 2, %rd4;
(EngineCore_DP0 pid=339398) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=339398) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=339398) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=339398) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=339398) 	setp.lt.s32 	%p1, %r28, 1;
(EngineCore_DP0 pid=339398) 	mov.b32 	%r199, 0f2B8CBCCC;
(EngineCore_DP0 pid=339398) 	setp.eq.b32 	%p44, %r2, 0;
(EngineCore_DP0 pid=339398) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=339398) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=339398) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=339398) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=339398) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=339398) 	shr.u32 	%r41, %r2, 3;
(EngineCore_DP0 pid=339398) 	and.b32 	%r42, %r41, 60;
(EngineCore_DP0 pid=339398) 	mov.b32 	%r43, global_smem;
(EngineCore_DP0 pid=339398) 	add.s32 	%r53, %r43, %r42;
(EngineCore_DP0 pid=339398) 	shl.b32 	%r44, %r2, 2;
(EngineCore_DP0 pid=339398) 	add.s32 	%r56, %r43, %r44;
(EngineCore_DP0 pid=339398) 	mov.b32 	%r49, 0;
(EngineCore_DP0 pid=339398) 	mov.b32 	%r197, 0f00000000;
(EngineCore_DP0 pid=339398) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=339398) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=339398) 	mov.b32 	%r198, %r49;
(EngineCore_DP0 pid=339398) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=339398) 	.loc	1 189 22                        // quant_slide_tuned_Llama3.2-1B.py:189:22
(EngineCore_DP0 pid=339398) 	add.s32 	%r59, %r4, %r198;
(EngineCore_DP0 pid=339398) 	setp.lt.s32 	%p2, %r59, %r27;
(EngineCore_DP0 pid=339398) 	.loc	1 190 29                        // quant_slide_tuned_Llama3.2-1B.py:190:29
(EngineCore_DP0 pid=339398) 	mad.wide.s32 	%rd6, %r59, 2, %rd1;
(EngineCore_DP0 pid=339398) 	.loc	1 190 21                        // quant_slide_tuned_Llama3.2-1B.py:190:21
(EngineCore_DP0 pid=339398) 	// begin inline asm
(EngineCore_DP0 pid=339398) 	mov.u32 %r45, %r49;
(EngineCore_DP0 pid=339398) 	mov.u32 %r46, %r49;
(EngineCore_DP0 pid=339398) 	mov.u32 %r47, %r49;
(EngineCore_DP0 pid=339398) 	mov.u32 %r48, %r49;
(EngineCore_DP0 pid=339398) 	@%p2 ld.global.v4.b32 { %r45, %r46, %r47, %r48 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=339398) 	// end inline asm
(EngineCore_DP0 pid=339398) 	mov.b32 	{%rs1, %rs2}, %r45;
(EngineCore_DP0 pid=339398) 	mov.b32 	{%rs3, %rs4}, %r46;
(EngineCore_DP0 pid=339398) 	mov.b32 	{%rs5, %rs6}, %r47;
(EngineCore_DP0 pid=339398) 	mov.b32 	{%rs7, %rs8}, %r48;
(EngineCore_DP0 pid=339398) 	.loc	1 191 50                        // quant_slide_tuned_Llama3.2-1B.py:191:50
(EngineCore_DP0 pid=339398) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=339398) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=339398) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=339398) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=339398) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=339398) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=339398) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=339398) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=339398) $L__tmp1:
(EngineCore_DP0 pid=339398) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=339398) 	bar.sync 	0;
(EngineCore_DP0 pid=339398) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=339398) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=339398) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=339398) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=339398) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=339398) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=339398) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=339398) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=339398) 	cvt.f32.bf16 	%r60, %rs23;
(EngineCore_DP0 pid=339398) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=339398) 	shfl.sync.bfly.b32 	%r61, %r60, 16, 31, -1;
(EngineCore_DP0 pid=339398) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=339398) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=339398) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=339398) 	shfl.sync.bfly.b32 	%r63, %r62, 8, 31, -1;
(EngineCore_DP0 pid=339398) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=339398) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=339398) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=339398) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=339398) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=339398) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=339398) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=339398) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=339398) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=339398) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=339398) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=339398) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=339398) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=339398) 	max.f32 	%r54, %r68, %r69;
(EngineCore_DP0 pid=339398) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=339398) 	// begin inline asm
(EngineCore_DP0 pid=339398) 	@%p3 st.shared.b32 [ %r53 + 0 ], %r54;
(EngineCore_DP0 pid=339398) 	// end inline asm
(EngineCore_DP0 pid=339398) 	bar.sync 	0;
(EngineCore_DP0 pid=339398) 	// begin inline asm
(EngineCore_DP0 pid=339398) 	@%p4 ld.shared.b32 %r55, [ %r56 + 0 ];
(EngineCore_DP0 pid=339398) 	// end inline asm
(EngineCore_DP0 pid=339398) 	shfl.sync.bfly.b32 	%r70, %r55, 8, 31, -1;
(EngineCore_DP0 pid=339398) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=339398) 	max.f32 	%r71, %r55, %r70;
(EngineCore_DP0 pid=339398) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=339398) 	shfl.sync.bfly.b32 	%r72, %r71, 4, 31, -1;
(EngineCore_DP0 pid=339398) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=339398) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=339398) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=339398) 	shfl.sync.bfly.b32 	%r74, %r73, 2, 31, -1;
(EngineCore_DP0 pid=339398) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=339398) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=339398) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=339398) 	shfl.sync.bfly.b32 	%r76, %r75, 1, 31, -1;
(EngineCore_DP0 pid=339398) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=339398) 	max.f32 	%r58, %r75, %r76;
(EngineCore_DP0 pid=339398) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=339398) 	// begin inline asm
(EngineCore_DP0 pid=339398) 	@%p44 st.shared.b32 [ %r56 + 0 ], %r58;
(EngineCore_DP0 pid=339398) 	// end inline asm
(EngineCore_DP0 pid=339398) 	bar.sync 	0;
(EngineCore_DP0 pid=339398) 	ld.shared.b32 	%r77, [global_smem];
(EngineCore_DP0 pid=339398) $L__tmp2:
(EngineCore_DP0 pid=339398) 	.loc	1 191 36                        // quant_slide_tuned_Llama3.2-1B.py:191:36
(EngineCore_DP0 pid=339398) 	max.f32 	%r197, %r197, %r77;
(EngineCore_DP0 pid=339398) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=339398) 	add.s32 	%r198, %r198, 4096;
(EngineCore_DP0 pid=339398) 	setp.lt.s32 	%p6, %r198, %r28;
(EngineCore_DP0 pid=339398) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=339398) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=339398) 	.loc	1 193 32                        // quant_slide_tuned_Llama3.2-1B.py:193:32
(EngineCore_DP0 pid=339398) 	max.f32 	%r199, %r197, 0f2B8CBCCC;
(EngineCore_DP0 pid=339398) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=339398) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=339398) 	mov.b32 	%r79, 0f43E00000;
(EngineCore_DP0 pid=339398) 	.loc	1 194 32                        // quant_slide_tuned_Llama3.2-1B.py:194:32
(EngineCore_DP0 pid=339398) 	div.full.f32 	%r80, %r199, %r79;
(EngineCore_DP0 pid=339398) 	.loc	1 194 41                        // quant_slide_tuned_Llama3.2-1B.py:194:41
(EngineCore_DP0 pid=339398) 	max.f32 	%r78, %r80, 0f36924925;
(EngineCore_DP0 pid=339398) 	.loc	1 196 25                        // quant_slide_tuned_Llama3.2-1B.py:196:25
(EngineCore_DP0 pid=339398) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=339398) 	.loc	1 196 30                        // quant_slide_tuned_Llama3.2-1B.py:196:30
(EngineCore_DP0 pid=339398) 	// begin inline asm
(EngineCore_DP0 pid=339398) 	@%p44 st.global.b32 [ %rd7 + 0 ], { %r78 };
(EngineCore_DP0 pid=339398) 	// end inline asm
(EngineCore_DP0 pid=339398) 	.loc	1 199 29                        // quant_slide_tuned_Llama3.2-1B.py:199:29
(EngineCore_DP0 pid=339398) 	shl.b32 	%r15, %r29, 1;
(EngineCore_DP0 pid=339398) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=339398) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=339398) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=339398) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=339398) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=339398) 	ld.param.b32 	%r33, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=339398) 	shr.s32 	%r34, %r33, 31;
(EngineCore_DP0 pid=339398) 	shr.u32 	%r35, %r34, 30;
(EngineCore_DP0 pid=339398) 	add.s32 	%r36, %r33, %r35;
(EngineCore_DP0 pid=339398) 	shr.s32 	%r37, %r36, 2;
(EngineCore_DP0 pid=339398) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=339398) 	mul.lo.s32 	%r38, %r37, %r1;
(EngineCore_DP0 pid=339398) 	mad.wide.s32 	%rd2, %r38, 4, %rd5;
(EngineCore_DP0 pid=339398) 	div.full.f32 	%r14, %r79, %r199;
(EngineCore_DP0 pid=339398) 	shl.b32 	%r16, %r3, 2;
(EngineCore_DP0 pid=339398) 	mov.b32 	%r200, 0;
(EngineCore_DP0 pid=339398) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=339398)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=339398) 	.loc	1 202 31                        // quant_slide_tuned_Llama3.2-1B.py:202:31
(EngineCore_DP0 pid=339398) 	add.s32 	%r102, %r16, %r200;
(EngineCore_DP0 pid=339398) 	add.s32 	%r103, %r200, 1;
(EngineCore_DP0 pid=339398) 	.loc	1 203 30                        // quant_slide_tuned_Llama3.2-1B.py:203:30
(EngineCore_DP0 pid=339398) 	add.s32 	%r104, %r102, 2;
(EngineCore_DP0 pid=339398) 	setp.lt.s32 	%p25, %r102, %r15;
(EngineCore_DP0 pid=339398) 	setp.lt.s32 	%p26, %r104, %r15;
(EngineCore_DP0 pid=339398) 	.loc	1 206 24                        // quant_slide_tuned_Llama3.2-1B.py:206:24
(EngineCore_DP0 pid=339398) 	shr.u32 	%r105, %r102, 1;
(EngineCore_DP0 pid=339398) 	shr.u32 	%r106, %r104, 1;
(EngineCore_DP0 pid=339398) 	.loc	1 207 23                        // quant_slide_tuned_Llama3.2-1B.py:207:23
(EngineCore_DP0 pid=339398) 	shr.u32 	%r107, %r103, 31;
(EngineCore_DP0 pid=339398) 	add.s32 	%r108, %r103, %r107;
(EngineCore_DP0 pid=339398) 	and.b32 	%r109, %r108, 2147483646;
(EngineCore_DP0 pid=339398) 	sub.s32 	%r110, %r103, %r109;
(EngineCore_DP0 pid=339398) 	.loc	1 208 30                        // quant_slide_tuned_Llama3.2-1B.py:208:30
(EngineCore_DP0 pid=339398) 	shl.b32 	%r111, %r110, 1;
(EngineCore_DP0 pid=339398) 	.loc	1 208 22                        // quant_slide_tuned_Llama3.2-1B.py:208:22
(EngineCore_DP0 pid=339398) 	mul.lo.s32 	%r112, %r105, 6;
(EngineCore_DP0 pid=339398) 	mul.lo.s32 	%r113, %r106, 6;
(EngineCore_DP0 pid=339398) 	.loc	1 208 26                        // quant_slide_tuned_Llama3.2-1B.py:208:26
(EngineCore_DP0 pid=339398) 	add.s32 	%r114, %r112, %r111;
(EngineCore_DP0 pid=339398) 	add.s32 	%r115, %r113, %r111;
(EngineCore_DP0 pid=339398) 	.loc	1 211 53                        // quant_slide_tuned_Llama3.2-1B.py:211:53
(EngineCore_DP0 pid=339398) 	setp.lt.s32 	%p27, %r112, %r27;
(EngineCore_DP0 pid=339398) 	setp.lt.s32 	%p28, %r114, %r27;
(EngineCore_DP0 pid=339398) 	setp.lt.s32 	%p29, %r113, %r27;
(EngineCore_DP0 pid=339398) 	setp.lt.s32 	%p30, %r115, %r27;
(EngineCore_DP0 pid=339398) 	.loc	1 211 37                        // quant_slide_tuned_Llama3.2-1B.py:211:37
(EngineCore_DP0 pid=339398) 	and.pred 	%p9, %p25, %p27;
(EngineCore_DP0 pid=339398) 	and.pred 	%p10, %p25, %p28;
(EngineCore_DP0 pid=339398) 	and.pred 	%p11, %p26, %p29;
(EngineCore_DP0 pid=339398) 	and.pred 	%p12, %p26, %p30;
(EngineCore_DP0 pid=339398) 	.loc	1 210 29                        // quant_slide_tuned_Llama3.2-1B.py:210:29
(EngineCore_DP0 pid=339398) 	mad.wide.s32 	%rd8, %r112, 2, %rd1;
(EngineCore_DP0 pid=339398) 	mad.wide.s32 	%rd9, %r114, 2, %rd1;
(EngineCore_DP0 pid=339398) 	mad.wide.s32 	%rd10, %r113, 2, %rd1;
(EngineCore_DP0 pid=339398) 	mad.wide.s32 	%rd11, %r115, 2, %rd1;
(EngineCore_DP0 pid=339398) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=339398) 	.loc	1 210 21                        // quant_slide_tuned_Llama3.2-1B.py:210:21
(EngineCore_DP0 pid=339398) 	// begin inline asm
(EngineCore_DP0 pid=339398) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=339398) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=339398) 	// end inline asm
(EngineCore_DP0 pid=339398) 	// begin inline asm
(EngineCore_DP0 pid=339398) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=339398) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=339398) 	// end inline asm
(EngineCore_DP0 pid=339398) 	// begin inline asm
(EngineCore_DP0 pid=339398) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=339398) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=339398) 	// end inline asm
(EngineCore_DP0 pid=339398) 	// begin inline asm
(EngineCore_DP0 pid=339398) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=339398) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=339398) 	// end inline asm
(EngineCore_DP0 pid=339398) 	.loc	1 211 79                        // quant_slide_tuned_Llama3.2-1B.py:211:79
(EngineCore_DP0 pid=339398) 	cvt.f32.bf16 	%r116, %rs24;
(EngineCore_DP0 pid=339398) 	cvt.f32.bf16 	%r117, %rs26;
(EngineCore_DP0 pid=339398) 	cvt.f32.bf16 	%r118, %rs28;
(EngineCore_DP0 pid=339398) 	cvt.f32.bf16 	%r119, %rs30;
(EngineCore_DP0 pid=339398) 	.loc	1 217 48                        // quant_slide_tuned_Llama3.2-1B.py:217:48
(EngineCore_DP0 pid=339398) 	or.b32 	%r120, %r114, 1;
(EngineCore_DP0 pid=339398) 	or.b32 	%r121, %r115, 1;
(EngineCore_DP0 pid=339398) 	or.b32 	%r122, %r115, 2;
(EngineCore_DP0 pid=339398) 	or.b32 	%r123, %r115, 3;
(EngineCore_DP0 pid=339398) 	or.b32 	%r124, %r112, 1;
(EngineCore_DP0 pid=339398) 	or.b32 	%r125, %r113, 1;
(EngineCore_DP0 pid=339398) 	or.b32 	%r126, %r112, 2;
(EngineCore_DP0 pid=339398) 	or.b32 	%r127, %r112, 3;
(EngineCore_DP0 pid=339398) 	.loc	1 217 53                        // quant_slide_tuned_Llama3.2-1B.py:217:53
(EngineCore_DP0 pid=339398) 	setp.lt.s32 	%p31, %r123, %r27;
(EngineCore_DP0 pid=339398) 	setp.lt.s32 	%p32, %r122, %r27;
(EngineCore_DP0 pid=339398) 	setp.lt.s32 	%p33, %r121, %r27;
(EngineCore_DP0 pid=339398) 	setp.lt.s32 	%p34, %r120, %r27;
(EngineCore_DP0 pid=339398) 	setp.lt.s32 	%p35, %r127, %r27;
(EngineCore_DP0 pid=339398) 	setp.lt.s32 	%p36, %r126, %r27;
(EngineCore_DP0 pid=339398) 	setp.lt.s32 	%p37, %r125, %r27;
(EngineCore_DP0 pid=339398) 	setp.lt.s32 	%p38, %r124, %r27;
(EngineCore_DP0 pid=339398) 	.loc	1 213 37                        // quant_slide_tuned_Llama3.2-1B.py:213:37
(EngineCore_DP0 pid=339398) 	and.pred 	%p13, %p25, %p38;
(EngineCore_DP0 pid=339398) 	and.pred 	%p14, %p25, %p34;
(EngineCore_DP0 pid=339398) 	and.pred 	%p15, %p26, %p37;
(EngineCore_DP0 pid=339398) 	and.pred 	%p16, %p26, %p33;
(EngineCore_DP0 pid=339398) 	.loc	1 212 39                        // quant_slide_tuned_Llama3.2-1B.py:212:39
(EngineCore_DP0 pid=339398) 	add.s64 	%rd12, %rd8, 2;
(EngineCore_DP0 pid=339398) 	add.s64 	%rd13, %rd9, 2;
(EngineCore_DP0 pid=339398) 	add.s64 	%rd14, %rd10, 2;
(EngineCore_DP0 pid=339398) 	add.s64 	%rd15, %rd11, 2;
(EngineCore_DP0 pid=339398) 	.loc	1 212 21                        // quant_slide_tuned_Llama3.2-1B.py:212:21
(EngineCore_DP0 pid=339398) 	// begin inline asm
(EngineCore_DP0 pid=339398) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=339398) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=339398) 	// end inline asm
(EngineCore_DP0 pid=339398) 	// begin inline asm
(EngineCore_DP0 pid=339398) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=339398) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=339398) 	// end inline asm
(EngineCore_DP0 pid=339398) 	// begin inline asm
(EngineCore_DP0 pid=339398) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=339398) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=339398) 	// end inline asm
(EngineCore_DP0 pid=339398) 	// begin inline asm
(EngineCore_DP0 pid=339398) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=339398) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=339398) 	// end inline asm
(EngineCore_DP0 pid=339398) 	.loc	1 213 79                        // quant_slide_tuned_Llama3.2-1B.py:213:79
(EngineCore_DP0 pid=339398) 	cvt.f32.bf16 	%r128, %rs32;
(EngineCore_DP0 pid=339398) 	cvt.f32.bf16 	%r129, %rs34;
(EngineCore_DP0 pid=339398) 	cvt.f32.bf16 	%r130, %rs36;
(EngineCore_DP0 pid=339398) 	cvt.f32.bf16 	%r131, %rs38;
(EngineCore_DP0 pid=339398) 	.loc	1 215 48                        // quant_slide_tuned_Llama3.2-1B.py:215:48
(EngineCore_DP0 pid=339398) 	add.s32 	%r132, %r114, 2;
(EngineCore_DP0 pid=339398) 	add.s32 	%r133, %r113, 2;
(EngineCore_DP0 pid=339398) 	.loc	1 215 53                        // quant_slide_tuned_Llama3.2-1B.py:215:53
(EngineCore_DP0 pid=339398) 	setp.lt.s32 	%p39, %r132, %r27;
(EngineCore_DP0 pid=339398) 	setp.lt.s32 	%p40, %r133, %r27;
(EngineCore_DP0 pid=339398) 	.loc	1 215 37                        // quant_slide_tuned_Llama3.2-1B.py:215:37
(EngineCore_DP0 pid=339398) 	and.pred 	%p17, %p25, %p36;
(EngineCore_DP0 pid=339398) 	and.pred 	%p18, %p25, %p39;
(EngineCore_DP0 pid=339398) 	and.pred 	%p19, %p26, %p40;
(EngineCore_DP0 pid=339398) 	and.pred 	%p20, %p26, %p32;
(EngineCore_DP0 pid=339398) 	.loc	1 214 39                        // quant_slide_tuned_Llama3.2-1B.py:214:39
(EngineCore_DP0 pid=339398) 	add.s64 	%rd16, %rd8, 4;
(EngineCore_DP0 pid=339398) 	add.s64 	%rd17, %rd9, 4;
(EngineCore_DP0 pid=339398) 	add.s64 	%rd18, %rd10, 4;
(EngineCore_DP0 pid=339398) 	add.s64 	%rd19, %rd11, 4;
(EngineCore_DP0 pid=339398) 	.loc	1 214 21                        // quant_slide_tuned_Llama3.2-1B.py:214:21
(EngineCore_DP0 pid=339398) 	// begin inline asm
(EngineCore_DP0 pid=339398) 	mov.u16 %rs40, %rs25;
(EngineCore_DP0 pid=339398) 	@%p17 ld.global.b16 { %rs40 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=339398) 	// end inline asm
(EngineCore_DP0 pid=339398) 	// begin inline asm
(EngineCore_DP0 pid=339398) 	mov.u16 %rs42, %rs25;
(EngineCore_DP0 pid=339398) 	@%p18 ld.global.b16 { %rs42 }, [ %rd17 + 0 ];
(EngineCore_DP0 pid=339398) 	// end inline asm
(EngineCore_DP0 pid=339398) 	// begin inline asm
(EngineCore_DP0 pid=339398) 	mov.u16 %rs44, %rs25;
(EngineCore_DP0 pid=339398) 	@%p19 ld.global.b16 { %rs44 }, [ %rd18 + 0 ];
(EngineCore_DP0 pid=339398) 	// end inline asm
(EngineCore_DP0 pid=339398) 	// begin inline asm
(EngineCore_DP0 pid=339398) 	mov.u16 %rs46, %rs25;
(EngineCore_DP0 pid=339398) 	@%p20 ld.global.b16 { %rs46 }, [ %rd19 + 0 ];
(EngineCore_DP0 pid=339398) 	// end inline asm
(EngineCore_DP0 pid=339398) 	.loc	1 215 79                        // quant_slide_tuned_Llama3.2-1B.py:215:79
(EngineCore_DP0 pid=339398) 	cvt.f32.bf16 	%r134, %rs40;
(EngineCore_DP0 pid=339398) 	cvt.f32.bf16 	%r135, %rs42;
(EngineCore_DP0 pid=339398) 	cvt.f32.bf16 	%r136, %rs44;
(EngineCore_DP0 pid=339398) 	cvt.f32.bf16 	%r137, %rs46;
(EngineCore_DP0 pid=339398) 	.loc	1 217 48                        // quant_slide_tuned_Llama3.2-1B.py:217:48
(EngineCore_DP0 pid=339398) 	add.s32 	%r138, %r114, 3;
(EngineCore_DP0 pid=339398) 	add.s32 	%r139, %r113, 3;
(EngineCore_DP0 pid=339398) 	.loc	1 217 53                        // quant_slide_tuned_Llama3.2-1B.py:217:53
(EngineCore_DP0 pid=339398) 	setp.lt.s32 	%p41, %r138, %r27;
(EngineCore_DP0 pid=339398) 	setp.lt.s32 	%p42, %r139, %r27;
(EngineCore_DP0 pid=339398) 	.loc	1 217 37                        // quant_slide_tuned_Llama3.2-1B.py:217:37
(EngineCore_DP0 pid=339398) 	and.pred 	%p21, %p25, %p35;
(EngineCore_DP0 pid=339398) 	and.pred 	%p22, %p25, %p41;
(EngineCore_DP0 pid=339398) 	and.pred 	%p23, %p26, %p42;
(EngineCore_DP0 pid=339398) 	and.pred 	%p24, %p26, %p31;
(EngineCore_DP0 pid=339398) 	.loc	1 216 39                        // quant_slide_tuned_Llama3.2-1B.py:216:39
(EngineCore_DP0 pid=339398) 	add.s64 	%rd20, %rd8, 6;
(EngineCore_DP0 pid=339398) 	add.s64 	%rd21, %rd9, 6;
(EngineCore_DP0 pid=339398) 	add.s64 	%rd22, %rd10, 6;
(EngineCore_DP0 pid=339398) 	add.s64 	%rd23, %rd11, 6;
(EngineCore_DP0 pid=339398) 	.loc	1 216 21                        // quant_slide_tuned_Llama3.2-1B.py:216:21
(EngineCore_DP0 pid=339398) 	// begin inline asm
(EngineCore_DP0 pid=339398) 	mov.u16 %rs48, %rs25;
(EngineCore_DP0 pid=339398) 	@%p21 ld.global.b16 { %rs48 }, [ %rd20 + 0 ];
(EngineCore_DP0 pid=339398) 	// end inline asm
(EngineCore_DP0 pid=339398) 	// begin inline asm
(EngineCore_DP0 pid=339398) 	mov.u16 %rs50, %rs25;
(EngineCore_DP0 pid=339398) 	@%p22 ld.global.b16 { %rs50 }, [ %rd21 + 0 ];
(EngineCore_DP0 pid=339398) 	// end inline asm
(EngineCore_DP0 pid=339398) 	// begin inline asm
(EngineCore_DP0 pid=339398) 	mov.u16 %rs52, %rs25;
(EngineCore_DP0 pid=339398) 	@%p23 ld.global.b16 { %rs52 }, [ %rd22 + 0 ];
(EngineCore_DP0 pid=339398) 	// end inline asm
(EngineCore_DP0 pid=339398) 	// begin inline asm
(EngineCore_DP0 pid=339398) 	mov.u16 %rs54, %rs25;
(EngineCore_DP0 pid=339398) 	@%p24 ld.global.b16 { %rs54 }, [ %rd23 + 0 ];
(EngineCore_DP0 pid=339398) 	// end inline asm
(EngineCore_DP0 pid=339398) 	.loc	1 217 79                        // quant_slide_tuned_Llama3.2-1B.py:217:79
(EngineCore_DP0 pid=339398) 	cvt.f32.bf16 	%r140, %rs48;
(EngineCore_DP0 pid=339398) 	cvt.f32.bf16 	%r141, %rs50;
(EngineCore_DP0 pid=339398) 	cvt.f32.bf16 	%r142, %rs52;
(EngineCore_DP0 pid=339398) 	cvt.f32.bf16 	%r143, %rs54;
(EngineCore_DP0 pid=339398) 	.loc	1 219 27                        // quant_slide_tuned_Llama3.2-1B.py:219:27
(EngineCore_DP0 pid=339398) 	mul.f32 	%r144, %r14, %r116;
(EngineCore_DP0 pid=339398) 	mul.f32 	%r145, %r14, %r117;
(EngineCore_DP0 pid=339398) 	mul.f32 	%r146, %r14, %r118;
(EngineCore_DP0 pid=339398) 	mul.f32 	%r147, %r14, %r119;
(EngineCore_DP0 pid=339398) 	mov.b32 	%r148, 0f43E00000;
(EngineCore_DP0 pid=339398) 	.loc	1 219 48                        // quant_slide_tuned_Llama3.2-1B.py:219:48
(EngineCore_DP0 pid=339398) 	min.xorsign.abs.f32 	%r82, %r144, %r148;
(EngineCore_DP0 pid=339398) 	min.xorsign.abs.f32 	%r83, %r145, %r148;
(EngineCore_DP0 pid=339398) 	min.xorsign.abs.f32 	%r84, %r146, %r148;
(EngineCore_DP0 pid=339398) 	min.xorsign.abs.f32 	%r85, %r147, %r148;
(EngineCore_DP0 pid=339398) 	.loc	1 219 60                        // quant_slide_tuned_Llama3.2-1B.py:219:60
(EngineCore_DP0 pid=339398) 	// begin inline asm
(EngineCore_DP0 pid=339398) 	cvt.rn.satfinite.e4m3x2.f32  %rs56, %r83, %r82; 
(EngineCore_DP0 pid=339398) 
(EngineCore_DP0 pid=339398) 	// end inline asm
(EngineCore_DP0 pid=339398) 	shr.u16 	%rs64, %rs56, 8;
(EngineCore_DP0 pid=339398) 	// begin inline asm
(EngineCore_DP0 pid=339398) 	cvt.rn.satfinite.e4m3x2.f32  %rs57, %r85, %r84; 
(EngineCore_DP0 pid=339398) 
(EngineCore_DP0 pid=339398) 	// end inline asm
(EngineCore_DP0 pid=339398) 	shr.u16 	%rs65, %rs57, 8;
(EngineCore_DP0 pid=339398) 	.loc	1 220 27                        // quant_slide_tuned_Llama3.2-1B.py:220:27
(EngineCore_DP0 pid=339398) 	mul.f32 	%r149, %r14, %r128;
(EngineCore_DP0 pid=339398) 	mul.f32 	%r150, %r14, %r129;
(EngineCore_DP0 pid=339398) 	mul.f32 	%r151, %r14, %r130;
(EngineCore_DP0 pid=339398) 	mul.f32 	%r152, %r14, %r131;
(EngineCore_DP0 pid=339398) 	.loc	1 220 48                        // quant_slide_tuned_Llama3.2-1B.py:220:48
(EngineCore_DP0 pid=339398) 	min.xorsign.abs.f32 	%r86, %r149, %r148;
(EngineCore_DP0 pid=339398) 	min.xorsign.abs.f32 	%r87, %r150, %r148;
(EngineCore_DP0 pid=339398) 	min.xorsign.abs.f32 	%r88, %r151, %r148;
(EngineCore_DP0 pid=339398) 	min.xorsign.abs.f32 	%r89, %r152, %r148;
(EngineCore_DP0 pid=339398) 	.loc	1 220 60                        // quant_slide_tuned_Llama3.2-1B.py:220:60
(EngineCore_DP0 pid=339398) 	// begin inline asm
(EngineCore_DP0 pid=339398) 	cvt.rn.satfinite.e4m3x2.f32  %rs58, %r87, %r86; 
(EngineCore_DP0 pid=339398) 
(EngineCore_DP0 pid=339398) 	// end inline asm
(EngineCore_DP0 pid=339398) 	shr.u16 	%rs66, %rs58, 8;
(EngineCore_DP0 pid=339398) 	// begin inline asm
(EngineCore_DP0 pid=339398) 	cvt.rn.satfinite.e4m3x2.f32  %rs59, %r89, %r88; 
(EngineCore_DP0 pid=339398) 
(EngineCore_DP0 pid=339398) 	// end inline asm
(EngineCore_DP0 pid=339398) 	shr.u16 	%rs67, %rs59, 8;
(EngineCore_DP0 pid=339398) 	.loc	1 221 27                        // quant_slide_tuned_Llama3.2-1B.py:221:27
(EngineCore_DP0 pid=339398) 	mul.f32 	%r153, %r14, %r134;
(EngineCore_DP0 pid=339398) 	mul.f32 	%r154, %r14, %r135;
(EngineCore_DP0 pid=339398) 	mul.f32 	%r155, %r14, %r136;
(EngineCore_DP0 pid=339398) 	mul.f32 	%r156, %r14, %r137;
(EngineCore_DP0 pid=339398) 	.loc	1 221 48                        // quant_slide_tuned_Llama3.2-1B.py:221:48
(EngineCore_DP0 pid=339398) 	min.xorsign.abs.f32 	%r90, %r153, %r148;
(EngineCore_DP0 pid=339398) 	min.xorsign.abs.f32 	%r91, %r154, %r148;
(EngineCore_DP0 pid=339398) 	min.xorsign.abs.f32 	%r92, %r155, %r148;
(EngineCore_DP0 pid=339398) 	min.xorsign.abs.f32 	%r93, %r156, %r148;
(EngineCore_DP0 pid=339398) 	.loc	1 221 60                        // quant_slide_tuned_Llama3.2-1B.py:221:60
(EngineCore_DP0 pid=339398) 	// begin inline asm
(EngineCore_DP0 pid=339398) 	cvt.rn.satfinite.e4m3x2.f32  %rs60, %r91, %r90; 
(EngineCore_DP0 pid=339398) 
(EngineCore_DP0 pid=339398) 	// end inline asm
(EngineCore_DP0 pid=339398) 	shr.u16 	%rs68, %rs60, 8;
(EngineCore_DP0 pid=339398) 	// begin inline asm
(EngineCore_DP0 pid=339398) 	cvt.rn.satfinite.e4m3x2.f32  %rs61, %r93, %r92; 
(EngineCore_DP0 pid=339398) 
(EngineCore_DP0 pid=339398) 	// end inline asm
(EngineCore_DP0 pid=339398) 	shr.u16 	%rs69, %rs61, 8;
(EngineCore_DP0 pid=339398) 	.loc	1 222 27                        // quant_slide_tuned_Llama3.2-1B.py:222:27
(EngineCore_DP0 pid=339398) 	mul.f32 	%r157, %r14, %r140;
(EngineCore_DP0 pid=339398) 	mul.f32 	%r158, %r14, %r141;
(EngineCore_DP0 pid=339398) 	mul.f32 	%r159, %r14, %r142;
(EngineCore_DP0 pid=339398) 	mul.f32 	%r160, %r14, %r143;
(EngineCore_DP0 pid=339398) 	.loc	1 222 48                        // quant_slide_tuned_Llama3.2-1B.py:222:48
(EngineCore_DP0 pid=339398) 	min.xorsign.abs.f32 	%r94, %r157, %r148;
(EngineCore_DP0 pid=339398) 	min.xorsign.abs.f32 	%r95, %r158, %r148;
(EngineCore_DP0 pid=339398) 	min.xorsign.abs.f32 	%r96, %r159, %r148;
(EngineCore_DP0 pid=339398) 	min.xorsign.abs.f32 	%r97, %r160, %r148;
(EngineCore_DP0 pid=339398) 	.loc	1 222 60                        // quant_slide_tuned_Llama3.2-1B.py:222:60
(EngineCore_DP0 pid=339398) 	// begin inline asm
(EngineCore_DP0 pid=339398) 	cvt.rn.satfinite.e4m3x2.f32  %rs62, %r95, %r94; 
(EngineCore_DP0 pid=339398) 
(EngineCore_DP0 pid=339398) 	// end inline asm
(EngineCore_DP0 pid=339398) 	shr.u16 	%rs70, %rs62, 8;
(EngineCore_DP0 pid=339398) 	// begin inline asm
(EngineCore_DP0 pid=339398) 	cvt.rn.satfinite.e4m3x2.f32  %rs63, %r97, %r96; 
(EngineCore_DP0 pid=339398) 
(EngineCore_DP0 pid=339398) 	// end inline asm
(EngineCore_DP0 pid=339398) 	shr.u16 	%rs71, %rs63, 8;
(EngineCore_DP0 pid=339398) 	.loc	1 224 45                        // quant_slide_tuned_Llama3.2-1B.py:224:45
(EngineCore_DP0 pid=339398) 	cvt.u32.u16 	%r161, %rs56;
(EngineCore_DP0 pid=339398) 	and.b32 	%r162, %r161, 255;
(EngineCore_DP0 pid=339398) 	cvt.u32.u16 	%r163, %rs64;
(EngineCore_DP0 pid=339398) 	cvt.u32.u16 	%r164, %rs57;
(EngineCore_DP0 pid=339398) 	and.b32 	%r165, %r164, 255;
(EngineCore_DP0 pid=339398) 	cvt.u32.u16 	%r166, %rs65;
(EngineCore_DP0 pid=339398) 	.loc	1 226 45                        // quant_slide_tuned_Llama3.2-1B.py:226:45
(EngineCore_DP0 pid=339398) 	cvt.u32.u16 	%r167, %rs60;
(EngineCore_DP0 pid=339398) 	and.b32 	%r168, %r167, 255;
(EngineCore_DP0 pid=339398) 	cvt.u32.u16 	%r169, %rs68;
(EngineCore_DP0 pid=339398) 	cvt.u32.u16 	%r170, %rs61;
(EngineCore_DP0 pid=339398) 	and.b32 	%r171, %r170, 255;
(EngineCore_DP0 pid=339398) 	cvt.u32.u16 	%r172, %rs69;
(EngineCore_DP0 pid=339398) 	.loc	1 227 45                        // quant_slide_tuned_Llama3.2-1B.py:227:45
(EngineCore_DP0 pid=339398) 	cvt.u32.u16 	%r173, %rs62;
(EngineCore_DP0 pid=339398) 	cvt.u32.u16 	%r174, %rs70;
(EngineCore_DP0 pid=339398) 	cvt.u32.u16 	%r175, %rs63;
(EngineCore_DP0 pid=339398) 	cvt.u32.u16 	%r176, %rs71;
(EngineCore_DP0 pid=339398) 	.loc	1 229 30                        // quant_slide_tuned_Llama3.2-1B.py:229:30
(EngineCore_DP0 pid=339398) 	and.b16 	%rs72, %rs58, 255;
(EngineCore_DP0 pid=339398) 	mul.wide.u16 	%r177, %rs72, 256;
(EngineCore_DP0 pid=339398) 	mul.wide.u16 	%r178, %rs66, 256;
(EngineCore_DP0 pid=339398) 	and.b16 	%rs73, %rs59, 255;
(EngineCore_DP0 pid=339398) 	mul.wide.u16 	%r179, %rs73, 256;
(EngineCore_DP0 pid=339398) 	mul.wide.u16 	%r180, %rs67, 256;
(EngineCore_DP0 pid=339398) 	.loc	1 229 24                        // quant_slide_tuned_Llama3.2-1B.py:229:24
(EngineCore_DP0 pid=339398) 	or.b32 	%r181, %r177, %r162;
(EngineCore_DP0 pid=339398) 	or.b32 	%r182, %r178, %r163;
(EngineCore_DP0 pid=339398) 	or.b32 	%r183, %r179, %r165;
(EngineCore_DP0 pid=339398) 	or.b32 	%r184, %r180, %r166;
(EngineCore_DP0 pid=339398) 	.loc	1 229 42                        // quant_slide_tuned_Llama3.2-1B.py:229:42
(EngineCore_DP0 pid=339398) 	shl.b32 	%r185, %r168, 16;
(EngineCore_DP0 pid=339398) 	shl.b32 	%r186, %r169, 16;
(EngineCore_DP0 pid=339398) 	shl.b32 	%r187, %r171, 16;
(EngineCore_DP0 pid=339398) 	shl.b32 	%r188, %r172, 16;
(EngineCore_DP0 pid=339398) 	.loc	1 229 36                        // quant_slide_tuned_Llama3.2-1B.py:229:36
(EngineCore_DP0 pid=339398) 	or.b32 	%r189, %r185, %r181;
(EngineCore_DP0 pid=339398) 	or.b32 	%r190, %r186, %r182;
(EngineCore_DP0 pid=339398) 	or.b32 	%r191, %r187, %r183;
(EngineCore_DP0 pid=339398) 	or.b32 	%r192, %r188, %r184;
(EngineCore_DP0 pid=339398) 	.loc	1 229 55                        // quant_slide_tuned_Llama3.2-1B.py:229:55
(EngineCore_DP0 pid=339398) 	shl.b32 	%r193, %r173, 24;
(EngineCore_DP0 pid=339398) 	shl.b32 	%r194, %r174, 24;
(EngineCore_DP0 pid=339398) 	shl.b32 	%r195, %r175, 24;
(EngineCore_DP0 pid=339398) 	shl.b32 	%r196, %r176, 24;
(EngineCore_DP0 pid=339398) 	.loc	1 229 49                        // quant_slide_tuned_Llama3.2-1B.py:229:49
(EngineCore_DP0 pid=339398) 	or.b32 	%r98, %r193, %r189;
(EngineCore_DP0 pid=339398) 	or.b32 	%r99, %r194, %r190;
(EngineCore_DP0 pid=339398) 	or.b32 	%r100, %r195, %r191;
(EngineCore_DP0 pid=339398) 	or.b32 	%r101, %r196, %r192;
(EngineCore_DP0 pid=339398) 	.loc	1 230 29                        // quant_slide_tuned_Llama3.2-1B.py:230:29
(EngineCore_DP0 pid=339398) 	mad.wide.s32 	%rd24, %r102, 4, %rd2;
(EngineCore_DP0 pid=339398) 	add.s64 	%rd25, %rd24, 8;
(EngineCore_DP0 pid=339398) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-1B.py:230:39
(EngineCore_DP0 pid=339398) 	// begin inline asm
(EngineCore_DP0 pid=339398) 	@%p25 st.global.v2.b32 [ %rd24 + 0 ], { %r98, %r99 };
(EngineCore_DP0 pid=339398) 	// end inline asm
(EngineCore_DP0 pid=339398) 	// begin inline asm
(EngineCore_DP0 pid=339398) 	@%p26 st.global.v2.b32 [ %rd25 + 0 ], { %r100, %r101 };
(EngineCore_DP0 pid=339398) 	// end inline asm
(EngineCore_DP0 pid=339398) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=339398) 	add.s32 	%r200, %r200, 2048;
(EngineCore_DP0 pid=339398) 	setp.lt.s32 	%p43, %r200, %r15;
(EngineCore_DP0 pid=339398) 	@%p43 bra 	$L__BB0_6;
(EngineCore_DP0 pid=339398) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=339398) 	.loc	1 201 4                         // quant_slide_tuned_Llama3.2-1B.py:201:4
(EngineCore_DP0 pid=339398) 	ret;
(EngineCore_DP0 pid=339398) $L__tmp3:
(EngineCore_DP0 pid=339398) $L__func_end0:
(EngineCore_DP0 pid=339398)                                         // -- End function
(EngineCore_DP0 pid=339398) }
(EngineCore_DP0 pid=339398) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=339398) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=339398) 	.section	.debug_abbrev
(EngineCore_DP0 pid=339398) 	{
(EngineCore_DP0 pid=339398) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=339398) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=339398) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=339398) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=339398) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=339398) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=339398) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=339398) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=339398) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=339398) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=339398) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=339398) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=339398) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=339398) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=339398) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=339398) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=339398) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=339398) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=339398) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=339398) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=339398) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=339398) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=339398) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=339398) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=339398) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=339398) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=339398) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=339398) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=339398) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=339398) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=339398) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=339398) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=339398) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=339398) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=339398) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=339398) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=339398) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=339398) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=339398) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=339398) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=339398) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=339398) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=339398) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=339398) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=339398) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=339398) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=339398) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=339398) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=339398) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=339398) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=339398) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=339398) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=339398) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=339398) 	}
(EngineCore_DP0 pid=339398) 	.section	.debug_info
(EngineCore_DP0 pid=339398) 	{
(EngineCore_DP0 pid=339398) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=339398) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=339398) .b8 0
(EngineCore_DP0 pid=339398) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=339398) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=339398) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=339398) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=339398) .b8 114
(EngineCore_DP0 pid=339398) .b8 105
(EngineCore_DP0 pid=339398) .b8 116
(EngineCore_DP0 pid=339398) .b8 111
(EngineCore_DP0 pid=339398) .b8 110
(EngineCore_DP0 pid=339398) .b8 0
(EngineCore_DP0 pid=339398) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=339398) .b8 0
(EngineCore_DP0 pid=339398) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=339398) .b8 117
(EngineCore_DP0 pid=339398) .b8 97
(EngineCore_DP0 pid=339398) .b8 110
(EngineCore_DP0 pid=339398) .b8 116
(EngineCore_DP0 pid=339398) .b8 95
(EngineCore_DP0 pid=339398) .b8 115
(EngineCore_DP0 pid=339398) .b8 108
(EngineCore_DP0 pid=339398) .b8 105
(EngineCore_DP0 pid=339398) .b8 100
(EngineCore_DP0 pid=339398) .b8 101
(EngineCore_DP0 pid=339398) .b8 95
(EngineCore_DP0 pid=339398) .b8 116
(EngineCore_DP0 pid=339398) .b8 117
(EngineCore_DP0 pid=339398) .b8 110
(EngineCore_DP0 pid=339398) .b8 101
(EngineCore_DP0 pid=339398) .b8 100
(EngineCore_DP0 pid=339398) .b8 95
(EngineCore_DP0 pid=339398) .b8 76
(EngineCore_DP0 pid=339398) .b8 108
(EngineCore_DP0 pid=339398) .b8 97
(EngineCore_DP0 pid=339398) .b8 109
(EngineCore_DP0 pid=339398) .b8 97
(EngineCore_DP0 pid=339398) .b8 51
(EngineCore_DP0 pid=339398) .b8 46
(EngineCore_DP0 pid=339398) .b8 50
(EngineCore_DP0 pid=339398) .b8 45
(EngineCore_DP0 pid=339398) .b8 49
(EngineCore_DP0 pid=339398) .b8 66
(EngineCore_DP0 pid=339398) .b8 46
(EngineCore_DP0 pid=339398) .b8 112
(EngineCore_DP0 pid=339398) .b8 121
(EngineCore_DP0 pid=339398) .b8 0
(EngineCore_DP0 pid=339398) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=339398) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=339398) .b8 114
(EngineCore_DP0 pid=339398) .b8 111
(EngineCore_DP0 pid=339398) .b8 111
(EngineCore_DP0 pid=339398) .b8 116
(EngineCore_DP0 pid=339398) .b8 47
(EngineCore_DP0 pid=339398) .b8 118
(EngineCore_DP0 pid=339398) .b8 108
(EngineCore_DP0 pid=339398) .b8 108
(EngineCore_DP0 pid=339398) .b8 109
(EngineCore_DP0 pid=339398) .b8 98
(EngineCore_DP0 pid=339398) .b8 101
(EngineCore_DP0 pid=339398) .b8 110
(EngineCore_DP0 pid=339398) .b8 99
(EngineCore_DP0 pid=339398) .b8 104
(EngineCore_DP0 pid=339398) .b8 47
(EngineCore_DP0 pid=339398) .b8 115
(EngineCore_DP0 pid=339398) .b8 108
(EngineCore_DP0 pid=339398) .b8 105
(EngineCore_DP0 pid=339398) .b8 100
(EngineCore_DP0 pid=339398) .b8 101
(EngineCore_DP0 pid=339398) .b8 115
(EngineCore_DP0 pid=339398) .b8 112
(EngineCore_DP0 pid=339398) .b8 97
(EngineCore_DP0 pid=339398) .b8 114
(EngineCore_DP0 pid=339398) .b8 115
(EngineCore_DP0 pid=339398) .b8 101
(EngineCore_DP0 pid=339398) .b8 47
(EngineCore_DP0 pid=339398) .b8 99
(EngineCore_DP0 pid=339398) .b8 115
(EngineCore_DP0 pid=339398) .b8 114
(EngineCore_DP0 pid=339398) .b8 99
(EngineCore_DP0 pid=339398) .b8 47
(EngineCore_DP0 pid=339398) .b8 102
(EngineCore_DP0 pid=339398) .b8 117
(EngineCore_DP0 pid=339398) .b8 115
(EngineCore_DP0 pid=339398) .b8 101
(EngineCore_DP0 pid=339398) .b8 100
(EngineCore_DP0 pid=339398) .b8 95
(EngineCore_DP0 pid=339398) .b8 113
(EngineCore_DP0 pid=339398) .b8 117
(EngineCore_DP0 pid=339398) .b8 97
(EngineCore_DP0 pid=339398) .b8 110
(EngineCore_DP0 pid=339398) .b8 116
(EngineCore_DP0 pid=339398) .b8 95
(EngineCore_DP0 pid=339398) .b8 115
(EngineCore_DP0 pid=339398) .b8 108
(EngineCore_DP0 pid=339398) .b8 105
(EngineCore_DP0 pid=339398) .b8 100
(EngineCore_DP0 pid=339398) .b8 101
(EngineCore_DP0 pid=339398) .b8 95
(EngineCore_DP0 pid=339398) .b8 116
(EngineCore_DP0 pid=339398) .b8 114
(EngineCore_DP0 pid=339398) .b8 105
(EngineCore_DP0 pid=339398) .b8 116
(EngineCore_DP0 pid=339398) .b8 111
(EngineCore_DP0 pid=339398) .b8 110
(EngineCore_DP0 pid=339398) .b8 47
(EngineCore_DP0 pid=339398) .b8 98
(EngineCore_DP0 pid=339398) .b8 117
(EngineCore_DP0 pid=339398) .b8 105
(EngineCore_DP0 pid=339398) .b8 108
(EngineCore_DP0 pid=339398) .b8 100
(EngineCore_DP0 pid=339398) .b8 47
(EngineCore_DP0 pid=339398) .b8 71
(EngineCore_DP0 pid=339398) .b8 66
(EngineCore_DP0 pid=339398) .b8 49
(EngineCore_DP0 pid=339398) .b8 48
(EngineCore_DP0 pid=339398) .b8 95
(EngineCore_DP0 pid=339398) .b8 99
(EngineCore_DP0 pid=339398) .b8 99
(EngineCore_DP0 pid=339398) .b8 49
(EngineCore_DP0 pid=339398) .b8 50
(EngineCore_DP0 pid=339398) .b8 49
(EngineCore_DP0 pid=339398) .b8 95
(EngineCore_DP0 pid=339398) .b8 112
(EngineCore_DP0 pid=339398) .b8 121
(EngineCore_DP0 pid=339398) .b8 51
(EngineCore_DP0 pid=339398) .b8 49
(EngineCore_DP0 pid=339398) .b8 50
(EngineCore_DP0 pid=339398) .b8 95
(EngineCore_DP0 pid=339398) .b8 99
(EngineCore_DP0 pid=339398) .b8 117
(EngineCore_DP0 pid=339398) .b8 49
(EngineCore_DP0 pid=339398) .b8 50
(EngineCore_DP0 pid=339398) .b8 57
(EngineCore_DP0 pid=339398) .b8 95
(EngineCore_DP0 pid=339398) .b8 97
(EngineCore_DP0 pid=339398) .b8 97
(EngineCore_DP0 pid=339398) .b8 114
(EngineCore_DP0 pid=339398) .b8 99
(EngineCore_DP0 pid=339398) .b8 104
(EngineCore_DP0 pid=339398) .b8 54
(EngineCore_DP0 pid=339398) .b8 52
(EngineCore_DP0 pid=339398) .b8 0
(EngineCore_DP0 pid=339398) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=339398) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=339398) .b8 113
(EngineCore_DP0 pid=339398) .b8 117
(EngineCore_DP0 pid=339398) .b8 97
(EngineCore_DP0 pid=339398) .b8 110
(EngineCore_DP0 pid=339398) .b8 116
(EngineCore_DP0 pid=339398) .b8 95
(EngineCore_DP0 pid=339398) .b8 115
(EngineCore_DP0 pid=339398) .b8 108
(EngineCore_DP0 pid=339398) .b8 105
(EngineCore_DP0 pid=339398) .b8 100
(EngineCore_DP0 pid=339398) .b8 101
(EngineCore_DP0 pid=339398) .b8 95
(EngineCore_DP0 pid=339398) .b8 102
(EngineCore_DP0 pid=339398) .b8 112
(EngineCore_DP0 pid=339398) .b8 56
(EngineCore_DP0 pid=339398) .b8 95
(EngineCore_DP0 pid=339398) .b8 107
(EngineCore_DP0 pid=339398) .b8 101
(EngineCore_DP0 pid=339398) .b8 114
(EngineCore_DP0 pid=339398) .b8 110
(EngineCore_DP0 pid=339398) .b8 101
(EngineCore_DP0 pid=339398) .b8 108
(EngineCore_DP0 pid=339398) .b8 0
(EngineCore_DP0 pid=339398) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=339398) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=339398) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=339398) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=339398) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=339398) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=339398) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=339398) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=339398) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=339398) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=339398) .b8 191                                 // DW_AT_call_line
(EngineCore_DP0 pid=339398) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=339398) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=339398) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=339398) 	}
(EngineCore_DP0 pid=339398) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=339398) 
(EngineCore_DP0 pid=339398) ================================================================
(EngineCore_DP0 pid=339398) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=339398) 
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpjy2wgnr8.ptx', '-o', '/tmp/tmpjy2wgnr8.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866] 
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866] 
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866] 
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpjy2wgnr8.ptx -o /tmp/tmpjy2wgnr8.ptx.o
(EngineCore_DP0 pid=339398) ERROR 01-25 19:18:19 [core.py:866] 

STDERR:
[2026-01-25 19:18:04] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:18:04] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:18:04] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:18:04] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:18:04] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:18:04] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:18:04] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:18:04] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:18:04] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:18:04] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:18:04] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:18:04] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:18:04] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:18:04] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:18:07] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:18:07] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:18:07] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:18:07] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:18:07] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:18:07] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:18:07] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:18:07] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:18:07] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:18:07] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:18:07] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:18:07] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:18:07] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:18:07] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=339398) [2026-01-25 19:18:08] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=339398) [2026-01-25 19:18:08] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=339398) [2026-01-25 19:18:08] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=339398) [2026-01-25 19:18:08] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=339398) [2026-01-25 19:18:08] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=339398) [2026-01-25 19:18:08] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=339398) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=339398) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.21s/it]
(EngineCore_DP0 pid=339398) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.21s/it]
(EngineCore_DP0 pid=339398) 
(EngineCore_DP0 pid=339398) [2026-01-25 19:18:18] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=339398) [2026-01-25 19:18:18] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5308416 bytes
(EngineCore_DP0 pid=339398) [2026-01-25 19:18:18] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=339398) [2026-01-25 19:18:18] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3538944 bytes
(EngineCore_DP0 pid=339398) [2026-01-25 19:18:18] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=339398) [2026-01-25 19:18:18] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 28311552 bytes
(EngineCore_DP0 pid=339398) [2026-01-25 19:18:18] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=339398) [2026-01-25 19:18:18] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14024704 bytes
(EngineCore_DP0 pid=339398) Process EngineCore_DP0:
(EngineCore_DP0 pid=339398) Traceback (most recent call last):
(EngineCore_DP0 pid=339398)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=339398)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=339398)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=339398)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=339398) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpjy2wgnr8.ptx', '-o', '/tmp/tmpjy2wgnr8.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=339398) 
(EngineCore_DP0 pid=339398) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=339398) 
(EngineCore_DP0 pid=339398) Traceback (most recent call last):
(EngineCore_DP0 pid=339398)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=339398)     self.run()
(EngineCore_DP0 pid=339398)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=339398)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=339398)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=339398)     raise e
(EngineCore_DP0 pid=339398)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=339398)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=339398)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=339398)     super().__init__(
(EngineCore_DP0 pid=339398)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=339398)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=339398)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=339398)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=339398)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=339398)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=339398)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=339398)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=339398)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=339398)     return func(*args, **kwargs)
(EngineCore_DP0 pid=339398)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=339398)     return func(*args, **kwargs)
(EngineCore_DP0 pid=339398)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=339398)     self.model_runner.profile_run()
(EngineCore_DP0 pid=339398)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=339398)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=339398)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=339398)     return func(*args, **kwargs)
(EngineCore_DP0 pid=339398)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=339398)     outputs = self.model(
(EngineCore_DP0 pid=339398)               ^^^^^^^^^^^
(EngineCore_DP0 pid=339398)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=339398)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=339398)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=339398)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=339398)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=339398)     model_output = self.model(
(EngineCore_DP0 pid=339398)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=339398)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=339398)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=339398)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=339398)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=339398)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=339398)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=339398)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=339398)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=339398)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=339398)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=339398)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=339398)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=339398)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=339398)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=339398)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=339398)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=339398)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=339398)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=339398)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=339398)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=339398)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=339398)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=339398)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=339398)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=339398)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=339398)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=339398)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=339398)     return self._linear_fn(
(EngineCore_DP0 pid=339398)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=339398)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=339398)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=339398)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=339398)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=339398)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=339398)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=339398)     return fn(input, L)
(EngineCore_DP0 pid=339398)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=339398)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=339398)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=339398)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=339398)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=339398)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=339398)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=339398)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=339398)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=339398)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=339398)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=339398)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=339398)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=339398)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339398)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=339398)     raise PTXASError(error)
(EngineCore_DP0 pid=339398) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=339398) `ptxas` stderr:
(EngineCore_DP0 pid=339398) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=339398) 
(EngineCore_DP0 pid=339398) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpjy2wgnr8.ptx -o /tmp/tmpjy2wgnr8.ptx.o
(EngineCore_DP0 pid=339398) 
[rank0]:[W125 19:18:19.625903908 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=8192

========== M=16384 ==========
Time: 2026-01-25 19:18:20
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-FP8_M16384.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:18:30 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:18:30 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=339943) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=339943) 
(EngineCore_DP0 pid=339943) 
(EngineCore_DP0 pid=339943) ================================================================
(EngineCore_DP0 pid=339943) Internal Triton PTX codegen error
(EngineCore_DP0 pid=339943) `ptxas` stderr:
(EngineCore_DP0 pid=339943) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=339943) 
(EngineCore_DP0 pid=339943) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmphwmi818q.ptx -o /tmp/tmphwmi818q.ptx.o
(EngineCore_DP0 pid=339943) 
(EngineCore_DP0 pid=339943) 
(EngineCore_DP0 pid=339943) //
(EngineCore_DP0 pid=339943) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=339943) //
(EngineCore_DP0 pid=339943) 
(EngineCore_DP0 pid=339943) .version 8.7
(EngineCore_DP0 pid=339943) .target sm_121a
(EngineCore_DP0 pid=339943) .address_size 64
(EngineCore_DP0 pid=339943) 
(EngineCore_DP0 pid=339943) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=339943) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=339943)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=339943) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=339943) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=339943) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=339943) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=339943) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=339943) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=339943) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=339943) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=339943) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=339943) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=339943) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=339943) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=339943) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=339943) )
(EngineCore_DP0 pid=339943) .reqntid 512
(EngineCore_DP0 pid=339943) {
(EngineCore_DP0 pid=339943) 	.reg .pred 	%p<45>;
(EngineCore_DP0 pid=339943) 	.reg .b16 	%rs<74>;
(EngineCore_DP0 pid=339943) 	.reg .b32 	%r<201>;
(EngineCore_DP0 pid=339943) 	.reg .b64 	%rd<26>;
(EngineCore_DP0 pid=339943) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=339943) $L__func_begin0:
(EngineCore_DP0 pid=339943) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=339943) 
(EngineCore_DP0 pid=339943) // %bb.0:
(EngineCore_DP0 pid=339943) 	ld.param.b32 	%r29, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=339943) 	ld.param.b32 	%r28, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=339943) 	ld.param.b32 	%r27, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=339943) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=339943) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=339943) $L__tmp0:
(EngineCore_DP0 pid=339943) 	.loc	1 177 24                        // quant_slide_tuned_Llama3.2-1B.py:177:24
(EngineCore_DP0 pid=339943) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=339943) 	ld.param.b32 	%r31, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=339943) 	.loc	1 182 26                        // quant_slide_tuned_Llama3.2-1B.py:182:26
(EngineCore_DP0 pid=339943) 	mul.lo.s32 	%r32, %r31, %r1;
(EngineCore_DP0 pid=339943) 	.loc	1 182 20                        // quant_slide_tuned_Llama3.2-1B.py:182:20
(EngineCore_DP0 pid=339943) 	mad.wide.s32 	%rd1, %r32, 2, %rd4;
(EngineCore_DP0 pid=339943) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=339943) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=339943) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=339943) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=339943) 	setp.lt.s32 	%p1, %r28, 1;
(EngineCore_DP0 pid=339943) 	mov.b32 	%r199, 0f2B8CBCCC;
(EngineCore_DP0 pid=339943) 	setp.eq.b32 	%p44, %r2, 0;
(EngineCore_DP0 pid=339943) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=339943) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=339943) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=339943) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=339943) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=339943) 	shr.u32 	%r41, %r2, 3;
(EngineCore_DP0 pid=339943) 	and.b32 	%r42, %r41, 60;
(EngineCore_DP0 pid=339943) 	mov.b32 	%r43, global_smem;
(EngineCore_DP0 pid=339943) 	add.s32 	%r53, %r43, %r42;
(EngineCore_DP0 pid=339943) 	shl.b32 	%r44, %r2, 2;
(EngineCore_DP0 pid=339943) 	add.s32 	%r56, %r43, %r44;
(EngineCore_DP0 pid=339943) 	mov.b32 	%r49, 0;
(EngineCore_DP0 pid=339943) 	mov.b32 	%r197, 0f00000000;
(EngineCore_DP0 pid=339943) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=339943) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=339943) 	mov.b32 	%r198, %r49;
(EngineCore_DP0 pid=339943) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=339943) 	.loc	1 189 22                        // quant_slide_tuned_Llama3.2-1B.py:189:22
(EngineCore_DP0 pid=339943) 	add.s32 	%r59, %r4, %r198;
(EngineCore_DP0 pid=339943) 	setp.lt.s32 	%p2, %r59, %r27;
(EngineCore_DP0 pid=339943) 	.loc	1 190 29                        // quant_slide_tuned_Llama3.2-1B.py:190:29
(EngineCore_DP0 pid=339943) 	mad.wide.s32 	%rd6, %r59, 2, %rd1;
(EngineCore_DP0 pid=339943) 	.loc	1 190 21                        // quant_slide_tuned_Llama3.2-1B.py:190:21
(EngineCore_DP0 pid=339943) 	// begin inline asm
(EngineCore_DP0 pid=339943) 	mov.u32 %r45, %r49;
(EngineCore_DP0 pid=339943) 	mov.u32 %r46, %r49;
(EngineCore_DP0 pid=339943) 	mov.u32 %r47, %r49;
(EngineCore_DP0 pid=339943) 	mov.u32 %r48, %r49;
(EngineCore_DP0 pid=339943) 	@%p2 ld.global.v4.b32 { %r45, %r46, %r47, %r48 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=339943) 	// end inline asm
(EngineCore_DP0 pid=339943) 	mov.b32 	{%rs1, %rs2}, %r45;
(EngineCore_DP0 pid=339943) 	mov.b32 	{%rs3, %rs4}, %r46;
(EngineCore_DP0 pid=339943) 	mov.b32 	{%rs5, %rs6}, %r47;
(EngineCore_DP0 pid=339943) 	mov.b32 	{%rs7, %rs8}, %r48;
(EngineCore_DP0 pid=339943) 	.loc	1 191 50                        // quant_slide_tuned_Llama3.2-1B.py:191:50
(EngineCore_DP0 pid=339943) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=339943) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=339943) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=339943) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=339943) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=339943) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=339943) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=339943) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=339943) $L__tmp1:
(EngineCore_DP0 pid=339943) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=339943) 	bar.sync 	0;
(EngineCore_DP0 pid=339943) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=339943) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=339943) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=339943) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=339943) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=339943) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=339943) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=339943) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=339943) 	cvt.f32.bf16 	%r60, %rs23;
(EngineCore_DP0 pid=339943) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=339943) 	shfl.sync.bfly.b32 	%r61, %r60, 16, 31, -1;
(EngineCore_DP0 pid=339943) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=339943) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=339943) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=339943) 	shfl.sync.bfly.b32 	%r63, %r62, 8, 31, -1;
(EngineCore_DP0 pid=339943) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=339943) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=339943) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=339943) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=339943) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=339943) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=339943) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=339943) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=339943) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=339943) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=339943) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=339943) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=339943) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=339943) 	max.f32 	%r54, %r68, %r69;
(EngineCore_DP0 pid=339943) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=339943) 	// begin inline asm
(EngineCore_DP0 pid=339943) 	@%p3 st.shared.b32 [ %r53 + 0 ], %r54;
(EngineCore_DP0 pid=339943) 	// end inline asm
(EngineCore_DP0 pid=339943) 	bar.sync 	0;
(EngineCore_DP0 pid=339943) 	// begin inline asm
(EngineCore_DP0 pid=339943) 	@%p4 ld.shared.b32 %r55, [ %r56 + 0 ];
(EngineCore_DP0 pid=339943) 	// end inline asm
(EngineCore_DP0 pid=339943) 	shfl.sync.bfly.b32 	%r70, %r55, 8, 31, -1;
(EngineCore_DP0 pid=339943) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=339943) 	max.f32 	%r71, %r55, %r70;
(EngineCore_DP0 pid=339943) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=339943) 	shfl.sync.bfly.b32 	%r72, %r71, 4, 31, -1;
(EngineCore_DP0 pid=339943) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=339943) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=339943) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=339943) 	shfl.sync.bfly.b32 	%r74, %r73, 2, 31, -1;
(EngineCore_DP0 pid=339943) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=339943) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=339943) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=339943) 	shfl.sync.bfly.b32 	%r76, %r75, 1, 31, -1;
(EngineCore_DP0 pid=339943) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=339943) 	max.f32 	%r58, %r75, %r76;
(EngineCore_DP0 pid=339943) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=339943) 	// begin inline asm
(EngineCore_DP0 pid=339943) 	@%p44 st.shared.b32 [ %r56 + 0 ], %r58;
(EngineCore_DP0 pid=339943) 	// end inline asm
(EngineCore_DP0 pid=339943) 	bar.sync 	0;
(EngineCore_DP0 pid=339943) 	ld.shared.b32 	%r77, [global_smem];
(EngineCore_DP0 pid=339943) $L__tmp2:
(EngineCore_DP0 pid=339943) 	.loc	1 191 36                        // quant_slide_tuned_Llama3.2-1B.py:191:36
(EngineCore_DP0 pid=339943) 	max.f32 	%r197, %r197, %r77;
(EngineCore_DP0 pid=339943) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=339943) 	add.s32 	%r198, %r198, 4096;
(EngineCore_DP0 pid=339943) 	setp.lt.s32 	%p6, %r198, %r28;
(EngineCore_DP0 pid=339943) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=339943) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=339943) 	.loc	1 193 32                        // quant_slide_tuned_Llama3.2-1B.py:193:32
(EngineCore_DP0 pid=339943) 	max.f32 	%r199, %r197, 0f2B8CBCCC;
(EngineCore_DP0 pid=339943) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=339943) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=339943) 	mov.b32 	%r79, 0f43E00000;
(EngineCore_DP0 pid=339943) 	.loc	1 194 32                        // quant_slide_tuned_Llama3.2-1B.py:194:32
(EngineCore_DP0 pid=339943) 	div.full.f32 	%r80, %r199, %r79;
(EngineCore_DP0 pid=339943) 	.loc	1 194 41                        // quant_slide_tuned_Llama3.2-1B.py:194:41
(EngineCore_DP0 pid=339943) 	max.f32 	%r78, %r80, 0f36924925;
(EngineCore_DP0 pid=339943) 	.loc	1 196 25                        // quant_slide_tuned_Llama3.2-1B.py:196:25
(EngineCore_DP0 pid=339943) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=339943) 	.loc	1 196 30                        // quant_slide_tuned_Llama3.2-1B.py:196:30
(EngineCore_DP0 pid=339943) 	// begin inline asm
(EngineCore_DP0 pid=339943) 	@%p44 st.global.b32 [ %rd7 + 0 ], { %r78 };
(EngineCore_DP0 pid=339943) 	// end inline asm
(EngineCore_DP0 pid=339943) 	.loc	1 199 29                        // quant_slide_tuned_Llama3.2-1B.py:199:29
(EngineCore_DP0 pid=339943) 	shl.b32 	%r15, %r29, 1;
(EngineCore_DP0 pid=339943) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=339943) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=339943) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=339943) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=339943) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=339943) 	ld.param.b32 	%r33, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=339943) 	shr.s32 	%r34, %r33, 31;
(EngineCore_DP0 pid=339943) 	shr.u32 	%r35, %r34, 30;
(EngineCore_DP0 pid=339943) 	add.s32 	%r36, %r33, %r35;
(EngineCore_DP0 pid=339943) 	shr.s32 	%r37, %r36, 2;
(EngineCore_DP0 pid=339943) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=339943) 	mul.lo.s32 	%r38, %r37, %r1;
(EngineCore_DP0 pid=339943) 	mad.wide.s32 	%rd2, %r38, 4, %rd5;
(EngineCore_DP0 pid=339943) 	div.full.f32 	%r14, %r79, %r199;
(EngineCore_DP0 pid=339943) 	shl.b32 	%r16, %r3, 2;
(EngineCore_DP0 pid=339943) 	mov.b32 	%r200, 0;
(EngineCore_DP0 pid=339943) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=339943)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=339943) 	.loc	1 202 31                        // quant_slide_tuned_Llama3.2-1B.py:202:31
(EngineCore_DP0 pid=339943) 	add.s32 	%r102, %r16, %r200;
(EngineCore_DP0 pid=339943) 	add.s32 	%r103, %r200, 1;
(EngineCore_DP0 pid=339943) 	.loc	1 203 30                        // quant_slide_tuned_Llama3.2-1B.py:203:30
(EngineCore_DP0 pid=339943) 	add.s32 	%r104, %r102, 2;
(EngineCore_DP0 pid=339943) 	setp.lt.s32 	%p25, %r102, %r15;
(EngineCore_DP0 pid=339943) 	setp.lt.s32 	%p26, %r104, %r15;
(EngineCore_DP0 pid=339943) 	.loc	1 206 24                        // quant_slide_tuned_Llama3.2-1B.py:206:24
(EngineCore_DP0 pid=339943) 	shr.u32 	%r105, %r102, 1;
(EngineCore_DP0 pid=339943) 	shr.u32 	%r106, %r104, 1;
(EngineCore_DP0 pid=339943) 	.loc	1 207 23                        // quant_slide_tuned_Llama3.2-1B.py:207:23
(EngineCore_DP0 pid=339943) 	shr.u32 	%r107, %r103, 31;
(EngineCore_DP0 pid=339943) 	add.s32 	%r108, %r103, %r107;
(EngineCore_DP0 pid=339943) 	and.b32 	%r109, %r108, 2147483646;
(EngineCore_DP0 pid=339943) 	sub.s32 	%r110, %r103, %r109;
(EngineCore_DP0 pid=339943) 	.loc	1 208 30                        // quant_slide_tuned_Llama3.2-1B.py:208:30
(EngineCore_DP0 pid=339943) 	shl.b32 	%r111, %r110, 1;
(EngineCore_DP0 pid=339943) 	.loc	1 208 22                        // quant_slide_tuned_Llama3.2-1B.py:208:22
(EngineCore_DP0 pid=339943) 	mul.lo.s32 	%r112, %r105, 6;
(EngineCore_DP0 pid=339943) 	mul.lo.s32 	%r113, %r106, 6;
(EngineCore_DP0 pid=339943) 	.loc	1 208 26                        // quant_slide_tuned_Llama3.2-1B.py:208:26
(EngineCore_DP0 pid=339943) 	add.s32 	%r114, %r112, %r111;
(EngineCore_DP0 pid=339943) 	add.s32 	%r115, %r113, %r111;
(EngineCore_DP0 pid=339943) 	.loc	1 211 53                        // quant_slide_tuned_Llama3.2-1B.py:211:53
(EngineCore_DP0 pid=339943) 	setp.lt.s32 	%p27, %r112, %r27;
(EngineCore_DP0 pid=339943) 	setp.lt.s32 	%p28, %r114, %r27;
(EngineCore_DP0 pid=339943) 	setp.lt.s32 	%p29, %r113, %r27;
(EngineCore_DP0 pid=339943) 	setp.lt.s32 	%p30, %r115, %r27;
(EngineCore_DP0 pid=339943) 	.loc	1 211 37                        // quant_slide_tuned_Llama3.2-1B.py:211:37
(EngineCore_DP0 pid=339943) 	and.pred 	%p9, %p25, %p27;
(EngineCore_DP0 pid=339943) 	and.pred 	%p10, %p25, %p28;
(EngineCore_DP0 pid=339943) 	and.pred 	%p11, %p26, %p29;
(EngineCore_DP0 pid=339943) 	and.pred 	%p12, %p26, %p30;
(EngineCore_DP0 pid=339943) 	.loc	1 210 29                        // quant_slide_tuned_Llama3.2-1B.py:210:29
(EngineCore_DP0 pid=339943) 	mad.wide.s32 	%rd8, %r112, 2, %rd1;
(EngineCore_DP0 pid=339943) 	mad.wide.s32 	%rd9, %r114, 2, %rd1;
(EngineCore_DP0 pid=339943) 	mad.wide.s32 	%rd10, %r113, 2, %rd1;
(EngineCore_DP0 pid=339943) 	mad.wide.s32 	%rd11, %r115, 2, %rd1;
(EngineCore_DP0 pid=339943) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=339943) 	.loc	1 210 21                        // quant_slide_tuned_Llama3.2-1B.py:210:21
(EngineCore_DP0 pid=339943) 	// begin inline asm
(EngineCore_DP0 pid=339943) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=339943) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=339943) 	// end inline asm
(EngineCore_DP0 pid=339943) 	// begin inline asm
(EngineCore_DP0 pid=339943) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=339943) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=339943) 	// end inline asm
(EngineCore_DP0 pid=339943) 	// begin inline asm
(EngineCore_DP0 pid=339943) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=339943) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=339943) 	// end inline asm
(EngineCore_DP0 pid=339943) 	// begin inline asm
(EngineCore_DP0 pid=339943) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=339943) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=339943) 	// end inline asm
(EngineCore_DP0 pid=339943) 	.loc	1 211 79                        // quant_slide_tuned_Llama3.2-1B.py:211:79
(EngineCore_DP0 pid=339943) 	cvt.f32.bf16 	%r116, %rs24;
(EngineCore_DP0 pid=339943) 	cvt.f32.bf16 	%r117, %rs26;
(EngineCore_DP0 pid=339943) 	cvt.f32.bf16 	%r118, %rs28;
(EngineCore_DP0 pid=339943) 	cvt.f32.bf16 	%r119, %rs30;
(EngineCore_DP0 pid=339943) 	.loc	1 217 48                        // quant_slide_tuned_Llama3.2-1B.py:217:48
(EngineCore_DP0 pid=339943) 	or.b32 	%r120, %r114, 1;
(EngineCore_DP0 pid=339943) 	or.b32 	%r121, %r115, 1;
(EngineCore_DP0 pid=339943) 	or.b32 	%r122, %r115, 2;
(EngineCore_DP0 pid=339943) 	or.b32 	%r123, %r115, 3;
(EngineCore_DP0 pid=339943) 	or.b32 	%r124, %r112, 1;
(EngineCore_DP0 pid=339943) 	or.b32 	%r125, %r113, 1;
(EngineCore_DP0 pid=339943) 	or.b32 	%r126, %r112, 2;
(EngineCore_DP0 pid=339943) 	or.b32 	%r127, %r112, 3;
(EngineCore_DP0 pid=339943) 	.loc	1 217 53                        // quant_slide_tuned_Llama3.2-1B.py:217:53
(EngineCore_DP0 pid=339943) 	setp.lt.s32 	%p31, %r123, %r27;
(EngineCore_DP0 pid=339943) 	setp.lt.s32 	%p32, %r122, %r27;
(EngineCore_DP0 pid=339943) 	setp.lt.s32 	%p33, %r121, %r27;
(EngineCore_DP0 pid=339943) 	setp.lt.s32 	%p34, %r120, %r27;
(EngineCore_DP0 pid=339943) 	setp.lt.s32 	%p35, %r127, %r27;
(EngineCore_DP0 pid=339943) 	setp.lt.s32 	%p36, %r126, %r27;
(EngineCore_DP0 pid=339943) 	setp.lt.s32 	%p37, %r125, %r27;
(EngineCore_DP0 pid=339943) 	setp.lt.s32 	%p38, %r124, %r27;
(EngineCore_DP0 pid=339943) 	.loc	1 213 37                        // quant_slide_tuned_Llama3.2-1B.py:213:37
(EngineCore_DP0 pid=339943) 	and.pred 	%p13, %p25, %p38;
(EngineCore_DP0 pid=339943) 	and.pred 	%p14, %p25, %p34;
(EngineCore_DP0 pid=339943) 	and.pred 	%p15, %p26, %p37;
(EngineCore_DP0 pid=339943) 	and.pred 	%p16, %p26, %p33;
(EngineCore_DP0 pid=339943) 	.loc	1 212 39                        // quant_slide_tuned_Llama3.2-1B.py:212:39
(EngineCore_DP0 pid=339943) 	add.s64 	%rd12, %rd8, 2;
(EngineCore_DP0 pid=339943) 	add.s64 	%rd13, %rd9, 2;
(EngineCore_DP0 pid=339943) 	add.s64 	%rd14, %rd10, 2;
(EngineCore_DP0 pid=339943) 	add.s64 	%rd15, %rd11, 2;
(EngineCore_DP0 pid=339943) 	.loc	1 212 21                        // quant_slide_tuned_Llama3.2-1B.py:212:21
(EngineCore_DP0 pid=339943) 	// begin inline asm
(EngineCore_DP0 pid=339943) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=339943) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=339943) 	// end inline asm
(EngineCore_DP0 pid=339943) 	// begin inline asm
(EngineCore_DP0 pid=339943) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=339943) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=339943) 	// end inline asm
(EngineCore_DP0 pid=339943) 	// begin inline asm
(EngineCore_DP0 pid=339943) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=339943) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=339943) 	// end inline asm
(EngineCore_DP0 pid=339943) 	// begin inline asm
(EngineCore_DP0 pid=339943) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=339943) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=339943) 	// end inline asm
(EngineCore_DP0 pid=339943) 	.loc	1 213 79                        // quant_slide_tuned_Llama3.2-1B.py:213:79
(EngineCore_DP0 pid=339943) 	cvt.f32.bf16 	%r128, %rs32;
(EngineCore_DP0 pid=339943) 	cvt.f32.bf16 	%r129, %rs34;
(EngineCore_DP0 pid=339943) 	cvt.f32.bf16 	%r130, %rs36;
(EngineCore_DP0 pid=339943) 	cvt.f32.bf16 	%r131, %rs38;
(EngineCore_DP0 pid=339943) 	.loc	1 215 48                        // quant_slide_tuned_Llama3.2-1B.py:215:48
(EngineCore_DP0 pid=339943) 	add.s32 	%r132, %r114, 2;
(EngineCore_DP0 pid=339943) 	add.s32 	%r133, %r113, 2;
(EngineCore_DP0 pid=339943) 	.loc	1 215 53                        // quant_slide_tuned_Llama3.2-1B.py:215:53
(EngineCore_DP0 pid=339943) 	setp.lt.s32 	%p39, %r132, %r27;
(EngineCore_DP0 pid=339943) 	setp.lt.s32 	%p40, %r133, %r27;
(EngineCore_DP0 pid=339943) 	.loc	1 215 37                        // quant_slide_tuned_Llama3.2-1B.py:215:37
(EngineCore_DP0 pid=339943) 	and.pred 	%p17, %p25, %p36;
(EngineCore_DP0 pid=339943) 	and.pred 	%p18, %p25, %p39;
(EngineCore_DP0 pid=339943) 	and.pred 	%p19, %p26, %p40;
(EngineCore_DP0 pid=339943) 	and.pred 	%p20, %p26, %p32;
(EngineCore_DP0 pid=339943) 	.loc	1 214 39                        // quant_slide_tuned_Llama3.2-1B.py:214:39
(EngineCore_DP0 pid=339943) 	add.s64 	%rd16, %rd8, 4;
(EngineCore_DP0 pid=339943) 	add.s64 	%rd17, %rd9, 4;
(EngineCore_DP0 pid=339943) 	add.s64 	%rd18, %rd10, 4;
(EngineCore_DP0 pid=339943) 	add.s64 	%rd19, %rd11, 4;
(EngineCore_DP0 pid=339943) 	.loc	1 214 21                        // quant_slide_tuned_Llama3.2-1B.py:214:21
(EngineCore_DP0 pid=339943) 	// begin inline asm
(EngineCore_DP0 pid=339943) 	mov.u16 %rs40, %rs25;
(EngineCore_DP0 pid=339943) 	@%p17 ld.global.b16 { %rs40 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=339943) 	// end inline asm
(EngineCore_DP0 pid=339943) 	// begin inline asm
(EngineCore_DP0 pid=339943) 	mov.u16 %rs42, %rs25;
(EngineCore_DP0 pid=339943) 	@%p18 ld.global.b16 { %rs42 }, [ %rd17 + 0 ];
(EngineCore_DP0 pid=339943) 	// end inline asm
(EngineCore_DP0 pid=339943) 	// begin inline asm
(EngineCore_DP0 pid=339943) 	mov.u16 %rs44, %rs25;
(EngineCore_DP0 pid=339943) 	@%p19 ld.global.b16 { %rs44 }, [ %rd18 + 0 ];
(EngineCore_DP0 pid=339943) 	// end inline asm
(EngineCore_DP0 pid=339943) 	// begin inline asm
(EngineCore_DP0 pid=339943) 	mov.u16 %rs46, %rs25;
(EngineCore_DP0 pid=339943) 	@%p20 ld.global.b16 { %rs46 }, [ %rd19 + 0 ];
(EngineCore_DP0 pid=339943) 	// end inline asm
(EngineCore_DP0 pid=339943) 	.loc	1 215 79                        // quant_slide_tuned_Llama3.2-1B.py:215:79
(EngineCore_DP0 pid=339943) 	cvt.f32.bf16 	%r134, %rs40;
(EngineCore_DP0 pid=339943) 	cvt.f32.bf16 	%r135, %rs42;
(EngineCore_DP0 pid=339943) 	cvt.f32.bf16 	%r136, %rs44;
(EngineCore_DP0 pid=339943) 	cvt.f32.bf16 	%r137, %rs46;
(EngineCore_DP0 pid=339943) 	.loc	1 217 48                        // quant_slide_tuned_Llama3.2-1B.py:217:48
(EngineCore_DP0 pid=339943) 	add.s32 	%r138, %r114, 3;
(EngineCore_DP0 pid=339943) 	add.s32 	%r139, %r113, 3;
(EngineCore_DP0 pid=339943) 	.loc	1 217 53                        // quant_slide_tuned_Llama3.2-1B.py:217:53
(EngineCore_DP0 pid=339943) 	setp.lt.s32 	%p41, %r138, %r27;
(EngineCore_DP0 pid=339943) 	setp.lt.s32 	%p42, %r139, %r27;
(EngineCore_DP0 pid=339943) 	.loc	1 217 37                        // quant_slide_tuned_Llama3.2-1B.py:217:37
(EngineCore_DP0 pid=339943) 	and.pred 	%p21, %p25, %p35;
(EngineCore_DP0 pid=339943) 	and.pred 	%p22, %p25, %p41;
(EngineCore_DP0 pid=339943) 	and.pred 	%p23, %p26, %p42;
(EngineCore_DP0 pid=339943) 	and.pred 	%p24, %p26, %p31;
(EngineCore_DP0 pid=339943) 	.loc	1 216 39                        // quant_slide_tuned_Llama3.2-1B.py:216:39
(EngineCore_DP0 pid=339943) 	add.s64 	%rd20, %rd8, 6;
(EngineCore_DP0 pid=339943) 	add.s64 	%rd21, %rd9, 6;
(EngineCore_DP0 pid=339943) 	add.s64 	%rd22, %rd10, 6;
(EngineCore_DP0 pid=339943) 	add.s64 	%rd23, %rd11, 6;
(EngineCore_DP0 pid=339943) 	.loc	1 216 21                        // quant_slide_tuned_Llama3.2-1B.py:216:21
(EngineCore_DP0 pid=339943) 	// begin inline asm
(EngineCore_DP0 pid=339943) 	mov.u16 %rs48, %rs25;
(EngineCore_DP0 pid=339943) 	@%p21 ld.global.b16 { %rs48 }, [ %rd20 + 0 ];
(EngineCore_DP0 pid=339943) 	// end inline asm
(EngineCore_DP0 pid=339943) 	// begin inline asm
(EngineCore_DP0 pid=339943) 	mov.u16 %rs50, %rs25;
(EngineCore_DP0 pid=339943) 	@%p22 ld.global.b16 { %rs50 }, [ %rd21 + 0 ];
(EngineCore_DP0 pid=339943) 	// end inline asm
(EngineCore_DP0 pid=339943) 	// begin inline asm
(EngineCore_DP0 pid=339943) 	mov.u16 %rs52, %rs25;
(EngineCore_DP0 pid=339943) 	@%p23 ld.global.b16 { %rs52 }, [ %rd22 + 0 ];
(EngineCore_DP0 pid=339943) 	// end inline asm
(EngineCore_DP0 pid=339943) 	// begin inline asm
(EngineCore_DP0 pid=339943) 	mov.u16 %rs54, %rs25;
(EngineCore_DP0 pid=339943) 	@%p24 ld.global.b16 { %rs54 }, [ %rd23 + 0 ];
(EngineCore_DP0 pid=339943) 	// end inline asm
(EngineCore_DP0 pid=339943) 	.loc	1 217 79                        // quant_slide_tuned_Llama3.2-1B.py:217:79
(EngineCore_DP0 pid=339943) 	cvt.f32.bf16 	%r140, %rs48;
(EngineCore_DP0 pid=339943) 	cvt.f32.bf16 	%r141, %rs50;
(EngineCore_DP0 pid=339943) 	cvt.f32.bf16 	%r142, %rs52;
(EngineCore_DP0 pid=339943) 	cvt.f32.bf16 	%r143, %rs54;
(EngineCore_DP0 pid=339943) 	.loc	1 219 27                        // quant_slide_tuned_Llama3.2-1B.py:219:27
(EngineCore_DP0 pid=339943) 	mul.f32 	%r144, %r14, %r116;
(EngineCore_DP0 pid=339943) 	mul.f32 	%r145, %r14, %r117;
(EngineCore_DP0 pid=339943) 	mul.f32 	%r146, %r14, %r118;
(EngineCore_DP0 pid=339943) 	mul.f32 	%r147, %r14, %r119;
(EngineCore_DP0 pid=339943) 	mov.b32 	%r148, 0f43E00000;
(EngineCore_DP0 pid=339943) 	.loc	1 219 48                        // quant_slide_tuned_Llama3.2-1B.py:219:48
(EngineCore_DP0 pid=339943) 	min.xorsign.abs.f32 	%r82, %r144, %r148;
(EngineCore_DP0 pid=339943) 	min.xorsign.abs.f32 	%r83, %r145, %r148;
(EngineCore_DP0 pid=339943) 	min.xorsign.abs.f32 	%r84, %r146, %r148;
(EngineCore_DP0 pid=339943) 	min.xorsign.abs.f32 	%r85, %r147, %r148;
(EngineCore_DP0 pid=339943) 	.loc	1 219 60                        // quant_slide_tuned_Llama3.2-1B.py:219:60
(EngineCore_DP0 pid=339943) 	// begin inline asm
(EngineCore_DP0 pid=339943) 	cvt.rn.satfinite.e4m3x2.f32  %rs56, %r83, %r82; 
(EngineCore_DP0 pid=339943) 
(EngineCore_DP0 pid=339943) 	// end inline asm
(EngineCore_DP0 pid=339943) 	shr.u16 	%rs64, %rs56, 8;
(EngineCore_DP0 pid=339943) 	// begin inline asm
(EngineCore_DP0 pid=339943) 	cvt.rn.satfinite.e4m3x2.f32  %rs57, %r85, %r84; 
(EngineCore_DP0 pid=339943) 
(EngineCore_DP0 pid=339943) 	// end inline asm
(EngineCore_DP0 pid=339943) 	shr.u16 	%rs65, %rs57, 8;
(EngineCore_DP0 pid=339943) 	.loc	1 220 27                        // quant_slide_tuned_Llama3.2-1B.py:220:27
(EngineCore_DP0 pid=339943) 	mul.f32 	%r149, %r14, %r128;
(EngineCore_DP0 pid=339943) 	mul.f32 	%r150, %r14, %r129;
(EngineCore_DP0 pid=339943) 	mul.f32 	%r151, %r14, %r130;
(EngineCore_DP0 pid=339943) 	mul.f32 	%r152, %r14, %r131;
(EngineCore_DP0 pid=339943) 	.loc	1 220 48                        // quant_slide_tuned_Llama3.2-1B.py:220:48
(EngineCore_DP0 pid=339943) 	min.xorsign.abs.f32 	%r86, %r149, %r148;
(EngineCore_DP0 pid=339943) 	min.xorsign.abs.f32 	%r87, %r150, %r148;
(EngineCore_DP0 pid=339943) 	min.xorsign.abs.f32 	%r88, %r151, %r148;
(EngineCore_DP0 pid=339943) 	min.xorsign.abs.f32 	%r89, %r152, %r148;
(EngineCore_DP0 pid=339943) 	.loc	1 220 60                        // quant_slide_tuned_Llama3.2-1B.py:220:60
(EngineCore_DP0 pid=339943) 	// begin inline asm
(EngineCore_DP0 pid=339943) 	cvt.rn.satfinite.e4m3x2.f32  %rs58, %r87, %r86; 
(EngineCore_DP0 pid=339943) 
(EngineCore_DP0 pid=339943) 	// end inline asm
(EngineCore_DP0 pid=339943) 	shr.u16 	%rs66, %rs58, 8;
(EngineCore_DP0 pid=339943) 	// begin inline asm
(EngineCore_DP0 pid=339943) 	cvt.rn.satfinite.e4m3x2.f32  %rs59, %r89, %r88; 
(EngineCore_DP0 pid=339943) 
(EngineCore_DP0 pid=339943) 	// end inline asm
(EngineCore_DP0 pid=339943) 	shr.u16 	%rs67, %rs59, 8;
(EngineCore_DP0 pid=339943) 	.loc	1 221 27                        // quant_slide_tuned_Llama3.2-1B.py:221:27
(EngineCore_DP0 pid=339943) 	mul.f32 	%r153, %r14, %r134;
(EngineCore_DP0 pid=339943) 	mul.f32 	%r154, %r14, %r135;
(EngineCore_DP0 pid=339943) 	mul.f32 	%r155, %r14, %r136;
(EngineCore_DP0 pid=339943) 	mul.f32 	%r156, %r14, %r137;
(EngineCore_DP0 pid=339943) 	.loc	1 221 48                        // quant_slide_tuned_Llama3.2-1B.py:221:48
(EngineCore_DP0 pid=339943) 	min.xorsign.abs.f32 	%r90, %r153, %r148;
(EngineCore_DP0 pid=339943) 	min.xorsign.abs.f32 	%r91, %r154, %r148;
(EngineCore_DP0 pid=339943) 	min.xorsign.abs.f32 	%r92, %r155, %r148;
(EngineCore_DP0 pid=339943) 	min.xorsign.abs.f32 	%r93, %r156, %r148;
(EngineCore_DP0 pid=339943) 	.loc	1 221 60                        // quant_slide_tuned_Llama3.2-1B.py:221:60
(EngineCore_DP0 pid=339943) 	// begin inline asm
(EngineCore_DP0 pid=339943) 	cvt.rn.satfinite.e4m3x2.f32  %rs60, %r91, %r90; 
(EngineCore_DP0 pid=339943) 
(EngineCore_DP0 pid=339943) 	// end inline asm
(EngineCore_DP0 pid=339943) 	shr.u16 	%rs68, %rs60, 8;
(EngineCore_DP0 pid=339943) 	// begin inline asm
(EngineCore_DP0 pid=339943) 	cvt.rn.satfinite.e4m3x2.f32  %rs61, %r93, %r92; 
(EngineCore_DP0 pid=339943) 
(EngineCore_DP0 pid=339943) 	// end inline asm
(EngineCore_DP0 pid=339943) 	shr.u16 	%rs69, %rs61, 8;
(EngineCore_DP0 pid=339943) 	.loc	1 222 27                        // quant_slide_tuned_Llama3.2-1B.py:222:27
(EngineCore_DP0 pid=339943) 	mul.f32 	%r157, %r14, %r140;
(EngineCore_DP0 pid=339943) 	mul.f32 	%r158, %r14, %r141;
(EngineCore_DP0 pid=339943) 	mul.f32 	%r159, %r14, %r142;
(EngineCore_DP0 pid=339943) 	mul.f32 	%r160, %r14, %r143;
(EngineCore_DP0 pid=339943) 	.loc	1 222 48                        // quant_slide_tuned_Llama3.2-1B.py:222:48
(EngineCore_DP0 pid=339943) 	min.xorsign.abs.f32 	%r94, %r157, %r148;
(EngineCore_DP0 pid=339943) 	min.xorsign.abs.f32 	%r95, %r158, %r148;
(EngineCore_DP0 pid=339943) 	min.xorsign.abs.f32 	%r96, %r159, %r148;
(EngineCore_DP0 pid=339943) 	min.xorsign.abs.f32 	%r97, %r160, %r148;
(EngineCore_DP0 pid=339943) 	.loc	1 222 60                        // quant_slide_tuned_Llama3.2-1B.py:222:60
(EngineCore_DP0 pid=339943) 	// begin inline asm
(EngineCore_DP0 pid=339943) 	cvt.rn.satfinite.e4m3x2.f32  %rs62, %r95, %r94; 
(EngineCore_DP0 pid=339943) 
(EngineCore_DP0 pid=339943) 	// end inline asm
(EngineCore_DP0 pid=339943) 	shr.u16 	%rs70, %rs62, 8;
(EngineCore_DP0 pid=339943) 	// begin inline asm
(EngineCore_DP0 pid=339943) 	cvt.rn.satfinite.e4m3x2.f32  %rs63, %r97, %r96; 
(EngineCore_DP0 pid=339943) 
(EngineCore_DP0 pid=339943) 	// end inline asm
(EngineCore_DP0 pid=339943) 	shr.u16 	%rs71, %rs63, 8;
(EngineCore_DP0 pid=339943) 	.loc	1 224 45                        // quant_slide_tuned_Llama3.2-1B.py:224:45
(EngineCore_DP0 pid=339943) 	cvt.u32.u16 	%r161, %rs56;
(EngineCore_DP0 pid=339943) 	and.b32 	%r162, %r161, 255;
(EngineCore_DP0 pid=339943) 	cvt.u32.u16 	%r163, %rs64;
(EngineCore_DP0 pid=339943) 	cvt.u32.u16 	%r164, %rs57;
(EngineCore_DP0 pid=339943) 	and.b32 	%r165, %r164, 255;
(EngineCore_DP0 pid=339943) 	cvt.u32.u16 	%r166, %rs65;
(EngineCore_DP0 pid=339943) 	.loc	1 226 45                        // quant_slide_tuned_Llama3.2-1B.py:226:45
(EngineCore_DP0 pid=339943) 	cvt.u32.u16 	%r167, %rs60;
(EngineCore_DP0 pid=339943) 	and.b32 	%r168, %r167, 255;
(EngineCore_DP0 pid=339943) 	cvt.u32.u16 	%r169, %rs68;
(EngineCore_DP0 pid=339943) 	cvt.u32.u16 	%r170, %rs61;
(EngineCore_DP0 pid=339943) 	and.b32 	%r171, %r170, 255;
(EngineCore_DP0 pid=339943) 	cvt.u32.u16 	%r172, %rs69;
(EngineCore_DP0 pid=339943) 	.loc	1 227 45                        // quant_slide_tuned_Llama3.2-1B.py:227:45
(EngineCore_DP0 pid=339943) 	cvt.u32.u16 	%r173, %rs62;
(EngineCore_DP0 pid=339943) 	cvt.u32.u16 	%r174, %rs70;
(EngineCore_DP0 pid=339943) 	cvt.u32.u16 	%r175, %rs63;
(EngineCore_DP0 pid=339943) 	cvt.u32.u16 	%r176, %rs71;
(EngineCore_DP0 pid=339943) 	.loc	1 229 30                        // quant_slide_tuned_Llama3.2-1B.py:229:30
(EngineCore_DP0 pid=339943) 	and.b16 	%rs72, %rs58, 255;
(EngineCore_DP0 pid=339943) 	mul.wide.u16 	%r177, %rs72, 256;
(EngineCore_DP0 pid=339943) 	mul.wide.u16 	%r178, %rs66, 256;
(EngineCore_DP0 pid=339943) 	and.b16 	%rs73, %rs59, 255;
(EngineCore_DP0 pid=339943) 	mul.wide.u16 	%r179, %rs73, 256;
(EngineCore_DP0 pid=339943) 	mul.wide.u16 	%r180, %rs67, 256;
(EngineCore_DP0 pid=339943) 	.loc	1 229 24                        // quant_slide_tuned_Llama3.2-1B.py:229:24
(EngineCore_DP0 pid=339943) 	or.b32 	%r181, %r177, %r162;
(EngineCore_DP0 pid=339943) 	or.b32 	%r182, %r178, %r163;
(EngineCore_DP0 pid=339943) 	or.b32 	%r183, %r179, %r165;
(EngineCore_DP0 pid=339943) 	or.b32 	%r184, %r180, %r166;
(EngineCore_DP0 pid=339943) 	.loc	1 229 42                        // quant_slide_tuned_Llama3.2-1B.py:229:42
(EngineCore_DP0 pid=339943) 	shl.b32 	%r185, %r168, 16;
(EngineCore_DP0 pid=339943) 	shl.b32 	%r186, %r169, 16;
(EngineCore_DP0 pid=339943) 	shl.b32 	%r187, %r171, 16;
(EngineCore_DP0 pid=339943) 	shl.b32 	%r188, %r172, 16;
(EngineCore_DP0 pid=339943) 	.loc	1 229 36                        // quant_slide_tuned_Llama3.2-1B.py:229:36
(EngineCore_DP0 pid=339943) 	or.b32 	%r189, %r185, %r181;
(EngineCore_DP0 pid=339943) 	or.b32 	%r190, %r186, %r182;
(EngineCore_DP0 pid=339943) 	or.b32 	%r191, %r187, %r183;
(EngineCore_DP0 pid=339943) 	or.b32 	%r192, %r188, %r184;
(EngineCore_DP0 pid=339943) 	.loc	1 229 55                        // quant_slide_tuned_Llama3.2-1B.py:229:55
(EngineCore_DP0 pid=339943) 	shl.b32 	%r193, %r173, 24;
(EngineCore_DP0 pid=339943) 	shl.b32 	%r194, %r174, 24;
(EngineCore_DP0 pid=339943) 	shl.b32 	%r195, %r175, 24;
(EngineCore_DP0 pid=339943) 	shl.b32 	%r196, %r176, 24;
(EngineCore_DP0 pid=339943) 	.loc	1 229 49                        // quant_slide_tuned_Llama3.2-1B.py:229:49
(EngineCore_DP0 pid=339943) 	or.b32 	%r98, %r193, %r189;
(EngineCore_DP0 pid=339943) 	or.b32 	%r99, %r194, %r190;
(EngineCore_DP0 pid=339943) 	or.b32 	%r100, %r195, %r191;
(EngineCore_DP0 pid=339943) 	or.b32 	%r101, %r196, %r192;
(EngineCore_DP0 pid=339943) 	.loc	1 230 29                        // quant_slide_tuned_Llama3.2-1B.py:230:29
(EngineCore_DP0 pid=339943) 	mad.wide.s32 	%rd24, %r102, 4, %rd2;
(EngineCore_DP0 pid=339943) 	add.s64 	%rd25, %rd24, 8;
(EngineCore_DP0 pid=339943) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-1B.py:230:39
(EngineCore_DP0 pid=339943) 	// begin inline asm
(EngineCore_DP0 pid=339943) 	@%p25 st.global.v2.b32 [ %rd24 + 0 ], { %r98, %r99 };
(EngineCore_DP0 pid=339943) 	// end inline asm
(EngineCore_DP0 pid=339943) 	// begin inline asm
(EngineCore_DP0 pid=339943) 	@%p26 st.global.v2.b32 [ %rd25 + 0 ], { %r100, %r101 };
(EngineCore_DP0 pid=339943) 	// end inline asm
(EngineCore_DP0 pid=339943) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=339943) 	add.s32 	%r200, %r200, 2048;
(EngineCore_DP0 pid=339943) 	setp.lt.s32 	%p43, %r200, %r15;
(EngineCore_DP0 pid=339943) 	@%p43 bra 	$L__BB0_6;
(EngineCore_DP0 pid=339943) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=339943) 	.loc	1 201 4                         // quant_slide_tuned_Llama3.2-1B.py:201:4
(EngineCore_DP0 pid=339943) 	ret;
(EngineCore_DP0 pid=339943) $L__tmp3:
(EngineCore_DP0 pid=339943) $L__func_end0:
(EngineCore_DP0 pid=339943)                                         // -- End function
(EngineCore_DP0 pid=339943) }
(EngineCore_DP0 pid=339943) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=339943) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=339943) 	.section	.debug_abbrev
(EngineCore_DP0 pid=339943) 	{
(EngineCore_DP0 pid=339943) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=339943) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=339943) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=339943) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=339943) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=339943) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=339943) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=339943) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=339943) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=339943) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=339943) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=339943) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=339943) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=339943) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=339943) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=339943) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=339943) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=339943) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=339943) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=339943) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=339943) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=339943) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=339943) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=339943) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=339943) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=339943) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=339943) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=339943) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=339943) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=339943) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=339943) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=339943) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=339943) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=339943) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=339943) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=339943) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=339943) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=339943) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=339943) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=339943) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=339943) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=339943) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=339943) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=339943) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=339943) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=339943) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=339943) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=339943) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=339943) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=339943) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=339943) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=339943) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=339943) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=339943) 	}
(EngineCore_DP0 pid=339943) 	.section	.debug_info
(EngineCore_DP0 pid=339943) 	{
(EngineCore_DP0 pid=339943) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=339943) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=339943) .b8 0
(EngineCore_DP0 pid=339943) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=339943) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=339943) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=339943) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=339943) .b8 114
(EngineCore_DP0 pid=339943) .b8 105
(EngineCore_DP0 pid=339943) .b8 116
(EngineCore_DP0 pid=339943) .b8 111
(EngineCore_DP0 pid=339943) .b8 110
(EngineCore_DP0 pid=339943) .b8 0
(EngineCore_DP0 pid=339943) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=339943) .b8 0
(EngineCore_DP0 pid=339943) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=339943) .b8 117
(EngineCore_DP0 pid=339943) .b8 97
(EngineCore_DP0 pid=339943) .b8 110
(EngineCore_DP0 pid=339943) .b8 116
(EngineCore_DP0 pid=339943) .b8 95
(EngineCore_DP0 pid=339943) .b8 115
(EngineCore_DP0 pid=339943) .b8 108
(EngineCore_DP0 pid=339943) .b8 105
(EngineCore_DP0 pid=339943) .b8 100
(EngineCore_DP0 pid=339943) .b8 101
(EngineCore_DP0 pid=339943) .b8 95
(EngineCore_DP0 pid=339943) .b8 116
(EngineCore_DP0 pid=339943) .b8 117
(EngineCore_DP0 pid=339943) .b8 110
(EngineCore_DP0 pid=339943) .b8 101
(EngineCore_DP0 pid=339943) .b8 100
(EngineCore_DP0 pid=339943) .b8 95
(EngineCore_DP0 pid=339943) .b8 76
(EngineCore_DP0 pid=339943) .b8 108
(EngineCore_DP0 pid=339943) .b8 97
(EngineCore_DP0 pid=339943) .b8 109
(EngineCore_DP0 pid=339943) .b8 97
(EngineCore_DP0 pid=339943) .b8 51
(EngineCore_DP0 pid=339943) .b8 46
(EngineCore_DP0 pid=339943) .b8 50
(EngineCore_DP0 pid=339943) .b8 45
(EngineCore_DP0 pid=339943) .b8 49
(EngineCore_DP0 pid=339943) .b8 66
(EngineCore_DP0 pid=339943) .b8 46
(EngineCore_DP0 pid=339943) .b8 112
(EngineCore_DP0 pid=339943) .b8 121
(EngineCore_DP0 pid=339943) .b8 0
(EngineCore_DP0 pid=339943) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=339943) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=339943) .b8 114
(EngineCore_DP0 pid=339943) .b8 111
(EngineCore_DP0 pid=339943) .b8 111
(EngineCore_DP0 pid=339943) .b8 116
(EngineCore_DP0 pid=339943) .b8 47
(EngineCore_DP0 pid=339943) .b8 118
(EngineCore_DP0 pid=339943) .b8 108
(EngineCore_DP0 pid=339943) .b8 108
(EngineCore_DP0 pid=339943) .b8 109
(EngineCore_DP0 pid=339943) .b8 98
(EngineCore_DP0 pid=339943) .b8 101
(EngineCore_DP0 pid=339943) .b8 110
(EngineCore_DP0 pid=339943) .b8 99
(EngineCore_DP0 pid=339943) .b8 104
(EngineCore_DP0 pid=339943) .b8 47
(EngineCore_DP0 pid=339943) .b8 115
(EngineCore_DP0 pid=339943) .b8 108
(EngineCore_DP0 pid=339943) .b8 105
(EngineCore_DP0 pid=339943) .b8 100
(EngineCore_DP0 pid=339943) .b8 101
(EngineCore_DP0 pid=339943) .b8 115
(EngineCore_DP0 pid=339943) .b8 112
(EngineCore_DP0 pid=339943) .b8 97
(EngineCore_DP0 pid=339943) .b8 114
(EngineCore_DP0 pid=339943) .b8 115
(EngineCore_DP0 pid=339943) .b8 101
(EngineCore_DP0 pid=339943) .b8 47
(EngineCore_DP0 pid=339943) .b8 99
(EngineCore_DP0 pid=339943) .b8 115
(EngineCore_DP0 pid=339943) .b8 114
(EngineCore_DP0 pid=339943) .b8 99
(EngineCore_DP0 pid=339943) .b8 47
(EngineCore_DP0 pid=339943) .b8 102
(EngineCore_DP0 pid=339943) .b8 117
(EngineCore_DP0 pid=339943) .b8 115
(EngineCore_DP0 pid=339943) .b8 101
(EngineCore_DP0 pid=339943) .b8 100
(EngineCore_DP0 pid=339943) .b8 95
(EngineCore_DP0 pid=339943) .b8 113
(EngineCore_DP0 pid=339943) .b8 117
(EngineCore_DP0 pid=339943) .b8 97
(EngineCore_DP0 pid=339943) .b8 110
(EngineCore_DP0 pid=339943) .b8 116
(EngineCore_DP0 pid=339943) .b8 95
(EngineCore_DP0 pid=339943) .b8 115
(EngineCore_DP0 pid=339943) .b8 108
(EngineCore_DP0 pid=339943) .b8 105
(EngineCore_DP0 pid=339943) .b8 100
(EngineCore_DP0 pid=339943) .b8 101
(EngineCore_DP0 pid=339943) .b8 95
(EngineCore_DP0 pid=339943) .b8 116
(EngineCore_DP0 pid=339943) .b8 114
(EngineCore_DP0 pid=339943) .b8 105
(EngineCore_DP0 pid=339943) .b8 116
(EngineCore_DP0 pid=339943) .b8 111
(EngineCore_DP0 pid=339943) .b8 110
(EngineCore_DP0 pid=339943) .b8 47
(EngineCore_DP0 pid=339943) .b8 98
(EngineCore_DP0 pid=339943) .b8 117
(EngineCore_DP0 pid=339943) .b8 105
(EngineCore_DP0 pid=339943) .b8 108
(EngineCore_DP0 pid=339943) .b8 100
(EngineCore_DP0 pid=339943) .b8 47
(EngineCore_DP0 pid=339943) .b8 71
(EngineCore_DP0 pid=339943) .b8 66
(EngineCore_DP0 pid=339943) .b8 49
(EngineCore_DP0 pid=339943) .b8 48
(EngineCore_DP0 pid=339943) .b8 95
(EngineCore_DP0 pid=339943) .b8 99
(EngineCore_DP0 pid=339943) .b8 99
(EngineCore_DP0 pid=339943) .b8 49
(EngineCore_DP0 pid=339943) .b8 50
(EngineCore_DP0 pid=339943) .b8 49
(EngineCore_DP0 pid=339943) .b8 95
(EngineCore_DP0 pid=339943) .b8 112
(EngineCore_DP0 pid=339943) .b8 121
(EngineCore_DP0 pid=339943) .b8 51
(EngineCore_DP0 pid=339943) .b8 49
(EngineCore_DP0 pid=339943) .b8 50
(EngineCore_DP0 pid=339943) .b8 95
(EngineCore_DP0 pid=339943) .b8 99
(EngineCore_DP0 pid=339943) .b8 117
(EngineCore_DP0 pid=339943) .b8 49
(EngineCore_DP0 pid=339943) .b8 50
(EngineCore_DP0 pid=339943) .b8 57
(EngineCore_DP0 pid=339943) .b8 95
(EngineCore_DP0 pid=339943) .b8 97
(EngineCore_DP0 pid=339943) .b8 97
(EngineCore_DP0 pid=339943) .b8 114
(EngineCore_DP0 pid=339943) .b8 99
(EngineCore_DP0 pid=339943) .b8 104
(EngineCore_DP0 pid=339943) .b8 54
(EngineCore_DP0 pid=339943) .b8 52
(EngineCore_DP0 pid=339943) .b8 0
(EngineCore_DP0 pid=339943) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=339943) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=339943) .b8 113
(EngineCore_DP0 pid=339943) .b8 117
(EngineCore_DP0 pid=339943) .b8 97
(EngineCore_DP0 pid=339943) .b8 110
(EngineCore_DP0 pid=339943) .b8 116
(EngineCore_DP0 pid=339943) .b8 95
(EngineCore_DP0 pid=339943) .b8 115
(EngineCore_DP0 pid=339943) .b8 108
(EngineCore_DP0 pid=339943) .b8 105
(EngineCore_DP0 pid=339943) .b8 100
(EngineCore_DP0 pid=339943) .b8 101
(EngineCore_DP0 pid=339943) .b8 95
(EngineCore_DP0 pid=339943) .b8 102
(EngineCore_DP0 pid=339943) .b8 112
(EngineCore_DP0 pid=339943) .b8 56
(EngineCore_DP0 pid=339943) .b8 95
(EngineCore_DP0 pid=339943) .b8 107
(EngineCore_DP0 pid=339943) .b8 101
(EngineCore_DP0 pid=339943) .b8 114
(EngineCore_DP0 pid=339943) .b8 110
(EngineCore_DP0 pid=339943) .b8 101
(EngineCore_DP0 pid=339943) .b8 108
(EngineCore_DP0 pid=339943) .b8 0
(EngineCore_DP0 pid=339943) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=339943) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=339943) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=339943) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=339943) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=339943) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=339943) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=339943) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=339943) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=339943) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=339943) .b8 191                                 // DW_AT_call_line
(EngineCore_DP0 pid=339943) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=339943) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=339943) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=339943) 	}
(EngineCore_DP0 pid=339943) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=339943) 
(EngineCore_DP0 pid=339943) ================================================================
(EngineCore_DP0 pid=339943) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=339943) 
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmphwmi818q.ptx', '-o', '/tmp/tmphwmi818q.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866] 
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866] 
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866] 
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmphwmi818q.ptx -o /tmp/tmphwmi818q.ptx.o
(EngineCore_DP0 pid=339943) ERROR 01-25 19:18:45 [core.py:866] 

STDERR:
[2026-01-25 19:18:30] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:18:30] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:18:30] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:18:30] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:18:30] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:18:30] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:18:30] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:18:30] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:18:30] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:18:30] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:18:30] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:18:30] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:18:30] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:18:30] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:18:33] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:18:33] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:18:33] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:18:33] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:18:33] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:18:33] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:18:33] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:18:33] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:18:33] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:18:33] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:18:33] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:18:33] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:18:33] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:18:33] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=339943) [2026-01-25 19:18:34] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=339943) [2026-01-25 19:18:34] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=339943) [2026-01-25 19:18:34] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=339943) [2026-01-25 19:18:34] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=339943) [2026-01-25 19:18:34] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=339943) [2026-01-25 19:18:34] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=339943) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=339943) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.28s/it]
(EngineCore_DP0 pid=339943) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.28s/it]
(EngineCore_DP0 pid=339943) 
(EngineCore_DP0 pid=339943) [2026-01-25 19:18:44] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=339943) [2026-01-25 19:18:44] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5308416 bytes
(EngineCore_DP0 pid=339943) [2026-01-25 19:18:44] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=339943) [2026-01-25 19:18:44] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3538944 bytes
(EngineCore_DP0 pid=339943) [2026-01-25 19:18:44] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=339943) [2026-01-25 19:18:44] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 28311552 bytes
(EngineCore_DP0 pid=339943) [2026-01-25 19:18:44] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=339943) [2026-01-25 19:18:44] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14024704 bytes
(EngineCore_DP0 pid=339943) Process EngineCore_DP0:
(EngineCore_DP0 pid=339943) Traceback (most recent call last):
(EngineCore_DP0 pid=339943)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=339943)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=339943)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=339943)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=339943) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmphwmi818q.ptx', '-o', '/tmp/tmphwmi818q.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=339943) 
(EngineCore_DP0 pid=339943) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=339943) 
(EngineCore_DP0 pid=339943) Traceback (most recent call last):
(EngineCore_DP0 pid=339943)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=339943)     self.run()
(EngineCore_DP0 pid=339943)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=339943)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=339943)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=339943)     raise e
(EngineCore_DP0 pid=339943)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=339943)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=339943)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=339943)     super().__init__(
(EngineCore_DP0 pid=339943)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=339943)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=339943)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=339943)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=339943)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=339943)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=339943)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=339943)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=339943)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=339943)     return func(*args, **kwargs)
(EngineCore_DP0 pid=339943)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=339943)     return func(*args, **kwargs)
(EngineCore_DP0 pid=339943)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=339943)     self.model_runner.profile_run()
(EngineCore_DP0 pid=339943)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=339943)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=339943)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=339943)     return func(*args, **kwargs)
(EngineCore_DP0 pid=339943)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=339943)     outputs = self.model(
(EngineCore_DP0 pid=339943)               ^^^^^^^^^^^
(EngineCore_DP0 pid=339943)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=339943)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=339943)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=339943)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=339943)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=339943)     model_output = self.model(
(EngineCore_DP0 pid=339943)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=339943)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=339943)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=339943)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=339943)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=339943)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=339943)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=339943)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=339943)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=339943)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=339943)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=339943)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=339943)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=339943)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=339943)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=339943)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=339943)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=339943)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=339943)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=339943)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=339943)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=339943)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=339943)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=339943)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=339943)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=339943)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=339943)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=339943)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=339943)     return self._linear_fn(
(EngineCore_DP0 pid=339943)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=339943)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=339943)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=339943)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=339943)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=339943)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=339943)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=339943)     return fn(input, L)
(EngineCore_DP0 pid=339943)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=339943)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=339943)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=339943)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=339943)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=339943)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=339943)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=339943)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=339943)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=339943)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=339943)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=339943)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=339943)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=339943)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=339943)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=339943)     raise PTXASError(error)
(EngineCore_DP0 pid=339943) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=339943) `ptxas` stderr:
(EngineCore_DP0 pid=339943) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=339943) 
(EngineCore_DP0 pid=339943) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmphwmi818q.ptx -o /tmp/tmphwmi818q.ptx.o
(EngineCore_DP0 pid=339943) 
[rank0]:[W125 19:18:45.851326700 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=16384

========== M=32768 ==========
Time: 2026-01-25 19:18:47
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-FP8_M32768.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:19:02 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:19:02 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=340598) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=340598) 
(EngineCore_DP0 pid=340598) 
(EngineCore_DP0 pid=340598) ================================================================
(EngineCore_DP0 pid=340598) Internal Triton PTX codegen error
(EngineCore_DP0 pid=340598) `ptxas` stderr:
(EngineCore_DP0 pid=340598) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=340598) 
(EngineCore_DP0 pid=340598) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp9dlqxahl.ptx -o /tmp/tmp9dlqxahl.ptx.o
(EngineCore_DP0 pid=340598) 
(EngineCore_DP0 pid=340598) 
(EngineCore_DP0 pid=340598) //
(EngineCore_DP0 pid=340598) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=340598) //
(EngineCore_DP0 pid=340598) 
(EngineCore_DP0 pid=340598) .version 8.7
(EngineCore_DP0 pid=340598) .target sm_121a
(EngineCore_DP0 pid=340598) .address_size 64
(EngineCore_DP0 pid=340598) 
(EngineCore_DP0 pid=340598) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=340598) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=340598)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=340598) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=340598) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=340598) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=340598) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=340598) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=340598) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=340598) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=340598) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=340598) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=340598) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=340598) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=340598) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=340598) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=340598) )
(EngineCore_DP0 pid=340598) .reqntid 512
(EngineCore_DP0 pid=340598) {
(EngineCore_DP0 pid=340598) 	.reg .pred 	%p<45>;
(EngineCore_DP0 pid=340598) 	.reg .b16 	%rs<74>;
(EngineCore_DP0 pid=340598) 	.reg .b32 	%r<201>;
(EngineCore_DP0 pid=340598) 	.reg .b64 	%rd<26>;
(EngineCore_DP0 pid=340598) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=340598) $L__func_begin0:
(EngineCore_DP0 pid=340598) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=340598) 
(EngineCore_DP0 pid=340598) // %bb.0:
(EngineCore_DP0 pid=340598) 	ld.param.b32 	%r29, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=340598) 	ld.param.b32 	%r28, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=340598) 	ld.param.b32 	%r27, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=340598) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=340598) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=340598) $L__tmp0:
(EngineCore_DP0 pid=340598) 	.loc	1 177 24                        // quant_slide_tuned_Llama3.2-1B.py:177:24
(EngineCore_DP0 pid=340598) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=340598) 	ld.param.b32 	%r31, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=340598) 	.loc	1 182 26                        // quant_slide_tuned_Llama3.2-1B.py:182:26
(EngineCore_DP0 pid=340598) 	mul.lo.s32 	%r32, %r31, %r1;
(EngineCore_DP0 pid=340598) 	.loc	1 182 20                        // quant_slide_tuned_Llama3.2-1B.py:182:20
(EngineCore_DP0 pid=340598) 	mad.wide.s32 	%rd1, %r32, 2, %rd4;
(EngineCore_DP0 pid=340598) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=340598) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=340598) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=340598) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=340598) 	setp.lt.s32 	%p1, %r28, 1;
(EngineCore_DP0 pid=340598) 	mov.b32 	%r199, 0f2B8CBCCC;
(EngineCore_DP0 pid=340598) 	setp.eq.b32 	%p44, %r2, 0;
(EngineCore_DP0 pid=340598) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=340598) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=340598) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=340598) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=340598) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=340598) 	shr.u32 	%r41, %r2, 3;
(EngineCore_DP0 pid=340598) 	and.b32 	%r42, %r41, 60;
(EngineCore_DP0 pid=340598) 	mov.b32 	%r43, global_smem;
(EngineCore_DP0 pid=340598) 	add.s32 	%r53, %r43, %r42;
(EngineCore_DP0 pid=340598) 	shl.b32 	%r44, %r2, 2;
(EngineCore_DP0 pid=340598) 	add.s32 	%r56, %r43, %r44;
(EngineCore_DP0 pid=340598) 	mov.b32 	%r49, 0;
(EngineCore_DP0 pid=340598) 	mov.b32 	%r197, 0f00000000;
(EngineCore_DP0 pid=340598) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=340598) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=340598) 	mov.b32 	%r198, %r49;
(EngineCore_DP0 pid=340598) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=340598) 	.loc	1 189 22                        // quant_slide_tuned_Llama3.2-1B.py:189:22
(EngineCore_DP0 pid=340598) 	add.s32 	%r59, %r4, %r198;
(EngineCore_DP0 pid=340598) 	setp.lt.s32 	%p2, %r59, %r27;
(EngineCore_DP0 pid=340598) 	.loc	1 190 29                        // quant_slide_tuned_Llama3.2-1B.py:190:29
(EngineCore_DP0 pid=340598) 	mad.wide.s32 	%rd6, %r59, 2, %rd1;
(EngineCore_DP0 pid=340598) 	.loc	1 190 21                        // quant_slide_tuned_Llama3.2-1B.py:190:21
(EngineCore_DP0 pid=340598) 	// begin inline asm
(EngineCore_DP0 pid=340598) 	mov.u32 %r45, %r49;
(EngineCore_DP0 pid=340598) 	mov.u32 %r46, %r49;
(EngineCore_DP0 pid=340598) 	mov.u32 %r47, %r49;
(EngineCore_DP0 pid=340598) 	mov.u32 %r48, %r49;
(EngineCore_DP0 pid=340598) 	@%p2 ld.global.v4.b32 { %r45, %r46, %r47, %r48 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=340598) 	// end inline asm
(EngineCore_DP0 pid=340598) 	mov.b32 	{%rs1, %rs2}, %r45;
(EngineCore_DP0 pid=340598) 	mov.b32 	{%rs3, %rs4}, %r46;
(EngineCore_DP0 pid=340598) 	mov.b32 	{%rs5, %rs6}, %r47;
(EngineCore_DP0 pid=340598) 	mov.b32 	{%rs7, %rs8}, %r48;
(EngineCore_DP0 pid=340598) 	.loc	1 191 50                        // quant_slide_tuned_Llama3.2-1B.py:191:50
(EngineCore_DP0 pid=340598) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=340598) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=340598) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=340598) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=340598) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=340598) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=340598) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=340598) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=340598) $L__tmp1:
(EngineCore_DP0 pid=340598) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=340598) 	bar.sync 	0;
(EngineCore_DP0 pid=340598) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=340598) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=340598) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=340598) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=340598) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=340598) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=340598) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=340598) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=340598) 	cvt.f32.bf16 	%r60, %rs23;
(EngineCore_DP0 pid=340598) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=340598) 	shfl.sync.bfly.b32 	%r61, %r60, 16, 31, -1;
(EngineCore_DP0 pid=340598) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=340598) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=340598) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=340598) 	shfl.sync.bfly.b32 	%r63, %r62, 8, 31, -1;
(EngineCore_DP0 pid=340598) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=340598) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=340598) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=340598) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=340598) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=340598) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=340598) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=340598) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=340598) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=340598) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=340598) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=340598) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=340598) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=340598) 	max.f32 	%r54, %r68, %r69;
(EngineCore_DP0 pid=340598) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=340598) 	// begin inline asm
(EngineCore_DP0 pid=340598) 	@%p3 st.shared.b32 [ %r53 + 0 ], %r54;
(EngineCore_DP0 pid=340598) 	// end inline asm
(EngineCore_DP0 pid=340598) 	bar.sync 	0;
(EngineCore_DP0 pid=340598) 	// begin inline asm
(EngineCore_DP0 pid=340598) 	@%p4 ld.shared.b32 %r55, [ %r56 + 0 ];
(EngineCore_DP0 pid=340598) 	// end inline asm
(EngineCore_DP0 pid=340598) 	shfl.sync.bfly.b32 	%r70, %r55, 8, 31, -1;
(EngineCore_DP0 pid=340598) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=340598) 	max.f32 	%r71, %r55, %r70;
(EngineCore_DP0 pid=340598) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=340598) 	shfl.sync.bfly.b32 	%r72, %r71, 4, 31, -1;
(EngineCore_DP0 pid=340598) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=340598) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=340598) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=340598) 	shfl.sync.bfly.b32 	%r74, %r73, 2, 31, -1;
(EngineCore_DP0 pid=340598) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=340598) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=340598) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=340598) 	shfl.sync.bfly.b32 	%r76, %r75, 1, 31, -1;
(EngineCore_DP0 pid=340598) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=340598) 	max.f32 	%r58, %r75, %r76;
(EngineCore_DP0 pid=340598) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=340598) 	// begin inline asm
(EngineCore_DP0 pid=340598) 	@%p44 st.shared.b32 [ %r56 + 0 ], %r58;
(EngineCore_DP0 pid=340598) 	// end inline asm
(EngineCore_DP0 pid=340598) 	bar.sync 	0;
(EngineCore_DP0 pid=340598) 	ld.shared.b32 	%r77, [global_smem];
(EngineCore_DP0 pid=340598) $L__tmp2:
(EngineCore_DP0 pid=340598) 	.loc	1 191 36                        // quant_slide_tuned_Llama3.2-1B.py:191:36
(EngineCore_DP0 pid=340598) 	max.f32 	%r197, %r197, %r77;
(EngineCore_DP0 pid=340598) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=340598) 	add.s32 	%r198, %r198, 4096;
(EngineCore_DP0 pid=340598) 	setp.lt.s32 	%p6, %r198, %r28;
(EngineCore_DP0 pid=340598) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=340598) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=340598) 	.loc	1 193 32                        // quant_slide_tuned_Llama3.2-1B.py:193:32
(EngineCore_DP0 pid=340598) 	max.f32 	%r199, %r197, 0f2B8CBCCC;
(EngineCore_DP0 pid=340598) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=340598) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=340598) 	mov.b32 	%r79, 0f43E00000;
(EngineCore_DP0 pid=340598) 	.loc	1 194 32                        // quant_slide_tuned_Llama3.2-1B.py:194:32
(EngineCore_DP0 pid=340598) 	div.full.f32 	%r80, %r199, %r79;
(EngineCore_DP0 pid=340598) 	.loc	1 194 41                        // quant_slide_tuned_Llama3.2-1B.py:194:41
(EngineCore_DP0 pid=340598) 	max.f32 	%r78, %r80, 0f36924925;
(EngineCore_DP0 pid=340598) 	.loc	1 196 25                        // quant_slide_tuned_Llama3.2-1B.py:196:25
(EngineCore_DP0 pid=340598) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=340598) 	.loc	1 196 30                        // quant_slide_tuned_Llama3.2-1B.py:196:30
(EngineCore_DP0 pid=340598) 	// begin inline asm
(EngineCore_DP0 pid=340598) 	@%p44 st.global.b32 [ %rd7 + 0 ], { %r78 };
(EngineCore_DP0 pid=340598) 	// end inline asm
(EngineCore_DP0 pid=340598) 	.loc	1 199 29                        // quant_slide_tuned_Llama3.2-1B.py:199:29
(EngineCore_DP0 pid=340598) 	shl.b32 	%r15, %r29, 1;
(EngineCore_DP0 pid=340598) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=340598) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=340598) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=340598) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=340598) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=340598) 	ld.param.b32 	%r33, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=340598) 	shr.s32 	%r34, %r33, 31;
(EngineCore_DP0 pid=340598) 	shr.u32 	%r35, %r34, 30;
(EngineCore_DP0 pid=340598) 	add.s32 	%r36, %r33, %r35;
(EngineCore_DP0 pid=340598) 	shr.s32 	%r37, %r36, 2;
(EngineCore_DP0 pid=340598) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=340598) 	mul.lo.s32 	%r38, %r37, %r1;
(EngineCore_DP0 pid=340598) 	mad.wide.s32 	%rd2, %r38, 4, %rd5;
(EngineCore_DP0 pid=340598) 	div.full.f32 	%r14, %r79, %r199;
(EngineCore_DP0 pid=340598) 	shl.b32 	%r16, %r3, 2;
(EngineCore_DP0 pid=340598) 	mov.b32 	%r200, 0;
(EngineCore_DP0 pid=340598) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=340598)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=340598) 	.loc	1 202 31                        // quant_slide_tuned_Llama3.2-1B.py:202:31
(EngineCore_DP0 pid=340598) 	add.s32 	%r102, %r16, %r200;
(EngineCore_DP0 pid=340598) 	add.s32 	%r103, %r200, 1;
(EngineCore_DP0 pid=340598) 	.loc	1 203 30                        // quant_slide_tuned_Llama3.2-1B.py:203:30
(EngineCore_DP0 pid=340598) 	add.s32 	%r104, %r102, 2;
(EngineCore_DP0 pid=340598) 	setp.lt.s32 	%p25, %r102, %r15;
(EngineCore_DP0 pid=340598) 	setp.lt.s32 	%p26, %r104, %r15;
(EngineCore_DP0 pid=340598) 	.loc	1 206 24                        // quant_slide_tuned_Llama3.2-1B.py:206:24
(EngineCore_DP0 pid=340598) 	shr.u32 	%r105, %r102, 1;
(EngineCore_DP0 pid=340598) 	shr.u32 	%r106, %r104, 1;
(EngineCore_DP0 pid=340598) 	.loc	1 207 23                        // quant_slide_tuned_Llama3.2-1B.py:207:23
(EngineCore_DP0 pid=340598) 	shr.u32 	%r107, %r103, 31;
(EngineCore_DP0 pid=340598) 	add.s32 	%r108, %r103, %r107;
(EngineCore_DP0 pid=340598) 	and.b32 	%r109, %r108, 2147483646;
(EngineCore_DP0 pid=340598) 	sub.s32 	%r110, %r103, %r109;
(EngineCore_DP0 pid=340598) 	.loc	1 208 30                        // quant_slide_tuned_Llama3.2-1B.py:208:30
(EngineCore_DP0 pid=340598) 	shl.b32 	%r111, %r110, 1;
(EngineCore_DP0 pid=340598) 	.loc	1 208 22                        // quant_slide_tuned_Llama3.2-1B.py:208:22
(EngineCore_DP0 pid=340598) 	mul.lo.s32 	%r112, %r105, 6;
(EngineCore_DP0 pid=340598) 	mul.lo.s32 	%r113, %r106, 6;
(EngineCore_DP0 pid=340598) 	.loc	1 208 26                        // quant_slide_tuned_Llama3.2-1B.py:208:26
(EngineCore_DP0 pid=340598) 	add.s32 	%r114, %r112, %r111;
(EngineCore_DP0 pid=340598) 	add.s32 	%r115, %r113, %r111;
(EngineCore_DP0 pid=340598) 	.loc	1 211 53                        // quant_slide_tuned_Llama3.2-1B.py:211:53
(EngineCore_DP0 pid=340598) 	setp.lt.s32 	%p27, %r112, %r27;
(EngineCore_DP0 pid=340598) 	setp.lt.s32 	%p28, %r114, %r27;
(EngineCore_DP0 pid=340598) 	setp.lt.s32 	%p29, %r113, %r27;
(EngineCore_DP0 pid=340598) 	setp.lt.s32 	%p30, %r115, %r27;
(EngineCore_DP0 pid=340598) 	.loc	1 211 37                        // quant_slide_tuned_Llama3.2-1B.py:211:37
(EngineCore_DP0 pid=340598) 	and.pred 	%p9, %p25, %p27;
(EngineCore_DP0 pid=340598) 	and.pred 	%p10, %p25, %p28;
(EngineCore_DP0 pid=340598) 	and.pred 	%p11, %p26, %p29;
(EngineCore_DP0 pid=340598) 	and.pred 	%p12, %p26, %p30;
(EngineCore_DP0 pid=340598) 	.loc	1 210 29                        // quant_slide_tuned_Llama3.2-1B.py:210:29
(EngineCore_DP0 pid=340598) 	mad.wide.s32 	%rd8, %r112, 2, %rd1;
(EngineCore_DP0 pid=340598) 	mad.wide.s32 	%rd9, %r114, 2, %rd1;
(EngineCore_DP0 pid=340598) 	mad.wide.s32 	%rd10, %r113, 2, %rd1;
(EngineCore_DP0 pid=340598) 	mad.wide.s32 	%rd11, %r115, 2, %rd1;
(EngineCore_DP0 pid=340598) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=340598) 	.loc	1 210 21                        // quant_slide_tuned_Llama3.2-1B.py:210:21
(EngineCore_DP0 pid=340598) 	// begin inline asm
(EngineCore_DP0 pid=340598) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=340598) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=340598) 	// end inline asm
(EngineCore_DP0 pid=340598) 	// begin inline asm
(EngineCore_DP0 pid=340598) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=340598) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=340598) 	// end inline asm
(EngineCore_DP0 pid=340598) 	// begin inline asm
(EngineCore_DP0 pid=340598) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=340598) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=340598) 	// end inline asm
(EngineCore_DP0 pid=340598) 	// begin inline asm
(EngineCore_DP0 pid=340598) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=340598) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=340598) 	// end inline asm
(EngineCore_DP0 pid=340598) 	.loc	1 211 79                        // quant_slide_tuned_Llama3.2-1B.py:211:79
(EngineCore_DP0 pid=340598) 	cvt.f32.bf16 	%r116, %rs24;
(EngineCore_DP0 pid=340598) 	cvt.f32.bf16 	%r117, %rs26;
(EngineCore_DP0 pid=340598) 	cvt.f32.bf16 	%r118, %rs28;
(EngineCore_DP0 pid=340598) 	cvt.f32.bf16 	%r119, %rs30;
(EngineCore_DP0 pid=340598) 	.loc	1 217 48                        // quant_slide_tuned_Llama3.2-1B.py:217:48
(EngineCore_DP0 pid=340598) 	or.b32 	%r120, %r114, 1;
(EngineCore_DP0 pid=340598) 	or.b32 	%r121, %r115, 1;
(EngineCore_DP0 pid=340598) 	or.b32 	%r122, %r115, 2;
(EngineCore_DP0 pid=340598) 	or.b32 	%r123, %r115, 3;
(EngineCore_DP0 pid=340598) 	or.b32 	%r124, %r112, 1;
(EngineCore_DP0 pid=340598) 	or.b32 	%r125, %r113, 1;
(EngineCore_DP0 pid=340598) 	or.b32 	%r126, %r112, 2;
(EngineCore_DP0 pid=340598) 	or.b32 	%r127, %r112, 3;
(EngineCore_DP0 pid=340598) 	.loc	1 217 53                        // quant_slide_tuned_Llama3.2-1B.py:217:53
(EngineCore_DP0 pid=340598) 	setp.lt.s32 	%p31, %r123, %r27;
(EngineCore_DP0 pid=340598) 	setp.lt.s32 	%p32, %r122, %r27;
(EngineCore_DP0 pid=340598) 	setp.lt.s32 	%p33, %r121, %r27;
(EngineCore_DP0 pid=340598) 	setp.lt.s32 	%p34, %r120, %r27;
(EngineCore_DP0 pid=340598) 	setp.lt.s32 	%p35, %r127, %r27;
(EngineCore_DP0 pid=340598) 	setp.lt.s32 	%p36, %r126, %r27;
(EngineCore_DP0 pid=340598) 	setp.lt.s32 	%p37, %r125, %r27;
(EngineCore_DP0 pid=340598) 	setp.lt.s32 	%p38, %r124, %r27;
(EngineCore_DP0 pid=340598) 	.loc	1 213 37                        // quant_slide_tuned_Llama3.2-1B.py:213:37
(EngineCore_DP0 pid=340598) 	and.pred 	%p13, %p25, %p38;
(EngineCore_DP0 pid=340598) 	and.pred 	%p14, %p25, %p34;
(EngineCore_DP0 pid=340598) 	and.pred 	%p15, %p26, %p37;
(EngineCore_DP0 pid=340598) 	and.pred 	%p16, %p26, %p33;
(EngineCore_DP0 pid=340598) 	.loc	1 212 39                        // quant_slide_tuned_Llama3.2-1B.py:212:39
(EngineCore_DP0 pid=340598) 	add.s64 	%rd12, %rd8, 2;
(EngineCore_DP0 pid=340598) 	add.s64 	%rd13, %rd9, 2;
(EngineCore_DP0 pid=340598) 	add.s64 	%rd14, %rd10, 2;
(EngineCore_DP0 pid=340598) 	add.s64 	%rd15, %rd11, 2;
(EngineCore_DP0 pid=340598) 	.loc	1 212 21                        // quant_slide_tuned_Llama3.2-1B.py:212:21
(EngineCore_DP0 pid=340598) 	// begin inline asm
(EngineCore_DP0 pid=340598) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=340598) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=340598) 	// end inline asm
(EngineCore_DP0 pid=340598) 	// begin inline asm
(EngineCore_DP0 pid=340598) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=340598) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=340598) 	// end inline asm
(EngineCore_DP0 pid=340598) 	// begin inline asm
(EngineCore_DP0 pid=340598) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=340598) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=340598) 	// end inline asm
(EngineCore_DP0 pid=340598) 	// begin inline asm
(EngineCore_DP0 pid=340598) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=340598) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=340598) 	// end inline asm
(EngineCore_DP0 pid=340598) 	.loc	1 213 79                        // quant_slide_tuned_Llama3.2-1B.py:213:79
(EngineCore_DP0 pid=340598) 	cvt.f32.bf16 	%r128, %rs32;
(EngineCore_DP0 pid=340598) 	cvt.f32.bf16 	%r129, %rs34;
(EngineCore_DP0 pid=340598) 	cvt.f32.bf16 	%r130, %rs36;
(EngineCore_DP0 pid=340598) 	cvt.f32.bf16 	%r131, %rs38;
(EngineCore_DP0 pid=340598) 	.loc	1 215 48                        // quant_slide_tuned_Llama3.2-1B.py:215:48
(EngineCore_DP0 pid=340598) 	add.s32 	%r132, %r114, 2;
(EngineCore_DP0 pid=340598) 	add.s32 	%r133, %r113, 2;
(EngineCore_DP0 pid=340598) 	.loc	1 215 53                        // quant_slide_tuned_Llama3.2-1B.py:215:53
(EngineCore_DP0 pid=340598) 	setp.lt.s32 	%p39, %r132, %r27;
(EngineCore_DP0 pid=340598) 	setp.lt.s32 	%p40, %r133, %r27;
(EngineCore_DP0 pid=340598) 	.loc	1 215 37                        // quant_slide_tuned_Llama3.2-1B.py:215:37
(EngineCore_DP0 pid=340598) 	and.pred 	%p17, %p25, %p36;
(EngineCore_DP0 pid=340598) 	and.pred 	%p18, %p25, %p39;
(EngineCore_DP0 pid=340598) 	and.pred 	%p19, %p26, %p40;
(EngineCore_DP0 pid=340598) 	and.pred 	%p20, %p26, %p32;
(EngineCore_DP0 pid=340598) 	.loc	1 214 39                        // quant_slide_tuned_Llama3.2-1B.py:214:39
(EngineCore_DP0 pid=340598) 	add.s64 	%rd16, %rd8, 4;
(EngineCore_DP0 pid=340598) 	add.s64 	%rd17, %rd9, 4;
(EngineCore_DP0 pid=340598) 	add.s64 	%rd18, %rd10, 4;
(EngineCore_DP0 pid=340598) 	add.s64 	%rd19, %rd11, 4;
(EngineCore_DP0 pid=340598) 	.loc	1 214 21                        // quant_slide_tuned_Llama3.2-1B.py:214:21
(EngineCore_DP0 pid=340598) 	// begin inline asm
(EngineCore_DP0 pid=340598) 	mov.u16 %rs40, %rs25;
(EngineCore_DP0 pid=340598) 	@%p17 ld.global.b16 { %rs40 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=340598) 	// end inline asm
(EngineCore_DP0 pid=340598) 	// begin inline asm
(EngineCore_DP0 pid=340598) 	mov.u16 %rs42, %rs25;
(EngineCore_DP0 pid=340598) 	@%p18 ld.global.b16 { %rs42 }, [ %rd17 + 0 ];
(EngineCore_DP0 pid=340598) 	// end inline asm
(EngineCore_DP0 pid=340598) 	// begin inline asm
(EngineCore_DP0 pid=340598) 	mov.u16 %rs44, %rs25;
(EngineCore_DP0 pid=340598) 	@%p19 ld.global.b16 { %rs44 }, [ %rd18 + 0 ];
(EngineCore_DP0 pid=340598) 	// end inline asm
(EngineCore_DP0 pid=340598) 	// begin inline asm
(EngineCore_DP0 pid=340598) 	mov.u16 %rs46, %rs25;
(EngineCore_DP0 pid=340598) 	@%p20 ld.global.b16 { %rs46 }, [ %rd19 + 0 ];
(EngineCore_DP0 pid=340598) 	// end inline asm
(EngineCore_DP0 pid=340598) 	.loc	1 215 79                        // quant_slide_tuned_Llama3.2-1B.py:215:79
(EngineCore_DP0 pid=340598) 	cvt.f32.bf16 	%r134, %rs40;
(EngineCore_DP0 pid=340598) 	cvt.f32.bf16 	%r135, %rs42;
(EngineCore_DP0 pid=340598) 	cvt.f32.bf16 	%r136, %rs44;
(EngineCore_DP0 pid=340598) 	cvt.f32.bf16 	%r137, %rs46;
(EngineCore_DP0 pid=340598) 	.loc	1 217 48                        // quant_slide_tuned_Llama3.2-1B.py:217:48
(EngineCore_DP0 pid=340598) 	add.s32 	%r138, %r114, 3;
(EngineCore_DP0 pid=340598) 	add.s32 	%r139, %r113, 3;
(EngineCore_DP0 pid=340598) 	.loc	1 217 53                        // quant_slide_tuned_Llama3.2-1B.py:217:53
(EngineCore_DP0 pid=340598) 	setp.lt.s32 	%p41, %r138, %r27;
(EngineCore_DP0 pid=340598) 	setp.lt.s32 	%p42, %r139, %r27;
(EngineCore_DP0 pid=340598) 	.loc	1 217 37                        // quant_slide_tuned_Llama3.2-1B.py:217:37
(EngineCore_DP0 pid=340598) 	and.pred 	%p21, %p25, %p35;
(EngineCore_DP0 pid=340598) 	and.pred 	%p22, %p25, %p41;
(EngineCore_DP0 pid=340598) 	and.pred 	%p23, %p26, %p42;
(EngineCore_DP0 pid=340598) 	and.pred 	%p24, %p26, %p31;
(EngineCore_DP0 pid=340598) 	.loc	1 216 39                        // quant_slide_tuned_Llama3.2-1B.py:216:39
(EngineCore_DP0 pid=340598) 	add.s64 	%rd20, %rd8, 6;
(EngineCore_DP0 pid=340598) 	add.s64 	%rd21, %rd9, 6;
(EngineCore_DP0 pid=340598) 	add.s64 	%rd22, %rd10, 6;
(EngineCore_DP0 pid=340598) 	add.s64 	%rd23, %rd11, 6;
(EngineCore_DP0 pid=340598) 	.loc	1 216 21                        // quant_slide_tuned_Llama3.2-1B.py:216:21
(EngineCore_DP0 pid=340598) 	// begin inline asm
(EngineCore_DP0 pid=340598) 	mov.u16 %rs48, %rs25;
(EngineCore_DP0 pid=340598) 	@%p21 ld.global.b16 { %rs48 }, [ %rd20 + 0 ];
(EngineCore_DP0 pid=340598) 	// end inline asm
(EngineCore_DP0 pid=340598) 	// begin inline asm
(EngineCore_DP0 pid=340598) 	mov.u16 %rs50, %rs25;
(EngineCore_DP0 pid=340598) 	@%p22 ld.global.b16 { %rs50 }, [ %rd21 + 0 ];
(EngineCore_DP0 pid=340598) 	// end inline asm
(EngineCore_DP0 pid=340598) 	// begin inline asm
(EngineCore_DP0 pid=340598) 	mov.u16 %rs52, %rs25;
(EngineCore_DP0 pid=340598) 	@%p23 ld.global.b16 { %rs52 }, [ %rd22 + 0 ];
(EngineCore_DP0 pid=340598) 	// end inline asm
(EngineCore_DP0 pid=340598) 	// begin inline asm
(EngineCore_DP0 pid=340598) 	mov.u16 %rs54, %rs25;
(EngineCore_DP0 pid=340598) 	@%p24 ld.global.b16 { %rs54 }, [ %rd23 + 0 ];
(EngineCore_DP0 pid=340598) 	// end inline asm
(EngineCore_DP0 pid=340598) 	.loc	1 217 79                        // quant_slide_tuned_Llama3.2-1B.py:217:79
(EngineCore_DP0 pid=340598) 	cvt.f32.bf16 	%r140, %rs48;
(EngineCore_DP0 pid=340598) 	cvt.f32.bf16 	%r141, %rs50;
(EngineCore_DP0 pid=340598) 	cvt.f32.bf16 	%r142, %rs52;
(EngineCore_DP0 pid=340598) 	cvt.f32.bf16 	%r143, %rs54;
(EngineCore_DP0 pid=340598) 	.loc	1 219 27                        // quant_slide_tuned_Llama3.2-1B.py:219:27
(EngineCore_DP0 pid=340598) 	mul.f32 	%r144, %r14, %r116;
(EngineCore_DP0 pid=340598) 	mul.f32 	%r145, %r14, %r117;
(EngineCore_DP0 pid=340598) 	mul.f32 	%r146, %r14, %r118;
(EngineCore_DP0 pid=340598) 	mul.f32 	%r147, %r14, %r119;
(EngineCore_DP0 pid=340598) 	mov.b32 	%r148, 0f43E00000;
(EngineCore_DP0 pid=340598) 	.loc	1 219 48                        // quant_slide_tuned_Llama3.2-1B.py:219:48
(EngineCore_DP0 pid=340598) 	min.xorsign.abs.f32 	%r82, %r144, %r148;
(EngineCore_DP0 pid=340598) 	min.xorsign.abs.f32 	%r83, %r145, %r148;
(EngineCore_DP0 pid=340598) 	min.xorsign.abs.f32 	%r84, %r146, %r148;
(EngineCore_DP0 pid=340598) 	min.xorsign.abs.f32 	%r85, %r147, %r148;
(EngineCore_DP0 pid=340598) 	.loc	1 219 60                        // quant_slide_tuned_Llama3.2-1B.py:219:60
(EngineCore_DP0 pid=340598) 	// begin inline asm
(EngineCore_DP0 pid=340598) 	cvt.rn.satfinite.e4m3x2.f32  %rs56, %r83, %r82; 
(EngineCore_DP0 pid=340598) 
(EngineCore_DP0 pid=340598) 	// end inline asm
(EngineCore_DP0 pid=340598) 	shr.u16 	%rs64, %rs56, 8;
(EngineCore_DP0 pid=340598) 	// begin inline asm
(EngineCore_DP0 pid=340598) 	cvt.rn.satfinite.e4m3x2.f32  %rs57, %r85, %r84; 
(EngineCore_DP0 pid=340598) 
(EngineCore_DP0 pid=340598) 	// end inline asm
(EngineCore_DP0 pid=340598) 	shr.u16 	%rs65, %rs57, 8;
(EngineCore_DP0 pid=340598) 	.loc	1 220 27                        // quant_slide_tuned_Llama3.2-1B.py:220:27
(EngineCore_DP0 pid=340598) 	mul.f32 	%r149, %r14, %r128;
(EngineCore_DP0 pid=340598) 	mul.f32 	%r150, %r14, %r129;
(EngineCore_DP0 pid=340598) 	mul.f32 	%r151, %r14, %r130;
(EngineCore_DP0 pid=340598) 	mul.f32 	%r152, %r14, %r131;
(EngineCore_DP0 pid=340598) 	.loc	1 220 48                        // quant_slide_tuned_Llama3.2-1B.py:220:48
(EngineCore_DP0 pid=340598) 	min.xorsign.abs.f32 	%r86, %r149, %r148;
(EngineCore_DP0 pid=340598) 	min.xorsign.abs.f32 	%r87, %r150, %r148;
(EngineCore_DP0 pid=340598) 	min.xorsign.abs.f32 	%r88, %r151, %r148;
(EngineCore_DP0 pid=340598) 	min.xorsign.abs.f32 	%r89, %r152, %r148;
(EngineCore_DP0 pid=340598) 	.loc	1 220 60                        // quant_slide_tuned_Llama3.2-1B.py:220:60
(EngineCore_DP0 pid=340598) 	// begin inline asm
(EngineCore_DP0 pid=340598) 	cvt.rn.satfinite.e4m3x2.f32  %rs58, %r87, %r86; 
(EngineCore_DP0 pid=340598) 
(EngineCore_DP0 pid=340598) 	// end inline asm
(EngineCore_DP0 pid=340598) 	shr.u16 	%rs66, %rs58, 8;
(EngineCore_DP0 pid=340598) 	// begin inline asm
(EngineCore_DP0 pid=340598) 	cvt.rn.satfinite.e4m3x2.f32  %rs59, %r89, %r88; 
(EngineCore_DP0 pid=340598) 
(EngineCore_DP0 pid=340598) 	// end inline asm
(EngineCore_DP0 pid=340598) 	shr.u16 	%rs67, %rs59, 8;
(EngineCore_DP0 pid=340598) 	.loc	1 221 27                        // quant_slide_tuned_Llama3.2-1B.py:221:27
(EngineCore_DP0 pid=340598) 	mul.f32 	%r153, %r14, %r134;
(EngineCore_DP0 pid=340598) 	mul.f32 	%r154, %r14, %r135;
(EngineCore_DP0 pid=340598) 	mul.f32 	%r155, %r14, %r136;
(EngineCore_DP0 pid=340598) 	mul.f32 	%r156, %r14, %r137;
(EngineCore_DP0 pid=340598) 	.loc	1 221 48                        // quant_slide_tuned_Llama3.2-1B.py:221:48
(EngineCore_DP0 pid=340598) 	min.xorsign.abs.f32 	%r90, %r153, %r148;
(EngineCore_DP0 pid=340598) 	min.xorsign.abs.f32 	%r91, %r154, %r148;
(EngineCore_DP0 pid=340598) 	min.xorsign.abs.f32 	%r92, %r155, %r148;
(EngineCore_DP0 pid=340598) 	min.xorsign.abs.f32 	%r93, %r156, %r148;
(EngineCore_DP0 pid=340598) 	.loc	1 221 60                        // quant_slide_tuned_Llama3.2-1B.py:221:60
(EngineCore_DP0 pid=340598) 	// begin inline asm
(EngineCore_DP0 pid=340598) 	cvt.rn.satfinite.e4m3x2.f32  %rs60, %r91, %r90; 
(EngineCore_DP0 pid=340598) 
(EngineCore_DP0 pid=340598) 	// end inline asm
(EngineCore_DP0 pid=340598) 	shr.u16 	%rs68, %rs60, 8;
(EngineCore_DP0 pid=340598) 	// begin inline asm
(EngineCore_DP0 pid=340598) 	cvt.rn.satfinite.e4m3x2.f32  %rs61, %r93, %r92; 
(EngineCore_DP0 pid=340598) 
(EngineCore_DP0 pid=340598) 	// end inline asm
(EngineCore_DP0 pid=340598) 	shr.u16 	%rs69, %rs61, 8;
(EngineCore_DP0 pid=340598) 	.loc	1 222 27                        // quant_slide_tuned_Llama3.2-1B.py:222:27
(EngineCore_DP0 pid=340598) 	mul.f32 	%r157, %r14, %r140;
(EngineCore_DP0 pid=340598) 	mul.f32 	%r158, %r14, %r141;
(EngineCore_DP0 pid=340598) 	mul.f32 	%r159, %r14, %r142;
(EngineCore_DP0 pid=340598) 	mul.f32 	%r160, %r14, %r143;
(EngineCore_DP0 pid=340598) 	.loc	1 222 48                        // quant_slide_tuned_Llama3.2-1B.py:222:48
(EngineCore_DP0 pid=340598) 	min.xorsign.abs.f32 	%r94, %r157, %r148;
(EngineCore_DP0 pid=340598) 	min.xorsign.abs.f32 	%r95, %r158, %r148;
(EngineCore_DP0 pid=340598) 	min.xorsign.abs.f32 	%r96, %r159, %r148;
(EngineCore_DP0 pid=340598) 	min.xorsign.abs.f32 	%r97, %r160, %r148;
(EngineCore_DP0 pid=340598) 	.loc	1 222 60                        // quant_slide_tuned_Llama3.2-1B.py:222:60
(EngineCore_DP0 pid=340598) 	// begin inline asm
(EngineCore_DP0 pid=340598) 	cvt.rn.satfinite.e4m3x2.f32  %rs62, %r95, %r94; 
(EngineCore_DP0 pid=340598) 
(EngineCore_DP0 pid=340598) 	// end inline asm
(EngineCore_DP0 pid=340598) 	shr.u16 	%rs70, %rs62, 8;
(EngineCore_DP0 pid=340598) 	// begin inline asm
(EngineCore_DP0 pid=340598) 	cvt.rn.satfinite.e4m3x2.f32  %rs63, %r97, %r96; 
(EngineCore_DP0 pid=340598) 
(EngineCore_DP0 pid=340598) 	// end inline asm
(EngineCore_DP0 pid=340598) 	shr.u16 	%rs71, %rs63, 8;
(EngineCore_DP0 pid=340598) 	.loc	1 224 45                        // quant_slide_tuned_Llama3.2-1B.py:224:45
(EngineCore_DP0 pid=340598) 	cvt.u32.u16 	%r161, %rs56;
(EngineCore_DP0 pid=340598) 	and.b32 	%r162, %r161, 255;
(EngineCore_DP0 pid=340598) 	cvt.u32.u16 	%r163, %rs64;
(EngineCore_DP0 pid=340598) 	cvt.u32.u16 	%r164, %rs57;
(EngineCore_DP0 pid=340598) 	and.b32 	%r165, %r164, 255;
(EngineCore_DP0 pid=340598) 	cvt.u32.u16 	%r166, %rs65;
(EngineCore_DP0 pid=340598) 	.loc	1 226 45                        // quant_slide_tuned_Llama3.2-1B.py:226:45
(EngineCore_DP0 pid=340598) 	cvt.u32.u16 	%r167, %rs60;
(EngineCore_DP0 pid=340598) 	and.b32 	%r168, %r167, 255;
(EngineCore_DP0 pid=340598) 	cvt.u32.u16 	%r169, %rs68;
(EngineCore_DP0 pid=340598) 	cvt.u32.u16 	%r170, %rs61;
(EngineCore_DP0 pid=340598) 	and.b32 	%r171, %r170, 255;
(EngineCore_DP0 pid=340598) 	cvt.u32.u16 	%r172, %rs69;
(EngineCore_DP0 pid=340598) 	.loc	1 227 45                        // quant_slide_tuned_Llama3.2-1B.py:227:45
(EngineCore_DP0 pid=340598) 	cvt.u32.u16 	%r173, %rs62;
(EngineCore_DP0 pid=340598) 	cvt.u32.u16 	%r174, %rs70;
(EngineCore_DP0 pid=340598) 	cvt.u32.u16 	%r175, %rs63;
(EngineCore_DP0 pid=340598) 	cvt.u32.u16 	%r176, %rs71;
(EngineCore_DP0 pid=340598) 	.loc	1 229 30                        // quant_slide_tuned_Llama3.2-1B.py:229:30
(EngineCore_DP0 pid=340598) 	and.b16 	%rs72, %rs58, 255;
(EngineCore_DP0 pid=340598) 	mul.wide.u16 	%r177, %rs72, 256;
(EngineCore_DP0 pid=340598) 	mul.wide.u16 	%r178, %rs66, 256;
(EngineCore_DP0 pid=340598) 	and.b16 	%rs73, %rs59, 255;
(EngineCore_DP0 pid=340598) 	mul.wide.u16 	%r179, %rs73, 256;
(EngineCore_DP0 pid=340598) 	mul.wide.u16 	%r180, %rs67, 256;
(EngineCore_DP0 pid=340598) 	.loc	1 229 24                        // quant_slide_tuned_Llama3.2-1B.py:229:24
(EngineCore_DP0 pid=340598) 	or.b32 	%r181, %r177, %r162;
(EngineCore_DP0 pid=340598) 	or.b32 	%r182, %r178, %r163;
(EngineCore_DP0 pid=340598) 	or.b32 	%r183, %r179, %r165;
(EngineCore_DP0 pid=340598) 	or.b32 	%r184, %r180, %r166;
(EngineCore_DP0 pid=340598) 	.loc	1 229 42                        // quant_slide_tuned_Llama3.2-1B.py:229:42
(EngineCore_DP0 pid=340598) 	shl.b32 	%r185, %r168, 16;
(EngineCore_DP0 pid=340598) 	shl.b32 	%r186, %r169, 16;
(EngineCore_DP0 pid=340598) 	shl.b32 	%r187, %r171, 16;
(EngineCore_DP0 pid=340598) 	shl.b32 	%r188, %r172, 16;
(EngineCore_DP0 pid=340598) 	.loc	1 229 36                        // quant_slide_tuned_Llama3.2-1B.py:229:36
(EngineCore_DP0 pid=340598) 	or.b32 	%r189, %r185, %r181;
(EngineCore_DP0 pid=340598) 	or.b32 	%r190, %r186, %r182;
(EngineCore_DP0 pid=340598) 	or.b32 	%r191, %r187, %r183;
(EngineCore_DP0 pid=340598) 	or.b32 	%r192, %r188, %r184;
(EngineCore_DP0 pid=340598) 	.loc	1 229 55                        // quant_slide_tuned_Llama3.2-1B.py:229:55
(EngineCore_DP0 pid=340598) 	shl.b32 	%r193, %r173, 24;
(EngineCore_DP0 pid=340598) 	shl.b32 	%r194, %r174, 24;
(EngineCore_DP0 pid=340598) 	shl.b32 	%r195, %r175, 24;
(EngineCore_DP0 pid=340598) 	shl.b32 	%r196, %r176, 24;
(EngineCore_DP0 pid=340598) 	.loc	1 229 49                        // quant_slide_tuned_Llama3.2-1B.py:229:49
(EngineCore_DP0 pid=340598) 	or.b32 	%r98, %r193, %r189;
(EngineCore_DP0 pid=340598) 	or.b32 	%r99, %r194, %r190;
(EngineCore_DP0 pid=340598) 	or.b32 	%r100, %r195, %r191;
(EngineCore_DP0 pid=340598) 	or.b32 	%r101, %r196, %r192;
(EngineCore_DP0 pid=340598) 	.loc	1 230 29                        // quant_slide_tuned_Llama3.2-1B.py:230:29
(EngineCore_DP0 pid=340598) 	mad.wide.s32 	%rd24, %r102, 4, %rd2;
(EngineCore_DP0 pid=340598) 	add.s64 	%rd25, %rd24, 8;
(EngineCore_DP0 pid=340598) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-1B.py:230:39
(EngineCore_DP0 pid=340598) 	// begin inline asm
(EngineCore_DP0 pid=340598) 	@%p25 st.global.v2.b32 [ %rd24 + 0 ], { %r98, %r99 };
(EngineCore_DP0 pid=340598) 	// end inline asm
(EngineCore_DP0 pid=340598) 	// begin inline asm
(EngineCore_DP0 pid=340598) 	@%p26 st.global.v2.b32 [ %rd25 + 0 ], { %r100, %r101 };
(EngineCore_DP0 pid=340598) 	// end inline asm
(EngineCore_DP0 pid=340598) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=340598) 	add.s32 	%r200, %r200, 2048;
(EngineCore_DP0 pid=340598) 	setp.lt.s32 	%p43, %r200, %r15;
(EngineCore_DP0 pid=340598) 	@%p43 bra 	$L__BB0_6;
(EngineCore_DP0 pid=340598) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=340598) 	.loc	1 201 4                         // quant_slide_tuned_Llama3.2-1B.py:201:4
(EngineCore_DP0 pid=340598) 	ret;
(EngineCore_DP0 pid=340598) $L__tmp3:
(EngineCore_DP0 pid=340598) $L__func_end0:
(EngineCore_DP0 pid=340598)                                         // -- End function
(EngineCore_DP0 pid=340598) }
(EngineCore_DP0 pid=340598) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=340598) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=340598) 	.section	.debug_abbrev
(EngineCore_DP0 pid=340598) 	{
(EngineCore_DP0 pid=340598) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=340598) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=340598) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=340598) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=340598) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=340598) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=340598) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=340598) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=340598) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=340598) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=340598) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=340598) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=340598) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=340598) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=340598) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=340598) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=340598) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=340598) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=340598) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=340598) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=340598) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=340598) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=340598) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=340598) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=340598) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=340598) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=340598) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=340598) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=340598) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=340598) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=340598) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=340598) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=340598) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=340598) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=340598) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=340598) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=340598) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=340598) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=340598) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=340598) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=340598) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=340598) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=340598) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=340598) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=340598) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=340598) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=340598) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=340598) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=340598) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=340598) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=340598) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=340598) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=340598) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=340598) 	}
(EngineCore_DP0 pid=340598) 	.section	.debug_info
(EngineCore_DP0 pid=340598) 	{
(EngineCore_DP0 pid=340598) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=340598) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=340598) .b8 0
(EngineCore_DP0 pid=340598) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=340598) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=340598) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=340598) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=340598) .b8 114
(EngineCore_DP0 pid=340598) .b8 105
(EngineCore_DP0 pid=340598) .b8 116
(EngineCore_DP0 pid=340598) .b8 111
(EngineCore_DP0 pid=340598) .b8 110
(EngineCore_DP0 pid=340598) .b8 0
(EngineCore_DP0 pid=340598) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=340598) .b8 0
(EngineCore_DP0 pid=340598) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=340598) .b8 117
(EngineCore_DP0 pid=340598) .b8 97
(EngineCore_DP0 pid=340598) .b8 110
(EngineCore_DP0 pid=340598) .b8 116
(EngineCore_DP0 pid=340598) .b8 95
(EngineCore_DP0 pid=340598) .b8 115
(EngineCore_DP0 pid=340598) .b8 108
(EngineCore_DP0 pid=340598) .b8 105
(EngineCore_DP0 pid=340598) .b8 100
(EngineCore_DP0 pid=340598) .b8 101
(EngineCore_DP0 pid=340598) .b8 95
(EngineCore_DP0 pid=340598) .b8 116
(EngineCore_DP0 pid=340598) .b8 117
(EngineCore_DP0 pid=340598) .b8 110
(EngineCore_DP0 pid=340598) .b8 101
(EngineCore_DP0 pid=340598) .b8 100
(EngineCore_DP0 pid=340598) .b8 95
(EngineCore_DP0 pid=340598) .b8 76
(EngineCore_DP0 pid=340598) .b8 108
(EngineCore_DP0 pid=340598) .b8 97
(EngineCore_DP0 pid=340598) .b8 109
(EngineCore_DP0 pid=340598) .b8 97
(EngineCore_DP0 pid=340598) .b8 51
(EngineCore_DP0 pid=340598) .b8 46
(EngineCore_DP0 pid=340598) .b8 50
(EngineCore_DP0 pid=340598) .b8 45
(EngineCore_DP0 pid=340598) .b8 49
(EngineCore_DP0 pid=340598) .b8 66
(EngineCore_DP0 pid=340598) .b8 46
(EngineCore_DP0 pid=340598) .b8 112
(EngineCore_DP0 pid=340598) .b8 121
(EngineCore_DP0 pid=340598) .b8 0
(EngineCore_DP0 pid=340598) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=340598) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=340598) .b8 114
(EngineCore_DP0 pid=340598) .b8 111
(EngineCore_DP0 pid=340598) .b8 111
(EngineCore_DP0 pid=340598) .b8 116
(EngineCore_DP0 pid=340598) .b8 47
(EngineCore_DP0 pid=340598) .b8 118
(EngineCore_DP0 pid=340598) .b8 108
(EngineCore_DP0 pid=340598) .b8 108
(EngineCore_DP0 pid=340598) .b8 109
(EngineCore_DP0 pid=340598) .b8 98
(EngineCore_DP0 pid=340598) .b8 101
(EngineCore_DP0 pid=340598) .b8 110
(EngineCore_DP0 pid=340598) .b8 99
(EngineCore_DP0 pid=340598) .b8 104
(EngineCore_DP0 pid=340598) .b8 47
(EngineCore_DP0 pid=340598) .b8 115
(EngineCore_DP0 pid=340598) .b8 108
(EngineCore_DP0 pid=340598) .b8 105
(EngineCore_DP0 pid=340598) .b8 100
(EngineCore_DP0 pid=340598) .b8 101
(EngineCore_DP0 pid=340598) .b8 115
(EngineCore_DP0 pid=340598) .b8 112
(EngineCore_DP0 pid=340598) .b8 97
(EngineCore_DP0 pid=340598) .b8 114
(EngineCore_DP0 pid=340598) .b8 115
(EngineCore_DP0 pid=340598) .b8 101
(EngineCore_DP0 pid=340598) .b8 47
(EngineCore_DP0 pid=340598) .b8 99
(EngineCore_DP0 pid=340598) .b8 115
(EngineCore_DP0 pid=340598) .b8 114
(EngineCore_DP0 pid=340598) .b8 99
(EngineCore_DP0 pid=340598) .b8 47
(EngineCore_DP0 pid=340598) .b8 102
(EngineCore_DP0 pid=340598) .b8 117
(EngineCore_DP0 pid=340598) .b8 115
(EngineCore_DP0 pid=340598) .b8 101
(EngineCore_DP0 pid=340598) .b8 100
(EngineCore_DP0 pid=340598) .b8 95
(EngineCore_DP0 pid=340598) .b8 113
(EngineCore_DP0 pid=340598) .b8 117
(EngineCore_DP0 pid=340598) .b8 97
(EngineCore_DP0 pid=340598) .b8 110
(EngineCore_DP0 pid=340598) .b8 116
(EngineCore_DP0 pid=340598) .b8 95
(EngineCore_DP0 pid=340598) .b8 115
(EngineCore_DP0 pid=340598) .b8 108
(EngineCore_DP0 pid=340598) .b8 105
(EngineCore_DP0 pid=340598) .b8 100
(EngineCore_DP0 pid=340598) .b8 101
(EngineCore_DP0 pid=340598) .b8 95
(EngineCore_DP0 pid=340598) .b8 116
(EngineCore_DP0 pid=340598) .b8 114
(EngineCore_DP0 pid=340598) .b8 105
(EngineCore_DP0 pid=340598) .b8 116
(EngineCore_DP0 pid=340598) .b8 111
(EngineCore_DP0 pid=340598) .b8 110
(EngineCore_DP0 pid=340598) .b8 47
(EngineCore_DP0 pid=340598) .b8 98
(EngineCore_DP0 pid=340598) .b8 117
(EngineCore_DP0 pid=340598) .b8 105
(EngineCore_DP0 pid=340598) .b8 108
(EngineCore_DP0 pid=340598) .b8 100
(EngineCore_DP0 pid=340598) .b8 47
(EngineCore_DP0 pid=340598) .b8 71
(EngineCore_DP0 pid=340598) .b8 66
(EngineCore_DP0 pid=340598) .b8 49
(EngineCore_DP0 pid=340598) .b8 48
(EngineCore_DP0 pid=340598) .b8 95
(EngineCore_DP0 pid=340598) .b8 99
(EngineCore_DP0 pid=340598) .b8 99
(EngineCore_DP0 pid=340598) .b8 49
(EngineCore_DP0 pid=340598) .b8 50
(EngineCore_DP0 pid=340598) .b8 49
(EngineCore_DP0 pid=340598) .b8 95
(EngineCore_DP0 pid=340598) .b8 112
(EngineCore_DP0 pid=340598) .b8 121
(EngineCore_DP0 pid=340598) .b8 51
(EngineCore_DP0 pid=340598) .b8 49
(EngineCore_DP0 pid=340598) .b8 50
(EngineCore_DP0 pid=340598) .b8 95
(EngineCore_DP0 pid=340598) .b8 99
(EngineCore_DP0 pid=340598) .b8 117
(EngineCore_DP0 pid=340598) .b8 49
(EngineCore_DP0 pid=340598) .b8 50
(EngineCore_DP0 pid=340598) .b8 57
(EngineCore_DP0 pid=340598) .b8 95
(EngineCore_DP0 pid=340598) .b8 97
(EngineCore_DP0 pid=340598) .b8 97
(EngineCore_DP0 pid=340598) .b8 114
(EngineCore_DP0 pid=340598) .b8 99
(EngineCore_DP0 pid=340598) .b8 104
(EngineCore_DP0 pid=340598) .b8 54
(EngineCore_DP0 pid=340598) .b8 52
(EngineCore_DP0 pid=340598) .b8 0
(EngineCore_DP0 pid=340598) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=340598) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=340598) .b8 113
(EngineCore_DP0 pid=340598) .b8 117
(EngineCore_DP0 pid=340598) .b8 97
(EngineCore_DP0 pid=340598) .b8 110
(EngineCore_DP0 pid=340598) .b8 116
(EngineCore_DP0 pid=340598) .b8 95
(EngineCore_DP0 pid=340598) .b8 115
(EngineCore_DP0 pid=340598) .b8 108
(EngineCore_DP0 pid=340598) .b8 105
(EngineCore_DP0 pid=340598) .b8 100
(EngineCore_DP0 pid=340598) .b8 101
(EngineCore_DP0 pid=340598) .b8 95
(EngineCore_DP0 pid=340598) .b8 102
(EngineCore_DP0 pid=340598) .b8 112
(EngineCore_DP0 pid=340598) .b8 56
(EngineCore_DP0 pid=340598) .b8 95
(EngineCore_DP0 pid=340598) .b8 107
(EngineCore_DP0 pid=340598) .b8 101
(EngineCore_DP0 pid=340598) .b8 114
(EngineCore_DP0 pid=340598) .b8 110
(EngineCore_DP0 pid=340598) .b8 101
(EngineCore_DP0 pid=340598) .b8 108
(EngineCore_DP0 pid=340598) .b8 0
(EngineCore_DP0 pid=340598) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=340598) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=340598) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=340598) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=340598) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=340598) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=340598) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=340598) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=340598) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=340598) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=340598) .b8 191                                 // DW_AT_call_line
(EngineCore_DP0 pid=340598) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=340598) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=340598) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=340598) 	}
(EngineCore_DP0 pid=340598) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=340598) 
(EngineCore_DP0 pid=340598) ================================================================
(EngineCore_DP0 pid=340598) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=340598) 
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp9dlqxahl.ptx', '-o', '/tmp/tmp9dlqxahl.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866] 
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866] 
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866] 
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp9dlqxahl.ptx -o /tmp/tmp9dlqxahl.ptx.o
(EngineCore_DP0 pid=340598) ERROR 01-25 19:19:17 [core.py:866] 

STDERR:
[2026-01-25 19:19:02] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:19:02] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:19:02] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:19:02] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:19:02] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:19:02] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:19:02] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:19:02] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:19:02] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:19:02] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:19:02] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:19:02] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:19:02] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:19:02] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:19:05] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:19:05] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:19:05] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:19:05] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:19:05] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:19:05] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:19:05] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:19:05] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:19:05] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:19:05] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:19:05] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:19:05] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:19:05] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:19:05] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=340598) [2026-01-25 19:19:06] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=340598) [2026-01-25 19:19:06] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=340598) [2026-01-25 19:19:06] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=340598) [2026-01-25 19:19:06] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=340598) [2026-01-25 19:19:06] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=340598) [2026-01-25 19:19:06] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=340598) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=340598) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.45s/it]
(EngineCore_DP0 pid=340598) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.45s/it]
(EngineCore_DP0 pid=340598) 
(EngineCore_DP0 pid=340598) [2026-01-25 19:19:16] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=340598) [2026-01-25 19:19:16] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5308416 bytes
(EngineCore_DP0 pid=340598) [2026-01-25 19:19:16] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=340598) [2026-01-25 19:19:16] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3538944 bytes
(EngineCore_DP0 pid=340598) [2026-01-25 19:19:16] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=340598) [2026-01-25 19:19:16] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 28311552 bytes
(EngineCore_DP0 pid=340598) [2026-01-25 19:19:16] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=340598) [2026-01-25 19:19:16] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14024704 bytes
(EngineCore_DP0 pid=340598) Process EngineCore_DP0:
(EngineCore_DP0 pid=340598) Traceback (most recent call last):
(EngineCore_DP0 pid=340598)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=340598)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=340598)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=340598)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=340598) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp9dlqxahl.ptx', '-o', '/tmp/tmp9dlqxahl.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=340598) 
(EngineCore_DP0 pid=340598) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=340598) 
(EngineCore_DP0 pid=340598) Traceback (most recent call last):
(EngineCore_DP0 pid=340598)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=340598)     self.run()
(EngineCore_DP0 pid=340598)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=340598)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=340598)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=340598)     raise e
(EngineCore_DP0 pid=340598)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=340598)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=340598)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=340598)     super().__init__(
(EngineCore_DP0 pid=340598)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=340598)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=340598)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=340598)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=340598)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=340598)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=340598)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=340598)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=340598)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=340598)     return func(*args, **kwargs)
(EngineCore_DP0 pid=340598)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=340598)     return func(*args, **kwargs)
(EngineCore_DP0 pid=340598)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=340598)     self.model_runner.profile_run()
(EngineCore_DP0 pid=340598)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=340598)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=340598)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=340598)     return func(*args, **kwargs)
(EngineCore_DP0 pid=340598)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=340598)     outputs = self.model(
(EngineCore_DP0 pid=340598)               ^^^^^^^^^^^
(EngineCore_DP0 pid=340598)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=340598)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=340598)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=340598)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=340598)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=340598)     model_output = self.model(
(EngineCore_DP0 pid=340598)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=340598)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=340598)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=340598)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=340598)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=340598)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=340598)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=340598)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=340598)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=340598)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=340598)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=340598)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=340598)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=340598)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=340598)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=340598)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=340598)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=340598)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=340598)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=340598)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=340598)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=340598)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=340598)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=340598)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=340598)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=340598)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=340598)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=340598)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=340598)     return self._linear_fn(
(EngineCore_DP0 pid=340598)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=340598)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=340598)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=340598)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=340598)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=340598)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=340598)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=340598)     return fn(input, L)
(EngineCore_DP0 pid=340598)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=340598)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=340598)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=340598)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=340598)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=340598)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=340598)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=340598)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=340598)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=340598)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=340598)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=340598)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=340598)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=340598)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=340598)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=340598)     raise PTXASError(error)
(EngineCore_DP0 pid=340598) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=340598) `ptxas` stderr:
(EngineCore_DP0 pid=340598) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=340598) 
(EngineCore_DP0 pid=340598) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp9dlqxahl.ptx -o /tmp/tmp9dlqxahl.ptx.o
(EngineCore_DP0 pid=340598) 
[rank0]:[W125 19:19:17.105916174 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=32768

========== M=65536 ==========
Time: 2026-01-25 19:19:19
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-FP8_M65536.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:19:46 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:19:46 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=341389) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=341389) 
(EngineCore_DP0 pid=341389) 
(EngineCore_DP0 pid=341389) ================================================================
(EngineCore_DP0 pid=341389) Internal Triton PTX codegen error
(EngineCore_DP0 pid=341389) `ptxas` stderr:
(EngineCore_DP0 pid=341389) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=341389) 
(EngineCore_DP0 pid=341389) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpsoj_fxpe.ptx -o /tmp/tmpsoj_fxpe.ptx.o
(EngineCore_DP0 pid=341389) 
(EngineCore_DP0 pid=341389) 
(EngineCore_DP0 pid=341389) //
(EngineCore_DP0 pid=341389) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=341389) //
(EngineCore_DP0 pid=341389) 
(EngineCore_DP0 pid=341389) .version 8.7
(EngineCore_DP0 pid=341389) .target sm_121a
(EngineCore_DP0 pid=341389) .address_size 64
(EngineCore_DP0 pid=341389) 
(EngineCore_DP0 pid=341389) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=341389) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=341389)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=341389) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=341389) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=341389) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=341389) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=341389) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=341389) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=341389) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=341389) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=341389) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=341389) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=341389) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=341389) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=341389) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=341389) )
(EngineCore_DP0 pid=341389) .reqntid 512
(EngineCore_DP0 pid=341389) {
(EngineCore_DP0 pid=341389) 	.reg .pred 	%p<45>;
(EngineCore_DP0 pid=341389) 	.reg .b16 	%rs<74>;
(EngineCore_DP0 pid=341389) 	.reg .b32 	%r<201>;
(EngineCore_DP0 pid=341389) 	.reg .b64 	%rd<26>;
(EngineCore_DP0 pid=341389) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=341389) $L__func_begin0:
(EngineCore_DP0 pid=341389) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=341389) 
(EngineCore_DP0 pid=341389) // %bb.0:
(EngineCore_DP0 pid=341389) 	ld.param.b32 	%r29, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=341389) 	ld.param.b32 	%r28, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=341389) 	ld.param.b32 	%r27, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=341389) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=341389) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=341389) $L__tmp0:
(EngineCore_DP0 pid=341389) 	.loc	1 177 24                        // quant_slide_tuned_Llama3.2-1B.py:177:24
(EngineCore_DP0 pid=341389) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=341389) 	ld.param.b32 	%r31, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=341389) 	.loc	1 182 26                        // quant_slide_tuned_Llama3.2-1B.py:182:26
(EngineCore_DP0 pid=341389) 	mul.lo.s32 	%r32, %r31, %r1;
(EngineCore_DP0 pid=341389) 	.loc	1 182 20                        // quant_slide_tuned_Llama3.2-1B.py:182:20
(EngineCore_DP0 pid=341389) 	mad.wide.s32 	%rd1, %r32, 2, %rd4;
(EngineCore_DP0 pid=341389) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=341389) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=341389) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=341389) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=341389) 	setp.lt.s32 	%p1, %r28, 1;
(EngineCore_DP0 pid=341389) 	mov.b32 	%r199, 0f2B8CBCCC;
(EngineCore_DP0 pid=341389) 	setp.eq.b32 	%p44, %r2, 0;
(EngineCore_DP0 pid=341389) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=341389) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=341389) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=341389) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=341389) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=341389) 	shr.u32 	%r41, %r2, 3;
(EngineCore_DP0 pid=341389) 	and.b32 	%r42, %r41, 60;
(EngineCore_DP0 pid=341389) 	mov.b32 	%r43, global_smem;
(EngineCore_DP0 pid=341389) 	add.s32 	%r53, %r43, %r42;
(EngineCore_DP0 pid=341389) 	shl.b32 	%r44, %r2, 2;
(EngineCore_DP0 pid=341389) 	add.s32 	%r56, %r43, %r44;
(EngineCore_DP0 pid=341389) 	mov.b32 	%r49, 0;
(EngineCore_DP0 pid=341389) 	mov.b32 	%r197, 0f00000000;
(EngineCore_DP0 pid=341389) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=341389) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=341389) 	mov.b32 	%r198, %r49;
(EngineCore_DP0 pid=341389) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=341389) 	.loc	1 189 22                        // quant_slide_tuned_Llama3.2-1B.py:189:22
(EngineCore_DP0 pid=341389) 	add.s32 	%r59, %r4, %r198;
(EngineCore_DP0 pid=341389) 	setp.lt.s32 	%p2, %r59, %r27;
(EngineCore_DP0 pid=341389) 	.loc	1 190 29                        // quant_slide_tuned_Llama3.2-1B.py:190:29
(EngineCore_DP0 pid=341389) 	mad.wide.s32 	%rd6, %r59, 2, %rd1;
(EngineCore_DP0 pid=341389) 	.loc	1 190 21                        // quant_slide_tuned_Llama3.2-1B.py:190:21
(EngineCore_DP0 pid=341389) 	// begin inline asm
(EngineCore_DP0 pid=341389) 	mov.u32 %r45, %r49;
(EngineCore_DP0 pid=341389) 	mov.u32 %r46, %r49;
(EngineCore_DP0 pid=341389) 	mov.u32 %r47, %r49;
(EngineCore_DP0 pid=341389) 	mov.u32 %r48, %r49;
(EngineCore_DP0 pid=341389) 	@%p2 ld.global.v4.b32 { %r45, %r46, %r47, %r48 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=341389) 	// end inline asm
(EngineCore_DP0 pid=341389) 	mov.b32 	{%rs1, %rs2}, %r45;
(EngineCore_DP0 pid=341389) 	mov.b32 	{%rs3, %rs4}, %r46;
(EngineCore_DP0 pid=341389) 	mov.b32 	{%rs5, %rs6}, %r47;
(EngineCore_DP0 pid=341389) 	mov.b32 	{%rs7, %rs8}, %r48;
(EngineCore_DP0 pid=341389) 	.loc	1 191 50                        // quant_slide_tuned_Llama3.2-1B.py:191:50
(EngineCore_DP0 pid=341389) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=341389) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=341389) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=341389) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=341389) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=341389) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=341389) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=341389) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=341389) $L__tmp1:
(EngineCore_DP0 pid=341389) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=341389) 	bar.sync 	0;
(EngineCore_DP0 pid=341389) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=341389) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=341389) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=341389) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=341389) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=341389) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=341389) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=341389) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=341389) 	cvt.f32.bf16 	%r60, %rs23;
(EngineCore_DP0 pid=341389) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=341389) 	shfl.sync.bfly.b32 	%r61, %r60, 16, 31, -1;
(EngineCore_DP0 pid=341389) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=341389) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=341389) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=341389) 	shfl.sync.bfly.b32 	%r63, %r62, 8, 31, -1;
(EngineCore_DP0 pid=341389) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=341389) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=341389) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=341389) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=341389) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=341389) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=341389) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=341389) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=341389) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=341389) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=341389) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=341389) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=341389) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=341389) 	max.f32 	%r54, %r68, %r69;
(EngineCore_DP0 pid=341389) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=341389) 	// begin inline asm
(EngineCore_DP0 pid=341389) 	@%p3 st.shared.b32 [ %r53 + 0 ], %r54;
(EngineCore_DP0 pid=341389) 	// end inline asm
(EngineCore_DP0 pid=341389) 	bar.sync 	0;
(EngineCore_DP0 pid=341389) 	// begin inline asm
(EngineCore_DP0 pid=341389) 	@%p4 ld.shared.b32 %r55, [ %r56 + 0 ];
(EngineCore_DP0 pid=341389) 	// end inline asm
(EngineCore_DP0 pid=341389) 	shfl.sync.bfly.b32 	%r70, %r55, 8, 31, -1;
(EngineCore_DP0 pid=341389) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=341389) 	max.f32 	%r71, %r55, %r70;
(EngineCore_DP0 pid=341389) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=341389) 	shfl.sync.bfly.b32 	%r72, %r71, 4, 31, -1;
(EngineCore_DP0 pid=341389) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=341389) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=341389) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=341389) 	shfl.sync.bfly.b32 	%r74, %r73, 2, 31, -1;
(EngineCore_DP0 pid=341389) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=341389) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=341389) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=341389) 	shfl.sync.bfly.b32 	%r76, %r75, 1, 31, -1;
(EngineCore_DP0 pid=341389) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=341389) 	max.f32 	%r58, %r75, %r76;
(EngineCore_DP0 pid=341389) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=341389) 	// begin inline asm
(EngineCore_DP0 pid=341389) 	@%p44 st.shared.b32 [ %r56 + 0 ], %r58;
(EngineCore_DP0 pid=341389) 	// end inline asm
(EngineCore_DP0 pid=341389) 	bar.sync 	0;
(EngineCore_DP0 pid=341389) 	ld.shared.b32 	%r77, [global_smem];
(EngineCore_DP0 pid=341389) $L__tmp2:
(EngineCore_DP0 pid=341389) 	.loc	1 191 36                        // quant_slide_tuned_Llama3.2-1B.py:191:36
(EngineCore_DP0 pid=341389) 	max.f32 	%r197, %r197, %r77;
(EngineCore_DP0 pid=341389) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=341389) 	add.s32 	%r198, %r198, 4096;
(EngineCore_DP0 pid=341389) 	setp.lt.s32 	%p6, %r198, %r28;
(EngineCore_DP0 pid=341389) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=341389) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=341389) 	.loc	1 193 32                        // quant_slide_tuned_Llama3.2-1B.py:193:32
(EngineCore_DP0 pid=341389) 	max.f32 	%r199, %r197, 0f2B8CBCCC;
(EngineCore_DP0 pid=341389) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=341389) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=341389) 	mov.b32 	%r79, 0f43E00000;
(EngineCore_DP0 pid=341389) 	.loc	1 194 32                        // quant_slide_tuned_Llama3.2-1B.py:194:32
(EngineCore_DP0 pid=341389) 	div.full.f32 	%r80, %r199, %r79;
(EngineCore_DP0 pid=341389) 	.loc	1 194 41                        // quant_slide_tuned_Llama3.2-1B.py:194:41
(EngineCore_DP0 pid=341389) 	max.f32 	%r78, %r80, 0f36924925;
(EngineCore_DP0 pid=341389) 	.loc	1 196 25                        // quant_slide_tuned_Llama3.2-1B.py:196:25
(EngineCore_DP0 pid=341389) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=341389) 	.loc	1 196 30                        // quant_slide_tuned_Llama3.2-1B.py:196:30
(EngineCore_DP0 pid=341389) 	// begin inline asm
(EngineCore_DP0 pid=341389) 	@%p44 st.global.b32 [ %rd7 + 0 ], { %r78 };
(EngineCore_DP0 pid=341389) 	// end inline asm
(EngineCore_DP0 pid=341389) 	.loc	1 199 29                        // quant_slide_tuned_Llama3.2-1B.py:199:29
(EngineCore_DP0 pid=341389) 	shl.b32 	%r15, %r29, 1;
(EngineCore_DP0 pid=341389) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=341389) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=341389) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=341389) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=341389) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=341389) 	ld.param.b32 	%r33, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=341389) 	shr.s32 	%r34, %r33, 31;
(EngineCore_DP0 pid=341389) 	shr.u32 	%r35, %r34, 30;
(EngineCore_DP0 pid=341389) 	add.s32 	%r36, %r33, %r35;
(EngineCore_DP0 pid=341389) 	shr.s32 	%r37, %r36, 2;
(EngineCore_DP0 pid=341389) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=341389) 	mul.lo.s32 	%r38, %r37, %r1;
(EngineCore_DP0 pid=341389) 	mad.wide.s32 	%rd2, %r38, 4, %rd5;
(EngineCore_DP0 pid=341389) 	div.full.f32 	%r14, %r79, %r199;
(EngineCore_DP0 pid=341389) 	shl.b32 	%r16, %r3, 2;
(EngineCore_DP0 pid=341389) 	mov.b32 	%r200, 0;
(EngineCore_DP0 pid=341389) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=341389)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=341389) 	.loc	1 202 31                        // quant_slide_tuned_Llama3.2-1B.py:202:31
(EngineCore_DP0 pid=341389) 	add.s32 	%r102, %r16, %r200;
(EngineCore_DP0 pid=341389) 	add.s32 	%r103, %r200, 1;
(EngineCore_DP0 pid=341389) 	.loc	1 203 30                        // quant_slide_tuned_Llama3.2-1B.py:203:30
(EngineCore_DP0 pid=341389) 	add.s32 	%r104, %r102, 2;
(EngineCore_DP0 pid=341389) 	setp.lt.s32 	%p25, %r102, %r15;
(EngineCore_DP0 pid=341389) 	setp.lt.s32 	%p26, %r104, %r15;
(EngineCore_DP0 pid=341389) 	.loc	1 206 24                        // quant_slide_tuned_Llama3.2-1B.py:206:24
(EngineCore_DP0 pid=341389) 	shr.u32 	%r105, %r102, 1;
(EngineCore_DP0 pid=341389) 	shr.u32 	%r106, %r104, 1;
(EngineCore_DP0 pid=341389) 	.loc	1 207 23                        // quant_slide_tuned_Llama3.2-1B.py:207:23
(EngineCore_DP0 pid=341389) 	shr.u32 	%r107, %r103, 31;
(EngineCore_DP0 pid=341389) 	add.s32 	%r108, %r103, %r107;
(EngineCore_DP0 pid=341389) 	and.b32 	%r109, %r108, 2147483646;
(EngineCore_DP0 pid=341389) 	sub.s32 	%r110, %r103, %r109;
(EngineCore_DP0 pid=341389) 	.loc	1 208 30                        // quant_slide_tuned_Llama3.2-1B.py:208:30
(EngineCore_DP0 pid=341389) 	shl.b32 	%r111, %r110, 1;
(EngineCore_DP0 pid=341389) 	.loc	1 208 22                        // quant_slide_tuned_Llama3.2-1B.py:208:22
(EngineCore_DP0 pid=341389) 	mul.lo.s32 	%r112, %r105, 6;
(EngineCore_DP0 pid=341389) 	mul.lo.s32 	%r113, %r106, 6;
(EngineCore_DP0 pid=341389) 	.loc	1 208 26                        // quant_slide_tuned_Llama3.2-1B.py:208:26
(EngineCore_DP0 pid=341389) 	add.s32 	%r114, %r112, %r111;
(EngineCore_DP0 pid=341389) 	add.s32 	%r115, %r113, %r111;
(EngineCore_DP0 pid=341389) 	.loc	1 211 53                        // quant_slide_tuned_Llama3.2-1B.py:211:53
(EngineCore_DP0 pid=341389) 	setp.lt.s32 	%p27, %r112, %r27;
(EngineCore_DP0 pid=341389) 	setp.lt.s32 	%p28, %r114, %r27;
(EngineCore_DP0 pid=341389) 	setp.lt.s32 	%p29, %r113, %r27;
(EngineCore_DP0 pid=341389) 	setp.lt.s32 	%p30, %r115, %r27;
(EngineCore_DP0 pid=341389) 	.loc	1 211 37                        // quant_slide_tuned_Llama3.2-1B.py:211:37
(EngineCore_DP0 pid=341389) 	and.pred 	%p9, %p25, %p27;
(EngineCore_DP0 pid=341389) 	and.pred 	%p10, %p25, %p28;
(EngineCore_DP0 pid=341389) 	and.pred 	%p11, %p26, %p29;
(EngineCore_DP0 pid=341389) 	and.pred 	%p12, %p26, %p30;
(EngineCore_DP0 pid=341389) 	.loc	1 210 29                        // quant_slide_tuned_Llama3.2-1B.py:210:29
(EngineCore_DP0 pid=341389) 	mad.wide.s32 	%rd8, %r112, 2, %rd1;
(EngineCore_DP0 pid=341389) 	mad.wide.s32 	%rd9, %r114, 2, %rd1;
(EngineCore_DP0 pid=341389) 	mad.wide.s32 	%rd10, %r113, 2, %rd1;
(EngineCore_DP0 pid=341389) 	mad.wide.s32 	%rd11, %r115, 2, %rd1;
(EngineCore_DP0 pid=341389) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=341389) 	.loc	1 210 21                        // quant_slide_tuned_Llama3.2-1B.py:210:21
(EngineCore_DP0 pid=341389) 	// begin inline asm
(EngineCore_DP0 pid=341389) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=341389) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=341389) 	// end inline asm
(EngineCore_DP0 pid=341389) 	// begin inline asm
(EngineCore_DP0 pid=341389) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=341389) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=341389) 	// end inline asm
(EngineCore_DP0 pid=341389) 	// begin inline asm
(EngineCore_DP0 pid=341389) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=341389) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=341389) 	// end inline asm
(EngineCore_DP0 pid=341389) 	// begin inline asm
(EngineCore_DP0 pid=341389) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=341389) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=341389) 	// end inline asm
(EngineCore_DP0 pid=341389) 	.loc	1 211 79                        // quant_slide_tuned_Llama3.2-1B.py:211:79
(EngineCore_DP0 pid=341389) 	cvt.f32.bf16 	%r116, %rs24;
(EngineCore_DP0 pid=341389) 	cvt.f32.bf16 	%r117, %rs26;
(EngineCore_DP0 pid=341389) 	cvt.f32.bf16 	%r118, %rs28;
(EngineCore_DP0 pid=341389) 	cvt.f32.bf16 	%r119, %rs30;
(EngineCore_DP0 pid=341389) 	.loc	1 217 48                        // quant_slide_tuned_Llama3.2-1B.py:217:48
(EngineCore_DP0 pid=341389) 	or.b32 	%r120, %r114, 1;
(EngineCore_DP0 pid=341389) 	or.b32 	%r121, %r115, 1;
(EngineCore_DP0 pid=341389) 	or.b32 	%r122, %r115, 2;
(EngineCore_DP0 pid=341389) 	or.b32 	%r123, %r115, 3;
(EngineCore_DP0 pid=341389) 	or.b32 	%r124, %r112, 1;
(EngineCore_DP0 pid=341389) 	or.b32 	%r125, %r113, 1;
(EngineCore_DP0 pid=341389) 	or.b32 	%r126, %r112, 2;
(EngineCore_DP0 pid=341389) 	or.b32 	%r127, %r112, 3;
(EngineCore_DP0 pid=341389) 	.loc	1 217 53                        // quant_slide_tuned_Llama3.2-1B.py:217:53
(EngineCore_DP0 pid=341389) 	setp.lt.s32 	%p31, %r123, %r27;
(EngineCore_DP0 pid=341389) 	setp.lt.s32 	%p32, %r122, %r27;
(EngineCore_DP0 pid=341389) 	setp.lt.s32 	%p33, %r121, %r27;
(EngineCore_DP0 pid=341389) 	setp.lt.s32 	%p34, %r120, %r27;
(EngineCore_DP0 pid=341389) 	setp.lt.s32 	%p35, %r127, %r27;
(EngineCore_DP0 pid=341389) 	setp.lt.s32 	%p36, %r126, %r27;
(EngineCore_DP0 pid=341389) 	setp.lt.s32 	%p37, %r125, %r27;
(EngineCore_DP0 pid=341389) 	setp.lt.s32 	%p38, %r124, %r27;
(EngineCore_DP0 pid=341389) 	.loc	1 213 37                        // quant_slide_tuned_Llama3.2-1B.py:213:37
(EngineCore_DP0 pid=341389) 	and.pred 	%p13, %p25, %p38;
(EngineCore_DP0 pid=341389) 	and.pred 	%p14, %p25, %p34;
(EngineCore_DP0 pid=341389) 	and.pred 	%p15, %p26, %p37;
(EngineCore_DP0 pid=341389) 	and.pred 	%p16, %p26, %p33;
(EngineCore_DP0 pid=341389) 	.loc	1 212 39                        // quant_slide_tuned_Llama3.2-1B.py:212:39
(EngineCore_DP0 pid=341389) 	add.s64 	%rd12, %rd8, 2;
(EngineCore_DP0 pid=341389) 	add.s64 	%rd13, %rd9, 2;
(EngineCore_DP0 pid=341389) 	add.s64 	%rd14, %rd10, 2;
(EngineCore_DP0 pid=341389) 	add.s64 	%rd15, %rd11, 2;
(EngineCore_DP0 pid=341389) 	.loc	1 212 21                        // quant_slide_tuned_Llama3.2-1B.py:212:21
(EngineCore_DP0 pid=341389) 	// begin inline asm
(EngineCore_DP0 pid=341389) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=341389) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=341389) 	// end inline asm
(EngineCore_DP0 pid=341389) 	// begin inline asm
(EngineCore_DP0 pid=341389) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=341389) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=341389) 	// end inline asm
(EngineCore_DP0 pid=341389) 	// begin inline asm
(EngineCore_DP0 pid=341389) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=341389) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=341389) 	// end inline asm
(EngineCore_DP0 pid=341389) 	// begin inline asm
(EngineCore_DP0 pid=341389) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=341389) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=341389) 	// end inline asm
(EngineCore_DP0 pid=341389) 	.loc	1 213 79                        // quant_slide_tuned_Llama3.2-1B.py:213:79
(EngineCore_DP0 pid=341389) 	cvt.f32.bf16 	%r128, %rs32;
(EngineCore_DP0 pid=341389) 	cvt.f32.bf16 	%r129, %rs34;
(EngineCore_DP0 pid=341389) 	cvt.f32.bf16 	%r130, %rs36;
(EngineCore_DP0 pid=341389) 	cvt.f32.bf16 	%r131, %rs38;
(EngineCore_DP0 pid=341389) 	.loc	1 215 48                        // quant_slide_tuned_Llama3.2-1B.py:215:48
(EngineCore_DP0 pid=341389) 	add.s32 	%r132, %r114, 2;
(EngineCore_DP0 pid=341389) 	add.s32 	%r133, %r113, 2;
(EngineCore_DP0 pid=341389) 	.loc	1 215 53                        // quant_slide_tuned_Llama3.2-1B.py:215:53
(EngineCore_DP0 pid=341389) 	setp.lt.s32 	%p39, %r132, %r27;
(EngineCore_DP0 pid=341389) 	setp.lt.s32 	%p40, %r133, %r27;
(EngineCore_DP0 pid=341389) 	.loc	1 215 37                        // quant_slide_tuned_Llama3.2-1B.py:215:37
(EngineCore_DP0 pid=341389) 	and.pred 	%p17, %p25, %p36;
(EngineCore_DP0 pid=341389) 	and.pred 	%p18, %p25, %p39;
(EngineCore_DP0 pid=341389) 	and.pred 	%p19, %p26, %p40;
(EngineCore_DP0 pid=341389) 	and.pred 	%p20, %p26, %p32;
(EngineCore_DP0 pid=341389) 	.loc	1 214 39                        // quant_slide_tuned_Llama3.2-1B.py:214:39
(EngineCore_DP0 pid=341389) 	add.s64 	%rd16, %rd8, 4;
(EngineCore_DP0 pid=341389) 	add.s64 	%rd17, %rd9, 4;
(EngineCore_DP0 pid=341389) 	add.s64 	%rd18, %rd10, 4;
(EngineCore_DP0 pid=341389) 	add.s64 	%rd19, %rd11, 4;
(EngineCore_DP0 pid=341389) 	.loc	1 214 21                        // quant_slide_tuned_Llama3.2-1B.py:214:21
(EngineCore_DP0 pid=341389) 	// begin inline asm
(EngineCore_DP0 pid=341389) 	mov.u16 %rs40, %rs25;
(EngineCore_DP0 pid=341389) 	@%p17 ld.global.b16 { %rs40 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=341389) 	// end inline asm
(EngineCore_DP0 pid=341389) 	// begin inline asm
(EngineCore_DP0 pid=341389) 	mov.u16 %rs42, %rs25;
(EngineCore_DP0 pid=341389) 	@%p18 ld.global.b16 { %rs42 }, [ %rd17 + 0 ];
(EngineCore_DP0 pid=341389) 	// end inline asm
(EngineCore_DP0 pid=341389) 	// begin inline asm
(EngineCore_DP0 pid=341389) 	mov.u16 %rs44, %rs25;
(EngineCore_DP0 pid=341389) 	@%p19 ld.global.b16 { %rs44 }, [ %rd18 + 0 ];
(EngineCore_DP0 pid=341389) 	// end inline asm
(EngineCore_DP0 pid=341389) 	// begin inline asm
(EngineCore_DP0 pid=341389) 	mov.u16 %rs46, %rs25;
(EngineCore_DP0 pid=341389) 	@%p20 ld.global.b16 { %rs46 }, [ %rd19 + 0 ];
(EngineCore_DP0 pid=341389) 	// end inline asm
(EngineCore_DP0 pid=341389) 	.loc	1 215 79                        // quant_slide_tuned_Llama3.2-1B.py:215:79
(EngineCore_DP0 pid=341389) 	cvt.f32.bf16 	%r134, %rs40;
(EngineCore_DP0 pid=341389) 	cvt.f32.bf16 	%r135, %rs42;
(EngineCore_DP0 pid=341389) 	cvt.f32.bf16 	%r136, %rs44;
(EngineCore_DP0 pid=341389) 	cvt.f32.bf16 	%r137, %rs46;
(EngineCore_DP0 pid=341389) 	.loc	1 217 48                        // quant_slide_tuned_Llama3.2-1B.py:217:48
(EngineCore_DP0 pid=341389) 	add.s32 	%r138, %r114, 3;
(EngineCore_DP0 pid=341389) 	add.s32 	%r139, %r113, 3;
(EngineCore_DP0 pid=341389) 	.loc	1 217 53                        // quant_slide_tuned_Llama3.2-1B.py:217:53
(EngineCore_DP0 pid=341389) 	setp.lt.s32 	%p41, %r138, %r27;
(EngineCore_DP0 pid=341389) 	setp.lt.s32 	%p42, %r139, %r27;
(EngineCore_DP0 pid=341389) 	.loc	1 217 37                        // quant_slide_tuned_Llama3.2-1B.py:217:37
(EngineCore_DP0 pid=341389) 	and.pred 	%p21, %p25, %p35;
(EngineCore_DP0 pid=341389) 	and.pred 	%p22, %p25, %p41;
(EngineCore_DP0 pid=341389) 	and.pred 	%p23, %p26, %p42;
(EngineCore_DP0 pid=341389) 	and.pred 	%p24, %p26, %p31;
(EngineCore_DP0 pid=341389) 	.loc	1 216 39                        // quant_slide_tuned_Llama3.2-1B.py:216:39
(EngineCore_DP0 pid=341389) 	add.s64 	%rd20, %rd8, 6;
(EngineCore_DP0 pid=341389) 	add.s64 	%rd21, %rd9, 6;
(EngineCore_DP0 pid=341389) 	add.s64 	%rd22, %rd10, 6;
(EngineCore_DP0 pid=341389) 	add.s64 	%rd23, %rd11, 6;
(EngineCore_DP0 pid=341389) 	.loc	1 216 21                        // quant_slide_tuned_Llama3.2-1B.py:216:21
(EngineCore_DP0 pid=341389) 	// begin inline asm
(EngineCore_DP0 pid=341389) 	mov.u16 %rs48, %rs25;
(EngineCore_DP0 pid=341389) 	@%p21 ld.global.b16 { %rs48 }, [ %rd20 + 0 ];
(EngineCore_DP0 pid=341389) 	// end inline asm
(EngineCore_DP0 pid=341389) 	// begin inline asm
(EngineCore_DP0 pid=341389) 	mov.u16 %rs50, %rs25;
(EngineCore_DP0 pid=341389) 	@%p22 ld.global.b16 { %rs50 }, [ %rd21 + 0 ];
(EngineCore_DP0 pid=341389) 	// end inline asm
(EngineCore_DP0 pid=341389) 	// begin inline asm
(EngineCore_DP0 pid=341389) 	mov.u16 %rs52, %rs25;
(EngineCore_DP0 pid=341389) 	@%p23 ld.global.b16 { %rs52 }, [ %rd22 + 0 ];
(EngineCore_DP0 pid=341389) 	// end inline asm
(EngineCore_DP0 pid=341389) 	// begin inline asm
(EngineCore_DP0 pid=341389) 	mov.u16 %rs54, %rs25;
(EngineCore_DP0 pid=341389) 	@%p24 ld.global.b16 { %rs54 }, [ %rd23 + 0 ];
(EngineCore_DP0 pid=341389) 	// end inline asm
(EngineCore_DP0 pid=341389) 	.loc	1 217 79                        // quant_slide_tuned_Llama3.2-1B.py:217:79
(EngineCore_DP0 pid=341389) 	cvt.f32.bf16 	%r140, %rs48;
(EngineCore_DP0 pid=341389) 	cvt.f32.bf16 	%r141, %rs50;
(EngineCore_DP0 pid=341389) 	cvt.f32.bf16 	%r142, %rs52;
(EngineCore_DP0 pid=341389) 	cvt.f32.bf16 	%r143, %rs54;
(EngineCore_DP0 pid=341389) 	.loc	1 219 27                        // quant_slide_tuned_Llama3.2-1B.py:219:27
(EngineCore_DP0 pid=341389) 	mul.f32 	%r144, %r14, %r116;
(EngineCore_DP0 pid=341389) 	mul.f32 	%r145, %r14, %r117;
(EngineCore_DP0 pid=341389) 	mul.f32 	%r146, %r14, %r118;
(EngineCore_DP0 pid=341389) 	mul.f32 	%r147, %r14, %r119;
(EngineCore_DP0 pid=341389) 	mov.b32 	%r148, 0f43E00000;
(EngineCore_DP0 pid=341389) 	.loc	1 219 48                        // quant_slide_tuned_Llama3.2-1B.py:219:48
(EngineCore_DP0 pid=341389) 	min.xorsign.abs.f32 	%r82, %r144, %r148;
(EngineCore_DP0 pid=341389) 	min.xorsign.abs.f32 	%r83, %r145, %r148;
(EngineCore_DP0 pid=341389) 	min.xorsign.abs.f32 	%r84, %r146, %r148;
(EngineCore_DP0 pid=341389) 	min.xorsign.abs.f32 	%r85, %r147, %r148;
(EngineCore_DP0 pid=341389) 	.loc	1 219 60                        // quant_slide_tuned_Llama3.2-1B.py:219:60
(EngineCore_DP0 pid=341389) 	// begin inline asm
(EngineCore_DP0 pid=341389) 	cvt.rn.satfinite.e4m3x2.f32  %rs56, %r83, %r82; 
(EngineCore_DP0 pid=341389) 
(EngineCore_DP0 pid=341389) 	// end inline asm
(EngineCore_DP0 pid=341389) 	shr.u16 	%rs64, %rs56, 8;
(EngineCore_DP0 pid=341389) 	// begin inline asm
(EngineCore_DP0 pid=341389) 	cvt.rn.satfinite.e4m3x2.f32  %rs57, %r85, %r84; 
(EngineCore_DP0 pid=341389) 
(EngineCore_DP0 pid=341389) 	// end inline asm
(EngineCore_DP0 pid=341389) 	shr.u16 	%rs65, %rs57, 8;
(EngineCore_DP0 pid=341389) 	.loc	1 220 27                        // quant_slide_tuned_Llama3.2-1B.py:220:27
(EngineCore_DP0 pid=341389) 	mul.f32 	%r149, %r14, %r128;
(EngineCore_DP0 pid=341389) 	mul.f32 	%r150, %r14, %r129;
(EngineCore_DP0 pid=341389) 	mul.f32 	%r151, %r14, %r130;
(EngineCore_DP0 pid=341389) 	mul.f32 	%r152, %r14, %r131;
(EngineCore_DP0 pid=341389) 	.loc	1 220 48                        // quant_slide_tuned_Llama3.2-1B.py:220:48
(EngineCore_DP0 pid=341389) 	min.xorsign.abs.f32 	%r86, %r149, %r148;
(EngineCore_DP0 pid=341389) 	min.xorsign.abs.f32 	%r87, %r150, %r148;
(EngineCore_DP0 pid=341389) 	min.xorsign.abs.f32 	%r88, %r151, %r148;
(EngineCore_DP0 pid=341389) 	min.xorsign.abs.f32 	%r89, %r152, %r148;
(EngineCore_DP0 pid=341389) 	.loc	1 220 60                        // quant_slide_tuned_Llama3.2-1B.py:220:60
(EngineCore_DP0 pid=341389) 	// begin inline asm
(EngineCore_DP0 pid=341389) 	cvt.rn.satfinite.e4m3x2.f32  %rs58, %r87, %r86; 
(EngineCore_DP0 pid=341389) 
(EngineCore_DP0 pid=341389) 	// end inline asm
(EngineCore_DP0 pid=341389) 	shr.u16 	%rs66, %rs58, 8;
(EngineCore_DP0 pid=341389) 	// begin inline asm
(EngineCore_DP0 pid=341389) 	cvt.rn.satfinite.e4m3x2.f32  %rs59, %r89, %r88; 
(EngineCore_DP0 pid=341389) 
(EngineCore_DP0 pid=341389) 	// end inline asm
(EngineCore_DP0 pid=341389) 	shr.u16 	%rs67, %rs59, 8;
(EngineCore_DP0 pid=341389) 	.loc	1 221 27                        // quant_slide_tuned_Llama3.2-1B.py:221:27
(EngineCore_DP0 pid=341389) 	mul.f32 	%r153, %r14, %r134;
(EngineCore_DP0 pid=341389) 	mul.f32 	%r154, %r14, %r135;
(EngineCore_DP0 pid=341389) 	mul.f32 	%r155, %r14, %r136;
(EngineCore_DP0 pid=341389) 	mul.f32 	%r156, %r14, %r137;
(EngineCore_DP0 pid=341389) 	.loc	1 221 48                        // quant_slide_tuned_Llama3.2-1B.py:221:48
(EngineCore_DP0 pid=341389) 	min.xorsign.abs.f32 	%r90, %r153, %r148;
(EngineCore_DP0 pid=341389) 	min.xorsign.abs.f32 	%r91, %r154, %r148;
(EngineCore_DP0 pid=341389) 	min.xorsign.abs.f32 	%r92, %r155, %r148;
(EngineCore_DP0 pid=341389) 	min.xorsign.abs.f32 	%r93, %r156, %r148;
(EngineCore_DP0 pid=341389) 	.loc	1 221 60                        // quant_slide_tuned_Llama3.2-1B.py:221:60
(EngineCore_DP0 pid=341389) 	// begin inline asm
(EngineCore_DP0 pid=341389) 	cvt.rn.satfinite.e4m3x2.f32  %rs60, %r91, %r90; 
(EngineCore_DP0 pid=341389) 
(EngineCore_DP0 pid=341389) 	// end inline asm
(EngineCore_DP0 pid=341389) 	shr.u16 	%rs68, %rs60, 8;
(EngineCore_DP0 pid=341389) 	// begin inline asm
(EngineCore_DP0 pid=341389) 	cvt.rn.satfinite.e4m3x2.f32  %rs61, %r93, %r92; 
(EngineCore_DP0 pid=341389) 
(EngineCore_DP0 pid=341389) 	// end inline asm
(EngineCore_DP0 pid=341389) 	shr.u16 	%rs69, %rs61, 8;
(EngineCore_DP0 pid=341389) 	.loc	1 222 27                        // quant_slide_tuned_Llama3.2-1B.py:222:27
(EngineCore_DP0 pid=341389) 	mul.f32 	%r157, %r14, %r140;
(EngineCore_DP0 pid=341389) 	mul.f32 	%r158, %r14, %r141;
(EngineCore_DP0 pid=341389) 	mul.f32 	%r159, %r14, %r142;
(EngineCore_DP0 pid=341389) 	mul.f32 	%r160, %r14, %r143;
(EngineCore_DP0 pid=341389) 	.loc	1 222 48                        // quant_slide_tuned_Llama3.2-1B.py:222:48
(EngineCore_DP0 pid=341389) 	min.xorsign.abs.f32 	%r94, %r157, %r148;
(EngineCore_DP0 pid=341389) 	min.xorsign.abs.f32 	%r95, %r158, %r148;
(EngineCore_DP0 pid=341389) 	min.xorsign.abs.f32 	%r96, %r159, %r148;
(EngineCore_DP0 pid=341389) 	min.xorsign.abs.f32 	%r97, %r160, %r148;
(EngineCore_DP0 pid=341389) 	.loc	1 222 60                        // quant_slide_tuned_Llama3.2-1B.py:222:60
(EngineCore_DP0 pid=341389) 	// begin inline asm
(EngineCore_DP0 pid=341389) 	cvt.rn.satfinite.e4m3x2.f32  %rs62, %r95, %r94; 
(EngineCore_DP0 pid=341389) 
(EngineCore_DP0 pid=341389) 	// end inline asm
(EngineCore_DP0 pid=341389) 	shr.u16 	%rs70, %rs62, 8;
(EngineCore_DP0 pid=341389) 	// begin inline asm
(EngineCore_DP0 pid=341389) 	cvt.rn.satfinite.e4m3x2.f32  %rs63, %r97, %r96; 
(EngineCore_DP0 pid=341389) 
(EngineCore_DP0 pid=341389) 	// end inline asm
(EngineCore_DP0 pid=341389) 	shr.u16 	%rs71, %rs63, 8;
(EngineCore_DP0 pid=341389) 	.loc	1 224 45                        // quant_slide_tuned_Llama3.2-1B.py:224:45
(EngineCore_DP0 pid=341389) 	cvt.u32.u16 	%r161, %rs56;
(EngineCore_DP0 pid=341389) 	and.b32 	%r162, %r161, 255;
(EngineCore_DP0 pid=341389) 	cvt.u32.u16 	%r163, %rs64;
(EngineCore_DP0 pid=341389) 	cvt.u32.u16 	%r164, %rs57;
(EngineCore_DP0 pid=341389) 	and.b32 	%r165, %r164, 255;
(EngineCore_DP0 pid=341389) 	cvt.u32.u16 	%r166, %rs65;
(EngineCore_DP0 pid=341389) 	.loc	1 226 45                        // quant_slide_tuned_Llama3.2-1B.py:226:45
(EngineCore_DP0 pid=341389) 	cvt.u32.u16 	%r167, %rs60;
(EngineCore_DP0 pid=341389) 	and.b32 	%r168, %r167, 255;
(EngineCore_DP0 pid=341389) 	cvt.u32.u16 	%r169, %rs68;
(EngineCore_DP0 pid=341389) 	cvt.u32.u16 	%r170, %rs61;
(EngineCore_DP0 pid=341389) 	and.b32 	%r171, %r170, 255;
(EngineCore_DP0 pid=341389) 	cvt.u32.u16 	%r172, %rs69;
(EngineCore_DP0 pid=341389) 	.loc	1 227 45                        // quant_slide_tuned_Llama3.2-1B.py:227:45
(EngineCore_DP0 pid=341389) 	cvt.u32.u16 	%r173, %rs62;
(EngineCore_DP0 pid=341389) 	cvt.u32.u16 	%r174, %rs70;
(EngineCore_DP0 pid=341389) 	cvt.u32.u16 	%r175, %rs63;
(EngineCore_DP0 pid=341389) 	cvt.u32.u16 	%r176, %rs71;
(EngineCore_DP0 pid=341389) 	.loc	1 229 30                        // quant_slide_tuned_Llama3.2-1B.py:229:30
(EngineCore_DP0 pid=341389) 	and.b16 	%rs72, %rs58, 255;
(EngineCore_DP0 pid=341389) 	mul.wide.u16 	%r177, %rs72, 256;
(EngineCore_DP0 pid=341389) 	mul.wide.u16 	%r178, %rs66, 256;
(EngineCore_DP0 pid=341389) 	and.b16 	%rs73, %rs59, 255;
(EngineCore_DP0 pid=341389) 	mul.wide.u16 	%r179, %rs73, 256;
(EngineCore_DP0 pid=341389) 	mul.wide.u16 	%r180, %rs67, 256;
(EngineCore_DP0 pid=341389) 	.loc	1 229 24                        // quant_slide_tuned_Llama3.2-1B.py:229:24
(EngineCore_DP0 pid=341389) 	or.b32 	%r181, %r177, %r162;
(EngineCore_DP0 pid=341389) 	or.b32 	%r182, %r178, %r163;
(EngineCore_DP0 pid=341389) 	or.b32 	%r183, %r179, %r165;
(EngineCore_DP0 pid=341389) 	or.b32 	%r184, %r180, %r166;
(EngineCore_DP0 pid=341389) 	.loc	1 229 42                        // quant_slide_tuned_Llama3.2-1B.py:229:42
(EngineCore_DP0 pid=341389) 	shl.b32 	%r185, %r168, 16;
(EngineCore_DP0 pid=341389) 	shl.b32 	%r186, %r169, 16;
(EngineCore_DP0 pid=341389) 	shl.b32 	%r187, %r171, 16;
(EngineCore_DP0 pid=341389) 	shl.b32 	%r188, %r172, 16;
(EngineCore_DP0 pid=341389) 	.loc	1 229 36                        // quant_slide_tuned_Llama3.2-1B.py:229:36
(EngineCore_DP0 pid=341389) 	or.b32 	%r189, %r185, %r181;
(EngineCore_DP0 pid=341389) 	or.b32 	%r190, %r186, %r182;
(EngineCore_DP0 pid=341389) 	or.b32 	%r191, %r187, %r183;
(EngineCore_DP0 pid=341389) 	or.b32 	%r192, %r188, %r184;
(EngineCore_DP0 pid=341389) 	.loc	1 229 55                        // quant_slide_tuned_Llama3.2-1B.py:229:55
(EngineCore_DP0 pid=341389) 	shl.b32 	%r193, %r173, 24;
(EngineCore_DP0 pid=341389) 	shl.b32 	%r194, %r174, 24;
(EngineCore_DP0 pid=341389) 	shl.b32 	%r195, %r175, 24;
(EngineCore_DP0 pid=341389) 	shl.b32 	%r196, %r176, 24;
(EngineCore_DP0 pid=341389) 	.loc	1 229 49                        // quant_slide_tuned_Llama3.2-1B.py:229:49
(EngineCore_DP0 pid=341389) 	or.b32 	%r98, %r193, %r189;
(EngineCore_DP0 pid=341389) 	or.b32 	%r99, %r194, %r190;
(EngineCore_DP0 pid=341389) 	or.b32 	%r100, %r195, %r191;
(EngineCore_DP0 pid=341389) 	or.b32 	%r101, %r196, %r192;
(EngineCore_DP0 pid=341389) 	.loc	1 230 29                        // quant_slide_tuned_Llama3.2-1B.py:230:29
(EngineCore_DP0 pid=341389) 	mad.wide.s32 	%rd24, %r102, 4, %rd2;
(EngineCore_DP0 pid=341389) 	add.s64 	%rd25, %rd24, 8;
(EngineCore_DP0 pid=341389) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-1B.py:230:39
(EngineCore_DP0 pid=341389) 	// begin inline asm
(EngineCore_DP0 pid=341389) 	@%p25 st.global.v2.b32 [ %rd24 + 0 ], { %r98, %r99 };
(EngineCore_DP0 pid=341389) 	// end inline asm
(EngineCore_DP0 pid=341389) 	// begin inline asm
(EngineCore_DP0 pid=341389) 	@%p26 st.global.v2.b32 [ %rd25 + 0 ], { %r100, %r101 };
(EngineCore_DP0 pid=341389) 	// end inline asm
(EngineCore_DP0 pid=341389) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=341389) 	add.s32 	%r200, %r200, 2048;
(EngineCore_DP0 pid=341389) 	setp.lt.s32 	%p43, %r200, %r15;
(EngineCore_DP0 pid=341389) 	@%p43 bra 	$L__BB0_6;
(EngineCore_DP0 pid=341389) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=341389) 	.loc	1 201 4                         // quant_slide_tuned_Llama3.2-1B.py:201:4
(EngineCore_DP0 pid=341389) 	ret;
(EngineCore_DP0 pid=341389) $L__tmp3:
(EngineCore_DP0 pid=341389) $L__func_end0:
(EngineCore_DP0 pid=341389)                                         // -- End function
(EngineCore_DP0 pid=341389) }
(EngineCore_DP0 pid=341389) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=341389) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=341389) 	.section	.debug_abbrev
(EngineCore_DP0 pid=341389) 	{
(EngineCore_DP0 pid=341389) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=341389) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=341389) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=341389) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=341389) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=341389) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=341389) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=341389) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=341389) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=341389) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=341389) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=341389) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=341389) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=341389) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=341389) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=341389) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=341389) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=341389) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=341389) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=341389) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=341389) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=341389) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=341389) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=341389) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=341389) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=341389) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=341389) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=341389) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=341389) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=341389) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=341389) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=341389) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=341389) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=341389) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=341389) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=341389) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=341389) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=341389) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=341389) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=341389) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=341389) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=341389) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=341389) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=341389) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=341389) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=341389) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=341389) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=341389) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=341389) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=341389) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=341389) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=341389) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=341389) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=341389) 	}
(EngineCore_DP0 pid=341389) 	.section	.debug_info
(EngineCore_DP0 pid=341389) 	{
(EngineCore_DP0 pid=341389) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=341389) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=341389) .b8 0
(EngineCore_DP0 pid=341389) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=341389) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=341389) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=341389) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=341389) .b8 114
(EngineCore_DP0 pid=341389) .b8 105
(EngineCore_DP0 pid=341389) .b8 116
(EngineCore_DP0 pid=341389) .b8 111
(EngineCore_DP0 pid=341389) .b8 110
(EngineCore_DP0 pid=341389) .b8 0
(EngineCore_DP0 pid=341389) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=341389) .b8 0
(EngineCore_DP0 pid=341389) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=341389) .b8 117
(EngineCore_DP0 pid=341389) .b8 97
(EngineCore_DP0 pid=341389) .b8 110
(EngineCore_DP0 pid=341389) .b8 116
(EngineCore_DP0 pid=341389) .b8 95
(EngineCore_DP0 pid=341389) .b8 115
(EngineCore_DP0 pid=341389) .b8 108
(EngineCore_DP0 pid=341389) .b8 105
(EngineCore_DP0 pid=341389) .b8 100
(EngineCore_DP0 pid=341389) .b8 101
(EngineCore_DP0 pid=341389) .b8 95
(EngineCore_DP0 pid=341389) .b8 116
(EngineCore_DP0 pid=341389) .b8 117
(EngineCore_DP0 pid=341389) .b8 110
(EngineCore_DP0 pid=341389) .b8 101
(EngineCore_DP0 pid=341389) .b8 100
(EngineCore_DP0 pid=341389) .b8 95
(EngineCore_DP0 pid=341389) .b8 76
(EngineCore_DP0 pid=341389) .b8 108
(EngineCore_DP0 pid=341389) .b8 97
(EngineCore_DP0 pid=341389) .b8 109
(EngineCore_DP0 pid=341389) .b8 97
(EngineCore_DP0 pid=341389) .b8 51
(EngineCore_DP0 pid=341389) .b8 46
(EngineCore_DP0 pid=341389) .b8 50
(EngineCore_DP0 pid=341389) .b8 45
(EngineCore_DP0 pid=341389) .b8 49
(EngineCore_DP0 pid=341389) .b8 66
(EngineCore_DP0 pid=341389) .b8 46
(EngineCore_DP0 pid=341389) .b8 112
(EngineCore_DP0 pid=341389) .b8 121
(EngineCore_DP0 pid=341389) .b8 0
(EngineCore_DP0 pid=341389) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=341389) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=341389) .b8 114
(EngineCore_DP0 pid=341389) .b8 111
(EngineCore_DP0 pid=341389) .b8 111
(EngineCore_DP0 pid=341389) .b8 116
(EngineCore_DP0 pid=341389) .b8 47
(EngineCore_DP0 pid=341389) .b8 118
(EngineCore_DP0 pid=341389) .b8 108
(EngineCore_DP0 pid=341389) .b8 108
(EngineCore_DP0 pid=341389) .b8 109
(EngineCore_DP0 pid=341389) .b8 98
(EngineCore_DP0 pid=341389) .b8 101
(EngineCore_DP0 pid=341389) .b8 110
(EngineCore_DP0 pid=341389) .b8 99
(EngineCore_DP0 pid=341389) .b8 104
(EngineCore_DP0 pid=341389) .b8 47
(EngineCore_DP0 pid=341389) .b8 115
(EngineCore_DP0 pid=341389) .b8 108
(EngineCore_DP0 pid=341389) .b8 105
(EngineCore_DP0 pid=341389) .b8 100
(EngineCore_DP0 pid=341389) .b8 101
(EngineCore_DP0 pid=341389) .b8 115
(EngineCore_DP0 pid=341389) .b8 112
(EngineCore_DP0 pid=341389) .b8 97
(EngineCore_DP0 pid=341389) .b8 114
(EngineCore_DP0 pid=341389) .b8 115
(EngineCore_DP0 pid=341389) .b8 101
(EngineCore_DP0 pid=341389) .b8 47
(EngineCore_DP0 pid=341389) .b8 99
(EngineCore_DP0 pid=341389) .b8 115
(EngineCore_DP0 pid=341389) .b8 114
(EngineCore_DP0 pid=341389) .b8 99
(EngineCore_DP0 pid=341389) .b8 47
(EngineCore_DP0 pid=341389) .b8 102
(EngineCore_DP0 pid=341389) .b8 117
(EngineCore_DP0 pid=341389) .b8 115
(EngineCore_DP0 pid=341389) .b8 101
(EngineCore_DP0 pid=341389) .b8 100
(EngineCore_DP0 pid=341389) .b8 95
(EngineCore_DP0 pid=341389) .b8 113
(EngineCore_DP0 pid=341389) .b8 117
(EngineCore_DP0 pid=341389) .b8 97
(EngineCore_DP0 pid=341389) .b8 110
(EngineCore_DP0 pid=341389) .b8 116
(EngineCore_DP0 pid=341389) .b8 95
(EngineCore_DP0 pid=341389) .b8 115
(EngineCore_DP0 pid=341389) .b8 108
(EngineCore_DP0 pid=341389) .b8 105
(EngineCore_DP0 pid=341389) .b8 100
(EngineCore_DP0 pid=341389) .b8 101
(EngineCore_DP0 pid=341389) .b8 95
(EngineCore_DP0 pid=341389) .b8 116
(EngineCore_DP0 pid=341389) .b8 114
(EngineCore_DP0 pid=341389) .b8 105
(EngineCore_DP0 pid=341389) .b8 116
(EngineCore_DP0 pid=341389) .b8 111
(EngineCore_DP0 pid=341389) .b8 110
(EngineCore_DP0 pid=341389) .b8 47
(EngineCore_DP0 pid=341389) .b8 98
(EngineCore_DP0 pid=341389) .b8 117
(EngineCore_DP0 pid=341389) .b8 105
(EngineCore_DP0 pid=341389) .b8 108
(EngineCore_DP0 pid=341389) .b8 100
(EngineCore_DP0 pid=341389) .b8 47
(EngineCore_DP0 pid=341389) .b8 71
(EngineCore_DP0 pid=341389) .b8 66
(EngineCore_DP0 pid=341389) .b8 49
(EngineCore_DP0 pid=341389) .b8 48
(EngineCore_DP0 pid=341389) .b8 95
(EngineCore_DP0 pid=341389) .b8 99
(EngineCore_DP0 pid=341389) .b8 99
(EngineCore_DP0 pid=341389) .b8 49
(EngineCore_DP0 pid=341389) .b8 50
(EngineCore_DP0 pid=341389) .b8 49
(EngineCore_DP0 pid=341389) .b8 95
(EngineCore_DP0 pid=341389) .b8 112
(EngineCore_DP0 pid=341389) .b8 121
(EngineCore_DP0 pid=341389) .b8 51
(EngineCore_DP0 pid=341389) .b8 49
(EngineCore_DP0 pid=341389) .b8 50
(EngineCore_DP0 pid=341389) .b8 95
(EngineCore_DP0 pid=341389) .b8 99
(EngineCore_DP0 pid=341389) .b8 117
(EngineCore_DP0 pid=341389) .b8 49
(EngineCore_DP0 pid=341389) .b8 50
(EngineCore_DP0 pid=341389) .b8 57
(EngineCore_DP0 pid=341389) .b8 95
(EngineCore_DP0 pid=341389) .b8 97
(EngineCore_DP0 pid=341389) .b8 97
(EngineCore_DP0 pid=341389) .b8 114
(EngineCore_DP0 pid=341389) .b8 99
(EngineCore_DP0 pid=341389) .b8 104
(EngineCore_DP0 pid=341389) .b8 54
(EngineCore_DP0 pid=341389) .b8 52
(EngineCore_DP0 pid=341389) .b8 0
(EngineCore_DP0 pid=341389) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=341389) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=341389) .b8 113
(EngineCore_DP0 pid=341389) .b8 117
(EngineCore_DP0 pid=341389) .b8 97
(EngineCore_DP0 pid=341389) .b8 110
(EngineCore_DP0 pid=341389) .b8 116
(EngineCore_DP0 pid=341389) .b8 95
(EngineCore_DP0 pid=341389) .b8 115
(EngineCore_DP0 pid=341389) .b8 108
(EngineCore_DP0 pid=341389) .b8 105
(EngineCore_DP0 pid=341389) .b8 100
(EngineCore_DP0 pid=341389) .b8 101
(EngineCore_DP0 pid=341389) .b8 95
(EngineCore_DP0 pid=341389) .b8 102
(EngineCore_DP0 pid=341389) .b8 112
(EngineCore_DP0 pid=341389) .b8 56
(EngineCore_DP0 pid=341389) .b8 95
(EngineCore_DP0 pid=341389) .b8 107
(EngineCore_DP0 pid=341389) .b8 101
(EngineCore_DP0 pid=341389) .b8 114
(EngineCore_DP0 pid=341389) .b8 110
(EngineCore_DP0 pid=341389) .b8 101
(EngineCore_DP0 pid=341389) .b8 108
(EngineCore_DP0 pid=341389) .b8 0
(EngineCore_DP0 pid=341389) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=341389) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=341389) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=341389) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=341389) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=341389) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=341389) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=341389) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=341389) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=341389) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=341389) .b8 191                                 // DW_AT_call_line
(EngineCore_DP0 pid=341389) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=341389) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=341389) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=341389) 	}
(EngineCore_DP0 pid=341389) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=341389) 
(EngineCore_DP0 pid=341389) ================================================================
(EngineCore_DP0 pid=341389) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=341389) 
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpsoj_fxpe.ptx', '-o', '/tmp/tmpsoj_fxpe.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866] 
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866] 
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866] 
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpsoj_fxpe.ptx -o /tmp/tmpsoj_fxpe.ptx.o
(EngineCore_DP0 pid=341389) ERROR 01-25 19:20:01 [core.py:866] 

STDERR:
[2026-01-25 19:19:46] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:19:46] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:19:46] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:19:46] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:19:46] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:19:46] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:19:46] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:19:46] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:19:46] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:19:46] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:19:46] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:19:46] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:19:46] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:19:46] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:19:49] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:19:49] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:19:49] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:19:49] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:19:49] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:19:49] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:19:49] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:19:49] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:19:49] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:19:49] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:19:49] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:19:49] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:19:49] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:19:49] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=341389) [2026-01-25 19:19:50] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=341389) [2026-01-25 19:19:50] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=341389) [2026-01-25 19:19:50] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=341389) [2026-01-25 19:19:50] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=341389) [2026-01-25 19:19:50] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=341389) [2026-01-25 19:19:50] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=341389) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=341389) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.38s/it]
(EngineCore_DP0 pid=341389) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.38s/it]
(EngineCore_DP0 pid=341389) 
(EngineCore_DP0 pid=341389) [2026-01-25 19:20:00] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=341389) [2026-01-25 19:20:00] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5308416 bytes
(EngineCore_DP0 pid=341389) [2026-01-25 19:20:00] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=341389) [2026-01-25 19:20:00] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3538944 bytes
(EngineCore_DP0 pid=341389) [2026-01-25 19:20:00] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=341389) [2026-01-25 19:20:00] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 28311552 bytes
(EngineCore_DP0 pid=341389) [2026-01-25 19:20:00] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=341389) [2026-01-25 19:20:00] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14024704 bytes
(EngineCore_DP0 pid=341389) Process EngineCore_DP0:
(EngineCore_DP0 pid=341389) Traceback (most recent call last):
(EngineCore_DP0 pid=341389)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=341389)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=341389)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=341389)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=341389) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpsoj_fxpe.ptx', '-o', '/tmp/tmpsoj_fxpe.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=341389) 
(EngineCore_DP0 pid=341389) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=341389) 
(EngineCore_DP0 pid=341389) Traceback (most recent call last):
(EngineCore_DP0 pid=341389)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=341389)     self.run()
(EngineCore_DP0 pid=341389)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=341389)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=341389)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=341389)     raise e
(EngineCore_DP0 pid=341389)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=341389)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=341389)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=341389)     super().__init__(
(EngineCore_DP0 pid=341389)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=341389)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=341389)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=341389)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=341389)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=341389)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=341389)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=341389)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=341389)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=341389)     return func(*args, **kwargs)
(EngineCore_DP0 pid=341389)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=341389)     return func(*args, **kwargs)
(EngineCore_DP0 pid=341389)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=341389)     self.model_runner.profile_run()
(EngineCore_DP0 pid=341389)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=341389)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=341389)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=341389)     return func(*args, **kwargs)
(EngineCore_DP0 pid=341389)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=341389)     outputs = self.model(
(EngineCore_DP0 pid=341389)               ^^^^^^^^^^^
(EngineCore_DP0 pid=341389)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=341389)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=341389)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=341389)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=341389)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=341389)     model_output = self.model(
(EngineCore_DP0 pid=341389)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=341389)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=341389)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=341389)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=341389)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=341389)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=341389)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=341389)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=341389)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=341389)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=341389)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=341389)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=341389)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=341389)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=341389)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=341389)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=341389)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=341389)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=341389)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=341389)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=341389)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=341389)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=341389)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=341389)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=341389)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=341389)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=341389)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=341389)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=341389)     return self._linear_fn(
(EngineCore_DP0 pid=341389)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=341389)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=341389)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=341389)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=341389)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=341389)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=341389)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=341389)     return fn(input, L)
(EngineCore_DP0 pid=341389)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=341389)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=341389)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=341389)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=341389)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=341389)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=341389)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=341389)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=341389)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=341389)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=341389)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=341389)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=341389)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=341389)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341389)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=341389)     raise PTXASError(error)
(EngineCore_DP0 pid=341389) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=341389) `ptxas` stderr:
(EngineCore_DP0 pid=341389) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=341389) 
(EngineCore_DP0 pid=341389) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpsoj_fxpe.ptx -o /tmp/tmpsoj_fxpe.ptx.o
(EngineCore_DP0 pid=341389) 
[rank0]:[W125 19:20:01.760202525 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=65536

========== M=512 ==========
Time: 2026-01-25 20:04:18
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-3B-FP8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:04:22 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 20:04:22 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=392415) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=392415) 
(EngineCore_DP0 pid=392415) 
(EngineCore_DP0 pid=392415) ================================================================
(EngineCore_DP0 pid=392415) Internal Triton PTX codegen error
(EngineCore_DP0 pid=392415) `ptxas` stderr:
(EngineCore_DP0 pid=392415) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=392415) 
(EngineCore_DP0 pid=392415) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpyy7rbzcz.ptx -o /tmp/tmpyy7rbzcz.ptx.o
(EngineCore_DP0 pid=392415) 
(EngineCore_DP0 pid=392415) 
(EngineCore_DP0 pid=392415) //
(EngineCore_DP0 pid=392415) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=392415) //
(EngineCore_DP0 pid=392415) 
(EngineCore_DP0 pid=392415) .version 8.7
(EngineCore_DP0 pid=392415) .target sm_121a
(EngineCore_DP0 pid=392415) .address_size 64
(EngineCore_DP0 pid=392415) 
(EngineCore_DP0 pid=392415) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=392415) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=392415)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=392415) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=392415) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=392415) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=392415) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=392415) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=392415) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=392415) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=392415) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=392415) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=392415) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=392415) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=392415) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=392415) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=392415) )
(EngineCore_DP0 pid=392415) .reqntid 1024
(EngineCore_DP0 pid=392415) {
(EngineCore_DP0 pid=392415) 	.reg .pred 	%p<20>;
(EngineCore_DP0 pid=392415) 	.reg .b16 	%rs<25>;
(EngineCore_DP0 pid=392415) 	.reg .b32 	%r<114>;
(EngineCore_DP0 pid=392415) 	.reg .b64 	%rd<13>;
(EngineCore_DP0 pid=392415) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=392415) $L__func_begin0:
(EngineCore_DP0 pid=392415) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=392415) 
(EngineCore_DP0 pid=392415) // %bb.0:
(EngineCore_DP0 pid=392415) 	ld.param.b32 	%r19, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=392415) 	ld.param.b32 	%r18, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=392415) 	ld.param.b32 	%r17, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=392415) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=392415) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=392415) $L__tmp0:
(EngineCore_DP0 pid=392415) 	.loc	1 191 24                        // quant_slide_tuned_Llama3.2-3B.py:191:24
(EngineCore_DP0 pid=392415) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=392415) 	ld.param.b32 	%r21, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=392415) 	.loc	1 196 26                        // quant_slide_tuned_Llama3.2-3B.py:196:26
(EngineCore_DP0 pid=392415) 	mul.lo.s32 	%r22, %r21, %r1;
(EngineCore_DP0 pid=392415) 	.loc	1 196 20                        // quant_slide_tuned_Llama3.2-3B.py:196:20
(EngineCore_DP0 pid=392415) 	mad.wide.s32 	%rd1, %r22, 2, %rd4;
(EngineCore_DP0 pid=392415) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=392415) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=392415) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=392415) 	setp.lt.s32 	%p1, %r18, 1;
(EngineCore_DP0 pid=392415) 	mov.b32 	%r112, 0f2B8CBCCC;
(EngineCore_DP0 pid=392415) 	setp.eq.b32 	%p19, %r2, 0;
(EngineCore_DP0 pid=392415) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=392415) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=392415) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=392415) 	shl.b32 	%r3, %r2, 2;
(EngineCore_DP0 pid=392415) 	and.b32 	%r4, %r2, 31;
(EngineCore_DP0 pid=392415) 	shr.u32 	%r31, %r2, 3;
(EngineCore_DP0 pid=392415) 	and.b32 	%r32, %r31, 124;
(EngineCore_DP0 pid=392415) 	mov.b32 	%r33, global_smem;
(EngineCore_DP0 pid=392415) 	add.s32 	%r39, %r33, %r32;
(EngineCore_DP0 pid=392415) 	add.s32 	%r42, %r33, %r3;
(EngineCore_DP0 pid=392415) 	mov.b32 	%r37, 0;
(EngineCore_DP0 pid=392415) 	mov.b32 	%r110, 0f00000000;
(EngineCore_DP0 pid=392415) 	setp.lt.u32 	%p4, %r2, 32;
(EngineCore_DP0 pid=392415) 	setp.eq.b32 	%p3, %r4, 0;
(EngineCore_DP0 pid=392415) 	mov.b32 	%r111, %r37;
(EngineCore_DP0 pid=392415) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=392415) 	.loc	1 203 22                        // quant_slide_tuned_Llama3.2-3B.py:203:22
(EngineCore_DP0 pid=392415) 	add.s32 	%r45, %r3, %r111;
(EngineCore_DP0 pid=392415) 	setp.lt.s32 	%p2, %r45, %r17;
(EngineCore_DP0 pid=392415) 	.loc	1 204 29                        // quant_slide_tuned_Llama3.2-3B.py:204:29
(EngineCore_DP0 pid=392415) 	mad.wide.s32 	%rd6, %r45, 2, %rd1;
(EngineCore_DP0 pid=392415) 	.loc	1 204 21                        // quant_slide_tuned_Llama3.2-3B.py:204:21
(EngineCore_DP0 pid=392415) 	// begin inline asm
(EngineCore_DP0 pid=392415) 	mov.u32 %r35, %r37;
(EngineCore_DP0 pid=392415) 	mov.u32 %r36, %r37;
(EngineCore_DP0 pid=392415) 	@%p2 ld.global.v2.b32 { %r35, %r36 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=392415) 	// end inline asm
(EngineCore_DP0 pid=392415) 	mov.b32 	{%rs1, %rs2}, %r35;
(EngineCore_DP0 pid=392415) 	mov.b32 	{%rs3, %rs4}, %r36;
(EngineCore_DP0 pid=392415) 	.loc	1 205 50                        // quant_slide_tuned_Llama3.2-3B.py:205:50
(EngineCore_DP0 pid=392415) 	abs.bf16 	%rs5, %rs1;
(EngineCore_DP0 pid=392415) 	abs.bf16 	%rs6, %rs2;
(EngineCore_DP0 pid=392415) 	abs.bf16 	%rs7, %rs3;
(EngineCore_DP0 pid=392415) 	abs.bf16 	%rs8, %rs4;
(EngineCore_DP0 pid=392415) $L__tmp1:
(EngineCore_DP0 pid=392415) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=392415) 	bar.sync 	0;
(EngineCore_DP0 pid=392415) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=392415) 	max.bf16 	%rs9, %rs5, %rs6;
(EngineCore_DP0 pid=392415) 	max.bf16 	%rs10, %rs9, %rs7;
(EngineCore_DP0 pid=392415) 	max.bf16 	%rs11, %rs10, %rs8;
(EngineCore_DP0 pid=392415) 	cvt.f32.bf16 	%r46, %rs11;
(EngineCore_DP0 pid=392415) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=392415) 	shfl.sync.bfly.b32 	%r47, %r46, 16, 31, -1;
(EngineCore_DP0 pid=392415) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=392415) 	max.f32 	%r48, %r46, %r47;
(EngineCore_DP0 pid=392415) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=392415) 	shfl.sync.bfly.b32 	%r49, %r48, 8, 31, -1;
(EngineCore_DP0 pid=392415) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=392415) 	max.f32 	%r50, %r48, %r49;
(EngineCore_DP0 pid=392415) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=392415) 	shfl.sync.bfly.b32 	%r51, %r50, 4, 31, -1;
(EngineCore_DP0 pid=392415) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=392415) 	max.f32 	%r52, %r50, %r51;
(EngineCore_DP0 pid=392415) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=392415) 	shfl.sync.bfly.b32 	%r53, %r52, 2, 31, -1;
(EngineCore_DP0 pid=392415) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=392415) 	max.f32 	%r54, %r52, %r53;
(EngineCore_DP0 pid=392415) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=392415) 	shfl.sync.bfly.b32 	%r55, %r54, 1, 31, -1;
(EngineCore_DP0 pid=392415) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=392415) 	max.f32 	%r40, %r54, %r55;
(EngineCore_DP0 pid=392415) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=392415) 	// begin inline asm
(EngineCore_DP0 pid=392415) 	@%p3 st.shared.b32 [ %r39 + 0 ], %r40;
(EngineCore_DP0 pid=392415) 	// end inline asm
(EngineCore_DP0 pid=392415) 	bar.sync 	0;
(EngineCore_DP0 pid=392415) 	// begin inline asm
(EngineCore_DP0 pid=392415) 	@%p4 ld.shared.b32 %r41, [ %r42 + 0 ];
(EngineCore_DP0 pid=392415) 	// end inline asm
(EngineCore_DP0 pid=392415) 	shfl.sync.bfly.b32 	%r56, %r41, 16, 31, -1;
(EngineCore_DP0 pid=392415) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=392415) 	max.f32 	%r57, %r41, %r56;
(EngineCore_DP0 pid=392415) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=392415) 	shfl.sync.bfly.b32 	%r58, %r57, 8, 31, -1;
(EngineCore_DP0 pid=392415) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=392415) 	max.f32 	%r59, %r57, %r58;
(EngineCore_DP0 pid=392415) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=392415) 	shfl.sync.bfly.b32 	%r60, %r59, 4, 31, -1;
(EngineCore_DP0 pid=392415) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=392415) 	max.f32 	%r61, %r59, %r60;
(EngineCore_DP0 pid=392415) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=392415) 	shfl.sync.bfly.b32 	%r62, %r61, 2, 31, -1;
(EngineCore_DP0 pid=392415) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=392415) 	max.f32 	%r63, %r61, %r62;
(EngineCore_DP0 pid=392415) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=392415) 	shfl.sync.bfly.b32 	%r64, %r63, 1, 31, -1;
(EngineCore_DP0 pid=392415) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=392415) 	max.f32 	%r44, %r63, %r64;
(EngineCore_DP0 pid=392415) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=392415) 	// begin inline asm
(EngineCore_DP0 pid=392415) 	@%p19 st.shared.b32 [ %r42 + 0 ], %r44;
(EngineCore_DP0 pid=392415) 	// end inline asm
(EngineCore_DP0 pid=392415) 	bar.sync 	0;
(EngineCore_DP0 pid=392415) 	ld.shared.b32 	%r65, [global_smem];
(EngineCore_DP0 pid=392415) $L__tmp2:
(EngineCore_DP0 pid=392415) 	.loc	1 205 36                        // quant_slide_tuned_Llama3.2-3B.py:205:36
(EngineCore_DP0 pid=392415) 	max.f32 	%r110, %r110, %r65;
(EngineCore_DP0 pid=392415) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=392415) 	add.s32 	%r111, %r111, 4096;
(EngineCore_DP0 pid=392415) 	setp.lt.s32 	%p6, %r111, %r18;
(EngineCore_DP0 pid=392415) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=392415) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=392415) 	.loc	1 207 32                        // quant_slide_tuned_Llama3.2-3B.py:207:32
(EngineCore_DP0 pid=392415) 	max.f32 	%r112, %r110, 0f2B8CBCCC;
(EngineCore_DP0 pid=392415) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=392415) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-3B.py:0:32
(EngineCore_DP0 pid=392415) 	mov.b32 	%r67, 0f43E00000;
(EngineCore_DP0 pid=392415) 	.loc	1 208 32                        // quant_slide_tuned_Llama3.2-3B.py:208:32
(EngineCore_DP0 pid=392415) 	div.full.f32 	%r68, %r112, %r67;
(EngineCore_DP0 pid=392415) 	.loc	1 208 41                        // quant_slide_tuned_Llama3.2-3B.py:208:41
(EngineCore_DP0 pid=392415) 	max.f32 	%r66, %r68, 0f36924925;
(EngineCore_DP0 pid=392415) 	.loc	1 210 25                        // quant_slide_tuned_Llama3.2-3B.py:210:25
(EngineCore_DP0 pid=392415) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=392415) 	.loc	1 210 30                        // quant_slide_tuned_Llama3.2-3B.py:210:30
(EngineCore_DP0 pid=392415) 	// begin inline asm
(EngineCore_DP0 pid=392415) 	@%p19 st.global.b32 [ %rd7 + 0 ], { %r66 };
(EngineCore_DP0 pid=392415) 	// end inline asm
(EngineCore_DP0 pid=392415) 	.loc	1 213 29                        // quant_slide_tuned_Llama3.2-3B.py:213:29
(EngineCore_DP0 pid=392415) 	shl.b32 	%r14, %r19, 1;
(EngineCore_DP0 pid=392415) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=392415) 	setp.lt.s32 	%p8, %r14, 1;
(EngineCore_DP0 pid=392415) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=392415) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=392415) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-3B.py:0:41
(EngineCore_DP0 pid=392415) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=392415) 	shr.s32 	%r24, %r23, 31;
(EngineCore_DP0 pid=392415) 	shr.u32 	%r25, %r24, 30;
(EngineCore_DP0 pid=392415) 	add.s32 	%r26, %r23, %r25;
(EngineCore_DP0 pid=392415) 	shr.s32 	%r27, %r26, 2;
(EngineCore_DP0 pid=392415) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=392415) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=392415) 	mad.wide.s32 	%rd2, %r28, 4, %rd5;
(EngineCore_DP0 pid=392415) 	div.full.f32 	%r13, %r67, %r112;
(EngineCore_DP0 pid=392415) 	mov.b32 	%r113, 0;
(EngineCore_DP0 pid=392415) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=392415)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=392415) 	.loc	1 217 30                        // quant_slide_tuned_Llama3.2-3B.py:217:30
(EngineCore_DP0 pid=392415) 	add.s32 	%r80, %r2, %r113;
(EngineCore_DP0 pid=392415) 	setp.lt.s32 	%p13, %r80, %r14;
(EngineCore_DP0 pid=392415) 	.loc	1 220 24                        // quant_slide_tuned_Llama3.2-3B.py:220:24
(EngineCore_DP0 pid=392415) 	shr.u32 	%r81, %r80, 31;
(EngineCore_DP0 pid=392415) 	add.s32 	%r82, %r80, %r81;
(EngineCore_DP0 pid=392415) 	shr.u32 	%r83, %r82, 1;
(EngineCore_DP0 pid=392415) 	.loc	1 221 23                        // quant_slide_tuned_Llama3.2-3B.py:221:23
(EngineCore_DP0 pid=392415) 	and.b32 	%r84, %r82, 2147483646;
(EngineCore_DP0 pid=392415) 	sub.s32 	%r85, %r80, %r84;
(EngineCore_DP0 pid=392415) 	.loc	1 222 30                        // quant_slide_tuned_Llama3.2-3B.py:222:30
(EngineCore_DP0 pid=392415) 	shl.b32 	%r86, %r85, 1;
(EngineCore_DP0 pid=392415) 	.loc	1 222 26                        // quant_slide_tuned_Llama3.2-3B.py:222:26
(EngineCore_DP0 pid=392415) 	mad.lo.s32 	%r87, %r83, 6, %r86;
(EngineCore_DP0 pid=392415) 	.loc	1 225 53                        // quant_slide_tuned_Llama3.2-3B.py:225:53
(EngineCore_DP0 pid=392415) 	setp.lt.s32 	%p14, %r87, %r17;
(EngineCore_DP0 pid=392415) 	.loc	1 225 37                        // quant_slide_tuned_Llama3.2-3B.py:225:37
(EngineCore_DP0 pid=392415) 	and.pred 	%p9, %p13, %p14;
(EngineCore_DP0 pid=392415) 	.loc	1 224 29                        // quant_slide_tuned_Llama3.2-3B.py:224:29
(EngineCore_DP0 pid=392415) 	mad.wide.s32 	%rd8, %r87, 2, %rd1;
(EngineCore_DP0 pid=392415) 	mov.b16 	%rs13, 0;
(EngineCore_DP0 pid=392415) 	.loc	1 224 21                        // quant_slide_tuned_Llama3.2-3B.py:224:21
(EngineCore_DP0 pid=392415) 	// begin inline asm
(EngineCore_DP0 pid=392415) 	mov.u16 %rs12, %rs13;
(EngineCore_DP0 pid=392415) 	@%p9 ld.global.b16 { %rs12 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=392415) 	// end inline asm
(EngineCore_DP0 pid=392415) 	.loc	1 225 79                        // quant_slide_tuned_Llama3.2-3B.py:225:79
(EngineCore_DP0 pid=392415) 	cvt.f32.bf16 	%r88, %rs12;
(EngineCore_DP0 pid=392415) 	.loc	1 227 48                        // quant_slide_tuned_Llama3.2-3B.py:227:48
(EngineCore_DP0 pid=392415) 	or.b32 	%r89, %r87, 1;
(EngineCore_DP0 pid=392415) 	.loc	1 227 53                        // quant_slide_tuned_Llama3.2-3B.py:227:53
(EngineCore_DP0 pid=392415) 	setp.lt.s32 	%p15, %r89, %r17;
(EngineCore_DP0 pid=392415) 	.loc	1 227 37                        // quant_slide_tuned_Llama3.2-3B.py:227:37
(EngineCore_DP0 pid=392415) 	and.pred 	%p10, %p13, %p15;
(EngineCore_DP0 pid=392415) 	.loc	1 226 39                        // quant_slide_tuned_Llama3.2-3B.py:226:39
(EngineCore_DP0 pid=392415) 	add.s64 	%rd9, %rd8, 2;
(EngineCore_DP0 pid=392415) 	.loc	1 226 21                        // quant_slide_tuned_Llama3.2-3B.py:226:21
(EngineCore_DP0 pid=392415) 	// begin inline asm
(EngineCore_DP0 pid=392415) 	mov.u16 %rs14, %rs13;
(EngineCore_DP0 pid=392415) 	@%p10 ld.global.b16 { %rs14 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=392415) 	// end inline asm
(EngineCore_DP0 pid=392415) 	.loc	1 227 79                        // quant_slide_tuned_Llama3.2-3B.py:227:79
(EngineCore_DP0 pid=392415) 	cvt.f32.bf16 	%r90, %rs14;
(EngineCore_DP0 pid=392415) 	.loc	1 229 48                        // quant_slide_tuned_Llama3.2-3B.py:229:48
(EngineCore_DP0 pid=392415) 	add.s32 	%r91, %r87, 2;
(EngineCore_DP0 pid=392415) 	.loc	1 229 53                        // quant_slide_tuned_Llama3.2-3B.py:229:53
(EngineCore_DP0 pid=392415) 	setp.lt.s32 	%p16, %r91, %r17;
(EngineCore_DP0 pid=392415) 	.loc	1 229 37                        // quant_slide_tuned_Llama3.2-3B.py:229:37
(EngineCore_DP0 pid=392415) 	and.pred 	%p11, %p13, %p16;
(EngineCore_DP0 pid=392415) 	.loc	1 228 39                        // quant_slide_tuned_Llama3.2-3B.py:228:39
(EngineCore_DP0 pid=392415) 	add.s64 	%rd10, %rd8, 4;
(EngineCore_DP0 pid=392415) 	.loc	1 228 21                        // quant_slide_tuned_Llama3.2-3B.py:228:21
(EngineCore_DP0 pid=392415) 	// begin inline asm
(EngineCore_DP0 pid=392415) 	mov.u16 %rs16, %rs13;
(EngineCore_DP0 pid=392415) 	@%p11 ld.global.b16 { %rs16 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=392415) 	// end inline asm
(EngineCore_DP0 pid=392415) 	.loc	1 229 79                        // quant_slide_tuned_Llama3.2-3B.py:229:79
(EngineCore_DP0 pid=392415) 	cvt.f32.bf16 	%r92, %rs16;
(EngineCore_DP0 pid=392415) 	.loc	1 231 48                        // quant_slide_tuned_Llama3.2-3B.py:231:48
(EngineCore_DP0 pid=392415) 	add.s32 	%r93, %r87, 3;
(EngineCore_DP0 pid=392415) 	.loc	1 231 53                        // quant_slide_tuned_Llama3.2-3B.py:231:53
(EngineCore_DP0 pid=392415) 	setp.lt.s32 	%p17, %r93, %r17;
(EngineCore_DP0 pid=392415) 	.loc	1 231 37                        // quant_slide_tuned_Llama3.2-3B.py:231:37
(EngineCore_DP0 pid=392415) 	and.pred 	%p12, %p13, %p17;
(EngineCore_DP0 pid=392415) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-3B.py:230:39
(EngineCore_DP0 pid=392415) 	add.s64 	%rd11, %rd8, 6;
(EngineCore_DP0 pid=392415) 	.loc	1 230 21                        // quant_slide_tuned_Llama3.2-3B.py:230:21
(EngineCore_DP0 pid=392415) 	// begin inline asm
(EngineCore_DP0 pid=392415) 	mov.u16 %rs18, %rs13;
(EngineCore_DP0 pid=392415) 	@%p12 ld.global.b16 { %rs18 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=392415) 	// end inline asm
(EngineCore_DP0 pid=392415) 	.loc	1 231 79                        // quant_slide_tuned_Llama3.2-3B.py:231:79
(EngineCore_DP0 pid=392415) 	cvt.f32.bf16 	%r94, %rs18;
(EngineCore_DP0 pid=392415) 	.loc	1 233 27                        // quant_slide_tuned_Llama3.2-3B.py:233:27
(EngineCore_DP0 pid=392415) 	mul.f32 	%r95, %r13, %r88;
(EngineCore_DP0 pid=392415) 	mov.b32 	%r96, 0f43E00000;
(EngineCore_DP0 pid=392415) 	.loc	1 233 48                        // quant_slide_tuned_Llama3.2-3B.py:233:48
(EngineCore_DP0 pid=392415) 	min.xorsign.abs.f32 	%r70, %r95, %r96;
(EngineCore_DP0 pid=392415) 	.loc	1 233 60                        // quant_slide_tuned_Llama3.2-3B.py:233:60
(EngineCore_DP0 pid=392415) 	// begin inline asm
(EngineCore_DP0 pid=392415) 	cvt.rn.satfinite.e4m3x2.f32  %rs20, %r71, %r70; 
(EngineCore_DP0 pid=392415) 
(EngineCore_DP0 pid=392415) 	// end inline asm
(EngineCore_DP0 pid=392415) 	.loc	1 234 27                        // quant_slide_tuned_Llama3.2-3B.py:234:27
(EngineCore_DP0 pid=392415) 	mul.f32 	%r97, %r13, %r90;
(EngineCore_DP0 pid=392415) 	.loc	1 234 48                        // quant_slide_tuned_Llama3.2-3B.py:234:48
(EngineCore_DP0 pid=392415) 	min.xorsign.abs.f32 	%r72, %r97, %r96;
(EngineCore_DP0 pid=392415) 	.loc	1 234 60                        // quant_slide_tuned_Llama3.2-3B.py:234:60
(EngineCore_DP0 pid=392415) 	// begin inline asm
(EngineCore_DP0 pid=392415) 	cvt.rn.satfinite.e4m3x2.f32  %rs21, %r73, %r72; 
(EngineCore_DP0 pid=392415) 
(EngineCore_DP0 pid=392415) 	// end inline asm
(EngineCore_DP0 pid=392415) 	.loc	1 235 27                        // quant_slide_tuned_Llama3.2-3B.py:235:27
(EngineCore_DP0 pid=392415) 	mul.f32 	%r98, %r13, %r92;
(EngineCore_DP0 pid=392415) 	.loc	1 235 48                        // quant_slide_tuned_Llama3.2-3B.py:235:48
(EngineCore_DP0 pid=392415) 	min.xorsign.abs.f32 	%r74, %r98, %r96;
(EngineCore_DP0 pid=392415) 	.loc	1 235 60                        // quant_slide_tuned_Llama3.2-3B.py:235:60
(EngineCore_DP0 pid=392415) 	// begin inline asm
(EngineCore_DP0 pid=392415) 	cvt.rn.satfinite.e4m3x2.f32  %rs22, %r75, %r74; 
(EngineCore_DP0 pid=392415) 
(EngineCore_DP0 pid=392415) 	// end inline asm
(EngineCore_DP0 pid=392415) 	.loc	1 236 27                        // quant_slide_tuned_Llama3.2-3B.py:236:27
(EngineCore_DP0 pid=392415) 	mul.f32 	%r99, %r13, %r94;
(EngineCore_DP0 pid=392415) 	.loc	1 236 48                        // quant_slide_tuned_Llama3.2-3B.py:236:48
(EngineCore_DP0 pid=392415) 	min.xorsign.abs.f32 	%r76, %r99, %r96;
(EngineCore_DP0 pid=392415) 	.loc	1 236 60                        // quant_slide_tuned_Llama3.2-3B.py:236:60
(EngineCore_DP0 pid=392415) 	// begin inline asm
(EngineCore_DP0 pid=392415) 	cvt.rn.satfinite.e4m3x2.f32  %rs23, %r77, %r76; 
(EngineCore_DP0 pid=392415) 
(EngineCore_DP0 pid=392415) 	// end inline asm
(EngineCore_DP0 pid=392415) 	.loc	1 238 45                        // quant_slide_tuned_Llama3.2-3B.py:238:45
(EngineCore_DP0 pid=392415) 	cvt.u32.u16 	%r100, %rs20;
(EngineCore_DP0 pid=392415) 	and.b32 	%r101, %r100, 255;
(EngineCore_DP0 pid=392415) 	.loc	1 240 45                        // quant_slide_tuned_Llama3.2-3B.py:240:45
(EngineCore_DP0 pid=392415) 	cvt.u32.u16 	%r102, %rs22;
(EngineCore_DP0 pid=392415) 	and.b32 	%r103, %r102, 255;
(EngineCore_DP0 pid=392415) 	.loc	1 241 45                        // quant_slide_tuned_Llama3.2-3B.py:241:45
(EngineCore_DP0 pid=392415) 	cvt.u32.u16 	%r104, %rs23;
(EngineCore_DP0 pid=392415) 	.loc	1 243 30                        // quant_slide_tuned_Llama3.2-3B.py:243:30
(EngineCore_DP0 pid=392415) 	and.b16 	%rs24, %rs21, 255;
(EngineCore_DP0 pid=392415) 	mul.wide.u16 	%r105, %rs24, 256;
(EngineCore_DP0 pid=392415) 	.loc	1 243 24                        // quant_slide_tuned_Llama3.2-3B.py:243:24
(EngineCore_DP0 pid=392415) 	or.b32 	%r106, %r105, %r101;
(EngineCore_DP0 pid=392415) 	.loc	1 243 42                        // quant_slide_tuned_Llama3.2-3B.py:243:42
(EngineCore_DP0 pid=392415) 	shl.b32 	%r107, %r103, 16;
(EngineCore_DP0 pid=392415) 	.loc	1 243 36                        // quant_slide_tuned_Llama3.2-3B.py:243:36
(EngineCore_DP0 pid=392415) 	or.b32 	%r108, %r106, %r107;
(EngineCore_DP0 pid=392415) 	.loc	1 243 55                        // quant_slide_tuned_Llama3.2-3B.py:243:55
(EngineCore_DP0 pid=392415) 	shl.b32 	%r109, %r104, 24;
(EngineCore_DP0 pid=392415) 	.loc	1 243 49                        // quant_slide_tuned_Llama3.2-3B.py:243:49
(EngineCore_DP0 pid=392415) 	or.b32 	%r78, %r108, %r109;
(EngineCore_DP0 pid=392415) 	.loc	1 244 29                        // quant_slide_tuned_Llama3.2-3B.py:244:29
(EngineCore_DP0 pid=392415) 	mad.wide.s32 	%rd12, %r80, 4, %rd2;
(EngineCore_DP0 pid=392415) 	.loc	1 244 39                        // quant_slide_tuned_Llama3.2-3B.py:244:39
(EngineCore_DP0 pid=392415) 	// begin inline asm
(EngineCore_DP0 pid=392415) 	@%p13 st.global.b32 [ %rd12 + 0 ], { %r78 };
(EngineCore_DP0 pid=392415) 	// end inline asm
(EngineCore_DP0 pid=392415) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=392415) 	add.s32 	%r113, %r113, 1024;
(EngineCore_DP0 pid=392415) 	setp.lt.s32 	%p18, %r113, %r14;
(EngineCore_DP0 pid=392415) 	@%p18 bra 	$L__BB0_6;
(EngineCore_DP0 pid=392415) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=392415) 	.loc	1 215 4                         // quant_slide_tuned_Llama3.2-3B.py:215:4
(EngineCore_DP0 pid=392415) 	ret;
(EngineCore_DP0 pid=392415) $L__tmp3:
(EngineCore_DP0 pid=392415) $L__func_end0:
(EngineCore_DP0 pid=392415)                                         // -- End function
(EngineCore_DP0 pid=392415) }
(EngineCore_DP0 pid=392415) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py"
(EngineCore_DP0 pid=392415) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=392415) 	.section	.debug_abbrev
(EngineCore_DP0 pid=392415) 	{
(EngineCore_DP0 pid=392415) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=392415) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=392415) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=392415) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=392415) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=392415) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=392415) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=392415) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=392415) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=392415) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=392415) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=392415) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=392415) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=392415) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=392415) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=392415) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=392415) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=392415) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=392415) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=392415) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=392415) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=392415) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=392415) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=392415) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=392415) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=392415) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=392415) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=392415) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=392415) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=392415) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=392415) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=392415) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=392415) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=392415) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=392415) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=392415) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=392415) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=392415) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=392415) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=392415) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=392415) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=392415) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=392415) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=392415) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=392415) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=392415) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=392415) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=392415) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=392415) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=392415) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=392415) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=392415) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=392415) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=392415) 	}
(EngineCore_DP0 pid=392415) 	.section	.debug_info
(EngineCore_DP0 pid=392415) 	{
(EngineCore_DP0 pid=392415) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=392415) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=392415) .b8 0
(EngineCore_DP0 pid=392415) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=392415) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=392415) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=392415) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=392415) .b8 114
(EngineCore_DP0 pid=392415) .b8 105
(EngineCore_DP0 pid=392415) .b8 116
(EngineCore_DP0 pid=392415) .b8 111
(EngineCore_DP0 pid=392415) .b8 110
(EngineCore_DP0 pid=392415) .b8 0
(EngineCore_DP0 pid=392415) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=392415) .b8 0
(EngineCore_DP0 pid=392415) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=392415) .b8 117
(EngineCore_DP0 pid=392415) .b8 97
(EngineCore_DP0 pid=392415) .b8 110
(EngineCore_DP0 pid=392415) .b8 116
(EngineCore_DP0 pid=392415) .b8 95
(EngineCore_DP0 pid=392415) .b8 115
(EngineCore_DP0 pid=392415) .b8 108
(EngineCore_DP0 pid=392415) .b8 105
(EngineCore_DP0 pid=392415) .b8 100
(EngineCore_DP0 pid=392415) .b8 101
(EngineCore_DP0 pid=392415) .b8 95
(EngineCore_DP0 pid=392415) .b8 116
(EngineCore_DP0 pid=392415) .b8 117
(EngineCore_DP0 pid=392415) .b8 110
(EngineCore_DP0 pid=392415) .b8 101
(EngineCore_DP0 pid=392415) .b8 100
(EngineCore_DP0 pid=392415) .b8 95
(EngineCore_DP0 pid=392415) .b8 76
(EngineCore_DP0 pid=392415) .b8 108
(EngineCore_DP0 pid=392415) .b8 97
(EngineCore_DP0 pid=392415) .b8 109
(EngineCore_DP0 pid=392415) .b8 97
(EngineCore_DP0 pid=392415) .b8 51
(EngineCore_DP0 pid=392415) .b8 46
(EngineCore_DP0 pid=392415) .b8 50
(EngineCore_DP0 pid=392415) .b8 45
(EngineCore_DP0 pid=392415) .b8 51
(EngineCore_DP0 pid=392415) .b8 66
(EngineCore_DP0 pid=392415) .b8 46
(EngineCore_DP0 pid=392415) .b8 112
(EngineCore_DP0 pid=392415) .b8 121
(EngineCore_DP0 pid=392415) .b8 0
(EngineCore_DP0 pid=392415) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=392415) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=392415) .b8 114
(EngineCore_DP0 pid=392415) .b8 111
(EngineCore_DP0 pid=392415) .b8 111
(EngineCore_DP0 pid=392415) .b8 116
(EngineCore_DP0 pid=392415) .b8 47
(EngineCore_DP0 pid=392415) .b8 118
(EngineCore_DP0 pid=392415) .b8 108
(EngineCore_DP0 pid=392415) .b8 108
(EngineCore_DP0 pid=392415) .b8 109
(EngineCore_DP0 pid=392415) .b8 98
(EngineCore_DP0 pid=392415) .b8 101
(EngineCore_DP0 pid=392415) .b8 110
(EngineCore_DP0 pid=392415) .b8 99
(EngineCore_DP0 pid=392415) .b8 104
(EngineCore_DP0 pid=392415) .b8 47
(EngineCore_DP0 pid=392415) .b8 115
(EngineCore_DP0 pid=392415) .b8 108
(EngineCore_DP0 pid=392415) .b8 105
(EngineCore_DP0 pid=392415) .b8 100
(EngineCore_DP0 pid=392415) .b8 101
(EngineCore_DP0 pid=392415) .b8 115
(EngineCore_DP0 pid=392415) .b8 112
(EngineCore_DP0 pid=392415) .b8 97
(EngineCore_DP0 pid=392415) .b8 114
(EngineCore_DP0 pid=392415) .b8 115
(EngineCore_DP0 pid=392415) .b8 101
(EngineCore_DP0 pid=392415) .b8 47
(EngineCore_DP0 pid=392415) .b8 99
(EngineCore_DP0 pid=392415) .b8 115
(EngineCore_DP0 pid=392415) .b8 114
(EngineCore_DP0 pid=392415) .b8 99
(EngineCore_DP0 pid=392415) .b8 47
(EngineCore_DP0 pid=392415) .b8 102
(EngineCore_DP0 pid=392415) .b8 117
(EngineCore_DP0 pid=392415) .b8 115
(EngineCore_DP0 pid=392415) .b8 101
(EngineCore_DP0 pid=392415) .b8 100
(EngineCore_DP0 pid=392415) .b8 95
(EngineCore_DP0 pid=392415) .b8 113
(EngineCore_DP0 pid=392415) .b8 117
(EngineCore_DP0 pid=392415) .b8 97
(EngineCore_DP0 pid=392415) .b8 110
(EngineCore_DP0 pid=392415) .b8 116
(EngineCore_DP0 pid=392415) .b8 95
(EngineCore_DP0 pid=392415) .b8 115
(EngineCore_DP0 pid=392415) .b8 108
(EngineCore_DP0 pid=392415) .b8 105
(EngineCore_DP0 pid=392415) .b8 100
(EngineCore_DP0 pid=392415) .b8 101
(EngineCore_DP0 pid=392415) .b8 95
(EngineCore_DP0 pid=392415) .b8 116
(EngineCore_DP0 pid=392415) .b8 114
(EngineCore_DP0 pid=392415) .b8 105
(EngineCore_DP0 pid=392415) .b8 116
(EngineCore_DP0 pid=392415) .b8 111
(EngineCore_DP0 pid=392415) .b8 110
(EngineCore_DP0 pid=392415) .b8 47
(EngineCore_DP0 pid=392415) .b8 98
(EngineCore_DP0 pid=392415) .b8 117
(EngineCore_DP0 pid=392415) .b8 105
(EngineCore_DP0 pid=392415) .b8 108
(EngineCore_DP0 pid=392415) .b8 100
(EngineCore_DP0 pid=392415) .b8 47
(EngineCore_DP0 pid=392415) .b8 71
(EngineCore_DP0 pid=392415) .b8 66
(EngineCore_DP0 pid=392415) .b8 49
(EngineCore_DP0 pid=392415) .b8 48
(EngineCore_DP0 pid=392415) .b8 95
(EngineCore_DP0 pid=392415) .b8 99
(EngineCore_DP0 pid=392415) .b8 99
(EngineCore_DP0 pid=392415) .b8 49
(EngineCore_DP0 pid=392415) .b8 50
(EngineCore_DP0 pid=392415) .b8 49
(EngineCore_DP0 pid=392415) .b8 95
(EngineCore_DP0 pid=392415) .b8 112
(EngineCore_DP0 pid=392415) .b8 121
(EngineCore_DP0 pid=392415) .b8 51
(EngineCore_DP0 pid=392415) .b8 49
(EngineCore_DP0 pid=392415) .b8 50
(EngineCore_DP0 pid=392415) .b8 95
(EngineCore_DP0 pid=392415) .b8 99
(EngineCore_DP0 pid=392415) .b8 117
(EngineCore_DP0 pid=392415) .b8 49
(EngineCore_DP0 pid=392415) .b8 50
(EngineCore_DP0 pid=392415) .b8 57
(EngineCore_DP0 pid=392415) .b8 95
(EngineCore_DP0 pid=392415) .b8 97
(EngineCore_DP0 pid=392415) .b8 97
(EngineCore_DP0 pid=392415) .b8 114
(EngineCore_DP0 pid=392415) .b8 99
(EngineCore_DP0 pid=392415) .b8 104
(EngineCore_DP0 pid=392415) .b8 54
(EngineCore_DP0 pid=392415) .b8 52
(EngineCore_DP0 pid=392415) .b8 0
(EngineCore_DP0 pid=392415) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=392415) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=392415) .b8 113
(EngineCore_DP0 pid=392415) .b8 117
(EngineCore_DP0 pid=392415) .b8 97
(EngineCore_DP0 pid=392415) .b8 110
(EngineCore_DP0 pid=392415) .b8 116
(EngineCore_DP0 pid=392415) .b8 95
(EngineCore_DP0 pid=392415) .b8 115
(EngineCore_DP0 pid=392415) .b8 108
(EngineCore_DP0 pid=392415) .b8 105
(EngineCore_DP0 pid=392415) .b8 100
(EngineCore_DP0 pid=392415) .b8 101
(EngineCore_DP0 pid=392415) .b8 95
(EngineCore_DP0 pid=392415) .b8 102
(EngineCore_DP0 pid=392415) .b8 112
(EngineCore_DP0 pid=392415) .b8 56
(EngineCore_DP0 pid=392415) .b8 95
(EngineCore_DP0 pid=392415) .b8 107
(EngineCore_DP0 pid=392415) .b8 101
(EngineCore_DP0 pid=392415) .b8 114
(EngineCore_DP0 pid=392415) .b8 110
(EngineCore_DP0 pid=392415) .b8 101
(EngineCore_DP0 pid=392415) .b8 108
(EngineCore_DP0 pid=392415) .b8 0
(EngineCore_DP0 pid=392415) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=392415) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=392415) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=392415) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=392415) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=392415) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=392415) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=392415) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=392415) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=392415) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=392415) .b8 205                                 // DW_AT_call_line
(EngineCore_DP0 pid=392415) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=392415) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=392415) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=392415) 	}
(EngineCore_DP0 pid=392415) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=392415) 
(EngineCore_DP0 pid=392415) ================================================================
(EngineCore_DP0 pid=392415) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=392415) 
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpyy7rbzcz.ptx', '-o', '/tmp/tmpyy7rbzcz.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866] 
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866] 
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866] 
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpyy7rbzcz.ptx -o /tmp/tmpyy7rbzcz.ptx.o
(EngineCore_DP0 pid=392415) ERROR 01-25 20:04:50 [core.py:866] 

STDERR:
[2026-01-25 20:04:22] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:04:22] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:04:22] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:04:22] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:04:22] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:04:22] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:04:22] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:04:22] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:04:22] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:04:22] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:04:22] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:04:22] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:04:22] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:04:22] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:04:25] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:04:25] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:04:25] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:04:25] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:04:25] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:04:25] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:04:25] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:04:25] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:04:25] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:04:25] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:04:25] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:04:25] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:04:25] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:04:25] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=392415) [2026-01-25 20:04:26] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=392415) [2026-01-25 20:04:26] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=392415) [2026-01-25 20:04:26] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=392415) [2026-01-25 20:04:26] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=392415) [2026-01-25 20:04:26] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=392415) [2026-01-25 20:04:26] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=392415) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=392415) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:21<00:00, 21.76s/it]
(EngineCore_DP0 pid=392415) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:21<00:00, 21.76s/it]
(EngineCore_DP0 pid=392415) 
(EngineCore_DP0 pid=392415) [2026-01-25 20:04:49] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4096] -> 1D uint8
(EngineCore_DP0 pid=392415) [2026-01-25 20:04:49] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 13107200 bytes
(EngineCore_DP0 pid=392415) [2026-01-25 20:04:49] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4096] -> 1D uint8
(EngineCore_DP0 pid=392415) [2026-01-25 20:04:49] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 7864320 bytes
(EngineCore_DP0 pid=392415) [2026-01-25 20:04:49] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4096] -> 1D uint8
(EngineCore_DP0 pid=392415) [2026-01-25 20:04:49] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 41943040 bytes
(EngineCore_DP0 pid=392415) [2026-01-25 20:04:49] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 10944] -> 1D uint8
(EngineCore_DP0 pid=392415) [2026-01-25 20:04:49] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 21037056 bytes
(EngineCore_DP0 pid=392415) Process EngineCore_DP0:
(EngineCore_DP0 pid=392415) Traceback (most recent call last):
(EngineCore_DP0 pid=392415)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=392415)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=392415)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=392415)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=392415) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpyy7rbzcz.ptx', '-o', '/tmp/tmpyy7rbzcz.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=392415) 
(EngineCore_DP0 pid=392415) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=392415) 
(EngineCore_DP0 pid=392415) Traceback (most recent call last):
(EngineCore_DP0 pid=392415)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=392415)     self.run()
(EngineCore_DP0 pid=392415)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=392415)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=392415)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=392415)     raise e
(EngineCore_DP0 pid=392415)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=392415)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=392415)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=392415)     super().__init__(
(EngineCore_DP0 pid=392415)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=392415)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=392415)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=392415)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=392415)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=392415)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=392415)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=392415)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=392415)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=392415)     return func(*args, **kwargs)
(EngineCore_DP0 pid=392415)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=392415)     return func(*args, **kwargs)
(EngineCore_DP0 pid=392415)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=392415)     self.model_runner.profile_run()
(EngineCore_DP0 pid=392415)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=392415)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=392415)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=392415)     return func(*args, **kwargs)
(EngineCore_DP0 pid=392415)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=392415)     outputs = self.model(
(EngineCore_DP0 pid=392415)               ^^^^^^^^^^^
(EngineCore_DP0 pid=392415)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=392415)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=392415)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=392415)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=392415)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=392415)     model_output = self.model(
(EngineCore_DP0 pid=392415)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=392415)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=392415)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=392415)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=392415)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=392415)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=392415)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=392415)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=392415)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=392415)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=392415)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=392415)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=392415)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=392415)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=392415)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=392415)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=392415)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=392415)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=392415)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=392415)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=392415)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=392415)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=392415)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=392415)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=392415)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=392415)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=392415)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=392415)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=392415)     return self._linear_fn(
(EngineCore_DP0 pid=392415)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=392415)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=392415)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=392415)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=392415)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=392415)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=392415)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=392415)     return fn(input, L)
(EngineCore_DP0 pid=392415)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=392415)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=392415)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=392415)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=392415)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=392415)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=392415)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=392415)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=392415)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=392415)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=392415)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=392415)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=392415)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=392415)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392415)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=392415)     raise PTXASError(error)
(EngineCore_DP0 pid=392415) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=392415) `ptxas` stderr:
(EngineCore_DP0 pid=392415) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=392415) 
(EngineCore_DP0 pid=392415) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpyy7rbzcz.ptx -o /tmp/tmpyy7rbzcz.ptx.o
(EngineCore_DP0 pid=392415) 
[rank0]:[W125 20:04:50.992341983 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=512

========== M=1024 ==========
Time: 2026-01-25 20:04:52
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-3B-FP8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:04:56 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 20:04:56 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=393072) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=393072) 
(EngineCore_DP0 pid=393072) 
(EngineCore_DP0 pid=393072) ================================================================
(EngineCore_DP0 pid=393072) Internal Triton PTX codegen error
(EngineCore_DP0 pid=393072) `ptxas` stderr:
(EngineCore_DP0 pid=393072) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=393072) 
(EngineCore_DP0 pid=393072) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpjtk1k0gr.ptx -o /tmp/tmpjtk1k0gr.ptx.o
(EngineCore_DP0 pid=393072) 
(EngineCore_DP0 pid=393072) 
(EngineCore_DP0 pid=393072) //
(EngineCore_DP0 pid=393072) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=393072) //
(EngineCore_DP0 pid=393072) 
(EngineCore_DP0 pid=393072) .version 8.7
(EngineCore_DP0 pid=393072) .target sm_121a
(EngineCore_DP0 pid=393072) .address_size 64
(EngineCore_DP0 pid=393072) 
(EngineCore_DP0 pid=393072) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=393072) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=393072)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=393072) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=393072) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=393072) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=393072) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=393072) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=393072) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=393072) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=393072) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=393072) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=393072) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=393072) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=393072) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=393072) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=393072) )
(EngineCore_DP0 pid=393072) .reqntid 512
(EngineCore_DP0 pid=393072) {
(EngineCore_DP0 pid=393072) 	.reg .pred 	%p<20>;
(EngineCore_DP0 pid=393072) 	.reg .b16 	%rs<37>;
(EngineCore_DP0 pid=393072) 	.reg .b32 	%r<117>;
(EngineCore_DP0 pid=393072) 	.reg .b64 	%rd<13>;
(EngineCore_DP0 pid=393072) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=393072) $L__func_begin0:
(EngineCore_DP0 pid=393072) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=393072) 
(EngineCore_DP0 pid=393072) // %bb.0:
(EngineCore_DP0 pid=393072) 	ld.param.b32 	%r20, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=393072) 	ld.param.b32 	%r19, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=393072) 	ld.param.b32 	%r18, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=393072) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=393072) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=393072) $L__tmp0:
(EngineCore_DP0 pid=393072) 	.loc	1 191 24                        // quant_slide_tuned_Llama3.2-3B.py:191:24
(EngineCore_DP0 pid=393072) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=393072) 	ld.param.b32 	%r22, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=393072) 	.loc	1 196 26                        // quant_slide_tuned_Llama3.2-3B.py:196:26
(EngineCore_DP0 pid=393072) 	mul.lo.s32 	%r23, %r22, %r1;
(EngineCore_DP0 pid=393072) 	.loc	1 196 20                        // quant_slide_tuned_Llama3.2-3B.py:196:20
(EngineCore_DP0 pid=393072) 	mad.wide.s32 	%rd1, %r23, 2, %rd4;
(EngineCore_DP0 pid=393072) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=393072) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=393072) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=393072) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=393072) 	setp.lt.s32 	%p1, %r19, 1;
(EngineCore_DP0 pid=393072) 	mov.b32 	%r115, 0f2B8CBCCC;
(EngineCore_DP0 pid=393072) 	setp.eq.b32 	%p19, %r2, 0;
(EngineCore_DP0 pid=393072) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=393072) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=393072) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=393072) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=393072) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=393072) 	shr.u32 	%r32, %r2, 3;
(EngineCore_DP0 pid=393072) 	and.b32 	%r33, %r32, 60;
(EngineCore_DP0 pid=393072) 	mov.b32 	%r34, global_smem;
(EngineCore_DP0 pid=393072) 	add.s32 	%r44, %r34, %r33;
(EngineCore_DP0 pid=393072) 	shl.b32 	%r35, %r2, 2;
(EngineCore_DP0 pid=393072) 	add.s32 	%r47, %r34, %r35;
(EngineCore_DP0 pid=393072) 	mov.b32 	%r40, 0;
(EngineCore_DP0 pid=393072) 	mov.b32 	%r113, 0f00000000;
(EngineCore_DP0 pid=393072) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=393072) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=393072) 	mov.b32 	%r114, %r40;
(EngineCore_DP0 pid=393072) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=393072) 	.loc	1 203 22                        // quant_slide_tuned_Llama3.2-3B.py:203:22
(EngineCore_DP0 pid=393072) 	add.s32 	%r50, %r4, %r114;
(EngineCore_DP0 pid=393072) 	setp.lt.s32 	%p2, %r50, %r18;
(EngineCore_DP0 pid=393072) 	.loc	1 204 29                        // quant_slide_tuned_Llama3.2-3B.py:204:29
(EngineCore_DP0 pid=393072) 	mad.wide.s32 	%rd6, %r50, 2, %rd1;
(EngineCore_DP0 pid=393072) 	.loc	1 204 21                        // quant_slide_tuned_Llama3.2-3B.py:204:21
(EngineCore_DP0 pid=393072) 	// begin inline asm
(EngineCore_DP0 pid=393072) 	mov.u32 %r36, %r40;
(EngineCore_DP0 pid=393072) 	mov.u32 %r37, %r40;
(EngineCore_DP0 pid=393072) 	mov.u32 %r38, %r40;
(EngineCore_DP0 pid=393072) 	mov.u32 %r39, %r40;
(EngineCore_DP0 pid=393072) 	@%p2 ld.global.v4.b32 { %r36, %r37, %r38, %r39 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=393072) 	// end inline asm
(EngineCore_DP0 pid=393072) 	mov.b32 	{%rs1, %rs2}, %r36;
(EngineCore_DP0 pid=393072) 	mov.b32 	{%rs3, %rs4}, %r37;
(EngineCore_DP0 pid=393072) 	mov.b32 	{%rs5, %rs6}, %r38;
(EngineCore_DP0 pid=393072) 	mov.b32 	{%rs7, %rs8}, %r39;
(EngineCore_DP0 pid=393072) 	.loc	1 205 50                        // quant_slide_tuned_Llama3.2-3B.py:205:50
(EngineCore_DP0 pid=393072) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=393072) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=393072) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=393072) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=393072) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=393072) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=393072) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=393072) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=393072) $L__tmp1:
(EngineCore_DP0 pid=393072) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=393072) 	bar.sync 	0;
(EngineCore_DP0 pid=393072) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=393072) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=393072) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=393072) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=393072) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=393072) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=393072) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=393072) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=393072) 	cvt.f32.bf16 	%r51, %rs23;
(EngineCore_DP0 pid=393072) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=393072) 	shfl.sync.bfly.b32 	%r52, %r51, 16, 31, -1;
(EngineCore_DP0 pid=393072) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=393072) 	max.f32 	%r53, %r51, %r52;
(EngineCore_DP0 pid=393072) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=393072) 	shfl.sync.bfly.b32 	%r54, %r53, 8, 31, -1;
(EngineCore_DP0 pid=393072) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=393072) 	max.f32 	%r55, %r53, %r54;
(EngineCore_DP0 pid=393072) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=393072) 	shfl.sync.bfly.b32 	%r56, %r55, 4, 31, -1;
(EngineCore_DP0 pid=393072) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=393072) 	max.f32 	%r57, %r55, %r56;
(EngineCore_DP0 pid=393072) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=393072) 	shfl.sync.bfly.b32 	%r58, %r57, 2, 31, -1;
(EngineCore_DP0 pid=393072) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=393072) 	max.f32 	%r59, %r57, %r58;
(EngineCore_DP0 pid=393072) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=393072) 	shfl.sync.bfly.b32 	%r60, %r59, 1, 31, -1;
(EngineCore_DP0 pid=393072) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=393072) 	max.f32 	%r45, %r59, %r60;
(EngineCore_DP0 pid=393072) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=393072) 	// begin inline asm
(EngineCore_DP0 pid=393072) 	@%p3 st.shared.b32 [ %r44 + 0 ], %r45;
(EngineCore_DP0 pid=393072) 	// end inline asm
(EngineCore_DP0 pid=393072) 	bar.sync 	0;
(EngineCore_DP0 pid=393072) 	// begin inline asm
(EngineCore_DP0 pid=393072) 	@%p4 ld.shared.b32 %r46, [ %r47 + 0 ];
(EngineCore_DP0 pid=393072) 	// end inline asm
(EngineCore_DP0 pid=393072) 	shfl.sync.bfly.b32 	%r61, %r46, 8, 31, -1;
(EngineCore_DP0 pid=393072) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=393072) 	max.f32 	%r62, %r46, %r61;
(EngineCore_DP0 pid=393072) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=393072) 	shfl.sync.bfly.b32 	%r63, %r62, 4, 31, -1;
(EngineCore_DP0 pid=393072) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=393072) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=393072) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=393072) 	shfl.sync.bfly.b32 	%r65, %r64, 2, 31, -1;
(EngineCore_DP0 pid=393072) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=393072) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=393072) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=393072) 	shfl.sync.bfly.b32 	%r67, %r66, 1, 31, -1;
(EngineCore_DP0 pid=393072) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=393072) 	max.f32 	%r49, %r66, %r67;
(EngineCore_DP0 pid=393072) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=393072) 	// begin inline asm
(EngineCore_DP0 pid=393072) 	@%p19 st.shared.b32 [ %r47 + 0 ], %r49;
(EngineCore_DP0 pid=393072) 	// end inline asm
(EngineCore_DP0 pid=393072) 	bar.sync 	0;
(EngineCore_DP0 pid=393072) 	ld.shared.b32 	%r68, [global_smem];
(EngineCore_DP0 pid=393072) $L__tmp2:
(EngineCore_DP0 pid=393072) 	.loc	1 205 36                        // quant_slide_tuned_Llama3.2-3B.py:205:36
(EngineCore_DP0 pid=393072) 	max.f32 	%r113, %r113, %r68;
(EngineCore_DP0 pid=393072) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=393072) 	add.s32 	%r114, %r114, 4096;
(EngineCore_DP0 pid=393072) 	setp.lt.s32 	%p6, %r114, %r19;
(EngineCore_DP0 pid=393072) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=393072) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=393072) 	.loc	1 207 32                        // quant_slide_tuned_Llama3.2-3B.py:207:32
(EngineCore_DP0 pid=393072) 	max.f32 	%r115, %r113, 0f2B8CBCCC;
(EngineCore_DP0 pid=393072) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=393072) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-3B.py:0:32
(EngineCore_DP0 pid=393072) 	mov.b32 	%r70, 0f43E00000;
(EngineCore_DP0 pid=393072) 	.loc	1 208 32                        // quant_slide_tuned_Llama3.2-3B.py:208:32
(EngineCore_DP0 pid=393072) 	div.full.f32 	%r71, %r115, %r70;
(EngineCore_DP0 pid=393072) 	.loc	1 208 41                        // quant_slide_tuned_Llama3.2-3B.py:208:41
(EngineCore_DP0 pid=393072) 	max.f32 	%r69, %r71, 0f36924925;
(EngineCore_DP0 pid=393072) 	.loc	1 210 25                        // quant_slide_tuned_Llama3.2-3B.py:210:25
(EngineCore_DP0 pid=393072) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=393072) 	.loc	1 210 30                        // quant_slide_tuned_Llama3.2-3B.py:210:30
(EngineCore_DP0 pid=393072) 	// begin inline asm
(EngineCore_DP0 pid=393072) 	@%p19 st.global.b32 [ %rd7 + 0 ], { %r69 };
(EngineCore_DP0 pid=393072) 	// end inline asm
(EngineCore_DP0 pid=393072) 	.loc	1 213 29                        // quant_slide_tuned_Llama3.2-3B.py:213:29
(EngineCore_DP0 pid=393072) 	shl.b32 	%r15, %r20, 1;
(EngineCore_DP0 pid=393072) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=393072) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=393072) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=393072) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=393072) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-3B.py:0:41
(EngineCore_DP0 pid=393072) 	ld.param.b32 	%r24, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=393072) 	shr.s32 	%r25, %r24, 31;
(EngineCore_DP0 pid=393072) 	shr.u32 	%r26, %r25, 30;
(EngineCore_DP0 pid=393072) 	add.s32 	%r27, %r24, %r26;
(EngineCore_DP0 pid=393072) 	shr.s32 	%r28, %r27, 2;
(EngineCore_DP0 pid=393072) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=393072) 	mul.lo.s32 	%r29, %r28, %r1;
(EngineCore_DP0 pid=393072) 	mad.wide.s32 	%rd2, %r29, 4, %rd5;
(EngineCore_DP0 pid=393072) 	div.full.f32 	%r14, %r70, %r115;
(EngineCore_DP0 pid=393072) 	mov.b32 	%r116, 0;
(EngineCore_DP0 pid=393072) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=393072)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=393072) 	.loc	1 217 30                        // quant_slide_tuned_Llama3.2-3B.py:217:30
(EngineCore_DP0 pid=393072) 	add.s32 	%r83, %r3, %r116;
(EngineCore_DP0 pid=393072) 	setp.lt.s32 	%p13, %r83, %r15;
(EngineCore_DP0 pid=393072) 	.loc	1 220 24                        // quant_slide_tuned_Llama3.2-3B.py:220:24
(EngineCore_DP0 pid=393072) 	shr.u32 	%r84, %r83, 31;
(EngineCore_DP0 pid=393072) 	add.s32 	%r85, %r83, %r84;
(EngineCore_DP0 pid=393072) 	shr.u32 	%r86, %r85, 1;
(EngineCore_DP0 pid=393072) 	.loc	1 221 23                        // quant_slide_tuned_Llama3.2-3B.py:221:23
(EngineCore_DP0 pid=393072) 	and.b32 	%r87, %r85, 2147483646;
(EngineCore_DP0 pid=393072) 	sub.s32 	%r88, %r83, %r87;
(EngineCore_DP0 pid=393072) 	.loc	1 222 30                        // quant_slide_tuned_Llama3.2-3B.py:222:30
(EngineCore_DP0 pid=393072) 	shl.b32 	%r89, %r88, 1;
(EngineCore_DP0 pid=393072) 	.loc	1 222 26                        // quant_slide_tuned_Llama3.2-3B.py:222:26
(EngineCore_DP0 pid=393072) 	mad.lo.s32 	%r90, %r86, 6, %r89;
(EngineCore_DP0 pid=393072) 	.loc	1 225 53                        // quant_slide_tuned_Llama3.2-3B.py:225:53
(EngineCore_DP0 pid=393072) 	setp.lt.s32 	%p14, %r90, %r18;
(EngineCore_DP0 pid=393072) 	.loc	1 225 37                        // quant_slide_tuned_Llama3.2-3B.py:225:37
(EngineCore_DP0 pid=393072) 	and.pred 	%p9, %p13, %p14;
(EngineCore_DP0 pid=393072) 	.loc	1 224 29                        // quant_slide_tuned_Llama3.2-3B.py:224:29
(EngineCore_DP0 pid=393072) 	mad.wide.s32 	%rd8, %r90, 2, %rd1;
(EngineCore_DP0 pid=393072) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=393072) 	.loc	1 224 21                        // quant_slide_tuned_Llama3.2-3B.py:224:21
(EngineCore_DP0 pid=393072) 	// begin inline asm
(EngineCore_DP0 pid=393072) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=393072) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=393072) 	// end inline asm
(EngineCore_DP0 pid=393072) 	.loc	1 225 79                        // quant_slide_tuned_Llama3.2-3B.py:225:79
(EngineCore_DP0 pid=393072) 	cvt.f32.bf16 	%r91, %rs24;
(EngineCore_DP0 pid=393072) 	.loc	1 227 48                        // quant_slide_tuned_Llama3.2-3B.py:227:48
(EngineCore_DP0 pid=393072) 	or.b32 	%r92, %r90, 1;
(EngineCore_DP0 pid=393072) 	.loc	1 227 53                        // quant_slide_tuned_Llama3.2-3B.py:227:53
(EngineCore_DP0 pid=393072) 	setp.lt.s32 	%p15, %r92, %r18;
(EngineCore_DP0 pid=393072) 	.loc	1 227 37                        // quant_slide_tuned_Llama3.2-3B.py:227:37
(EngineCore_DP0 pid=393072) 	and.pred 	%p10, %p13, %p15;
(EngineCore_DP0 pid=393072) 	.loc	1 226 39                        // quant_slide_tuned_Llama3.2-3B.py:226:39
(EngineCore_DP0 pid=393072) 	add.s64 	%rd9, %rd8, 2;
(EngineCore_DP0 pid=393072) 	.loc	1 226 21                        // quant_slide_tuned_Llama3.2-3B.py:226:21
(EngineCore_DP0 pid=393072) 	// begin inline asm
(EngineCore_DP0 pid=393072) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=393072) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=393072) 	// end inline asm
(EngineCore_DP0 pid=393072) 	.loc	1 227 79                        // quant_slide_tuned_Llama3.2-3B.py:227:79
(EngineCore_DP0 pid=393072) 	cvt.f32.bf16 	%r93, %rs26;
(EngineCore_DP0 pid=393072) 	.loc	1 229 48                        // quant_slide_tuned_Llama3.2-3B.py:229:48
(EngineCore_DP0 pid=393072) 	add.s32 	%r94, %r90, 2;
(EngineCore_DP0 pid=393072) 	.loc	1 229 53                        // quant_slide_tuned_Llama3.2-3B.py:229:53
(EngineCore_DP0 pid=393072) 	setp.lt.s32 	%p16, %r94, %r18;
(EngineCore_DP0 pid=393072) 	.loc	1 229 37                        // quant_slide_tuned_Llama3.2-3B.py:229:37
(EngineCore_DP0 pid=393072) 	and.pred 	%p11, %p13, %p16;
(EngineCore_DP0 pid=393072) 	.loc	1 228 39                        // quant_slide_tuned_Llama3.2-3B.py:228:39
(EngineCore_DP0 pid=393072) 	add.s64 	%rd10, %rd8, 4;
(EngineCore_DP0 pid=393072) 	.loc	1 228 21                        // quant_slide_tuned_Llama3.2-3B.py:228:21
(EngineCore_DP0 pid=393072) 	// begin inline asm
(EngineCore_DP0 pid=393072) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=393072) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=393072) 	// end inline asm
(EngineCore_DP0 pid=393072) 	.loc	1 229 79                        // quant_slide_tuned_Llama3.2-3B.py:229:79
(EngineCore_DP0 pid=393072) 	cvt.f32.bf16 	%r95, %rs28;
(EngineCore_DP0 pid=393072) 	.loc	1 231 48                        // quant_slide_tuned_Llama3.2-3B.py:231:48
(EngineCore_DP0 pid=393072) 	add.s32 	%r96, %r90, 3;
(EngineCore_DP0 pid=393072) 	.loc	1 231 53                        // quant_slide_tuned_Llama3.2-3B.py:231:53
(EngineCore_DP0 pid=393072) 	setp.lt.s32 	%p17, %r96, %r18;
(EngineCore_DP0 pid=393072) 	.loc	1 231 37                        // quant_slide_tuned_Llama3.2-3B.py:231:37
(EngineCore_DP0 pid=393072) 	and.pred 	%p12, %p13, %p17;
(EngineCore_DP0 pid=393072) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-3B.py:230:39
(EngineCore_DP0 pid=393072) 	add.s64 	%rd11, %rd8, 6;
(EngineCore_DP0 pid=393072) 	.loc	1 230 21                        // quant_slide_tuned_Llama3.2-3B.py:230:21
(EngineCore_DP0 pid=393072) 	// begin inline asm
(EngineCore_DP0 pid=393072) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=393072) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=393072) 	// end inline asm
(EngineCore_DP0 pid=393072) 	.loc	1 231 79                        // quant_slide_tuned_Llama3.2-3B.py:231:79
(EngineCore_DP0 pid=393072) 	cvt.f32.bf16 	%r97, %rs30;
(EngineCore_DP0 pid=393072) 	.loc	1 233 27                        // quant_slide_tuned_Llama3.2-3B.py:233:27
(EngineCore_DP0 pid=393072) 	mul.f32 	%r98, %r14, %r91;
(EngineCore_DP0 pid=393072) 	mov.b32 	%r99, 0f43E00000;
(EngineCore_DP0 pid=393072) 	.loc	1 233 48                        // quant_slide_tuned_Llama3.2-3B.py:233:48
(EngineCore_DP0 pid=393072) 	min.xorsign.abs.f32 	%r73, %r98, %r99;
(EngineCore_DP0 pid=393072) 	.loc	1 233 60                        // quant_slide_tuned_Llama3.2-3B.py:233:60
(EngineCore_DP0 pid=393072) 	// begin inline asm
(EngineCore_DP0 pid=393072) 	cvt.rn.satfinite.e4m3x2.f32  %rs32, %r74, %r73; 
(EngineCore_DP0 pid=393072) 
(EngineCore_DP0 pid=393072) 	// end inline asm
(EngineCore_DP0 pid=393072) 	.loc	1 234 27                        // quant_slide_tuned_Llama3.2-3B.py:234:27
(EngineCore_DP0 pid=393072) 	mul.f32 	%r100, %r14, %r93;
(EngineCore_DP0 pid=393072) 	.loc	1 234 48                        // quant_slide_tuned_Llama3.2-3B.py:234:48
(EngineCore_DP0 pid=393072) 	min.xorsign.abs.f32 	%r75, %r100, %r99;
(EngineCore_DP0 pid=393072) 	.loc	1 234 60                        // quant_slide_tuned_Llama3.2-3B.py:234:60
(EngineCore_DP0 pid=393072) 	// begin inline asm
(EngineCore_DP0 pid=393072) 	cvt.rn.satfinite.e4m3x2.f32  %rs33, %r76, %r75; 
(EngineCore_DP0 pid=393072) 
(EngineCore_DP0 pid=393072) 	// end inline asm
(EngineCore_DP0 pid=393072) 	.loc	1 235 27                        // quant_slide_tuned_Llama3.2-3B.py:235:27
(EngineCore_DP0 pid=393072) 	mul.f32 	%r101, %r14, %r95;
(EngineCore_DP0 pid=393072) 	.loc	1 235 48                        // quant_slide_tuned_Llama3.2-3B.py:235:48
(EngineCore_DP0 pid=393072) 	min.xorsign.abs.f32 	%r77, %r101, %r99;
(EngineCore_DP0 pid=393072) 	.loc	1 235 60                        // quant_slide_tuned_Llama3.2-3B.py:235:60
(EngineCore_DP0 pid=393072) 	// begin inline asm
(EngineCore_DP0 pid=393072) 	cvt.rn.satfinite.e4m3x2.f32  %rs34, %r78, %r77; 
(EngineCore_DP0 pid=393072) 
(EngineCore_DP0 pid=393072) 	// end inline asm
(EngineCore_DP0 pid=393072) 	.loc	1 236 27                        // quant_slide_tuned_Llama3.2-3B.py:236:27
(EngineCore_DP0 pid=393072) 	mul.f32 	%r102, %r14, %r97;
(EngineCore_DP0 pid=393072) 	.loc	1 236 48                        // quant_slide_tuned_Llama3.2-3B.py:236:48
(EngineCore_DP0 pid=393072) 	min.xorsign.abs.f32 	%r79, %r102, %r99;
(EngineCore_DP0 pid=393072) 	.loc	1 236 60                        // quant_slide_tuned_Llama3.2-3B.py:236:60
(EngineCore_DP0 pid=393072) 	// begin inline asm
(EngineCore_DP0 pid=393072) 	cvt.rn.satfinite.e4m3x2.f32  %rs35, %r80, %r79; 
(EngineCore_DP0 pid=393072) 
(EngineCore_DP0 pid=393072) 	// end inline asm
(EngineCore_DP0 pid=393072) 	.loc	1 238 45                        // quant_slide_tuned_Llama3.2-3B.py:238:45
(EngineCore_DP0 pid=393072) 	cvt.u32.u16 	%r103, %rs32;
(EngineCore_DP0 pid=393072) 	and.b32 	%r104, %r103, 255;
(EngineCore_DP0 pid=393072) 	.loc	1 240 45                        // quant_slide_tuned_Llama3.2-3B.py:240:45
(EngineCore_DP0 pid=393072) 	cvt.u32.u16 	%r105, %rs34;
(EngineCore_DP0 pid=393072) 	and.b32 	%r106, %r105, 255;
(EngineCore_DP0 pid=393072) 	.loc	1 241 45                        // quant_slide_tuned_Llama3.2-3B.py:241:45
(EngineCore_DP0 pid=393072) 	cvt.u32.u16 	%r107, %rs35;
(EngineCore_DP0 pid=393072) 	.loc	1 243 30                        // quant_slide_tuned_Llama3.2-3B.py:243:30
(EngineCore_DP0 pid=393072) 	and.b16 	%rs36, %rs33, 255;
(EngineCore_DP0 pid=393072) 	mul.wide.u16 	%r108, %rs36, 256;
(EngineCore_DP0 pid=393072) 	.loc	1 243 24                        // quant_slide_tuned_Llama3.2-3B.py:243:24
(EngineCore_DP0 pid=393072) 	or.b32 	%r109, %r108, %r104;
(EngineCore_DP0 pid=393072) 	.loc	1 243 42                        // quant_slide_tuned_Llama3.2-3B.py:243:42
(EngineCore_DP0 pid=393072) 	shl.b32 	%r110, %r106, 16;
(EngineCore_DP0 pid=393072) 	.loc	1 243 36                        // quant_slide_tuned_Llama3.2-3B.py:243:36
(EngineCore_DP0 pid=393072) 	or.b32 	%r111, %r109, %r110;
(EngineCore_DP0 pid=393072) 	.loc	1 243 55                        // quant_slide_tuned_Llama3.2-3B.py:243:55
(EngineCore_DP0 pid=393072) 	shl.b32 	%r112, %r107, 24;
(EngineCore_DP0 pid=393072) 	.loc	1 243 49                        // quant_slide_tuned_Llama3.2-3B.py:243:49
(EngineCore_DP0 pid=393072) 	or.b32 	%r81, %r111, %r112;
(EngineCore_DP0 pid=393072) 	.loc	1 244 29                        // quant_slide_tuned_Llama3.2-3B.py:244:29
(EngineCore_DP0 pid=393072) 	mad.wide.s32 	%rd12, %r83, 4, %rd2;
(EngineCore_DP0 pid=393072) 	.loc	1 244 39                        // quant_slide_tuned_Llama3.2-3B.py:244:39
(EngineCore_DP0 pid=393072) 	// begin inline asm
(EngineCore_DP0 pid=393072) 	@%p13 st.global.b32 [ %rd12 + 0 ], { %r81 };
(EngineCore_DP0 pid=393072) 	// end inline asm
(EngineCore_DP0 pid=393072) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=393072) 	add.s32 	%r116, %r116, 512;
(EngineCore_DP0 pid=393072) 	setp.lt.s32 	%p18, %r116, %r15;
(EngineCore_DP0 pid=393072) 	@%p18 bra 	$L__BB0_6;
(EngineCore_DP0 pid=393072) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=393072) 	.loc	1 215 4                         // quant_slide_tuned_Llama3.2-3B.py:215:4
(EngineCore_DP0 pid=393072) 	ret;
(EngineCore_DP0 pid=393072) $L__tmp3:
(EngineCore_DP0 pid=393072) $L__func_end0:
(EngineCore_DP0 pid=393072)                                         // -- End function
(EngineCore_DP0 pid=393072) }
(EngineCore_DP0 pid=393072) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py"
(EngineCore_DP0 pid=393072) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=393072) 	.section	.debug_abbrev
(EngineCore_DP0 pid=393072) 	{
(EngineCore_DP0 pid=393072) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=393072) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=393072) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=393072) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=393072) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=393072) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=393072) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=393072) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=393072) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=393072) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=393072) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=393072) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=393072) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=393072) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=393072) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=393072) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=393072) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=393072) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=393072) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=393072) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=393072) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=393072) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=393072) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=393072) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=393072) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=393072) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=393072) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=393072) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=393072) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=393072) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=393072) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=393072) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=393072) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=393072) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=393072) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=393072) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=393072) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=393072) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=393072) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=393072) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=393072) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=393072) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=393072) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=393072) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=393072) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=393072) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=393072) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=393072) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=393072) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=393072) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=393072) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=393072) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=393072) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=393072) 	}
(EngineCore_DP0 pid=393072) 	.section	.debug_info
(EngineCore_DP0 pid=393072) 	{
(EngineCore_DP0 pid=393072) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=393072) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=393072) .b8 0
(EngineCore_DP0 pid=393072) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=393072) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=393072) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=393072) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=393072) .b8 114
(EngineCore_DP0 pid=393072) .b8 105
(EngineCore_DP0 pid=393072) .b8 116
(EngineCore_DP0 pid=393072) .b8 111
(EngineCore_DP0 pid=393072) .b8 110
(EngineCore_DP0 pid=393072) .b8 0
(EngineCore_DP0 pid=393072) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=393072) .b8 0
(EngineCore_DP0 pid=393072) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=393072) .b8 117
(EngineCore_DP0 pid=393072) .b8 97
(EngineCore_DP0 pid=393072) .b8 110
(EngineCore_DP0 pid=393072) .b8 116
(EngineCore_DP0 pid=393072) .b8 95
(EngineCore_DP0 pid=393072) .b8 115
(EngineCore_DP0 pid=393072) .b8 108
(EngineCore_DP0 pid=393072) .b8 105
(EngineCore_DP0 pid=393072) .b8 100
(EngineCore_DP0 pid=393072) .b8 101
(EngineCore_DP0 pid=393072) .b8 95
(EngineCore_DP0 pid=393072) .b8 116
(EngineCore_DP0 pid=393072) .b8 117
(EngineCore_DP0 pid=393072) .b8 110
(EngineCore_DP0 pid=393072) .b8 101
(EngineCore_DP0 pid=393072) .b8 100
(EngineCore_DP0 pid=393072) .b8 95
(EngineCore_DP0 pid=393072) .b8 76
(EngineCore_DP0 pid=393072) .b8 108
(EngineCore_DP0 pid=393072) .b8 97
(EngineCore_DP0 pid=393072) .b8 109
(EngineCore_DP0 pid=393072) .b8 97
(EngineCore_DP0 pid=393072) .b8 51
(EngineCore_DP0 pid=393072) .b8 46
(EngineCore_DP0 pid=393072) .b8 50
(EngineCore_DP0 pid=393072) .b8 45
(EngineCore_DP0 pid=393072) .b8 51
(EngineCore_DP0 pid=393072) .b8 66
(EngineCore_DP0 pid=393072) .b8 46
(EngineCore_DP0 pid=393072) .b8 112
(EngineCore_DP0 pid=393072) .b8 121
(EngineCore_DP0 pid=393072) .b8 0
(EngineCore_DP0 pid=393072) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=393072) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=393072) .b8 114
(EngineCore_DP0 pid=393072) .b8 111
(EngineCore_DP0 pid=393072) .b8 111
(EngineCore_DP0 pid=393072) .b8 116
(EngineCore_DP0 pid=393072) .b8 47
(EngineCore_DP0 pid=393072) .b8 118
(EngineCore_DP0 pid=393072) .b8 108
(EngineCore_DP0 pid=393072) .b8 108
(EngineCore_DP0 pid=393072) .b8 109
(EngineCore_DP0 pid=393072) .b8 98
(EngineCore_DP0 pid=393072) .b8 101
(EngineCore_DP0 pid=393072) .b8 110
(EngineCore_DP0 pid=393072) .b8 99
(EngineCore_DP0 pid=393072) .b8 104
(EngineCore_DP0 pid=393072) .b8 47
(EngineCore_DP0 pid=393072) .b8 115
(EngineCore_DP0 pid=393072) .b8 108
(EngineCore_DP0 pid=393072) .b8 105
(EngineCore_DP0 pid=393072) .b8 100
(EngineCore_DP0 pid=393072) .b8 101
(EngineCore_DP0 pid=393072) .b8 115
(EngineCore_DP0 pid=393072) .b8 112
(EngineCore_DP0 pid=393072) .b8 97
(EngineCore_DP0 pid=393072) .b8 114
(EngineCore_DP0 pid=393072) .b8 115
(EngineCore_DP0 pid=393072) .b8 101
(EngineCore_DP0 pid=393072) .b8 47
(EngineCore_DP0 pid=393072) .b8 99
(EngineCore_DP0 pid=393072) .b8 115
(EngineCore_DP0 pid=393072) .b8 114
(EngineCore_DP0 pid=393072) .b8 99
(EngineCore_DP0 pid=393072) .b8 47
(EngineCore_DP0 pid=393072) .b8 102
(EngineCore_DP0 pid=393072) .b8 117
(EngineCore_DP0 pid=393072) .b8 115
(EngineCore_DP0 pid=393072) .b8 101
(EngineCore_DP0 pid=393072) .b8 100
(EngineCore_DP0 pid=393072) .b8 95
(EngineCore_DP0 pid=393072) .b8 113
(EngineCore_DP0 pid=393072) .b8 117
(EngineCore_DP0 pid=393072) .b8 97
(EngineCore_DP0 pid=393072) .b8 110
(EngineCore_DP0 pid=393072) .b8 116
(EngineCore_DP0 pid=393072) .b8 95
(EngineCore_DP0 pid=393072) .b8 115
(EngineCore_DP0 pid=393072) .b8 108
(EngineCore_DP0 pid=393072) .b8 105
(EngineCore_DP0 pid=393072) .b8 100
(EngineCore_DP0 pid=393072) .b8 101
(EngineCore_DP0 pid=393072) .b8 95
(EngineCore_DP0 pid=393072) .b8 116
(EngineCore_DP0 pid=393072) .b8 114
(EngineCore_DP0 pid=393072) .b8 105
(EngineCore_DP0 pid=393072) .b8 116
(EngineCore_DP0 pid=393072) .b8 111
(EngineCore_DP0 pid=393072) .b8 110
(EngineCore_DP0 pid=393072) .b8 47
(EngineCore_DP0 pid=393072) .b8 98
(EngineCore_DP0 pid=393072) .b8 117
(EngineCore_DP0 pid=393072) .b8 105
(EngineCore_DP0 pid=393072) .b8 108
(EngineCore_DP0 pid=393072) .b8 100
(EngineCore_DP0 pid=393072) .b8 47
(EngineCore_DP0 pid=393072) .b8 71
(EngineCore_DP0 pid=393072) .b8 66
(EngineCore_DP0 pid=393072) .b8 49
(EngineCore_DP0 pid=393072) .b8 48
(EngineCore_DP0 pid=393072) .b8 95
(EngineCore_DP0 pid=393072) .b8 99
(EngineCore_DP0 pid=393072) .b8 99
(EngineCore_DP0 pid=393072) .b8 49
(EngineCore_DP0 pid=393072) .b8 50
(EngineCore_DP0 pid=393072) .b8 49
(EngineCore_DP0 pid=393072) .b8 95
(EngineCore_DP0 pid=393072) .b8 112
(EngineCore_DP0 pid=393072) .b8 121
(EngineCore_DP0 pid=393072) .b8 51
(EngineCore_DP0 pid=393072) .b8 49
(EngineCore_DP0 pid=393072) .b8 50
(EngineCore_DP0 pid=393072) .b8 95
(EngineCore_DP0 pid=393072) .b8 99
(EngineCore_DP0 pid=393072) .b8 117
(EngineCore_DP0 pid=393072) .b8 49
(EngineCore_DP0 pid=393072) .b8 50
(EngineCore_DP0 pid=393072) .b8 57
(EngineCore_DP0 pid=393072) .b8 95
(EngineCore_DP0 pid=393072) .b8 97
(EngineCore_DP0 pid=393072) .b8 97
(EngineCore_DP0 pid=393072) .b8 114
(EngineCore_DP0 pid=393072) .b8 99
(EngineCore_DP0 pid=393072) .b8 104
(EngineCore_DP0 pid=393072) .b8 54
(EngineCore_DP0 pid=393072) .b8 52
(EngineCore_DP0 pid=393072) .b8 0
(EngineCore_DP0 pid=393072) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=393072) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=393072) .b8 113
(EngineCore_DP0 pid=393072) .b8 117
(EngineCore_DP0 pid=393072) .b8 97
(EngineCore_DP0 pid=393072) .b8 110
(EngineCore_DP0 pid=393072) .b8 116
(EngineCore_DP0 pid=393072) .b8 95
(EngineCore_DP0 pid=393072) .b8 115
(EngineCore_DP0 pid=393072) .b8 108
(EngineCore_DP0 pid=393072) .b8 105
(EngineCore_DP0 pid=393072) .b8 100
(EngineCore_DP0 pid=393072) .b8 101
(EngineCore_DP0 pid=393072) .b8 95
(EngineCore_DP0 pid=393072) .b8 102
(EngineCore_DP0 pid=393072) .b8 112
(EngineCore_DP0 pid=393072) .b8 56
(EngineCore_DP0 pid=393072) .b8 95
(EngineCore_DP0 pid=393072) .b8 107
(EngineCore_DP0 pid=393072) .b8 101
(EngineCore_DP0 pid=393072) .b8 114
(EngineCore_DP0 pid=393072) .b8 110
(EngineCore_DP0 pid=393072) .b8 101
(EngineCore_DP0 pid=393072) .b8 108
(EngineCore_DP0 pid=393072) .b8 0
(EngineCore_DP0 pid=393072) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=393072) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=393072) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=393072) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=393072) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=393072) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=393072) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=393072) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=393072) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=393072) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=393072) .b8 205                                 // DW_AT_call_line
(EngineCore_DP0 pid=393072) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=393072) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=393072) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=393072) 	}
(EngineCore_DP0 pid=393072) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=393072) 
(EngineCore_DP0 pid=393072) ================================================================
(EngineCore_DP0 pid=393072) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=393072) 
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpjtk1k0gr.ptx', '-o', '/tmp/tmpjtk1k0gr.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866] 
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866] 
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866] 
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpjtk1k0gr.ptx -o /tmp/tmpjtk1k0gr.ptx.o
(EngineCore_DP0 pid=393072) ERROR 01-25 20:05:23 [core.py:866] 

STDERR:
[2026-01-25 20:04:56] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:04:56] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:04:56] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:04:56] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:04:56] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:04:56] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:04:56] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:04:56] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:04:56] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:04:56] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:04:56] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:04:56] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:04:56] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:04:56] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:04:59] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:04:59] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:04:59] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:04:59] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:04:59] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:04:59] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:04:59] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:04:59] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:04:59] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:04:59] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:04:59] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:04:59] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:04:59] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:04:59] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=393072) [2026-01-25 20:05:00] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=393072) [2026-01-25 20:05:00] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=393072) [2026-01-25 20:05:00] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=393072) [2026-01-25 20:05:00] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=393072) [2026-01-25 20:05:00] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=393072) [2026-01-25 20:05:00] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=393072) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=393072) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:20<00:00, 20.77s/it]
(EngineCore_DP0 pid=393072) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:20<00:00, 20.77s/it]
(EngineCore_DP0 pid=393072) 
(EngineCore_DP0 pid=393072) [2026-01-25 20:05:22] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4096] -> 1D uint8
(EngineCore_DP0 pid=393072) [2026-01-25 20:05:22] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 13107200 bytes
(EngineCore_DP0 pid=393072) [2026-01-25 20:05:22] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4096] -> 1D uint8
(EngineCore_DP0 pid=393072) [2026-01-25 20:05:22] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 7864320 bytes
(EngineCore_DP0 pid=393072) [2026-01-25 20:05:22] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4096] -> 1D uint8
(EngineCore_DP0 pid=393072) [2026-01-25 20:05:22] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 41943040 bytes
(EngineCore_DP0 pid=393072) [2026-01-25 20:05:22] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 10944] -> 1D uint8
(EngineCore_DP0 pid=393072) [2026-01-25 20:05:22] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 21037056 bytes
(EngineCore_DP0 pid=393072) Process EngineCore_DP0:
(EngineCore_DP0 pid=393072) Traceback (most recent call last):
(EngineCore_DP0 pid=393072)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=393072)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=393072)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=393072)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=393072) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpjtk1k0gr.ptx', '-o', '/tmp/tmpjtk1k0gr.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=393072) 
(EngineCore_DP0 pid=393072) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=393072) 
(EngineCore_DP0 pid=393072) Traceback (most recent call last):
(EngineCore_DP0 pid=393072)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=393072)     self.run()
(EngineCore_DP0 pid=393072)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=393072)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=393072)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=393072)     raise e
(EngineCore_DP0 pid=393072)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=393072)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=393072)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=393072)     super().__init__(
(EngineCore_DP0 pid=393072)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=393072)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=393072)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=393072)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=393072)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=393072)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=393072)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=393072)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=393072)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=393072)     return func(*args, **kwargs)
(EngineCore_DP0 pid=393072)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=393072)     return func(*args, **kwargs)
(EngineCore_DP0 pid=393072)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=393072)     self.model_runner.profile_run()
(EngineCore_DP0 pid=393072)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=393072)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=393072)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=393072)     return func(*args, **kwargs)
(EngineCore_DP0 pid=393072)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=393072)     outputs = self.model(
(EngineCore_DP0 pid=393072)               ^^^^^^^^^^^
(EngineCore_DP0 pid=393072)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=393072)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=393072)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=393072)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=393072)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=393072)     model_output = self.model(
(EngineCore_DP0 pid=393072)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=393072)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=393072)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=393072)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=393072)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=393072)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=393072)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=393072)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=393072)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=393072)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=393072)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=393072)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=393072)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=393072)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=393072)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=393072)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=393072)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=393072)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=393072)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=393072)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=393072)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=393072)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=393072)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=393072)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=393072)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=393072)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=393072)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=393072)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=393072)     return self._linear_fn(
(EngineCore_DP0 pid=393072)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=393072)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=393072)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=393072)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=393072)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=393072)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=393072)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=393072)     return fn(input, L)
(EngineCore_DP0 pid=393072)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=393072)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=393072)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=393072)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=393072)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=393072)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=393072)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=393072)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=393072)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=393072)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=393072)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=393072)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=393072)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=393072)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393072)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=393072)     raise PTXASError(error)
(EngineCore_DP0 pid=393072) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=393072) `ptxas` stderr:
(EngineCore_DP0 pid=393072) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=393072) 
(EngineCore_DP0 pid=393072) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpjtk1k0gr.ptx -o /tmp/tmpjtk1k0gr.ptx.o
(EngineCore_DP0 pid=393072) 
[rank0]:[W125 20:05:23.802873146 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=1024

========== M=2048 ==========
Time: 2026-01-25 20:05:25
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-3B-FP8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:05:29 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 20:05:29 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=393709) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=393709) 
(EngineCore_DP0 pid=393709) 
(EngineCore_DP0 pid=393709) ================================================================
(EngineCore_DP0 pid=393709) Internal Triton PTX codegen error
(EngineCore_DP0 pid=393709) `ptxas` stderr:
(EngineCore_DP0 pid=393709) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=393709) 
(EngineCore_DP0 pid=393709) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp3_owo6zv.ptx -o /tmp/tmp3_owo6zv.ptx.o
(EngineCore_DP0 pid=393709) 
(EngineCore_DP0 pid=393709) 
(EngineCore_DP0 pid=393709) //
(EngineCore_DP0 pid=393709) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=393709) //
(EngineCore_DP0 pid=393709) 
(EngineCore_DP0 pid=393709) .version 8.7
(EngineCore_DP0 pid=393709) .target sm_121a
(EngineCore_DP0 pid=393709) .address_size 64
(EngineCore_DP0 pid=393709) 
(EngineCore_DP0 pid=393709) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=393709) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=393709)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=393709) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=393709) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=393709) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=393709) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=393709) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=393709) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=393709) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=393709) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=393709) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=393709) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=393709) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=393709) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=393709) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=393709) )
(EngineCore_DP0 pid=393709) .reqntid 512
(EngineCore_DP0 pid=393709) {
(EngineCore_DP0 pid=393709) 	.reg .pred 	%p<20>;
(EngineCore_DP0 pid=393709) 	.reg .b16 	%rs<37>;
(EngineCore_DP0 pid=393709) 	.reg .b32 	%r<117>;
(EngineCore_DP0 pid=393709) 	.reg .b64 	%rd<13>;
(EngineCore_DP0 pid=393709) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=393709) $L__func_begin0:
(EngineCore_DP0 pid=393709) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=393709) 
(EngineCore_DP0 pid=393709) // %bb.0:
(EngineCore_DP0 pid=393709) 	ld.param.b32 	%r20, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=393709) 	ld.param.b32 	%r19, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=393709) 	ld.param.b32 	%r18, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=393709) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=393709) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=393709) $L__tmp0:
(EngineCore_DP0 pid=393709) 	.loc	1 191 24                        // quant_slide_tuned_Llama3.2-3B.py:191:24
(EngineCore_DP0 pid=393709) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=393709) 	ld.param.b32 	%r22, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=393709) 	.loc	1 196 26                        // quant_slide_tuned_Llama3.2-3B.py:196:26
(EngineCore_DP0 pid=393709) 	mul.lo.s32 	%r23, %r22, %r1;
(EngineCore_DP0 pid=393709) 	.loc	1 196 20                        // quant_slide_tuned_Llama3.2-3B.py:196:20
(EngineCore_DP0 pid=393709) 	mad.wide.s32 	%rd1, %r23, 2, %rd4;
(EngineCore_DP0 pid=393709) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=393709) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=393709) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=393709) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=393709) 	setp.lt.s32 	%p1, %r19, 1;
(EngineCore_DP0 pid=393709) 	mov.b32 	%r115, 0f2B8CBCCC;
(EngineCore_DP0 pid=393709) 	setp.eq.b32 	%p19, %r2, 0;
(EngineCore_DP0 pid=393709) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=393709) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=393709) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=393709) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=393709) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=393709) 	shr.u32 	%r32, %r2, 3;
(EngineCore_DP0 pid=393709) 	and.b32 	%r33, %r32, 60;
(EngineCore_DP0 pid=393709) 	mov.b32 	%r34, global_smem;
(EngineCore_DP0 pid=393709) 	add.s32 	%r44, %r34, %r33;
(EngineCore_DP0 pid=393709) 	shl.b32 	%r35, %r2, 2;
(EngineCore_DP0 pid=393709) 	add.s32 	%r47, %r34, %r35;
(EngineCore_DP0 pid=393709) 	mov.b32 	%r40, 0;
(EngineCore_DP0 pid=393709) 	mov.b32 	%r113, 0f00000000;
(EngineCore_DP0 pid=393709) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=393709) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=393709) 	mov.b32 	%r114, %r40;
(EngineCore_DP0 pid=393709) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=393709) 	.loc	1 203 22                        // quant_slide_tuned_Llama3.2-3B.py:203:22
(EngineCore_DP0 pid=393709) 	add.s32 	%r50, %r4, %r114;
(EngineCore_DP0 pid=393709) 	setp.lt.s32 	%p2, %r50, %r18;
(EngineCore_DP0 pid=393709) 	.loc	1 204 29                        // quant_slide_tuned_Llama3.2-3B.py:204:29
(EngineCore_DP0 pid=393709) 	mad.wide.s32 	%rd6, %r50, 2, %rd1;
(EngineCore_DP0 pid=393709) 	.loc	1 204 21                        // quant_slide_tuned_Llama3.2-3B.py:204:21
(EngineCore_DP0 pid=393709) 	// begin inline asm
(EngineCore_DP0 pid=393709) 	mov.u32 %r36, %r40;
(EngineCore_DP0 pid=393709) 	mov.u32 %r37, %r40;
(EngineCore_DP0 pid=393709) 	mov.u32 %r38, %r40;
(EngineCore_DP0 pid=393709) 	mov.u32 %r39, %r40;
(EngineCore_DP0 pid=393709) 	@%p2 ld.global.v4.b32 { %r36, %r37, %r38, %r39 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=393709) 	// end inline asm
(EngineCore_DP0 pid=393709) 	mov.b32 	{%rs1, %rs2}, %r36;
(EngineCore_DP0 pid=393709) 	mov.b32 	{%rs3, %rs4}, %r37;
(EngineCore_DP0 pid=393709) 	mov.b32 	{%rs5, %rs6}, %r38;
(EngineCore_DP0 pid=393709) 	mov.b32 	{%rs7, %rs8}, %r39;
(EngineCore_DP0 pid=393709) 	.loc	1 205 50                        // quant_slide_tuned_Llama3.2-3B.py:205:50
(EngineCore_DP0 pid=393709) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=393709) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=393709) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=393709) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=393709) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=393709) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=393709) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=393709) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=393709) $L__tmp1:
(EngineCore_DP0 pid=393709) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=393709) 	bar.sync 	0;
(EngineCore_DP0 pid=393709) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=393709) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=393709) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=393709) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=393709) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=393709) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=393709) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=393709) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=393709) 	cvt.f32.bf16 	%r51, %rs23;
(EngineCore_DP0 pid=393709) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=393709) 	shfl.sync.bfly.b32 	%r52, %r51, 16, 31, -1;
(EngineCore_DP0 pid=393709) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=393709) 	max.f32 	%r53, %r51, %r52;
(EngineCore_DP0 pid=393709) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=393709) 	shfl.sync.bfly.b32 	%r54, %r53, 8, 31, -1;
(EngineCore_DP0 pid=393709) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=393709) 	max.f32 	%r55, %r53, %r54;
(EngineCore_DP0 pid=393709) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=393709) 	shfl.sync.bfly.b32 	%r56, %r55, 4, 31, -1;
(EngineCore_DP0 pid=393709) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=393709) 	max.f32 	%r57, %r55, %r56;
(EngineCore_DP0 pid=393709) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=393709) 	shfl.sync.bfly.b32 	%r58, %r57, 2, 31, -1;
(EngineCore_DP0 pid=393709) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=393709) 	max.f32 	%r59, %r57, %r58;
(EngineCore_DP0 pid=393709) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=393709) 	shfl.sync.bfly.b32 	%r60, %r59, 1, 31, -1;
(EngineCore_DP0 pid=393709) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=393709) 	max.f32 	%r45, %r59, %r60;
(EngineCore_DP0 pid=393709) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=393709) 	// begin inline asm
(EngineCore_DP0 pid=393709) 	@%p3 st.shared.b32 [ %r44 + 0 ], %r45;
(EngineCore_DP0 pid=393709) 	// end inline asm
(EngineCore_DP0 pid=393709) 	bar.sync 	0;
(EngineCore_DP0 pid=393709) 	// begin inline asm
(EngineCore_DP0 pid=393709) 	@%p4 ld.shared.b32 %r46, [ %r47 + 0 ];
(EngineCore_DP0 pid=393709) 	// end inline asm
(EngineCore_DP0 pid=393709) 	shfl.sync.bfly.b32 	%r61, %r46, 8, 31, -1;
(EngineCore_DP0 pid=393709) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=393709) 	max.f32 	%r62, %r46, %r61;
(EngineCore_DP0 pid=393709) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=393709) 	shfl.sync.bfly.b32 	%r63, %r62, 4, 31, -1;
(EngineCore_DP0 pid=393709) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=393709) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=393709) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=393709) 	shfl.sync.bfly.b32 	%r65, %r64, 2, 31, -1;
(EngineCore_DP0 pid=393709) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=393709) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=393709) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=393709) 	shfl.sync.bfly.b32 	%r67, %r66, 1, 31, -1;
(EngineCore_DP0 pid=393709) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=393709) 	max.f32 	%r49, %r66, %r67;
(EngineCore_DP0 pid=393709) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=393709) 	// begin inline asm
(EngineCore_DP0 pid=393709) 	@%p19 st.shared.b32 [ %r47 + 0 ], %r49;
(EngineCore_DP0 pid=393709) 	// end inline asm
(EngineCore_DP0 pid=393709) 	bar.sync 	0;
(EngineCore_DP0 pid=393709) 	ld.shared.b32 	%r68, [global_smem];
(EngineCore_DP0 pid=393709) $L__tmp2:
(EngineCore_DP0 pid=393709) 	.loc	1 205 36                        // quant_slide_tuned_Llama3.2-3B.py:205:36
(EngineCore_DP0 pid=393709) 	max.f32 	%r113, %r113, %r68;
(EngineCore_DP0 pid=393709) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=393709) 	add.s32 	%r114, %r114, 4096;
(EngineCore_DP0 pid=393709) 	setp.lt.s32 	%p6, %r114, %r19;
(EngineCore_DP0 pid=393709) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=393709) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=393709) 	.loc	1 207 32                        // quant_slide_tuned_Llama3.2-3B.py:207:32
(EngineCore_DP0 pid=393709) 	max.f32 	%r115, %r113, 0f2B8CBCCC;
(EngineCore_DP0 pid=393709) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=393709) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-3B.py:0:32
(EngineCore_DP0 pid=393709) 	mov.b32 	%r70, 0f43E00000;
(EngineCore_DP0 pid=393709) 	.loc	1 208 32                        // quant_slide_tuned_Llama3.2-3B.py:208:32
(EngineCore_DP0 pid=393709) 	div.full.f32 	%r71, %r115, %r70;
(EngineCore_DP0 pid=393709) 	.loc	1 208 41                        // quant_slide_tuned_Llama3.2-3B.py:208:41
(EngineCore_DP0 pid=393709) 	max.f32 	%r69, %r71, 0f36924925;
(EngineCore_DP0 pid=393709) 	.loc	1 210 25                        // quant_slide_tuned_Llama3.2-3B.py:210:25
(EngineCore_DP0 pid=393709) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=393709) 	.loc	1 210 30                        // quant_slide_tuned_Llama3.2-3B.py:210:30
(EngineCore_DP0 pid=393709) 	// begin inline asm
(EngineCore_DP0 pid=393709) 	@%p19 st.global.b32 [ %rd7 + 0 ], { %r69 };
(EngineCore_DP0 pid=393709) 	// end inline asm
(EngineCore_DP0 pid=393709) 	.loc	1 213 29                        // quant_slide_tuned_Llama3.2-3B.py:213:29
(EngineCore_DP0 pid=393709) 	shl.b32 	%r15, %r20, 1;
(EngineCore_DP0 pid=393709) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=393709) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=393709) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=393709) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=393709) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-3B.py:0:41
(EngineCore_DP0 pid=393709) 	ld.param.b32 	%r24, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=393709) 	shr.s32 	%r25, %r24, 31;
(EngineCore_DP0 pid=393709) 	shr.u32 	%r26, %r25, 30;
(EngineCore_DP0 pid=393709) 	add.s32 	%r27, %r24, %r26;
(EngineCore_DP0 pid=393709) 	shr.s32 	%r28, %r27, 2;
(EngineCore_DP0 pid=393709) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=393709) 	mul.lo.s32 	%r29, %r28, %r1;
(EngineCore_DP0 pid=393709) 	mad.wide.s32 	%rd2, %r29, 4, %rd5;
(EngineCore_DP0 pid=393709) 	div.full.f32 	%r14, %r70, %r115;
(EngineCore_DP0 pid=393709) 	mov.b32 	%r116, 0;
(EngineCore_DP0 pid=393709) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=393709)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=393709) 	.loc	1 217 30                        // quant_slide_tuned_Llama3.2-3B.py:217:30
(EngineCore_DP0 pid=393709) 	add.s32 	%r83, %r3, %r116;
(EngineCore_DP0 pid=393709) 	setp.lt.s32 	%p13, %r83, %r15;
(EngineCore_DP0 pid=393709) 	.loc	1 220 24                        // quant_slide_tuned_Llama3.2-3B.py:220:24
(EngineCore_DP0 pid=393709) 	shr.u32 	%r84, %r83, 31;
(EngineCore_DP0 pid=393709) 	add.s32 	%r85, %r83, %r84;
(EngineCore_DP0 pid=393709) 	shr.u32 	%r86, %r85, 1;
(EngineCore_DP0 pid=393709) 	.loc	1 221 23                        // quant_slide_tuned_Llama3.2-3B.py:221:23
(EngineCore_DP0 pid=393709) 	and.b32 	%r87, %r85, 2147483646;
(EngineCore_DP0 pid=393709) 	sub.s32 	%r88, %r83, %r87;
(EngineCore_DP0 pid=393709) 	.loc	1 222 30                        // quant_slide_tuned_Llama3.2-3B.py:222:30
(EngineCore_DP0 pid=393709) 	shl.b32 	%r89, %r88, 1;
(EngineCore_DP0 pid=393709) 	.loc	1 222 26                        // quant_slide_tuned_Llama3.2-3B.py:222:26
(EngineCore_DP0 pid=393709) 	mad.lo.s32 	%r90, %r86, 6, %r89;
(EngineCore_DP0 pid=393709) 	.loc	1 225 53                        // quant_slide_tuned_Llama3.2-3B.py:225:53
(EngineCore_DP0 pid=393709) 	setp.lt.s32 	%p14, %r90, %r18;
(EngineCore_DP0 pid=393709) 	.loc	1 225 37                        // quant_slide_tuned_Llama3.2-3B.py:225:37
(EngineCore_DP0 pid=393709) 	and.pred 	%p9, %p13, %p14;
(EngineCore_DP0 pid=393709) 	.loc	1 224 29                        // quant_slide_tuned_Llama3.2-3B.py:224:29
(EngineCore_DP0 pid=393709) 	mad.wide.s32 	%rd8, %r90, 2, %rd1;
(EngineCore_DP0 pid=393709) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=393709) 	.loc	1 224 21                        // quant_slide_tuned_Llama3.2-3B.py:224:21
(EngineCore_DP0 pid=393709) 	// begin inline asm
(EngineCore_DP0 pid=393709) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=393709) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=393709) 	// end inline asm
(EngineCore_DP0 pid=393709) 	.loc	1 225 79                        // quant_slide_tuned_Llama3.2-3B.py:225:79
(EngineCore_DP0 pid=393709) 	cvt.f32.bf16 	%r91, %rs24;
(EngineCore_DP0 pid=393709) 	.loc	1 227 48                        // quant_slide_tuned_Llama3.2-3B.py:227:48
(EngineCore_DP0 pid=393709) 	or.b32 	%r92, %r90, 1;
(EngineCore_DP0 pid=393709) 	.loc	1 227 53                        // quant_slide_tuned_Llama3.2-3B.py:227:53
(EngineCore_DP0 pid=393709) 	setp.lt.s32 	%p15, %r92, %r18;
(EngineCore_DP0 pid=393709) 	.loc	1 227 37                        // quant_slide_tuned_Llama3.2-3B.py:227:37
(EngineCore_DP0 pid=393709) 	and.pred 	%p10, %p13, %p15;
(EngineCore_DP0 pid=393709) 	.loc	1 226 39                        // quant_slide_tuned_Llama3.2-3B.py:226:39
(EngineCore_DP0 pid=393709) 	add.s64 	%rd9, %rd8, 2;
(EngineCore_DP0 pid=393709) 	.loc	1 226 21                        // quant_slide_tuned_Llama3.2-3B.py:226:21
(EngineCore_DP0 pid=393709) 	// begin inline asm
(EngineCore_DP0 pid=393709) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=393709) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=393709) 	// end inline asm
(EngineCore_DP0 pid=393709) 	.loc	1 227 79                        // quant_slide_tuned_Llama3.2-3B.py:227:79
(EngineCore_DP0 pid=393709) 	cvt.f32.bf16 	%r93, %rs26;
(EngineCore_DP0 pid=393709) 	.loc	1 229 48                        // quant_slide_tuned_Llama3.2-3B.py:229:48
(EngineCore_DP0 pid=393709) 	add.s32 	%r94, %r90, 2;
(EngineCore_DP0 pid=393709) 	.loc	1 229 53                        // quant_slide_tuned_Llama3.2-3B.py:229:53
(EngineCore_DP0 pid=393709) 	setp.lt.s32 	%p16, %r94, %r18;
(EngineCore_DP0 pid=393709) 	.loc	1 229 37                        // quant_slide_tuned_Llama3.2-3B.py:229:37
(EngineCore_DP0 pid=393709) 	and.pred 	%p11, %p13, %p16;
(EngineCore_DP0 pid=393709) 	.loc	1 228 39                        // quant_slide_tuned_Llama3.2-3B.py:228:39
(EngineCore_DP0 pid=393709) 	add.s64 	%rd10, %rd8, 4;
(EngineCore_DP0 pid=393709) 	.loc	1 228 21                        // quant_slide_tuned_Llama3.2-3B.py:228:21
(EngineCore_DP0 pid=393709) 	// begin inline asm
(EngineCore_DP0 pid=393709) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=393709) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=393709) 	// end inline asm
(EngineCore_DP0 pid=393709) 	.loc	1 229 79                        // quant_slide_tuned_Llama3.2-3B.py:229:79
(EngineCore_DP0 pid=393709) 	cvt.f32.bf16 	%r95, %rs28;
(EngineCore_DP0 pid=393709) 	.loc	1 231 48                        // quant_slide_tuned_Llama3.2-3B.py:231:48
(EngineCore_DP0 pid=393709) 	add.s32 	%r96, %r90, 3;
(EngineCore_DP0 pid=393709) 	.loc	1 231 53                        // quant_slide_tuned_Llama3.2-3B.py:231:53
(EngineCore_DP0 pid=393709) 	setp.lt.s32 	%p17, %r96, %r18;
(EngineCore_DP0 pid=393709) 	.loc	1 231 37                        // quant_slide_tuned_Llama3.2-3B.py:231:37
(EngineCore_DP0 pid=393709) 	and.pred 	%p12, %p13, %p17;
(EngineCore_DP0 pid=393709) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-3B.py:230:39
(EngineCore_DP0 pid=393709) 	add.s64 	%rd11, %rd8, 6;
(EngineCore_DP0 pid=393709) 	.loc	1 230 21                        // quant_slide_tuned_Llama3.2-3B.py:230:21
(EngineCore_DP0 pid=393709) 	// begin inline asm
(EngineCore_DP0 pid=393709) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=393709) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=393709) 	// end inline asm
(EngineCore_DP0 pid=393709) 	.loc	1 231 79                        // quant_slide_tuned_Llama3.2-3B.py:231:79
(EngineCore_DP0 pid=393709) 	cvt.f32.bf16 	%r97, %rs30;
(EngineCore_DP0 pid=393709) 	.loc	1 233 27                        // quant_slide_tuned_Llama3.2-3B.py:233:27
(EngineCore_DP0 pid=393709) 	mul.f32 	%r98, %r14, %r91;
(EngineCore_DP0 pid=393709) 	mov.b32 	%r99, 0f43E00000;
(EngineCore_DP0 pid=393709) 	.loc	1 233 48                        // quant_slide_tuned_Llama3.2-3B.py:233:48
(EngineCore_DP0 pid=393709) 	min.xorsign.abs.f32 	%r73, %r98, %r99;
(EngineCore_DP0 pid=393709) 	.loc	1 233 60                        // quant_slide_tuned_Llama3.2-3B.py:233:60
(EngineCore_DP0 pid=393709) 	// begin inline asm
(EngineCore_DP0 pid=393709) 	cvt.rn.satfinite.e4m3x2.f32  %rs32, %r74, %r73; 
(EngineCore_DP0 pid=393709) 
(EngineCore_DP0 pid=393709) 	// end inline asm
(EngineCore_DP0 pid=393709) 	.loc	1 234 27                        // quant_slide_tuned_Llama3.2-3B.py:234:27
(EngineCore_DP0 pid=393709) 	mul.f32 	%r100, %r14, %r93;
(EngineCore_DP0 pid=393709) 	.loc	1 234 48                        // quant_slide_tuned_Llama3.2-3B.py:234:48
(EngineCore_DP0 pid=393709) 	min.xorsign.abs.f32 	%r75, %r100, %r99;
(EngineCore_DP0 pid=393709) 	.loc	1 234 60                        // quant_slide_tuned_Llama3.2-3B.py:234:60
(EngineCore_DP0 pid=393709) 	// begin inline asm
(EngineCore_DP0 pid=393709) 	cvt.rn.satfinite.e4m3x2.f32  %rs33, %r76, %r75; 
(EngineCore_DP0 pid=393709) 
(EngineCore_DP0 pid=393709) 	// end inline asm
(EngineCore_DP0 pid=393709) 	.loc	1 235 27                        // quant_slide_tuned_Llama3.2-3B.py:235:27
(EngineCore_DP0 pid=393709) 	mul.f32 	%r101, %r14, %r95;
(EngineCore_DP0 pid=393709) 	.loc	1 235 48                        // quant_slide_tuned_Llama3.2-3B.py:235:48
(EngineCore_DP0 pid=393709) 	min.xorsign.abs.f32 	%r77, %r101, %r99;
(EngineCore_DP0 pid=393709) 	.loc	1 235 60                        // quant_slide_tuned_Llama3.2-3B.py:235:60
(EngineCore_DP0 pid=393709) 	// begin inline asm
(EngineCore_DP0 pid=393709) 	cvt.rn.satfinite.e4m3x2.f32  %rs34, %r78, %r77; 
(EngineCore_DP0 pid=393709) 
(EngineCore_DP0 pid=393709) 	// end inline asm
(EngineCore_DP0 pid=393709) 	.loc	1 236 27                        // quant_slide_tuned_Llama3.2-3B.py:236:27
(EngineCore_DP0 pid=393709) 	mul.f32 	%r102, %r14, %r97;
(EngineCore_DP0 pid=393709) 	.loc	1 236 48                        // quant_slide_tuned_Llama3.2-3B.py:236:48
(EngineCore_DP0 pid=393709) 	min.xorsign.abs.f32 	%r79, %r102, %r99;
(EngineCore_DP0 pid=393709) 	.loc	1 236 60                        // quant_slide_tuned_Llama3.2-3B.py:236:60
(EngineCore_DP0 pid=393709) 	// begin inline asm
(EngineCore_DP0 pid=393709) 	cvt.rn.satfinite.e4m3x2.f32  %rs35, %r80, %r79; 
(EngineCore_DP0 pid=393709) 
(EngineCore_DP0 pid=393709) 	// end inline asm
(EngineCore_DP0 pid=393709) 	.loc	1 238 45                        // quant_slide_tuned_Llama3.2-3B.py:238:45
(EngineCore_DP0 pid=393709) 	cvt.u32.u16 	%r103, %rs32;
(EngineCore_DP0 pid=393709) 	and.b32 	%r104, %r103, 255;
(EngineCore_DP0 pid=393709) 	.loc	1 240 45                        // quant_slide_tuned_Llama3.2-3B.py:240:45
(EngineCore_DP0 pid=393709) 	cvt.u32.u16 	%r105, %rs34;
(EngineCore_DP0 pid=393709) 	and.b32 	%r106, %r105, 255;
(EngineCore_DP0 pid=393709) 	.loc	1 241 45                        // quant_slide_tuned_Llama3.2-3B.py:241:45
(EngineCore_DP0 pid=393709) 	cvt.u32.u16 	%r107, %rs35;
(EngineCore_DP0 pid=393709) 	.loc	1 243 30                        // quant_slide_tuned_Llama3.2-3B.py:243:30
(EngineCore_DP0 pid=393709) 	and.b16 	%rs36, %rs33, 255;
(EngineCore_DP0 pid=393709) 	mul.wide.u16 	%r108, %rs36, 256;
(EngineCore_DP0 pid=393709) 	.loc	1 243 24                        // quant_slide_tuned_Llama3.2-3B.py:243:24
(EngineCore_DP0 pid=393709) 	or.b32 	%r109, %r108, %r104;
(EngineCore_DP0 pid=393709) 	.loc	1 243 42                        // quant_slide_tuned_Llama3.2-3B.py:243:42
(EngineCore_DP0 pid=393709) 	shl.b32 	%r110, %r106, 16;
(EngineCore_DP0 pid=393709) 	.loc	1 243 36                        // quant_slide_tuned_Llama3.2-3B.py:243:36
(EngineCore_DP0 pid=393709) 	or.b32 	%r111, %r109, %r110;
(EngineCore_DP0 pid=393709) 	.loc	1 243 55                        // quant_slide_tuned_Llama3.2-3B.py:243:55
(EngineCore_DP0 pid=393709) 	shl.b32 	%r112, %r107, 24;
(EngineCore_DP0 pid=393709) 	.loc	1 243 49                        // quant_slide_tuned_Llama3.2-3B.py:243:49
(EngineCore_DP0 pid=393709) 	or.b32 	%r81, %r111, %r112;
(EngineCore_DP0 pid=393709) 	.loc	1 244 29                        // quant_slide_tuned_Llama3.2-3B.py:244:29
(EngineCore_DP0 pid=393709) 	mad.wide.s32 	%rd12, %r83, 4, %rd2;
(EngineCore_DP0 pid=393709) 	.loc	1 244 39                        // quant_slide_tuned_Llama3.2-3B.py:244:39
(EngineCore_DP0 pid=393709) 	// begin inline asm
(EngineCore_DP0 pid=393709) 	@%p13 st.global.b32 [ %rd12 + 0 ], { %r81 };
(EngineCore_DP0 pid=393709) 	// end inline asm
(EngineCore_DP0 pid=393709) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=393709) 	add.s32 	%r116, %r116, 512;
(EngineCore_DP0 pid=393709) 	setp.lt.s32 	%p18, %r116, %r15;
(EngineCore_DP0 pid=393709) 	@%p18 bra 	$L__BB0_6;
(EngineCore_DP0 pid=393709) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=393709) 	.loc	1 215 4                         // quant_slide_tuned_Llama3.2-3B.py:215:4
(EngineCore_DP0 pid=393709) 	ret;
(EngineCore_DP0 pid=393709) $L__tmp3:
(EngineCore_DP0 pid=393709) $L__func_end0:
(EngineCore_DP0 pid=393709)                                         // -- End function
(EngineCore_DP0 pid=393709) }
(EngineCore_DP0 pid=393709) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py"
(EngineCore_DP0 pid=393709) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=393709) 	.section	.debug_abbrev
(EngineCore_DP0 pid=393709) 	{
(EngineCore_DP0 pid=393709) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=393709) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=393709) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=393709) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=393709) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=393709) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=393709) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=393709) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=393709) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=393709) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=393709) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=393709) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=393709) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=393709) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=393709) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=393709) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=393709) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=393709) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=393709) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=393709) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=393709) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=393709) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=393709) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=393709) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=393709) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=393709) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=393709) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=393709) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=393709) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=393709) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=393709) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=393709) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=393709) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=393709) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=393709) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=393709) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=393709) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=393709) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=393709) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=393709) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=393709) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=393709) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=393709) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=393709) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=393709) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=393709) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=393709) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=393709) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=393709) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=393709) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=393709) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=393709) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=393709) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=393709) 	}
(EngineCore_DP0 pid=393709) 	.section	.debug_info
(EngineCore_DP0 pid=393709) 	{
(EngineCore_DP0 pid=393709) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=393709) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=393709) .b8 0
(EngineCore_DP0 pid=393709) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=393709) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=393709) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=393709) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=393709) .b8 114
(EngineCore_DP0 pid=393709) .b8 105
(EngineCore_DP0 pid=393709) .b8 116
(EngineCore_DP0 pid=393709) .b8 111
(EngineCore_DP0 pid=393709) .b8 110
(EngineCore_DP0 pid=393709) .b8 0
(EngineCore_DP0 pid=393709) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=393709) .b8 0
(EngineCore_DP0 pid=393709) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=393709) .b8 117
(EngineCore_DP0 pid=393709) .b8 97
(EngineCore_DP0 pid=393709) .b8 110
(EngineCore_DP0 pid=393709) .b8 116
(EngineCore_DP0 pid=393709) .b8 95
(EngineCore_DP0 pid=393709) .b8 115
(EngineCore_DP0 pid=393709) .b8 108
(EngineCore_DP0 pid=393709) .b8 105
(EngineCore_DP0 pid=393709) .b8 100
(EngineCore_DP0 pid=393709) .b8 101
(EngineCore_DP0 pid=393709) .b8 95
(EngineCore_DP0 pid=393709) .b8 116
(EngineCore_DP0 pid=393709) .b8 117
(EngineCore_DP0 pid=393709) .b8 110
(EngineCore_DP0 pid=393709) .b8 101
(EngineCore_DP0 pid=393709) .b8 100
(EngineCore_DP0 pid=393709) .b8 95
(EngineCore_DP0 pid=393709) .b8 76
(EngineCore_DP0 pid=393709) .b8 108
(EngineCore_DP0 pid=393709) .b8 97
(EngineCore_DP0 pid=393709) .b8 109
(EngineCore_DP0 pid=393709) .b8 97
(EngineCore_DP0 pid=393709) .b8 51
(EngineCore_DP0 pid=393709) .b8 46
(EngineCore_DP0 pid=393709) .b8 50
(EngineCore_DP0 pid=393709) .b8 45
(EngineCore_DP0 pid=393709) .b8 51
(EngineCore_DP0 pid=393709) .b8 66
(EngineCore_DP0 pid=393709) .b8 46
(EngineCore_DP0 pid=393709) .b8 112
(EngineCore_DP0 pid=393709) .b8 121
(EngineCore_DP0 pid=393709) .b8 0
(EngineCore_DP0 pid=393709) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=393709) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=393709) .b8 114
(EngineCore_DP0 pid=393709) .b8 111
(EngineCore_DP0 pid=393709) .b8 111
(EngineCore_DP0 pid=393709) .b8 116
(EngineCore_DP0 pid=393709) .b8 47
(EngineCore_DP0 pid=393709) .b8 118
(EngineCore_DP0 pid=393709) .b8 108
(EngineCore_DP0 pid=393709) .b8 108
(EngineCore_DP0 pid=393709) .b8 109
(EngineCore_DP0 pid=393709) .b8 98
(EngineCore_DP0 pid=393709) .b8 101
(EngineCore_DP0 pid=393709) .b8 110
(EngineCore_DP0 pid=393709) .b8 99
(EngineCore_DP0 pid=393709) .b8 104
(EngineCore_DP0 pid=393709) .b8 47
(EngineCore_DP0 pid=393709) .b8 115
(EngineCore_DP0 pid=393709) .b8 108
(EngineCore_DP0 pid=393709) .b8 105
(EngineCore_DP0 pid=393709) .b8 100
(EngineCore_DP0 pid=393709) .b8 101
(EngineCore_DP0 pid=393709) .b8 115
(EngineCore_DP0 pid=393709) .b8 112
(EngineCore_DP0 pid=393709) .b8 97
(EngineCore_DP0 pid=393709) .b8 114
(EngineCore_DP0 pid=393709) .b8 115
(EngineCore_DP0 pid=393709) .b8 101
(EngineCore_DP0 pid=393709) .b8 47
(EngineCore_DP0 pid=393709) .b8 99
(EngineCore_DP0 pid=393709) .b8 115
(EngineCore_DP0 pid=393709) .b8 114
(EngineCore_DP0 pid=393709) .b8 99
(EngineCore_DP0 pid=393709) .b8 47
(EngineCore_DP0 pid=393709) .b8 102
(EngineCore_DP0 pid=393709) .b8 117
(EngineCore_DP0 pid=393709) .b8 115
(EngineCore_DP0 pid=393709) .b8 101
(EngineCore_DP0 pid=393709) .b8 100
(EngineCore_DP0 pid=393709) .b8 95
(EngineCore_DP0 pid=393709) .b8 113
(EngineCore_DP0 pid=393709) .b8 117
(EngineCore_DP0 pid=393709) .b8 97
(EngineCore_DP0 pid=393709) .b8 110
(EngineCore_DP0 pid=393709) .b8 116
(EngineCore_DP0 pid=393709) .b8 95
(EngineCore_DP0 pid=393709) .b8 115
(EngineCore_DP0 pid=393709) .b8 108
(EngineCore_DP0 pid=393709) .b8 105
(EngineCore_DP0 pid=393709) .b8 100
(EngineCore_DP0 pid=393709) .b8 101
(EngineCore_DP0 pid=393709) .b8 95
(EngineCore_DP0 pid=393709) .b8 116
(EngineCore_DP0 pid=393709) .b8 114
(EngineCore_DP0 pid=393709) .b8 105
(EngineCore_DP0 pid=393709) .b8 116
(EngineCore_DP0 pid=393709) .b8 111
(EngineCore_DP0 pid=393709) .b8 110
(EngineCore_DP0 pid=393709) .b8 47
(EngineCore_DP0 pid=393709) .b8 98
(EngineCore_DP0 pid=393709) .b8 117
(EngineCore_DP0 pid=393709) .b8 105
(EngineCore_DP0 pid=393709) .b8 108
(EngineCore_DP0 pid=393709) .b8 100
(EngineCore_DP0 pid=393709) .b8 47
(EngineCore_DP0 pid=393709) .b8 71
(EngineCore_DP0 pid=393709) .b8 66
(EngineCore_DP0 pid=393709) .b8 49
(EngineCore_DP0 pid=393709) .b8 48
(EngineCore_DP0 pid=393709) .b8 95
(EngineCore_DP0 pid=393709) .b8 99
(EngineCore_DP0 pid=393709) .b8 99
(EngineCore_DP0 pid=393709) .b8 49
(EngineCore_DP0 pid=393709) .b8 50
(EngineCore_DP0 pid=393709) .b8 49
(EngineCore_DP0 pid=393709) .b8 95
(EngineCore_DP0 pid=393709) .b8 112
(EngineCore_DP0 pid=393709) .b8 121
(EngineCore_DP0 pid=393709) .b8 51
(EngineCore_DP0 pid=393709) .b8 49
(EngineCore_DP0 pid=393709) .b8 50
(EngineCore_DP0 pid=393709) .b8 95
(EngineCore_DP0 pid=393709) .b8 99
(EngineCore_DP0 pid=393709) .b8 117
(EngineCore_DP0 pid=393709) .b8 49
(EngineCore_DP0 pid=393709) .b8 50
(EngineCore_DP0 pid=393709) .b8 57
(EngineCore_DP0 pid=393709) .b8 95
(EngineCore_DP0 pid=393709) .b8 97
(EngineCore_DP0 pid=393709) .b8 97
(EngineCore_DP0 pid=393709) .b8 114
(EngineCore_DP0 pid=393709) .b8 99
(EngineCore_DP0 pid=393709) .b8 104
(EngineCore_DP0 pid=393709) .b8 54
(EngineCore_DP0 pid=393709) .b8 52
(EngineCore_DP0 pid=393709) .b8 0
(EngineCore_DP0 pid=393709) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=393709) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=393709) .b8 113
(EngineCore_DP0 pid=393709) .b8 117
(EngineCore_DP0 pid=393709) .b8 97
(EngineCore_DP0 pid=393709) .b8 110
(EngineCore_DP0 pid=393709) .b8 116
(EngineCore_DP0 pid=393709) .b8 95
(EngineCore_DP0 pid=393709) .b8 115
(EngineCore_DP0 pid=393709) .b8 108
(EngineCore_DP0 pid=393709) .b8 105
(EngineCore_DP0 pid=393709) .b8 100
(EngineCore_DP0 pid=393709) .b8 101
(EngineCore_DP0 pid=393709) .b8 95
(EngineCore_DP0 pid=393709) .b8 102
(EngineCore_DP0 pid=393709) .b8 112
(EngineCore_DP0 pid=393709) .b8 56
(EngineCore_DP0 pid=393709) .b8 95
(EngineCore_DP0 pid=393709) .b8 107
(EngineCore_DP0 pid=393709) .b8 101
(EngineCore_DP0 pid=393709) .b8 114
(EngineCore_DP0 pid=393709) .b8 110
(EngineCore_DP0 pid=393709) .b8 101
(EngineCore_DP0 pid=393709) .b8 108
(EngineCore_DP0 pid=393709) .b8 0
(EngineCore_DP0 pid=393709) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=393709) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=393709) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=393709) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=393709) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=393709) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=393709) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=393709) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=393709) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=393709) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=393709) .b8 205                                 // DW_AT_call_line
(EngineCore_DP0 pid=393709) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=393709) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=393709) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=393709) 	}
(EngineCore_DP0 pid=393709) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=393709) 
(EngineCore_DP0 pid=393709) ================================================================
(EngineCore_DP0 pid=393709) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=393709) 
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp3_owo6zv.ptx', '-o', '/tmp/tmp3_owo6zv.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866] 
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866] 
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866] 
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp3_owo6zv.ptx -o /tmp/tmp3_owo6zv.ptx.o
(EngineCore_DP0 pid=393709) ERROR 01-25 20:05:56 [core.py:866] 

STDERR:
[2026-01-25 20:05:29] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:05:29] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:05:29] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:05:29] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:05:29] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:05:29] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:05:29] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:05:29] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:05:29] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:05:29] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:05:29] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:05:29] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:05:29] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:05:29] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:05:32] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:05:32] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:05:32] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:05:32] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:05:32] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:05:32] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:05:32] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:05:32] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:05:32] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:05:32] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:05:32] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:05:32] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:05:32] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:05:32] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=393709) [2026-01-25 20:05:33] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=393709) [2026-01-25 20:05:33] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=393709) [2026-01-25 20:05:33] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=393709) [2026-01-25 20:05:33] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=393709) [2026-01-25 20:05:33] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=393709) [2026-01-25 20:05:33] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=393709) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=393709) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:20<00:00, 20.60s/it]
(EngineCore_DP0 pid=393709) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:20<00:00, 20.60s/it]
(EngineCore_DP0 pid=393709) 
(EngineCore_DP0 pid=393709) [2026-01-25 20:05:55] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4096] -> 1D uint8
(EngineCore_DP0 pid=393709) [2026-01-25 20:05:55] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 13107200 bytes
(EngineCore_DP0 pid=393709) [2026-01-25 20:05:55] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4096] -> 1D uint8
(EngineCore_DP0 pid=393709) [2026-01-25 20:05:55] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 7864320 bytes
(EngineCore_DP0 pid=393709) [2026-01-25 20:05:55] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4096] -> 1D uint8
(EngineCore_DP0 pid=393709) [2026-01-25 20:05:55] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 41943040 bytes
(EngineCore_DP0 pid=393709) [2026-01-25 20:05:55] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 10944] -> 1D uint8
(EngineCore_DP0 pid=393709) [2026-01-25 20:05:55] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 21037056 bytes
(EngineCore_DP0 pid=393709) Process EngineCore_DP0:
(EngineCore_DP0 pid=393709) Traceback (most recent call last):
(EngineCore_DP0 pid=393709)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=393709)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=393709)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=393709)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=393709) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp3_owo6zv.ptx', '-o', '/tmp/tmp3_owo6zv.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=393709) 
(EngineCore_DP0 pid=393709) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=393709) 
(EngineCore_DP0 pid=393709) Traceback (most recent call last):
(EngineCore_DP0 pid=393709)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=393709)     self.run()
(EngineCore_DP0 pid=393709)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=393709)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=393709)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=393709)     raise e
(EngineCore_DP0 pid=393709)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=393709)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=393709)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=393709)     super().__init__(
(EngineCore_DP0 pid=393709)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=393709)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=393709)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=393709)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=393709)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=393709)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=393709)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=393709)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=393709)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=393709)     return func(*args, **kwargs)
(EngineCore_DP0 pid=393709)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=393709)     return func(*args, **kwargs)
(EngineCore_DP0 pid=393709)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=393709)     self.model_runner.profile_run()
(EngineCore_DP0 pid=393709)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=393709)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=393709)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=393709)     return func(*args, **kwargs)
(EngineCore_DP0 pid=393709)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=393709)     outputs = self.model(
(EngineCore_DP0 pid=393709)               ^^^^^^^^^^^
(EngineCore_DP0 pid=393709)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=393709)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=393709)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=393709)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=393709)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=393709)     model_output = self.model(
(EngineCore_DP0 pid=393709)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=393709)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=393709)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=393709)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=393709)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=393709)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=393709)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=393709)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=393709)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=393709)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=393709)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=393709)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=393709)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=393709)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=393709)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=393709)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=393709)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=393709)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=393709)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=393709)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=393709)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=393709)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=393709)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=393709)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=393709)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=393709)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=393709)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=393709)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=393709)     return self._linear_fn(
(EngineCore_DP0 pid=393709)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=393709)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=393709)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=393709)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=393709)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=393709)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=393709)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=393709)     return fn(input, L)
(EngineCore_DP0 pid=393709)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=393709)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=393709)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=393709)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=393709)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=393709)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=393709)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=393709)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=393709)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=393709)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=393709)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=393709)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=393709)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=393709)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=393709)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=393709)     raise PTXASError(error)
(EngineCore_DP0 pid=393709) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=393709) `ptxas` stderr:
(EngineCore_DP0 pid=393709) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=393709) 
(EngineCore_DP0 pid=393709) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp3_owo6zv.ptx -o /tmp/tmp3_owo6zv.ptx.o
(EngineCore_DP0 pid=393709) 
[rank0]:[W125 20:05:56.752993361 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=2048

========== M=4096 ==========
Time: 2026-01-25 20:05:58
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-3B-FP8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:06:03 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 20:06:03 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=394380) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=394380) 
(EngineCore_DP0 pid=394380) 
(EngineCore_DP0 pid=394380) ================================================================
(EngineCore_DP0 pid=394380) Internal Triton PTX codegen error
(EngineCore_DP0 pid=394380) `ptxas` stderr:
(EngineCore_DP0 pid=394380) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=394380) 
(EngineCore_DP0 pid=394380) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp3g2udyaw.ptx -o /tmp/tmp3g2udyaw.ptx.o
(EngineCore_DP0 pid=394380) 
(EngineCore_DP0 pid=394380) 
(EngineCore_DP0 pid=394380) //
(EngineCore_DP0 pid=394380) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=394380) //
(EngineCore_DP0 pid=394380) 
(EngineCore_DP0 pid=394380) .version 8.7
(EngineCore_DP0 pid=394380) .target sm_121a
(EngineCore_DP0 pid=394380) .address_size 64
(EngineCore_DP0 pid=394380) 
(EngineCore_DP0 pid=394380) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=394380) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=394380)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=394380) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=394380) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=394380) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=394380) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=394380) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=394380) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=394380) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=394380) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=394380) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=394380) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=394380) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=394380) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=394380) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=394380) )
(EngineCore_DP0 pid=394380) .reqntid 512
(EngineCore_DP0 pid=394380) {
(EngineCore_DP0 pid=394380) 	.reg .pred 	%p<28>;
(EngineCore_DP0 pid=394380) 	.reg .b16 	%rs<49>;
(EngineCore_DP0 pid=394380) 	.reg .b32 	%r<139>;
(EngineCore_DP0 pid=394380) 	.reg .b64 	%rd<17>;
(EngineCore_DP0 pid=394380) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=394380) $L__func_begin0:
(EngineCore_DP0 pid=394380) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=394380) 
(EngineCore_DP0 pid=394380) // %bb.0:
(EngineCore_DP0 pid=394380) 	ld.param.b32 	%r21, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=394380) 	ld.param.b32 	%r20, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=394380) 	ld.param.b32 	%r19, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=394380) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=394380) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=394380) $L__tmp0:
(EngineCore_DP0 pid=394380) 	.loc	1 191 24                        // quant_slide_tuned_Llama3.2-3B.py:191:24
(EngineCore_DP0 pid=394380) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=394380) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=394380) 	.loc	1 196 26                        // quant_slide_tuned_Llama3.2-3B.py:196:26
(EngineCore_DP0 pid=394380) 	mul.lo.s32 	%r24, %r23, %r1;
(EngineCore_DP0 pid=394380) 	.loc	1 196 20                        // quant_slide_tuned_Llama3.2-3B.py:196:20
(EngineCore_DP0 pid=394380) 	mad.wide.s32 	%rd1, %r24, 2, %rd4;
(EngineCore_DP0 pid=394380) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=394380) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=394380) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=394380) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=394380) 	setp.lt.s32 	%p1, %r20, 1;
(EngineCore_DP0 pid=394380) 	mov.b32 	%r137, 0f2B8CBCCC;
(EngineCore_DP0 pid=394380) 	setp.eq.b32 	%p27, %r2, 0;
(EngineCore_DP0 pid=394380) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=394380) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=394380) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=394380) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=394380) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=394380) 	shr.u32 	%r33, %r2, 3;
(EngineCore_DP0 pid=394380) 	and.b32 	%r34, %r33, 60;
(EngineCore_DP0 pid=394380) 	mov.b32 	%r35, global_smem;
(EngineCore_DP0 pid=394380) 	add.s32 	%r45, %r35, %r34;
(EngineCore_DP0 pid=394380) 	shl.b32 	%r36, %r2, 2;
(EngineCore_DP0 pid=394380) 	add.s32 	%r48, %r35, %r36;
(EngineCore_DP0 pid=394380) 	mov.b32 	%r41, 0;
(EngineCore_DP0 pid=394380) 	mov.b32 	%r135, 0f00000000;
(EngineCore_DP0 pid=394380) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=394380) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=394380) 	mov.b32 	%r136, %r41;
(EngineCore_DP0 pid=394380) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=394380) 	.loc	1 203 22                        // quant_slide_tuned_Llama3.2-3B.py:203:22
(EngineCore_DP0 pid=394380) 	add.s32 	%r51, %r4, %r136;
(EngineCore_DP0 pid=394380) 	setp.lt.s32 	%p2, %r51, %r19;
(EngineCore_DP0 pid=394380) 	.loc	1 204 29                        // quant_slide_tuned_Llama3.2-3B.py:204:29
(EngineCore_DP0 pid=394380) 	mad.wide.s32 	%rd6, %r51, 2, %rd1;
(EngineCore_DP0 pid=394380) 	.loc	1 204 21                        // quant_slide_tuned_Llama3.2-3B.py:204:21
(EngineCore_DP0 pid=394380) 	// begin inline asm
(EngineCore_DP0 pid=394380) 	mov.u32 %r37, %r41;
(EngineCore_DP0 pid=394380) 	mov.u32 %r38, %r41;
(EngineCore_DP0 pid=394380) 	mov.u32 %r39, %r41;
(EngineCore_DP0 pid=394380) 	mov.u32 %r40, %r41;
(EngineCore_DP0 pid=394380) 	@%p2 ld.global.v4.b32 { %r37, %r38, %r39, %r40 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=394380) 	// end inline asm
(EngineCore_DP0 pid=394380) 	mov.b32 	{%rs1, %rs2}, %r37;
(EngineCore_DP0 pid=394380) 	mov.b32 	{%rs3, %rs4}, %r38;
(EngineCore_DP0 pid=394380) 	mov.b32 	{%rs5, %rs6}, %r39;
(EngineCore_DP0 pid=394380) 	mov.b32 	{%rs7, %rs8}, %r40;
(EngineCore_DP0 pid=394380) 	.loc	1 205 50                        // quant_slide_tuned_Llama3.2-3B.py:205:50
(EngineCore_DP0 pid=394380) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=394380) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=394380) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=394380) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=394380) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=394380) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=394380) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=394380) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=394380) $L__tmp1:
(EngineCore_DP0 pid=394380) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=394380) 	bar.sync 	0;
(EngineCore_DP0 pid=394380) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=394380) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=394380) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=394380) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=394380) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=394380) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=394380) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=394380) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=394380) 	cvt.f32.bf16 	%r52, %rs23;
(EngineCore_DP0 pid=394380) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=394380) 	shfl.sync.bfly.b32 	%r53, %r52, 16, 31, -1;
(EngineCore_DP0 pid=394380) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=394380) 	max.f32 	%r54, %r52, %r53;
(EngineCore_DP0 pid=394380) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=394380) 	shfl.sync.bfly.b32 	%r55, %r54, 8, 31, -1;
(EngineCore_DP0 pid=394380) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=394380) 	max.f32 	%r56, %r54, %r55;
(EngineCore_DP0 pid=394380) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=394380) 	shfl.sync.bfly.b32 	%r57, %r56, 4, 31, -1;
(EngineCore_DP0 pid=394380) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=394380) 	max.f32 	%r58, %r56, %r57;
(EngineCore_DP0 pid=394380) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=394380) 	shfl.sync.bfly.b32 	%r59, %r58, 2, 31, -1;
(EngineCore_DP0 pid=394380) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=394380) 	max.f32 	%r60, %r58, %r59;
(EngineCore_DP0 pid=394380) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=394380) 	shfl.sync.bfly.b32 	%r61, %r60, 1, 31, -1;
(EngineCore_DP0 pid=394380) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=394380) 	max.f32 	%r46, %r60, %r61;
(EngineCore_DP0 pid=394380) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=394380) 	// begin inline asm
(EngineCore_DP0 pid=394380) 	@%p3 st.shared.b32 [ %r45 + 0 ], %r46;
(EngineCore_DP0 pid=394380) 	// end inline asm
(EngineCore_DP0 pid=394380) 	bar.sync 	0;
(EngineCore_DP0 pid=394380) 	// begin inline asm
(EngineCore_DP0 pid=394380) 	@%p4 ld.shared.b32 %r47, [ %r48 + 0 ];
(EngineCore_DP0 pid=394380) 	// end inline asm
(EngineCore_DP0 pid=394380) 	shfl.sync.bfly.b32 	%r62, %r47, 8, 31, -1;
(EngineCore_DP0 pid=394380) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=394380) 	max.f32 	%r63, %r47, %r62;
(EngineCore_DP0 pid=394380) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=394380) 	shfl.sync.bfly.b32 	%r64, %r63, 4, 31, -1;
(EngineCore_DP0 pid=394380) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=394380) 	max.f32 	%r65, %r63, %r64;
(EngineCore_DP0 pid=394380) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=394380) 	shfl.sync.bfly.b32 	%r66, %r65, 2, 31, -1;
(EngineCore_DP0 pid=394380) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=394380) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=394380) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=394380) 	shfl.sync.bfly.b32 	%r68, %r67, 1, 31, -1;
(EngineCore_DP0 pid=394380) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=394380) 	max.f32 	%r50, %r67, %r68;
(EngineCore_DP0 pid=394380) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=394380) 	// begin inline asm
(EngineCore_DP0 pid=394380) 	@%p27 st.shared.b32 [ %r48 + 0 ], %r50;
(EngineCore_DP0 pid=394380) 	// end inline asm
(EngineCore_DP0 pid=394380) 	bar.sync 	0;
(EngineCore_DP0 pid=394380) 	ld.shared.b32 	%r69, [global_smem];
(EngineCore_DP0 pid=394380) $L__tmp2:
(EngineCore_DP0 pid=394380) 	.loc	1 205 36                        // quant_slide_tuned_Llama3.2-3B.py:205:36
(EngineCore_DP0 pid=394380) 	max.f32 	%r135, %r135, %r69;
(EngineCore_DP0 pid=394380) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=394380) 	add.s32 	%r136, %r136, 4096;
(EngineCore_DP0 pid=394380) 	setp.lt.s32 	%p6, %r136, %r20;
(EngineCore_DP0 pid=394380) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=394380) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=394380) 	.loc	1 207 32                        // quant_slide_tuned_Llama3.2-3B.py:207:32
(EngineCore_DP0 pid=394380) 	max.f32 	%r137, %r135, 0f2B8CBCCC;
(EngineCore_DP0 pid=394380) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=394380) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-3B.py:0:32
(EngineCore_DP0 pid=394380) 	mov.b32 	%r71, 0f43E00000;
(EngineCore_DP0 pid=394380) 	.loc	1 208 32                        // quant_slide_tuned_Llama3.2-3B.py:208:32
(EngineCore_DP0 pid=394380) 	div.full.f32 	%r72, %r137, %r71;
(EngineCore_DP0 pid=394380) 	.loc	1 208 41                        // quant_slide_tuned_Llama3.2-3B.py:208:41
(EngineCore_DP0 pid=394380) 	max.f32 	%r70, %r72, 0f36924925;
(EngineCore_DP0 pid=394380) 	.loc	1 210 25                        // quant_slide_tuned_Llama3.2-3B.py:210:25
(EngineCore_DP0 pid=394380) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=394380) 	.loc	1 210 30                        // quant_slide_tuned_Llama3.2-3B.py:210:30
(EngineCore_DP0 pid=394380) 	// begin inline asm
(EngineCore_DP0 pid=394380) 	@%p27 st.global.b32 [ %rd7 + 0 ], { %r70 };
(EngineCore_DP0 pid=394380) 	// end inline asm
(EngineCore_DP0 pid=394380) 	.loc	1 213 29                        // quant_slide_tuned_Llama3.2-3B.py:213:29
(EngineCore_DP0 pid=394380) 	shl.b32 	%r15, %r21, 1;
(EngineCore_DP0 pid=394380) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=394380) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=394380) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=394380) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=394380) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-3B.py:0:41
(EngineCore_DP0 pid=394380) 	ld.param.b32 	%r25, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=394380) 	shr.s32 	%r26, %r25, 31;
(EngineCore_DP0 pid=394380) 	shr.u32 	%r27, %r26, 30;
(EngineCore_DP0 pid=394380) 	add.s32 	%r28, %r25, %r27;
(EngineCore_DP0 pid=394380) 	shr.s32 	%r29, %r28, 2;
(EngineCore_DP0 pid=394380) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=394380) 	mul.lo.s32 	%r30, %r29, %r1;
(EngineCore_DP0 pid=394380) 	mad.wide.s32 	%rd2, %r30, 4, %rd5;
(EngineCore_DP0 pid=394380) 	div.full.f32 	%r14, %r71, %r137;
(EngineCore_DP0 pid=394380) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=394380) 	mov.b32 	%r138, 0;
(EngineCore_DP0 pid=394380) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=394380)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=394380) 	.loc	1 216 31                        // quant_slide_tuned_Llama3.2-3B.py:216:31
(EngineCore_DP0 pid=394380) 	add.s32 	%r84, %r16, %r138;
(EngineCore_DP0 pid=394380) 	.loc	1 217 30                        // quant_slide_tuned_Llama3.2-3B.py:217:30
(EngineCore_DP0 pid=394380) 	add.s32 	%r85, %r138, 1;
(EngineCore_DP0 pid=394380) 	setp.lt.s32 	%p17, %r84, %r15;
(EngineCore_DP0 pid=394380) 	.loc	1 220 24                        // quant_slide_tuned_Llama3.2-3B.py:220:24
(EngineCore_DP0 pid=394380) 	shr.u32 	%r86, %r84, 1;
(EngineCore_DP0 pid=394380) 	.loc	1 221 23                        // quant_slide_tuned_Llama3.2-3B.py:221:23
(EngineCore_DP0 pid=394380) 	shr.u32 	%r87, %r85, 31;
(EngineCore_DP0 pid=394380) 	add.s32 	%r88, %r85, %r87;
(EngineCore_DP0 pid=394380) 	and.b32 	%r89, %r88, 2147483646;
(EngineCore_DP0 pid=394380) 	sub.s32 	%r90, %r85, %r89;
(EngineCore_DP0 pid=394380) 	.loc	1 222 22                        // quant_slide_tuned_Llama3.2-3B.py:222:22
(EngineCore_DP0 pid=394380) 	mul.lo.s32 	%r91, %r86, 6;
(EngineCore_DP0 pid=394380) 	.loc	1 222 30                        // quant_slide_tuned_Llama3.2-3B.py:222:30
(EngineCore_DP0 pid=394380) 	shl.b32 	%r92, %r90, 1;
(EngineCore_DP0 pid=394380) 	.loc	1 222 26                        // quant_slide_tuned_Llama3.2-3B.py:222:26
(EngineCore_DP0 pid=394380) 	add.s32 	%r93, %r91, %r92;
(EngineCore_DP0 pid=394380) 	.loc	1 225 53                        // quant_slide_tuned_Llama3.2-3B.py:225:53
(EngineCore_DP0 pid=394380) 	setp.lt.s32 	%p18, %r91, %r19;
(EngineCore_DP0 pid=394380) 	setp.lt.s32 	%p19, %r93, %r19;
(EngineCore_DP0 pid=394380) 	.loc	1 225 37                        // quant_slide_tuned_Llama3.2-3B.py:225:37
(EngineCore_DP0 pid=394380) 	and.pred 	%p9, %p17, %p18;
(EngineCore_DP0 pid=394380) 	and.pred 	%p10, %p17, %p19;
(EngineCore_DP0 pid=394380) 	.loc	1 224 29                        // quant_slide_tuned_Llama3.2-3B.py:224:29
(EngineCore_DP0 pid=394380) 	mad.wide.s32 	%rd8, %r91, 2, %rd1;
(EngineCore_DP0 pid=394380) 	mad.wide.s32 	%rd9, %r93, 2, %rd1;
(EngineCore_DP0 pid=394380) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=394380) 	.loc	1 224 21                        // quant_slide_tuned_Llama3.2-3B.py:224:21
(EngineCore_DP0 pid=394380) 	// begin inline asm
(EngineCore_DP0 pid=394380) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=394380) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=394380) 	// end inline asm
(EngineCore_DP0 pid=394380) 	// begin inline asm
(EngineCore_DP0 pid=394380) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=394380) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=394380) 	// end inline asm
(EngineCore_DP0 pid=394380) 	.loc	1 225 79                        // quant_slide_tuned_Llama3.2-3B.py:225:79
(EngineCore_DP0 pid=394380) 	cvt.f32.bf16 	%r94, %rs24;
(EngineCore_DP0 pid=394380) 	cvt.f32.bf16 	%r95, %rs26;
(EngineCore_DP0 pid=394380) 	.loc	1 227 48                        // quant_slide_tuned_Llama3.2-3B.py:227:48
(EngineCore_DP0 pid=394380) 	or.b32 	%r96, %r91, 1;
(EngineCore_DP0 pid=394380) 	or.b32 	%r97, %r93, 1;
(EngineCore_DP0 pid=394380) 	.loc	1 227 53                        // quant_slide_tuned_Llama3.2-3B.py:227:53
(EngineCore_DP0 pid=394380) 	setp.lt.s32 	%p20, %r96, %r19;
(EngineCore_DP0 pid=394380) 	setp.lt.s32 	%p21, %r97, %r19;
(EngineCore_DP0 pid=394380) 	.loc	1 227 37                        // quant_slide_tuned_Llama3.2-3B.py:227:37
(EngineCore_DP0 pid=394380) 	and.pred 	%p11, %p17, %p20;
(EngineCore_DP0 pid=394380) 	and.pred 	%p12, %p17, %p21;
(EngineCore_DP0 pid=394380) 	.loc	1 226 39                        // quant_slide_tuned_Llama3.2-3B.py:226:39
(EngineCore_DP0 pid=394380) 	add.s64 	%rd10, %rd8, 2;
(EngineCore_DP0 pid=394380) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=394380) 	.loc	1 226 21                        // quant_slide_tuned_Llama3.2-3B.py:226:21
(EngineCore_DP0 pid=394380) 	// begin inline asm
(EngineCore_DP0 pid=394380) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=394380) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=394380) 	// end inline asm
(EngineCore_DP0 pid=394380) 	// begin inline asm
(EngineCore_DP0 pid=394380) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=394380) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=394380) 	// end inline asm
(EngineCore_DP0 pid=394380) 	.loc	1 227 79                        // quant_slide_tuned_Llama3.2-3B.py:227:79
(EngineCore_DP0 pid=394380) 	cvt.f32.bf16 	%r98, %rs28;
(EngineCore_DP0 pid=394380) 	cvt.f32.bf16 	%r99, %rs30;
(EngineCore_DP0 pid=394380) 	.loc	1 229 48                        // quant_slide_tuned_Llama3.2-3B.py:229:48
(EngineCore_DP0 pid=394380) 	add.s32 	%r100, %r91, 2;
(EngineCore_DP0 pid=394380) 	add.s32 	%r101, %r93, 2;
(EngineCore_DP0 pid=394380) 	.loc	1 229 53                        // quant_slide_tuned_Llama3.2-3B.py:229:53
(EngineCore_DP0 pid=394380) 	setp.lt.s32 	%p22, %r100, %r19;
(EngineCore_DP0 pid=394380) 	setp.lt.s32 	%p23, %r101, %r19;
(EngineCore_DP0 pid=394380) 	.loc	1 229 37                        // quant_slide_tuned_Llama3.2-3B.py:229:37
(EngineCore_DP0 pid=394380) 	and.pred 	%p13, %p17, %p22;
(EngineCore_DP0 pid=394380) 	and.pred 	%p14, %p17, %p23;
(EngineCore_DP0 pid=394380) 	.loc	1 228 39                        // quant_slide_tuned_Llama3.2-3B.py:228:39
(EngineCore_DP0 pid=394380) 	add.s64 	%rd12, %rd8, 4;
(EngineCore_DP0 pid=394380) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=394380) 	.loc	1 228 21                        // quant_slide_tuned_Llama3.2-3B.py:228:21
(EngineCore_DP0 pid=394380) 	// begin inline asm
(EngineCore_DP0 pid=394380) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=394380) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=394380) 	// end inline asm
(EngineCore_DP0 pid=394380) 	// begin inline asm
(EngineCore_DP0 pid=394380) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=394380) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=394380) 	// end inline asm
(EngineCore_DP0 pid=394380) 	.loc	1 229 79                        // quant_slide_tuned_Llama3.2-3B.py:229:79
(EngineCore_DP0 pid=394380) 	cvt.f32.bf16 	%r102, %rs32;
(EngineCore_DP0 pid=394380) 	cvt.f32.bf16 	%r103, %rs34;
(EngineCore_DP0 pid=394380) 	.loc	1 231 48                        // quant_slide_tuned_Llama3.2-3B.py:231:48
(EngineCore_DP0 pid=394380) 	add.s32 	%r104, %r91, 3;
(EngineCore_DP0 pid=394380) 	add.s32 	%r105, %r93, 3;
(EngineCore_DP0 pid=394380) 	.loc	1 231 53                        // quant_slide_tuned_Llama3.2-3B.py:231:53
(EngineCore_DP0 pid=394380) 	setp.lt.s32 	%p24, %r104, %r19;
(EngineCore_DP0 pid=394380) 	setp.lt.s32 	%p25, %r105, %r19;
(EngineCore_DP0 pid=394380) 	.loc	1 231 37                        // quant_slide_tuned_Llama3.2-3B.py:231:37
(EngineCore_DP0 pid=394380) 	and.pred 	%p15, %p17, %p24;
(EngineCore_DP0 pid=394380) 	and.pred 	%p16, %p17, %p25;
(EngineCore_DP0 pid=394380) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-3B.py:230:39
(EngineCore_DP0 pid=394380) 	add.s64 	%rd14, %rd8, 6;
(EngineCore_DP0 pid=394380) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=394380) 	.loc	1 230 21                        // quant_slide_tuned_Llama3.2-3B.py:230:21
(EngineCore_DP0 pid=394380) 	// begin inline asm
(EngineCore_DP0 pid=394380) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=394380) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=394380) 	// end inline asm
(EngineCore_DP0 pid=394380) 	// begin inline asm
(EngineCore_DP0 pid=394380) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=394380) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=394380) 	// end inline asm
(EngineCore_DP0 pid=394380) 	.loc	1 231 79                        // quant_slide_tuned_Llama3.2-3B.py:231:79
(EngineCore_DP0 pid=394380) 	cvt.f32.bf16 	%r106, %rs36;
(EngineCore_DP0 pid=394380) 	cvt.f32.bf16 	%r107, %rs38;
(EngineCore_DP0 pid=394380) 	.loc	1 233 27                        // quant_slide_tuned_Llama3.2-3B.py:233:27
(EngineCore_DP0 pid=394380) 	mul.f32 	%r108, %r14, %r94;
(EngineCore_DP0 pid=394380) 	mul.f32 	%r109, %r14, %r95;
(EngineCore_DP0 pid=394380) 	mov.b32 	%r110, 0f43E00000;
(EngineCore_DP0 pid=394380) 	.loc	1 233 48                        // quant_slide_tuned_Llama3.2-3B.py:233:48
(EngineCore_DP0 pid=394380) 	min.xorsign.abs.f32 	%r74, %r108, %r110;
(EngineCore_DP0 pid=394380) 	min.xorsign.abs.f32 	%r75, %r109, %r110;
(EngineCore_DP0 pid=394380) 	.loc	1 233 60                        // quant_slide_tuned_Llama3.2-3B.py:233:60
(EngineCore_DP0 pid=394380) 	// begin inline asm
(EngineCore_DP0 pid=394380) 	cvt.rn.satfinite.e4m3x2.f32  %rs40, %r75, %r74; 
(EngineCore_DP0 pid=394380) 
(EngineCore_DP0 pid=394380) 	// end inline asm
(EngineCore_DP0 pid=394380) 	shr.u16 	%rs44, %rs40, 8;
(EngineCore_DP0 pid=394380) 	.loc	1 234 27                        // quant_slide_tuned_Llama3.2-3B.py:234:27
(EngineCore_DP0 pid=394380) 	mul.f32 	%r111, %r14, %r98;
(EngineCore_DP0 pid=394380) 	mul.f32 	%r112, %r14, %r99;
(EngineCore_DP0 pid=394380) 	.loc	1 234 48                        // quant_slide_tuned_Llama3.2-3B.py:234:48
(EngineCore_DP0 pid=394380) 	min.xorsign.abs.f32 	%r76, %r111, %r110;
(EngineCore_DP0 pid=394380) 	min.xorsign.abs.f32 	%r77, %r112, %r110;
(EngineCore_DP0 pid=394380) 	.loc	1 234 60                        // quant_slide_tuned_Llama3.2-3B.py:234:60
(EngineCore_DP0 pid=394380) 	// begin inline asm
(EngineCore_DP0 pid=394380) 	cvt.rn.satfinite.e4m3x2.f32  %rs41, %r77, %r76; 
(EngineCore_DP0 pid=394380) 
(EngineCore_DP0 pid=394380) 	// end inline asm
(EngineCore_DP0 pid=394380) 	shr.u16 	%rs45, %rs41, 8;
(EngineCore_DP0 pid=394380) 	.loc	1 235 27                        // quant_slide_tuned_Llama3.2-3B.py:235:27
(EngineCore_DP0 pid=394380) 	mul.f32 	%r113, %r14, %r102;
(EngineCore_DP0 pid=394380) 	mul.f32 	%r114, %r14, %r103;
(EngineCore_DP0 pid=394380) 	.loc	1 235 48                        // quant_slide_tuned_Llama3.2-3B.py:235:48
(EngineCore_DP0 pid=394380) 	min.xorsign.abs.f32 	%r78, %r113, %r110;
(EngineCore_DP0 pid=394380) 	min.xorsign.abs.f32 	%r79, %r114, %r110;
(EngineCore_DP0 pid=394380) 	.loc	1 235 60                        // quant_slide_tuned_Llama3.2-3B.py:235:60
(EngineCore_DP0 pid=394380) 	// begin inline asm
(EngineCore_DP0 pid=394380) 	cvt.rn.satfinite.e4m3x2.f32  %rs42, %r79, %r78; 
(EngineCore_DP0 pid=394380) 
(EngineCore_DP0 pid=394380) 	// end inline asm
(EngineCore_DP0 pid=394380) 	shr.u16 	%rs46, %rs42, 8;
(EngineCore_DP0 pid=394380) 	.loc	1 236 27                        // quant_slide_tuned_Llama3.2-3B.py:236:27
(EngineCore_DP0 pid=394380) 	mul.f32 	%r115, %r14, %r106;
(EngineCore_DP0 pid=394380) 	mul.f32 	%r116, %r14, %r107;
(EngineCore_DP0 pid=394380) 	.loc	1 236 48                        // quant_slide_tuned_Llama3.2-3B.py:236:48
(EngineCore_DP0 pid=394380) 	min.xorsign.abs.f32 	%r80, %r115, %r110;
(EngineCore_DP0 pid=394380) 	min.xorsign.abs.f32 	%r81, %r116, %r110;
(EngineCore_DP0 pid=394380) 	.loc	1 236 60                        // quant_slide_tuned_Llama3.2-3B.py:236:60
(EngineCore_DP0 pid=394380) 	// begin inline asm
(EngineCore_DP0 pid=394380) 	cvt.rn.satfinite.e4m3x2.f32  %rs43, %r81, %r80; 
(EngineCore_DP0 pid=394380) 
(EngineCore_DP0 pid=394380) 	// end inline asm
(EngineCore_DP0 pid=394380) 	shr.u16 	%rs47, %rs43, 8;
(EngineCore_DP0 pid=394380) 	.loc	1 238 45                        // quant_slide_tuned_Llama3.2-3B.py:238:45
(EngineCore_DP0 pid=394380) 	cvt.u32.u16 	%r117, %rs40;
(EngineCore_DP0 pid=394380) 	and.b32 	%r118, %r117, 255;
(EngineCore_DP0 pid=394380) 	cvt.u32.u16 	%r119, %rs44;
(EngineCore_DP0 pid=394380) 	.loc	1 240 45                        // quant_slide_tuned_Llama3.2-3B.py:240:45
(EngineCore_DP0 pid=394380) 	cvt.u32.u16 	%r120, %rs42;
(EngineCore_DP0 pid=394380) 	and.b32 	%r121, %r120, 255;
(EngineCore_DP0 pid=394380) 	cvt.u32.u16 	%r122, %rs46;
(EngineCore_DP0 pid=394380) 	.loc	1 241 45                        // quant_slide_tuned_Llama3.2-3B.py:241:45
(EngineCore_DP0 pid=394380) 	cvt.u32.u16 	%r123, %rs43;
(EngineCore_DP0 pid=394380) 	cvt.u32.u16 	%r124, %rs47;
(EngineCore_DP0 pid=394380) 	.loc	1 243 30                        // quant_slide_tuned_Llama3.2-3B.py:243:30
(EngineCore_DP0 pid=394380) 	and.b16 	%rs48, %rs41, 255;
(EngineCore_DP0 pid=394380) 	mul.wide.u16 	%r125, %rs48, 256;
(EngineCore_DP0 pid=394380) 	mul.wide.u16 	%r126, %rs45, 256;
(EngineCore_DP0 pid=394380) 	.loc	1 243 24                        // quant_slide_tuned_Llama3.2-3B.py:243:24
(EngineCore_DP0 pid=394380) 	or.b32 	%r127, %r125, %r118;
(EngineCore_DP0 pid=394380) 	or.b32 	%r128, %r126, %r119;
(EngineCore_DP0 pid=394380) 	.loc	1 243 42                        // quant_slide_tuned_Llama3.2-3B.py:243:42
(EngineCore_DP0 pid=394380) 	shl.b32 	%r129, %r121, 16;
(EngineCore_DP0 pid=394380) 	shl.b32 	%r130, %r122, 16;
(EngineCore_DP0 pid=394380) 	.loc	1 243 36                        // quant_slide_tuned_Llama3.2-3B.py:243:36
(EngineCore_DP0 pid=394380) 	or.b32 	%r131, %r127, %r129;
(EngineCore_DP0 pid=394380) 	or.b32 	%r132, %r128, %r130;
(EngineCore_DP0 pid=394380) 	.loc	1 243 55                        // quant_slide_tuned_Llama3.2-3B.py:243:55
(EngineCore_DP0 pid=394380) 	shl.b32 	%r133, %r123, 24;
(EngineCore_DP0 pid=394380) 	shl.b32 	%r134, %r124, 24;
(EngineCore_DP0 pid=394380) 	.loc	1 243 49                        // quant_slide_tuned_Llama3.2-3B.py:243:49
(EngineCore_DP0 pid=394380) 	or.b32 	%r82, %r131, %r133;
(EngineCore_DP0 pid=394380) 	or.b32 	%r83, %r132, %r134;
(EngineCore_DP0 pid=394380) 	.loc	1 244 29                        // quant_slide_tuned_Llama3.2-3B.py:244:29
(EngineCore_DP0 pid=394380) 	mad.wide.s32 	%rd16, %r84, 4, %rd2;
(EngineCore_DP0 pid=394380) 	.loc	1 244 39                        // quant_slide_tuned_Llama3.2-3B.py:244:39
(EngineCore_DP0 pid=394380) 	// begin inline asm
(EngineCore_DP0 pid=394380) 	@%p17 st.global.v2.b32 [ %rd16 + 0 ], { %r82, %r83 };
(EngineCore_DP0 pid=394380) 	// end inline asm
(EngineCore_DP0 pid=394380) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=394380) 	add.s32 	%r138, %r138, 1024;
(EngineCore_DP0 pid=394380) 	setp.lt.s32 	%p26, %r138, %r15;
(EngineCore_DP0 pid=394380) 	@%p26 bra 	$L__BB0_6;
(EngineCore_DP0 pid=394380) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=394380) 	.loc	1 215 4                         // quant_slide_tuned_Llama3.2-3B.py:215:4
(EngineCore_DP0 pid=394380) 	ret;
(EngineCore_DP0 pid=394380) $L__tmp3:
(EngineCore_DP0 pid=394380) $L__func_end0:
(EngineCore_DP0 pid=394380)                                         // -- End function
(EngineCore_DP0 pid=394380) }
(EngineCore_DP0 pid=394380) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py"
(EngineCore_DP0 pid=394380) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=394380) 	.section	.debug_abbrev
(EngineCore_DP0 pid=394380) 	{
(EngineCore_DP0 pid=394380) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=394380) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=394380) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=394380) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=394380) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=394380) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=394380) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=394380) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=394380) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=394380) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=394380) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=394380) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=394380) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=394380) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=394380) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=394380) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=394380) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=394380) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=394380) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=394380) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=394380) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=394380) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=394380) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=394380) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=394380) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=394380) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=394380) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=394380) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=394380) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=394380) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=394380) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=394380) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=394380) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=394380) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=394380) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=394380) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=394380) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=394380) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=394380) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=394380) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=394380) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=394380) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=394380) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=394380) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=394380) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=394380) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=394380) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=394380) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=394380) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=394380) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=394380) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=394380) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=394380) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=394380) 	}
(EngineCore_DP0 pid=394380) 	.section	.debug_info
(EngineCore_DP0 pid=394380) 	{
(EngineCore_DP0 pid=394380) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=394380) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=394380) .b8 0
(EngineCore_DP0 pid=394380) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=394380) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=394380) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=394380) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=394380) .b8 114
(EngineCore_DP0 pid=394380) .b8 105
(EngineCore_DP0 pid=394380) .b8 116
(EngineCore_DP0 pid=394380) .b8 111
(EngineCore_DP0 pid=394380) .b8 110
(EngineCore_DP0 pid=394380) .b8 0
(EngineCore_DP0 pid=394380) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=394380) .b8 0
(EngineCore_DP0 pid=394380) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=394380) .b8 117
(EngineCore_DP0 pid=394380) .b8 97
(EngineCore_DP0 pid=394380) .b8 110
(EngineCore_DP0 pid=394380) .b8 116
(EngineCore_DP0 pid=394380) .b8 95
(EngineCore_DP0 pid=394380) .b8 115
(EngineCore_DP0 pid=394380) .b8 108
(EngineCore_DP0 pid=394380) .b8 105
(EngineCore_DP0 pid=394380) .b8 100
(EngineCore_DP0 pid=394380) .b8 101
(EngineCore_DP0 pid=394380) .b8 95
(EngineCore_DP0 pid=394380) .b8 116
(EngineCore_DP0 pid=394380) .b8 117
(EngineCore_DP0 pid=394380) .b8 110
(EngineCore_DP0 pid=394380) .b8 101
(EngineCore_DP0 pid=394380) .b8 100
(EngineCore_DP0 pid=394380) .b8 95
(EngineCore_DP0 pid=394380) .b8 76
(EngineCore_DP0 pid=394380) .b8 108
(EngineCore_DP0 pid=394380) .b8 97
(EngineCore_DP0 pid=394380) .b8 109
(EngineCore_DP0 pid=394380) .b8 97
(EngineCore_DP0 pid=394380) .b8 51
(EngineCore_DP0 pid=394380) .b8 46
(EngineCore_DP0 pid=394380) .b8 50
(EngineCore_DP0 pid=394380) .b8 45
(EngineCore_DP0 pid=394380) .b8 51
(EngineCore_DP0 pid=394380) .b8 66
(EngineCore_DP0 pid=394380) .b8 46
(EngineCore_DP0 pid=394380) .b8 112
(EngineCore_DP0 pid=394380) .b8 121
(EngineCore_DP0 pid=394380) .b8 0
(EngineCore_DP0 pid=394380) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=394380) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=394380) .b8 114
(EngineCore_DP0 pid=394380) .b8 111
(EngineCore_DP0 pid=394380) .b8 111
(EngineCore_DP0 pid=394380) .b8 116
(EngineCore_DP0 pid=394380) .b8 47
(EngineCore_DP0 pid=394380) .b8 118
(EngineCore_DP0 pid=394380) .b8 108
(EngineCore_DP0 pid=394380) .b8 108
(EngineCore_DP0 pid=394380) .b8 109
(EngineCore_DP0 pid=394380) .b8 98
(EngineCore_DP0 pid=394380) .b8 101
(EngineCore_DP0 pid=394380) .b8 110
(EngineCore_DP0 pid=394380) .b8 99
(EngineCore_DP0 pid=394380) .b8 104
(EngineCore_DP0 pid=394380) .b8 47
(EngineCore_DP0 pid=394380) .b8 115
(EngineCore_DP0 pid=394380) .b8 108
(EngineCore_DP0 pid=394380) .b8 105
(EngineCore_DP0 pid=394380) .b8 100
(EngineCore_DP0 pid=394380) .b8 101
(EngineCore_DP0 pid=394380) .b8 115
(EngineCore_DP0 pid=394380) .b8 112
(EngineCore_DP0 pid=394380) .b8 97
(EngineCore_DP0 pid=394380) .b8 114
(EngineCore_DP0 pid=394380) .b8 115
(EngineCore_DP0 pid=394380) .b8 101
(EngineCore_DP0 pid=394380) .b8 47
(EngineCore_DP0 pid=394380) .b8 99
(EngineCore_DP0 pid=394380) .b8 115
(EngineCore_DP0 pid=394380) .b8 114
(EngineCore_DP0 pid=394380) .b8 99
(EngineCore_DP0 pid=394380) .b8 47
(EngineCore_DP0 pid=394380) .b8 102
(EngineCore_DP0 pid=394380) .b8 117
(EngineCore_DP0 pid=394380) .b8 115
(EngineCore_DP0 pid=394380) .b8 101
(EngineCore_DP0 pid=394380) .b8 100
(EngineCore_DP0 pid=394380) .b8 95
(EngineCore_DP0 pid=394380) .b8 113
(EngineCore_DP0 pid=394380) .b8 117
(EngineCore_DP0 pid=394380) .b8 97
(EngineCore_DP0 pid=394380) .b8 110
(EngineCore_DP0 pid=394380) .b8 116
(EngineCore_DP0 pid=394380) .b8 95
(EngineCore_DP0 pid=394380) .b8 115
(EngineCore_DP0 pid=394380) .b8 108
(EngineCore_DP0 pid=394380) .b8 105
(EngineCore_DP0 pid=394380) .b8 100
(EngineCore_DP0 pid=394380) .b8 101
(EngineCore_DP0 pid=394380) .b8 95
(EngineCore_DP0 pid=394380) .b8 116
(EngineCore_DP0 pid=394380) .b8 114
(EngineCore_DP0 pid=394380) .b8 105
(EngineCore_DP0 pid=394380) .b8 116
(EngineCore_DP0 pid=394380) .b8 111
(EngineCore_DP0 pid=394380) .b8 110
(EngineCore_DP0 pid=394380) .b8 47
(EngineCore_DP0 pid=394380) .b8 98
(EngineCore_DP0 pid=394380) .b8 117
(EngineCore_DP0 pid=394380) .b8 105
(EngineCore_DP0 pid=394380) .b8 108
(EngineCore_DP0 pid=394380) .b8 100
(EngineCore_DP0 pid=394380) .b8 47
(EngineCore_DP0 pid=394380) .b8 71
(EngineCore_DP0 pid=394380) .b8 66
(EngineCore_DP0 pid=394380) .b8 49
(EngineCore_DP0 pid=394380) .b8 48
(EngineCore_DP0 pid=394380) .b8 95
(EngineCore_DP0 pid=394380) .b8 99
(EngineCore_DP0 pid=394380) .b8 99
(EngineCore_DP0 pid=394380) .b8 49
(EngineCore_DP0 pid=394380) .b8 50
(EngineCore_DP0 pid=394380) .b8 49
(EngineCore_DP0 pid=394380) .b8 95
(EngineCore_DP0 pid=394380) .b8 112
(EngineCore_DP0 pid=394380) .b8 121
(EngineCore_DP0 pid=394380) .b8 51
(EngineCore_DP0 pid=394380) .b8 49
(EngineCore_DP0 pid=394380) .b8 50
(EngineCore_DP0 pid=394380) .b8 95
(EngineCore_DP0 pid=394380) .b8 99
(EngineCore_DP0 pid=394380) .b8 117
(EngineCore_DP0 pid=394380) .b8 49
(EngineCore_DP0 pid=394380) .b8 50
(EngineCore_DP0 pid=394380) .b8 57
(EngineCore_DP0 pid=394380) .b8 95
(EngineCore_DP0 pid=394380) .b8 97
(EngineCore_DP0 pid=394380) .b8 97
(EngineCore_DP0 pid=394380) .b8 114
(EngineCore_DP0 pid=394380) .b8 99
(EngineCore_DP0 pid=394380) .b8 104
(EngineCore_DP0 pid=394380) .b8 54
(EngineCore_DP0 pid=394380) .b8 52
(EngineCore_DP0 pid=394380) .b8 0
(EngineCore_DP0 pid=394380) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=394380) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=394380) .b8 113
(EngineCore_DP0 pid=394380) .b8 117
(EngineCore_DP0 pid=394380) .b8 97
(EngineCore_DP0 pid=394380) .b8 110
(EngineCore_DP0 pid=394380) .b8 116
(EngineCore_DP0 pid=394380) .b8 95
(EngineCore_DP0 pid=394380) .b8 115
(EngineCore_DP0 pid=394380) .b8 108
(EngineCore_DP0 pid=394380) .b8 105
(EngineCore_DP0 pid=394380) .b8 100
(EngineCore_DP0 pid=394380) .b8 101
(EngineCore_DP0 pid=394380) .b8 95
(EngineCore_DP0 pid=394380) .b8 102
(EngineCore_DP0 pid=394380) .b8 112
(EngineCore_DP0 pid=394380) .b8 56
(EngineCore_DP0 pid=394380) .b8 95
(EngineCore_DP0 pid=394380) .b8 107
(EngineCore_DP0 pid=394380) .b8 101
(EngineCore_DP0 pid=394380) .b8 114
(EngineCore_DP0 pid=394380) .b8 110
(EngineCore_DP0 pid=394380) .b8 101
(EngineCore_DP0 pid=394380) .b8 108
(EngineCore_DP0 pid=394380) .b8 0
(EngineCore_DP0 pid=394380) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=394380) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=394380) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=394380) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=394380) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=394380) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=394380) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=394380) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=394380) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=394380) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=394380) .b8 205                                 // DW_AT_call_line
(EngineCore_DP0 pid=394380) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=394380) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=394380) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=394380) 	}
(EngineCore_DP0 pid=394380) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=394380) 
(EngineCore_DP0 pid=394380) ================================================================
(EngineCore_DP0 pid=394380) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=394380) 
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp3g2udyaw.ptx', '-o', '/tmp/tmp3g2udyaw.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866] 
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866] 
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866] 
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp3g2udyaw.ptx -o /tmp/tmp3g2udyaw.ptx.o
(EngineCore_DP0 pid=394380) ERROR 01-25 20:06:29 [core.py:866] 

STDERR:
[2026-01-25 20:06:03] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:06:03] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:06:03] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:06:03] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:06:03] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:06:03] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:06:03] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:06:03] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:06:03] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:06:03] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:06:03] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:06:03] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:06:03] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:06:03] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:06:06] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:06:06] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:06:06] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:06:06] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:06:06] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:06:06] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:06:06] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:06:06] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:06:06] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:06:06] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:06:06] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:06:06] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:06:06] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:06:06] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=394380) [2026-01-25 20:06:07] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=394380) [2026-01-25 20:06:07] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=394380) [2026-01-25 20:06:07] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=394380) [2026-01-25 20:06:07] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=394380) [2026-01-25 20:06:07] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=394380) [2026-01-25 20:06:07] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=394380) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=394380) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:20<00:00, 20.47s/it]
(EngineCore_DP0 pid=394380) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:20<00:00, 20.47s/it]
(EngineCore_DP0 pid=394380) 
(EngineCore_DP0 pid=394380) [2026-01-25 20:06:28] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4096] -> 1D uint8
(EngineCore_DP0 pid=394380) [2026-01-25 20:06:28] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 13107200 bytes
(EngineCore_DP0 pid=394380) [2026-01-25 20:06:28] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4096] -> 1D uint8
(EngineCore_DP0 pid=394380) [2026-01-25 20:06:28] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 7864320 bytes
(EngineCore_DP0 pid=394380) [2026-01-25 20:06:28] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4096] -> 1D uint8
(EngineCore_DP0 pid=394380) [2026-01-25 20:06:28] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 41943040 bytes
(EngineCore_DP0 pid=394380) [2026-01-25 20:06:28] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 10944] -> 1D uint8
(EngineCore_DP0 pid=394380) [2026-01-25 20:06:28] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 21037056 bytes
(EngineCore_DP0 pid=394380) Process EngineCore_DP0:
(EngineCore_DP0 pid=394380) Traceback (most recent call last):
(EngineCore_DP0 pid=394380)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=394380)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=394380)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=394380)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=394380) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp3g2udyaw.ptx', '-o', '/tmp/tmp3g2udyaw.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=394380) 
(EngineCore_DP0 pid=394380) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=394380) 
(EngineCore_DP0 pid=394380) Traceback (most recent call last):
(EngineCore_DP0 pid=394380)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=394380)     self.run()
(EngineCore_DP0 pid=394380)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=394380)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=394380)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=394380)     raise e
(EngineCore_DP0 pid=394380)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=394380)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=394380)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=394380)     super().__init__(
(EngineCore_DP0 pid=394380)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=394380)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=394380)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=394380)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=394380)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=394380)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=394380)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=394380)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=394380)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=394380)     return func(*args, **kwargs)
(EngineCore_DP0 pid=394380)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=394380)     return func(*args, **kwargs)
(EngineCore_DP0 pid=394380)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=394380)     self.model_runner.profile_run()
(EngineCore_DP0 pid=394380)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=394380)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=394380)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=394380)     return func(*args, **kwargs)
(EngineCore_DP0 pid=394380)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=394380)     outputs = self.model(
(EngineCore_DP0 pid=394380)               ^^^^^^^^^^^
(EngineCore_DP0 pid=394380)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=394380)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=394380)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=394380)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=394380)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=394380)     model_output = self.model(
(EngineCore_DP0 pid=394380)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=394380)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=394380)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=394380)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=394380)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=394380)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=394380)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=394380)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=394380)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=394380)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=394380)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=394380)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=394380)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=394380)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=394380)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=394380)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=394380)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=394380)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=394380)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=394380)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=394380)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=394380)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=394380)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=394380)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=394380)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=394380)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=394380)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=394380)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=394380)     return self._linear_fn(
(EngineCore_DP0 pid=394380)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=394380)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=394380)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=394380)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=394380)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=394380)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=394380)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=394380)     return fn(input, L)
(EngineCore_DP0 pid=394380)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=394380)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=394380)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=394380)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=394380)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=394380)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=394380)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=394380)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=394380)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=394380)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=394380)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=394380)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=394380)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=394380)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=394380)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=394380)     raise PTXASError(error)
(EngineCore_DP0 pid=394380) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=394380) `ptxas` stderr:
(EngineCore_DP0 pid=394380) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=394380) 
(EngineCore_DP0 pid=394380) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp3g2udyaw.ptx -o /tmp/tmp3g2udyaw.ptx.o
(EngineCore_DP0 pid=394380) 
[rank0]:[W125 20:06:30.416298419 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=4096

========== M=8192 ==========
Time: 2026-01-25 20:06:31
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-3B-FP8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:06:38 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 20:06:38 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=395059) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=395059) 
(EngineCore_DP0 pid=395059) 
(EngineCore_DP0 pid=395059) ================================================================
(EngineCore_DP0 pid=395059) Internal Triton PTX codegen error
(EngineCore_DP0 pid=395059) `ptxas` stderr:
(EngineCore_DP0 pid=395059) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=395059) 
(EngineCore_DP0 pid=395059) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp8acljiy7.ptx -o /tmp/tmp8acljiy7.ptx.o
(EngineCore_DP0 pid=395059) 
(EngineCore_DP0 pid=395059) 
(EngineCore_DP0 pid=395059) //
(EngineCore_DP0 pid=395059) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=395059) //
(EngineCore_DP0 pid=395059) 
(EngineCore_DP0 pid=395059) .version 8.7
(EngineCore_DP0 pid=395059) .target sm_121a
(EngineCore_DP0 pid=395059) .address_size 64
(EngineCore_DP0 pid=395059) 
(EngineCore_DP0 pid=395059) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=395059) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=395059)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=395059) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=395059) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=395059) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=395059) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=395059) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=395059) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=395059) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=395059) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=395059) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=395059) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=395059) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=395059) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=395059) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=395059) )
(EngineCore_DP0 pid=395059) .reqntid 512
(EngineCore_DP0 pid=395059) {
(EngineCore_DP0 pid=395059) 	.reg .pred 	%p<29>;
(EngineCore_DP0 pid=395059) 	.reg .b16 	%rs<73>;
(EngineCore_DP0 pid=395059) 	.reg .b32 	%r<148>;
(EngineCore_DP0 pid=395059) 	.reg .b64 	%rd<18>;
(EngineCore_DP0 pid=395059) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=395059) $L__func_begin0:
(EngineCore_DP0 pid=395059) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=395059) 
(EngineCore_DP0 pid=395059) // %bb.0:
(EngineCore_DP0 pid=395059) 	ld.param.b32 	%r21, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=395059) 	ld.param.b32 	%r20, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=395059) 	ld.param.b32 	%r19, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=395059) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=395059) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=395059) $L__tmp0:
(EngineCore_DP0 pid=395059) 	.loc	1 191 24                        // quant_slide_tuned_Llama3.2-3B.py:191:24
(EngineCore_DP0 pid=395059) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=395059) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=395059) 	.loc	1 196 26                        // quant_slide_tuned_Llama3.2-3B.py:196:26
(EngineCore_DP0 pid=395059) 	mul.lo.s32 	%r24, %r23, %r1;
(EngineCore_DP0 pid=395059) 	.loc	1 196 20                        // quant_slide_tuned_Llama3.2-3B.py:196:20
(EngineCore_DP0 pid=395059) 	mad.wide.s32 	%rd1, %r24, 2, %rd4;
(EngineCore_DP0 pid=395059) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=395059) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=395059) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=395059) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=395059) 	setp.lt.s32 	%p1, %r20, 1;
(EngineCore_DP0 pid=395059) 	mov.b32 	%r146, 0f2B8CBCCC;
(EngineCore_DP0 pid=395059) 	setp.eq.b32 	%p28, %r2, 0;
(EngineCore_DP0 pid=395059) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=395059) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=395059) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=395059) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=395059) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=395059) 	shr.u32 	%r33, %r2, 3;
(EngineCore_DP0 pid=395059) 	and.b32 	%r34, %r33, 60;
(EngineCore_DP0 pid=395059) 	mov.b32 	%r35, global_smem;
(EngineCore_DP0 pid=395059) 	add.s32 	%r53, %r35, %r34;
(EngineCore_DP0 pid=395059) 	shl.b32 	%r36, %r2, 2;
(EngineCore_DP0 pid=395059) 	add.s32 	%r56, %r35, %r36;
(EngineCore_DP0 pid=395059) 	mov.b32 	%r41, 0;
(EngineCore_DP0 pid=395059) 	mov.b32 	%r144, 0f00000000;
(EngineCore_DP0 pid=395059) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=395059) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=395059) 	mov.b32 	%r145, %r41;
(EngineCore_DP0 pid=395059) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=395059) 	.loc	1 202 19                        // quant_slide_tuned_Llama3.2-3B.py:202:19
(EngineCore_DP0 pid=395059) 	add.s32 	%r59, %r4, %r145;
(EngineCore_DP0 pid=395059) 	.loc	1 203 22                        // quant_slide_tuned_Llama3.2-3B.py:203:22
(EngineCore_DP0 pid=395059) 	add.s32 	%r60, %r59, 4096;
(EngineCore_DP0 pid=395059) 	setp.lt.s32 	%p2, %r59, %r19;
(EngineCore_DP0 pid=395059) 	setp.lt.s32 	%p3, %r60, %r19;
(EngineCore_DP0 pid=395059) 	.loc	1 204 29                        // quant_slide_tuned_Llama3.2-3B.py:204:29
(EngineCore_DP0 pid=395059) 	mad.wide.s32 	%rd6, %r59, 2, %rd1;
(EngineCore_DP0 pid=395059) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=395059) 	.loc	1 204 21                        // quant_slide_tuned_Llama3.2-3B.py:204:21
(EngineCore_DP0 pid=395059) 	// begin inline asm
(EngineCore_DP0 pid=395059) 	mov.u32 %r37, %r41;
(EngineCore_DP0 pid=395059) 	mov.u32 %r38, %r41;
(EngineCore_DP0 pid=395059) 	mov.u32 %r39, %r41;
(EngineCore_DP0 pid=395059) 	mov.u32 %r40, %r41;
(EngineCore_DP0 pid=395059) 	@%p2 ld.global.v4.b32 { %r37, %r38, %r39, %r40 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=395059) 	// end inline asm
(EngineCore_DP0 pid=395059) 	mov.b32 	{%rs1, %rs2}, %r37;
(EngineCore_DP0 pid=395059) 	mov.b32 	{%rs3, %rs4}, %r38;
(EngineCore_DP0 pid=395059) 	mov.b32 	{%rs5, %rs6}, %r39;
(EngineCore_DP0 pid=395059) 	mov.b32 	{%rs7, %rs8}, %r40;
(EngineCore_DP0 pid=395059) 	// begin inline asm
(EngineCore_DP0 pid=395059) 	mov.u32 %r45, %r41;
(EngineCore_DP0 pid=395059) 	mov.u32 %r46, %r41;
(EngineCore_DP0 pid=395059) 	mov.u32 %r47, %r41;
(EngineCore_DP0 pid=395059) 	mov.u32 %r48, %r41;
(EngineCore_DP0 pid=395059) 	@%p3 ld.global.v4.b32 { %r45, %r46, %r47, %r48 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=395059) 	// end inline asm
(EngineCore_DP0 pid=395059) 	mov.b32 	{%rs9, %rs10}, %r45;
(EngineCore_DP0 pid=395059) 	mov.b32 	{%rs11, %rs12}, %r46;
(EngineCore_DP0 pid=395059) 	mov.b32 	{%rs13, %rs14}, %r47;
(EngineCore_DP0 pid=395059) 	mov.b32 	{%rs15, %rs16}, %r48;
(EngineCore_DP0 pid=395059) 	.loc	1 205 50                        // quant_slide_tuned_Llama3.2-3B.py:205:50
(EngineCore_DP0 pid=395059) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=395059) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=395059) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=395059) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=395059) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=395059) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=395059) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=395059) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=395059) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=395059) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=395059) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=395059) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=395059) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=395059) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=395059) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=395059) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=395059) $L__tmp1:
(EngineCore_DP0 pid=395059) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=395059) 	bar.sync 	0;
(EngineCore_DP0 pid=395059) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=395059) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=395059) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=395059) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=395059) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=395059) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=395059) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=395059) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=395059) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=395059) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=395059) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=395059) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=395059) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=395059) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=395059) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=395059) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=395059) 	cvt.f32.bf16 	%r61, %rs47;
(EngineCore_DP0 pid=395059) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=395059) 	shfl.sync.bfly.b32 	%r62, %r61, 16, 31, -1;
(EngineCore_DP0 pid=395059) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=395059) 	max.f32 	%r63, %r61, %r62;
(EngineCore_DP0 pid=395059) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=395059) 	shfl.sync.bfly.b32 	%r64, %r63, 8, 31, -1;
(EngineCore_DP0 pid=395059) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=395059) 	max.f32 	%r65, %r63, %r64;
(EngineCore_DP0 pid=395059) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=395059) 	shfl.sync.bfly.b32 	%r66, %r65, 4, 31, -1;
(EngineCore_DP0 pid=395059) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=395059) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=395059) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=395059) 	shfl.sync.bfly.b32 	%r68, %r67, 2, 31, -1;
(EngineCore_DP0 pid=395059) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=395059) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=395059) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=395059) 	shfl.sync.bfly.b32 	%r70, %r69, 1, 31, -1;
(EngineCore_DP0 pid=395059) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=395059) 	max.f32 	%r54, %r69, %r70;
(EngineCore_DP0 pid=395059) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=395059) 	// begin inline asm
(EngineCore_DP0 pid=395059) 	@%p4 st.shared.b32 [ %r53 + 0 ], %r54;
(EngineCore_DP0 pid=395059) 	// end inline asm
(EngineCore_DP0 pid=395059) 	bar.sync 	0;
(EngineCore_DP0 pid=395059) 	// begin inline asm
(EngineCore_DP0 pid=395059) 	@%p5 ld.shared.b32 %r55, [ %r56 + 0 ];
(EngineCore_DP0 pid=395059) 	// end inline asm
(EngineCore_DP0 pid=395059) 	shfl.sync.bfly.b32 	%r71, %r55, 8, 31, -1;
(EngineCore_DP0 pid=395059) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=395059) 	max.f32 	%r72, %r55, %r71;
(EngineCore_DP0 pid=395059) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=395059) 	shfl.sync.bfly.b32 	%r73, %r72, 4, 31, -1;
(EngineCore_DP0 pid=395059) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=395059) 	max.f32 	%r74, %r72, %r73;
(EngineCore_DP0 pid=395059) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=395059) 	shfl.sync.bfly.b32 	%r75, %r74, 2, 31, -1;
(EngineCore_DP0 pid=395059) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=395059) 	max.f32 	%r76, %r74, %r75;
(EngineCore_DP0 pid=395059) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=395059) 	shfl.sync.bfly.b32 	%r77, %r76, 1, 31, -1;
(EngineCore_DP0 pid=395059) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=395059) 	max.f32 	%r58, %r76, %r77;
(EngineCore_DP0 pid=395059) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=395059) 	// begin inline asm
(EngineCore_DP0 pid=395059) 	@%p28 st.shared.b32 [ %r56 + 0 ], %r58;
(EngineCore_DP0 pid=395059) 	// end inline asm
(EngineCore_DP0 pid=395059) 	bar.sync 	0;
(EngineCore_DP0 pid=395059) 	ld.shared.b32 	%r78, [global_smem];
(EngineCore_DP0 pid=395059) $L__tmp2:
(EngineCore_DP0 pid=395059) 	.loc	1 205 36                        // quant_slide_tuned_Llama3.2-3B.py:205:36
(EngineCore_DP0 pid=395059) 	max.f32 	%r144, %r144, %r78;
(EngineCore_DP0 pid=395059) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=395059) 	add.s32 	%r145, %r145, 8192;
(EngineCore_DP0 pid=395059) 	setp.lt.s32 	%p7, %r145, %r20;
(EngineCore_DP0 pid=395059) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=395059) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=395059) 	.loc	1 207 32                        // quant_slide_tuned_Llama3.2-3B.py:207:32
(EngineCore_DP0 pid=395059) 	max.f32 	%r146, %r144, 0f2B8CBCCC;
(EngineCore_DP0 pid=395059) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=395059) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-3B.py:0:32
(EngineCore_DP0 pid=395059) 	mov.b32 	%r80, 0f43E00000;
(EngineCore_DP0 pid=395059) 	.loc	1 208 32                        // quant_slide_tuned_Llama3.2-3B.py:208:32
(EngineCore_DP0 pid=395059) 	div.full.f32 	%r81, %r146, %r80;
(EngineCore_DP0 pid=395059) 	.loc	1 208 41                        // quant_slide_tuned_Llama3.2-3B.py:208:41
(EngineCore_DP0 pid=395059) 	max.f32 	%r79, %r81, 0f36924925;
(EngineCore_DP0 pid=395059) 	.loc	1 210 25                        // quant_slide_tuned_Llama3.2-3B.py:210:25
(EngineCore_DP0 pid=395059) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=395059) 	.loc	1 210 30                        // quant_slide_tuned_Llama3.2-3B.py:210:30
(EngineCore_DP0 pid=395059) 	// begin inline asm
(EngineCore_DP0 pid=395059) 	@%p28 st.global.b32 [ %rd8 + 0 ], { %r79 };
(EngineCore_DP0 pid=395059) 	// end inline asm
(EngineCore_DP0 pid=395059) 	.loc	1 213 29                        // quant_slide_tuned_Llama3.2-3B.py:213:29
(EngineCore_DP0 pid=395059) 	shl.b32 	%r15, %r21, 1;
(EngineCore_DP0 pid=395059) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=395059) 	setp.lt.s32 	%p9, %r15, 1;
(EngineCore_DP0 pid=395059) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=395059) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=395059) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-3B.py:0:41
(EngineCore_DP0 pid=395059) 	ld.param.b32 	%r25, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=395059) 	shr.s32 	%r26, %r25, 31;
(EngineCore_DP0 pid=395059) 	shr.u32 	%r27, %r26, 30;
(EngineCore_DP0 pid=395059) 	add.s32 	%r28, %r25, %r27;
(EngineCore_DP0 pid=395059) 	shr.s32 	%r29, %r28, 2;
(EngineCore_DP0 pid=395059) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=395059) 	mul.lo.s32 	%r30, %r29, %r1;
(EngineCore_DP0 pid=395059) 	mad.wide.s32 	%rd2, %r30, 4, %rd5;
(EngineCore_DP0 pid=395059) 	div.full.f32 	%r14, %r80, %r146;
(EngineCore_DP0 pid=395059) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=395059) 	mov.b32 	%r147, 0;
(EngineCore_DP0 pid=395059) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=395059)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=395059) 	.loc	1 216 31                        // quant_slide_tuned_Llama3.2-3B.py:216:31
(EngineCore_DP0 pid=395059) 	add.s32 	%r93, %r16, %r147;
(EngineCore_DP0 pid=395059) 	.loc	1 217 30                        // quant_slide_tuned_Llama3.2-3B.py:217:30
(EngineCore_DP0 pid=395059) 	add.s32 	%r94, %r147, 1;
(EngineCore_DP0 pid=395059) 	setp.lt.s32 	%p18, %r93, %r15;
(EngineCore_DP0 pid=395059) 	.loc	1 220 24                        // quant_slide_tuned_Llama3.2-3B.py:220:24
(EngineCore_DP0 pid=395059) 	shr.u32 	%r95, %r93, 1;
(EngineCore_DP0 pid=395059) 	.loc	1 221 23                        // quant_slide_tuned_Llama3.2-3B.py:221:23
(EngineCore_DP0 pid=395059) 	shr.u32 	%r96, %r94, 31;
(EngineCore_DP0 pid=395059) 	add.s32 	%r97, %r94, %r96;
(EngineCore_DP0 pid=395059) 	and.b32 	%r98, %r97, 2147483646;
(EngineCore_DP0 pid=395059) 	sub.s32 	%r99, %r94, %r98;
(EngineCore_DP0 pid=395059) 	.loc	1 222 22                        // quant_slide_tuned_Llama3.2-3B.py:222:22
(EngineCore_DP0 pid=395059) 	mul.lo.s32 	%r100, %r95, 6;
(EngineCore_DP0 pid=395059) 	.loc	1 222 30                        // quant_slide_tuned_Llama3.2-3B.py:222:30
(EngineCore_DP0 pid=395059) 	shl.b32 	%r101, %r99, 1;
(EngineCore_DP0 pid=395059) 	.loc	1 222 26                        // quant_slide_tuned_Llama3.2-3B.py:222:26
(EngineCore_DP0 pid=395059) 	add.s32 	%r102, %r100, %r101;
(EngineCore_DP0 pid=395059) 	.loc	1 225 53                        // quant_slide_tuned_Llama3.2-3B.py:225:53
(EngineCore_DP0 pid=395059) 	setp.lt.s32 	%p19, %r100, %r19;
(EngineCore_DP0 pid=395059) 	setp.lt.s32 	%p20, %r102, %r19;
(EngineCore_DP0 pid=395059) 	.loc	1 225 37                        // quant_slide_tuned_Llama3.2-3B.py:225:37
(EngineCore_DP0 pid=395059) 	and.pred 	%p10, %p18, %p19;
(EngineCore_DP0 pid=395059) 	and.pred 	%p11, %p18, %p20;
(EngineCore_DP0 pid=395059) 	.loc	1 224 29                        // quant_slide_tuned_Llama3.2-3B.py:224:29
(EngineCore_DP0 pid=395059) 	mad.wide.s32 	%rd9, %r100, 2, %rd1;
(EngineCore_DP0 pid=395059) 	mad.wide.s32 	%rd10, %r102, 2, %rd1;
(EngineCore_DP0 pid=395059) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=395059) 	.loc	1 224 21                        // quant_slide_tuned_Llama3.2-3B.py:224:21
(EngineCore_DP0 pid=395059) 	// begin inline asm
(EngineCore_DP0 pid=395059) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=395059) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=395059) 	// end inline asm
(EngineCore_DP0 pid=395059) 	// begin inline asm
(EngineCore_DP0 pid=395059) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=395059) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=395059) 	// end inline asm
(EngineCore_DP0 pid=395059) 	.loc	1 225 79                        // quant_slide_tuned_Llama3.2-3B.py:225:79
(EngineCore_DP0 pid=395059) 	cvt.f32.bf16 	%r103, %rs48;
(EngineCore_DP0 pid=395059) 	cvt.f32.bf16 	%r104, %rs50;
(EngineCore_DP0 pid=395059) 	.loc	1 227 48                        // quant_slide_tuned_Llama3.2-3B.py:227:48
(EngineCore_DP0 pid=395059) 	or.b32 	%r105, %r100, 1;
(EngineCore_DP0 pid=395059) 	or.b32 	%r106, %r102, 1;
(EngineCore_DP0 pid=395059) 	.loc	1 227 53                        // quant_slide_tuned_Llama3.2-3B.py:227:53
(EngineCore_DP0 pid=395059) 	setp.lt.s32 	%p21, %r105, %r19;
(EngineCore_DP0 pid=395059) 	setp.lt.s32 	%p22, %r106, %r19;
(EngineCore_DP0 pid=395059) 	.loc	1 227 37                        // quant_slide_tuned_Llama3.2-3B.py:227:37
(EngineCore_DP0 pid=395059) 	and.pred 	%p12, %p18, %p21;
(EngineCore_DP0 pid=395059) 	and.pred 	%p13, %p18, %p22;
(EngineCore_DP0 pid=395059) 	.loc	1 226 39                        // quant_slide_tuned_Llama3.2-3B.py:226:39
(EngineCore_DP0 pid=395059) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=395059) 	add.s64 	%rd12, %rd10, 2;
(EngineCore_DP0 pid=395059) 	.loc	1 226 21                        // quant_slide_tuned_Llama3.2-3B.py:226:21
(EngineCore_DP0 pid=395059) 	// begin inline asm
(EngineCore_DP0 pid=395059) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=395059) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=395059) 	// end inline asm
(EngineCore_DP0 pid=395059) 	// begin inline asm
(EngineCore_DP0 pid=395059) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=395059) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=395059) 	// end inline asm
(EngineCore_DP0 pid=395059) 	.loc	1 227 79                        // quant_slide_tuned_Llama3.2-3B.py:227:79
(EngineCore_DP0 pid=395059) 	cvt.f32.bf16 	%r107, %rs52;
(EngineCore_DP0 pid=395059) 	cvt.f32.bf16 	%r108, %rs54;
(EngineCore_DP0 pid=395059) 	.loc	1 229 48                        // quant_slide_tuned_Llama3.2-3B.py:229:48
(EngineCore_DP0 pid=395059) 	add.s32 	%r109, %r100, 2;
(EngineCore_DP0 pid=395059) 	add.s32 	%r110, %r102, 2;
(EngineCore_DP0 pid=395059) 	.loc	1 229 53                        // quant_slide_tuned_Llama3.2-3B.py:229:53
(EngineCore_DP0 pid=395059) 	setp.lt.s32 	%p23, %r109, %r19;
(EngineCore_DP0 pid=395059) 	setp.lt.s32 	%p24, %r110, %r19;
(EngineCore_DP0 pid=395059) 	.loc	1 229 37                        // quant_slide_tuned_Llama3.2-3B.py:229:37
(EngineCore_DP0 pid=395059) 	and.pred 	%p14, %p18, %p23;
(EngineCore_DP0 pid=395059) 	and.pred 	%p15, %p18, %p24;
(EngineCore_DP0 pid=395059) 	.loc	1 228 39                        // quant_slide_tuned_Llama3.2-3B.py:228:39
(EngineCore_DP0 pid=395059) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=395059) 	add.s64 	%rd14, %rd10, 4;
(EngineCore_DP0 pid=395059) 	.loc	1 228 21                        // quant_slide_tuned_Llama3.2-3B.py:228:21
(EngineCore_DP0 pid=395059) 	// begin inline asm
(EngineCore_DP0 pid=395059) 	mov.u16 %rs56, %rs49;
(EngineCore_DP0 pid=395059) 	@%p14 ld.global.b16 { %rs56 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=395059) 	// end inline asm
(EngineCore_DP0 pid=395059) 	// begin inline asm
(EngineCore_DP0 pid=395059) 	mov.u16 %rs58, %rs49;
(EngineCore_DP0 pid=395059) 	@%p15 ld.global.b16 { %rs58 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=395059) 	// end inline asm
(EngineCore_DP0 pid=395059) 	.loc	1 229 79                        // quant_slide_tuned_Llama3.2-3B.py:229:79
(EngineCore_DP0 pid=395059) 	cvt.f32.bf16 	%r111, %rs56;
(EngineCore_DP0 pid=395059) 	cvt.f32.bf16 	%r112, %rs58;
(EngineCore_DP0 pid=395059) 	.loc	1 231 48                        // quant_slide_tuned_Llama3.2-3B.py:231:48
(EngineCore_DP0 pid=395059) 	add.s32 	%r113, %r100, 3;
(EngineCore_DP0 pid=395059) 	add.s32 	%r114, %r102, 3;
(EngineCore_DP0 pid=395059) 	.loc	1 231 53                        // quant_slide_tuned_Llama3.2-3B.py:231:53
(EngineCore_DP0 pid=395059) 	setp.lt.s32 	%p25, %r113, %r19;
(EngineCore_DP0 pid=395059) 	setp.lt.s32 	%p26, %r114, %r19;
(EngineCore_DP0 pid=395059) 	.loc	1 231 37                        // quant_slide_tuned_Llama3.2-3B.py:231:37
(EngineCore_DP0 pid=395059) 	and.pred 	%p16, %p18, %p25;
(EngineCore_DP0 pid=395059) 	and.pred 	%p17, %p18, %p26;
(EngineCore_DP0 pid=395059) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-3B.py:230:39
(EngineCore_DP0 pid=395059) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=395059) 	add.s64 	%rd16, %rd10, 6;
(EngineCore_DP0 pid=395059) 	.loc	1 230 21                        // quant_slide_tuned_Llama3.2-3B.py:230:21
(EngineCore_DP0 pid=395059) 	// begin inline asm
(EngineCore_DP0 pid=395059) 	mov.u16 %rs60, %rs49;
(EngineCore_DP0 pid=395059) 	@%p16 ld.global.b16 { %rs60 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=395059) 	// end inline asm
(EngineCore_DP0 pid=395059) 	// begin inline asm
(EngineCore_DP0 pid=395059) 	mov.u16 %rs62, %rs49;
(EngineCore_DP0 pid=395059) 	@%p17 ld.global.b16 { %rs62 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=395059) 	// end inline asm
(EngineCore_DP0 pid=395059) 	.loc	1 231 79                        // quant_slide_tuned_Llama3.2-3B.py:231:79
(EngineCore_DP0 pid=395059) 	cvt.f32.bf16 	%r115, %rs60;
(EngineCore_DP0 pid=395059) 	cvt.f32.bf16 	%r116, %rs62;
(EngineCore_DP0 pid=395059) 	.loc	1 233 27                        // quant_slide_tuned_Llama3.2-3B.py:233:27
(EngineCore_DP0 pid=395059) 	mul.f32 	%r117, %r14, %r103;
(EngineCore_DP0 pid=395059) 	mul.f32 	%r118, %r14, %r104;
(EngineCore_DP0 pid=395059) 	mov.b32 	%r119, 0f43E00000;
(EngineCore_DP0 pid=395059) 	.loc	1 233 48                        // quant_slide_tuned_Llama3.2-3B.py:233:48
(EngineCore_DP0 pid=395059) 	min.xorsign.abs.f32 	%r83, %r117, %r119;
(EngineCore_DP0 pid=395059) 	min.xorsign.abs.f32 	%r84, %r118, %r119;
(EngineCore_DP0 pid=395059) 	.loc	1 233 60                        // quant_slide_tuned_Llama3.2-3B.py:233:60
(EngineCore_DP0 pid=395059) 	// begin inline asm
(EngineCore_DP0 pid=395059) 	cvt.rn.satfinite.e4m3x2.f32  %rs64, %r84, %r83; 
(EngineCore_DP0 pid=395059) 
(EngineCore_DP0 pid=395059) 	// end inline asm
(EngineCore_DP0 pid=395059) 	shr.u16 	%rs68, %rs64, 8;
(EngineCore_DP0 pid=395059) 	.loc	1 234 27                        // quant_slide_tuned_Llama3.2-3B.py:234:27
(EngineCore_DP0 pid=395059) 	mul.f32 	%r120, %r14, %r107;
(EngineCore_DP0 pid=395059) 	mul.f32 	%r121, %r14, %r108;
(EngineCore_DP0 pid=395059) 	.loc	1 234 48                        // quant_slide_tuned_Llama3.2-3B.py:234:48
(EngineCore_DP0 pid=395059) 	min.xorsign.abs.f32 	%r85, %r120, %r119;
(EngineCore_DP0 pid=395059) 	min.xorsign.abs.f32 	%r86, %r121, %r119;
(EngineCore_DP0 pid=395059) 	.loc	1 234 60                        // quant_slide_tuned_Llama3.2-3B.py:234:60
(EngineCore_DP0 pid=395059) 	// begin inline asm
(EngineCore_DP0 pid=395059) 	cvt.rn.satfinite.e4m3x2.f32  %rs65, %r86, %r85; 
(EngineCore_DP0 pid=395059) 
(EngineCore_DP0 pid=395059) 	// end inline asm
(EngineCore_DP0 pid=395059) 	shr.u16 	%rs69, %rs65, 8;
(EngineCore_DP0 pid=395059) 	.loc	1 235 27                        // quant_slide_tuned_Llama3.2-3B.py:235:27
(EngineCore_DP0 pid=395059) 	mul.f32 	%r122, %r14, %r111;
(EngineCore_DP0 pid=395059) 	mul.f32 	%r123, %r14, %r112;
(EngineCore_DP0 pid=395059) 	.loc	1 235 48                        // quant_slide_tuned_Llama3.2-3B.py:235:48
(EngineCore_DP0 pid=395059) 	min.xorsign.abs.f32 	%r87, %r122, %r119;
(EngineCore_DP0 pid=395059) 	min.xorsign.abs.f32 	%r88, %r123, %r119;
(EngineCore_DP0 pid=395059) 	.loc	1 235 60                        // quant_slide_tuned_Llama3.2-3B.py:235:60
(EngineCore_DP0 pid=395059) 	// begin inline asm
(EngineCore_DP0 pid=395059) 	cvt.rn.satfinite.e4m3x2.f32  %rs66, %r88, %r87; 
(EngineCore_DP0 pid=395059) 
(EngineCore_DP0 pid=395059) 	// end inline asm
(EngineCore_DP0 pid=395059) 	shr.u16 	%rs70, %rs66, 8;
(EngineCore_DP0 pid=395059) 	.loc	1 236 27                        // quant_slide_tuned_Llama3.2-3B.py:236:27
(EngineCore_DP0 pid=395059) 	mul.f32 	%r124, %r14, %r115;
(EngineCore_DP0 pid=395059) 	mul.f32 	%r125, %r14, %r116;
(EngineCore_DP0 pid=395059) 	.loc	1 236 48                        // quant_slide_tuned_Llama3.2-3B.py:236:48
(EngineCore_DP0 pid=395059) 	min.xorsign.abs.f32 	%r89, %r124, %r119;
(EngineCore_DP0 pid=395059) 	min.xorsign.abs.f32 	%r90, %r125, %r119;
(EngineCore_DP0 pid=395059) 	.loc	1 236 60                        // quant_slide_tuned_Llama3.2-3B.py:236:60
(EngineCore_DP0 pid=395059) 	// begin inline asm
(EngineCore_DP0 pid=395059) 	cvt.rn.satfinite.e4m3x2.f32  %rs67, %r90, %r89; 
(EngineCore_DP0 pid=395059) 
(EngineCore_DP0 pid=395059) 	// end inline asm
(EngineCore_DP0 pid=395059) 	shr.u16 	%rs71, %rs67, 8;
(EngineCore_DP0 pid=395059) 	.loc	1 238 45                        // quant_slide_tuned_Llama3.2-3B.py:238:45
(EngineCore_DP0 pid=395059) 	cvt.u32.u16 	%r126, %rs64;
(EngineCore_DP0 pid=395059) 	and.b32 	%r127, %r126, 255;
(EngineCore_DP0 pid=395059) 	cvt.u32.u16 	%r128, %rs68;
(EngineCore_DP0 pid=395059) 	.loc	1 240 45                        // quant_slide_tuned_Llama3.2-3B.py:240:45
(EngineCore_DP0 pid=395059) 	cvt.u32.u16 	%r129, %rs66;
(EngineCore_DP0 pid=395059) 	and.b32 	%r130, %r129, 255;
(EngineCore_DP0 pid=395059) 	cvt.u32.u16 	%r131, %rs70;
(EngineCore_DP0 pid=395059) 	.loc	1 241 45                        // quant_slide_tuned_Llama3.2-3B.py:241:45
(EngineCore_DP0 pid=395059) 	cvt.u32.u16 	%r132, %rs67;
(EngineCore_DP0 pid=395059) 	cvt.u32.u16 	%r133, %rs71;
(EngineCore_DP0 pid=395059) 	.loc	1 243 30                        // quant_slide_tuned_Llama3.2-3B.py:243:30
(EngineCore_DP0 pid=395059) 	and.b16 	%rs72, %rs65, 255;
(EngineCore_DP0 pid=395059) 	mul.wide.u16 	%r134, %rs72, 256;
(EngineCore_DP0 pid=395059) 	mul.wide.u16 	%r135, %rs69, 256;
(EngineCore_DP0 pid=395059) 	.loc	1 243 24                        // quant_slide_tuned_Llama3.2-3B.py:243:24
(EngineCore_DP0 pid=395059) 	or.b32 	%r136, %r134, %r127;
(EngineCore_DP0 pid=395059) 	or.b32 	%r137, %r135, %r128;
(EngineCore_DP0 pid=395059) 	.loc	1 243 42                        // quant_slide_tuned_Llama3.2-3B.py:243:42
(EngineCore_DP0 pid=395059) 	shl.b32 	%r138, %r130, 16;
(EngineCore_DP0 pid=395059) 	shl.b32 	%r139, %r131, 16;
(EngineCore_DP0 pid=395059) 	.loc	1 243 36                        // quant_slide_tuned_Llama3.2-3B.py:243:36
(EngineCore_DP0 pid=395059) 	or.b32 	%r140, %r136, %r138;
(EngineCore_DP0 pid=395059) 	or.b32 	%r141, %r137, %r139;
(EngineCore_DP0 pid=395059) 	.loc	1 243 55                        // quant_slide_tuned_Llama3.2-3B.py:243:55
(EngineCore_DP0 pid=395059) 	shl.b32 	%r142, %r132, 24;
(EngineCore_DP0 pid=395059) 	shl.b32 	%r143, %r133, 24;
(EngineCore_DP0 pid=395059) 	.loc	1 243 49                        // quant_slide_tuned_Llama3.2-3B.py:243:49
(EngineCore_DP0 pid=395059) 	or.b32 	%r91, %r140, %r142;
(EngineCore_DP0 pid=395059) 	or.b32 	%r92, %r141, %r143;
(EngineCore_DP0 pid=395059) 	.loc	1 244 29                        // quant_slide_tuned_Llama3.2-3B.py:244:29
(EngineCore_DP0 pid=395059) 	mad.wide.s32 	%rd17, %r93, 4, %rd2;
(EngineCore_DP0 pid=395059) 	.loc	1 244 39                        // quant_slide_tuned_Llama3.2-3B.py:244:39
(EngineCore_DP0 pid=395059) 	// begin inline asm
(EngineCore_DP0 pid=395059) 	@%p18 st.global.v2.b32 [ %rd17 + 0 ], { %r91, %r92 };
(EngineCore_DP0 pid=395059) 	// end inline asm
(EngineCore_DP0 pid=395059) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=395059) 	add.s32 	%r147, %r147, 1024;
(EngineCore_DP0 pid=395059) 	setp.lt.s32 	%p27, %r147, %r15;
(EngineCore_DP0 pid=395059) 	@%p27 bra 	$L__BB0_6;
(EngineCore_DP0 pid=395059) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=395059) 	.loc	1 215 4                         // quant_slide_tuned_Llama3.2-3B.py:215:4
(EngineCore_DP0 pid=395059) 	ret;
(EngineCore_DP0 pid=395059) $L__tmp3:
(EngineCore_DP0 pid=395059) $L__func_end0:
(EngineCore_DP0 pid=395059)                                         // -- End function
(EngineCore_DP0 pid=395059) }
(EngineCore_DP0 pid=395059) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py"
(EngineCore_DP0 pid=395059) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=395059) 	.section	.debug_abbrev
(EngineCore_DP0 pid=395059) 	{
(EngineCore_DP0 pid=395059) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=395059) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=395059) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=395059) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=395059) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=395059) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=395059) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=395059) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=395059) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=395059) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=395059) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=395059) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=395059) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=395059) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=395059) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=395059) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=395059) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=395059) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=395059) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=395059) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=395059) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=395059) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=395059) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=395059) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=395059) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=395059) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=395059) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=395059) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=395059) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=395059) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=395059) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=395059) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=395059) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=395059) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=395059) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=395059) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=395059) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=395059) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=395059) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=395059) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=395059) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=395059) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=395059) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=395059) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=395059) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=395059) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=395059) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=395059) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=395059) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=395059) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=395059) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=395059) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=395059) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=395059) 	}
(EngineCore_DP0 pid=395059) 	.section	.debug_info
(EngineCore_DP0 pid=395059) 	{
(EngineCore_DP0 pid=395059) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=395059) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=395059) .b8 0
(EngineCore_DP0 pid=395059) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=395059) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=395059) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=395059) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=395059) .b8 114
(EngineCore_DP0 pid=395059) .b8 105
(EngineCore_DP0 pid=395059) .b8 116
(EngineCore_DP0 pid=395059) .b8 111
(EngineCore_DP0 pid=395059) .b8 110
(EngineCore_DP0 pid=395059) .b8 0
(EngineCore_DP0 pid=395059) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=395059) .b8 0
(EngineCore_DP0 pid=395059) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=395059) .b8 117
(EngineCore_DP0 pid=395059) .b8 97
(EngineCore_DP0 pid=395059) .b8 110
(EngineCore_DP0 pid=395059) .b8 116
(EngineCore_DP0 pid=395059) .b8 95
(EngineCore_DP0 pid=395059) .b8 115
(EngineCore_DP0 pid=395059) .b8 108
(EngineCore_DP0 pid=395059) .b8 105
(EngineCore_DP0 pid=395059) .b8 100
(EngineCore_DP0 pid=395059) .b8 101
(EngineCore_DP0 pid=395059) .b8 95
(EngineCore_DP0 pid=395059) .b8 116
(EngineCore_DP0 pid=395059) .b8 117
(EngineCore_DP0 pid=395059) .b8 110
(EngineCore_DP0 pid=395059) .b8 101
(EngineCore_DP0 pid=395059) .b8 100
(EngineCore_DP0 pid=395059) .b8 95
(EngineCore_DP0 pid=395059) .b8 76
(EngineCore_DP0 pid=395059) .b8 108
(EngineCore_DP0 pid=395059) .b8 97
(EngineCore_DP0 pid=395059) .b8 109
(EngineCore_DP0 pid=395059) .b8 97
(EngineCore_DP0 pid=395059) .b8 51
(EngineCore_DP0 pid=395059) .b8 46
(EngineCore_DP0 pid=395059) .b8 50
(EngineCore_DP0 pid=395059) .b8 45
(EngineCore_DP0 pid=395059) .b8 51
(EngineCore_DP0 pid=395059) .b8 66
(EngineCore_DP0 pid=395059) .b8 46
(EngineCore_DP0 pid=395059) .b8 112
(EngineCore_DP0 pid=395059) .b8 121
(EngineCore_DP0 pid=395059) .b8 0
(EngineCore_DP0 pid=395059) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=395059) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=395059) .b8 114
(EngineCore_DP0 pid=395059) .b8 111
(EngineCore_DP0 pid=395059) .b8 111
(EngineCore_DP0 pid=395059) .b8 116
(EngineCore_DP0 pid=395059) .b8 47
(EngineCore_DP0 pid=395059) .b8 118
(EngineCore_DP0 pid=395059) .b8 108
(EngineCore_DP0 pid=395059) .b8 108
(EngineCore_DP0 pid=395059) .b8 109
(EngineCore_DP0 pid=395059) .b8 98
(EngineCore_DP0 pid=395059) .b8 101
(EngineCore_DP0 pid=395059) .b8 110
(EngineCore_DP0 pid=395059) .b8 99
(EngineCore_DP0 pid=395059) .b8 104
(EngineCore_DP0 pid=395059) .b8 47
(EngineCore_DP0 pid=395059) .b8 115
(EngineCore_DP0 pid=395059) .b8 108
(EngineCore_DP0 pid=395059) .b8 105
(EngineCore_DP0 pid=395059) .b8 100
(EngineCore_DP0 pid=395059) .b8 101
(EngineCore_DP0 pid=395059) .b8 115
(EngineCore_DP0 pid=395059) .b8 112
(EngineCore_DP0 pid=395059) .b8 97
(EngineCore_DP0 pid=395059) .b8 114
(EngineCore_DP0 pid=395059) .b8 115
(EngineCore_DP0 pid=395059) .b8 101
(EngineCore_DP0 pid=395059) .b8 47
(EngineCore_DP0 pid=395059) .b8 99
(EngineCore_DP0 pid=395059) .b8 115
(EngineCore_DP0 pid=395059) .b8 114
(EngineCore_DP0 pid=395059) .b8 99
(EngineCore_DP0 pid=395059) .b8 47
(EngineCore_DP0 pid=395059) .b8 102
(EngineCore_DP0 pid=395059) .b8 117
(EngineCore_DP0 pid=395059) .b8 115
(EngineCore_DP0 pid=395059) .b8 101
(EngineCore_DP0 pid=395059) .b8 100
(EngineCore_DP0 pid=395059) .b8 95
(EngineCore_DP0 pid=395059) .b8 113
(EngineCore_DP0 pid=395059) .b8 117
(EngineCore_DP0 pid=395059) .b8 97
(EngineCore_DP0 pid=395059) .b8 110
(EngineCore_DP0 pid=395059) .b8 116
(EngineCore_DP0 pid=395059) .b8 95
(EngineCore_DP0 pid=395059) .b8 115
(EngineCore_DP0 pid=395059) .b8 108
(EngineCore_DP0 pid=395059) .b8 105
(EngineCore_DP0 pid=395059) .b8 100
(EngineCore_DP0 pid=395059) .b8 101
(EngineCore_DP0 pid=395059) .b8 95
(EngineCore_DP0 pid=395059) .b8 116
(EngineCore_DP0 pid=395059) .b8 114
(EngineCore_DP0 pid=395059) .b8 105
(EngineCore_DP0 pid=395059) .b8 116
(EngineCore_DP0 pid=395059) .b8 111
(EngineCore_DP0 pid=395059) .b8 110
(EngineCore_DP0 pid=395059) .b8 47
(EngineCore_DP0 pid=395059) .b8 98
(EngineCore_DP0 pid=395059) .b8 117
(EngineCore_DP0 pid=395059) .b8 105
(EngineCore_DP0 pid=395059) .b8 108
(EngineCore_DP0 pid=395059) .b8 100
(EngineCore_DP0 pid=395059) .b8 47
(EngineCore_DP0 pid=395059) .b8 71
(EngineCore_DP0 pid=395059) .b8 66
(EngineCore_DP0 pid=395059) .b8 49
(EngineCore_DP0 pid=395059) .b8 48
(EngineCore_DP0 pid=395059) .b8 95
(EngineCore_DP0 pid=395059) .b8 99
(EngineCore_DP0 pid=395059) .b8 99
(EngineCore_DP0 pid=395059) .b8 49
(EngineCore_DP0 pid=395059) .b8 50
(EngineCore_DP0 pid=395059) .b8 49
(EngineCore_DP0 pid=395059) .b8 95
(EngineCore_DP0 pid=395059) .b8 112
(EngineCore_DP0 pid=395059) .b8 121
(EngineCore_DP0 pid=395059) .b8 51
(EngineCore_DP0 pid=395059) .b8 49
(EngineCore_DP0 pid=395059) .b8 50
(EngineCore_DP0 pid=395059) .b8 95
(EngineCore_DP0 pid=395059) .b8 99
(EngineCore_DP0 pid=395059) .b8 117
(EngineCore_DP0 pid=395059) .b8 49
(EngineCore_DP0 pid=395059) .b8 50
(EngineCore_DP0 pid=395059) .b8 57
(EngineCore_DP0 pid=395059) .b8 95
(EngineCore_DP0 pid=395059) .b8 97
(EngineCore_DP0 pid=395059) .b8 97
(EngineCore_DP0 pid=395059) .b8 114
(EngineCore_DP0 pid=395059) .b8 99
(EngineCore_DP0 pid=395059) .b8 104
(EngineCore_DP0 pid=395059) .b8 54
(EngineCore_DP0 pid=395059) .b8 52
(EngineCore_DP0 pid=395059) .b8 0
(EngineCore_DP0 pid=395059) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=395059) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=395059) .b8 113
(EngineCore_DP0 pid=395059) .b8 117
(EngineCore_DP0 pid=395059) .b8 97
(EngineCore_DP0 pid=395059) .b8 110
(EngineCore_DP0 pid=395059) .b8 116
(EngineCore_DP0 pid=395059) .b8 95
(EngineCore_DP0 pid=395059) .b8 115
(EngineCore_DP0 pid=395059) .b8 108
(EngineCore_DP0 pid=395059) .b8 105
(EngineCore_DP0 pid=395059) .b8 100
(EngineCore_DP0 pid=395059) .b8 101
(EngineCore_DP0 pid=395059) .b8 95
(EngineCore_DP0 pid=395059) .b8 102
(EngineCore_DP0 pid=395059) .b8 112
(EngineCore_DP0 pid=395059) .b8 56
(EngineCore_DP0 pid=395059) .b8 95
(EngineCore_DP0 pid=395059) .b8 107
(EngineCore_DP0 pid=395059) .b8 101
(EngineCore_DP0 pid=395059) .b8 114
(EngineCore_DP0 pid=395059) .b8 110
(EngineCore_DP0 pid=395059) .b8 101
(EngineCore_DP0 pid=395059) .b8 108
(EngineCore_DP0 pid=395059) .b8 0
(EngineCore_DP0 pid=395059) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=395059) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=395059) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=395059) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=395059) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=395059) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=395059) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=395059) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=395059) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=395059) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=395059) .b8 205                                 // DW_AT_call_line
(EngineCore_DP0 pid=395059) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=395059) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=395059) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=395059) 	}
(EngineCore_DP0 pid=395059) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=395059) 
(EngineCore_DP0 pid=395059) ================================================================
(EngineCore_DP0 pid=395059) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=395059) 
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp8acljiy7.ptx', '-o', '/tmp/tmp8acljiy7.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866] 
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866] 
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866] 
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp8acljiy7.ptx -o /tmp/tmp8acljiy7.ptx.o
(EngineCore_DP0 pid=395059) ERROR 01-25 20:07:05 [core.py:866] 

STDERR:
[2026-01-25 20:06:38] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:06:38] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:06:38] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:06:38] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:06:38] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:06:38] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:06:38] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:06:38] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:06:38] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:06:38] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:06:38] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:06:38] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:06:38] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:06:38] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:06:41] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:06:41] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:06:41] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:06:41] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:06:41] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:06:41] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:06:41] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:06:41] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:06:41] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:06:41] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:06:41] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:06:41] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:06:41] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:06:41] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=395059) [2026-01-25 20:06:42] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=395059) [2026-01-25 20:06:42] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=395059) [2026-01-25 20:06:42] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=395059) [2026-01-25 20:06:42] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=395059) [2026-01-25 20:06:42] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=395059) [2026-01-25 20:06:42] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=395059) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=395059) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:20<00:00, 20.84s/it]
(EngineCore_DP0 pid=395059) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:20<00:00, 20.84s/it]
(EngineCore_DP0 pid=395059) 
(EngineCore_DP0 pid=395059) [2026-01-25 20:07:04] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4096] -> 1D uint8
(EngineCore_DP0 pid=395059) [2026-01-25 20:07:04] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 13107200 bytes
(EngineCore_DP0 pid=395059) [2026-01-25 20:07:04] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4096] -> 1D uint8
(EngineCore_DP0 pid=395059) [2026-01-25 20:07:04] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 7864320 bytes
(EngineCore_DP0 pid=395059) [2026-01-25 20:07:04] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4096] -> 1D uint8
(EngineCore_DP0 pid=395059) [2026-01-25 20:07:04] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 41943040 bytes
(EngineCore_DP0 pid=395059) [2026-01-25 20:07:04] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 10944] -> 1D uint8
(EngineCore_DP0 pid=395059) [2026-01-25 20:07:04] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 21037056 bytes
(EngineCore_DP0 pid=395059) Process EngineCore_DP0:
(EngineCore_DP0 pid=395059) Traceback (most recent call last):
(EngineCore_DP0 pid=395059)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=395059)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=395059)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=395059)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=395059) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp8acljiy7.ptx', '-o', '/tmp/tmp8acljiy7.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=395059) 
(EngineCore_DP0 pid=395059) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=395059) 
(EngineCore_DP0 pid=395059) Traceback (most recent call last):
(EngineCore_DP0 pid=395059)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=395059)     self.run()
(EngineCore_DP0 pid=395059)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=395059)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=395059)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=395059)     raise e
(EngineCore_DP0 pid=395059)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=395059)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=395059)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=395059)     super().__init__(
(EngineCore_DP0 pid=395059)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=395059)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=395059)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=395059)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=395059)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=395059)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=395059)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=395059)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=395059)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=395059)     return func(*args, **kwargs)
(EngineCore_DP0 pid=395059)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=395059)     return func(*args, **kwargs)
(EngineCore_DP0 pid=395059)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=395059)     self.model_runner.profile_run()
(EngineCore_DP0 pid=395059)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=395059)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=395059)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=395059)     return func(*args, **kwargs)
(EngineCore_DP0 pid=395059)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=395059)     outputs = self.model(
(EngineCore_DP0 pid=395059)               ^^^^^^^^^^^
(EngineCore_DP0 pid=395059)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=395059)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=395059)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=395059)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=395059)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=395059)     model_output = self.model(
(EngineCore_DP0 pid=395059)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=395059)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=395059)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=395059)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=395059)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=395059)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=395059)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=395059)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=395059)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=395059)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=395059)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=395059)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=395059)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=395059)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=395059)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=395059)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=395059)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=395059)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=395059)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=395059)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=395059)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=395059)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=395059)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=395059)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=395059)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=395059)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=395059)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=395059)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=395059)     return self._linear_fn(
(EngineCore_DP0 pid=395059)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=395059)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=395059)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=395059)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=395059)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=395059)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=395059)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=395059)     return fn(input, L)
(EngineCore_DP0 pid=395059)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=395059)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=395059)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=395059)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=395059)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=395059)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=395059)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=395059)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=395059)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=395059)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=395059)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=395059)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=395059)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=395059)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395059)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=395059)     raise PTXASError(error)
(EngineCore_DP0 pid=395059) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=395059) `ptxas` stderr:
(EngineCore_DP0 pid=395059) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=395059) 
(EngineCore_DP0 pid=395059) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp8acljiy7.ptx -o /tmp/tmp8acljiy7.ptx.o
(EngineCore_DP0 pid=395059) 
[rank0]:[W125 20:07:05.978976865 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=8192

========== M=16384 ==========
Time: 2026-01-25 20:07:07
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-3B-FP8_M16384.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:07:16 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 20:07:16 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=395776) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=395776) 
(EngineCore_DP0 pid=395776) 
(EngineCore_DP0 pid=395776) ================================================================
(EngineCore_DP0 pid=395776) Internal Triton PTX codegen error
(EngineCore_DP0 pid=395776) `ptxas` stderr:
(EngineCore_DP0 pid=395776) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=395776) 
(EngineCore_DP0 pid=395776) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpwwgvhaof.ptx -o /tmp/tmpwwgvhaof.ptx.o
(EngineCore_DP0 pid=395776) 
(EngineCore_DP0 pid=395776) 
(EngineCore_DP0 pid=395776) //
(EngineCore_DP0 pid=395776) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=395776) //
(EngineCore_DP0 pid=395776) 
(EngineCore_DP0 pid=395776) .version 8.7
(EngineCore_DP0 pid=395776) .target sm_121a
(EngineCore_DP0 pid=395776) .address_size 64
(EngineCore_DP0 pid=395776) 
(EngineCore_DP0 pid=395776) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=395776) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=395776)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=395776) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=395776) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=395776) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=395776) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=395776) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=395776) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=395776) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=395776) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=395776) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=395776) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=395776) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=395776) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=395776) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=395776) )
(EngineCore_DP0 pid=395776) .reqntid 512
(EngineCore_DP0 pid=395776) {
(EngineCore_DP0 pid=395776) 	.reg .pred 	%p<29>;
(EngineCore_DP0 pid=395776) 	.reg .b16 	%rs<73>;
(EngineCore_DP0 pid=395776) 	.reg .b32 	%r<148>;
(EngineCore_DP0 pid=395776) 	.reg .b64 	%rd<18>;
(EngineCore_DP0 pid=395776) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=395776) $L__func_begin0:
(EngineCore_DP0 pid=395776) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=395776) 
(EngineCore_DP0 pid=395776) // %bb.0:
(EngineCore_DP0 pid=395776) 	ld.param.b32 	%r21, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=395776) 	ld.param.b32 	%r20, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=395776) 	ld.param.b32 	%r19, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=395776) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=395776) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=395776) $L__tmp0:
(EngineCore_DP0 pid=395776) 	.loc	1 191 24                        // quant_slide_tuned_Llama3.2-3B.py:191:24
(EngineCore_DP0 pid=395776) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=395776) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=395776) 	.loc	1 196 26                        // quant_slide_tuned_Llama3.2-3B.py:196:26
(EngineCore_DP0 pid=395776) 	mul.lo.s32 	%r24, %r23, %r1;
(EngineCore_DP0 pid=395776) 	.loc	1 196 20                        // quant_slide_tuned_Llama3.2-3B.py:196:20
(EngineCore_DP0 pid=395776) 	mad.wide.s32 	%rd1, %r24, 2, %rd4;
(EngineCore_DP0 pid=395776) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=395776) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=395776) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=395776) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=395776) 	setp.lt.s32 	%p1, %r20, 1;
(EngineCore_DP0 pid=395776) 	mov.b32 	%r146, 0f2B8CBCCC;
(EngineCore_DP0 pid=395776) 	setp.eq.b32 	%p28, %r2, 0;
(EngineCore_DP0 pid=395776) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=395776) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=395776) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=395776) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=395776) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=395776) 	shr.u32 	%r33, %r2, 3;
(EngineCore_DP0 pid=395776) 	and.b32 	%r34, %r33, 60;
(EngineCore_DP0 pid=395776) 	mov.b32 	%r35, global_smem;
(EngineCore_DP0 pid=395776) 	add.s32 	%r53, %r35, %r34;
(EngineCore_DP0 pid=395776) 	shl.b32 	%r36, %r2, 2;
(EngineCore_DP0 pid=395776) 	add.s32 	%r56, %r35, %r36;
(EngineCore_DP0 pid=395776) 	mov.b32 	%r41, 0;
(EngineCore_DP0 pid=395776) 	mov.b32 	%r144, 0f00000000;
(EngineCore_DP0 pid=395776) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=395776) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=395776) 	mov.b32 	%r145, %r41;
(EngineCore_DP0 pid=395776) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=395776) 	.loc	1 202 19                        // quant_slide_tuned_Llama3.2-3B.py:202:19
(EngineCore_DP0 pid=395776) 	add.s32 	%r59, %r4, %r145;
(EngineCore_DP0 pid=395776) 	.loc	1 203 22                        // quant_slide_tuned_Llama3.2-3B.py:203:22
(EngineCore_DP0 pid=395776) 	add.s32 	%r60, %r59, 4096;
(EngineCore_DP0 pid=395776) 	setp.lt.s32 	%p2, %r59, %r19;
(EngineCore_DP0 pid=395776) 	setp.lt.s32 	%p3, %r60, %r19;
(EngineCore_DP0 pid=395776) 	.loc	1 204 29                        // quant_slide_tuned_Llama3.2-3B.py:204:29
(EngineCore_DP0 pid=395776) 	mad.wide.s32 	%rd6, %r59, 2, %rd1;
(EngineCore_DP0 pid=395776) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=395776) 	.loc	1 204 21                        // quant_slide_tuned_Llama3.2-3B.py:204:21
(EngineCore_DP0 pid=395776) 	// begin inline asm
(EngineCore_DP0 pid=395776) 	mov.u32 %r37, %r41;
(EngineCore_DP0 pid=395776) 	mov.u32 %r38, %r41;
(EngineCore_DP0 pid=395776) 	mov.u32 %r39, %r41;
(EngineCore_DP0 pid=395776) 	mov.u32 %r40, %r41;
(EngineCore_DP0 pid=395776) 	@%p2 ld.global.v4.b32 { %r37, %r38, %r39, %r40 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=395776) 	// end inline asm
(EngineCore_DP0 pid=395776) 	mov.b32 	{%rs1, %rs2}, %r37;
(EngineCore_DP0 pid=395776) 	mov.b32 	{%rs3, %rs4}, %r38;
(EngineCore_DP0 pid=395776) 	mov.b32 	{%rs5, %rs6}, %r39;
(EngineCore_DP0 pid=395776) 	mov.b32 	{%rs7, %rs8}, %r40;
(EngineCore_DP0 pid=395776) 	// begin inline asm
(EngineCore_DP0 pid=395776) 	mov.u32 %r45, %r41;
(EngineCore_DP0 pid=395776) 	mov.u32 %r46, %r41;
(EngineCore_DP0 pid=395776) 	mov.u32 %r47, %r41;
(EngineCore_DP0 pid=395776) 	mov.u32 %r48, %r41;
(EngineCore_DP0 pid=395776) 	@%p3 ld.global.v4.b32 { %r45, %r46, %r47, %r48 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=395776) 	// end inline asm
(EngineCore_DP0 pid=395776) 	mov.b32 	{%rs9, %rs10}, %r45;
(EngineCore_DP0 pid=395776) 	mov.b32 	{%rs11, %rs12}, %r46;
(EngineCore_DP0 pid=395776) 	mov.b32 	{%rs13, %rs14}, %r47;
(EngineCore_DP0 pid=395776) 	mov.b32 	{%rs15, %rs16}, %r48;
(EngineCore_DP0 pid=395776) 	.loc	1 205 50                        // quant_slide_tuned_Llama3.2-3B.py:205:50
(EngineCore_DP0 pid=395776) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=395776) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=395776) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=395776) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=395776) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=395776) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=395776) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=395776) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=395776) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=395776) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=395776) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=395776) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=395776) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=395776) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=395776) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=395776) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=395776) $L__tmp1:
(EngineCore_DP0 pid=395776) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=395776) 	bar.sync 	0;
(EngineCore_DP0 pid=395776) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=395776) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=395776) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=395776) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=395776) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=395776) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=395776) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=395776) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=395776) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=395776) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=395776) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=395776) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=395776) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=395776) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=395776) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=395776) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=395776) 	cvt.f32.bf16 	%r61, %rs47;
(EngineCore_DP0 pid=395776) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=395776) 	shfl.sync.bfly.b32 	%r62, %r61, 16, 31, -1;
(EngineCore_DP0 pid=395776) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=395776) 	max.f32 	%r63, %r61, %r62;
(EngineCore_DP0 pid=395776) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=395776) 	shfl.sync.bfly.b32 	%r64, %r63, 8, 31, -1;
(EngineCore_DP0 pid=395776) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=395776) 	max.f32 	%r65, %r63, %r64;
(EngineCore_DP0 pid=395776) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=395776) 	shfl.sync.bfly.b32 	%r66, %r65, 4, 31, -1;
(EngineCore_DP0 pid=395776) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=395776) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=395776) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=395776) 	shfl.sync.bfly.b32 	%r68, %r67, 2, 31, -1;
(EngineCore_DP0 pid=395776) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=395776) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=395776) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=395776) 	shfl.sync.bfly.b32 	%r70, %r69, 1, 31, -1;
(EngineCore_DP0 pid=395776) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=395776) 	max.f32 	%r54, %r69, %r70;
(EngineCore_DP0 pid=395776) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=395776) 	// begin inline asm
(EngineCore_DP0 pid=395776) 	@%p4 st.shared.b32 [ %r53 + 0 ], %r54;
(EngineCore_DP0 pid=395776) 	// end inline asm
(EngineCore_DP0 pid=395776) 	bar.sync 	0;
(EngineCore_DP0 pid=395776) 	// begin inline asm
(EngineCore_DP0 pid=395776) 	@%p5 ld.shared.b32 %r55, [ %r56 + 0 ];
(EngineCore_DP0 pid=395776) 	// end inline asm
(EngineCore_DP0 pid=395776) 	shfl.sync.bfly.b32 	%r71, %r55, 8, 31, -1;
(EngineCore_DP0 pid=395776) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=395776) 	max.f32 	%r72, %r55, %r71;
(EngineCore_DP0 pid=395776) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=395776) 	shfl.sync.bfly.b32 	%r73, %r72, 4, 31, -1;
(EngineCore_DP0 pid=395776) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=395776) 	max.f32 	%r74, %r72, %r73;
(EngineCore_DP0 pid=395776) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=395776) 	shfl.sync.bfly.b32 	%r75, %r74, 2, 31, -1;
(EngineCore_DP0 pid=395776) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=395776) 	max.f32 	%r76, %r74, %r75;
(EngineCore_DP0 pid=395776) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=395776) 	shfl.sync.bfly.b32 	%r77, %r76, 1, 31, -1;
(EngineCore_DP0 pid=395776) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=395776) 	max.f32 	%r58, %r76, %r77;
(EngineCore_DP0 pid=395776) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=395776) 	// begin inline asm
(EngineCore_DP0 pid=395776) 	@%p28 st.shared.b32 [ %r56 + 0 ], %r58;
(EngineCore_DP0 pid=395776) 	// end inline asm
(EngineCore_DP0 pid=395776) 	bar.sync 	0;
(EngineCore_DP0 pid=395776) 	ld.shared.b32 	%r78, [global_smem];
(EngineCore_DP0 pid=395776) $L__tmp2:
(EngineCore_DP0 pid=395776) 	.loc	1 205 36                        // quant_slide_tuned_Llama3.2-3B.py:205:36
(EngineCore_DP0 pid=395776) 	max.f32 	%r144, %r144, %r78;
(EngineCore_DP0 pid=395776) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=395776) 	add.s32 	%r145, %r145, 8192;
(EngineCore_DP0 pid=395776) 	setp.lt.s32 	%p7, %r145, %r20;
(EngineCore_DP0 pid=395776) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=395776) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=395776) 	.loc	1 207 32                        // quant_slide_tuned_Llama3.2-3B.py:207:32
(EngineCore_DP0 pid=395776) 	max.f32 	%r146, %r144, 0f2B8CBCCC;
(EngineCore_DP0 pid=395776) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=395776) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-3B.py:0:32
(EngineCore_DP0 pid=395776) 	mov.b32 	%r80, 0f43E00000;
(EngineCore_DP0 pid=395776) 	.loc	1 208 32                        // quant_slide_tuned_Llama3.2-3B.py:208:32
(EngineCore_DP0 pid=395776) 	div.full.f32 	%r81, %r146, %r80;
(EngineCore_DP0 pid=395776) 	.loc	1 208 41                        // quant_slide_tuned_Llama3.2-3B.py:208:41
(EngineCore_DP0 pid=395776) 	max.f32 	%r79, %r81, 0f36924925;
(EngineCore_DP0 pid=395776) 	.loc	1 210 25                        // quant_slide_tuned_Llama3.2-3B.py:210:25
(EngineCore_DP0 pid=395776) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=395776) 	.loc	1 210 30                        // quant_slide_tuned_Llama3.2-3B.py:210:30
(EngineCore_DP0 pid=395776) 	// begin inline asm
(EngineCore_DP0 pid=395776) 	@%p28 st.global.b32 [ %rd8 + 0 ], { %r79 };
(EngineCore_DP0 pid=395776) 	// end inline asm
(EngineCore_DP0 pid=395776) 	.loc	1 213 29                        // quant_slide_tuned_Llama3.2-3B.py:213:29
(EngineCore_DP0 pid=395776) 	shl.b32 	%r15, %r21, 1;
(EngineCore_DP0 pid=395776) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=395776) 	setp.lt.s32 	%p9, %r15, 1;
(EngineCore_DP0 pid=395776) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=395776) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=395776) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-3B.py:0:41
(EngineCore_DP0 pid=395776) 	ld.param.b32 	%r25, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=395776) 	shr.s32 	%r26, %r25, 31;
(EngineCore_DP0 pid=395776) 	shr.u32 	%r27, %r26, 30;
(EngineCore_DP0 pid=395776) 	add.s32 	%r28, %r25, %r27;
(EngineCore_DP0 pid=395776) 	shr.s32 	%r29, %r28, 2;
(EngineCore_DP0 pid=395776) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=395776) 	mul.lo.s32 	%r30, %r29, %r1;
(EngineCore_DP0 pid=395776) 	mad.wide.s32 	%rd2, %r30, 4, %rd5;
(EngineCore_DP0 pid=395776) 	div.full.f32 	%r14, %r80, %r146;
(EngineCore_DP0 pid=395776) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=395776) 	mov.b32 	%r147, 0;
(EngineCore_DP0 pid=395776) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=395776)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=395776) 	.loc	1 216 31                        // quant_slide_tuned_Llama3.2-3B.py:216:31
(EngineCore_DP0 pid=395776) 	add.s32 	%r93, %r16, %r147;
(EngineCore_DP0 pid=395776) 	.loc	1 217 30                        // quant_slide_tuned_Llama3.2-3B.py:217:30
(EngineCore_DP0 pid=395776) 	add.s32 	%r94, %r147, 1;
(EngineCore_DP0 pid=395776) 	setp.lt.s32 	%p18, %r93, %r15;
(EngineCore_DP0 pid=395776) 	.loc	1 220 24                        // quant_slide_tuned_Llama3.2-3B.py:220:24
(EngineCore_DP0 pid=395776) 	shr.u32 	%r95, %r93, 1;
(EngineCore_DP0 pid=395776) 	.loc	1 221 23                        // quant_slide_tuned_Llama3.2-3B.py:221:23
(EngineCore_DP0 pid=395776) 	shr.u32 	%r96, %r94, 31;
(EngineCore_DP0 pid=395776) 	add.s32 	%r97, %r94, %r96;
(EngineCore_DP0 pid=395776) 	and.b32 	%r98, %r97, 2147483646;
(EngineCore_DP0 pid=395776) 	sub.s32 	%r99, %r94, %r98;
(EngineCore_DP0 pid=395776) 	.loc	1 222 22                        // quant_slide_tuned_Llama3.2-3B.py:222:22
(EngineCore_DP0 pid=395776) 	mul.lo.s32 	%r100, %r95, 6;
(EngineCore_DP0 pid=395776) 	.loc	1 222 30                        // quant_slide_tuned_Llama3.2-3B.py:222:30
(EngineCore_DP0 pid=395776) 	shl.b32 	%r101, %r99, 1;
(EngineCore_DP0 pid=395776) 	.loc	1 222 26                        // quant_slide_tuned_Llama3.2-3B.py:222:26
(EngineCore_DP0 pid=395776) 	add.s32 	%r102, %r100, %r101;
(EngineCore_DP0 pid=395776) 	.loc	1 225 53                        // quant_slide_tuned_Llama3.2-3B.py:225:53
(EngineCore_DP0 pid=395776) 	setp.lt.s32 	%p19, %r100, %r19;
(EngineCore_DP0 pid=395776) 	setp.lt.s32 	%p20, %r102, %r19;
(EngineCore_DP0 pid=395776) 	.loc	1 225 37                        // quant_slide_tuned_Llama3.2-3B.py:225:37
(EngineCore_DP0 pid=395776) 	and.pred 	%p10, %p18, %p19;
(EngineCore_DP0 pid=395776) 	and.pred 	%p11, %p18, %p20;
(EngineCore_DP0 pid=395776) 	.loc	1 224 29                        // quant_slide_tuned_Llama3.2-3B.py:224:29
(EngineCore_DP0 pid=395776) 	mad.wide.s32 	%rd9, %r100, 2, %rd1;
(EngineCore_DP0 pid=395776) 	mad.wide.s32 	%rd10, %r102, 2, %rd1;
(EngineCore_DP0 pid=395776) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=395776) 	.loc	1 224 21                        // quant_slide_tuned_Llama3.2-3B.py:224:21
(EngineCore_DP0 pid=395776) 	// begin inline asm
(EngineCore_DP0 pid=395776) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=395776) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=395776) 	// end inline asm
(EngineCore_DP0 pid=395776) 	// begin inline asm
(EngineCore_DP0 pid=395776) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=395776) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=395776) 	// end inline asm
(EngineCore_DP0 pid=395776) 	.loc	1 225 79                        // quant_slide_tuned_Llama3.2-3B.py:225:79
(EngineCore_DP0 pid=395776) 	cvt.f32.bf16 	%r103, %rs48;
(EngineCore_DP0 pid=395776) 	cvt.f32.bf16 	%r104, %rs50;
(EngineCore_DP0 pid=395776) 	.loc	1 227 48                        // quant_slide_tuned_Llama3.2-3B.py:227:48
(EngineCore_DP0 pid=395776) 	or.b32 	%r105, %r100, 1;
(EngineCore_DP0 pid=395776) 	or.b32 	%r106, %r102, 1;
(EngineCore_DP0 pid=395776) 	.loc	1 227 53                        // quant_slide_tuned_Llama3.2-3B.py:227:53
(EngineCore_DP0 pid=395776) 	setp.lt.s32 	%p21, %r105, %r19;
(EngineCore_DP0 pid=395776) 	setp.lt.s32 	%p22, %r106, %r19;
(EngineCore_DP0 pid=395776) 	.loc	1 227 37                        // quant_slide_tuned_Llama3.2-3B.py:227:37
(EngineCore_DP0 pid=395776) 	and.pred 	%p12, %p18, %p21;
(EngineCore_DP0 pid=395776) 	and.pred 	%p13, %p18, %p22;
(EngineCore_DP0 pid=395776) 	.loc	1 226 39                        // quant_slide_tuned_Llama3.2-3B.py:226:39
(EngineCore_DP0 pid=395776) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=395776) 	add.s64 	%rd12, %rd10, 2;
(EngineCore_DP0 pid=395776) 	.loc	1 226 21                        // quant_slide_tuned_Llama3.2-3B.py:226:21
(EngineCore_DP0 pid=395776) 	// begin inline asm
(EngineCore_DP0 pid=395776) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=395776) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=395776) 	// end inline asm
(EngineCore_DP0 pid=395776) 	// begin inline asm
(EngineCore_DP0 pid=395776) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=395776) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=395776) 	// end inline asm
(EngineCore_DP0 pid=395776) 	.loc	1 227 79                        // quant_slide_tuned_Llama3.2-3B.py:227:79
(EngineCore_DP0 pid=395776) 	cvt.f32.bf16 	%r107, %rs52;
(EngineCore_DP0 pid=395776) 	cvt.f32.bf16 	%r108, %rs54;
(EngineCore_DP0 pid=395776) 	.loc	1 229 48                        // quant_slide_tuned_Llama3.2-3B.py:229:48
(EngineCore_DP0 pid=395776) 	add.s32 	%r109, %r100, 2;
(EngineCore_DP0 pid=395776) 	add.s32 	%r110, %r102, 2;
(EngineCore_DP0 pid=395776) 	.loc	1 229 53                        // quant_slide_tuned_Llama3.2-3B.py:229:53
(EngineCore_DP0 pid=395776) 	setp.lt.s32 	%p23, %r109, %r19;
(EngineCore_DP0 pid=395776) 	setp.lt.s32 	%p24, %r110, %r19;
(EngineCore_DP0 pid=395776) 	.loc	1 229 37                        // quant_slide_tuned_Llama3.2-3B.py:229:37
(EngineCore_DP0 pid=395776) 	and.pred 	%p14, %p18, %p23;
(EngineCore_DP0 pid=395776) 	and.pred 	%p15, %p18, %p24;
(EngineCore_DP0 pid=395776) 	.loc	1 228 39                        // quant_slide_tuned_Llama3.2-3B.py:228:39
(EngineCore_DP0 pid=395776) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=395776) 	add.s64 	%rd14, %rd10, 4;
(EngineCore_DP0 pid=395776) 	.loc	1 228 21                        // quant_slide_tuned_Llama3.2-3B.py:228:21
(EngineCore_DP0 pid=395776) 	// begin inline asm
(EngineCore_DP0 pid=395776) 	mov.u16 %rs56, %rs49;
(EngineCore_DP0 pid=395776) 	@%p14 ld.global.b16 { %rs56 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=395776) 	// end inline asm
(EngineCore_DP0 pid=395776) 	// begin inline asm
(EngineCore_DP0 pid=395776) 	mov.u16 %rs58, %rs49;
(EngineCore_DP0 pid=395776) 	@%p15 ld.global.b16 { %rs58 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=395776) 	// end inline asm
(EngineCore_DP0 pid=395776) 	.loc	1 229 79                        // quant_slide_tuned_Llama3.2-3B.py:229:79
(EngineCore_DP0 pid=395776) 	cvt.f32.bf16 	%r111, %rs56;
(EngineCore_DP0 pid=395776) 	cvt.f32.bf16 	%r112, %rs58;
(EngineCore_DP0 pid=395776) 	.loc	1 231 48                        // quant_slide_tuned_Llama3.2-3B.py:231:48
(EngineCore_DP0 pid=395776) 	add.s32 	%r113, %r100, 3;
(EngineCore_DP0 pid=395776) 	add.s32 	%r114, %r102, 3;
(EngineCore_DP0 pid=395776) 	.loc	1 231 53                        // quant_slide_tuned_Llama3.2-3B.py:231:53
(EngineCore_DP0 pid=395776) 	setp.lt.s32 	%p25, %r113, %r19;
(EngineCore_DP0 pid=395776) 	setp.lt.s32 	%p26, %r114, %r19;
(EngineCore_DP0 pid=395776) 	.loc	1 231 37                        // quant_slide_tuned_Llama3.2-3B.py:231:37
(EngineCore_DP0 pid=395776) 	and.pred 	%p16, %p18, %p25;
(EngineCore_DP0 pid=395776) 	and.pred 	%p17, %p18, %p26;
(EngineCore_DP0 pid=395776) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-3B.py:230:39
(EngineCore_DP0 pid=395776) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=395776) 	add.s64 	%rd16, %rd10, 6;
(EngineCore_DP0 pid=395776) 	.loc	1 230 21                        // quant_slide_tuned_Llama3.2-3B.py:230:21
(EngineCore_DP0 pid=395776) 	// begin inline asm
(EngineCore_DP0 pid=395776) 	mov.u16 %rs60, %rs49;
(EngineCore_DP0 pid=395776) 	@%p16 ld.global.b16 { %rs60 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=395776) 	// end inline asm
(EngineCore_DP0 pid=395776) 	// begin inline asm
(EngineCore_DP0 pid=395776) 	mov.u16 %rs62, %rs49;
(EngineCore_DP0 pid=395776) 	@%p17 ld.global.b16 { %rs62 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=395776) 	// end inline asm
(EngineCore_DP0 pid=395776) 	.loc	1 231 79                        // quant_slide_tuned_Llama3.2-3B.py:231:79
(EngineCore_DP0 pid=395776) 	cvt.f32.bf16 	%r115, %rs60;
(EngineCore_DP0 pid=395776) 	cvt.f32.bf16 	%r116, %rs62;
(EngineCore_DP0 pid=395776) 	.loc	1 233 27                        // quant_slide_tuned_Llama3.2-3B.py:233:27
(EngineCore_DP0 pid=395776) 	mul.f32 	%r117, %r14, %r103;
(EngineCore_DP0 pid=395776) 	mul.f32 	%r118, %r14, %r104;
(EngineCore_DP0 pid=395776) 	mov.b32 	%r119, 0f43E00000;
(EngineCore_DP0 pid=395776) 	.loc	1 233 48                        // quant_slide_tuned_Llama3.2-3B.py:233:48
(EngineCore_DP0 pid=395776) 	min.xorsign.abs.f32 	%r83, %r117, %r119;
(EngineCore_DP0 pid=395776) 	min.xorsign.abs.f32 	%r84, %r118, %r119;
(EngineCore_DP0 pid=395776) 	.loc	1 233 60                        // quant_slide_tuned_Llama3.2-3B.py:233:60
(EngineCore_DP0 pid=395776) 	// begin inline asm
(EngineCore_DP0 pid=395776) 	cvt.rn.satfinite.e4m3x2.f32  %rs64, %r84, %r83; 
(EngineCore_DP0 pid=395776) 
(EngineCore_DP0 pid=395776) 	// end inline asm
(EngineCore_DP0 pid=395776) 	shr.u16 	%rs68, %rs64, 8;
(EngineCore_DP0 pid=395776) 	.loc	1 234 27                        // quant_slide_tuned_Llama3.2-3B.py:234:27
(EngineCore_DP0 pid=395776) 	mul.f32 	%r120, %r14, %r107;
(EngineCore_DP0 pid=395776) 	mul.f32 	%r121, %r14, %r108;
(EngineCore_DP0 pid=395776) 	.loc	1 234 48                        // quant_slide_tuned_Llama3.2-3B.py:234:48
(EngineCore_DP0 pid=395776) 	min.xorsign.abs.f32 	%r85, %r120, %r119;
(EngineCore_DP0 pid=395776) 	min.xorsign.abs.f32 	%r86, %r121, %r119;
(EngineCore_DP0 pid=395776) 	.loc	1 234 60                        // quant_slide_tuned_Llama3.2-3B.py:234:60
(EngineCore_DP0 pid=395776) 	// begin inline asm
(EngineCore_DP0 pid=395776) 	cvt.rn.satfinite.e4m3x2.f32  %rs65, %r86, %r85; 
(EngineCore_DP0 pid=395776) 
(EngineCore_DP0 pid=395776) 	// end inline asm
(EngineCore_DP0 pid=395776) 	shr.u16 	%rs69, %rs65, 8;
(EngineCore_DP0 pid=395776) 	.loc	1 235 27                        // quant_slide_tuned_Llama3.2-3B.py:235:27
(EngineCore_DP0 pid=395776) 	mul.f32 	%r122, %r14, %r111;
(EngineCore_DP0 pid=395776) 	mul.f32 	%r123, %r14, %r112;
(EngineCore_DP0 pid=395776) 	.loc	1 235 48                        // quant_slide_tuned_Llama3.2-3B.py:235:48
(EngineCore_DP0 pid=395776) 	min.xorsign.abs.f32 	%r87, %r122, %r119;
(EngineCore_DP0 pid=395776) 	min.xorsign.abs.f32 	%r88, %r123, %r119;
(EngineCore_DP0 pid=395776) 	.loc	1 235 60                        // quant_slide_tuned_Llama3.2-3B.py:235:60
(EngineCore_DP0 pid=395776) 	// begin inline asm
(EngineCore_DP0 pid=395776) 	cvt.rn.satfinite.e4m3x2.f32  %rs66, %r88, %r87; 
(EngineCore_DP0 pid=395776) 
(EngineCore_DP0 pid=395776) 	// end inline asm
(EngineCore_DP0 pid=395776) 	shr.u16 	%rs70, %rs66, 8;
(EngineCore_DP0 pid=395776) 	.loc	1 236 27                        // quant_slide_tuned_Llama3.2-3B.py:236:27
(EngineCore_DP0 pid=395776) 	mul.f32 	%r124, %r14, %r115;
(EngineCore_DP0 pid=395776) 	mul.f32 	%r125, %r14, %r116;
(EngineCore_DP0 pid=395776) 	.loc	1 236 48                        // quant_slide_tuned_Llama3.2-3B.py:236:48
(EngineCore_DP0 pid=395776) 	min.xorsign.abs.f32 	%r89, %r124, %r119;
(EngineCore_DP0 pid=395776) 	min.xorsign.abs.f32 	%r90, %r125, %r119;
(EngineCore_DP0 pid=395776) 	.loc	1 236 60                        // quant_slide_tuned_Llama3.2-3B.py:236:60
(EngineCore_DP0 pid=395776) 	// begin inline asm
(EngineCore_DP0 pid=395776) 	cvt.rn.satfinite.e4m3x2.f32  %rs67, %r90, %r89; 
(EngineCore_DP0 pid=395776) 
(EngineCore_DP0 pid=395776) 	// end inline asm
(EngineCore_DP0 pid=395776) 	shr.u16 	%rs71, %rs67, 8;
(EngineCore_DP0 pid=395776) 	.loc	1 238 45                        // quant_slide_tuned_Llama3.2-3B.py:238:45
(EngineCore_DP0 pid=395776) 	cvt.u32.u16 	%r126, %rs64;
(EngineCore_DP0 pid=395776) 	and.b32 	%r127, %r126, 255;
(EngineCore_DP0 pid=395776) 	cvt.u32.u16 	%r128, %rs68;
(EngineCore_DP0 pid=395776) 	.loc	1 240 45                        // quant_slide_tuned_Llama3.2-3B.py:240:45
(EngineCore_DP0 pid=395776) 	cvt.u32.u16 	%r129, %rs66;
(EngineCore_DP0 pid=395776) 	and.b32 	%r130, %r129, 255;
(EngineCore_DP0 pid=395776) 	cvt.u32.u16 	%r131, %rs70;
(EngineCore_DP0 pid=395776) 	.loc	1 241 45                        // quant_slide_tuned_Llama3.2-3B.py:241:45
(EngineCore_DP0 pid=395776) 	cvt.u32.u16 	%r132, %rs67;
(EngineCore_DP0 pid=395776) 	cvt.u32.u16 	%r133, %rs71;
(EngineCore_DP0 pid=395776) 	.loc	1 243 30                        // quant_slide_tuned_Llama3.2-3B.py:243:30
(EngineCore_DP0 pid=395776) 	and.b16 	%rs72, %rs65, 255;
(EngineCore_DP0 pid=395776) 	mul.wide.u16 	%r134, %rs72, 256;
(EngineCore_DP0 pid=395776) 	mul.wide.u16 	%r135, %rs69, 256;
(EngineCore_DP0 pid=395776) 	.loc	1 243 24                        // quant_slide_tuned_Llama3.2-3B.py:243:24
(EngineCore_DP0 pid=395776) 	or.b32 	%r136, %r134, %r127;
(EngineCore_DP0 pid=395776) 	or.b32 	%r137, %r135, %r128;
(EngineCore_DP0 pid=395776) 	.loc	1 243 42                        // quant_slide_tuned_Llama3.2-3B.py:243:42
(EngineCore_DP0 pid=395776) 	shl.b32 	%r138, %r130, 16;
(EngineCore_DP0 pid=395776) 	shl.b32 	%r139, %r131, 16;
(EngineCore_DP0 pid=395776) 	.loc	1 243 36                        // quant_slide_tuned_Llama3.2-3B.py:243:36
(EngineCore_DP0 pid=395776) 	or.b32 	%r140, %r136, %r138;
(EngineCore_DP0 pid=395776) 	or.b32 	%r141, %r137, %r139;
(EngineCore_DP0 pid=395776) 	.loc	1 243 55                        // quant_slide_tuned_Llama3.2-3B.py:243:55
(EngineCore_DP0 pid=395776) 	shl.b32 	%r142, %r132, 24;
(EngineCore_DP0 pid=395776) 	shl.b32 	%r143, %r133, 24;
(EngineCore_DP0 pid=395776) 	.loc	1 243 49                        // quant_slide_tuned_Llama3.2-3B.py:243:49
(EngineCore_DP0 pid=395776) 	or.b32 	%r91, %r140, %r142;
(EngineCore_DP0 pid=395776) 	or.b32 	%r92, %r141, %r143;
(EngineCore_DP0 pid=395776) 	.loc	1 244 29                        // quant_slide_tuned_Llama3.2-3B.py:244:29
(EngineCore_DP0 pid=395776) 	mad.wide.s32 	%rd17, %r93, 4, %rd2;
(EngineCore_DP0 pid=395776) 	.loc	1 244 39                        // quant_slide_tuned_Llama3.2-3B.py:244:39
(EngineCore_DP0 pid=395776) 	// begin inline asm
(EngineCore_DP0 pid=395776) 	@%p18 st.global.v2.b32 [ %rd17 + 0 ], { %r91, %r92 };
(EngineCore_DP0 pid=395776) 	// end inline asm
(EngineCore_DP0 pid=395776) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=395776) 	add.s32 	%r147, %r147, 1024;
(EngineCore_DP0 pid=395776) 	setp.lt.s32 	%p27, %r147, %r15;
(EngineCore_DP0 pid=395776) 	@%p27 bra 	$L__BB0_6;
(EngineCore_DP0 pid=395776) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=395776) 	.loc	1 215 4                         // quant_slide_tuned_Llama3.2-3B.py:215:4
(EngineCore_DP0 pid=395776) 	ret;
(EngineCore_DP0 pid=395776) $L__tmp3:
(EngineCore_DP0 pid=395776) $L__func_end0:
(EngineCore_DP0 pid=395776)                                         // -- End function
(EngineCore_DP0 pid=395776) }
(EngineCore_DP0 pid=395776) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py"
(EngineCore_DP0 pid=395776) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=395776) 	.section	.debug_abbrev
(EngineCore_DP0 pid=395776) 	{
(EngineCore_DP0 pid=395776) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=395776) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=395776) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=395776) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=395776) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=395776) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=395776) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=395776) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=395776) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=395776) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=395776) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=395776) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=395776) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=395776) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=395776) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=395776) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=395776) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=395776) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=395776) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=395776) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=395776) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=395776) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=395776) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=395776) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=395776) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=395776) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=395776) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=395776) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=395776) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=395776) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=395776) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=395776) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=395776) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=395776) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=395776) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=395776) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=395776) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=395776) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=395776) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=395776) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=395776) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=395776) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=395776) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=395776) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=395776) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=395776) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=395776) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=395776) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=395776) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=395776) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=395776) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=395776) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=395776) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=395776) 	}
(EngineCore_DP0 pid=395776) 	.section	.debug_info
(EngineCore_DP0 pid=395776) 	{
(EngineCore_DP0 pid=395776) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=395776) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=395776) .b8 0
(EngineCore_DP0 pid=395776) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=395776) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=395776) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=395776) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=395776) .b8 114
(EngineCore_DP0 pid=395776) .b8 105
(EngineCore_DP0 pid=395776) .b8 116
(EngineCore_DP0 pid=395776) .b8 111
(EngineCore_DP0 pid=395776) .b8 110
(EngineCore_DP0 pid=395776) .b8 0
(EngineCore_DP0 pid=395776) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=395776) .b8 0
(EngineCore_DP0 pid=395776) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=395776) .b8 117
(EngineCore_DP0 pid=395776) .b8 97
(EngineCore_DP0 pid=395776) .b8 110
(EngineCore_DP0 pid=395776) .b8 116
(EngineCore_DP0 pid=395776) .b8 95
(EngineCore_DP0 pid=395776) .b8 115
(EngineCore_DP0 pid=395776) .b8 108
(EngineCore_DP0 pid=395776) .b8 105
(EngineCore_DP0 pid=395776) .b8 100
(EngineCore_DP0 pid=395776) .b8 101
(EngineCore_DP0 pid=395776) .b8 95
(EngineCore_DP0 pid=395776) .b8 116
(EngineCore_DP0 pid=395776) .b8 117
(EngineCore_DP0 pid=395776) .b8 110
(EngineCore_DP0 pid=395776) .b8 101
(EngineCore_DP0 pid=395776) .b8 100
(EngineCore_DP0 pid=395776) .b8 95
(EngineCore_DP0 pid=395776) .b8 76
(EngineCore_DP0 pid=395776) .b8 108
(EngineCore_DP0 pid=395776) .b8 97
(EngineCore_DP0 pid=395776) .b8 109
(EngineCore_DP0 pid=395776) .b8 97
(EngineCore_DP0 pid=395776) .b8 51
(EngineCore_DP0 pid=395776) .b8 46
(EngineCore_DP0 pid=395776) .b8 50
(EngineCore_DP0 pid=395776) .b8 45
(EngineCore_DP0 pid=395776) .b8 51
(EngineCore_DP0 pid=395776) .b8 66
(EngineCore_DP0 pid=395776) .b8 46
(EngineCore_DP0 pid=395776) .b8 112
(EngineCore_DP0 pid=395776) .b8 121
(EngineCore_DP0 pid=395776) .b8 0
(EngineCore_DP0 pid=395776) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=395776) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=395776) .b8 114
(EngineCore_DP0 pid=395776) .b8 111
(EngineCore_DP0 pid=395776) .b8 111
(EngineCore_DP0 pid=395776) .b8 116
(EngineCore_DP0 pid=395776) .b8 47
(EngineCore_DP0 pid=395776) .b8 118
(EngineCore_DP0 pid=395776) .b8 108
(EngineCore_DP0 pid=395776) .b8 108
(EngineCore_DP0 pid=395776) .b8 109
(EngineCore_DP0 pid=395776) .b8 98
(EngineCore_DP0 pid=395776) .b8 101
(EngineCore_DP0 pid=395776) .b8 110
(EngineCore_DP0 pid=395776) .b8 99
(EngineCore_DP0 pid=395776) .b8 104
(EngineCore_DP0 pid=395776) .b8 47
(EngineCore_DP0 pid=395776) .b8 115
(EngineCore_DP0 pid=395776) .b8 108
(EngineCore_DP0 pid=395776) .b8 105
(EngineCore_DP0 pid=395776) .b8 100
(EngineCore_DP0 pid=395776) .b8 101
(EngineCore_DP0 pid=395776) .b8 115
(EngineCore_DP0 pid=395776) .b8 112
(EngineCore_DP0 pid=395776) .b8 97
(EngineCore_DP0 pid=395776) .b8 114
(EngineCore_DP0 pid=395776) .b8 115
(EngineCore_DP0 pid=395776) .b8 101
(EngineCore_DP0 pid=395776) .b8 47
(EngineCore_DP0 pid=395776) .b8 99
(EngineCore_DP0 pid=395776) .b8 115
(EngineCore_DP0 pid=395776) .b8 114
(EngineCore_DP0 pid=395776) .b8 99
(EngineCore_DP0 pid=395776) .b8 47
(EngineCore_DP0 pid=395776) .b8 102
(EngineCore_DP0 pid=395776) .b8 117
(EngineCore_DP0 pid=395776) .b8 115
(EngineCore_DP0 pid=395776) .b8 101
(EngineCore_DP0 pid=395776) .b8 100
(EngineCore_DP0 pid=395776) .b8 95
(EngineCore_DP0 pid=395776) .b8 113
(EngineCore_DP0 pid=395776) .b8 117
(EngineCore_DP0 pid=395776) .b8 97
(EngineCore_DP0 pid=395776) .b8 110
(EngineCore_DP0 pid=395776) .b8 116
(EngineCore_DP0 pid=395776) .b8 95
(EngineCore_DP0 pid=395776) .b8 115
(EngineCore_DP0 pid=395776) .b8 108
(EngineCore_DP0 pid=395776) .b8 105
(EngineCore_DP0 pid=395776) .b8 100
(EngineCore_DP0 pid=395776) .b8 101
(EngineCore_DP0 pid=395776) .b8 95
(EngineCore_DP0 pid=395776) .b8 116
(EngineCore_DP0 pid=395776) .b8 114
(EngineCore_DP0 pid=395776) .b8 105
(EngineCore_DP0 pid=395776) .b8 116
(EngineCore_DP0 pid=395776) .b8 111
(EngineCore_DP0 pid=395776) .b8 110
(EngineCore_DP0 pid=395776) .b8 47
(EngineCore_DP0 pid=395776) .b8 98
(EngineCore_DP0 pid=395776) .b8 117
(EngineCore_DP0 pid=395776) .b8 105
(EngineCore_DP0 pid=395776) .b8 108
(EngineCore_DP0 pid=395776) .b8 100
(EngineCore_DP0 pid=395776) .b8 47
(EngineCore_DP0 pid=395776) .b8 71
(EngineCore_DP0 pid=395776) .b8 66
(EngineCore_DP0 pid=395776) .b8 49
(EngineCore_DP0 pid=395776) .b8 48
(EngineCore_DP0 pid=395776) .b8 95
(EngineCore_DP0 pid=395776) .b8 99
(EngineCore_DP0 pid=395776) .b8 99
(EngineCore_DP0 pid=395776) .b8 49
(EngineCore_DP0 pid=395776) .b8 50
(EngineCore_DP0 pid=395776) .b8 49
(EngineCore_DP0 pid=395776) .b8 95
(EngineCore_DP0 pid=395776) .b8 112
(EngineCore_DP0 pid=395776) .b8 121
(EngineCore_DP0 pid=395776) .b8 51
(EngineCore_DP0 pid=395776) .b8 49
(EngineCore_DP0 pid=395776) .b8 50
(EngineCore_DP0 pid=395776) .b8 95
(EngineCore_DP0 pid=395776) .b8 99
(EngineCore_DP0 pid=395776) .b8 117
(EngineCore_DP0 pid=395776) .b8 49
(EngineCore_DP0 pid=395776) .b8 50
(EngineCore_DP0 pid=395776) .b8 57
(EngineCore_DP0 pid=395776) .b8 95
(EngineCore_DP0 pid=395776) .b8 97
(EngineCore_DP0 pid=395776) .b8 97
(EngineCore_DP0 pid=395776) .b8 114
(EngineCore_DP0 pid=395776) .b8 99
(EngineCore_DP0 pid=395776) .b8 104
(EngineCore_DP0 pid=395776) .b8 54
(EngineCore_DP0 pid=395776) .b8 52
(EngineCore_DP0 pid=395776) .b8 0
(EngineCore_DP0 pid=395776) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=395776) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=395776) .b8 113
(EngineCore_DP0 pid=395776) .b8 117
(EngineCore_DP0 pid=395776) .b8 97
(EngineCore_DP0 pid=395776) .b8 110
(EngineCore_DP0 pid=395776) .b8 116
(EngineCore_DP0 pid=395776) .b8 95
(EngineCore_DP0 pid=395776) .b8 115
(EngineCore_DP0 pid=395776) .b8 108
(EngineCore_DP0 pid=395776) .b8 105
(EngineCore_DP0 pid=395776) .b8 100
(EngineCore_DP0 pid=395776) .b8 101
(EngineCore_DP0 pid=395776) .b8 95
(EngineCore_DP0 pid=395776) .b8 102
(EngineCore_DP0 pid=395776) .b8 112
(EngineCore_DP0 pid=395776) .b8 56
(EngineCore_DP0 pid=395776) .b8 95
(EngineCore_DP0 pid=395776) .b8 107
(EngineCore_DP0 pid=395776) .b8 101
(EngineCore_DP0 pid=395776) .b8 114
(EngineCore_DP0 pid=395776) .b8 110
(EngineCore_DP0 pid=395776) .b8 101
(EngineCore_DP0 pid=395776) .b8 108
(EngineCore_DP0 pid=395776) .b8 0
(EngineCore_DP0 pid=395776) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=395776) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=395776) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=395776) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=395776) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=395776) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=395776) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=395776) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=395776) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=395776) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=395776) .b8 205                                 // DW_AT_call_line
(EngineCore_DP0 pid=395776) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=395776) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=395776) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=395776) 	}
(EngineCore_DP0 pid=395776) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=395776) 
(EngineCore_DP0 pid=395776) ================================================================
(EngineCore_DP0 pid=395776) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=395776) 
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpwwgvhaof.ptx', '-o', '/tmp/tmpwwgvhaof.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866] 
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866] 
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866] 
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpwwgvhaof.ptx -o /tmp/tmpwwgvhaof.ptx.o
(EngineCore_DP0 pid=395776) ERROR 01-25 20:07:44 [core.py:866] 

STDERR:
[2026-01-25 20:07:16] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:07:16] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:07:16] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:07:16] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:07:16] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:07:16] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:07:16] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:07:16] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:07:16] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:07:16] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:07:16] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:07:16] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:07:16] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:07:16] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:07:20] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:07:20] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:07:20] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:07:20] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:07:20] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:07:20] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:07:20] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:07:20] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:07:20] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:07:20] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:07:20] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:07:20] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:07:20] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:07:20] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=395776) [2026-01-25 20:07:21] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=395776) [2026-01-25 20:07:21] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=395776) [2026-01-25 20:07:21] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=395776) [2026-01-25 20:07:21] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=395776) [2026-01-25 20:07:21] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=395776) [2026-01-25 20:07:21] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=395776) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=395776) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:21<00:00, 21.13s/it]
(EngineCore_DP0 pid=395776) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:21<00:00, 21.13s/it]
(EngineCore_DP0 pid=395776) 
(EngineCore_DP0 pid=395776) [2026-01-25 20:07:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4096] -> 1D uint8
(EngineCore_DP0 pid=395776) [2026-01-25 20:07:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 13107200 bytes
(EngineCore_DP0 pid=395776) [2026-01-25 20:07:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4096] -> 1D uint8
(EngineCore_DP0 pid=395776) [2026-01-25 20:07:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 7864320 bytes
(EngineCore_DP0 pid=395776) [2026-01-25 20:07:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4096] -> 1D uint8
(EngineCore_DP0 pid=395776) [2026-01-25 20:07:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 41943040 bytes
(EngineCore_DP0 pid=395776) [2026-01-25 20:07:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 10944] -> 1D uint8
(EngineCore_DP0 pid=395776) [2026-01-25 20:07:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 21037056 bytes
(EngineCore_DP0 pid=395776) Process EngineCore_DP0:
(EngineCore_DP0 pid=395776) Traceback (most recent call last):
(EngineCore_DP0 pid=395776)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=395776)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=395776)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=395776)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=395776) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpwwgvhaof.ptx', '-o', '/tmp/tmpwwgvhaof.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=395776) 
(EngineCore_DP0 pid=395776) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=395776) 
(EngineCore_DP0 pid=395776) Traceback (most recent call last):
(EngineCore_DP0 pid=395776)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=395776)     self.run()
(EngineCore_DP0 pid=395776)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=395776)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=395776)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=395776)     raise e
(EngineCore_DP0 pid=395776)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=395776)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=395776)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=395776)     super().__init__(
(EngineCore_DP0 pid=395776)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=395776)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=395776)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=395776)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=395776)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=395776)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=395776)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=395776)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=395776)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=395776)     return func(*args, **kwargs)
(EngineCore_DP0 pid=395776)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=395776)     return func(*args, **kwargs)
(EngineCore_DP0 pid=395776)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=395776)     self.model_runner.profile_run()
(EngineCore_DP0 pid=395776)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=395776)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=395776)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=395776)     return func(*args, **kwargs)
(EngineCore_DP0 pid=395776)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=395776)     outputs = self.model(
(EngineCore_DP0 pid=395776)               ^^^^^^^^^^^
(EngineCore_DP0 pid=395776)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=395776)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=395776)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=395776)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=395776)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=395776)     model_output = self.model(
(EngineCore_DP0 pid=395776)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=395776)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=395776)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=395776)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=395776)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=395776)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=395776)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=395776)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=395776)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=395776)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=395776)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=395776)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=395776)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=395776)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=395776)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=395776)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=395776)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=395776)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=395776)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=395776)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=395776)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=395776)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=395776)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=395776)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=395776)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=395776)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=395776)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=395776)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=395776)     return self._linear_fn(
(EngineCore_DP0 pid=395776)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=395776)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=395776)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=395776)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=395776)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=395776)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=395776)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=395776)     return fn(input, L)
(EngineCore_DP0 pid=395776)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=395776)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=395776)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=395776)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=395776)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=395776)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=395776)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=395776)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=395776)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=395776)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=395776)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=395776)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=395776)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=395776)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=395776)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=395776)     raise PTXASError(error)
(EngineCore_DP0 pid=395776) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=395776) `ptxas` stderr:
(EngineCore_DP0 pid=395776) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=395776) 
(EngineCore_DP0 pid=395776) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpwwgvhaof.ptx -o /tmp/tmpwwgvhaof.ptx.o
(EngineCore_DP0 pid=395776) 
[rank0]:[W125 20:07:44.507216479 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=16384

========== M=32768 ==========
Time: 2026-01-25 20:07:45
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-3B-FP8_M32768.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:08:00 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 20:08:00 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=396569) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=396569) 
(EngineCore_DP0 pid=396569) 
(EngineCore_DP0 pid=396569) ================================================================
(EngineCore_DP0 pid=396569) Internal Triton PTX codegen error
(EngineCore_DP0 pid=396569) `ptxas` stderr:
(EngineCore_DP0 pid=396569) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=396569) 
(EngineCore_DP0 pid=396569) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp0t31dqa2.ptx -o /tmp/tmp0t31dqa2.ptx.o
(EngineCore_DP0 pid=396569) 
(EngineCore_DP0 pid=396569) 
(EngineCore_DP0 pid=396569) //
(EngineCore_DP0 pid=396569) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=396569) //
(EngineCore_DP0 pid=396569) 
(EngineCore_DP0 pid=396569) .version 8.7
(EngineCore_DP0 pid=396569) .target sm_121a
(EngineCore_DP0 pid=396569) .address_size 64
(EngineCore_DP0 pid=396569) 
(EngineCore_DP0 pid=396569) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=396569) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=396569)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=396569) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=396569) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=396569) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=396569) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=396569) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=396569) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=396569) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=396569) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=396569) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=396569) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=396569) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=396569) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=396569) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=396569) )
(EngineCore_DP0 pid=396569) .reqntid 512
(EngineCore_DP0 pid=396569) {
(EngineCore_DP0 pid=396569) 	.reg .pred 	%p<44>;
(EngineCore_DP0 pid=396569) 	.reg .b16 	%rs<74>;
(EngineCore_DP0 pid=396569) 	.reg .b32 	%r<199>;
(EngineCore_DP0 pid=396569) 	.reg .b64 	%rd<25>;
(EngineCore_DP0 pid=396569) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=396569) $L__func_begin0:
(EngineCore_DP0 pid=396569) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=396569) 
(EngineCore_DP0 pid=396569) // %bb.0:
(EngineCore_DP0 pid=396569) 	ld.param.b32 	%r29, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=396569) 	ld.param.b32 	%r28, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=396569) 	ld.param.b32 	%r27, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=396569) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=396569) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=396569) $L__tmp0:
(EngineCore_DP0 pid=396569) 	.loc	1 191 24                        // quant_slide_tuned_Llama3.2-3B.py:191:24
(EngineCore_DP0 pid=396569) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=396569) 	ld.param.b32 	%r31, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=396569) 	.loc	1 196 26                        // quant_slide_tuned_Llama3.2-3B.py:196:26
(EngineCore_DP0 pid=396569) 	mul.lo.s32 	%r32, %r31, %r1;
(EngineCore_DP0 pid=396569) 	.loc	1 196 20                        // quant_slide_tuned_Llama3.2-3B.py:196:20
(EngineCore_DP0 pid=396569) 	mad.wide.s32 	%rd1, %r32, 2, %rd4;
(EngineCore_DP0 pid=396569) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=396569) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=396569) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=396569) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=396569) 	setp.lt.s32 	%p1, %r28, 1;
(EngineCore_DP0 pid=396569) 	mov.b32 	%r197, 0f2B8CBCCC;
(EngineCore_DP0 pid=396569) 	setp.eq.b32 	%p43, %r2, 0;
(EngineCore_DP0 pid=396569) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=396569) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=396569) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=396569) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=396569) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=396569) 	shr.u32 	%r41, %r2, 3;
(EngineCore_DP0 pid=396569) 	and.b32 	%r42, %r41, 60;
(EngineCore_DP0 pid=396569) 	mov.b32 	%r43, global_smem;
(EngineCore_DP0 pid=396569) 	add.s32 	%r53, %r43, %r42;
(EngineCore_DP0 pid=396569) 	shl.b32 	%r44, %r2, 2;
(EngineCore_DP0 pid=396569) 	add.s32 	%r56, %r43, %r44;
(EngineCore_DP0 pid=396569) 	mov.b32 	%r49, 0;
(EngineCore_DP0 pid=396569) 	mov.b32 	%r195, 0f00000000;
(EngineCore_DP0 pid=396569) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=396569) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=396569) 	mov.b32 	%r196, %r49;
(EngineCore_DP0 pid=396569) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=396569) 	.loc	1 203 22                        // quant_slide_tuned_Llama3.2-3B.py:203:22
(EngineCore_DP0 pid=396569) 	add.s32 	%r59, %r4, %r196;
(EngineCore_DP0 pid=396569) 	setp.lt.s32 	%p2, %r59, %r27;
(EngineCore_DP0 pid=396569) 	.loc	1 204 29                        // quant_slide_tuned_Llama3.2-3B.py:204:29
(EngineCore_DP0 pid=396569) 	mad.wide.s32 	%rd6, %r59, 2, %rd1;
(EngineCore_DP0 pid=396569) 	.loc	1 204 21                        // quant_slide_tuned_Llama3.2-3B.py:204:21
(EngineCore_DP0 pid=396569) 	// begin inline asm
(EngineCore_DP0 pid=396569) 	mov.u32 %r45, %r49;
(EngineCore_DP0 pid=396569) 	mov.u32 %r46, %r49;
(EngineCore_DP0 pid=396569) 	mov.u32 %r47, %r49;
(EngineCore_DP0 pid=396569) 	mov.u32 %r48, %r49;
(EngineCore_DP0 pid=396569) 	@%p2 ld.global.v4.b32 { %r45, %r46, %r47, %r48 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=396569) 	// end inline asm
(EngineCore_DP0 pid=396569) 	mov.b32 	{%rs1, %rs2}, %r45;
(EngineCore_DP0 pid=396569) 	mov.b32 	{%rs3, %rs4}, %r46;
(EngineCore_DP0 pid=396569) 	mov.b32 	{%rs5, %rs6}, %r47;
(EngineCore_DP0 pid=396569) 	mov.b32 	{%rs7, %rs8}, %r48;
(EngineCore_DP0 pid=396569) 	.loc	1 205 50                        // quant_slide_tuned_Llama3.2-3B.py:205:50
(EngineCore_DP0 pid=396569) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=396569) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=396569) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=396569) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=396569) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=396569) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=396569) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=396569) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=396569) $L__tmp1:
(EngineCore_DP0 pid=396569) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=396569) 	bar.sync 	0;
(EngineCore_DP0 pid=396569) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=396569) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=396569) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=396569) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=396569) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=396569) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=396569) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=396569) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=396569) 	cvt.f32.bf16 	%r60, %rs23;
(EngineCore_DP0 pid=396569) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=396569) 	shfl.sync.bfly.b32 	%r61, %r60, 16, 31, -1;
(EngineCore_DP0 pid=396569) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=396569) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=396569) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=396569) 	shfl.sync.bfly.b32 	%r63, %r62, 8, 31, -1;
(EngineCore_DP0 pid=396569) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=396569) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=396569) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=396569) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=396569) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=396569) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=396569) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=396569) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=396569) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=396569) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=396569) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=396569) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=396569) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=396569) 	max.f32 	%r54, %r68, %r69;
(EngineCore_DP0 pid=396569) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=396569) 	// begin inline asm
(EngineCore_DP0 pid=396569) 	@%p3 st.shared.b32 [ %r53 + 0 ], %r54;
(EngineCore_DP0 pid=396569) 	// end inline asm
(EngineCore_DP0 pid=396569) 	bar.sync 	0;
(EngineCore_DP0 pid=396569) 	// begin inline asm
(EngineCore_DP0 pid=396569) 	@%p4 ld.shared.b32 %r55, [ %r56 + 0 ];
(EngineCore_DP0 pid=396569) 	// end inline asm
(EngineCore_DP0 pid=396569) 	shfl.sync.bfly.b32 	%r70, %r55, 8, 31, -1;
(EngineCore_DP0 pid=396569) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=396569) 	max.f32 	%r71, %r55, %r70;
(EngineCore_DP0 pid=396569) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=396569) 	shfl.sync.bfly.b32 	%r72, %r71, 4, 31, -1;
(EngineCore_DP0 pid=396569) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=396569) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=396569) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=396569) 	shfl.sync.bfly.b32 	%r74, %r73, 2, 31, -1;
(EngineCore_DP0 pid=396569) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=396569) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=396569) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=396569) 	shfl.sync.bfly.b32 	%r76, %r75, 1, 31, -1;
(EngineCore_DP0 pid=396569) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=396569) 	max.f32 	%r58, %r75, %r76;
(EngineCore_DP0 pid=396569) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=396569) 	// begin inline asm
(EngineCore_DP0 pid=396569) 	@%p43 st.shared.b32 [ %r56 + 0 ], %r58;
(EngineCore_DP0 pid=396569) 	// end inline asm
(EngineCore_DP0 pid=396569) 	bar.sync 	0;
(EngineCore_DP0 pid=396569) 	ld.shared.b32 	%r77, [global_smem];
(EngineCore_DP0 pid=396569) $L__tmp2:
(EngineCore_DP0 pid=396569) 	.loc	1 205 36                        // quant_slide_tuned_Llama3.2-3B.py:205:36
(EngineCore_DP0 pid=396569) 	max.f32 	%r195, %r195, %r77;
(EngineCore_DP0 pid=396569) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=396569) 	add.s32 	%r196, %r196, 4096;
(EngineCore_DP0 pid=396569) 	setp.lt.s32 	%p6, %r196, %r28;
(EngineCore_DP0 pid=396569) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=396569) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=396569) 	.loc	1 207 32                        // quant_slide_tuned_Llama3.2-3B.py:207:32
(EngineCore_DP0 pid=396569) 	max.f32 	%r197, %r195, 0f2B8CBCCC;
(EngineCore_DP0 pid=396569) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=396569) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-3B.py:0:32
(EngineCore_DP0 pid=396569) 	mov.b32 	%r79, 0f43E00000;
(EngineCore_DP0 pid=396569) 	.loc	1 208 32                        // quant_slide_tuned_Llama3.2-3B.py:208:32
(EngineCore_DP0 pid=396569) 	div.full.f32 	%r80, %r197, %r79;
(EngineCore_DP0 pid=396569) 	.loc	1 208 41                        // quant_slide_tuned_Llama3.2-3B.py:208:41
(EngineCore_DP0 pid=396569) 	max.f32 	%r78, %r80, 0f36924925;
(EngineCore_DP0 pid=396569) 	.loc	1 210 25                        // quant_slide_tuned_Llama3.2-3B.py:210:25
(EngineCore_DP0 pid=396569) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=396569) 	.loc	1 210 30                        // quant_slide_tuned_Llama3.2-3B.py:210:30
(EngineCore_DP0 pid=396569) 	// begin inline asm
(EngineCore_DP0 pid=396569) 	@%p43 st.global.b32 [ %rd7 + 0 ], { %r78 };
(EngineCore_DP0 pid=396569) 	// end inline asm
(EngineCore_DP0 pid=396569) 	.loc	1 213 29                        // quant_slide_tuned_Llama3.2-3B.py:213:29
(EngineCore_DP0 pid=396569) 	shl.b32 	%r15, %r29, 1;
(EngineCore_DP0 pid=396569) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=396569) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=396569) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=396569) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=396569) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-3B.py:0:41
(EngineCore_DP0 pid=396569) 	ld.param.b32 	%r33, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=396569) 	shr.s32 	%r34, %r33, 31;
(EngineCore_DP0 pid=396569) 	shr.u32 	%r35, %r34, 30;
(EngineCore_DP0 pid=396569) 	add.s32 	%r36, %r33, %r35;
(EngineCore_DP0 pid=396569) 	shr.s32 	%r37, %r36, 2;
(EngineCore_DP0 pid=396569) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=396569) 	mul.lo.s32 	%r38, %r37, %r1;
(EngineCore_DP0 pid=396569) 	mad.wide.s32 	%rd2, %r38, 4, %rd5;
(EngineCore_DP0 pid=396569) 	div.full.f32 	%r14, %r79, %r197;
(EngineCore_DP0 pid=396569) 	shl.b32 	%r16, %r3, 2;
(EngineCore_DP0 pid=396569) 	mov.b32 	%r198, 0;
(EngineCore_DP0 pid=396569) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=396569)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=396569) 	.loc	1 216 31                        // quant_slide_tuned_Llama3.2-3B.py:216:31
(EngineCore_DP0 pid=396569) 	add.s32 	%r102, %r16, %r198;
(EngineCore_DP0 pid=396569) 	.loc	1 217 30                        // quant_slide_tuned_Llama3.2-3B.py:217:30
(EngineCore_DP0 pid=396569) 	add.s32 	%r103, %r198, 1;
(EngineCore_DP0 pid=396569) 	setp.lt.s32 	%p25, %r102, %r15;
(EngineCore_DP0 pid=396569) 	.loc	1 220 24                        // quant_slide_tuned_Llama3.2-3B.py:220:24
(EngineCore_DP0 pid=396569) 	shr.u32 	%r104, %r102, 1;
(EngineCore_DP0 pid=396569) 	.loc	1 221 23                        // quant_slide_tuned_Llama3.2-3B.py:221:23
(EngineCore_DP0 pid=396569) 	shr.u32 	%r105, %r103, 31;
(EngineCore_DP0 pid=396569) 	add.s32 	%r106, %r103, %r105;
(EngineCore_DP0 pid=396569) 	and.b32 	%r107, %r106, 2147483646;
(EngineCore_DP0 pid=396569) 	sub.s32 	%r108, %r103, %r107;
(EngineCore_DP0 pid=396569) 	.loc	1 222 30                        // quant_slide_tuned_Llama3.2-3B.py:222:30
(EngineCore_DP0 pid=396569) 	shl.b32 	%r109, %r108, 1;
(EngineCore_DP0 pid=396569) 	.loc	1 222 22                        // quant_slide_tuned_Llama3.2-3B.py:222:22
(EngineCore_DP0 pid=396569) 	mul.lo.s32 	%r110, %r104, 6;
(EngineCore_DP0 pid=396569) 	add.s32 	%r111, %r110, 6;
(EngineCore_DP0 pid=396569) 	.loc	1 222 26                        // quant_slide_tuned_Llama3.2-3B.py:222:26
(EngineCore_DP0 pid=396569) 	add.s32 	%r112, %r110, %r109;
(EngineCore_DP0 pid=396569) 	add.s32 	%r113, %r111, %r109;
(EngineCore_DP0 pid=396569) 	.loc	1 225 53                        // quant_slide_tuned_Llama3.2-3B.py:225:53
(EngineCore_DP0 pid=396569) 	setp.lt.s32 	%p26, %r110, %r27;
(EngineCore_DP0 pid=396569) 	setp.lt.s32 	%p27, %r112, %r27;
(EngineCore_DP0 pid=396569) 	setp.lt.s32 	%p28, %r111, %r27;
(EngineCore_DP0 pid=396569) 	setp.lt.s32 	%p29, %r113, %r27;
(EngineCore_DP0 pid=396569) 	.loc	1 225 37                        // quant_slide_tuned_Llama3.2-3B.py:225:37
(EngineCore_DP0 pid=396569) 	and.pred 	%p9, %p25, %p26;
(EngineCore_DP0 pid=396569) 	and.pred 	%p10, %p25, %p27;
(EngineCore_DP0 pid=396569) 	and.pred 	%p11, %p25, %p28;
(EngineCore_DP0 pid=396569) 	and.pred 	%p12, %p25, %p29;
(EngineCore_DP0 pid=396569) 	.loc	1 224 29                        // quant_slide_tuned_Llama3.2-3B.py:224:29
(EngineCore_DP0 pid=396569) 	mad.wide.s32 	%rd8, %r110, 2, %rd1;
(EngineCore_DP0 pid=396569) 	mad.wide.s32 	%rd9, %r112, 2, %rd1;
(EngineCore_DP0 pid=396569) 	mad.wide.s32 	%rd10, %r111, 2, %rd1;
(EngineCore_DP0 pid=396569) 	mad.wide.s32 	%rd11, %r113, 2, %rd1;
(EngineCore_DP0 pid=396569) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=396569) 	.loc	1 224 21                        // quant_slide_tuned_Llama3.2-3B.py:224:21
(EngineCore_DP0 pid=396569) 	// begin inline asm
(EngineCore_DP0 pid=396569) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=396569) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=396569) 	// end inline asm
(EngineCore_DP0 pid=396569) 	// begin inline asm
(EngineCore_DP0 pid=396569) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=396569) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=396569) 	// end inline asm
(EngineCore_DP0 pid=396569) 	// begin inline asm
(EngineCore_DP0 pid=396569) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=396569) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=396569) 	// end inline asm
(EngineCore_DP0 pid=396569) 	// begin inline asm
(EngineCore_DP0 pid=396569) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=396569) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=396569) 	// end inline asm
(EngineCore_DP0 pid=396569) 	.loc	1 225 79                        // quant_slide_tuned_Llama3.2-3B.py:225:79
(EngineCore_DP0 pid=396569) 	cvt.f32.bf16 	%r114, %rs24;
(EngineCore_DP0 pid=396569) 	cvt.f32.bf16 	%r115, %rs26;
(EngineCore_DP0 pid=396569) 	cvt.f32.bf16 	%r116, %rs28;
(EngineCore_DP0 pid=396569) 	cvt.f32.bf16 	%r117, %rs30;
(EngineCore_DP0 pid=396569) 	.loc	1 231 48                        // quant_slide_tuned_Llama3.2-3B.py:231:48
(EngineCore_DP0 pid=396569) 	or.b32 	%r118, %r112, 1;
(EngineCore_DP0 pid=396569) 	or.b32 	%r119, %r113, 1;
(EngineCore_DP0 pid=396569) 	or.b32 	%r120, %r113, 2;
(EngineCore_DP0 pid=396569) 	or.b32 	%r121, %r113, 3;
(EngineCore_DP0 pid=396569) 	or.b32 	%r122, %r110, 1;
(EngineCore_DP0 pid=396569) 	add.s32 	%r123, %r110, 7;
(EngineCore_DP0 pid=396569) 	or.b32 	%r124, %r110, 2;
(EngineCore_DP0 pid=396569) 	or.b32 	%r125, %r110, 3;
(EngineCore_DP0 pid=396569) 	.loc	1 231 53                        // quant_slide_tuned_Llama3.2-3B.py:231:53
(EngineCore_DP0 pid=396569) 	setp.lt.s32 	%p30, %r121, %r27;
(EngineCore_DP0 pid=396569) 	setp.lt.s32 	%p31, %r120, %r27;
(EngineCore_DP0 pid=396569) 	setp.lt.s32 	%p32, %r119, %r27;
(EngineCore_DP0 pid=396569) 	setp.lt.s32 	%p33, %r118, %r27;
(EngineCore_DP0 pid=396569) 	setp.lt.s32 	%p34, %r125, %r27;
(EngineCore_DP0 pid=396569) 	setp.lt.s32 	%p35, %r124, %r27;
(EngineCore_DP0 pid=396569) 	setp.lt.s32 	%p36, %r123, %r27;
(EngineCore_DP0 pid=396569) 	setp.lt.s32 	%p37, %r122, %r27;
(EngineCore_DP0 pid=396569) 	.loc	1 227 37                        // quant_slide_tuned_Llama3.2-3B.py:227:37
(EngineCore_DP0 pid=396569) 	and.pred 	%p13, %p25, %p37;
(EngineCore_DP0 pid=396569) 	and.pred 	%p14, %p25, %p33;
(EngineCore_DP0 pid=396569) 	and.pred 	%p15, %p25, %p36;
(EngineCore_DP0 pid=396569) 	and.pred 	%p16, %p25, %p32;
(EngineCore_DP0 pid=396569) 	.loc	1 226 39                        // quant_slide_tuned_Llama3.2-3B.py:226:39
(EngineCore_DP0 pid=396569) 	add.s64 	%rd12, %rd8, 2;
(EngineCore_DP0 pid=396569) 	add.s64 	%rd13, %rd9, 2;
(EngineCore_DP0 pid=396569) 	add.s64 	%rd14, %rd10, 2;
(EngineCore_DP0 pid=396569) 	add.s64 	%rd15, %rd11, 2;
(EngineCore_DP0 pid=396569) 	.loc	1 226 21                        // quant_slide_tuned_Llama3.2-3B.py:226:21
(EngineCore_DP0 pid=396569) 	// begin inline asm
(EngineCore_DP0 pid=396569) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=396569) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=396569) 	// end inline asm
(EngineCore_DP0 pid=396569) 	// begin inline asm
(EngineCore_DP0 pid=396569) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=396569) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=396569) 	// end inline asm
(EngineCore_DP0 pid=396569) 	// begin inline asm
(EngineCore_DP0 pid=396569) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=396569) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=396569) 	// end inline asm
(EngineCore_DP0 pid=396569) 	// begin inline asm
(EngineCore_DP0 pid=396569) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=396569) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=396569) 	// end inline asm
(EngineCore_DP0 pid=396569) 	.loc	1 227 79                        // quant_slide_tuned_Llama3.2-3B.py:227:79
(EngineCore_DP0 pid=396569) 	cvt.f32.bf16 	%r126, %rs32;
(EngineCore_DP0 pid=396569) 	cvt.f32.bf16 	%r127, %rs34;
(EngineCore_DP0 pid=396569) 	cvt.f32.bf16 	%r128, %rs36;
(EngineCore_DP0 pid=396569) 	cvt.f32.bf16 	%r129, %rs38;
(EngineCore_DP0 pid=396569) 	.loc	1 229 48                        // quant_slide_tuned_Llama3.2-3B.py:229:48
(EngineCore_DP0 pid=396569) 	add.s32 	%r130, %r112, 2;
(EngineCore_DP0 pid=396569) 	add.s32 	%r131, %r110, 8;
(EngineCore_DP0 pid=396569) 	.loc	1 229 53                        // quant_slide_tuned_Llama3.2-3B.py:229:53
(EngineCore_DP0 pid=396569) 	setp.lt.s32 	%p38, %r130, %r27;
(EngineCore_DP0 pid=396569) 	setp.lt.s32 	%p39, %r131, %r27;
(EngineCore_DP0 pid=396569) 	.loc	1 229 37                        // quant_slide_tuned_Llama3.2-3B.py:229:37
(EngineCore_DP0 pid=396569) 	and.pred 	%p17, %p25, %p35;
(EngineCore_DP0 pid=396569) 	and.pred 	%p18, %p25, %p38;
(EngineCore_DP0 pid=396569) 	and.pred 	%p19, %p25, %p39;
(EngineCore_DP0 pid=396569) 	and.pred 	%p20, %p25, %p31;
(EngineCore_DP0 pid=396569) 	.loc	1 228 39                        // quant_slide_tuned_Llama3.2-3B.py:228:39
(EngineCore_DP0 pid=396569) 	add.s64 	%rd16, %rd8, 4;
(EngineCore_DP0 pid=396569) 	add.s64 	%rd17, %rd9, 4;
(EngineCore_DP0 pid=396569) 	add.s64 	%rd18, %rd10, 4;
(EngineCore_DP0 pid=396569) 	add.s64 	%rd19, %rd11, 4;
(EngineCore_DP0 pid=396569) 	.loc	1 228 21                        // quant_slide_tuned_Llama3.2-3B.py:228:21
(EngineCore_DP0 pid=396569) 	// begin inline asm
(EngineCore_DP0 pid=396569) 	mov.u16 %rs40, %rs25;
(EngineCore_DP0 pid=396569) 	@%p17 ld.global.b16 { %rs40 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=396569) 	// end inline asm
(EngineCore_DP0 pid=396569) 	// begin inline asm
(EngineCore_DP0 pid=396569) 	mov.u16 %rs42, %rs25;
(EngineCore_DP0 pid=396569) 	@%p18 ld.global.b16 { %rs42 }, [ %rd17 + 0 ];
(EngineCore_DP0 pid=396569) 	// end inline asm
(EngineCore_DP0 pid=396569) 	// begin inline asm
(EngineCore_DP0 pid=396569) 	mov.u16 %rs44, %rs25;
(EngineCore_DP0 pid=396569) 	@%p19 ld.global.b16 { %rs44 }, [ %rd18 + 0 ];
(EngineCore_DP0 pid=396569) 	// end inline asm
(EngineCore_DP0 pid=396569) 	// begin inline asm
(EngineCore_DP0 pid=396569) 	mov.u16 %rs46, %rs25;
(EngineCore_DP0 pid=396569) 	@%p20 ld.global.b16 { %rs46 }, [ %rd19 + 0 ];
(EngineCore_DP0 pid=396569) 	// end inline asm
(EngineCore_DP0 pid=396569) 	.loc	1 229 79                        // quant_slide_tuned_Llama3.2-3B.py:229:79
(EngineCore_DP0 pid=396569) 	cvt.f32.bf16 	%r132, %rs40;
(EngineCore_DP0 pid=396569) 	cvt.f32.bf16 	%r133, %rs42;
(EngineCore_DP0 pid=396569) 	cvt.f32.bf16 	%r134, %rs44;
(EngineCore_DP0 pid=396569) 	cvt.f32.bf16 	%r135, %rs46;
(EngineCore_DP0 pid=396569) 	.loc	1 231 48                        // quant_slide_tuned_Llama3.2-3B.py:231:48
(EngineCore_DP0 pid=396569) 	add.s32 	%r136, %r112, 3;
(EngineCore_DP0 pid=396569) 	add.s32 	%r137, %r110, 9;
(EngineCore_DP0 pid=396569) 	.loc	1 231 53                        // quant_slide_tuned_Llama3.2-3B.py:231:53
(EngineCore_DP0 pid=396569) 	setp.lt.s32 	%p40, %r136, %r27;
(EngineCore_DP0 pid=396569) 	setp.lt.s32 	%p41, %r137, %r27;
(EngineCore_DP0 pid=396569) 	.loc	1 231 37                        // quant_slide_tuned_Llama3.2-3B.py:231:37
(EngineCore_DP0 pid=396569) 	and.pred 	%p21, %p25, %p34;
(EngineCore_DP0 pid=396569) 	and.pred 	%p22, %p25, %p40;
(EngineCore_DP0 pid=396569) 	and.pred 	%p23, %p25, %p41;
(EngineCore_DP0 pid=396569) 	and.pred 	%p24, %p25, %p30;
(EngineCore_DP0 pid=396569) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-3B.py:230:39
(EngineCore_DP0 pid=396569) 	add.s64 	%rd20, %rd8, 6;
(EngineCore_DP0 pid=396569) 	add.s64 	%rd21, %rd9, 6;
(EngineCore_DP0 pid=396569) 	add.s64 	%rd22, %rd10, 6;
(EngineCore_DP0 pid=396569) 	add.s64 	%rd23, %rd11, 6;
(EngineCore_DP0 pid=396569) 	.loc	1 230 21                        // quant_slide_tuned_Llama3.2-3B.py:230:21
(EngineCore_DP0 pid=396569) 	// begin inline asm
(EngineCore_DP0 pid=396569) 	mov.u16 %rs48, %rs25;
(EngineCore_DP0 pid=396569) 	@%p21 ld.global.b16 { %rs48 }, [ %rd20 + 0 ];
(EngineCore_DP0 pid=396569) 	// end inline asm
(EngineCore_DP0 pid=396569) 	// begin inline asm
(EngineCore_DP0 pid=396569) 	mov.u16 %rs50, %rs25;
(EngineCore_DP0 pid=396569) 	@%p22 ld.global.b16 { %rs50 }, [ %rd21 + 0 ];
(EngineCore_DP0 pid=396569) 	// end inline asm
(EngineCore_DP0 pid=396569) 	// begin inline asm
(EngineCore_DP0 pid=396569) 	mov.u16 %rs52, %rs25;
(EngineCore_DP0 pid=396569) 	@%p23 ld.global.b16 { %rs52 }, [ %rd22 + 0 ];
(EngineCore_DP0 pid=396569) 	// end inline asm
(EngineCore_DP0 pid=396569) 	// begin inline asm
(EngineCore_DP0 pid=396569) 	mov.u16 %rs54, %rs25;
(EngineCore_DP0 pid=396569) 	@%p24 ld.global.b16 { %rs54 }, [ %rd23 + 0 ];
(EngineCore_DP0 pid=396569) 	// end inline asm
(EngineCore_DP0 pid=396569) 	.loc	1 231 79                        // quant_slide_tuned_Llama3.2-3B.py:231:79
(EngineCore_DP0 pid=396569) 	cvt.f32.bf16 	%r138, %rs48;
(EngineCore_DP0 pid=396569) 	cvt.f32.bf16 	%r139, %rs50;
(EngineCore_DP0 pid=396569) 	cvt.f32.bf16 	%r140, %rs52;
(EngineCore_DP0 pid=396569) 	cvt.f32.bf16 	%r141, %rs54;
(EngineCore_DP0 pid=396569) 	.loc	1 233 27                        // quant_slide_tuned_Llama3.2-3B.py:233:27
(EngineCore_DP0 pid=396569) 	mul.f32 	%r142, %r14, %r114;
(EngineCore_DP0 pid=396569) 	mul.f32 	%r143, %r14, %r115;
(EngineCore_DP0 pid=396569) 	mul.f32 	%r144, %r14, %r116;
(EngineCore_DP0 pid=396569) 	mul.f32 	%r145, %r14, %r117;
(EngineCore_DP0 pid=396569) 	mov.b32 	%r146, 0f43E00000;
(EngineCore_DP0 pid=396569) 	.loc	1 233 48                        // quant_slide_tuned_Llama3.2-3B.py:233:48
(EngineCore_DP0 pid=396569) 	min.xorsign.abs.f32 	%r82, %r142, %r146;
(EngineCore_DP0 pid=396569) 	min.xorsign.abs.f32 	%r83, %r143, %r146;
(EngineCore_DP0 pid=396569) 	min.xorsign.abs.f32 	%r84, %r144, %r146;
(EngineCore_DP0 pid=396569) 	min.xorsign.abs.f32 	%r85, %r145, %r146;
(EngineCore_DP0 pid=396569) 	.loc	1 233 60                        // quant_slide_tuned_Llama3.2-3B.py:233:60
(EngineCore_DP0 pid=396569) 	// begin inline asm
(EngineCore_DP0 pid=396569) 	cvt.rn.satfinite.e4m3x2.f32  %rs56, %r83, %r82; 
(EngineCore_DP0 pid=396569) 
(EngineCore_DP0 pid=396569) 	// end inline asm
(EngineCore_DP0 pid=396569) 	shr.u16 	%rs64, %rs56, 8;
(EngineCore_DP0 pid=396569) 	// begin inline asm
(EngineCore_DP0 pid=396569) 	cvt.rn.satfinite.e4m3x2.f32  %rs57, %r85, %r84; 
(EngineCore_DP0 pid=396569) 
(EngineCore_DP0 pid=396569) 	// end inline asm
(EngineCore_DP0 pid=396569) 	shr.u16 	%rs65, %rs57, 8;
(EngineCore_DP0 pid=396569) 	.loc	1 234 27                        // quant_slide_tuned_Llama3.2-3B.py:234:27
(EngineCore_DP0 pid=396569) 	mul.f32 	%r147, %r14, %r126;
(EngineCore_DP0 pid=396569) 	mul.f32 	%r148, %r14, %r127;
(EngineCore_DP0 pid=396569) 	mul.f32 	%r149, %r14, %r128;
(EngineCore_DP0 pid=396569) 	mul.f32 	%r150, %r14, %r129;
(EngineCore_DP0 pid=396569) 	.loc	1 234 48                        // quant_slide_tuned_Llama3.2-3B.py:234:48
(EngineCore_DP0 pid=396569) 	min.xorsign.abs.f32 	%r86, %r147, %r146;
(EngineCore_DP0 pid=396569) 	min.xorsign.abs.f32 	%r87, %r148, %r146;
(EngineCore_DP0 pid=396569) 	min.xorsign.abs.f32 	%r88, %r149, %r146;
(EngineCore_DP0 pid=396569) 	min.xorsign.abs.f32 	%r89, %r150, %r146;
(EngineCore_DP0 pid=396569) 	.loc	1 234 60                        // quant_slide_tuned_Llama3.2-3B.py:234:60
(EngineCore_DP0 pid=396569) 	// begin inline asm
(EngineCore_DP0 pid=396569) 	cvt.rn.satfinite.e4m3x2.f32  %rs58, %r87, %r86; 
(EngineCore_DP0 pid=396569) 
(EngineCore_DP0 pid=396569) 	// end inline asm
(EngineCore_DP0 pid=396569) 	shr.u16 	%rs66, %rs58, 8;
(EngineCore_DP0 pid=396569) 	// begin inline asm
(EngineCore_DP0 pid=396569) 	cvt.rn.satfinite.e4m3x2.f32  %rs59, %r89, %r88; 
(EngineCore_DP0 pid=396569) 
(EngineCore_DP0 pid=396569) 	// end inline asm
(EngineCore_DP0 pid=396569) 	shr.u16 	%rs67, %rs59, 8;
(EngineCore_DP0 pid=396569) 	.loc	1 235 27                        // quant_slide_tuned_Llama3.2-3B.py:235:27
(EngineCore_DP0 pid=396569) 	mul.f32 	%r151, %r14, %r132;
(EngineCore_DP0 pid=396569) 	mul.f32 	%r152, %r14, %r133;
(EngineCore_DP0 pid=396569) 	mul.f32 	%r153, %r14, %r134;
(EngineCore_DP0 pid=396569) 	mul.f32 	%r154, %r14, %r135;
(EngineCore_DP0 pid=396569) 	.loc	1 235 48                        // quant_slide_tuned_Llama3.2-3B.py:235:48
(EngineCore_DP0 pid=396569) 	min.xorsign.abs.f32 	%r90, %r151, %r146;
(EngineCore_DP0 pid=396569) 	min.xorsign.abs.f32 	%r91, %r152, %r146;
(EngineCore_DP0 pid=396569) 	min.xorsign.abs.f32 	%r92, %r153, %r146;
(EngineCore_DP0 pid=396569) 	min.xorsign.abs.f32 	%r93, %r154, %r146;
(EngineCore_DP0 pid=396569) 	.loc	1 235 60                        // quant_slide_tuned_Llama3.2-3B.py:235:60
(EngineCore_DP0 pid=396569) 	// begin inline asm
(EngineCore_DP0 pid=396569) 	cvt.rn.satfinite.e4m3x2.f32  %rs60, %r91, %r90; 
(EngineCore_DP0 pid=396569) 
(EngineCore_DP0 pid=396569) 	// end inline asm
(EngineCore_DP0 pid=396569) 	shr.u16 	%rs68, %rs60, 8;
(EngineCore_DP0 pid=396569) 	// begin inline asm
(EngineCore_DP0 pid=396569) 	cvt.rn.satfinite.e4m3x2.f32  %rs61, %r93, %r92; 
(EngineCore_DP0 pid=396569) 
(EngineCore_DP0 pid=396569) 	// end inline asm
(EngineCore_DP0 pid=396569) 	shr.u16 	%rs69, %rs61, 8;
(EngineCore_DP0 pid=396569) 	.loc	1 236 27                        // quant_slide_tuned_Llama3.2-3B.py:236:27
(EngineCore_DP0 pid=396569) 	mul.f32 	%r155, %r14, %r138;
(EngineCore_DP0 pid=396569) 	mul.f32 	%r156, %r14, %r139;
(EngineCore_DP0 pid=396569) 	mul.f32 	%r157, %r14, %r140;
(EngineCore_DP0 pid=396569) 	mul.f32 	%r158, %r14, %r141;
(EngineCore_DP0 pid=396569) 	.loc	1 236 48                        // quant_slide_tuned_Llama3.2-3B.py:236:48
(EngineCore_DP0 pid=396569) 	min.xorsign.abs.f32 	%r94, %r155, %r146;
(EngineCore_DP0 pid=396569) 	min.xorsign.abs.f32 	%r95, %r156, %r146;
(EngineCore_DP0 pid=396569) 	min.xorsign.abs.f32 	%r96, %r157, %r146;
(EngineCore_DP0 pid=396569) 	min.xorsign.abs.f32 	%r97, %r158, %r146;
(EngineCore_DP0 pid=396569) 	.loc	1 236 60                        // quant_slide_tuned_Llama3.2-3B.py:236:60
(EngineCore_DP0 pid=396569) 	// begin inline asm
(EngineCore_DP0 pid=396569) 	cvt.rn.satfinite.e4m3x2.f32  %rs62, %r95, %r94; 
(EngineCore_DP0 pid=396569) 
(EngineCore_DP0 pid=396569) 	// end inline asm
(EngineCore_DP0 pid=396569) 	shr.u16 	%rs70, %rs62, 8;
(EngineCore_DP0 pid=396569) 	// begin inline asm
(EngineCore_DP0 pid=396569) 	cvt.rn.satfinite.e4m3x2.f32  %rs63, %r97, %r96; 
(EngineCore_DP0 pid=396569) 
(EngineCore_DP0 pid=396569) 	// end inline asm
(EngineCore_DP0 pid=396569) 	shr.u16 	%rs71, %rs63, 8;
(EngineCore_DP0 pid=396569) 	.loc	1 238 45                        // quant_slide_tuned_Llama3.2-3B.py:238:45
(EngineCore_DP0 pid=396569) 	cvt.u32.u16 	%r159, %rs56;
(EngineCore_DP0 pid=396569) 	and.b32 	%r160, %r159, 255;
(EngineCore_DP0 pid=396569) 	cvt.u32.u16 	%r161, %rs64;
(EngineCore_DP0 pid=396569) 	cvt.u32.u16 	%r162, %rs57;
(EngineCore_DP0 pid=396569) 	and.b32 	%r163, %r162, 255;
(EngineCore_DP0 pid=396569) 	cvt.u32.u16 	%r164, %rs65;
(EngineCore_DP0 pid=396569) 	.loc	1 240 45                        // quant_slide_tuned_Llama3.2-3B.py:240:45
(EngineCore_DP0 pid=396569) 	cvt.u32.u16 	%r165, %rs60;
(EngineCore_DP0 pid=396569) 	and.b32 	%r166, %r165, 255;
(EngineCore_DP0 pid=396569) 	cvt.u32.u16 	%r167, %rs68;
(EngineCore_DP0 pid=396569) 	cvt.u32.u16 	%r168, %rs61;
(EngineCore_DP0 pid=396569) 	and.b32 	%r169, %r168, 255;
(EngineCore_DP0 pid=396569) 	cvt.u32.u16 	%r170, %rs69;
(EngineCore_DP0 pid=396569) 	.loc	1 241 45                        // quant_slide_tuned_Llama3.2-3B.py:241:45
(EngineCore_DP0 pid=396569) 	cvt.u32.u16 	%r171, %rs62;
(EngineCore_DP0 pid=396569) 	cvt.u32.u16 	%r172, %rs70;
(EngineCore_DP0 pid=396569) 	cvt.u32.u16 	%r173, %rs63;
(EngineCore_DP0 pid=396569) 	cvt.u32.u16 	%r174, %rs71;
(EngineCore_DP0 pid=396569) 	.loc	1 243 30                        // quant_slide_tuned_Llama3.2-3B.py:243:30
(EngineCore_DP0 pid=396569) 	and.b16 	%rs72, %rs58, 255;
(EngineCore_DP0 pid=396569) 	mul.wide.u16 	%r175, %rs72, 256;
(EngineCore_DP0 pid=396569) 	mul.wide.u16 	%r176, %rs66, 256;
(EngineCore_DP0 pid=396569) 	and.b16 	%rs73, %rs59, 255;
(EngineCore_DP0 pid=396569) 	mul.wide.u16 	%r177, %rs73, 256;
(EngineCore_DP0 pid=396569) 	mul.wide.u16 	%r178, %rs67, 256;
(EngineCore_DP0 pid=396569) 	.loc	1 243 24                        // quant_slide_tuned_Llama3.2-3B.py:243:24
(EngineCore_DP0 pid=396569) 	or.b32 	%r179, %r175, %r160;
(EngineCore_DP0 pid=396569) 	or.b32 	%r180, %r176, %r161;
(EngineCore_DP0 pid=396569) 	or.b32 	%r181, %r177, %r163;
(EngineCore_DP0 pid=396569) 	or.b32 	%r182, %r178, %r164;
(EngineCore_DP0 pid=396569) 	.loc	1 243 42                        // quant_slide_tuned_Llama3.2-3B.py:243:42
(EngineCore_DP0 pid=396569) 	shl.b32 	%r183, %r166, 16;
(EngineCore_DP0 pid=396569) 	shl.b32 	%r184, %r167, 16;
(EngineCore_DP0 pid=396569) 	shl.b32 	%r185, %r169, 16;
(EngineCore_DP0 pid=396569) 	shl.b32 	%r186, %r170, 16;
(EngineCore_DP0 pid=396569) 	.loc	1 243 36                        // quant_slide_tuned_Llama3.2-3B.py:243:36
(EngineCore_DP0 pid=396569) 	or.b32 	%r187, %r183, %r179;
(EngineCore_DP0 pid=396569) 	or.b32 	%r188, %r184, %r180;
(EngineCore_DP0 pid=396569) 	or.b32 	%r189, %r185, %r181;
(EngineCore_DP0 pid=396569) 	or.b32 	%r190, %r186, %r182;
(EngineCore_DP0 pid=396569) 	.loc	1 243 55                        // quant_slide_tuned_Llama3.2-3B.py:243:55
(EngineCore_DP0 pid=396569) 	shl.b32 	%r191, %r171, 24;
(EngineCore_DP0 pid=396569) 	shl.b32 	%r192, %r172, 24;
(EngineCore_DP0 pid=396569) 	shl.b32 	%r193, %r173, 24;
(EngineCore_DP0 pid=396569) 	shl.b32 	%r194, %r174, 24;
(EngineCore_DP0 pid=396569) 	.loc	1 243 49                        // quant_slide_tuned_Llama3.2-3B.py:243:49
(EngineCore_DP0 pid=396569) 	or.b32 	%r98, %r191, %r187;
(EngineCore_DP0 pid=396569) 	or.b32 	%r99, %r192, %r188;
(EngineCore_DP0 pid=396569) 	or.b32 	%r100, %r193, %r189;
(EngineCore_DP0 pid=396569) 	or.b32 	%r101, %r194, %r190;
(EngineCore_DP0 pid=396569) 	.loc	1 244 29                        // quant_slide_tuned_Llama3.2-3B.py:244:29
(EngineCore_DP0 pid=396569) 	mad.wide.s32 	%rd24, %r102, 4, %rd2;
(EngineCore_DP0 pid=396569) 	.loc	1 244 39                        // quant_slide_tuned_Llama3.2-3B.py:244:39
(EngineCore_DP0 pid=396569) 	// begin inline asm
(EngineCore_DP0 pid=396569) 	@%p25 st.global.v4.b32 [ %rd24 + 0 ], { %r98, %r99, %r100, %r101 };
(EngineCore_DP0 pid=396569) 	// end inline asm
(EngineCore_DP0 pid=396569) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=396569) 	add.s32 	%r198, %r198, 2048;
(EngineCore_DP0 pid=396569) 	setp.lt.s32 	%p42, %r198, %r15;
(EngineCore_DP0 pid=396569) 	@%p42 bra 	$L__BB0_6;
(EngineCore_DP0 pid=396569) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=396569) 	.loc	1 215 4                         // quant_slide_tuned_Llama3.2-3B.py:215:4
(EngineCore_DP0 pid=396569) 	ret;
(EngineCore_DP0 pid=396569) $L__tmp3:
(EngineCore_DP0 pid=396569) $L__func_end0:
(EngineCore_DP0 pid=396569)                                         // -- End function
(EngineCore_DP0 pid=396569) }
(EngineCore_DP0 pid=396569) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py"
(EngineCore_DP0 pid=396569) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=396569) 	.section	.debug_abbrev
(EngineCore_DP0 pid=396569) 	{
(EngineCore_DP0 pid=396569) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=396569) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=396569) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=396569) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=396569) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=396569) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=396569) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=396569) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=396569) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=396569) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=396569) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=396569) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=396569) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=396569) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=396569) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=396569) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=396569) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=396569) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=396569) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=396569) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=396569) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=396569) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=396569) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=396569) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=396569) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=396569) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=396569) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=396569) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=396569) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=396569) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=396569) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=396569) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=396569) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=396569) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=396569) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=396569) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=396569) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=396569) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=396569) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=396569) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=396569) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=396569) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=396569) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=396569) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=396569) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=396569) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=396569) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=396569) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=396569) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=396569) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=396569) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=396569) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=396569) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=396569) 	}
(EngineCore_DP0 pid=396569) 	.section	.debug_info
(EngineCore_DP0 pid=396569) 	{
(EngineCore_DP0 pid=396569) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=396569) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=396569) .b8 0
(EngineCore_DP0 pid=396569) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=396569) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=396569) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=396569) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=396569) .b8 114
(EngineCore_DP0 pid=396569) .b8 105
(EngineCore_DP0 pid=396569) .b8 116
(EngineCore_DP0 pid=396569) .b8 111
(EngineCore_DP0 pid=396569) .b8 110
(EngineCore_DP0 pid=396569) .b8 0
(EngineCore_DP0 pid=396569) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=396569) .b8 0
(EngineCore_DP0 pid=396569) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=396569) .b8 117
(EngineCore_DP0 pid=396569) .b8 97
(EngineCore_DP0 pid=396569) .b8 110
(EngineCore_DP0 pid=396569) .b8 116
(EngineCore_DP0 pid=396569) .b8 95
(EngineCore_DP0 pid=396569) .b8 115
(EngineCore_DP0 pid=396569) .b8 108
(EngineCore_DP0 pid=396569) .b8 105
(EngineCore_DP0 pid=396569) .b8 100
(EngineCore_DP0 pid=396569) .b8 101
(EngineCore_DP0 pid=396569) .b8 95
(EngineCore_DP0 pid=396569) .b8 116
(EngineCore_DP0 pid=396569) .b8 117
(EngineCore_DP0 pid=396569) .b8 110
(EngineCore_DP0 pid=396569) .b8 101
(EngineCore_DP0 pid=396569) .b8 100
(EngineCore_DP0 pid=396569) .b8 95
(EngineCore_DP0 pid=396569) .b8 76
(EngineCore_DP0 pid=396569) .b8 108
(EngineCore_DP0 pid=396569) .b8 97
(EngineCore_DP0 pid=396569) .b8 109
(EngineCore_DP0 pid=396569) .b8 97
(EngineCore_DP0 pid=396569) .b8 51
(EngineCore_DP0 pid=396569) .b8 46
(EngineCore_DP0 pid=396569) .b8 50
(EngineCore_DP0 pid=396569) .b8 45
(EngineCore_DP0 pid=396569) .b8 51
(EngineCore_DP0 pid=396569) .b8 66
(EngineCore_DP0 pid=396569) .b8 46
(EngineCore_DP0 pid=396569) .b8 112
(EngineCore_DP0 pid=396569) .b8 121
(EngineCore_DP0 pid=396569) .b8 0
(EngineCore_DP0 pid=396569) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=396569) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=396569) .b8 114
(EngineCore_DP0 pid=396569) .b8 111
(EngineCore_DP0 pid=396569) .b8 111
(EngineCore_DP0 pid=396569) .b8 116
(EngineCore_DP0 pid=396569) .b8 47
(EngineCore_DP0 pid=396569) .b8 118
(EngineCore_DP0 pid=396569) .b8 108
(EngineCore_DP0 pid=396569) .b8 108
(EngineCore_DP0 pid=396569) .b8 109
(EngineCore_DP0 pid=396569) .b8 98
(EngineCore_DP0 pid=396569) .b8 101
(EngineCore_DP0 pid=396569) .b8 110
(EngineCore_DP0 pid=396569) .b8 99
(EngineCore_DP0 pid=396569) .b8 104
(EngineCore_DP0 pid=396569) .b8 47
(EngineCore_DP0 pid=396569) .b8 115
(EngineCore_DP0 pid=396569) .b8 108
(EngineCore_DP0 pid=396569) .b8 105
(EngineCore_DP0 pid=396569) .b8 100
(EngineCore_DP0 pid=396569) .b8 101
(EngineCore_DP0 pid=396569) .b8 115
(EngineCore_DP0 pid=396569) .b8 112
(EngineCore_DP0 pid=396569) .b8 97
(EngineCore_DP0 pid=396569) .b8 114
(EngineCore_DP0 pid=396569) .b8 115
(EngineCore_DP0 pid=396569) .b8 101
(EngineCore_DP0 pid=396569) .b8 47
(EngineCore_DP0 pid=396569) .b8 99
(EngineCore_DP0 pid=396569) .b8 115
(EngineCore_DP0 pid=396569) .b8 114
(EngineCore_DP0 pid=396569) .b8 99
(EngineCore_DP0 pid=396569) .b8 47
(EngineCore_DP0 pid=396569) .b8 102
(EngineCore_DP0 pid=396569) .b8 117
(EngineCore_DP0 pid=396569) .b8 115
(EngineCore_DP0 pid=396569) .b8 101
(EngineCore_DP0 pid=396569) .b8 100
(EngineCore_DP0 pid=396569) .b8 95
(EngineCore_DP0 pid=396569) .b8 113
(EngineCore_DP0 pid=396569) .b8 117
(EngineCore_DP0 pid=396569) .b8 97
(EngineCore_DP0 pid=396569) .b8 110
(EngineCore_DP0 pid=396569) .b8 116
(EngineCore_DP0 pid=396569) .b8 95
(EngineCore_DP0 pid=396569) .b8 115
(EngineCore_DP0 pid=396569) .b8 108
(EngineCore_DP0 pid=396569) .b8 105
(EngineCore_DP0 pid=396569) .b8 100
(EngineCore_DP0 pid=396569) .b8 101
(EngineCore_DP0 pid=396569) .b8 95
(EngineCore_DP0 pid=396569) .b8 116
(EngineCore_DP0 pid=396569) .b8 114
(EngineCore_DP0 pid=396569) .b8 105
(EngineCore_DP0 pid=396569) .b8 116
(EngineCore_DP0 pid=396569) .b8 111
(EngineCore_DP0 pid=396569) .b8 110
(EngineCore_DP0 pid=396569) .b8 47
(EngineCore_DP0 pid=396569) .b8 98
(EngineCore_DP0 pid=396569) .b8 117
(EngineCore_DP0 pid=396569) .b8 105
(EngineCore_DP0 pid=396569) .b8 108
(EngineCore_DP0 pid=396569) .b8 100
(EngineCore_DP0 pid=396569) .b8 47
(EngineCore_DP0 pid=396569) .b8 71
(EngineCore_DP0 pid=396569) .b8 66
(EngineCore_DP0 pid=396569) .b8 49
(EngineCore_DP0 pid=396569) .b8 48
(EngineCore_DP0 pid=396569) .b8 95
(EngineCore_DP0 pid=396569) .b8 99
(EngineCore_DP0 pid=396569) .b8 99
(EngineCore_DP0 pid=396569) .b8 49
(EngineCore_DP0 pid=396569) .b8 50
(EngineCore_DP0 pid=396569) .b8 49
(EngineCore_DP0 pid=396569) .b8 95
(EngineCore_DP0 pid=396569) .b8 112
(EngineCore_DP0 pid=396569) .b8 121
(EngineCore_DP0 pid=396569) .b8 51
(EngineCore_DP0 pid=396569) .b8 49
(EngineCore_DP0 pid=396569) .b8 50
(EngineCore_DP0 pid=396569) .b8 95
(EngineCore_DP0 pid=396569) .b8 99
(EngineCore_DP0 pid=396569) .b8 117
(EngineCore_DP0 pid=396569) .b8 49
(EngineCore_DP0 pid=396569) .b8 50
(EngineCore_DP0 pid=396569) .b8 57
(EngineCore_DP0 pid=396569) .b8 95
(EngineCore_DP0 pid=396569) .b8 97
(EngineCore_DP0 pid=396569) .b8 97
(EngineCore_DP0 pid=396569) .b8 114
(EngineCore_DP0 pid=396569) .b8 99
(EngineCore_DP0 pid=396569) .b8 104
(EngineCore_DP0 pid=396569) .b8 54
(EngineCore_DP0 pid=396569) .b8 52
(EngineCore_DP0 pid=396569) .b8 0
(EngineCore_DP0 pid=396569) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=396569) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=396569) .b8 113
(EngineCore_DP0 pid=396569) .b8 117
(EngineCore_DP0 pid=396569) .b8 97
(EngineCore_DP0 pid=396569) .b8 110
(EngineCore_DP0 pid=396569) .b8 116
(EngineCore_DP0 pid=396569) .b8 95
(EngineCore_DP0 pid=396569) .b8 115
(EngineCore_DP0 pid=396569) .b8 108
(EngineCore_DP0 pid=396569) .b8 105
(EngineCore_DP0 pid=396569) .b8 100
(EngineCore_DP0 pid=396569) .b8 101
(EngineCore_DP0 pid=396569) .b8 95
(EngineCore_DP0 pid=396569) .b8 102
(EngineCore_DP0 pid=396569) .b8 112
(EngineCore_DP0 pid=396569) .b8 56
(EngineCore_DP0 pid=396569) .b8 95
(EngineCore_DP0 pid=396569) .b8 107
(EngineCore_DP0 pid=396569) .b8 101
(EngineCore_DP0 pid=396569) .b8 114
(EngineCore_DP0 pid=396569) .b8 110
(EngineCore_DP0 pid=396569) .b8 101
(EngineCore_DP0 pid=396569) .b8 108
(EngineCore_DP0 pid=396569) .b8 0
(EngineCore_DP0 pid=396569) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=396569) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=396569) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=396569) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=396569) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=396569) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=396569) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=396569) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=396569) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=396569) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=396569) .b8 205                                 // DW_AT_call_line
(EngineCore_DP0 pid=396569) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=396569) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=396569) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=396569) 	}
(EngineCore_DP0 pid=396569) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=396569) 
(EngineCore_DP0 pid=396569) ================================================================
(EngineCore_DP0 pid=396569) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=396569) 
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp0t31dqa2.ptx', '-o', '/tmp/tmp0t31dqa2.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866] 
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866] 
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866] 
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp0t31dqa2.ptx -o /tmp/tmp0t31dqa2.ptx.o
(EngineCore_DP0 pid=396569) ERROR 01-25 20:08:27 [core.py:866] 

STDERR:
[2026-01-25 20:08:00] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:08:00] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:08:00] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:08:00] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:08:00] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:08:00] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:08:00] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:08:00] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:08:00] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:08:00] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:08:00] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:08:00] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:08:00] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:08:00] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:08:04] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:08:04] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:08:04] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:08:04] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:08:04] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:08:04] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:08:04] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:08:04] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:08:04] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:08:04] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:08:04] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:08:04] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:08:04] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:08:04] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=396569) [2026-01-25 20:08:05] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=396569) [2026-01-25 20:08:05] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=396569) [2026-01-25 20:08:05] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=396569) [2026-01-25 20:08:05] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=396569) [2026-01-25 20:08:05] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=396569) [2026-01-25 20:08:05] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=396569) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=396569) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:20<00:00, 20.63s/it]
(EngineCore_DP0 pid=396569) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:20<00:00, 20.63s/it]
(EngineCore_DP0 pid=396569) 
(EngineCore_DP0 pid=396569) [2026-01-25 20:08:26] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4096] -> 1D uint8
(EngineCore_DP0 pid=396569) [2026-01-25 20:08:26] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 13107200 bytes
(EngineCore_DP0 pid=396569) [2026-01-25 20:08:26] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4096] -> 1D uint8
(EngineCore_DP0 pid=396569) [2026-01-25 20:08:26] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 7864320 bytes
(EngineCore_DP0 pid=396569) [2026-01-25 20:08:26] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4096] -> 1D uint8
(EngineCore_DP0 pid=396569) [2026-01-25 20:08:26] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 41943040 bytes
(EngineCore_DP0 pid=396569) [2026-01-25 20:08:26] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 10944] -> 1D uint8
(EngineCore_DP0 pid=396569) [2026-01-25 20:08:26] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 21037056 bytes
(EngineCore_DP0 pid=396569) Process EngineCore_DP0:
(EngineCore_DP0 pid=396569) Traceback (most recent call last):
(EngineCore_DP0 pid=396569)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=396569)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=396569)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=396569)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=396569) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp0t31dqa2.ptx', '-o', '/tmp/tmp0t31dqa2.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=396569) 
(EngineCore_DP0 pid=396569) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=396569) 
(EngineCore_DP0 pid=396569) Traceback (most recent call last):
(EngineCore_DP0 pid=396569)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=396569)     self.run()
(EngineCore_DP0 pid=396569)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=396569)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=396569)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=396569)     raise e
(EngineCore_DP0 pid=396569)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=396569)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=396569)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=396569)     super().__init__(
(EngineCore_DP0 pid=396569)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=396569)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=396569)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=396569)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=396569)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=396569)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=396569)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=396569)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=396569)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=396569)     return func(*args, **kwargs)
(EngineCore_DP0 pid=396569)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=396569)     return func(*args, **kwargs)
(EngineCore_DP0 pid=396569)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=396569)     self.model_runner.profile_run()
(EngineCore_DP0 pid=396569)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=396569)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=396569)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=396569)     return func(*args, **kwargs)
(EngineCore_DP0 pid=396569)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=396569)     outputs = self.model(
(EngineCore_DP0 pid=396569)               ^^^^^^^^^^^
(EngineCore_DP0 pid=396569)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=396569)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=396569)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=396569)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=396569)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=396569)     model_output = self.model(
(EngineCore_DP0 pid=396569)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=396569)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=396569)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=396569)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=396569)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=396569)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=396569)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=396569)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=396569)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=396569)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=396569)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=396569)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=396569)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=396569)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=396569)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=396569)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=396569)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=396569)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=396569)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=396569)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=396569)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=396569)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=396569)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=396569)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=396569)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=396569)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=396569)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=396569)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=396569)     return self._linear_fn(
(EngineCore_DP0 pid=396569)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=396569)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=396569)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=396569)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=396569)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=396569)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=396569)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=396569)     return fn(input, L)
(EngineCore_DP0 pid=396569)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=396569)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=396569)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=396569)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=396569)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=396569)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=396569)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=396569)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=396569)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=396569)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=396569)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=396569)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=396569)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=396569)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=396569)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=396569)     raise PTXASError(error)
(EngineCore_DP0 pid=396569) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=396569) `ptxas` stderr:
(EngineCore_DP0 pid=396569) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=396569) 
(EngineCore_DP0 pid=396569) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp0t31dqa2.ptx -o /tmp/tmp0t31dqa2.ptx.o
(EngineCore_DP0 pid=396569) 
[rank0]:[W125 20:08:28.262569360 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=32768

========== M=65536 ==========
Time: 2026-01-25 20:08:29
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-3B-FP8_M65536.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:08:56 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 20:08:56 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=397535) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=397535) 
(EngineCore_DP0 pid=397535) 
(EngineCore_DP0 pid=397535) ================================================================
(EngineCore_DP0 pid=397535) Internal Triton PTX codegen error
(EngineCore_DP0 pid=397535) `ptxas` stderr:
(EngineCore_DP0 pid=397535) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=397535) 
(EngineCore_DP0 pid=397535) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpkso4nfcd.ptx -o /tmp/tmpkso4nfcd.ptx.o
(EngineCore_DP0 pid=397535) 
(EngineCore_DP0 pid=397535) 
(EngineCore_DP0 pid=397535) //
(EngineCore_DP0 pid=397535) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=397535) //
(EngineCore_DP0 pid=397535) 
(EngineCore_DP0 pid=397535) .version 8.7
(EngineCore_DP0 pid=397535) .target sm_121a
(EngineCore_DP0 pid=397535) .address_size 64
(EngineCore_DP0 pid=397535) 
(EngineCore_DP0 pid=397535) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=397535) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=397535)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=397535) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=397535) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=397535) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=397535) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=397535) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=397535) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=397535) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=397535) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=397535) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=397535) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=397535) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=397535) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=397535) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=397535) )
(EngineCore_DP0 pid=397535) .reqntid 512
(EngineCore_DP0 pid=397535) {
(EngineCore_DP0 pid=397535) 	.reg .pred 	%p<28>;
(EngineCore_DP0 pid=397535) 	.reg .b16 	%rs<49>;
(EngineCore_DP0 pid=397535) 	.reg .b32 	%r<139>;
(EngineCore_DP0 pid=397535) 	.reg .b64 	%rd<17>;
(EngineCore_DP0 pid=397535) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=397535) $L__func_begin0:
(EngineCore_DP0 pid=397535) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=397535) 
(EngineCore_DP0 pid=397535) // %bb.0:
(EngineCore_DP0 pid=397535) 	ld.param.b32 	%r21, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=397535) 	ld.param.b32 	%r20, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=397535) 	ld.param.b32 	%r19, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=397535) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=397535) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=397535) $L__tmp0:
(EngineCore_DP0 pid=397535) 	.loc	1 191 24                        // quant_slide_tuned_Llama3.2-3B.py:191:24
(EngineCore_DP0 pid=397535) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=397535) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=397535) 	.loc	1 196 26                        // quant_slide_tuned_Llama3.2-3B.py:196:26
(EngineCore_DP0 pid=397535) 	mul.lo.s32 	%r24, %r23, %r1;
(EngineCore_DP0 pid=397535) 	.loc	1 196 20                        // quant_slide_tuned_Llama3.2-3B.py:196:20
(EngineCore_DP0 pid=397535) 	mad.wide.s32 	%rd1, %r24, 2, %rd4;
(EngineCore_DP0 pid=397535) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=397535) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=397535) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=397535) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=397535) 	setp.lt.s32 	%p1, %r20, 1;
(EngineCore_DP0 pid=397535) 	mov.b32 	%r137, 0f2B8CBCCC;
(EngineCore_DP0 pid=397535) 	setp.eq.b32 	%p27, %r2, 0;
(EngineCore_DP0 pid=397535) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=397535) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=397535) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=397535) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=397535) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=397535) 	shr.u32 	%r33, %r2, 3;
(EngineCore_DP0 pid=397535) 	and.b32 	%r34, %r33, 60;
(EngineCore_DP0 pid=397535) 	mov.b32 	%r35, global_smem;
(EngineCore_DP0 pid=397535) 	add.s32 	%r45, %r35, %r34;
(EngineCore_DP0 pid=397535) 	shl.b32 	%r36, %r2, 2;
(EngineCore_DP0 pid=397535) 	add.s32 	%r48, %r35, %r36;
(EngineCore_DP0 pid=397535) 	mov.b32 	%r41, 0;
(EngineCore_DP0 pid=397535) 	mov.b32 	%r135, 0f00000000;
(EngineCore_DP0 pid=397535) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=397535) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=397535) 	mov.b32 	%r136, %r41;
(EngineCore_DP0 pid=397535) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=397535) 	.loc	1 203 22                        // quant_slide_tuned_Llama3.2-3B.py:203:22
(EngineCore_DP0 pid=397535) 	add.s32 	%r51, %r4, %r136;
(EngineCore_DP0 pid=397535) 	setp.lt.s32 	%p2, %r51, %r19;
(EngineCore_DP0 pid=397535) 	.loc	1 204 29                        // quant_slide_tuned_Llama3.2-3B.py:204:29
(EngineCore_DP0 pid=397535) 	mad.wide.s32 	%rd6, %r51, 2, %rd1;
(EngineCore_DP0 pid=397535) 	.loc	1 204 21                        // quant_slide_tuned_Llama3.2-3B.py:204:21
(EngineCore_DP0 pid=397535) 	// begin inline asm
(EngineCore_DP0 pid=397535) 	mov.u32 %r37, %r41;
(EngineCore_DP0 pid=397535) 	mov.u32 %r38, %r41;
(EngineCore_DP0 pid=397535) 	mov.u32 %r39, %r41;
(EngineCore_DP0 pid=397535) 	mov.u32 %r40, %r41;
(EngineCore_DP0 pid=397535) 	@%p2 ld.global.v4.b32 { %r37, %r38, %r39, %r40 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=397535) 	// end inline asm
(EngineCore_DP0 pid=397535) 	mov.b32 	{%rs1, %rs2}, %r37;
(EngineCore_DP0 pid=397535) 	mov.b32 	{%rs3, %rs4}, %r38;
(EngineCore_DP0 pid=397535) 	mov.b32 	{%rs5, %rs6}, %r39;
(EngineCore_DP0 pid=397535) 	mov.b32 	{%rs7, %rs8}, %r40;
(EngineCore_DP0 pid=397535) 	.loc	1 205 50                        // quant_slide_tuned_Llama3.2-3B.py:205:50
(EngineCore_DP0 pid=397535) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=397535) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=397535) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=397535) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=397535) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=397535) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=397535) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=397535) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=397535) $L__tmp1:
(EngineCore_DP0 pid=397535) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=397535) 	bar.sync 	0;
(EngineCore_DP0 pid=397535) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=397535) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=397535) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=397535) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=397535) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=397535) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=397535) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=397535) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=397535) 	cvt.f32.bf16 	%r52, %rs23;
(EngineCore_DP0 pid=397535) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=397535) 	shfl.sync.bfly.b32 	%r53, %r52, 16, 31, -1;
(EngineCore_DP0 pid=397535) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=397535) 	max.f32 	%r54, %r52, %r53;
(EngineCore_DP0 pid=397535) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=397535) 	shfl.sync.bfly.b32 	%r55, %r54, 8, 31, -1;
(EngineCore_DP0 pid=397535) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=397535) 	max.f32 	%r56, %r54, %r55;
(EngineCore_DP0 pid=397535) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=397535) 	shfl.sync.bfly.b32 	%r57, %r56, 4, 31, -1;
(EngineCore_DP0 pid=397535) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=397535) 	max.f32 	%r58, %r56, %r57;
(EngineCore_DP0 pid=397535) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=397535) 	shfl.sync.bfly.b32 	%r59, %r58, 2, 31, -1;
(EngineCore_DP0 pid=397535) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=397535) 	max.f32 	%r60, %r58, %r59;
(EngineCore_DP0 pid=397535) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=397535) 	shfl.sync.bfly.b32 	%r61, %r60, 1, 31, -1;
(EngineCore_DP0 pid=397535) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=397535) 	max.f32 	%r46, %r60, %r61;
(EngineCore_DP0 pid=397535) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=397535) 	// begin inline asm
(EngineCore_DP0 pid=397535) 	@%p3 st.shared.b32 [ %r45 + 0 ], %r46;
(EngineCore_DP0 pid=397535) 	// end inline asm
(EngineCore_DP0 pid=397535) 	bar.sync 	0;
(EngineCore_DP0 pid=397535) 	// begin inline asm
(EngineCore_DP0 pid=397535) 	@%p4 ld.shared.b32 %r47, [ %r48 + 0 ];
(EngineCore_DP0 pid=397535) 	// end inline asm
(EngineCore_DP0 pid=397535) 	shfl.sync.bfly.b32 	%r62, %r47, 8, 31, -1;
(EngineCore_DP0 pid=397535) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=397535) 	max.f32 	%r63, %r47, %r62;
(EngineCore_DP0 pid=397535) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=397535) 	shfl.sync.bfly.b32 	%r64, %r63, 4, 31, -1;
(EngineCore_DP0 pid=397535) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=397535) 	max.f32 	%r65, %r63, %r64;
(EngineCore_DP0 pid=397535) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=397535) 	shfl.sync.bfly.b32 	%r66, %r65, 2, 31, -1;
(EngineCore_DP0 pid=397535) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=397535) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=397535) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=397535) 	shfl.sync.bfly.b32 	%r68, %r67, 1, 31, -1;
(EngineCore_DP0 pid=397535) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=397535) 	max.f32 	%r50, %r67, %r68;
(EngineCore_DP0 pid=397535) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=397535) 	// begin inline asm
(EngineCore_DP0 pid=397535) 	@%p27 st.shared.b32 [ %r48 + 0 ], %r50;
(EngineCore_DP0 pid=397535) 	// end inline asm
(EngineCore_DP0 pid=397535) 	bar.sync 	0;
(EngineCore_DP0 pid=397535) 	ld.shared.b32 	%r69, [global_smem];
(EngineCore_DP0 pid=397535) $L__tmp2:
(EngineCore_DP0 pid=397535) 	.loc	1 205 36                        // quant_slide_tuned_Llama3.2-3B.py:205:36
(EngineCore_DP0 pid=397535) 	max.f32 	%r135, %r135, %r69;
(EngineCore_DP0 pid=397535) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=397535) 	add.s32 	%r136, %r136, 4096;
(EngineCore_DP0 pid=397535) 	setp.lt.s32 	%p6, %r136, %r20;
(EngineCore_DP0 pid=397535) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=397535) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=397535) 	.loc	1 207 32                        // quant_slide_tuned_Llama3.2-3B.py:207:32
(EngineCore_DP0 pid=397535) 	max.f32 	%r137, %r135, 0f2B8CBCCC;
(EngineCore_DP0 pid=397535) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=397535) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-3B.py:0:32
(EngineCore_DP0 pid=397535) 	mov.b32 	%r71, 0f43E00000;
(EngineCore_DP0 pid=397535) 	.loc	1 208 32                        // quant_slide_tuned_Llama3.2-3B.py:208:32
(EngineCore_DP0 pid=397535) 	div.full.f32 	%r72, %r137, %r71;
(EngineCore_DP0 pid=397535) 	.loc	1 208 41                        // quant_slide_tuned_Llama3.2-3B.py:208:41
(EngineCore_DP0 pid=397535) 	max.f32 	%r70, %r72, 0f36924925;
(EngineCore_DP0 pid=397535) 	.loc	1 210 25                        // quant_slide_tuned_Llama3.2-3B.py:210:25
(EngineCore_DP0 pid=397535) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=397535) 	.loc	1 210 30                        // quant_slide_tuned_Llama3.2-3B.py:210:30
(EngineCore_DP0 pid=397535) 	// begin inline asm
(EngineCore_DP0 pid=397535) 	@%p27 st.global.b32 [ %rd7 + 0 ], { %r70 };
(EngineCore_DP0 pid=397535) 	// end inline asm
(EngineCore_DP0 pid=397535) 	.loc	1 213 29                        // quant_slide_tuned_Llama3.2-3B.py:213:29
(EngineCore_DP0 pid=397535) 	shl.b32 	%r15, %r21, 1;
(EngineCore_DP0 pid=397535) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=397535) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=397535) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=397535) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=397535) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-3B.py:0:41
(EngineCore_DP0 pid=397535) 	ld.param.b32 	%r25, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=397535) 	shr.s32 	%r26, %r25, 31;
(EngineCore_DP0 pid=397535) 	shr.u32 	%r27, %r26, 30;
(EngineCore_DP0 pid=397535) 	add.s32 	%r28, %r25, %r27;
(EngineCore_DP0 pid=397535) 	shr.s32 	%r29, %r28, 2;
(EngineCore_DP0 pid=397535) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=397535) 	mul.lo.s32 	%r30, %r29, %r1;
(EngineCore_DP0 pid=397535) 	mad.wide.s32 	%rd2, %r30, 4, %rd5;
(EngineCore_DP0 pid=397535) 	div.full.f32 	%r14, %r71, %r137;
(EngineCore_DP0 pid=397535) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=397535) 	mov.b32 	%r138, 0;
(EngineCore_DP0 pid=397535) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=397535)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=397535) 	.loc	1 216 31                        // quant_slide_tuned_Llama3.2-3B.py:216:31
(EngineCore_DP0 pid=397535) 	add.s32 	%r84, %r16, %r138;
(EngineCore_DP0 pid=397535) 	.loc	1 217 30                        // quant_slide_tuned_Llama3.2-3B.py:217:30
(EngineCore_DP0 pid=397535) 	add.s32 	%r85, %r138, 1;
(EngineCore_DP0 pid=397535) 	setp.lt.s32 	%p17, %r84, %r15;
(EngineCore_DP0 pid=397535) 	.loc	1 220 24                        // quant_slide_tuned_Llama3.2-3B.py:220:24
(EngineCore_DP0 pid=397535) 	shr.u32 	%r86, %r84, 1;
(EngineCore_DP0 pid=397535) 	.loc	1 221 23                        // quant_slide_tuned_Llama3.2-3B.py:221:23
(EngineCore_DP0 pid=397535) 	shr.u32 	%r87, %r85, 31;
(EngineCore_DP0 pid=397535) 	add.s32 	%r88, %r85, %r87;
(EngineCore_DP0 pid=397535) 	and.b32 	%r89, %r88, 2147483646;
(EngineCore_DP0 pid=397535) 	sub.s32 	%r90, %r85, %r89;
(EngineCore_DP0 pid=397535) 	.loc	1 222 22                        // quant_slide_tuned_Llama3.2-3B.py:222:22
(EngineCore_DP0 pid=397535) 	mul.lo.s32 	%r91, %r86, 6;
(EngineCore_DP0 pid=397535) 	.loc	1 222 30                        // quant_slide_tuned_Llama3.2-3B.py:222:30
(EngineCore_DP0 pid=397535) 	shl.b32 	%r92, %r90, 1;
(EngineCore_DP0 pid=397535) 	.loc	1 222 26                        // quant_slide_tuned_Llama3.2-3B.py:222:26
(EngineCore_DP0 pid=397535) 	add.s32 	%r93, %r91, %r92;
(EngineCore_DP0 pid=397535) 	.loc	1 225 53                        // quant_slide_tuned_Llama3.2-3B.py:225:53
(EngineCore_DP0 pid=397535) 	setp.lt.s32 	%p18, %r91, %r19;
(EngineCore_DP0 pid=397535) 	setp.lt.s32 	%p19, %r93, %r19;
(EngineCore_DP0 pid=397535) 	.loc	1 225 37                        // quant_slide_tuned_Llama3.2-3B.py:225:37
(EngineCore_DP0 pid=397535) 	and.pred 	%p9, %p17, %p18;
(EngineCore_DP0 pid=397535) 	and.pred 	%p10, %p17, %p19;
(EngineCore_DP0 pid=397535) 	.loc	1 224 29                        // quant_slide_tuned_Llama3.2-3B.py:224:29
(EngineCore_DP0 pid=397535) 	mad.wide.s32 	%rd8, %r91, 2, %rd1;
(EngineCore_DP0 pid=397535) 	mad.wide.s32 	%rd9, %r93, 2, %rd1;
(EngineCore_DP0 pid=397535) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=397535) 	.loc	1 224 21                        // quant_slide_tuned_Llama3.2-3B.py:224:21
(EngineCore_DP0 pid=397535) 	// begin inline asm
(EngineCore_DP0 pid=397535) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=397535) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=397535) 	// end inline asm
(EngineCore_DP0 pid=397535) 	// begin inline asm
(EngineCore_DP0 pid=397535) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=397535) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=397535) 	// end inline asm
(EngineCore_DP0 pid=397535) 	.loc	1 225 79                        // quant_slide_tuned_Llama3.2-3B.py:225:79
(EngineCore_DP0 pid=397535) 	cvt.f32.bf16 	%r94, %rs24;
(EngineCore_DP0 pid=397535) 	cvt.f32.bf16 	%r95, %rs26;
(EngineCore_DP0 pid=397535) 	.loc	1 227 48                        // quant_slide_tuned_Llama3.2-3B.py:227:48
(EngineCore_DP0 pid=397535) 	or.b32 	%r96, %r91, 1;
(EngineCore_DP0 pid=397535) 	or.b32 	%r97, %r93, 1;
(EngineCore_DP0 pid=397535) 	.loc	1 227 53                        // quant_slide_tuned_Llama3.2-3B.py:227:53
(EngineCore_DP0 pid=397535) 	setp.lt.s32 	%p20, %r96, %r19;
(EngineCore_DP0 pid=397535) 	setp.lt.s32 	%p21, %r97, %r19;
(EngineCore_DP0 pid=397535) 	.loc	1 227 37                        // quant_slide_tuned_Llama3.2-3B.py:227:37
(EngineCore_DP0 pid=397535) 	and.pred 	%p11, %p17, %p20;
(EngineCore_DP0 pid=397535) 	and.pred 	%p12, %p17, %p21;
(EngineCore_DP0 pid=397535) 	.loc	1 226 39                        // quant_slide_tuned_Llama3.2-3B.py:226:39
(EngineCore_DP0 pid=397535) 	add.s64 	%rd10, %rd8, 2;
(EngineCore_DP0 pid=397535) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=397535) 	.loc	1 226 21                        // quant_slide_tuned_Llama3.2-3B.py:226:21
(EngineCore_DP0 pid=397535) 	// begin inline asm
(EngineCore_DP0 pid=397535) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=397535) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=397535) 	// end inline asm
(EngineCore_DP0 pid=397535) 	// begin inline asm
(EngineCore_DP0 pid=397535) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=397535) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=397535) 	// end inline asm
(EngineCore_DP0 pid=397535) 	.loc	1 227 79                        // quant_slide_tuned_Llama3.2-3B.py:227:79
(EngineCore_DP0 pid=397535) 	cvt.f32.bf16 	%r98, %rs28;
(EngineCore_DP0 pid=397535) 	cvt.f32.bf16 	%r99, %rs30;
(EngineCore_DP0 pid=397535) 	.loc	1 229 48                        // quant_slide_tuned_Llama3.2-3B.py:229:48
(EngineCore_DP0 pid=397535) 	add.s32 	%r100, %r91, 2;
(EngineCore_DP0 pid=397535) 	add.s32 	%r101, %r93, 2;
(EngineCore_DP0 pid=397535) 	.loc	1 229 53                        // quant_slide_tuned_Llama3.2-3B.py:229:53
(EngineCore_DP0 pid=397535) 	setp.lt.s32 	%p22, %r100, %r19;
(EngineCore_DP0 pid=397535) 	setp.lt.s32 	%p23, %r101, %r19;
(EngineCore_DP0 pid=397535) 	.loc	1 229 37                        // quant_slide_tuned_Llama3.2-3B.py:229:37
(EngineCore_DP0 pid=397535) 	and.pred 	%p13, %p17, %p22;
(EngineCore_DP0 pid=397535) 	and.pred 	%p14, %p17, %p23;
(EngineCore_DP0 pid=397535) 	.loc	1 228 39                        // quant_slide_tuned_Llama3.2-3B.py:228:39
(EngineCore_DP0 pid=397535) 	add.s64 	%rd12, %rd8, 4;
(EngineCore_DP0 pid=397535) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=397535) 	.loc	1 228 21                        // quant_slide_tuned_Llama3.2-3B.py:228:21
(EngineCore_DP0 pid=397535) 	// begin inline asm
(EngineCore_DP0 pid=397535) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=397535) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=397535) 	// end inline asm
(EngineCore_DP0 pid=397535) 	// begin inline asm
(EngineCore_DP0 pid=397535) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=397535) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=397535) 	// end inline asm
(EngineCore_DP0 pid=397535) 	.loc	1 229 79                        // quant_slide_tuned_Llama3.2-3B.py:229:79
(EngineCore_DP0 pid=397535) 	cvt.f32.bf16 	%r102, %rs32;
(EngineCore_DP0 pid=397535) 	cvt.f32.bf16 	%r103, %rs34;
(EngineCore_DP0 pid=397535) 	.loc	1 231 48                        // quant_slide_tuned_Llama3.2-3B.py:231:48
(EngineCore_DP0 pid=397535) 	add.s32 	%r104, %r91, 3;
(EngineCore_DP0 pid=397535) 	add.s32 	%r105, %r93, 3;
(EngineCore_DP0 pid=397535) 	.loc	1 231 53                        // quant_slide_tuned_Llama3.2-3B.py:231:53
(EngineCore_DP0 pid=397535) 	setp.lt.s32 	%p24, %r104, %r19;
(EngineCore_DP0 pid=397535) 	setp.lt.s32 	%p25, %r105, %r19;
(EngineCore_DP0 pid=397535) 	.loc	1 231 37                        // quant_slide_tuned_Llama3.2-3B.py:231:37
(EngineCore_DP0 pid=397535) 	and.pred 	%p15, %p17, %p24;
(EngineCore_DP0 pid=397535) 	and.pred 	%p16, %p17, %p25;
(EngineCore_DP0 pid=397535) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-3B.py:230:39
(EngineCore_DP0 pid=397535) 	add.s64 	%rd14, %rd8, 6;
(EngineCore_DP0 pid=397535) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=397535) 	.loc	1 230 21                        // quant_slide_tuned_Llama3.2-3B.py:230:21
(EngineCore_DP0 pid=397535) 	// begin inline asm
(EngineCore_DP0 pid=397535) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=397535) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=397535) 	// end inline asm
(EngineCore_DP0 pid=397535) 	// begin inline asm
(EngineCore_DP0 pid=397535) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=397535) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=397535) 	// end inline asm
(EngineCore_DP0 pid=397535) 	.loc	1 231 79                        // quant_slide_tuned_Llama3.2-3B.py:231:79
(EngineCore_DP0 pid=397535) 	cvt.f32.bf16 	%r106, %rs36;
(EngineCore_DP0 pid=397535) 	cvt.f32.bf16 	%r107, %rs38;
(EngineCore_DP0 pid=397535) 	.loc	1 233 27                        // quant_slide_tuned_Llama3.2-3B.py:233:27
(EngineCore_DP0 pid=397535) 	mul.f32 	%r108, %r14, %r94;
(EngineCore_DP0 pid=397535) 	mul.f32 	%r109, %r14, %r95;
(EngineCore_DP0 pid=397535) 	mov.b32 	%r110, 0f43E00000;
(EngineCore_DP0 pid=397535) 	.loc	1 233 48                        // quant_slide_tuned_Llama3.2-3B.py:233:48
(EngineCore_DP0 pid=397535) 	min.xorsign.abs.f32 	%r74, %r108, %r110;
(EngineCore_DP0 pid=397535) 	min.xorsign.abs.f32 	%r75, %r109, %r110;
(EngineCore_DP0 pid=397535) 	.loc	1 233 60                        // quant_slide_tuned_Llama3.2-3B.py:233:60
(EngineCore_DP0 pid=397535) 	// begin inline asm
(EngineCore_DP0 pid=397535) 	cvt.rn.satfinite.e4m3x2.f32  %rs40, %r75, %r74; 
(EngineCore_DP0 pid=397535) 
(EngineCore_DP0 pid=397535) 	// end inline asm
(EngineCore_DP0 pid=397535) 	shr.u16 	%rs44, %rs40, 8;
(EngineCore_DP0 pid=397535) 	.loc	1 234 27                        // quant_slide_tuned_Llama3.2-3B.py:234:27
(EngineCore_DP0 pid=397535) 	mul.f32 	%r111, %r14, %r98;
(EngineCore_DP0 pid=397535) 	mul.f32 	%r112, %r14, %r99;
(EngineCore_DP0 pid=397535) 	.loc	1 234 48                        // quant_slide_tuned_Llama3.2-3B.py:234:48
(EngineCore_DP0 pid=397535) 	min.xorsign.abs.f32 	%r76, %r111, %r110;
(EngineCore_DP0 pid=397535) 	min.xorsign.abs.f32 	%r77, %r112, %r110;
(EngineCore_DP0 pid=397535) 	.loc	1 234 60                        // quant_slide_tuned_Llama3.2-3B.py:234:60
(EngineCore_DP0 pid=397535) 	// begin inline asm
(EngineCore_DP0 pid=397535) 	cvt.rn.satfinite.e4m3x2.f32  %rs41, %r77, %r76; 
(EngineCore_DP0 pid=397535) 
(EngineCore_DP0 pid=397535) 	// end inline asm
(EngineCore_DP0 pid=397535) 	shr.u16 	%rs45, %rs41, 8;
(EngineCore_DP0 pid=397535) 	.loc	1 235 27                        // quant_slide_tuned_Llama3.2-3B.py:235:27
(EngineCore_DP0 pid=397535) 	mul.f32 	%r113, %r14, %r102;
(EngineCore_DP0 pid=397535) 	mul.f32 	%r114, %r14, %r103;
(EngineCore_DP0 pid=397535) 	.loc	1 235 48                        // quant_slide_tuned_Llama3.2-3B.py:235:48
(EngineCore_DP0 pid=397535) 	min.xorsign.abs.f32 	%r78, %r113, %r110;
(EngineCore_DP0 pid=397535) 	min.xorsign.abs.f32 	%r79, %r114, %r110;
(EngineCore_DP0 pid=397535) 	.loc	1 235 60                        // quant_slide_tuned_Llama3.2-3B.py:235:60
(EngineCore_DP0 pid=397535) 	// begin inline asm
(EngineCore_DP0 pid=397535) 	cvt.rn.satfinite.e4m3x2.f32  %rs42, %r79, %r78; 
(EngineCore_DP0 pid=397535) 
(EngineCore_DP0 pid=397535) 	// end inline asm
(EngineCore_DP0 pid=397535) 	shr.u16 	%rs46, %rs42, 8;
(EngineCore_DP0 pid=397535) 	.loc	1 236 27                        // quant_slide_tuned_Llama3.2-3B.py:236:27
(EngineCore_DP0 pid=397535) 	mul.f32 	%r115, %r14, %r106;
(EngineCore_DP0 pid=397535) 	mul.f32 	%r116, %r14, %r107;
(EngineCore_DP0 pid=397535) 	.loc	1 236 48                        // quant_slide_tuned_Llama3.2-3B.py:236:48
(EngineCore_DP0 pid=397535) 	min.xorsign.abs.f32 	%r80, %r115, %r110;
(EngineCore_DP0 pid=397535) 	min.xorsign.abs.f32 	%r81, %r116, %r110;
(EngineCore_DP0 pid=397535) 	.loc	1 236 60                        // quant_slide_tuned_Llama3.2-3B.py:236:60
(EngineCore_DP0 pid=397535) 	// begin inline asm
(EngineCore_DP0 pid=397535) 	cvt.rn.satfinite.e4m3x2.f32  %rs43, %r81, %r80; 
(EngineCore_DP0 pid=397535) 
(EngineCore_DP0 pid=397535) 	// end inline asm
(EngineCore_DP0 pid=397535) 	shr.u16 	%rs47, %rs43, 8;
(EngineCore_DP0 pid=397535) 	.loc	1 238 45                        // quant_slide_tuned_Llama3.2-3B.py:238:45
(EngineCore_DP0 pid=397535) 	cvt.u32.u16 	%r117, %rs40;
(EngineCore_DP0 pid=397535) 	and.b32 	%r118, %r117, 255;
(EngineCore_DP0 pid=397535) 	cvt.u32.u16 	%r119, %rs44;
(EngineCore_DP0 pid=397535) 	.loc	1 240 45                        // quant_slide_tuned_Llama3.2-3B.py:240:45
(EngineCore_DP0 pid=397535) 	cvt.u32.u16 	%r120, %rs42;
(EngineCore_DP0 pid=397535) 	and.b32 	%r121, %r120, 255;
(EngineCore_DP0 pid=397535) 	cvt.u32.u16 	%r122, %rs46;
(EngineCore_DP0 pid=397535) 	.loc	1 241 45                        // quant_slide_tuned_Llama3.2-3B.py:241:45
(EngineCore_DP0 pid=397535) 	cvt.u32.u16 	%r123, %rs43;
(EngineCore_DP0 pid=397535) 	cvt.u32.u16 	%r124, %rs47;
(EngineCore_DP0 pid=397535) 	.loc	1 243 30                        // quant_slide_tuned_Llama3.2-3B.py:243:30
(EngineCore_DP0 pid=397535) 	and.b16 	%rs48, %rs41, 255;
(EngineCore_DP0 pid=397535) 	mul.wide.u16 	%r125, %rs48, 256;
(EngineCore_DP0 pid=397535) 	mul.wide.u16 	%r126, %rs45, 256;
(EngineCore_DP0 pid=397535) 	.loc	1 243 24                        // quant_slide_tuned_Llama3.2-3B.py:243:24
(EngineCore_DP0 pid=397535) 	or.b32 	%r127, %r125, %r118;
(EngineCore_DP0 pid=397535) 	or.b32 	%r128, %r126, %r119;
(EngineCore_DP0 pid=397535) 	.loc	1 243 42                        // quant_slide_tuned_Llama3.2-3B.py:243:42
(EngineCore_DP0 pid=397535) 	shl.b32 	%r129, %r121, 16;
(EngineCore_DP0 pid=397535) 	shl.b32 	%r130, %r122, 16;
(EngineCore_DP0 pid=397535) 	.loc	1 243 36                        // quant_slide_tuned_Llama3.2-3B.py:243:36
(EngineCore_DP0 pid=397535) 	or.b32 	%r131, %r127, %r129;
(EngineCore_DP0 pid=397535) 	or.b32 	%r132, %r128, %r130;
(EngineCore_DP0 pid=397535) 	.loc	1 243 55                        // quant_slide_tuned_Llama3.2-3B.py:243:55
(EngineCore_DP0 pid=397535) 	shl.b32 	%r133, %r123, 24;
(EngineCore_DP0 pid=397535) 	shl.b32 	%r134, %r124, 24;
(EngineCore_DP0 pid=397535) 	.loc	1 243 49                        // quant_slide_tuned_Llama3.2-3B.py:243:49
(EngineCore_DP0 pid=397535) 	or.b32 	%r82, %r131, %r133;
(EngineCore_DP0 pid=397535) 	or.b32 	%r83, %r132, %r134;
(EngineCore_DP0 pid=397535) 	.loc	1 244 29                        // quant_slide_tuned_Llama3.2-3B.py:244:29
(EngineCore_DP0 pid=397535) 	mad.wide.s32 	%rd16, %r84, 4, %rd2;
(EngineCore_DP0 pid=397535) 	.loc	1 244 39                        // quant_slide_tuned_Llama3.2-3B.py:244:39
(EngineCore_DP0 pid=397535) 	// begin inline asm
(EngineCore_DP0 pid=397535) 	@%p17 st.global.v2.b32 [ %rd16 + 0 ], { %r82, %r83 };
(EngineCore_DP0 pid=397535) 	// end inline asm
(EngineCore_DP0 pid=397535) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=397535) 	add.s32 	%r138, %r138, 1024;
(EngineCore_DP0 pid=397535) 	setp.lt.s32 	%p26, %r138, %r15;
(EngineCore_DP0 pid=397535) 	@%p26 bra 	$L__BB0_6;
(EngineCore_DP0 pid=397535) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=397535) 	.loc	1 215 4                         // quant_slide_tuned_Llama3.2-3B.py:215:4
(EngineCore_DP0 pid=397535) 	ret;
(EngineCore_DP0 pid=397535) $L__tmp3:
(EngineCore_DP0 pid=397535) $L__func_end0:
(EngineCore_DP0 pid=397535)                                         // -- End function
(EngineCore_DP0 pid=397535) }
(EngineCore_DP0 pid=397535) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py"
(EngineCore_DP0 pid=397535) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=397535) 	.section	.debug_abbrev
(EngineCore_DP0 pid=397535) 	{
(EngineCore_DP0 pid=397535) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=397535) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=397535) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=397535) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=397535) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=397535) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=397535) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=397535) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=397535) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=397535) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=397535) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=397535) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=397535) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=397535) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=397535) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=397535) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=397535) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=397535) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=397535) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=397535) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=397535) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=397535) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=397535) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=397535) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=397535) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=397535) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=397535) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=397535) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=397535) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=397535) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=397535) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=397535) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=397535) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=397535) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=397535) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=397535) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=397535) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=397535) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=397535) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=397535) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=397535) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=397535) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=397535) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=397535) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=397535) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=397535) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=397535) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=397535) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=397535) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=397535) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=397535) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=397535) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=397535) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=397535) 	}
(EngineCore_DP0 pid=397535) 	.section	.debug_info
(EngineCore_DP0 pid=397535) 	{
(EngineCore_DP0 pid=397535) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=397535) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=397535) .b8 0
(EngineCore_DP0 pid=397535) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=397535) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=397535) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=397535) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=397535) .b8 114
(EngineCore_DP0 pid=397535) .b8 105
(EngineCore_DP0 pid=397535) .b8 116
(EngineCore_DP0 pid=397535) .b8 111
(EngineCore_DP0 pid=397535) .b8 110
(EngineCore_DP0 pid=397535) .b8 0
(EngineCore_DP0 pid=397535) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=397535) .b8 0
(EngineCore_DP0 pid=397535) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=397535) .b8 117
(EngineCore_DP0 pid=397535) .b8 97
(EngineCore_DP0 pid=397535) .b8 110
(EngineCore_DP0 pid=397535) .b8 116
(EngineCore_DP0 pid=397535) .b8 95
(EngineCore_DP0 pid=397535) .b8 115
(EngineCore_DP0 pid=397535) .b8 108
(EngineCore_DP0 pid=397535) .b8 105
(EngineCore_DP0 pid=397535) .b8 100
(EngineCore_DP0 pid=397535) .b8 101
(EngineCore_DP0 pid=397535) .b8 95
(EngineCore_DP0 pid=397535) .b8 116
(EngineCore_DP0 pid=397535) .b8 117
(EngineCore_DP0 pid=397535) .b8 110
(EngineCore_DP0 pid=397535) .b8 101
(EngineCore_DP0 pid=397535) .b8 100
(EngineCore_DP0 pid=397535) .b8 95
(EngineCore_DP0 pid=397535) .b8 76
(EngineCore_DP0 pid=397535) .b8 108
(EngineCore_DP0 pid=397535) .b8 97
(EngineCore_DP0 pid=397535) .b8 109
(EngineCore_DP0 pid=397535) .b8 97
(EngineCore_DP0 pid=397535) .b8 51
(EngineCore_DP0 pid=397535) .b8 46
(EngineCore_DP0 pid=397535) .b8 50
(EngineCore_DP0 pid=397535) .b8 45
(EngineCore_DP0 pid=397535) .b8 51
(EngineCore_DP0 pid=397535) .b8 66
(EngineCore_DP0 pid=397535) .b8 46
(EngineCore_DP0 pid=397535) .b8 112
(EngineCore_DP0 pid=397535) .b8 121
(EngineCore_DP0 pid=397535) .b8 0
(EngineCore_DP0 pid=397535) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=397535) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=397535) .b8 114
(EngineCore_DP0 pid=397535) .b8 111
(EngineCore_DP0 pid=397535) .b8 111
(EngineCore_DP0 pid=397535) .b8 116
(EngineCore_DP0 pid=397535) .b8 47
(EngineCore_DP0 pid=397535) .b8 118
(EngineCore_DP0 pid=397535) .b8 108
(EngineCore_DP0 pid=397535) .b8 108
(EngineCore_DP0 pid=397535) .b8 109
(EngineCore_DP0 pid=397535) .b8 98
(EngineCore_DP0 pid=397535) .b8 101
(EngineCore_DP0 pid=397535) .b8 110
(EngineCore_DP0 pid=397535) .b8 99
(EngineCore_DP0 pid=397535) .b8 104
(EngineCore_DP0 pid=397535) .b8 47
(EngineCore_DP0 pid=397535) .b8 115
(EngineCore_DP0 pid=397535) .b8 108
(EngineCore_DP0 pid=397535) .b8 105
(EngineCore_DP0 pid=397535) .b8 100
(EngineCore_DP0 pid=397535) .b8 101
(EngineCore_DP0 pid=397535) .b8 115
(EngineCore_DP0 pid=397535) .b8 112
(EngineCore_DP0 pid=397535) .b8 97
(EngineCore_DP0 pid=397535) .b8 114
(EngineCore_DP0 pid=397535) .b8 115
(EngineCore_DP0 pid=397535) .b8 101
(EngineCore_DP0 pid=397535) .b8 47
(EngineCore_DP0 pid=397535) .b8 99
(EngineCore_DP0 pid=397535) .b8 115
(EngineCore_DP0 pid=397535) .b8 114
(EngineCore_DP0 pid=397535) .b8 99
(EngineCore_DP0 pid=397535) .b8 47
(EngineCore_DP0 pid=397535) .b8 102
(EngineCore_DP0 pid=397535) .b8 117
(EngineCore_DP0 pid=397535) .b8 115
(EngineCore_DP0 pid=397535) .b8 101
(EngineCore_DP0 pid=397535) .b8 100
(EngineCore_DP0 pid=397535) .b8 95
(EngineCore_DP0 pid=397535) .b8 113
(EngineCore_DP0 pid=397535) .b8 117
(EngineCore_DP0 pid=397535) .b8 97
(EngineCore_DP0 pid=397535) .b8 110
(EngineCore_DP0 pid=397535) .b8 116
(EngineCore_DP0 pid=397535) .b8 95
(EngineCore_DP0 pid=397535) .b8 115
(EngineCore_DP0 pid=397535) .b8 108
(EngineCore_DP0 pid=397535) .b8 105
(EngineCore_DP0 pid=397535) .b8 100
(EngineCore_DP0 pid=397535) .b8 101
(EngineCore_DP0 pid=397535) .b8 95
(EngineCore_DP0 pid=397535) .b8 116
(EngineCore_DP0 pid=397535) .b8 114
(EngineCore_DP0 pid=397535) .b8 105
(EngineCore_DP0 pid=397535) .b8 116
(EngineCore_DP0 pid=397535) .b8 111
(EngineCore_DP0 pid=397535) .b8 110
(EngineCore_DP0 pid=397535) .b8 47
(EngineCore_DP0 pid=397535) .b8 98
(EngineCore_DP0 pid=397535) .b8 117
(EngineCore_DP0 pid=397535) .b8 105
(EngineCore_DP0 pid=397535) .b8 108
(EngineCore_DP0 pid=397535) .b8 100
(EngineCore_DP0 pid=397535) .b8 47
(EngineCore_DP0 pid=397535) .b8 71
(EngineCore_DP0 pid=397535) .b8 66
(EngineCore_DP0 pid=397535) .b8 49
(EngineCore_DP0 pid=397535) .b8 48
(EngineCore_DP0 pid=397535) .b8 95
(EngineCore_DP0 pid=397535) .b8 99
(EngineCore_DP0 pid=397535) .b8 99
(EngineCore_DP0 pid=397535) .b8 49
(EngineCore_DP0 pid=397535) .b8 50
(EngineCore_DP0 pid=397535) .b8 49
(EngineCore_DP0 pid=397535) .b8 95
(EngineCore_DP0 pid=397535) .b8 112
(EngineCore_DP0 pid=397535) .b8 121
(EngineCore_DP0 pid=397535) .b8 51
(EngineCore_DP0 pid=397535) .b8 49
(EngineCore_DP0 pid=397535) .b8 50
(EngineCore_DP0 pid=397535) .b8 95
(EngineCore_DP0 pid=397535) .b8 99
(EngineCore_DP0 pid=397535) .b8 117
(EngineCore_DP0 pid=397535) .b8 49
(EngineCore_DP0 pid=397535) .b8 50
(EngineCore_DP0 pid=397535) .b8 57
(EngineCore_DP0 pid=397535) .b8 95
(EngineCore_DP0 pid=397535) .b8 97
(EngineCore_DP0 pid=397535) .b8 97
(EngineCore_DP0 pid=397535) .b8 114
(EngineCore_DP0 pid=397535) .b8 99
(EngineCore_DP0 pid=397535) .b8 104
(EngineCore_DP0 pid=397535) .b8 54
(EngineCore_DP0 pid=397535) .b8 52
(EngineCore_DP0 pid=397535) .b8 0
(EngineCore_DP0 pid=397535) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=397535) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=397535) .b8 113
(EngineCore_DP0 pid=397535) .b8 117
(EngineCore_DP0 pid=397535) .b8 97
(EngineCore_DP0 pid=397535) .b8 110
(EngineCore_DP0 pid=397535) .b8 116
(EngineCore_DP0 pid=397535) .b8 95
(EngineCore_DP0 pid=397535) .b8 115
(EngineCore_DP0 pid=397535) .b8 108
(EngineCore_DP0 pid=397535) .b8 105
(EngineCore_DP0 pid=397535) .b8 100
(EngineCore_DP0 pid=397535) .b8 101
(EngineCore_DP0 pid=397535) .b8 95
(EngineCore_DP0 pid=397535) .b8 102
(EngineCore_DP0 pid=397535) .b8 112
(EngineCore_DP0 pid=397535) .b8 56
(EngineCore_DP0 pid=397535) .b8 95
(EngineCore_DP0 pid=397535) .b8 107
(EngineCore_DP0 pid=397535) .b8 101
(EngineCore_DP0 pid=397535) .b8 114
(EngineCore_DP0 pid=397535) .b8 110
(EngineCore_DP0 pid=397535) .b8 101
(EngineCore_DP0 pid=397535) .b8 108
(EngineCore_DP0 pid=397535) .b8 0
(EngineCore_DP0 pid=397535) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=397535) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=397535) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=397535) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=397535) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=397535) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=397535) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=397535) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=397535) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=397535) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=397535) .b8 205                                 // DW_AT_call_line
(EngineCore_DP0 pid=397535) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=397535) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=397535) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=397535) 	}
(EngineCore_DP0 pid=397535) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=397535) 
(EngineCore_DP0 pid=397535) ================================================================
(EngineCore_DP0 pid=397535) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=397535) 
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpkso4nfcd.ptx', '-o', '/tmp/tmpkso4nfcd.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866] 
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866] 
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866] 
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpkso4nfcd.ptx -o /tmp/tmpkso4nfcd.ptx.o
(EngineCore_DP0 pid=397535) ERROR 01-25 20:09:23 [core.py:866] 

STDERR:
[2026-01-25 20:08:56] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:08:56] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:08:56] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:08:56] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:08:56] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:08:56] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:08:56] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:08:56] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:08:56] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:08:56] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:08:56] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:08:56] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:08:56] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:08:56] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:08:59] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:08:59] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:08:59] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:08:59] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:08:59] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:08:59] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:08:59] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:08:59] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:08:59] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:08:59] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:08:59] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:08:59] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:08:59] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:08:59] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=397535) [2026-01-25 20:09:00] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=397535) [2026-01-25 20:09:00] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=397535) [2026-01-25 20:09:00] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=397535) [2026-01-25 20:09:00] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=397535) [2026-01-25 20:09:00] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=397535) [2026-01-25 20:09:00] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=397535) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=397535) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:20<00:00, 20.81s/it]
(EngineCore_DP0 pid=397535) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:20<00:00, 20.81s/it]
(EngineCore_DP0 pid=397535) 
(EngineCore_DP0 pid=397535) [2026-01-25 20:09:22] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4096] -> 1D uint8
(EngineCore_DP0 pid=397535) [2026-01-25 20:09:22] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 13107200 bytes
(EngineCore_DP0 pid=397535) [2026-01-25 20:09:22] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4096] -> 1D uint8
(EngineCore_DP0 pid=397535) [2026-01-25 20:09:22] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 7864320 bytes
(EngineCore_DP0 pid=397535) [2026-01-25 20:09:22] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4096] -> 1D uint8
(EngineCore_DP0 pid=397535) [2026-01-25 20:09:22] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 41943040 bytes
(EngineCore_DP0 pid=397535) [2026-01-25 20:09:22] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 10944] -> 1D uint8
(EngineCore_DP0 pid=397535) [2026-01-25 20:09:22] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 21037056 bytes
(EngineCore_DP0 pid=397535) Process EngineCore_DP0:
(EngineCore_DP0 pid=397535) Traceback (most recent call last):
(EngineCore_DP0 pid=397535)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=397535)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=397535)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=397535)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=397535) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpkso4nfcd.ptx', '-o', '/tmp/tmpkso4nfcd.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=397535) 
(EngineCore_DP0 pid=397535) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=397535) 
(EngineCore_DP0 pid=397535) Traceback (most recent call last):
(EngineCore_DP0 pid=397535)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=397535)     self.run()
(EngineCore_DP0 pid=397535)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=397535)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=397535)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=397535)     raise e
(EngineCore_DP0 pid=397535)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=397535)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=397535)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=397535)     super().__init__(
(EngineCore_DP0 pid=397535)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=397535)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=397535)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=397535)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=397535)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=397535)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=397535)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=397535)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=397535)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=397535)     return func(*args, **kwargs)
(EngineCore_DP0 pid=397535)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=397535)     return func(*args, **kwargs)
(EngineCore_DP0 pid=397535)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=397535)     self.model_runner.profile_run()
(EngineCore_DP0 pid=397535)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=397535)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=397535)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=397535)     return func(*args, **kwargs)
(EngineCore_DP0 pid=397535)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=397535)     outputs = self.model(
(EngineCore_DP0 pid=397535)               ^^^^^^^^^^^
(EngineCore_DP0 pid=397535)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=397535)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=397535)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=397535)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=397535)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=397535)     model_output = self.model(
(EngineCore_DP0 pid=397535)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=397535)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=397535)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=397535)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=397535)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=397535)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=397535)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=397535)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=397535)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=397535)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=397535)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=397535)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=397535)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=397535)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=397535)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=397535)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=397535)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=397535)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=397535)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=397535)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=397535)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=397535)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=397535)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=397535)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=397535)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=397535)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=397535)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=397535)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=397535)     return self._linear_fn(
(EngineCore_DP0 pid=397535)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=397535)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=397535)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=397535)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=397535)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=397535)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=397535)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=397535)     return fn(input, L)
(EngineCore_DP0 pid=397535)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=397535)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=397535)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=397535)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=397535)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=397535)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=397535)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=397535)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=397535)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=397535)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=397535)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=397535)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=397535)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=397535)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=397535)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=397535)     raise PTXASError(error)
(EngineCore_DP0 pid=397535) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=397535) `ptxas` stderr:
(EngineCore_DP0 pid=397535) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=397535) 
(EngineCore_DP0 pid=397535) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpkso4nfcd.ptx -o /tmp/tmpkso4nfcd.ptx.o
(EngineCore_DP0 pid=397535) 
[rank0]:[W125 20:09:23.771674272 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=65536

========== M=512 ==========
Time: 2026-01-25 21:25:05
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Qwen2.5-7B-FP8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:25:09 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 21:25:09 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=474843) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=474843) 
(EngineCore_DP0 pid=474843) 
(EngineCore_DP0 pid=474843) ================================================================
(EngineCore_DP0 pid=474843) Internal Triton PTX codegen error
(EngineCore_DP0 pid=474843) `ptxas` stderr:
(EngineCore_DP0 pid=474843) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=474843) 
(EngineCore_DP0 pid=474843) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp4fzs63rr.ptx -o /tmp/tmp4fzs63rr.ptx.o
(EngineCore_DP0 pid=474843) 
(EngineCore_DP0 pid=474843) 
(EngineCore_DP0 pid=474843) //
(EngineCore_DP0 pid=474843) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=474843) //
(EngineCore_DP0 pid=474843) 
(EngineCore_DP0 pid=474843) .version 8.7
(EngineCore_DP0 pid=474843) .target sm_121a
(EngineCore_DP0 pid=474843) .address_size 64
(EngineCore_DP0 pid=474843) 
(EngineCore_DP0 pid=474843) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=474843) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=474843)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=474843) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=474843) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=474843) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=474843) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=474843) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=474843) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=474843) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=474843) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=474843) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=474843) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=474843) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=474843) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=474843) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=474843) )
(EngineCore_DP0 pid=474843) .reqntid 1024
(EngineCore_DP0 pid=474843) {
(EngineCore_DP0 pid=474843) 	.reg .pred 	%p<20>;
(EngineCore_DP0 pid=474843) 	.reg .b16 	%rs<25>;
(EngineCore_DP0 pid=474843) 	.reg .b32 	%r<114>;
(EngineCore_DP0 pid=474843) 	.reg .b64 	%rd<13>;
(EngineCore_DP0 pid=474843) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=474843) $L__func_begin0:
(EngineCore_DP0 pid=474843) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=474843) 
(EngineCore_DP0 pid=474843) // %bb.0:
(EngineCore_DP0 pid=474843) 	ld.param.b32 	%r19, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=474843) 	ld.param.b32 	%r18, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=474843) 	ld.param.b32 	%r17, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=474843) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=474843) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=474843) $L__tmp0:
(EngineCore_DP0 pid=474843) 	.loc	1 143 24                        // quant_slide_tuned_Qwen2.5-7B.py:143:24
(EngineCore_DP0 pid=474843) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=474843) 	ld.param.b32 	%r21, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=474843) 	.loc	1 148 26                        // quant_slide_tuned_Qwen2.5-7B.py:148:26
(EngineCore_DP0 pid=474843) 	mul.lo.s32 	%r22, %r21, %r1;
(EngineCore_DP0 pid=474843) 	.loc	1 148 20                        // quant_slide_tuned_Qwen2.5-7B.py:148:20
(EngineCore_DP0 pid=474843) 	mad.wide.s32 	%rd1, %r22, 2, %rd4;
(EngineCore_DP0 pid=474843) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=474843) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=474843) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=474843) 	setp.lt.s32 	%p1, %r18, 1;
(EngineCore_DP0 pid=474843) 	mov.b32 	%r112, 0f2B8CBCCC;
(EngineCore_DP0 pid=474843) 	setp.eq.b32 	%p19, %r2, 0;
(EngineCore_DP0 pid=474843) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=474843) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=474843) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=474843) 	shl.b32 	%r3, %r2, 2;
(EngineCore_DP0 pid=474843) 	and.b32 	%r4, %r2, 31;
(EngineCore_DP0 pid=474843) 	shr.u32 	%r31, %r2, 3;
(EngineCore_DP0 pid=474843) 	and.b32 	%r32, %r31, 124;
(EngineCore_DP0 pid=474843) 	mov.b32 	%r33, global_smem;
(EngineCore_DP0 pid=474843) 	add.s32 	%r39, %r33, %r32;
(EngineCore_DP0 pid=474843) 	add.s32 	%r42, %r33, %r3;
(EngineCore_DP0 pid=474843) 	mov.b32 	%r37, 0;
(EngineCore_DP0 pid=474843) 	mov.b32 	%r110, 0f00000000;
(EngineCore_DP0 pid=474843) 	setp.lt.u32 	%p4, %r2, 32;
(EngineCore_DP0 pid=474843) 	setp.eq.b32 	%p3, %r4, 0;
(EngineCore_DP0 pid=474843) 	mov.b32 	%r111, %r37;
(EngineCore_DP0 pid=474843) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=474843) 	.loc	1 155 22                        // quant_slide_tuned_Qwen2.5-7B.py:155:22
(EngineCore_DP0 pid=474843) 	add.s32 	%r45, %r3, %r111;
(EngineCore_DP0 pid=474843) 	setp.lt.s32 	%p2, %r45, %r17;
(EngineCore_DP0 pid=474843) 	.loc	1 156 29                        // quant_slide_tuned_Qwen2.5-7B.py:156:29
(EngineCore_DP0 pid=474843) 	mad.wide.s32 	%rd6, %r45, 2, %rd1;
(EngineCore_DP0 pid=474843) 	.loc	1 156 21                        // quant_slide_tuned_Qwen2.5-7B.py:156:21
(EngineCore_DP0 pid=474843) 	// begin inline asm
(EngineCore_DP0 pid=474843) 	mov.u32 %r35, %r37;
(EngineCore_DP0 pid=474843) 	mov.u32 %r36, %r37;
(EngineCore_DP0 pid=474843) 	@%p2 ld.global.v2.b32 { %r35, %r36 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=474843) 	// end inline asm
(EngineCore_DP0 pid=474843) 	mov.b32 	{%rs1, %rs2}, %r35;
(EngineCore_DP0 pid=474843) 	mov.b32 	{%rs3, %rs4}, %r36;
(EngineCore_DP0 pid=474843) 	.loc	1 157 50                        // quant_slide_tuned_Qwen2.5-7B.py:157:50
(EngineCore_DP0 pid=474843) 	abs.bf16 	%rs5, %rs1;
(EngineCore_DP0 pid=474843) 	abs.bf16 	%rs6, %rs2;
(EngineCore_DP0 pid=474843) 	abs.bf16 	%rs7, %rs3;
(EngineCore_DP0 pid=474843) 	abs.bf16 	%rs8, %rs4;
(EngineCore_DP0 pid=474843) $L__tmp1:
(EngineCore_DP0 pid=474843) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=474843) 	bar.sync 	0;
(EngineCore_DP0 pid=474843) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=474843) 	max.bf16 	%rs9, %rs5, %rs6;
(EngineCore_DP0 pid=474843) 	max.bf16 	%rs10, %rs9, %rs7;
(EngineCore_DP0 pid=474843) 	max.bf16 	%rs11, %rs10, %rs8;
(EngineCore_DP0 pid=474843) 	cvt.f32.bf16 	%r46, %rs11;
(EngineCore_DP0 pid=474843) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=474843) 	shfl.sync.bfly.b32 	%r47, %r46, 16, 31, -1;
(EngineCore_DP0 pid=474843) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=474843) 	max.f32 	%r48, %r46, %r47;
(EngineCore_DP0 pid=474843) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=474843) 	shfl.sync.bfly.b32 	%r49, %r48, 8, 31, -1;
(EngineCore_DP0 pid=474843) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=474843) 	max.f32 	%r50, %r48, %r49;
(EngineCore_DP0 pid=474843) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=474843) 	shfl.sync.bfly.b32 	%r51, %r50, 4, 31, -1;
(EngineCore_DP0 pid=474843) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=474843) 	max.f32 	%r52, %r50, %r51;
(EngineCore_DP0 pid=474843) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=474843) 	shfl.sync.bfly.b32 	%r53, %r52, 2, 31, -1;
(EngineCore_DP0 pid=474843) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=474843) 	max.f32 	%r54, %r52, %r53;
(EngineCore_DP0 pid=474843) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=474843) 	shfl.sync.bfly.b32 	%r55, %r54, 1, 31, -1;
(EngineCore_DP0 pid=474843) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=474843) 	max.f32 	%r40, %r54, %r55;
(EngineCore_DP0 pid=474843) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=474843) 	// begin inline asm
(EngineCore_DP0 pid=474843) 	@%p3 st.shared.b32 [ %r39 + 0 ], %r40;
(EngineCore_DP0 pid=474843) 	// end inline asm
(EngineCore_DP0 pid=474843) 	bar.sync 	0;
(EngineCore_DP0 pid=474843) 	// begin inline asm
(EngineCore_DP0 pid=474843) 	@%p4 ld.shared.b32 %r41, [ %r42 + 0 ];
(EngineCore_DP0 pid=474843) 	// end inline asm
(EngineCore_DP0 pid=474843) 	shfl.sync.bfly.b32 	%r56, %r41, 16, 31, -1;
(EngineCore_DP0 pid=474843) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=474843) 	max.f32 	%r57, %r41, %r56;
(EngineCore_DP0 pid=474843) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=474843) 	shfl.sync.bfly.b32 	%r58, %r57, 8, 31, -1;
(EngineCore_DP0 pid=474843) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=474843) 	max.f32 	%r59, %r57, %r58;
(EngineCore_DP0 pid=474843) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=474843) 	shfl.sync.bfly.b32 	%r60, %r59, 4, 31, -1;
(EngineCore_DP0 pid=474843) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=474843) 	max.f32 	%r61, %r59, %r60;
(EngineCore_DP0 pid=474843) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=474843) 	shfl.sync.bfly.b32 	%r62, %r61, 2, 31, -1;
(EngineCore_DP0 pid=474843) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=474843) 	max.f32 	%r63, %r61, %r62;
(EngineCore_DP0 pid=474843) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=474843) 	shfl.sync.bfly.b32 	%r64, %r63, 1, 31, -1;
(EngineCore_DP0 pid=474843) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=474843) 	max.f32 	%r44, %r63, %r64;
(EngineCore_DP0 pid=474843) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=474843) 	// begin inline asm
(EngineCore_DP0 pid=474843) 	@%p19 st.shared.b32 [ %r42 + 0 ], %r44;
(EngineCore_DP0 pid=474843) 	// end inline asm
(EngineCore_DP0 pid=474843) 	bar.sync 	0;
(EngineCore_DP0 pid=474843) 	ld.shared.b32 	%r65, [global_smem];
(EngineCore_DP0 pid=474843) $L__tmp2:
(EngineCore_DP0 pid=474843) 	.loc	1 157 36                        // quant_slide_tuned_Qwen2.5-7B.py:157:36
(EngineCore_DP0 pid=474843) 	max.f32 	%r110, %r110, %r65;
(EngineCore_DP0 pid=474843) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=474843) 	add.s32 	%r111, %r111, 4096;
(EngineCore_DP0 pid=474843) 	setp.lt.s32 	%p6, %r111, %r18;
(EngineCore_DP0 pid=474843) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=474843) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=474843) 	.loc	1 159 32                        // quant_slide_tuned_Qwen2.5-7B.py:159:32
(EngineCore_DP0 pid=474843) 	max.f32 	%r112, %r110, 0f2B8CBCCC;
(EngineCore_DP0 pid=474843) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=474843) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-7B.py:0:32
(EngineCore_DP0 pid=474843) 	mov.b32 	%r67, 0f43E00000;
(EngineCore_DP0 pid=474843) 	.loc	1 160 32                        // quant_slide_tuned_Qwen2.5-7B.py:160:32
(EngineCore_DP0 pid=474843) 	div.full.f32 	%r68, %r112, %r67;
(EngineCore_DP0 pid=474843) 	.loc	1 160 41                        // quant_slide_tuned_Qwen2.5-7B.py:160:41
(EngineCore_DP0 pid=474843) 	max.f32 	%r66, %r68, 0f36924925;
(EngineCore_DP0 pid=474843) 	.loc	1 162 25                        // quant_slide_tuned_Qwen2.5-7B.py:162:25
(EngineCore_DP0 pid=474843) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=474843) 	.loc	1 162 30                        // quant_slide_tuned_Qwen2.5-7B.py:162:30
(EngineCore_DP0 pid=474843) 	// begin inline asm
(EngineCore_DP0 pid=474843) 	@%p19 st.global.b32 [ %rd7 + 0 ], { %r66 };
(EngineCore_DP0 pid=474843) 	// end inline asm
(EngineCore_DP0 pid=474843) 	.loc	1 165 29                        // quant_slide_tuned_Qwen2.5-7B.py:165:29
(EngineCore_DP0 pid=474843) 	shl.b32 	%r14, %r19, 1;
(EngineCore_DP0 pid=474843) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=474843) 	setp.lt.s32 	%p8, %r14, 1;
(EngineCore_DP0 pid=474843) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=474843) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=474843) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-7B.py:0:41
(EngineCore_DP0 pid=474843) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=474843) 	shr.s32 	%r24, %r23, 31;
(EngineCore_DP0 pid=474843) 	shr.u32 	%r25, %r24, 30;
(EngineCore_DP0 pid=474843) 	add.s32 	%r26, %r23, %r25;
(EngineCore_DP0 pid=474843) 	shr.s32 	%r27, %r26, 2;
(EngineCore_DP0 pid=474843) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=474843) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=474843) 	mad.wide.s32 	%rd2, %r28, 4, %rd5;
(EngineCore_DP0 pid=474843) 	div.full.f32 	%r13, %r67, %r112;
(EngineCore_DP0 pid=474843) 	mov.b32 	%r113, 0;
(EngineCore_DP0 pid=474843) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=474843)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=474843) 	.loc	1 169 30                        // quant_slide_tuned_Qwen2.5-7B.py:169:30
(EngineCore_DP0 pid=474843) 	add.s32 	%r80, %r2, %r113;
(EngineCore_DP0 pid=474843) 	setp.lt.s32 	%p13, %r80, %r14;
(EngineCore_DP0 pid=474843) 	.loc	1 172 24                        // quant_slide_tuned_Qwen2.5-7B.py:172:24
(EngineCore_DP0 pid=474843) 	shr.u32 	%r81, %r80, 31;
(EngineCore_DP0 pid=474843) 	add.s32 	%r82, %r80, %r81;
(EngineCore_DP0 pid=474843) 	shr.u32 	%r83, %r82, 1;
(EngineCore_DP0 pid=474843) 	.loc	1 173 23                        // quant_slide_tuned_Qwen2.5-7B.py:173:23
(EngineCore_DP0 pid=474843) 	and.b32 	%r84, %r82, 2147483646;
(EngineCore_DP0 pid=474843) 	sub.s32 	%r85, %r80, %r84;
(EngineCore_DP0 pid=474843) 	.loc	1 174 30                        // quant_slide_tuned_Qwen2.5-7B.py:174:30
(EngineCore_DP0 pid=474843) 	shl.b32 	%r86, %r85, 1;
(EngineCore_DP0 pid=474843) 	.loc	1 174 26                        // quant_slide_tuned_Qwen2.5-7B.py:174:26
(EngineCore_DP0 pid=474843) 	mad.lo.s32 	%r87, %r83, 6, %r86;
(EngineCore_DP0 pid=474843) 	.loc	1 177 53                        // quant_slide_tuned_Qwen2.5-7B.py:177:53
(EngineCore_DP0 pid=474843) 	setp.lt.s32 	%p14, %r87, %r17;
(EngineCore_DP0 pid=474843) 	.loc	1 177 37                        // quant_slide_tuned_Qwen2.5-7B.py:177:37
(EngineCore_DP0 pid=474843) 	and.pred 	%p9, %p13, %p14;
(EngineCore_DP0 pid=474843) 	.loc	1 176 29                        // quant_slide_tuned_Qwen2.5-7B.py:176:29
(EngineCore_DP0 pid=474843) 	mad.wide.s32 	%rd8, %r87, 2, %rd1;
(EngineCore_DP0 pid=474843) 	mov.b16 	%rs13, 0;
(EngineCore_DP0 pid=474843) 	.loc	1 176 21                        // quant_slide_tuned_Qwen2.5-7B.py:176:21
(EngineCore_DP0 pid=474843) 	// begin inline asm
(EngineCore_DP0 pid=474843) 	mov.u16 %rs12, %rs13;
(EngineCore_DP0 pid=474843) 	@%p9 ld.global.b16 { %rs12 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=474843) 	// end inline asm
(EngineCore_DP0 pid=474843) 	.loc	1 177 79                        // quant_slide_tuned_Qwen2.5-7B.py:177:79
(EngineCore_DP0 pid=474843) 	cvt.f32.bf16 	%r88, %rs12;
(EngineCore_DP0 pid=474843) 	.loc	1 179 48                        // quant_slide_tuned_Qwen2.5-7B.py:179:48
(EngineCore_DP0 pid=474843) 	or.b32 	%r89, %r87, 1;
(EngineCore_DP0 pid=474843) 	.loc	1 179 53                        // quant_slide_tuned_Qwen2.5-7B.py:179:53
(EngineCore_DP0 pid=474843) 	setp.lt.s32 	%p15, %r89, %r17;
(EngineCore_DP0 pid=474843) 	.loc	1 179 37                        // quant_slide_tuned_Qwen2.5-7B.py:179:37
(EngineCore_DP0 pid=474843) 	and.pred 	%p10, %p13, %p15;
(EngineCore_DP0 pid=474843) 	.loc	1 178 39                        // quant_slide_tuned_Qwen2.5-7B.py:178:39
(EngineCore_DP0 pid=474843) 	add.s64 	%rd9, %rd8, 2;
(EngineCore_DP0 pid=474843) 	.loc	1 178 21                        // quant_slide_tuned_Qwen2.5-7B.py:178:21
(EngineCore_DP0 pid=474843) 	// begin inline asm
(EngineCore_DP0 pid=474843) 	mov.u16 %rs14, %rs13;
(EngineCore_DP0 pid=474843) 	@%p10 ld.global.b16 { %rs14 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=474843) 	// end inline asm
(EngineCore_DP0 pid=474843) 	.loc	1 179 79                        // quant_slide_tuned_Qwen2.5-7B.py:179:79
(EngineCore_DP0 pid=474843) 	cvt.f32.bf16 	%r90, %rs14;
(EngineCore_DP0 pid=474843) 	.loc	1 181 48                        // quant_slide_tuned_Qwen2.5-7B.py:181:48
(EngineCore_DP0 pid=474843) 	add.s32 	%r91, %r87, 2;
(EngineCore_DP0 pid=474843) 	.loc	1 181 53                        // quant_slide_tuned_Qwen2.5-7B.py:181:53
(EngineCore_DP0 pid=474843) 	setp.lt.s32 	%p16, %r91, %r17;
(EngineCore_DP0 pid=474843) 	.loc	1 181 37                        // quant_slide_tuned_Qwen2.5-7B.py:181:37
(EngineCore_DP0 pid=474843) 	and.pred 	%p11, %p13, %p16;
(EngineCore_DP0 pid=474843) 	.loc	1 180 39                        // quant_slide_tuned_Qwen2.5-7B.py:180:39
(EngineCore_DP0 pid=474843) 	add.s64 	%rd10, %rd8, 4;
(EngineCore_DP0 pid=474843) 	.loc	1 180 21                        // quant_slide_tuned_Qwen2.5-7B.py:180:21
(EngineCore_DP0 pid=474843) 	// begin inline asm
(EngineCore_DP0 pid=474843) 	mov.u16 %rs16, %rs13;
(EngineCore_DP0 pid=474843) 	@%p11 ld.global.b16 { %rs16 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=474843) 	// end inline asm
(EngineCore_DP0 pid=474843) 	.loc	1 181 79                        // quant_slide_tuned_Qwen2.5-7B.py:181:79
(EngineCore_DP0 pid=474843) 	cvt.f32.bf16 	%r92, %rs16;
(EngineCore_DP0 pid=474843) 	.loc	1 183 48                        // quant_slide_tuned_Qwen2.5-7B.py:183:48
(EngineCore_DP0 pid=474843) 	add.s32 	%r93, %r87, 3;
(EngineCore_DP0 pid=474843) 	.loc	1 183 53                        // quant_slide_tuned_Qwen2.5-7B.py:183:53
(EngineCore_DP0 pid=474843) 	setp.lt.s32 	%p17, %r93, %r17;
(EngineCore_DP0 pid=474843) 	.loc	1 183 37                        // quant_slide_tuned_Qwen2.5-7B.py:183:37
(EngineCore_DP0 pid=474843) 	and.pred 	%p12, %p13, %p17;
(EngineCore_DP0 pid=474843) 	.loc	1 182 39                        // quant_slide_tuned_Qwen2.5-7B.py:182:39
(EngineCore_DP0 pid=474843) 	add.s64 	%rd11, %rd8, 6;
(EngineCore_DP0 pid=474843) 	.loc	1 182 21                        // quant_slide_tuned_Qwen2.5-7B.py:182:21
(EngineCore_DP0 pid=474843) 	// begin inline asm
(EngineCore_DP0 pid=474843) 	mov.u16 %rs18, %rs13;
(EngineCore_DP0 pid=474843) 	@%p12 ld.global.b16 { %rs18 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=474843) 	// end inline asm
(EngineCore_DP0 pid=474843) 	.loc	1 183 79                        // quant_slide_tuned_Qwen2.5-7B.py:183:79
(EngineCore_DP0 pid=474843) 	cvt.f32.bf16 	%r94, %rs18;
(EngineCore_DP0 pid=474843) 	.loc	1 185 27                        // quant_slide_tuned_Qwen2.5-7B.py:185:27
(EngineCore_DP0 pid=474843) 	mul.f32 	%r95, %r13, %r88;
(EngineCore_DP0 pid=474843) 	mov.b32 	%r96, 0f43E00000;
(EngineCore_DP0 pid=474843) 	.loc	1 185 48                        // quant_slide_tuned_Qwen2.5-7B.py:185:48
(EngineCore_DP0 pid=474843) 	min.xorsign.abs.f32 	%r70, %r95, %r96;
(EngineCore_DP0 pid=474843) 	.loc	1 185 60                        // quant_slide_tuned_Qwen2.5-7B.py:185:60
(EngineCore_DP0 pid=474843) 	// begin inline asm
(EngineCore_DP0 pid=474843) 	cvt.rn.satfinite.e4m3x2.f32  %rs20, %r71, %r70; 
(EngineCore_DP0 pid=474843) 
(EngineCore_DP0 pid=474843) 	// end inline asm
(EngineCore_DP0 pid=474843) 	.loc	1 186 27                        // quant_slide_tuned_Qwen2.5-7B.py:186:27
(EngineCore_DP0 pid=474843) 	mul.f32 	%r97, %r13, %r90;
(EngineCore_DP0 pid=474843) 	.loc	1 186 48                        // quant_slide_tuned_Qwen2.5-7B.py:186:48
(EngineCore_DP0 pid=474843) 	min.xorsign.abs.f32 	%r72, %r97, %r96;
(EngineCore_DP0 pid=474843) 	.loc	1 186 60                        // quant_slide_tuned_Qwen2.5-7B.py:186:60
(EngineCore_DP0 pid=474843) 	// begin inline asm
(EngineCore_DP0 pid=474843) 	cvt.rn.satfinite.e4m3x2.f32  %rs21, %r73, %r72; 
(EngineCore_DP0 pid=474843) 
(EngineCore_DP0 pid=474843) 	// end inline asm
(EngineCore_DP0 pid=474843) 	.loc	1 187 27                        // quant_slide_tuned_Qwen2.5-7B.py:187:27
(EngineCore_DP0 pid=474843) 	mul.f32 	%r98, %r13, %r92;
(EngineCore_DP0 pid=474843) 	.loc	1 187 48                        // quant_slide_tuned_Qwen2.5-7B.py:187:48
(EngineCore_DP0 pid=474843) 	min.xorsign.abs.f32 	%r74, %r98, %r96;
(EngineCore_DP0 pid=474843) 	.loc	1 187 60                        // quant_slide_tuned_Qwen2.5-7B.py:187:60
(EngineCore_DP0 pid=474843) 	// begin inline asm
(EngineCore_DP0 pid=474843) 	cvt.rn.satfinite.e4m3x2.f32  %rs22, %r75, %r74; 
(EngineCore_DP0 pid=474843) 
(EngineCore_DP0 pid=474843) 	// end inline asm
(EngineCore_DP0 pid=474843) 	.loc	1 188 27                        // quant_slide_tuned_Qwen2.5-7B.py:188:27
(EngineCore_DP0 pid=474843) 	mul.f32 	%r99, %r13, %r94;
(EngineCore_DP0 pid=474843) 	.loc	1 188 48                        // quant_slide_tuned_Qwen2.5-7B.py:188:48
(EngineCore_DP0 pid=474843) 	min.xorsign.abs.f32 	%r76, %r99, %r96;
(EngineCore_DP0 pid=474843) 	.loc	1 188 60                        // quant_slide_tuned_Qwen2.5-7B.py:188:60
(EngineCore_DP0 pid=474843) 	// begin inline asm
(EngineCore_DP0 pid=474843) 	cvt.rn.satfinite.e4m3x2.f32  %rs23, %r77, %r76; 
(EngineCore_DP0 pid=474843) 
(EngineCore_DP0 pid=474843) 	// end inline asm
(EngineCore_DP0 pid=474843) 	.loc	1 190 45                        // quant_slide_tuned_Qwen2.5-7B.py:190:45
(EngineCore_DP0 pid=474843) 	cvt.u32.u16 	%r100, %rs20;
(EngineCore_DP0 pid=474843) 	and.b32 	%r101, %r100, 255;
(EngineCore_DP0 pid=474843) 	.loc	1 192 45                        // quant_slide_tuned_Qwen2.5-7B.py:192:45
(EngineCore_DP0 pid=474843) 	cvt.u32.u16 	%r102, %rs22;
(EngineCore_DP0 pid=474843) 	and.b32 	%r103, %r102, 255;
(EngineCore_DP0 pid=474843) 	.loc	1 193 45                        // quant_slide_tuned_Qwen2.5-7B.py:193:45
(EngineCore_DP0 pid=474843) 	cvt.u32.u16 	%r104, %rs23;
(EngineCore_DP0 pid=474843) 	.loc	1 195 30                        // quant_slide_tuned_Qwen2.5-7B.py:195:30
(EngineCore_DP0 pid=474843) 	and.b16 	%rs24, %rs21, 255;
(EngineCore_DP0 pid=474843) 	mul.wide.u16 	%r105, %rs24, 256;
(EngineCore_DP0 pid=474843) 	.loc	1 195 24                        // quant_slide_tuned_Qwen2.5-7B.py:195:24
(EngineCore_DP0 pid=474843) 	or.b32 	%r106, %r105, %r101;
(EngineCore_DP0 pid=474843) 	.loc	1 195 42                        // quant_slide_tuned_Qwen2.5-7B.py:195:42
(EngineCore_DP0 pid=474843) 	shl.b32 	%r107, %r103, 16;
(EngineCore_DP0 pid=474843) 	.loc	1 195 36                        // quant_slide_tuned_Qwen2.5-7B.py:195:36
(EngineCore_DP0 pid=474843) 	or.b32 	%r108, %r106, %r107;
(EngineCore_DP0 pid=474843) 	.loc	1 195 55                        // quant_slide_tuned_Qwen2.5-7B.py:195:55
(EngineCore_DP0 pid=474843) 	shl.b32 	%r109, %r104, 24;
(EngineCore_DP0 pid=474843) 	.loc	1 195 49                        // quant_slide_tuned_Qwen2.5-7B.py:195:49
(EngineCore_DP0 pid=474843) 	or.b32 	%r78, %r108, %r109;
(EngineCore_DP0 pid=474843) 	.loc	1 196 29                        // quant_slide_tuned_Qwen2.5-7B.py:196:29
(EngineCore_DP0 pid=474843) 	mad.wide.s32 	%rd12, %r80, 4, %rd2;
(EngineCore_DP0 pid=474843) 	.loc	1 196 39                        // quant_slide_tuned_Qwen2.5-7B.py:196:39
(EngineCore_DP0 pid=474843) 	// begin inline asm
(EngineCore_DP0 pid=474843) 	@%p13 st.global.b32 [ %rd12 + 0 ], { %r78 };
(EngineCore_DP0 pid=474843) 	// end inline asm
(EngineCore_DP0 pid=474843) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=474843) 	add.s32 	%r113, %r113, 1024;
(EngineCore_DP0 pid=474843) 	setp.lt.s32 	%p18, %r113, %r14;
(EngineCore_DP0 pid=474843) 	@%p18 bra 	$L__BB0_6;
(EngineCore_DP0 pid=474843) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=474843) 	.loc	1 167 4                         // quant_slide_tuned_Qwen2.5-7B.py:167:4
(EngineCore_DP0 pid=474843) 	ret;
(EngineCore_DP0 pid=474843) $L__tmp3:
(EngineCore_DP0 pid=474843) $L__func_end0:
(EngineCore_DP0 pid=474843)                                         // -- End function
(EngineCore_DP0 pid=474843) }
(EngineCore_DP0 pid=474843) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py"
(EngineCore_DP0 pid=474843) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=474843) 	.section	.debug_abbrev
(EngineCore_DP0 pid=474843) 	{
(EngineCore_DP0 pid=474843) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=474843) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=474843) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=474843) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=474843) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=474843) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=474843) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=474843) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=474843) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=474843) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=474843) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=474843) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=474843) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=474843) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=474843) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=474843) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=474843) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=474843) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=474843) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=474843) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=474843) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=474843) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=474843) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=474843) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=474843) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=474843) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=474843) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=474843) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=474843) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=474843) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=474843) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=474843) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=474843) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=474843) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=474843) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=474843) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=474843) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=474843) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=474843) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=474843) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=474843) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=474843) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=474843) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=474843) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=474843) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=474843) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=474843) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=474843) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=474843) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=474843) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=474843) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=474843) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=474843) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=474843) 	}
(EngineCore_DP0 pid=474843) 	.section	.debug_info
(EngineCore_DP0 pid=474843) 	{
(EngineCore_DP0 pid=474843) .b32 221                                // Length of Unit
(EngineCore_DP0 pid=474843) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=474843) .b8 0
(EngineCore_DP0 pid=474843) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=474843) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=474843) .b8 1                                   // Abbrev [1] 0xb:0xd6 DW_TAG_compile_unit
(EngineCore_DP0 pid=474843) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=474843) .b8 114
(EngineCore_DP0 pid=474843) .b8 105
(EngineCore_DP0 pid=474843) .b8 116
(EngineCore_DP0 pid=474843) .b8 111
(EngineCore_DP0 pid=474843) .b8 110
(EngineCore_DP0 pid=474843) .b8 0
(EngineCore_DP0 pid=474843) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=474843) .b8 0
(EngineCore_DP0 pid=474843) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=474843) .b8 117
(EngineCore_DP0 pid=474843) .b8 97
(EngineCore_DP0 pid=474843) .b8 110
(EngineCore_DP0 pid=474843) .b8 116
(EngineCore_DP0 pid=474843) .b8 95
(EngineCore_DP0 pid=474843) .b8 115
(EngineCore_DP0 pid=474843) .b8 108
(EngineCore_DP0 pid=474843) .b8 105
(EngineCore_DP0 pid=474843) .b8 100
(EngineCore_DP0 pid=474843) .b8 101
(EngineCore_DP0 pid=474843) .b8 95
(EngineCore_DP0 pid=474843) .b8 116
(EngineCore_DP0 pid=474843) .b8 117
(EngineCore_DP0 pid=474843) .b8 110
(EngineCore_DP0 pid=474843) .b8 101
(EngineCore_DP0 pid=474843) .b8 100
(EngineCore_DP0 pid=474843) .b8 95
(EngineCore_DP0 pid=474843) .b8 81
(EngineCore_DP0 pid=474843) .b8 119
(EngineCore_DP0 pid=474843) .b8 101
(EngineCore_DP0 pid=474843) .b8 110
(EngineCore_DP0 pid=474843) .b8 50
(EngineCore_DP0 pid=474843) .b8 46
(EngineCore_DP0 pid=474843) .b8 53
(EngineCore_DP0 pid=474843) .b8 45
(EngineCore_DP0 pid=474843) .b8 55
(EngineCore_DP0 pid=474843) .b8 66
(EngineCore_DP0 pid=474843) .b8 46
(EngineCore_DP0 pid=474843) .b8 112
(EngineCore_DP0 pid=474843) .b8 121
(EngineCore_DP0 pid=474843) .b8 0
(EngineCore_DP0 pid=474843) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=474843) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=474843) .b8 114
(EngineCore_DP0 pid=474843) .b8 111
(EngineCore_DP0 pid=474843) .b8 111
(EngineCore_DP0 pid=474843) .b8 116
(EngineCore_DP0 pid=474843) .b8 47
(EngineCore_DP0 pid=474843) .b8 118
(EngineCore_DP0 pid=474843) .b8 108
(EngineCore_DP0 pid=474843) .b8 108
(EngineCore_DP0 pid=474843) .b8 109
(EngineCore_DP0 pid=474843) .b8 98
(EngineCore_DP0 pid=474843) .b8 101
(EngineCore_DP0 pid=474843) .b8 110
(EngineCore_DP0 pid=474843) .b8 99
(EngineCore_DP0 pid=474843) .b8 104
(EngineCore_DP0 pid=474843) .b8 47
(EngineCore_DP0 pid=474843) .b8 115
(EngineCore_DP0 pid=474843) .b8 108
(EngineCore_DP0 pid=474843) .b8 105
(EngineCore_DP0 pid=474843) .b8 100
(EngineCore_DP0 pid=474843) .b8 101
(EngineCore_DP0 pid=474843) .b8 115
(EngineCore_DP0 pid=474843) .b8 112
(EngineCore_DP0 pid=474843) .b8 97
(EngineCore_DP0 pid=474843) .b8 114
(EngineCore_DP0 pid=474843) .b8 115
(EngineCore_DP0 pid=474843) .b8 101
(EngineCore_DP0 pid=474843) .b8 47
(EngineCore_DP0 pid=474843) .b8 99
(EngineCore_DP0 pid=474843) .b8 115
(EngineCore_DP0 pid=474843) .b8 114
(EngineCore_DP0 pid=474843) .b8 99
(EngineCore_DP0 pid=474843) .b8 47
(EngineCore_DP0 pid=474843) .b8 102
(EngineCore_DP0 pid=474843) .b8 117
(EngineCore_DP0 pid=474843) .b8 115
(EngineCore_DP0 pid=474843) .b8 101
(EngineCore_DP0 pid=474843) .b8 100
(EngineCore_DP0 pid=474843) .b8 95
(EngineCore_DP0 pid=474843) .b8 113
(EngineCore_DP0 pid=474843) .b8 117
(EngineCore_DP0 pid=474843) .b8 97
(EngineCore_DP0 pid=474843) .b8 110
(EngineCore_DP0 pid=474843) .b8 116
(EngineCore_DP0 pid=474843) .b8 95
(EngineCore_DP0 pid=474843) .b8 115
(EngineCore_DP0 pid=474843) .b8 108
(EngineCore_DP0 pid=474843) .b8 105
(EngineCore_DP0 pid=474843) .b8 100
(EngineCore_DP0 pid=474843) .b8 101
(EngineCore_DP0 pid=474843) .b8 95
(EngineCore_DP0 pid=474843) .b8 116
(EngineCore_DP0 pid=474843) .b8 114
(EngineCore_DP0 pid=474843) .b8 105
(EngineCore_DP0 pid=474843) .b8 116
(EngineCore_DP0 pid=474843) .b8 111
(EngineCore_DP0 pid=474843) .b8 110
(EngineCore_DP0 pid=474843) .b8 47
(EngineCore_DP0 pid=474843) .b8 98
(EngineCore_DP0 pid=474843) .b8 117
(EngineCore_DP0 pid=474843) .b8 105
(EngineCore_DP0 pid=474843) .b8 108
(EngineCore_DP0 pid=474843) .b8 100
(EngineCore_DP0 pid=474843) .b8 47
(EngineCore_DP0 pid=474843) .b8 71
(EngineCore_DP0 pid=474843) .b8 66
(EngineCore_DP0 pid=474843) .b8 49
(EngineCore_DP0 pid=474843) .b8 48
(EngineCore_DP0 pid=474843) .b8 95
(EngineCore_DP0 pid=474843) .b8 99
(EngineCore_DP0 pid=474843) .b8 99
(EngineCore_DP0 pid=474843) .b8 49
(EngineCore_DP0 pid=474843) .b8 50
(EngineCore_DP0 pid=474843) .b8 49
(EngineCore_DP0 pid=474843) .b8 95
(EngineCore_DP0 pid=474843) .b8 112
(EngineCore_DP0 pid=474843) .b8 121
(EngineCore_DP0 pid=474843) .b8 51
(EngineCore_DP0 pid=474843) .b8 49
(EngineCore_DP0 pid=474843) .b8 50
(EngineCore_DP0 pid=474843) .b8 95
(EngineCore_DP0 pid=474843) .b8 99
(EngineCore_DP0 pid=474843) .b8 117
(EngineCore_DP0 pid=474843) .b8 49
(EngineCore_DP0 pid=474843) .b8 50
(EngineCore_DP0 pid=474843) .b8 57
(EngineCore_DP0 pid=474843) .b8 95
(EngineCore_DP0 pid=474843) .b8 97
(EngineCore_DP0 pid=474843) .b8 97
(EngineCore_DP0 pid=474843) .b8 114
(EngineCore_DP0 pid=474843) .b8 99
(EngineCore_DP0 pid=474843) .b8 104
(EngineCore_DP0 pid=474843) .b8 54
(EngineCore_DP0 pid=474843) .b8 52
(EngineCore_DP0 pid=474843) .b8 0
(EngineCore_DP0 pid=474843) .b8 2                                   // Abbrev [2] 0x98:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=474843) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=474843) .b8 113
(EngineCore_DP0 pid=474843) .b8 117
(EngineCore_DP0 pid=474843) .b8 97
(EngineCore_DP0 pid=474843) .b8 110
(EngineCore_DP0 pid=474843) .b8 116
(EngineCore_DP0 pid=474843) .b8 95
(EngineCore_DP0 pid=474843) .b8 115
(EngineCore_DP0 pid=474843) .b8 108
(EngineCore_DP0 pid=474843) .b8 105
(EngineCore_DP0 pid=474843) .b8 100
(EngineCore_DP0 pid=474843) .b8 101
(EngineCore_DP0 pid=474843) .b8 95
(EngineCore_DP0 pid=474843) .b8 102
(EngineCore_DP0 pid=474843) .b8 112
(EngineCore_DP0 pid=474843) .b8 56
(EngineCore_DP0 pid=474843) .b8 95
(EngineCore_DP0 pid=474843) .b8 107
(EngineCore_DP0 pid=474843) .b8 101
(EngineCore_DP0 pid=474843) .b8 114
(EngineCore_DP0 pid=474843) .b8 110
(EngineCore_DP0 pid=474843) .b8 101
(EngineCore_DP0 pid=474843) .b8 108
(EngineCore_DP0 pid=474843) .b8 0
(EngineCore_DP0 pid=474843) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=474843) .b8 3                                   // Abbrev [3] 0xb2:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=474843) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=474843) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=474843) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=474843) .b8 4                                   // Abbrev [4] 0xc7:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=474843) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=474843) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=474843) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=474843) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=474843) .b8 157                                 // DW_AT_call_line
(EngineCore_DP0 pid=474843) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=474843) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=474843) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=474843) 	}
(EngineCore_DP0 pid=474843) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=474843) 
(EngineCore_DP0 pid=474843) ================================================================
(EngineCore_DP0 pid=474843) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=474843) 
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp4fzs63rr.ptx', '-o', '/tmp/tmp4fzs63rr.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866] 
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866] 
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866] 
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp4fzs63rr.ptx -o /tmp/tmp4fzs63rr.ptx.o
(EngineCore_DP0 pid=474843) ERROR 01-25 21:26:14 [core.py:866] 

STDERR:
[2026-01-25 21:25:09] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:25:09] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:25:09] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:25:09] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:25:09] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:25:09] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:25:09] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:25:09] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:25:09] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:25:09] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:25:09] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:25:09] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:25:09] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:25:09] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:25:12] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:25:12] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:25:12] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:25:12] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:25:12] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:25:12] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:25:12] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:25:12] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:25:12] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:25:12] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:25:12] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:25:12] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:25:12] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:25:12] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=474843) [2026-01-25 21:25:13] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=474843) [2026-01-25 21:25:13] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=474843) [2026-01-25 21:25:13] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=474843) [2026-01-25 21:25:13] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=474843) [2026-01-25 21:25:13] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=474843) [2026-01-25 21:25:13] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=474843) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=474843) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:24<00:24, 24.08s/it]
(EngineCore_DP0 pid=474843) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:58<00:00, 30.14s/it]
(EngineCore_DP0 pid=474843) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:58<00:00, 29.23s/it]
(EngineCore_DP0 pid=474843) 
(EngineCore_DP0 pid=474843) [2026-01-25 21:26:13] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=474843) [2026-01-25 21:26:13] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 13860864 bytes
(EngineCore_DP0 pid=474843) [2026-01-25 21:26:13] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=474843) [2026-01-25 21:26:13] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10780672 bytes
(EngineCore_DP0 pid=474843) [2026-01-25 21:26:13] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=474843) [2026-01-25 21:26:13] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 113967104 bytes
(EngineCore_DP0 pid=474843) [2026-01-25 21:26:13] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=474843) [2026-01-25 21:26:13] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 56655872 bytes
(EngineCore_DP0 pid=474843) Process EngineCore_DP0:
(EngineCore_DP0 pid=474843) Traceback (most recent call last):
(EngineCore_DP0 pid=474843)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=474843)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=474843)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=474843)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=474843) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp4fzs63rr.ptx', '-o', '/tmp/tmp4fzs63rr.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=474843) 
(EngineCore_DP0 pid=474843) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=474843) 
(EngineCore_DP0 pid=474843) Traceback (most recent call last):
(EngineCore_DP0 pid=474843)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=474843)     self.run()
(EngineCore_DP0 pid=474843)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=474843)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=474843)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=474843)     raise e
(EngineCore_DP0 pid=474843)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=474843)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=474843)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=474843)     super().__init__(
(EngineCore_DP0 pid=474843)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=474843)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=474843)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=474843)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=474843)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=474843)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=474843)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=474843)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=474843)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=474843)     return func(*args, **kwargs)
(EngineCore_DP0 pid=474843)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=474843)     return func(*args, **kwargs)
(EngineCore_DP0 pid=474843)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=474843)     self.model_runner.profile_run()
(EngineCore_DP0 pid=474843)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=474843)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=474843)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=474843)     return func(*args, **kwargs)
(EngineCore_DP0 pid=474843)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=474843)     outputs = self.model(
(EngineCore_DP0 pid=474843)               ^^^^^^^^^^^
(EngineCore_DP0 pid=474843)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=474843)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=474843)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=474843)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=474843)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=474843)     hidden_states = self.model(
(EngineCore_DP0 pid=474843)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=474843)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=474843)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=474843)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=474843)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=474843)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=474843)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=474843)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=474843)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=474843)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=474843)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=474843)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=474843)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=474843)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=474843)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=474843)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=474843)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=474843)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=474843)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=474843)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=474843)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=474843)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=474843)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=474843)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=474843)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=474843)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=474843)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=474843)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=474843)     return self._linear_fn(
(EngineCore_DP0 pid=474843)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=474843)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=474843)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=474843)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=474843)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=474843)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=474843)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=474843)     return fn(input, L)
(EngineCore_DP0 pid=474843)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=474843)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=474843)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=474843)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=474843)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=474843)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=474843)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=474843)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=474843)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=474843)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=474843)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=474843)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=474843)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=474843)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=474843)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=474843)     raise PTXASError(error)
(EngineCore_DP0 pid=474843) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=474843) `ptxas` stderr:
(EngineCore_DP0 pid=474843) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=474843) 
(EngineCore_DP0 pid=474843) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp4fzs63rr.ptx -o /tmp/tmp4fzs63rr.ptx.o
(EngineCore_DP0 pid=474843) 
[rank0]:[W125 21:26:14.091051424 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=512

========== M=1024 ==========
Time: 2026-01-25 21:26:16
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Qwen2.5-7B-FP8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:26:20 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 21:26:20 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=476003) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=476003) 
(EngineCore_DP0 pid=476003) 
(EngineCore_DP0 pid=476003) ================================================================
(EngineCore_DP0 pid=476003) Internal Triton PTX codegen error
(EngineCore_DP0 pid=476003) `ptxas` stderr:
(EngineCore_DP0 pid=476003) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=476003) 
(EngineCore_DP0 pid=476003) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpv5g5p6wc.ptx -o /tmp/tmpv5g5p6wc.ptx.o
(EngineCore_DP0 pid=476003) 
(EngineCore_DP0 pid=476003) 
(EngineCore_DP0 pid=476003) //
(EngineCore_DP0 pid=476003) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=476003) //
(EngineCore_DP0 pid=476003) 
(EngineCore_DP0 pid=476003) .version 8.7
(EngineCore_DP0 pid=476003) .target sm_121a
(EngineCore_DP0 pid=476003) .address_size 64
(EngineCore_DP0 pid=476003) 
(EngineCore_DP0 pid=476003) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=476003) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=476003)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=476003) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=476003) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=476003) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=476003) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=476003) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=476003) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=476003) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=476003) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=476003) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=476003) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=476003) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=476003) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=476003) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=476003) )
(EngineCore_DP0 pid=476003) .reqntid 512
(EngineCore_DP0 pid=476003) {
(EngineCore_DP0 pid=476003) 	.reg .pred 	%p<28>;
(EngineCore_DP0 pid=476003) 	.reg .b16 	%rs<49>;
(EngineCore_DP0 pid=476003) 	.reg .b32 	%r<139>;
(EngineCore_DP0 pid=476003) 	.reg .b64 	%rd<17>;
(EngineCore_DP0 pid=476003) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=476003) $L__func_begin0:
(EngineCore_DP0 pid=476003) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=476003) 
(EngineCore_DP0 pid=476003) // %bb.0:
(EngineCore_DP0 pid=476003) 	ld.param.b32 	%r21, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=476003) 	ld.param.b32 	%r20, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=476003) 	ld.param.b32 	%r19, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=476003) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=476003) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=476003) $L__tmp0:
(EngineCore_DP0 pid=476003) 	.loc	1 143 24                        // quant_slide_tuned_Qwen2.5-7B.py:143:24
(EngineCore_DP0 pid=476003) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=476003) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=476003) 	.loc	1 148 26                        // quant_slide_tuned_Qwen2.5-7B.py:148:26
(EngineCore_DP0 pid=476003) 	mul.lo.s32 	%r24, %r23, %r1;
(EngineCore_DP0 pid=476003) 	.loc	1 148 20                        // quant_slide_tuned_Qwen2.5-7B.py:148:20
(EngineCore_DP0 pid=476003) 	mad.wide.s32 	%rd1, %r24, 2, %rd4;
(EngineCore_DP0 pid=476003) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=476003) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=476003) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=476003) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=476003) 	setp.lt.s32 	%p1, %r20, 1;
(EngineCore_DP0 pid=476003) 	mov.b32 	%r137, 0f2B8CBCCC;
(EngineCore_DP0 pid=476003) 	setp.eq.b32 	%p27, %r2, 0;
(EngineCore_DP0 pid=476003) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=476003) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=476003) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=476003) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=476003) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=476003) 	shr.u32 	%r33, %r2, 3;
(EngineCore_DP0 pid=476003) 	and.b32 	%r34, %r33, 60;
(EngineCore_DP0 pid=476003) 	mov.b32 	%r35, global_smem;
(EngineCore_DP0 pid=476003) 	add.s32 	%r45, %r35, %r34;
(EngineCore_DP0 pid=476003) 	shl.b32 	%r36, %r2, 2;
(EngineCore_DP0 pid=476003) 	add.s32 	%r48, %r35, %r36;
(EngineCore_DP0 pid=476003) 	mov.b32 	%r41, 0;
(EngineCore_DP0 pid=476003) 	mov.b32 	%r135, 0f00000000;
(EngineCore_DP0 pid=476003) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=476003) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=476003) 	mov.b32 	%r136, %r41;
(EngineCore_DP0 pid=476003) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=476003) 	.loc	1 155 22                        // quant_slide_tuned_Qwen2.5-7B.py:155:22
(EngineCore_DP0 pid=476003) 	add.s32 	%r51, %r4, %r136;
(EngineCore_DP0 pid=476003) 	setp.lt.s32 	%p2, %r51, %r19;
(EngineCore_DP0 pid=476003) 	.loc	1 156 29                        // quant_slide_tuned_Qwen2.5-7B.py:156:29
(EngineCore_DP0 pid=476003) 	mad.wide.s32 	%rd6, %r51, 2, %rd1;
(EngineCore_DP0 pid=476003) 	.loc	1 156 21                        // quant_slide_tuned_Qwen2.5-7B.py:156:21
(EngineCore_DP0 pid=476003) 	// begin inline asm
(EngineCore_DP0 pid=476003) 	mov.u32 %r37, %r41;
(EngineCore_DP0 pid=476003) 	mov.u32 %r38, %r41;
(EngineCore_DP0 pid=476003) 	mov.u32 %r39, %r41;
(EngineCore_DP0 pid=476003) 	mov.u32 %r40, %r41;
(EngineCore_DP0 pid=476003) 	@%p2 ld.global.v4.b32 { %r37, %r38, %r39, %r40 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=476003) 	// end inline asm
(EngineCore_DP0 pid=476003) 	mov.b32 	{%rs1, %rs2}, %r37;
(EngineCore_DP0 pid=476003) 	mov.b32 	{%rs3, %rs4}, %r38;
(EngineCore_DP0 pid=476003) 	mov.b32 	{%rs5, %rs6}, %r39;
(EngineCore_DP0 pid=476003) 	mov.b32 	{%rs7, %rs8}, %r40;
(EngineCore_DP0 pid=476003) 	.loc	1 157 50                        // quant_slide_tuned_Qwen2.5-7B.py:157:50
(EngineCore_DP0 pid=476003) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=476003) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=476003) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=476003) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=476003) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=476003) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=476003) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=476003) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=476003) $L__tmp1:
(EngineCore_DP0 pid=476003) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=476003) 	bar.sync 	0;
(EngineCore_DP0 pid=476003) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=476003) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=476003) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=476003) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=476003) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=476003) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=476003) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=476003) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=476003) 	cvt.f32.bf16 	%r52, %rs23;
(EngineCore_DP0 pid=476003) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=476003) 	shfl.sync.bfly.b32 	%r53, %r52, 16, 31, -1;
(EngineCore_DP0 pid=476003) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=476003) 	max.f32 	%r54, %r52, %r53;
(EngineCore_DP0 pid=476003) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=476003) 	shfl.sync.bfly.b32 	%r55, %r54, 8, 31, -1;
(EngineCore_DP0 pid=476003) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=476003) 	max.f32 	%r56, %r54, %r55;
(EngineCore_DP0 pid=476003) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=476003) 	shfl.sync.bfly.b32 	%r57, %r56, 4, 31, -1;
(EngineCore_DP0 pid=476003) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=476003) 	max.f32 	%r58, %r56, %r57;
(EngineCore_DP0 pid=476003) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=476003) 	shfl.sync.bfly.b32 	%r59, %r58, 2, 31, -1;
(EngineCore_DP0 pid=476003) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=476003) 	max.f32 	%r60, %r58, %r59;
(EngineCore_DP0 pid=476003) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=476003) 	shfl.sync.bfly.b32 	%r61, %r60, 1, 31, -1;
(EngineCore_DP0 pid=476003) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=476003) 	max.f32 	%r46, %r60, %r61;
(EngineCore_DP0 pid=476003) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=476003) 	// begin inline asm
(EngineCore_DP0 pid=476003) 	@%p3 st.shared.b32 [ %r45 + 0 ], %r46;
(EngineCore_DP0 pid=476003) 	// end inline asm
(EngineCore_DP0 pid=476003) 	bar.sync 	0;
(EngineCore_DP0 pid=476003) 	// begin inline asm
(EngineCore_DP0 pid=476003) 	@%p4 ld.shared.b32 %r47, [ %r48 + 0 ];
(EngineCore_DP0 pid=476003) 	// end inline asm
(EngineCore_DP0 pid=476003) 	shfl.sync.bfly.b32 	%r62, %r47, 8, 31, -1;
(EngineCore_DP0 pid=476003) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=476003) 	max.f32 	%r63, %r47, %r62;
(EngineCore_DP0 pid=476003) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=476003) 	shfl.sync.bfly.b32 	%r64, %r63, 4, 31, -1;
(EngineCore_DP0 pid=476003) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=476003) 	max.f32 	%r65, %r63, %r64;
(EngineCore_DP0 pid=476003) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=476003) 	shfl.sync.bfly.b32 	%r66, %r65, 2, 31, -1;
(EngineCore_DP0 pid=476003) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=476003) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=476003) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=476003) 	shfl.sync.bfly.b32 	%r68, %r67, 1, 31, -1;
(EngineCore_DP0 pid=476003) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=476003) 	max.f32 	%r50, %r67, %r68;
(EngineCore_DP0 pid=476003) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=476003) 	// begin inline asm
(EngineCore_DP0 pid=476003) 	@%p27 st.shared.b32 [ %r48 + 0 ], %r50;
(EngineCore_DP0 pid=476003) 	// end inline asm
(EngineCore_DP0 pid=476003) 	bar.sync 	0;
(EngineCore_DP0 pid=476003) 	ld.shared.b32 	%r69, [global_smem];
(EngineCore_DP0 pid=476003) $L__tmp2:
(EngineCore_DP0 pid=476003) 	.loc	1 157 36                        // quant_slide_tuned_Qwen2.5-7B.py:157:36
(EngineCore_DP0 pid=476003) 	max.f32 	%r135, %r135, %r69;
(EngineCore_DP0 pid=476003) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=476003) 	add.s32 	%r136, %r136, 4096;
(EngineCore_DP0 pid=476003) 	setp.lt.s32 	%p6, %r136, %r20;
(EngineCore_DP0 pid=476003) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=476003) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=476003) 	.loc	1 159 32                        // quant_slide_tuned_Qwen2.5-7B.py:159:32
(EngineCore_DP0 pid=476003) 	max.f32 	%r137, %r135, 0f2B8CBCCC;
(EngineCore_DP0 pid=476003) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=476003) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-7B.py:0:32
(EngineCore_DP0 pid=476003) 	mov.b32 	%r71, 0f43E00000;
(EngineCore_DP0 pid=476003) 	.loc	1 160 32                        // quant_slide_tuned_Qwen2.5-7B.py:160:32
(EngineCore_DP0 pid=476003) 	div.full.f32 	%r72, %r137, %r71;
(EngineCore_DP0 pid=476003) 	.loc	1 160 41                        // quant_slide_tuned_Qwen2.5-7B.py:160:41
(EngineCore_DP0 pid=476003) 	max.f32 	%r70, %r72, 0f36924925;
(EngineCore_DP0 pid=476003) 	.loc	1 162 25                        // quant_slide_tuned_Qwen2.5-7B.py:162:25
(EngineCore_DP0 pid=476003) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=476003) 	.loc	1 162 30                        // quant_slide_tuned_Qwen2.5-7B.py:162:30
(EngineCore_DP0 pid=476003) 	// begin inline asm
(EngineCore_DP0 pid=476003) 	@%p27 st.global.b32 [ %rd7 + 0 ], { %r70 };
(EngineCore_DP0 pid=476003) 	// end inline asm
(EngineCore_DP0 pid=476003) 	.loc	1 165 29                        // quant_slide_tuned_Qwen2.5-7B.py:165:29
(EngineCore_DP0 pid=476003) 	shl.b32 	%r15, %r21, 1;
(EngineCore_DP0 pid=476003) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=476003) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=476003) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=476003) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=476003) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-7B.py:0:41
(EngineCore_DP0 pid=476003) 	ld.param.b32 	%r25, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=476003) 	shr.s32 	%r26, %r25, 31;
(EngineCore_DP0 pid=476003) 	shr.u32 	%r27, %r26, 30;
(EngineCore_DP0 pid=476003) 	add.s32 	%r28, %r25, %r27;
(EngineCore_DP0 pid=476003) 	shr.s32 	%r29, %r28, 2;
(EngineCore_DP0 pid=476003) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=476003) 	mul.lo.s32 	%r30, %r29, %r1;
(EngineCore_DP0 pid=476003) 	mad.wide.s32 	%rd2, %r30, 4, %rd5;
(EngineCore_DP0 pid=476003) 	div.full.f32 	%r14, %r71, %r137;
(EngineCore_DP0 pid=476003) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=476003) 	mov.b32 	%r138, 0;
(EngineCore_DP0 pid=476003) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=476003)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=476003) 	.loc	1 168 31                        // quant_slide_tuned_Qwen2.5-7B.py:168:31
(EngineCore_DP0 pid=476003) 	add.s32 	%r84, %r16, %r138;
(EngineCore_DP0 pid=476003) 	.loc	1 169 30                        // quant_slide_tuned_Qwen2.5-7B.py:169:30
(EngineCore_DP0 pid=476003) 	add.s32 	%r85, %r138, 1;
(EngineCore_DP0 pid=476003) 	setp.lt.s32 	%p17, %r84, %r15;
(EngineCore_DP0 pid=476003) 	.loc	1 172 24                        // quant_slide_tuned_Qwen2.5-7B.py:172:24
(EngineCore_DP0 pid=476003) 	shr.u32 	%r86, %r84, 1;
(EngineCore_DP0 pid=476003) 	.loc	1 173 23                        // quant_slide_tuned_Qwen2.5-7B.py:173:23
(EngineCore_DP0 pid=476003) 	shr.u32 	%r87, %r85, 31;
(EngineCore_DP0 pid=476003) 	add.s32 	%r88, %r85, %r87;
(EngineCore_DP0 pid=476003) 	and.b32 	%r89, %r88, 2147483646;
(EngineCore_DP0 pid=476003) 	sub.s32 	%r90, %r85, %r89;
(EngineCore_DP0 pid=476003) 	.loc	1 174 22                        // quant_slide_tuned_Qwen2.5-7B.py:174:22
(EngineCore_DP0 pid=476003) 	mul.lo.s32 	%r91, %r86, 6;
(EngineCore_DP0 pid=476003) 	.loc	1 174 30                        // quant_slide_tuned_Qwen2.5-7B.py:174:30
(EngineCore_DP0 pid=476003) 	shl.b32 	%r92, %r90, 1;
(EngineCore_DP0 pid=476003) 	.loc	1 174 26                        // quant_slide_tuned_Qwen2.5-7B.py:174:26
(EngineCore_DP0 pid=476003) 	add.s32 	%r93, %r91, %r92;
(EngineCore_DP0 pid=476003) 	.loc	1 177 53                        // quant_slide_tuned_Qwen2.5-7B.py:177:53
(EngineCore_DP0 pid=476003) 	setp.lt.s32 	%p18, %r91, %r19;
(EngineCore_DP0 pid=476003) 	setp.lt.s32 	%p19, %r93, %r19;
(EngineCore_DP0 pid=476003) 	.loc	1 177 37                        // quant_slide_tuned_Qwen2.5-7B.py:177:37
(EngineCore_DP0 pid=476003) 	and.pred 	%p9, %p17, %p18;
(EngineCore_DP0 pid=476003) 	and.pred 	%p10, %p17, %p19;
(EngineCore_DP0 pid=476003) 	.loc	1 176 29                        // quant_slide_tuned_Qwen2.5-7B.py:176:29
(EngineCore_DP0 pid=476003) 	mad.wide.s32 	%rd8, %r91, 2, %rd1;
(EngineCore_DP0 pid=476003) 	mad.wide.s32 	%rd9, %r93, 2, %rd1;
(EngineCore_DP0 pid=476003) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=476003) 	.loc	1 176 21                        // quant_slide_tuned_Qwen2.5-7B.py:176:21
(EngineCore_DP0 pid=476003) 	// begin inline asm
(EngineCore_DP0 pid=476003) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=476003) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=476003) 	// end inline asm
(EngineCore_DP0 pid=476003) 	// begin inline asm
(EngineCore_DP0 pid=476003) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=476003) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=476003) 	// end inline asm
(EngineCore_DP0 pid=476003) 	.loc	1 177 79                        // quant_slide_tuned_Qwen2.5-7B.py:177:79
(EngineCore_DP0 pid=476003) 	cvt.f32.bf16 	%r94, %rs24;
(EngineCore_DP0 pid=476003) 	cvt.f32.bf16 	%r95, %rs26;
(EngineCore_DP0 pid=476003) 	.loc	1 179 48                        // quant_slide_tuned_Qwen2.5-7B.py:179:48
(EngineCore_DP0 pid=476003) 	or.b32 	%r96, %r91, 1;
(EngineCore_DP0 pid=476003) 	or.b32 	%r97, %r93, 1;
(EngineCore_DP0 pid=476003) 	.loc	1 179 53                        // quant_slide_tuned_Qwen2.5-7B.py:179:53
(EngineCore_DP0 pid=476003) 	setp.lt.s32 	%p20, %r96, %r19;
(EngineCore_DP0 pid=476003) 	setp.lt.s32 	%p21, %r97, %r19;
(EngineCore_DP0 pid=476003) 	.loc	1 179 37                        // quant_slide_tuned_Qwen2.5-7B.py:179:37
(EngineCore_DP0 pid=476003) 	and.pred 	%p11, %p17, %p20;
(EngineCore_DP0 pid=476003) 	and.pred 	%p12, %p17, %p21;
(EngineCore_DP0 pid=476003) 	.loc	1 178 39                        // quant_slide_tuned_Qwen2.5-7B.py:178:39
(EngineCore_DP0 pid=476003) 	add.s64 	%rd10, %rd8, 2;
(EngineCore_DP0 pid=476003) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=476003) 	.loc	1 178 21                        // quant_slide_tuned_Qwen2.5-7B.py:178:21
(EngineCore_DP0 pid=476003) 	// begin inline asm
(EngineCore_DP0 pid=476003) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=476003) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=476003) 	// end inline asm
(EngineCore_DP0 pid=476003) 	// begin inline asm
(EngineCore_DP0 pid=476003) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=476003) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=476003) 	// end inline asm
(EngineCore_DP0 pid=476003) 	.loc	1 179 79                        // quant_slide_tuned_Qwen2.5-7B.py:179:79
(EngineCore_DP0 pid=476003) 	cvt.f32.bf16 	%r98, %rs28;
(EngineCore_DP0 pid=476003) 	cvt.f32.bf16 	%r99, %rs30;
(EngineCore_DP0 pid=476003) 	.loc	1 181 48                        // quant_slide_tuned_Qwen2.5-7B.py:181:48
(EngineCore_DP0 pid=476003) 	add.s32 	%r100, %r91, 2;
(EngineCore_DP0 pid=476003) 	add.s32 	%r101, %r93, 2;
(EngineCore_DP0 pid=476003) 	.loc	1 181 53                        // quant_slide_tuned_Qwen2.5-7B.py:181:53
(EngineCore_DP0 pid=476003) 	setp.lt.s32 	%p22, %r100, %r19;
(EngineCore_DP0 pid=476003) 	setp.lt.s32 	%p23, %r101, %r19;
(EngineCore_DP0 pid=476003) 	.loc	1 181 37                        // quant_slide_tuned_Qwen2.5-7B.py:181:37
(EngineCore_DP0 pid=476003) 	and.pred 	%p13, %p17, %p22;
(EngineCore_DP0 pid=476003) 	and.pred 	%p14, %p17, %p23;
(EngineCore_DP0 pid=476003) 	.loc	1 180 39                        // quant_slide_tuned_Qwen2.5-7B.py:180:39
(EngineCore_DP0 pid=476003) 	add.s64 	%rd12, %rd8, 4;
(EngineCore_DP0 pid=476003) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=476003) 	.loc	1 180 21                        // quant_slide_tuned_Qwen2.5-7B.py:180:21
(EngineCore_DP0 pid=476003) 	// begin inline asm
(EngineCore_DP0 pid=476003) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=476003) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=476003) 	// end inline asm
(EngineCore_DP0 pid=476003) 	// begin inline asm
(EngineCore_DP0 pid=476003) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=476003) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=476003) 	// end inline asm
(EngineCore_DP0 pid=476003) 	.loc	1 181 79                        // quant_slide_tuned_Qwen2.5-7B.py:181:79
(EngineCore_DP0 pid=476003) 	cvt.f32.bf16 	%r102, %rs32;
(EngineCore_DP0 pid=476003) 	cvt.f32.bf16 	%r103, %rs34;
(EngineCore_DP0 pid=476003) 	.loc	1 183 48                        // quant_slide_tuned_Qwen2.5-7B.py:183:48
(EngineCore_DP0 pid=476003) 	add.s32 	%r104, %r91, 3;
(EngineCore_DP0 pid=476003) 	add.s32 	%r105, %r93, 3;
(EngineCore_DP0 pid=476003) 	.loc	1 183 53                        // quant_slide_tuned_Qwen2.5-7B.py:183:53
(EngineCore_DP0 pid=476003) 	setp.lt.s32 	%p24, %r104, %r19;
(EngineCore_DP0 pid=476003) 	setp.lt.s32 	%p25, %r105, %r19;
(EngineCore_DP0 pid=476003) 	.loc	1 183 37                        // quant_slide_tuned_Qwen2.5-7B.py:183:37
(EngineCore_DP0 pid=476003) 	and.pred 	%p15, %p17, %p24;
(EngineCore_DP0 pid=476003) 	and.pred 	%p16, %p17, %p25;
(EngineCore_DP0 pid=476003) 	.loc	1 182 39                        // quant_slide_tuned_Qwen2.5-7B.py:182:39
(EngineCore_DP0 pid=476003) 	add.s64 	%rd14, %rd8, 6;
(EngineCore_DP0 pid=476003) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=476003) 	.loc	1 182 21                        // quant_slide_tuned_Qwen2.5-7B.py:182:21
(EngineCore_DP0 pid=476003) 	// begin inline asm
(EngineCore_DP0 pid=476003) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=476003) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=476003) 	// end inline asm
(EngineCore_DP0 pid=476003) 	// begin inline asm
(EngineCore_DP0 pid=476003) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=476003) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=476003) 	// end inline asm
(EngineCore_DP0 pid=476003) 	.loc	1 183 79                        // quant_slide_tuned_Qwen2.5-7B.py:183:79
(EngineCore_DP0 pid=476003) 	cvt.f32.bf16 	%r106, %rs36;
(EngineCore_DP0 pid=476003) 	cvt.f32.bf16 	%r107, %rs38;
(EngineCore_DP0 pid=476003) 	.loc	1 185 27                        // quant_slide_tuned_Qwen2.5-7B.py:185:27
(EngineCore_DP0 pid=476003) 	mul.f32 	%r108, %r14, %r94;
(EngineCore_DP0 pid=476003) 	mul.f32 	%r109, %r14, %r95;
(EngineCore_DP0 pid=476003) 	mov.b32 	%r110, 0f43E00000;
(EngineCore_DP0 pid=476003) 	.loc	1 185 48                        // quant_slide_tuned_Qwen2.5-7B.py:185:48
(EngineCore_DP0 pid=476003) 	min.xorsign.abs.f32 	%r74, %r108, %r110;
(EngineCore_DP0 pid=476003) 	min.xorsign.abs.f32 	%r75, %r109, %r110;
(EngineCore_DP0 pid=476003) 	.loc	1 185 60                        // quant_slide_tuned_Qwen2.5-7B.py:185:60
(EngineCore_DP0 pid=476003) 	// begin inline asm
(EngineCore_DP0 pid=476003) 	cvt.rn.satfinite.e4m3x2.f32  %rs40, %r75, %r74; 
(EngineCore_DP0 pid=476003) 
(EngineCore_DP0 pid=476003) 	// end inline asm
(EngineCore_DP0 pid=476003) 	shr.u16 	%rs44, %rs40, 8;
(EngineCore_DP0 pid=476003) 	.loc	1 186 27                        // quant_slide_tuned_Qwen2.5-7B.py:186:27
(EngineCore_DP0 pid=476003) 	mul.f32 	%r111, %r14, %r98;
(EngineCore_DP0 pid=476003) 	mul.f32 	%r112, %r14, %r99;
(EngineCore_DP0 pid=476003) 	.loc	1 186 48                        // quant_slide_tuned_Qwen2.5-7B.py:186:48
(EngineCore_DP0 pid=476003) 	min.xorsign.abs.f32 	%r76, %r111, %r110;
(EngineCore_DP0 pid=476003) 	min.xorsign.abs.f32 	%r77, %r112, %r110;
(EngineCore_DP0 pid=476003) 	.loc	1 186 60                        // quant_slide_tuned_Qwen2.5-7B.py:186:60
(EngineCore_DP0 pid=476003) 	// begin inline asm
(EngineCore_DP0 pid=476003) 	cvt.rn.satfinite.e4m3x2.f32  %rs41, %r77, %r76; 
(EngineCore_DP0 pid=476003) 
(EngineCore_DP0 pid=476003) 	// end inline asm
(EngineCore_DP0 pid=476003) 	shr.u16 	%rs45, %rs41, 8;
(EngineCore_DP0 pid=476003) 	.loc	1 187 27                        // quant_slide_tuned_Qwen2.5-7B.py:187:27
(EngineCore_DP0 pid=476003) 	mul.f32 	%r113, %r14, %r102;
(EngineCore_DP0 pid=476003) 	mul.f32 	%r114, %r14, %r103;
(EngineCore_DP0 pid=476003) 	.loc	1 187 48                        // quant_slide_tuned_Qwen2.5-7B.py:187:48
(EngineCore_DP0 pid=476003) 	min.xorsign.abs.f32 	%r78, %r113, %r110;
(EngineCore_DP0 pid=476003) 	min.xorsign.abs.f32 	%r79, %r114, %r110;
(EngineCore_DP0 pid=476003) 	.loc	1 187 60                        // quant_slide_tuned_Qwen2.5-7B.py:187:60
(EngineCore_DP0 pid=476003) 	// begin inline asm
(EngineCore_DP0 pid=476003) 	cvt.rn.satfinite.e4m3x2.f32  %rs42, %r79, %r78; 
(EngineCore_DP0 pid=476003) 
(EngineCore_DP0 pid=476003) 	// end inline asm
(EngineCore_DP0 pid=476003) 	shr.u16 	%rs46, %rs42, 8;
(EngineCore_DP0 pid=476003) 	.loc	1 188 27                        // quant_slide_tuned_Qwen2.5-7B.py:188:27
(EngineCore_DP0 pid=476003) 	mul.f32 	%r115, %r14, %r106;
(EngineCore_DP0 pid=476003) 	mul.f32 	%r116, %r14, %r107;
(EngineCore_DP0 pid=476003) 	.loc	1 188 48                        // quant_slide_tuned_Qwen2.5-7B.py:188:48
(EngineCore_DP0 pid=476003) 	min.xorsign.abs.f32 	%r80, %r115, %r110;
(EngineCore_DP0 pid=476003) 	min.xorsign.abs.f32 	%r81, %r116, %r110;
(EngineCore_DP0 pid=476003) 	.loc	1 188 60                        // quant_slide_tuned_Qwen2.5-7B.py:188:60
(EngineCore_DP0 pid=476003) 	// begin inline asm
(EngineCore_DP0 pid=476003) 	cvt.rn.satfinite.e4m3x2.f32  %rs43, %r81, %r80; 
(EngineCore_DP0 pid=476003) 
(EngineCore_DP0 pid=476003) 	// end inline asm
(EngineCore_DP0 pid=476003) 	shr.u16 	%rs47, %rs43, 8;
(EngineCore_DP0 pid=476003) 	.loc	1 190 45                        // quant_slide_tuned_Qwen2.5-7B.py:190:45
(EngineCore_DP0 pid=476003) 	cvt.u32.u16 	%r117, %rs40;
(EngineCore_DP0 pid=476003) 	and.b32 	%r118, %r117, 255;
(EngineCore_DP0 pid=476003) 	cvt.u32.u16 	%r119, %rs44;
(EngineCore_DP0 pid=476003) 	.loc	1 192 45                        // quant_slide_tuned_Qwen2.5-7B.py:192:45
(EngineCore_DP0 pid=476003) 	cvt.u32.u16 	%r120, %rs42;
(EngineCore_DP0 pid=476003) 	and.b32 	%r121, %r120, 255;
(EngineCore_DP0 pid=476003) 	cvt.u32.u16 	%r122, %rs46;
(EngineCore_DP0 pid=476003) 	.loc	1 193 45                        // quant_slide_tuned_Qwen2.5-7B.py:193:45
(EngineCore_DP0 pid=476003) 	cvt.u32.u16 	%r123, %rs43;
(EngineCore_DP0 pid=476003) 	cvt.u32.u16 	%r124, %rs47;
(EngineCore_DP0 pid=476003) 	.loc	1 195 30                        // quant_slide_tuned_Qwen2.5-7B.py:195:30
(EngineCore_DP0 pid=476003) 	and.b16 	%rs48, %rs41, 255;
(EngineCore_DP0 pid=476003) 	mul.wide.u16 	%r125, %rs48, 256;
(EngineCore_DP0 pid=476003) 	mul.wide.u16 	%r126, %rs45, 256;
(EngineCore_DP0 pid=476003) 	.loc	1 195 24                        // quant_slide_tuned_Qwen2.5-7B.py:195:24
(EngineCore_DP0 pid=476003) 	or.b32 	%r127, %r125, %r118;
(EngineCore_DP0 pid=476003) 	or.b32 	%r128, %r126, %r119;
(EngineCore_DP0 pid=476003) 	.loc	1 195 42                        // quant_slide_tuned_Qwen2.5-7B.py:195:42
(EngineCore_DP0 pid=476003) 	shl.b32 	%r129, %r121, 16;
(EngineCore_DP0 pid=476003) 	shl.b32 	%r130, %r122, 16;
(EngineCore_DP0 pid=476003) 	.loc	1 195 36                        // quant_slide_tuned_Qwen2.5-7B.py:195:36
(EngineCore_DP0 pid=476003) 	or.b32 	%r131, %r127, %r129;
(EngineCore_DP0 pid=476003) 	or.b32 	%r132, %r128, %r130;
(EngineCore_DP0 pid=476003) 	.loc	1 195 55                        // quant_slide_tuned_Qwen2.5-7B.py:195:55
(EngineCore_DP0 pid=476003) 	shl.b32 	%r133, %r123, 24;
(EngineCore_DP0 pid=476003) 	shl.b32 	%r134, %r124, 24;
(EngineCore_DP0 pid=476003) 	.loc	1 195 49                        // quant_slide_tuned_Qwen2.5-7B.py:195:49
(EngineCore_DP0 pid=476003) 	or.b32 	%r82, %r131, %r133;
(EngineCore_DP0 pid=476003) 	or.b32 	%r83, %r132, %r134;
(EngineCore_DP0 pid=476003) 	.loc	1 196 29                        // quant_slide_tuned_Qwen2.5-7B.py:196:29
(EngineCore_DP0 pid=476003) 	mad.wide.s32 	%rd16, %r84, 4, %rd2;
(EngineCore_DP0 pid=476003) 	.loc	1 196 39                        // quant_slide_tuned_Qwen2.5-7B.py:196:39
(EngineCore_DP0 pid=476003) 	// begin inline asm
(EngineCore_DP0 pid=476003) 	@%p17 st.global.v2.b32 [ %rd16 + 0 ], { %r82, %r83 };
(EngineCore_DP0 pid=476003) 	// end inline asm
(EngineCore_DP0 pid=476003) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=476003) 	add.s32 	%r138, %r138, 1024;
(EngineCore_DP0 pid=476003) 	setp.lt.s32 	%p26, %r138, %r15;
(EngineCore_DP0 pid=476003) 	@%p26 bra 	$L__BB0_6;
(EngineCore_DP0 pid=476003) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=476003) 	.loc	1 167 4                         // quant_slide_tuned_Qwen2.5-7B.py:167:4
(EngineCore_DP0 pid=476003) 	ret;
(EngineCore_DP0 pid=476003) $L__tmp3:
(EngineCore_DP0 pid=476003) $L__func_end0:
(EngineCore_DP0 pid=476003)                                         // -- End function
(EngineCore_DP0 pid=476003) }
(EngineCore_DP0 pid=476003) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py"
(EngineCore_DP0 pid=476003) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=476003) 	.section	.debug_abbrev
(EngineCore_DP0 pid=476003) 	{
(EngineCore_DP0 pid=476003) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=476003) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=476003) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=476003) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=476003) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=476003) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=476003) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=476003) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=476003) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=476003) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=476003) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=476003) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=476003) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=476003) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=476003) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=476003) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=476003) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=476003) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=476003) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=476003) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=476003) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=476003) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=476003) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=476003) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=476003) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=476003) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=476003) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=476003) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=476003) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=476003) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=476003) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=476003) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=476003) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=476003) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=476003) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=476003) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=476003) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=476003) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=476003) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=476003) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=476003) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=476003) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=476003) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=476003) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=476003) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=476003) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=476003) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=476003) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=476003) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=476003) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=476003) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=476003) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=476003) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=476003) 	}
(EngineCore_DP0 pid=476003) 	.section	.debug_info
(EngineCore_DP0 pid=476003) 	{
(EngineCore_DP0 pid=476003) .b32 221                                // Length of Unit
(EngineCore_DP0 pid=476003) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=476003) .b8 0
(EngineCore_DP0 pid=476003) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=476003) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=476003) .b8 1                                   // Abbrev [1] 0xb:0xd6 DW_TAG_compile_unit
(EngineCore_DP0 pid=476003) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=476003) .b8 114
(EngineCore_DP0 pid=476003) .b8 105
(EngineCore_DP0 pid=476003) .b8 116
(EngineCore_DP0 pid=476003) .b8 111
(EngineCore_DP0 pid=476003) .b8 110
(EngineCore_DP0 pid=476003) .b8 0
(EngineCore_DP0 pid=476003) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=476003) .b8 0
(EngineCore_DP0 pid=476003) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=476003) .b8 117
(EngineCore_DP0 pid=476003) .b8 97
(EngineCore_DP0 pid=476003) .b8 110
(EngineCore_DP0 pid=476003) .b8 116
(EngineCore_DP0 pid=476003) .b8 95
(EngineCore_DP0 pid=476003) .b8 115
(EngineCore_DP0 pid=476003) .b8 108
(EngineCore_DP0 pid=476003) .b8 105
(EngineCore_DP0 pid=476003) .b8 100
(EngineCore_DP0 pid=476003) .b8 101
(EngineCore_DP0 pid=476003) .b8 95
(EngineCore_DP0 pid=476003) .b8 116
(EngineCore_DP0 pid=476003) .b8 117
(EngineCore_DP0 pid=476003) .b8 110
(EngineCore_DP0 pid=476003) .b8 101
(EngineCore_DP0 pid=476003) .b8 100
(EngineCore_DP0 pid=476003) .b8 95
(EngineCore_DP0 pid=476003) .b8 81
(EngineCore_DP0 pid=476003) .b8 119
(EngineCore_DP0 pid=476003) .b8 101
(EngineCore_DP0 pid=476003) .b8 110
(EngineCore_DP0 pid=476003) .b8 50
(EngineCore_DP0 pid=476003) .b8 46
(EngineCore_DP0 pid=476003) .b8 53
(EngineCore_DP0 pid=476003) .b8 45
(EngineCore_DP0 pid=476003) .b8 55
(EngineCore_DP0 pid=476003) .b8 66
(EngineCore_DP0 pid=476003) .b8 46
(EngineCore_DP0 pid=476003) .b8 112
(EngineCore_DP0 pid=476003) .b8 121
(EngineCore_DP0 pid=476003) .b8 0
(EngineCore_DP0 pid=476003) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=476003) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=476003) .b8 114
(EngineCore_DP0 pid=476003) .b8 111
(EngineCore_DP0 pid=476003) .b8 111
(EngineCore_DP0 pid=476003) .b8 116
(EngineCore_DP0 pid=476003) .b8 47
(EngineCore_DP0 pid=476003) .b8 118
(EngineCore_DP0 pid=476003) .b8 108
(EngineCore_DP0 pid=476003) .b8 108
(EngineCore_DP0 pid=476003) .b8 109
(EngineCore_DP0 pid=476003) .b8 98
(EngineCore_DP0 pid=476003) .b8 101
(EngineCore_DP0 pid=476003) .b8 110
(EngineCore_DP0 pid=476003) .b8 99
(EngineCore_DP0 pid=476003) .b8 104
(EngineCore_DP0 pid=476003) .b8 47
(EngineCore_DP0 pid=476003) .b8 115
(EngineCore_DP0 pid=476003) .b8 108
(EngineCore_DP0 pid=476003) .b8 105
(EngineCore_DP0 pid=476003) .b8 100
(EngineCore_DP0 pid=476003) .b8 101
(EngineCore_DP0 pid=476003) .b8 115
(EngineCore_DP0 pid=476003) .b8 112
(EngineCore_DP0 pid=476003) .b8 97
(EngineCore_DP0 pid=476003) .b8 114
(EngineCore_DP0 pid=476003) .b8 115
(EngineCore_DP0 pid=476003) .b8 101
(EngineCore_DP0 pid=476003) .b8 47
(EngineCore_DP0 pid=476003) .b8 99
(EngineCore_DP0 pid=476003) .b8 115
(EngineCore_DP0 pid=476003) .b8 114
(EngineCore_DP0 pid=476003) .b8 99
(EngineCore_DP0 pid=476003) .b8 47
(EngineCore_DP0 pid=476003) .b8 102
(EngineCore_DP0 pid=476003) .b8 117
(EngineCore_DP0 pid=476003) .b8 115
(EngineCore_DP0 pid=476003) .b8 101
(EngineCore_DP0 pid=476003) .b8 100
(EngineCore_DP0 pid=476003) .b8 95
(EngineCore_DP0 pid=476003) .b8 113
(EngineCore_DP0 pid=476003) .b8 117
(EngineCore_DP0 pid=476003) .b8 97
(EngineCore_DP0 pid=476003) .b8 110
(EngineCore_DP0 pid=476003) .b8 116
(EngineCore_DP0 pid=476003) .b8 95
(EngineCore_DP0 pid=476003) .b8 115
(EngineCore_DP0 pid=476003) .b8 108
(EngineCore_DP0 pid=476003) .b8 105
(EngineCore_DP0 pid=476003) .b8 100
(EngineCore_DP0 pid=476003) .b8 101
(EngineCore_DP0 pid=476003) .b8 95
(EngineCore_DP0 pid=476003) .b8 116
(EngineCore_DP0 pid=476003) .b8 114
(EngineCore_DP0 pid=476003) .b8 105
(EngineCore_DP0 pid=476003) .b8 116
(EngineCore_DP0 pid=476003) .b8 111
(EngineCore_DP0 pid=476003) .b8 110
(EngineCore_DP0 pid=476003) .b8 47
(EngineCore_DP0 pid=476003) .b8 98
(EngineCore_DP0 pid=476003) .b8 117
(EngineCore_DP0 pid=476003) .b8 105
(EngineCore_DP0 pid=476003) .b8 108
(EngineCore_DP0 pid=476003) .b8 100
(EngineCore_DP0 pid=476003) .b8 47
(EngineCore_DP0 pid=476003) .b8 71
(EngineCore_DP0 pid=476003) .b8 66
(EngineCore_DP0 pid=476003) .b8 49
(EngineCore_DP0 pid=476003) .b8 48
(EngineCore_DP0 pid=476003) .b8 95
(EngineCore_DP0 pid=476003) .b8 99
(EngineCore_DP0 pid=476003) .b8 99
(EngineCore_DP0 pid=476003) .b8 49
(EngineCore_DP0 pid=476003) .b8 50
(EngineCore_DP0 pid=476003) .b8 49
(EngineCore_DP0 pid=476003) .b8 95
(EngineCore_DP0 pid=476003) .b8 112
(EngineCore_DP0 pid=476003) .b8 121
(EngineCore_DP0 pid=476003) .b8 51
(EngineCore_DP0 pid=476003) .b8 49
(EngineCore_DP0 pid=476003) .b8 50
(EngineCore_DP0 pid=476003) .b8 95
(EngineCore_DP0 pid=476003) .b8 99
(EngineCore_DP0 pid=476003) .b8 117
(EngineCore_DP0 pid=476003) .b8 49
(EngineCore_DP0 pid=476003) .b8 50
(EngineCore_DP0 pid=476003) .b8 57
(EngineCore_DP0 pid=476003) .b8 95
(EngineCore_DP0 pid=476003) .b8 97
(EngineCore_DP0 pid=476003) .b8 97
(EngineCore_DP0 pid=476003) .b8 114
(EngineCore_DP0 pid=476003) .b8 99
(EngineCore_DP0 pid=476003) .b8 104
(EngineCore_DP0 pid=476003) .b8 54
(EngineCore_DP0 pid=476003) .b8 52
(EngineCore_DP0 pid=476003) .b8 0
(EngineCore_DP0 pid=476003) .b8 2                                   // Abbrev [2] 0x98:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=476003) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=476003) .b8 113
(EngineCore_DP0 pid=476003) .b8 117
(EngineCore_DP0 pid=476003) .b8 97
(EngineCore_DP0 pid=476003) .b8 110
(EngineCore_DP0 pid=476003) .b8 116
(EngineCore_DP0 pid=476003) .b8 95
(EngineCore_DP0 pid=476003) .b8 115
(EngineCore_DP0 pid=476003) .b8 108
(EngineCore_DP0 pid=476003) .b8 105
(EngineCore_DP0 pid=476003) .b8 100
(EngineCore_DP0 pid=476003) .b8 101
(EngineCore_DP0 pid=476003) .b8 95
(EngineCore_DP0 pid=476003) .b8 102
(EngineCore_DP0 pid=476003) .b8 112
(EngineCore_DP0 pid=476003) .b8 56
(EngineCore_DP0 pid=476003) .b8 95
(EngineCore_DP0 pid=476003) .b8 107
(EngineCore_DP0 pid=476003) .b8 101
(EngineCore_DP0 pid=476003) .b8 114
(EngineCore_DP0 pid=476003) .b8 110
(EngineCore_DP0 pid=476003) .b8 101
(EngineCore_DP0 pid=476003) .b8 108
(EngineCore_DP0 pid=476003) .b8 0
(EngineCore_DP0 pid=476003) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=476003) .b8 3                                   // Abbrev [3] 0xb2:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=476003) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=476003) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=476003) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=476003) .b8 4                                   // Abbrev [4] 0xc7:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=476003) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=476003) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=476003) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=476003) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=476003) .b8 157                                 // DW_AT_call_line
(EngineCore_DP0 pid=476003) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=476003) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=476003) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=476003) 	}
(EngineCore_DP0 pid=476003) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=476003) 
(EngineCore_DP0 pid=476003) ================================================================
(EngineCore_DP0 pid=476003) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=476003) 
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpv5g5p6wc.ptx', '-o', '/tmp/tmpv5g5p6wc.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866] 
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866] 
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866] 
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpv5g5p6wc.ptx -o /tmp/tmpv5g5p6wc.ptx.o
(EngineCore_DP0 pid=476003) ERROR 01-25 21:27:23 [core.py:866] 

STDERR:
[2026-01-25 21:26:20] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:26:20] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:26:20] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:26:20] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:26:20] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:26:20] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:26:20] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:26:20] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:26:20] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:26:20] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:26:20] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:26:20] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:26:20] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:26:20] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:26:23] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:26:23] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:26:23] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:26:23] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:26:23] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:26:23] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:26:23] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:26:23] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:26:23] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:26:23] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:26:23] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:26:23] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:26:23] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:26:23] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=476003) [2026-01-25 21:26:24] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=476003) [2026-01-25 21:26:24] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=476003) [2026-01-25 21:26:24] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=476003) [2026-01-25 21:26:24] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=476003) [2026-01-25 21:26:24] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=476003) [2026-01-25 21:26:24] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=476003) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=476003) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:23<00:23, 23.61s/it]
(EngineCore_DP0 pid=476003) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:56<00:00, 29.28s/it]
(EngineCore_DP0 pid=476003) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:56<00:00, 28.43s/it]
(EngineCore_DP0 pid=476003) 
(EngineCore_DP0 pid=476003) [2026-01-25 21:27:22] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=476003) [2026-01-25 21:27:22] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 13860864 bytes
(EngineCore_DP0 pid=476003) [2026-01-25 21:27:22] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=476003) [2026-01-25 21:27:22] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10780672 bytes
(EngineCore_DP0 pid=476003) [2026-01-25 21:27:22] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=476003) [2026-01-25 21:27:22] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 113967104 bytes
(EngineCore_DP0 pid=476003) [2026-01-25 21:27:22] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=476003) [2026-01-25 21:27:22] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 56655872 bytes
(EngineCore_DP0 pid=476003) Process EngineCore_DP0:
(EngineCore_DP0 pid=476003) Traceback (most recent call last):
(EngineCore_DP0 pid=476003)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=476003)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=476003)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=476003)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=476003) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpv5g5p6wc.ptx', '-o', '/tmp/tmpv5g5p6wc.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=476003) 
(EngineCore_DP0 pid=476003) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=476003) 
(EngineCore_DP0 pid=476003) Traceback (most recent call last):
(EngineCore_DP0 pid=476003)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=476003)     self.run()
(EngineCore_DP0 pid=476003)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=476003)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=476003)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=476003)     raise e
(EngineCore_DP0 pid=476003)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=476003)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=476003)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=476003)     super().__init__(
(EngineCore_DP0 pid=476003)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=476003)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=476003)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=476003)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=476003)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=476003)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=476003)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=476003)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=476003)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=476003)     return func(*args, **kwargs)
(EngineCore_DP0 pid=476003)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=476003)     return func(*args, **kwargs)
(EngineCore_DP0 pid=476003)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=476003)     self.model_runner.profile_run()
(EngineCore_DP0 pid=476003)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=476003)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=476003)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=476003)     return func(*args, **kwargs)
(EngineCore_DP0 pid=476003)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=476003)     outputs = self.model(
(EngineCore_DP0 pid=476003)               ^^^^^^^^^^^
(EngineCore_DP0 pid=476003)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=476003)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=476003)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=476003)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=476003)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=476003)     hidden_states = self.model(
(EngineCore_DP0 pid=476003)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=476003)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=476003)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=476003)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=476003)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=476003)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=476003)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=476003)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=476003)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=476003)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=476003)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=476003)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=476003)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=476003)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=476003)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=476003)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=476003)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=476003)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=476003)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=476003)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=476003)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=476003)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=476003)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=476003)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=476003)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=476003)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=476003)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=476003)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=476003)     return self._linear_fn(
(EngineCore_DP0 pid=476003)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=476003)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=476003)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=476003)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=476003)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=476003)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=476003)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=476003)     return fn(input, L)
(EngineCore_DP0 pid=476003)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=476003)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=476003)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=476003)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=476003)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=476003)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=476003)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=476003)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=476003)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=476003)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=476003)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=476003)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=476003)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=476003)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=476003)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=476003)     raise PTXASError(error)
(EngineCore_DP0 pid=476003) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=476003) `ptxas` stderr:
(EngineCore_DP0 pid=476003) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=476003) 
(EngineCore_DP0 pid=476003) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpv5g5p6wc.ptx -o /tmp/tmpv5g5p6wc.ptx.o
(EngineCore_DP0 pid=476003) 
[rank0]:[W125 21:27:24.402706773 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=1024

========== M=2048 ==========
Time: 2026-01-25 21:27:25
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Qwen2.5-7B-FP8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:27:30 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 21:27:30 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=477164) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=477164) 
(EngineCore_DP0 pid=477164) 
(EngineCore_DP0 pid=477164) ================================================================
(EngineCore_DP0 pid=477164) Internal Triton PTX codegen error
(EngineCore_DP0 pid=477164) `ptxas` stderr:
(EngineCore_DP0 pid=477164) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=477164) 
(EngineCore_DP0 pid=477164) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpdg30hzch.ptx -o /tmp/tmpdg30hzch.ptx.o
(EngineCore_DP0 pid=477164) 
(EngineCore_DP0 pid=477164) 
(EngineCore_DP0 pid=477164) //
(EngineCore_DP0 pid=477164) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=477164) //
(EngineCore_DP0 pid=477164) 
(EngineCore_DP0 pid=477164) .version 8.7
(EngineCore_DP0 pid=477164) .target sm_121a
(EngineCore_DP0 pid=477164) .address_size 64
(EngineCore_DP0 pid=477164) 
(EngineCore_DP0 pid=477164) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=477164) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=477164)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=477164) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=477164) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=477164) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=477164) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=477164) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=477164) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=477164) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=477164) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=477164) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=477164) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=477164) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=477164) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=477164) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=477164) )
(EngineCore_DP0 pid=477164) .reqntid 512
(EngineCore_DP0 pid=477164) {
(EngineCore_DP0 pid=477164) 	.reg .pred 	%p<28>;
(EngineCore_DP0 pid=477164) 	.reg .b16 	%rs<49>;
(EngineCore_DP0 pid=477164) 	.reg .b32 	%r<139>;
(EngineCore_DP0 pid=477164) 	.reg .b64 	%rd<17>;
(EngineCore_DP0 pid=477164) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=477164) $L__func_begin0:
(EngineCore_DP0 pid=477164) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=477164) 
(EngineCore_DP0 pid=477164) // %bb.0:
(EngineCore_DP0 pid=477164) 	ld.param.b32 	%r21, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=477164) 	ld.param.b32 	%r20, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=477164) 	ld.param.b32 	%r19, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=477164) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=477164) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=477164) $L__tmp0:
(EngineCore_DP0 pid=477164) 	.loc	1 143 24                        // quant_slide_tuned_Qwen2.5-7B.py:143:24
(EngineCore_DP0 pid=477164) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=477164) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=477164) 	.loc	1 148 26                        // quant_slide_tuned_Qwen2.5-7B.py:148:26
(EngineCore_DP0 pid=477164) 	mul.lo.s32 	%r24, %r23, %r1;
(EngineCore_DP0 pid=477164) 	.loc	1 148 20                        // quant_slide_tuned_Qwen2.5-7B.py:148:20
(EngineCore_DP0 pid=477164) 	mad.wide.s32 	%rd1, %r24, 2, %rd4;
(EngineCore_DP0 pid=477164) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=477164) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=477164) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=477164) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=477164) 	setp.lt.s32 	%p1, %r20, 1;
(EngineCore_DP0 pid=477164) 	mov.b32 	%r137, 0f2B8CBCCC;
(EngineCore_DP0 pid=477164) 	setp.eq.b32 	%p27, %r2, 0;
(EngineCore_DP0 pid=477164) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=477164) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=477164) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=477164) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=477164) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=477164) 	shr.u32 	%r33, %r2, 3;
(EngineCore_DP0 pid=477164) 	and.b32 	%r34, %r33, 60;
(EngineCore_DP0 pid=477164) 	mov.b32 	%r35, global_smem;
(EngineCore_DP0 pid=477164) 	add.s32 	%r45, %r35, %r34;
(EngineCore_DP0 pid=477164) 	shl.b32 	%r36, %r2, 2;
(EngineCore_DP0 pid=477164) 	add.s32 	%r48, %r35, %r36;
(EngineCore_DP0 pid=477164) 	mov.b32 	%r41, 0;
(EngineCore_DP0 pid=477164) 	mov.b32 	%r135, 0f00000000;
(EngineCore_DP0 pid=477164) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=477164) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=477164) 	mov.b32 	%r136, %r41;
(EngineCore_DP0 pid=477164) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=477164) 	.loc	1 155 22                        // quant_slide_tuned_Qwen2.5-7B.py:155:22
(EngineCore_DP0 pid=477164) 	add.s32 	%r51, %r4, %r136;
(EngineCore_DP0 pid=477164) 	setp.lt.s32 	%p2, %r51, %r19;
(EngineCore_DP0 pid=477164) 	.loc	1 156 29                        // quant_slide_tuned_Qwen2.5-7B.py:156:29
(EngineCore_DP0 pid=477164) 	mad.wide.s32 	%rd6, %r51, 2, %rd1;
(EngineCore_DP0 pid=477164) 	.loc	1 156 21                        // quant_slide_tuned_Qwen2.5-7B.py:156:21
(EngineCore_DP0 pid=477164) 	// begin inline asm
(EngineCore_DP0 pid=477164) 	mov.u32 %r37, %r41;
(EngineCore_DP0 pid=477164) 	mov.u32 %r38, %r41;
(EngineCore_DP0 pid=477164) 	mov.u32 %r39, %r41;
(EngineCore_DP0 pid=477164) 	mov.u32 %r40, %r41;
(EngineCore_DP0 pid=477164) 	@%p2 ld.global.v4.b32 { %r37, %r38, %r39, %r40 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=477164) 	// end inline asm
(EngineCore_DP0 pid=477164) 	mov.b32 	{%rs1, %rs2}, %r37;
(EngineCore_DP0 pid=477164) 	mov.b32 	{%rs3, %rs4}, %r38;
(EngineCore_DP0 pid=477164) 	mov.b32 	{%rs5, %rs6}, %r39;
(EngineCore_DP0 pid=477164) 	mov.b32 	{%rs7, %rs8}, %r40;
(EngineCore_DP0 pid=477164) 	.loc	1 157 50                        // quant_slide_tuned_Qwen2.5-7B.py:157:50
(EngineCore_DP0 pid=477164) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=477164) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=477164) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=477164) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=477164) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=477164) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=477164) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=477164) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=477164) $L__tmp1:
(EngineCore_DP0 pid=477164) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=477164) 	bar.sync 	0;
(EngineCore_DP0 pid=477164) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=477164) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=477164) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=477164) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=477164) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=477164) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=477164) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=477164) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=477164) 	cvt.f32.bf16 	%r52, %rs23;
(EngineCore_DP0 pid=477164) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=477164) 	shfl.sync.bfly.b32 	%r53, %r52, 16, 31, -1;
(EngineCore_DP0 pid=477164) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=477164) 	max.f32 	%r54, %r52, %r53;
(EngineCore_DP0 pid=477164) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=477164) 	shfl.sync.bfly.b32 	%r55, %r54, 8, 31, -1;
(EngineCore_DP0 pid=477164) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=477164) 	max.f32 	%r56, %r54, %r55;
(EngineCore_DP0 pid=477164) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=477164) 	shfl.sync.bfly.b32 	%r57, %r56, 4, 31, -1;
(EngineCore_DP0 pid=477164) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=477164) 	max.f32 	%r58, %r56, %r57;
(EngineCore_DP0 pid=477164) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=477164) 	shfl.sync.bfly.b32 	%r59, %r58, 2, 31, -1;
(EngineCore_DP0 pid=477164) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=477164) 	max.f32 	%r60, %r58, %r59;
(EngineCore_DP0 pid=477164) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=477164) 	shfl.sync.bfly.b32 	%r61, %r60, 1, 31, -1;
(EngineCore_DP0 pid=477164) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=477164) 	max.f32 	%r46, %r60, %r61;
(EngineCore_DP0 pid=477164) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=477164) 	// begin inline asm
(EngineCore_DP0 pid=477164) 	@%p3 st.shared.b32 [ %r45 + 0 ], %r46;
(EngineCore_DP0 pid=477164) 	// end inline asm
(EngineCore_DP0 pid=477164) 	bar.sync 	0;
(EngineCore_DP0 pid=477164) 	// begin inline asm
(EngineCore_DP0 pid=477164) 	@%p4 ld.shared.b32 %r47, [ %r48 + 0 ];
(EngineCore_DP0 pid=477164) 	// end inline asm
(EngineCore_DP0 pid=477164) 	shfl.sync.bfly.b32 	%r62, %r47, 8, 31, -1;
(EngineCore_DP0 pid=477164) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=477164) 	max.f32 	%r63, %r47, %r62;
(EngineCore_DP0 pid=477164) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=477164) 	shfl.sync.bfly.b32 	%r64, %r63, 4, 31, -1;
(EngineCore_DP0 pid=477164) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=477164) 	max.f32 	%r65, %r63, %r64;
(EngineCore_DP0 pid=477164) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=477164) 	shfl.sync.bfly.b32 	%r66, %r65, 2, 31, -1;
(EngineCore_DP0 pid=477164) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=477164) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=477164) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=477164) 	shfl.sync.bfly.b32 	%r68, %r67, 1, 31, -1;
(EngineCore_DP0 pid=477164) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=477164) 	max.f32 	%r50, %r67, %r68;
(EngineCore_DP0 pid=477164) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=477164) 	// begin inline asm
(EngineCore_DP0 pid=477164) 	@%p27 st.shared.b32 [ %r48 + 0 ], %r50;
(EngineCore_DP0 pid=477164) 	// end inline asm
(EngineCore_DP0 pid=477164) 	bar.sync 	0;
(EngineCore_DP0 pid=477164) 	ld.shared.b32 	%r69, [global_smem];
(EngineCore_DP0 pid=477164) $L__tmp2:
(EngineCore_DP0 pid=477164) 	.loc	1 157 36                        // quant_slide_tuned_Qwen2.5-7B.py:157:36
(EngineCore_DP0 pid=477164) 	max.f32 	%r135, %r135, %r69;
(EngineCore_DP0 pid=477164) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=477164) 	add.s32 	%r136, %r136, 4096;
(EngineCore_DP0 pid=477164) 	setp.lt.s32 	%p6, %r136, %r20;
(EngineCore_DP0 pid=477164) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=477164) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=477164) 	.loc	1 159 32                        // quant_slide_tuned_Qwen2.5-7B.py:159:32
(EngineCore_DP0 pid=477164) 	max.f32 	%r137, %r135, 0f2B8CBCCC;
(EngineCore_DP0 pid=477164) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=477164) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-7B.py:0:32
(EngineCore_DP0 pid=477164) 	mov.b32 	%r71, 0f43E00000;
(EngineCore_DP0 pid=477164) 	.loc	1 160 32                        // quant_slide_tuned_Qwen2.5-7B.py:160:32
(EngineCore_DP0 pid=477164) 	div.full.f32 	%r72, %r137, %r71;
(EngineCore_DP0 pid=477164) 	.loc	1 160 41                        // quant_slide_tuned_Qwen2.5-7B.py:160:41
(EngineCore_DP0 pid=477164) 	max.f32 	%r70, %r72, 0f36924925;
(EngineCore_DP0 pid=477164) 	.loc	1 162 25                        // quant_slide_tuned_Qwen2.5-7B.py:162:25
(EngineCore_DP0 pid=477164) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=477164) 	.loc	1 162 30                        // quant_slide_tuned_Qwen2.5-7B.py:162:30
(EngineCore_DP0 pid=477164) 	// begin inline asm
(EngineCore_DP0 pid=477164) 	@%p27 st.global.b32 [ %rd7 + 0 ], { %r70 };
(EngineCore_DP0 pid=477164) 	// end inline asm
(EngineCore_DP0 pid=477164) 	.loc	1 165 29                        // quant_slide_tuned_Qwen2.5-7B.py:165:29
(EngineCore_DP0 pid=477164) 	shl.b32 	%r15, %r21, 1;
(EngineCore_DP0 pid=477164) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=477164) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=477164) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=477164) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=477164) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-7B.py:0:41
(EngineCore_DP0 pid=477164) 	ld.param.b32 	%r25, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=477164) 	shr.s32 	%r26, %r25, 31;
(EngineCore_DP0 pid=477164) 	shr.u32 	%r27, %r26, 30;
(EngineCore_DP0 pid=477164) 	add.s32 	%r28, %r25, %r27;
(EngineCore_DP0 pid=477164) 	shr.s32 	%r29, %r28, 2;
(EngineCore_DP0 pid=477164) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=477164) 	mul.lo.s32 	%r30, %r29, %r1;
(EngineCore_DP0 pid=477164) 	mad.wide.s32 	%rd2, %r30, 4, %rd5;
(EngineCore_DP0 pid=477164) 	div.full.f32 	%r14, %r71, %r137;
(EngineCore_DP0 pid=477164) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=477164) 	mov.b32 	%r138, 0;
(EngineCore_DP0 pid=477164) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=477164)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=477164) 	.loc	1 168 31                        // quant_slide_tuned_Qwen2.5-7B.py:168:31
(EngineCore_DP0 pid=477164) 	add.s32 	%r84, %r16, %r138;
(EngineCore_DP0 pid=477164) 	.loc	1 169 30                        // quant_slide_tuned_Qwen2.5-7B.py:169:30
(EngineCore_DP0 pid=477164) 	add.s32 	%r85, %r138, 1;
(EngineCore_DP0 pid=477164) 	setp.lt.s32 	%p17, %r84, %r15;
(EngineCore_DP0 pid=477164) 	.loc	1 172 24                        // quant_slide_tuned_Qwen2.5-7B.py:172:24
(EngineCore_DP0 pid=477164) 	shr.u32 	%r86, %r84, 1;
(EngineCore_DP0 pid=477164) 	.loc	1 173 23                        // quant_slide_tuned_Qwen2.5-7B.py:173:23
(EngineCore_DP0 pid=477164) 	shr.u32 	%r87, %r85, 31;
(EngineCore_DP0 pid=477164) 	add.s32 	%r88, %r85, %r87;
(EngineCore_DP0 pid=477164) 	and.b32 	%r89, %r88, 2147483646;
(EngineCore_DP0 pid=477164) 	sub.s32 	%r90, %r85, %r89;
(EngineCore_DP0 pid=477164) 	.loc	1 174 22                        // quant_slide_tuned_Qwen2.5-7B.py:174:22
(EngineCore_DP0 pid=477164) 	mul.lo.s32 	%r91, %r86, 6;
(EngineCore_DP0 pid=477164) 	.loc	1 174 30                        // quant_slide_tuned_Qwen2.5-7B.py:174:30
(EngineCore_DP0 pid=477164) 	shl.b32 	%r92, %r90, 1;
(EngineCore_DP0 pid=477164) 	.loc	1 174 26                        // quant_slide_tuned_Qwen2.5-7B.py:174:26
(EngineCore_DP0 pid=477164) 	add.s32 	%r93, %r91, %r92;
(EngineCore_DP0 pid=477164) 	.loc	1 177 53                        // quant_slide_tuned_Qwen2.5-7B.py:177:53
(EngineCore_DP0 pid=477164) 	setp.lt.s32 	%p18, %r91, %r19;
(EngineCore_DP0 pid=477164) 	setp.lt.s32 	%p19, %r93, %r19;
(EngineCore_DP0 pid=477164) 	.loc	1 177 37                        // quant_slide_tuned_Qwen2.5-7B.py:177:37
(EngineCore_DP0 pid=477164) 	and.pred 	%p9, %p17, %p18;
(EngineCore_DP0 pid=477164) 	and.pred 	%p10, %p17, %p19;
(EngineCore_DP0 pid=477164) 	.loc	1 176 29                        // quant_slide_tuned_Qwen2.5-7B.py:176:29
(EngineCore_DP0 pid=477164) 	mad.wide.s32 	%rd8, %r91, 2, %rd1;
(EngineCore_DP0 pid=477164) 	mad.wide.s32 	%rd9, %r93, 2, %rd1;
(EngineCore_DP0 pid=477164) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=477164) 	.loc	1 176 21                        // quant_slide_tuned_Qwen2.5-7B.py:176:21
(EngineCore_DP0 pid=477164) 	// begin inline asm
(EngineCore_DP0 pid=477164) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=477164) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=477164) 	// end inline asm
(EngineCore_DP0 pid=477164) 	// begin inline asm
(EngineCore_DP0 pid=477164) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=477164) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=477164) 	// end inline asm
(EngineCore_DP0 pid=477164) 	.loc	1 177 79                        // quant_slide_tuned_Qwen2.5-7B.py:177:79
(EngineCore_DP0 pid=477164) 	cvt.f32.bf16 	%r94, %rs24;
(EngineCore_DP0 pid=477164) 	cvt.f32.bf16 	%r95, %rs26;
(EngineCore_DP0 pid=477164) 	.loc	1 179 48                        // quant_slide_tuned_Qwen2.5-7B.py:179:48
(EngineCore_DP0 pid=477164) 	or.b32 	%r96, %r91, 1;
(EngineCore_DP0 pid=477164) 	or.b32 	%r97, %r93, 1;
(EngineCore_DP0 pid=477164) 	.loc	1 179 53                        // quant_slide_tuned_Qwen2.5-7B.py:179:53
(EngineCore_DP0 pid=477164) 	setp.lt.s32 	%p20, %r96, %r19;
(EngineCore_DP0 pid=477164) 	setp.lt.s32 	%p21, %r97, %r19;
(EngineCore_DP0 pid=477164) 	.loc	1 179 37                        // quant_slide_tuned_Qwen2.5-7B.py:179:37
(EngineCore_DP0 pid=477164) 	and.pred 	%p11, %p17, %p20;
(EngineCore_DP0 pid=477164) 	and.pred 	%p12, %p17, %p21;
(EngineCore_DP0 pid=477164) 	.loc	1 178 39                        // quant_slide_tuned_Qwen2.5-7B.py:178:39
(EngineCore_DP0 pid=477164) 	add.s64 	%rd10, %rd8, 2;
(EngineCore_DP0 pid=477164) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=477164) 	.loc	1 178 21                        // quant_slide_tuned_Qwen2.5-7B.py:178:21
(EngineCore_DP0 pid=477164) 	// begin inline asm
(EngineCore_DP0 pid=477164) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=477164) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=477164) 	// end inline asm
(EngineCore_DP0 pid=477164) 	// begin inline asm
(EngineCore_DP0 pid=477164) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=477164) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=477164) 	// end inline asm
(EngineCore_DP0 pid=477164) 	.loc	1 179 79                        // quant_slide_tuned_Qwen2.5-7B.py:179:79
(EngineCore_DP0 pid=477164) 	cvt.f32.bf16 	%r98, %rs28;
(EngineCore_DP0 pid=477164) 	cvt.f32.bf16 	%r99, %rs30;
(EngineCore_DP0 pid=477164) 	.loc	1 181 48                        // quant_slide_tuned_Qwen2.5-7B.py:181:48
(EngineCore_DP0 pid=477164) 	add.s32 	%r100, %r91, 2;
(EngineCore_DP0 pid=477164) 	add.s32 	%r101, %r93, 2;
(EngineCore_DP0 pid=477164) 	.loc	1 181 53                        // quant_slide_tuned_Qwen2.5-7B.py:181:53
(EngineCore_DP0 pid=477164) 	setp.lt.s32 	%p22, %r100, %r19;
(EngineCore_DP0 pid=477164) 	setp.lt.s32 	%p23, %r101, %r19;
(EngineCore_DP0 pid=477164) 	.loc	1 181 37                        // quant_slide_tuned_Qwen2.5-7B.py:181:37
(EngineCore_DP0 pid=477164) 	and.pred 	%p13, %p17, %p22;
(EngineCore_DP0 pid=477164) 	and.pred 	%p14, %p17, %p23;
(EngineCore_DP0 pid=477164) 	.loc	1 180 39                        // quant_slide_tuned_Qwen2.5-7B.py:180:39
(EngineCore_DP0 pid=477164) 	add.s64 	%rd12, %rd8, 4;
(EngineCore_DP0 pid=477164) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=477164) 	.loc	1 180 21                        // quant_slide_tuned_Qwen2.5-7B.py:180:21
(EngineCore_DP0 pid=477164) 	// begin inline asm
(EngineCore_DP0 pid=477164) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=477164) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=477164) 	// end inline asm
(EngineCore_DP0 pid=477164) 	// begin inline asm
(EngineCore_DP0 pid=477164) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=477164) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=477164) 	// end inline asm
(EngineCore_DP0 pid=477164) 	.loc	1 181 79                        // quant_slide_tuned_Qwen2.5-7B.py:181:79
(EngineCore_DP0 pid=477164) 	cvt.f32.bf16 	%r102, %rs32;
(EngineCore_DP0 pid=477164) 	cvt.f32.bf16 	%r103, %rs34;
(EngineCore_DP0 pid=477164) 	.loc	1 183 48                        // quant_slide_tuned_Qwen2.5-7B.py:183:48
(EngineCore_DP0 pid=477164) 	add.s32 	%r104, %r91, 3;
(EngineCore_DP0 pid=477164) 	add.s32 	%r105, %r93, 3;
(EngineCore_DP0 pid=477164) 	.loc	1 183 53                        // quant_slide_tuned_Qwen2.5-7B.py:183:53
(EngineCore_DP0 pid=477164) 	setp.lt.s32 	%p24, %r104, %r19;
(EngineCore_DP0 pid=477164) 	setp.lt.s32 	%p25, %r105, %r19;
(EngineCore_DP0 pid=477164) 	.loc	1 183 37                        // quant_slide_tuned_Qwen2.5-7B.py:183:37
(EngineCore_DP0 pid=477164) 	and.pred 	%p15, %p17, %p24;
(EngineCore_DP0 pid=477164) 	and.pred 	%p16, %p17, %p25;
(EngineCore_DP0 pid=477164) 	.loc	1 182 39                        // quant_slide_tuned_Qwen2.5-7B.py:182:39
(EngineCore_DP0 pid=477164) 	add.s64 	%rd14, %rd8, 6;
(EngineCore_DP0 pid=477164) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=477164) 	.loc	1 182 21                        // quant_slide_tuned_Qwen2.5-7B.py:182:21
(EngineCore_DP0 pid=477164) 	// begin inline asm
(EngineCore_DP0 pid=477164) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=477164) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=477164) 	// end inline asm
(EngineCore_DP0 pid=477164) 	// begin inline asm
(EngineCore_DP0 pid=477164) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=477164) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=477164) 	// end inline asm
(EngineCore_DP0 pid=477164) 	.loc	1 183 79                        // quant_slide_tuned_Qwen2.5-7B.py:183:79
(EngineCore_DP0 pid=477164) 	cvt.f32.bf16 	%r106, %rs36;
(EngineCore_DP0 pid=477164) 	cvt.f32.bf16 	%r107, %rs38;
(EngineCore_DP0 pid=477164) 	.loc	1 185 27                        // quant_slide_tuned_Qwen2.5-7B.py:185:27
(EngineCore_DP0 pid=477164) 	mul.f32 	%r108, %r14, %r94;
(EngineCore_DP0 pid=477164) 	mul.f32 	%r109, %r14, %r95;
(EngineCore_DP0 pid=477164) 	mov.b32 	%r110, 0f43E00000;
(EngineCore_DP0 pid=477164) 	.loc	1 185 48                        // quant_slide_tuned_Qwen2.5-7B.py:185:48
(EngineCore_DP0 pid=477164) 	min.xorsign.abs.f32 	%r74, %r108, %r110;
(EngineCore_DP0 pid=477164) 	min.xorsign.abs.f32 	%r75, %r109, %r110;
(EngineCore_DP0 pid=477164) 	.loc	1 185 60                        // quant_slide_tuned_Qwen2.5-7B.py:185:60
(EngineCore_DP0 pid=477164) 	// begin inline asm
(EngineCore_DP0 pid=477164) 	cvt.rn.satfinite.e4m3x2.f32  %rs40, %r75, %r74; 
(EngineCore_DP0 pid=477164) 
(EngineCore_DP0 pid=477164) 	// end inline asm
(EngineCore_DP0 pid=477164) 	shr.u16 	%rs44, %rs40, 8;
(EngineCore_DP0 pid=477164) 	.loc	1 186 27                        // quant_slide_tuned_Qwen2.5-7B.py:186:27
(EngineCore_DP0 pid=477164) 	mul.f32 	%r111, %r14, %r98;
(EngineCore_DP0 pid=477164) 	mul.f32 	%r112, %r14, %r99;
(EngineCore_DP0 pid=477164) 	.loc	1 186 48                        // quant_slide_tuned_Qwen2.5-7B.py:186:48
(EngineCore_DP0 pid=477164) 	min.xorsign.abs.f32 	%r76, %r111, %r110;
(EngineCore_DP0 pid=477164) 	min.xorsign.abs.f32 	%r77, %r112, %r110;
(EngineCore_DP0 pid=477164) 	.loc	1 186 60                        // quant_slide_tuned_Qwen2.5-7B.py:186:60
(EngineCore_DP0 pid=477164) 	// begin inline asm
(EngineCore_DP0 pid=477164) 	cvt.rn.satfinite.e4m3x2.f32  %rs41, %r77, %r76; 
(EngineCore_DP0 pid=477164) 
(EngineCore_DP0 pid=477164) 	// end inline asm
(EngineCore_DP0 pid=477164) 	shr.u16 	%rs45, %rs41, 8;
(EngineCore_DP0 pid=477164) 	.loc	1 187 27                        // quant_slide_tuned_Qwen2.5-7B.py:187:27
(EngineCore_DP0 pid=477164) 	mul.f32 	%r113, %r14, %r102;
(EngineCore_DP0 pid=477164) 	mul.f32 	%r114, %r14, %r103;
(EngineCore_DP0 pid=477164) 	.loc	1 187 48                        // quant_slide_tuned_Qwen2.5-7B.py:187:48
(EngineCore_DP0 pid=477164) 	min.xorsign.abs.f32 	%r78, %r113, %r110;
(EngineCore_DP0 pid=477164) 	min.xorsign.abs.f32 	%r79, %r114, %r110;
(EngineCore_DP0 pid=477164) 	.loc	1 187 60                        // quant_slide_tuned_Qwen2.5-7B.py:187:60
(EngineCore_DP0 pid=477164) 	// begin inline asm
(EngineCore_DP0 pid=477164) 	cvt.rn.satfinite.e4m3x2.f32  %rs42, %r79, %r78; 
(EngineCore_DP0 pid=477164) 
(EngineCore_DP0 pid=477164) 	// end inline asm
(EngineCore_DP0 pid=477164) 	shr.u16 	%rs46, %rs42, 8;
(EngineCore_DP0 pid=477164) 	.loc	1 188 27                        // quant_slide_tuned_Qwen2.5-7B.py:188:27
(EngineCore_DP0 pid=477164) 	mul.f32 	%r115, %r14, %r106;
(EngineCore_DP0 pid=477164) 	mul.f32 	%r116, %r14, %r107;
(EngineCore_DP0 pid=477164) 	.loc	1 188 48                        // quant_slide_tuned_Qwen2.5-7B.py:188:48
(EngineCore_DP0 pid=477164) 	min.xorsign.abs.f32 	%r80, %r115, %r110;
(EngineCore_DP0 pid=477164) 	min.xorsign.abs.f32 	%r81, %r116, %r110;
(EngineCore_DP0 pid=477164) 	.loc	1 188 60                        // quant_slide_tuned_Qwen2.5-7B.py:188:60
(EngineCore_DP0 pid=477164) 	// begin inline asm
(EngineCore_DP0 pid=477164) 	cvt.rn.satfinite.e4m3x2.f32  %rs43, %r81, %r80; 
(EngineCore_DP0 pid=477164) 
(EngineCore_DP0 pid=477164) 	// end inline asm
(EngineCore_DP0 pid=477164) 	shr.u16 	%rs47, %rs43, 8;
(EngineCore_DP0 pid=477164) 	.loc	1 190 45                        // quant_slide_tuned_Qwen2.5-7B.py:190:45
(EngineCore_DP0 pid=477164) 	cvt.u32.u16 	%r117, %rs40;
(EngineCore_DP0 pid=477164) 	and.b32 	%r118, %r117, 255;
(EngineCore_DP0 pid=477164) 	cvt.u32.u16 	%r119, %rs44;
(EngineCore_DP0 pid=477164) 	.loc	1 192 45                        // quant_slide_tuned_Qwen2.5-7B.py:192:45
(EngineCore_DP0 pid=477164) 	cvt.u32.u16 	%r120, %rs42;
(EngineCore_DP0 pid=477164) 	and.b32 	%r121, %r120, 255;
(EngineCore_DP0 pid=477164) 	cvt.u32.u16 	%r122, %rs46;
(EngineCore_DP0 pid=477164) 	.loc	1 193 45                        // quant_slide_tuned_Qwen2.5-7B.py:193:45
(EngineCore_DP0 pid=477164) 	cvt.u32.u16 	%r123, %rs43;
(EngineCore_DP0 pid=477164) 	cvt.u32.u16 	%r124, %rs47;
(EngineCore_DP0 pid=477164) 	.loc	1 195 30                        // quant_slide_tuned_Qwen2.5-7B.py:195:30
(EngineCore_DP0 pid=477164) 	and.b16 	%rs48, %rs41, 255;
(EngineCore_DP0 pid=477164) 	mul.wide.u16 	%r125, %rs48, 256;
(EngineCore_DP0 pid=477164) 	mul.wide.u16 	%r126, %rs45, 256;
(EngineCore_DP0 pid=477164) 	.loc	1 195 24                        // quant_slide_tuned_Qwen2.5-7B.py:195:24
(EngineCore_DP0 pid=477164) 	or.b32 	%r127, %r125, %r118;
(EngineCore_DP0 pid=477164) 	or.b32 	%r128, %r126, %r119;
(EngineCore_DP0 pid=477164) 	.loc	1 195 42                        // quant_slide_tuned_Qwen2.5-7B.py:195:42
(EngineCore_DP0 pid=477164) 	shl.b32 	%r129, %r121, 16;
(EngineCore_DP0 pid=477164) 	shl.b32 	%r130, %r122, 16;
(EngineCore_DP0 pid=477164) 	.loc	1 195 36                        // quant_slide_tuned_Qwen2.5-7B.py:195:36
(EngineCore_DP0 pid=477164) 	or.b32 	%r131, %r127, %r129;
(EngineCore_DP0 pid=477164) 	or.b32 	%r132, %r128, %r130;
(EngineCore_DP0 pid=477164) 	.loc	1 195 55                        // quant_slide_tuned_Qwen2.5-7B.py:195:55
(EngineCore_DP0 pid=477164) 	shl.b32 	%r133, %r123, 24;
(EngineCore_DP0 pid=477164) 	shl.b32 	%r134, %r124, 24;
(EngineCore_DP0 pid=477164) 	.loc	1 195 49                        // quant_slide_tuned_Qwen2.5-7B.py:195:49
(EngineCore_DP0 pid=477164) 	or.b32 	%r82, %r131, %r133;
(EngineCore_DP0 pid=477164) 	or.b32 	%r83, %r132, %r134;
(EngineCore_DP0 pid=477164) 	.loc	1 196 29                        // quant_slide_tuned_Qwen2.5-7B.py:196:29
(EngineCore_DP0 pid=477164) 	mad.wide.s32 	%rd16, %r84, 4, %rd2;
(EngineCore_DP0 pid=477164) 	.loc	1 196 39                        // quant_slide_tuned_Qwen2.5-7B.py:196:39
(EngineCore_DP0 pid=477164) 	// begin inline asm
(EngineCore_DP0 pid=477164) 	@%p17 st.global.v2.b32 [ %rd16 + 0 ], { %r82, %r83 };
(EngineCore_DP0 pid=477164) 	// end inline asm
(EngineCore_DP0 pid=477164) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=477164) 	add.s32 	%r138, %r138, 1024;
(EngineCore_DP0 pid=477164) 	setp.lt.s32 	%p26, %r138, %r15;
(EngineCore_DP0 pid=477164) 	@%p26 bra 	$L__BB0_6;
(EngineCore_DP0 pid=477164) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=477164) 	.loc	1 167 4                         // quant_slide_tuned_Qwen2.5-7B.py:167:4
(EngineCore_DP0 pid=477164) 	ret;
(EngineCore_DP0 pid=477164) $L__tmp3:
(EngineCore_DP0 pid=477164) $L__func_end0:
(EngineCore_DP0 pid=477164)                                         // -- End function
(EngineCore_DP0 pid=477164) }
(EngineCore_DP0 pid=477164) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py"
(EngineCore_DP0 pid=477164) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=477164) 	.section	.debug_abbrev
(EngineCore_DP0 pid=477164) 	{
(EngineCore_DP0 pid=477164) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=477164) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=477164) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=477164) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=477164) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=477164) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=477164) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=477164) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=477164) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=477164) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=477164) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=477164) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=477164) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=477164) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=477164) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=477164) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=477164) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=477164) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=477164) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=477164) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=477164) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=477164) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=477164) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=477164) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=477164) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=477164) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=477164) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=477164) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=477164) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=477164) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=477164) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=477164) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=477164) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=477164) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=477164) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=477164) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=477164) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=477164) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=477164) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=477164) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=477164) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=477164) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=477164) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=477164) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=477164) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=477164) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=477164) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=477164) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=477164) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=477164) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=477164) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=477164) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=477164) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=477164) 	}
(EngineCore_DP0 pid=477164) 	.section	.debug_info
(EngineCore_DP0 pid=477164) 	{
(EngineCore_DP0 pid=477164) .b32 221                                // Length of Unit
(EngineCore_DP0 pid=477164) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=477164) .b8 0
(EngineCore_DP0 pid=477164) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=477164) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=477164) .b8 1                                   // Abbrev [1] 0xb:0xd6 DW_TAG_compile_unit
(EngineCore_DP0 pid=477164) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=477164) .b8 114
(EngineCore_DP0 pid=477164) .b8 105
(EngineCore_DP0 pid=477164) .b8 116
(EngineCore_DP0 pid=477164) .b8 111
(EngineCore_DP0 pid=477164) .b8 110
(EngineCore_DP0 pid=477164) .b8 0
(EngineCore_DP0 pid=477164) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=477164) .b8 0
(EngineCore_DP0 pid=477164) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=477164) .b8 117
(EngineCore_DP0 pid=477164) .b8 97
(EngineCore_DP0 pid=477164) .b8 110
(EngineCore_DP0 pid=477164) .b8 116
(EngineCore_DP0 pid=477164) .b8 95
(EngineCore_DP0 pid=477164) .b8 115
(EngineCore_DP0 pid=477164) .b8 108
(EngineCore_DP0 pid=477164) .b8 105
(EngineCore_DP0 pid=477164) .b8 100
(EngineCore_DP0 pid=477164) .b8 101
(EngineCore_DP0 pid=477164) .b8 95
(EngineCore_DP0 pid=477164) .b8 116
(EngineCore_DP0 pid=477164) .b8 117
(EngineCore_DP0 pid=477164) .b8 110
(EngineCore_DP0 pid=477164) .b8 101
(EngineCore_DP0 pid=477164) .b8 100
(EngineCore_DP0 pid=477164) .b8 95
(EngineCore_DP0 pid=477164) .b8 81
(EngineCore_DP0 pid=477164) .b8 119
(EngineCore_DP0 pid=477164) .b8 101
(EngineCore_DP0 pid=477164) .b8 110
(EngineCore_DP0 pid=477164) .b8 50
(EngineCore_DP0 pid=477164) .b8 46
(EngineCore_DP0 pid=477164) .b8 53
(EngineCore_DP0 pid=477164) .b8 45
(EngineCore_DP0 pid=477164) .b8 55
(EngineCore_DP0 pid=477164) .b8 66
(EngineCore_DP0 pid=477164) .b8 46
(EngineCore_DP0 pid=477164) .b8 112
(EngineCore_DP0 pid=477164) .b8 121
(EngineCore_DP0 pid=477164) .b8 0
(EngineCore_DP0 pid=477164) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=477164) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=477164) .b8 114
(EngineCore_DP0 pid=477164) .b8 111
(EngineCore_DP0 pid=477164) .b8 111
(EngineCore_DP0 pid=477164) .b8 116
(EngineCore_DP0 pid=477164) .b8 47
(EngineCore_DP0 pid=477164) .b8 118
(EngineCore_DP0 pid=477164) .b8 108
(EngineCore_DP0 pid=477164) .b8 108
(EngineCore_DP0 pid=477164) .b8 109
(EngineCore_DP0 pid=477164) .b8 98
(EngineCore_DP0 pid=477164) .b8 101
(EngineCore_DP0 pid=477164) .b8 110
(EngineCore_DP0 pid=477164) .b8 99
(EngineCore_DP0 pid=477164) .b8 104
(EngineCore_DP0 pid=477164) .b8 47
(EngineCore_DP0 pid=477164) .b8 115
(EngineCore_DP0 pid=477164) .b8 108
(EngineCore_DP0 pid=477164) .b8 105
(EngineCore_DP0 pid=477164) .b8 100
(EngineCore_DP0 pid=477164) .b8 101
(EngineCore_DP0 pid=477164) .b8 115
(EngineCore_DP0 pid=477164) .b8 112
(EngineCore_DP0 pid=477164) .b8 97
(EngineCore_DP0 pid=477164) .b8 114
(EngineCore_DP0 pid=477164) .b8 115
(EngineCore_DP0 pid=477164) .b8 101
(EngineCore_DP0 pid=477164) .b8 47
(EngineCore_DP0 pid=477164) .b8 99
(EngineCore_DP0 pid=477164) .b8 115
(EngineCore_DP0 pid=477164) .b8 114
(EngineCore_DP0 pid=477164) .b8 99
(EngineCore_DP0 pid=477164) .b8 47
(EngineCore_DP0 pid=477164) .b8 102
(EngineCore_DP0 pid=477164) .b8 117
(EngineCore_DP0 pid=477164) .b8 115
(EngineCore_DP0 pid=477164) .b8 101
(EngineCore_DP0 pid=477164) .b8 100
(EngineCore_DP0 pid=477164) .b8 95
(EngineCore_DP0 pid=477164) .b8 113
(EngineCore_DP0 pid=477164) .b8 117
(EngineCore_DP0 pid=477164) .b8 97
(EngineCore_DP0 pid=477164) .b8 110
(EngineCore_DP0 pid=477164) .b8 116
(EngineCore_DP0 pid=477164) .b8 95
(EngineCore_DP0 pid=477164) .b8 115
(EngineCore_DP0 pid=477164) .b8 108
(EngineCore_DP0 pid=477164) .b8 105
(EngineCore_DP0 pid=477164) .b8 100
(EngineCore_DP0 pid=477164) .b8 101
(EngineCore_DP0 pid=477164) .b8 95
(EngineCore_DP0 pid=477164) .b8 116
(EngineCore_DP0 pid=477164) .b8 114
(EngineCore_DP0 pid=477164) .b8 105
(EngineCore_DP0 pid=477164) .b8 116
(EngineCore_DP0 pid=477164) .b8 111
(EngineCore_DP0 pid=477164) .b8 110
(EngineCore_DP0 pid=477164) .b8 47
(EngineCore_DP0 pid=477164) .b8 98
(EngineCore_DP0 pid=477164) .b8 117
(EngineCore_DP0 pid=477164) .b8 105
(EngineCore_DP0 pid=477164) .b8 108
(EngineCore_DP0 pid=477164) .b8 100
(EngineCore_DP0 pid=477164) .b8 47
(EngineCore_DP0 pid=477164) .b8 71
(EngineCore_DP0 pid=477164) .b8 66
(EngineCore_DP0 pid=477164) .b8 49
(EngineCore_DP0 pid=477164) .b8 48
(EngineCore_DP0 pid=477164) .b8 95
(EngineCore_DP0 pid=477164) .b8 99
(EngineCore_DP0 pid=477164) .b8 99
(EngineCore_DP0 pid=477164) .b8 49
(EngineCore_DP0 pid=477164) .b8 50
(EngineCore_DP0 pid=477164) .b8 49
(EngineCore_DP0 pid=477164) .b8 95
(EngineCore_DP0 pid=477164) .b8 112
(EngineCore_DP0 pid=477164) .b8 121
(EngineCore_DP0 pid=477164) .b8 51
(EngineCore_DP0 pid=477164) .b8 49
(EngineCore_DP0 pid=477164) .b8 50
(EngineCore_DP0 pid=477164) .b8 95
(EngineCore_DP0 pid=477164) .b8 99
(EngineCore_DP0 pid=477164) .b8 117
(EngineCore_DP0 pid=477164) .b8 49
(EngineCore_DP0 pid=477164) .b8 50
(EngineCore_DP0 pid=477164) .b8 57
(EngineCore_DP0 pid=477164) .b8 95
(EngineCore_DP0 pid=477164) .b8 97
(EngineCore_DP0 pid=477164) .b8 97
(EngineCore_DP0 pid=477164) .b8 114
(EngineCore_DP0 pid=477164) .b8 99
(EngineCore_DP0 pid=477164) .b8 104
(EngineCore_DP0 pid=477164) .b8 54
(EngineCore_DP0 pid=477164) .b8 52
(EngineCore_DP0 pid=477164) .b8 0
(EngineCore_DP0 pid=477164) .b8 2                                   // Abbrev [2] 0x98:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=477164) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=477164) .b8 113
(EngineCore_DP0 pid=477164) .b8 117
(EngineCore_DP0 pid=477164) .b8 97
(EngineCore_DP0 pid=477164) .b8 110
(EngineCore_DP0 pid=477164) .b8 116
(EngineCore_DP0 pid=477164) .b8 95
(EngineCore_DP0 pid=477164) .b8 115
(EngineCore_DP0 pid=477164) .b8 108
(EngineCore_DP0 pid=477164) .b8 105
(EngineCore_DP0 pid=477164) .b8 100
(EngineCore_DP0 pid=477164) .b8 101
(EngineCore_DP0 pid=477164) .b8 95
(EngineCore_DP0 pid=477164) .b8 102
(EngineCore_DP0 pid=477164) .b8 112
(EngineCore_DP0 pid=477164) .b8 56
(EngineCore_DP0 pid=477164) .b8 95
(EngineCore_DP0 pid=477164) .b8 107
(EngineCore_DP0 pid=477164) .b8 101
(EngineCore_DP0 pid=477164) .b8 114
(EngineCore_DP0 pid=477164) .b8 110
(EngineCore_DP0 pid=477164) .b8 101
(EngineCore_DP0 pid=477164) .b8 108
(EngineCore_DP0 pid=477164) .b8 0
(EngineCore_DP0 pid=477164) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=477164) .b8 3                                   // Abbrev [3] 0xb2:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=477164) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=477164) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=477164) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=477164) .b8 4                                   // Abbrev [4] 0xc7:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=477164) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=477164) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=477164) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=477164) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=477164) .b8 157                                 // DW_AT_call_line
(EngineCore_DP0 pid=477164) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=477164) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=477164) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=477164) 	}
(EngineCore_DP0 pid=477164) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=477164) 
(EngineCore_DP0 pid=477164) ================================================================
(EngineCore_DP0 pid=477164) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=477164) 
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpdg30hzch.ptx', '-o', '/tmp/tmpdg30hzch.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866] 
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866] 
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866] 
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpdg30hzch.ptx -o /tmp/tmpdg30hzch.ptx.o
(EngineCore_DP0 pid=477164) ERROR 01-25 21:28:34 [core.py:866] 

STDERR:
[2026-01-25 21:27:30] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:27:30] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:27:30] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:27:30] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:27:30] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:27:30] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:27:30] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:27:30] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:27:30] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:27:30] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:27:30] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:27:30] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:27:30] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:27:30] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:27:33] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:27:33] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:27:33] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:27:33] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:27:33] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:27:33] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:27:33] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:27:33] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:27:33] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:27:33] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:27:33] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:27:33] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:27:33] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:27:33] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=477164) [2026-01-25 21:27:34] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=477164) [2026-01-25 21:27:34] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=477164) [2026-01-25 21:27:34] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=477164) [2026-01-25 21:27:34] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=477164) [2026-01-25 21:27:34] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=477164) [2026-01-25 21:27:34] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=477164) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=477164) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:23<00:23, 23.74s/it]
(EngineCore_DP0 pid=477164) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:57<00:00, 29.48s/it]
(EngineCore_DP0 pid=477164) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:57<00:00, 28.62s/it]
(EngineCore_DP0 pid=477164) 
(EngineCore_DP0 pid=477164) [2026-01-25 21:28:32] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=477164) [2026-01-25 21:28:32] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 13860864 bytes
(EngineCore_DP0 pid=477164) [2026-01-25 21:28:32] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=477164) [2026-01-25 21:28:32] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10780672 bytes
(EngineCore_DP0 pid=477164) [2026-01-25 21:28:32] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=477164) [2026-01-25 21:28:32] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 113967104 bytes
(EngineCore_DP0 pid=477164) [2026-01-25 21:28:32] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=477164) [2026-01-25 21:28:32] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 56655872 bytes
(EngineCore_DP0 pid=477164) Process EngineCore_DP0:
(EngineCore_DP0 pid=477164) Traceback (most recent call last):
(EngineCore_DP0 pid=477164)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=477164)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=477164)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=477164)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=477164) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpdg30hzch.ptx', '-o', '/tmp/tmpdg30hzch.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=477164) 
(EngineCore_DP0 pid=477164) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=477164) 
(EngineCore_DP0 pid=477164) Traceback (most recent call last):
(EngineCore_DP0 pid=477164)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=477164)     self.run()
(EngineCore_DP0 pid=477164)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=477164)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=477164)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=477164)     raise e
(EngineCore_DP0 pid=477164)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=477164)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=477164)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=477164)     super().__init__(
(EngineCore_DP0 pid=477164)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=477164)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=477164)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=477164)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=477164)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=477164)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=477164)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=477164)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=477164)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=477164)     return func(*args, **kwargs)
(EngineCore_DP0 pid=477164)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=477164)     return func(*args, **kwargs)
(EngineCore_DP0 pid=477164)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=477164)     self.model_runner.profile_run()
(EngineCore_DP0 pid=477164)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=477164)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=477164)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=477164)     return func(*args, **kwargs)
(EngineCore_DP0 pid=477164)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=477164)     outputs = self.model(
(EngineCore_DP0 pid=477164)               ^^^^^^^^^^^
(EngineCore_DP0 pid=477164)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=477164)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=477164)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=477164)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=477164)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=477164)     hidden_states = self.model(
(EngineCore_DP0 pid=477164)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=477164)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=477164)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=477164)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=477164)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=477164)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=477164)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=477164)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=477164)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=477164)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=477164)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=477164)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=477164)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=477164)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=477164)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=477164)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=477164)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=477164)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=477164)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=477164)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=477164)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=477164)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=477164)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=477164)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=477164)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=477164)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=477164)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=477164)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=477164)     return self._linear_fn(
(EngineCore_DP0 pid=477164)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=477164)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=477164)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=477164)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=477164)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=477164)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=477164)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=477164)     return fn(input, L)
(EngineCore_DP0 pid=477164)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=477164)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=477164)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=477164)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=477164)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=477164)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=477164)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=477164)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=477164)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=477164)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=477164)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=477164)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=477164)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=477164)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=477164)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=477164)     raise PTXASError(error)
(EngineCore_DP0 pid=477164) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=477164) `ptxas` stderr:
(EngineCore_DP0 pid=477164) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=477164) 
(EngineCore_DP0 pid=477164) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpdg30hzch.ptx -o /tmp/tmpdg30hzch.ptx.o
(EngineCore_DP0 pid=477164) 
[rank0]:[W125 21:28:34.565083077 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=2048

========== M=4096 ==========
Time: 2026-01-25 21:28:36
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Qwen2.5-7B-FP8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:28:41 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 21:28:41 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=478360) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=478360) 
(EngineCore_DP0 pid=478360) 
(EngineCore_DP0 pid=478360) ================================================================
(EngineCore_DP0 pid=478360) Internal Triton PTX codegen error
(EngineCore_DP0 pid=478360) `ptxas` stderr:
(EngineCore_DP0 pid=478360) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=478360) 
(EngineCore_DP0 pid=478360) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpbf_57iw0.ptx -o /tmp/tmpbf_57iw0.ptx.o
(EngineCore_DP0 pid=478360) 
(EngineCore_DP0 pid=478360) 
(EngineCore_DP0 pid=478360) //
(EngineCore_DP0 pid=478360) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=478360) //
(EngineCore_DP0 pid=478360) 
(EngineCore_DP0 pid=478360) .version 8.7
(EngineCore_DP0 pid=478360) .target sm_121a
(EngineCore_DP0 pid=478360) .address_size 64
(EngineCore_DP0 pid=478360) 
(EngineCore_DP0 pid=478360) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=478360) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=478360)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=478360) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=478360) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=478360) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=478360) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=478360) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=478360) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=478360) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=478360) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=478360) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=478360) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=478360) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=478360) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=478360) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=478360) )
(EngineCore_DP0 pid=478360) .reqntid 512
(EngineCore_DP0 pid=478360) {
(EngineCore_DP0 pid=478360) 	.reg .pred 	%p<28>;
(EngineCore_DP0 pid=478360) 	.reg .b16 	%rs<49>;
(EngineCore_DP0 pid=478360) 	.reg .b32 	%r<139>;
(EngineCore_DP0 pid=478360) 	.reg .b64 	%rd<17>;
(EngineCore_DP0 pid=478360) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=478360) $L__func_begin0:
(EngineCore_DP0 pid=478360) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=478360) 
(EngineCore_DP0 pid=478360) // %bb.0:
(EngineCore_DP0 pid=478360) 	ld.param.b32 	%r21, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=478360) 	ld.param.b32 	%r20, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=478360) 	ld.param.b32 	%r19, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=478360) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=478360) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=478360) $L__tmp0:
(EngineCore_DP0 pid=478360) 	.loc	1 143 24                        // quant_slide_tuned_Qwen2.5-7B.py:143:24
(EngineCore_DP0 pid=478360) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=478360) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=478360) 	.loc	1 148 26                        // quant_slide_tuned_Qwen2.5-7B.py:148:26
(EngineCore_DP0 pid=478360) 	mul.lo.s32 	%r24, %r23, %r1;
(EngineCore_DP0 pid=478360) 	.loc	1 148 20                        // quant_slide_tuned_Qwen2.5-7B.py:148:20
(EngineCore_DP0 pid=478360) 	mad.wide.s32 	%rd1, %r24, 2, %rd4;
(EngineCore_DP0 pid=478360) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=478360) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=478360) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=478360) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=478360) 	setp.lt.s32 	%p1, %r20, 1;
(EngineCore_DP0 pid=478360) 	mov.b32 	%r137, 0f2B8CBCCC;
(EngineCore_DP0 pid=478360) 	setp.eq.b32 	%p27, %r2, 0;
(EngineCore_DP0 pid=478360) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=478360) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=478360) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=478360) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=478360) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=478360) 	shr.u32 	%r33, %r2, 3;
(EngineCore_DP0 pid=478360) 	and.b32 	%r34, %r33, 60;
(EngineCore_DP0 pid=478360) 	mov.b32 	%r35, global_smem;
(EngineCore_DP0 pid=478360) 	add.s32 	%r45, %r35, %r34;
(EngineCore_DP0 pid=478360) 	shl.b32 	%r36, %r2, 2;
(EngineCore_DP0 pid=478360) 	add.s32 	%r48, %r35, %r36;
(EngineCore_DP0 pid=478360) 	mov.b32 	%r41, 0;
(EngineCore_DP0 pid=478360) 	mov.b32 	%r135, 0f00000000;
(EngineCore_DP0 pid=478360) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=478360) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=478360) 	mov.b32 	%r136, %r41;
(EngineCore_DP0 pid=478360) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=478360) 	.loc	1 155 22                        // quant_slide_tuned_Qwen2.5-7B.py:155:22
(EngineCore_DP0 pid=478360) 	add.s32 	%r51, %r4, %r136;
(EngineCore_DP0 pid=478360) 	setp.lt.s32 	%p2, %r51, %r19;
(EngineCore_DP0 pid=478360) 	.loc	1 156 29                        // quant_slide_tuned_Qwen2.5-7B.py:156:29
(EngineCore_DP0 pid=478360) 	mad.wide.s32 	%rd6, %r51, 2, %rd1;
(EngineCore_DP0 pid=478360) 	.loc	1 156 21                        // quant_slide_tuned_Qwen2.5-7B.py:156:21
(EngineCore_DP0 pid=478360) 	// begin inline asm
(EngineCore_DP0 pid=478360) 	mov.u32 %r37, %r41;
(EngineCore_DP0 pid=478360) 	mov.u32 %r38, %r41;
(EngineCore_DP0 pid=478360) 	mov.u32 %r39, %r41;
(EngineCore_DP0 pid=478360) 	mov.u32 %r40, %r41;
(EngineCore_DP0 pid=478360) 	@%p2 ld.global.v4.b32 { %r37, %r38, %r39, %r40 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=478360) 	// end inline asm
(EngineCore_DP0 pid=478360) 	mov.b32 	{%rs1, %rs2}, %r37;
(EngineCore_DP0 pid=478360) 	mov.b32 	{%rs3, %rs4}, %r38;
(EngineCore_DP0 pid=478360) 	mov.b32 	{%rs5, %rs6}, %r39;
(EngineCore_DP0 pid=478360) 	mov.b32 	{%rs7, %rs8}, %r40;
(EngineCore_DP0 pid=478360) 	.loc	1 157 50                        // quant_slide_tuned_Qwen2.5-7B.py:157:50
(EngineCore_DP0 pid=478360) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=478360) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=478360) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=478360) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=478360) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=478360) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=478360) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=478360) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=478360) $L__tmp1:
(EngineCore_DP0 pid=478360) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=478360) 	bar.sync 	0;
(EngineCore_DP0 pid=478360) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=478360) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=478360) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=478360) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=478360) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=478360) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=478360) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=478360) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=478360) 	cvt.f32.bf16 	%r52, %rs23;
(EngineCore_DP0 pid=478360) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=478360) 	shfl.sync.bfly.b32 	%r53, %r52, 16, 31, -1;
(EngineCore_DP0 pid=478360) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=478360) 	max.f32 	%r54, %r52, %r53;
(EngineCore_DP0 pid=478360) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=478360) 	shfl.sync.bfly.b32 	%r55, %r54, 8, 31, -1;
(EngineCore_DP0 pid=478360) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=478360) 	max.f32 	%r56, %r54, %r55;
(EngineCore_DP0 pid=478360) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=478360) 	shfl.sync.bfly.b32 	%r57, %r56, 4, 31, -1;
(EngineCore_DP0 pid=478360) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=478360) 	max.f32 	%r58, %r56, %r57;
(EngineCore_DP0 pid=478360) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=478360) 	shfl.sync.bfly.b32 	%r59, %r58, 2, 31, -1;
(EngineCore_DP0 pid=478360) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=478360) 	max.f32 	%r60, %r58, %r59;
(EngineCore_DP0 pid=478360) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=478360) 	shfl.sync.bfly.b32 	%r61, %r60, 1, 31, -1;
(EngineCore_DP0 pid=478360) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=478360) 	max.f32 	%r46, %r60, %r61;
(EngineCore_DP0 pid=478360) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=478360) 	// begin inline asm
(EngineCore_DP0 pid=478360) 	@%p3 st.shared.b32 [ %r45 + 0 ], %r46;
(EngineCore_DP0 pid=478360) 	// end inline asm
(EngineCore_DP0 pid=478360) 	bar.sync 	0;
(EngineCore_DP0 pid=478360) 	// begin inline asm
(EngineCore_DP0 pid=478360) 	@%p4 ld.shared.b32 %r47, [ %r48 + 0 ];
(EngineCore_DP0 pid=478360) 	// end inline asm
(EngineCore_DP0 pid=478360) 	shfl.sync.bfly.b32 	%r62, %r47, 8, 31, -1;
(EngineCore_DP0 pid=478360) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=478360) 	max.f32 	%r63, %r47, %r62;
(EngineCore_DP0 pid=478360) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=478360) 	shfl.sync.bfly.b32 	%r64, %r63, 4, 31, -1;
(EngineCore_DP0 pid=478360) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=478360) 	max.f32 	%r65, %r63, %r64;
(EngineCore_DP0 pid=478360) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=478360) 	shfl.sync.bfly.b32 	%r66, %r65, 2, 31, -1;
(EngineCore_DP0 pid=478360) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=478360) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=478360) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=478360) 	shfl.sync.bfly.b32 	%r68, %r67, 1, 31, -1;
(EngineCore_DP0 pid=478360) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=478360) 	max.f32 	%r50, %r67, %r68;
(EngineCore_DP0 pid=478360) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=478360) 	// begin inline asm
(EngineCore_DP0 pid=478360) 	@%p27 st.shared.b32 [ %r48 + 0 ], %r50;
(EngineCore_DP0 pid=478360) 	// end inline asm
(EngineCore_DP0 pid=478360) 	bar.sync 	0;
(EngineCore_DP0 pid=478360) 	ld.shared.b32 	%r69, [global_smem];
(EngineCore_DP0 pid=478360) $L__tmp2:
(EngineCore_DP0 pid=478360) 	.loc	1 157 36                        // quant_slide_tuned_Qwen2.5-7B.py:157:36
(EngineCore_DP0 pid=478360) 	max.f32 	%r135, %r135, %r69;
(EngineCore_DP0 pid=478360) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=478360) 	add.s32 	%r136, %r136, 4096;
(EngineCore_DP0 pid=478360) 	setp.lt.s32 	%p6, %r136, %r20;
(EngineCore_DP0 pid=478360) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=478360) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=478360) 	.loc	1 159 32                        // quant_slide_tuned_Qwen2.5-7B.py:159:32
(EngineCore_DP0 pid=478360) 	max.f32 	%r137, %r135, 0f2B8CBCCC;
(EngineCore_DP0 pid=478360) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=478360) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-7B.py:0:32
(EngineCore_DP0 pid=478360) 	mov.b32 	%r71, 0f43E00000;
(EngineCore_DP0 pid=478360) 	.loc	1 160 32                        // quant_slide_tuned_Qwen2.5-7B.py:160:32
(EngineCore_DP0 pid=478360) 	div.full.f32 	%r72, %r137, %r71;
(EngineCore_DP0 pid=478360) 	.loc	1 160 41                        // quant_slide_tuned_Qwen2.5-7B.py:160:41
(EngineCore_DP0 pid=478360) 	max.f32 	%r70, %r72, 0f36924925;
(EngineCore_DP0 pid=478360) 	.loc	1 162 25                        // quant_slide_tuned_Qwen2.5-7B.py:162:25
(EngineCore_DP0 pid=478360) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=478360) 	.loc	1 162 30                        // quant_slide_tuned_Qwen2.5-7B.py:162:30
(EngineCore_DP0 pid=478360) 	// begin inline asm
(EngineCore_DP0 pid=478360) 	@%p27 st.global.b32 [ %rd7 + 0 ], { %r70 };
(EngineCore_DP0 pid=478360) 	// end inline asm
(EngineCore_DP0 pid=478360) 	.loc	1 165 29                        // quant_slide_tuned_Qwen2.5-7B.py:165:29
(EngineCore_DP0 pid=478360) 	shl.b32 	%r15, %r21, 1;
(EngineCore_DP0 pid=478360) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=478360) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=478360) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=478360) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=478360) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-7B.py:0:41
(EngineCore_DP0 pid=478360) 	ld.param.b32 	%r25, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=478360) 	shr.s32 	%r26, %r25, 31;
(EngineCore_DP0 pid=478360) 	shr.u32 	%r27, %r26, 30;
(EngineCore_DP0 pid=478360) 	add.s32 	%r28, %r25, %r27;
(EngineCore_DP0 pid=478360) 	shr.s32 	%r29, %r28, 2;
(EngineCore_DP0 pid=478360) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=478360) 	mul.lo.s32 	%r30, %r29, %r1;
(EngineCore_DP0 pid=478360) 	mad.wide.s32 	%rd2, %r30, 4, %rd5;
(EngineCore_DP0 pid=478360) 	div.full.f32 	%r14, %r71, %r137;
(EngineCore_DP0 pid=478360) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=478360) 	mov.b32 	%r138, 0;
(EngineCore_DP0 pid=478360) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=478360)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=478360) 	.loc	1 168 31                        // quant_slide_tuned_Qwen2.5-7B.py:168:31
(EngineCore_DP0 pid=478360) 	add.s32 	%r84, %r16, %r138;
(EngineCore_DP0 pid=478360) 	.loc	1 169 30                        // quant_slide_tuned_Qwen2.5-7B.py:169:30
(EngineCore_DP0 pid=478360) 	add.s32 	%r85, %r138, 1;
(EngineCore_DP0 pid=478360) 	setp.lt.s32 	%p17, %r84, %r15;
(EngineCore_DP0 pid=478360) 	.loc	1 172 24                        // quant_slide_tuned_Qwen2.5-7B.py:172:24
(EngineCore_DP0 pid=478360) 	shr.u32 	%r86, %r84, 1;
(EngineCore_DP0 pid=478360) 	.loc	1 173 23                        // quant_slide_tuned_Qwen2.5-7B.py:173:23
(EngineCore_DP0 pid=478360) 	shr.u32 	%r87, %r85, 31;
(EngineCore_DP0 pid=478360) 	add.s32 	%r88, %r85, %r87;
(EngineCore_DP0 pid=478360) 	and.b32 	%r89, %r88, 2147483646;
(EngineCore_DP0 pid=478360) 	sub.s32 	%r90, %r85, %r89;
(EngineCore_DP0 pid=478360) 	.loc	1 174 22                        // quant_slide_tuned_Qwen2.5-7B.py:174:22
(EngineCore_DP0 pid=478360) 	mul.lo.s32 	%r91, %r86, 6;
(EngineCore_DP0 pid=478360) 	.loc	1 174 30                        // quant_slide_tuned_Qwen2.5-7B.py:174:30
(EngineCore_DP0 pid=478360) 	shl.b32 	%r92, %r90, 1;
(EngineCore_DP0 pid=478360) 	.loc	1 174 26                        // quant_slide_tuned_Qwen2.5-7B.py:174:26
(EngineCore_DP0 pid=478360) 	add.s32 	%r93, %r91, %r92;
(EngineCore_DP0 pid=478360) 	.loc	1 177 53                        // quant_slide_tuned_Qwen2.5-7B.py:177:53
(EngineCore_DP0 pid=478360) 	setp.lt.s32 	%p18, %r91, %r19;
(EngineCore_DP0 pid=478360) 	setp.lt.s32 	%p19, %r93, %r19;
(EngineCore_DP0 pid=478360) 	.loc	1 177 37                        // quant_slide_tuned_Qwen2.5-7B.py:177:37
(EngineCore_DP0 pid=478360) 	and.pred 	%p9, %p17, %p18;
(EngineCore_DP0 pid=478360) 	and.pred 	%p10, %p17, %p19;
(EngineCore_DP0 pid=478360) 	.loc	1 176 29                        // quant_slide_tuned_Qwen2.5-7B.py:176:29
(EngineCore_DP0 pid=478360) 	mad.wide.s32 	%rd8, %r91, 2, %rd1;
(EngineCore_DP0 pid=478360) 	mad.wide.s32 	%rd9, %r93, 2, %rd1;
(EngineCore_DP0 pid=478360) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=478360) 	.loc	1 176 21                        // quant_slide_tuned_Qwen2.5-7B.py:176:21
(EngineCore_DP0 pid=478360) 	// begin inline asm
(EngineCore_DP0 pid=478360) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=478360) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=478360) 	// end inline asm
(EngineCore_DP0 pid=478360) 	// begin inline asm
(EngineCore_DP0 pid=478360) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=478360) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=478360) 	// end inline asm
(EngineCore_DP0 pid=478360) 	.loc	1 177 79                        // quant_slide_tuned_Qwen2.5-7B.py:177:79
(EngineCore_DP0 pid=478360) 	cvt.f32.bf16 	%r94, %rs24;
(EngineCore_DP0 pid=478360) 	cvt.f32.bf16 	%r95, %rs26;
(EngineCore_DP0 pid=478360) 	.loc	1 179 48                        // quant_slide_tuned_Qwen2.5-7B.py:179:48
(EngineCore_DP0 pid=478360) 	or.b32 	%r96, %r91, 1;
(EngineCore_DP0 pid=478360) 	or.b32 	%r97, %r93, 1;
(EngineCore_DP0 pid=478360) 	.loc	1 179 53                        // quant_slide_tuned_Qwen2.5-7B.py:179:53
(EngineCore_DP0 pid=478360) 	setp.lt.s32 	%p20, %r96, %r19;
(EngineCore_DP0 pid=478360) 	setp.lt.s32 	%p21, %r97, %r19;
(EngineCore_DP0 pid=478360) 	.loc	1 179 37                        // quant_slide_tuned_Qwen2.5-7B.py:179:37
(EngineCore_DP0 pid=478360) 	and.pred 	%p11, %p17, %p20;
(EngineCore_DP0 pid=478360) 	and.pred 	%p12, %p17, %p21;
(EngineCore_DP0 pid=478360) 	.loc	1 178 39                        // quant_slide_tuned_Qwen2.5-7B.py:178:39
(EngineCore_DP0 pid=478360) 	add.s64 	%rd10, %rd8, 2;
(EngineCore_DP0 pid=478360) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=478360) 	.loc	1 178 21                        // quant_slide_tuned_Qwen2.5-7B.py:178:21
(EngineCore_DP0 pid=478360) 	// begin inline asm
(EngineCore_DP0 pid=478360) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=478360) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=478360) 	// end inline asm
(EngineCore_DP0 pid=478360) 	// begin inline asm
(EngineCore_DP0 pid=478360) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=478360) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=478360) 	// end inline asm
(EngineCore_DP0 pid=478360) 	.loc	1 179 79                        // quant_slide_tuned_Qwen2.5-7B.py:179:79
(EngineCore_DP0 pid=478360) 	cvt.f32.bf16 	%r98, %rs28;
(EngineCore_DP0 pid=478360) 	cvt.f32.bf16 	%r99, %rs30;
(EngineCore_DP0 pid=478360) 	.loc	1 181 48                        // quant_slide_tuned_Qwen2.5-7B.py:181:48
(EngineCore_DP0 pid=478360) 	add.s32 	%r100, %r91, 2;
(EngineCore_DP0 pid=478360) 	add.s32 	%r101, %r93, 2;
(EngineCore_DP0 pid=478360) 	.loc	1 181 53                        // quant_slide_tuned_Qwen2.5-7B.py:181:53
(EngineCore_DP0 pid=478360) 	setp.lt.s32 	%p22, %r100, %r19;
(EngineCore_DP0 pid=478360) 	setp.lt.s32 	%p23, %r101, %r19;
(EngineCore_DP0 pid=478360) 	.loc	1 181 37                        // quant_slide_tuned_Qwen2.5-7B.py:181:37
(EngineCore_DP0 pid=478360) 	and.pred 	%p13, %p17, %p22;
(EngineCore_DP0 pid=478360) 	and.pred 	%p14, %p17, %p23;
(EngineCore_DP0 pid=478360) 	.loc	1 180 39                        // quant_slide_tuned_Qwen2.5-7B.py:180:39
(EngineCore_DP0 pid=478360) 	add.s64 	%rd12, %rd8, 4;
(EngineCore_DP0 pid=478360) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=478360) 	.loc	1 180 21                        // quant_slide_tuned_Qwen2.5-7B.py:180:21
(EngineCore_DP0 pid=478360) 	// begin inline asm
(EngineCore_DP0 pid=478360) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=478360) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=478360) 	// end inline asm
(EngineCore_DP0 pid=478360) 	// begin inline asm
(EngineCore_DP0 pid=478360) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=478360) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=478360) 	// end inline asm
(EngineCore_DP0 pid=478360) 	.loc	1 181 79                        // quant_slide_tuned_Qwen2.5-7B.py:181:79
(EngineCore_DP0 pid=478360) 	cvt.f32.bf16 	%r102, %rs32;
(EngineCore_DP0 pid=478360) 	cvt.f32.bf16 	%r103, %rs34;
(EngineCore_DP0 pid=478360) 	.loc	1 183 48                        // quant_slide_tuned_Qwen2.5-7B.py:183:48
(EngineCore_DP0 pid=478360) 	add.s32 	%r104, %r91, 3;
(EngineCore_DP0 pid=478360) 	add.s32 	%r105, %r93, 3;
(EngineCore_DP0 pid=478360) 	.loc	1 183 53                        // quant_slide_tuned_Qwen2.5-7B.py:183:53
(EngineCore_DP0 pid=478360) 	setp.lt.s32 	%p24, %r104, %r19;
(EngineCore_DP0 pid=478360) 	setp.lt.s32 	%p25, %r105, %r19;
(EngineCore_DP0 pid=478360) 	.loc	1 183 37                        // quant_slide_tuned_Qwen2.5-7B.py:183:37
(EngineCore_DP0 pid=478360) 	and.pred 	%p15, %p17, %p24;
(EngineCore_DP0 pid=478360) 	and.pred 	%p16, %p17, %p25;
(EngineCore_DP0 pid=478360) 	.loc	1 182 39                        // quant_slide_tuned_Qwen2.5-7B.py:182:39
(EngineCore_DP0 pid=478360) 	add.s64 	%rd14, %rd8, 6;
(EngineCore_DP0 pid=478360) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=478360) 	.loc	1 182 21                        // quant_slide_tuned_Qwen2.5-7B.py:182:21
(EngineCore_DP0 pid=478360) 	// begin inline asm
(EngineCore_DP0 pid=478360) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=478360) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=478360) 	// end inline asm
(EngineCore_DP0 pid=478360) 	// begin inline asm
(EngineCore_DP0 pid=478360) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=478360) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=478360) 	// end inline asm
(EngineCore_DP0 pid=478360) 	.loc	1 183 79                        // quant_slide_tuned_Qwen2.5-7B.py:183:79
(EngineCore_DP0 pid=478360) 	cvt.f32.bf16 	%r106, %rs36;
(EngineCore_DP0 pid=478360) 	cvt.f32.bf16 	%r107, %rs38;
(EngineCore_DP0 pid=478360) 	.loc	1 185 27                        // quant_slide_tuned_Qwen2.5-7B.py:185:27
(EngineCore_DP0 pid=478360) 	mul.f32 	%r108, %r14, %r94;
(EngineCore_DP0 pid=478360) 	mul.f32 	%r109, %r14, %r95;
(EngineCore_DP0 pid=478360) 	mov.b32 	%r110, 0f43E00000;
(EngineCore_DP0 pid=478360) 	.loc	1 185 48                        // quant_slide_tuned_Qwen2.5-7B.py:185:48
(EngineCore_DP0 pid=478360) 	min.xorsign.abs.f32 	%r74, %r108, %r110;
(EngineCore_DP0 pid=478360) 	min.xorsign.abs.f32 	%r75, %r109, %r110;
(EngineCore_DP0 pid=478360) 	.loc	1 185 60                        // quant_slide_tuned_Qwen2.5-7B.py:185:60
(EngineCore_DP0 pid=478360) 	// begin inline asm
(EngineCore_DP0 pid=478360) 	cvt.rn.satfinite.e4m3x2.f32  %rs40, %r75, %r74; 
(EngineCore_DP0 pid=478360) 
(EngineCore_DP0 pid=478360) 	// end inline asm
(EngineCore_DP0 pid=478360) 	shr.u16 	%rs44, %rs40, 8;
(EngineCore_DP0 pid=478360) 	.loc	1 186 27                        // quant_slide_tuned_Qwen2.5-7B.py:186:27
(EngineCore_DP0 pid=478360) 	mul.f32 	%r111, %r14, %r98;
(EngineCore_DP0 pid=478360) 	mul.f32 	%r112, %r14, %r99;
(EngineCore_DP0 pid=478360) 	.loc	1 186 48                        // quant_slide_tuned_Qwen2.5-7B.py:186:48
(EngineCore_DP0 pid=478360) 	min.xorsign.abs.f32 	%r76, %r111, %r110;
(EngineCore_DP0 pid=478360) 	min.xorsign.abs.f32 	%r77, %r112, %r110;
(EngineCore_DP0 pid=478360) 	.loc	1 186 60                        // quant_slide_tuned_Qwen2.5-7B.py:186:60
(EngineCore_DP0 pid=478360) 	// begin inline asm
(EngineCore_DP0 pid=478360) 	cvt.rn.satfinite.e4m3x2.f32  %rs41, %r77, %r76; 
(EngineCore_DP0 pid=478360) 
(EngineCore_DP0 pid=478360) 	// end inline asm
(EngineCore_DP0 pid=478360) 	shr.u16 	%rs45, %rs41, 8;
(EngineCore_DP0 pid=478360) 	.loc	1 187 27                        // quant_slide_tuned_Qwen2.5-7B.py:187:27
(EngineCore_DP0 pid=478360) 	mul.f32 	%r113, %r14, %r102;
(EngineCore_DP0 pid=478360) 	mul.f32 	%r114, %r14, %r103;
(EngineCore_DP0 pid=478360) 	.loc	1 187 48                        // quant_slide_tuned_Qwen2.5-7B.py:187:48
(EngineCore_DP0 pid=478360) 	min.xorsign.abs.f32 	%r78, %r113, %r110;
(EngineCore_DP0 pid=478360) 	min.xorsign.abs.f32 	%r79, %r114, %r110;
(EngineCore_DP0 pid=478360) 	.loc	1 187 60                        // quant_slide_tuned_Qwen2.5-7B.py:187:60
(EngineCore_DP0 pid=478360) 	// begin inline asm
(EngineCore_DP0 pid=478360) 	cvt.rn.satfinite.e4m3x2.f32  %rs42, %r79, %r78; 
(EngineCore_DP0 pid=478360) 
(EngineCore_DP0 pid=478360) 	// end inline asm
(EngineCore_DP0 pid=478360) 	shr.u16 	%rs46, %rs42, 8;
(EngineCore_DP0 pid=478360) 	.loc	1 188 27                        // quant_slide_tuned_Qwen2.5-7B.py:188:27
(EngineCore_DP0 pid=478360) 	mul.f32 	%r115, %r14, %r106;
(EngineCore_DP0 pid=478360) 	mul.f32 	%r116, %r14, %r107;
(EngineCore_DP0 pid=478360) 	.loc	1 188 48                        // quant_slide_tuned_Qwen2.5-7B.py:188:48
(EngineCore_DP0 pid=478360) 	min.xorsign.abs.f32 	%r80, %r115, %r110;
(EngineCore_DP0 pid=478360) 	min.xorsign.abs.f32 	%r81, %r116, %r110;
(EngineCore_DP0 pid=478360) 	.loc	1 188 60                        // quant_slide_tuned_Qwen2.5-7B.py:188:60
(EngineCore_DP0 pid=478360) 	// begin inline asm
(EngineCore_DP0 pid=478360) 	cvt.rn.satfinite.e4m3x2.f32  %rs43, %r81, %r80; 
(EngineCore_DP0 pid=478360) 
(EngineCore_DP0 pid=478360) 	// end inline asm
(EngineCore_DP0 pid=478360) 	shr.u16 	%rs47, %rs43, 8;
(EngineCore_DP0 pid=478360) 	.loc	1 190 45                        // quant_slide_tuned_Qwen2.5-7B.py:190:45
(EngineCore_DP0 pid=478360) 	cvt.u32.u16 	%r117, %rs40;
(EngineCore_DP0 pid=478360) 	and.b32 	%r118, %r117, 255;
(EngineCore_DP0 pid=478360) 	cvt.u32.u16 	%r119, %rs44;
(EngineCore_DP0 pid=478360) 	.loc	1 192 45                        // quant_slide_tuned_Qwen2.5-7B.py:192:45
(EngineCore_DP0 pid=478360) 	cvt.u32.u16 	%r120, %rs42;
(EngineCore_DP0 pid=478360) 	and.b32 	%r121, %r120, 255;
(EngineCore_DP0 pid=478360) 	cvt.u32.u16 	%r122, %rs46;
(EngineCore_DP0 pid=478360) 	.loc	1 193 45                        // quant_slide_tuned_Qwen2.5-7B.py:193:45
(EngineCore_DP0 pid=478360) 	cvt.u32.u16 	%r123, %rs43;
(EngineCore_DP0 pid=478360) 	cvt.u32.u16 	%r124, %rs47;
(EngineCore_DP0 pid=478360) 	.loc	1 195 30                        // quant_slide_tuned_Qwen2.5-7B.py:195:30
(EngineCore_DP0 pid=478360) 	and.b16 	%rs48, %rs41, 255;
(EngineCore_DP0 pid=478360) 	mul.wide.u16 	%r125, %rs48, 256;
(EngineCore_DP0 pid=478360) 	mul.wide.u16 	%r126, %rs45, 256;
(EngineCore_DP0 pid=478360) 	.loc	1 195 24                        // quant_slide_tuned_Qwen2.5-7B.py:195:24
(EngineCore_DP0 pid=478360) 	or.b32 	%r127, %r125, %r118;
(EngineCore_DP0 pid=478360) 	or.b32 	%r128, %r126, %r119;
(EngineCore_DP0 pid=478360) 	.loc	1 195 42                        // quant_slide_tuned_Qwen2.5-7B.py:195:42
(EngineCore_DP0 pid=478360) 	shl.b32 	%r129, %r121, 16;
(EngineCore_DP0 pid=478360) 	shl.b32 	%r130, %r122, 16;
(EngineCore_DP0 pid=478360) 	.loc	1 195 36                        // quant_slide_tuned_Qwen2.5-7B.py:195:36
(EngineCore_DP0 pid=478360) 	or.b32 	%r131, %r127, %r129;
(EngineCore_DP0 pid=478360) 	or.b32 	%r132, %r128, %r130;
(EngineCore_DP0 pid=478360) 	.loc	1 195 55                        // quant_slide_tuned_Qwen2.5-7B.py:195:55
(EngineCore_DP0 pid=478360) 	shl.b32 	%r133, %r123, 24;
(EngineCore_DP0 pid=478360) 	shl.b32 	%r134, %r124, 24;
(EngineCore_DP0 pid=478360) 	.loc	1 195 49                        // quant_slide_tuned_Qwen2.5-7B.py:195:49
(EngineCore_DP0 pid=478360) 	or.b32 	%r82, %r131, %r133;
(EngineCore_DP0 pid=478360) 	or.b32 	%r83, %r132, %r134;
(EngineCore_DP0 pid=478360) 	.loc	1 196 29                        // quant_slide_tuned_Qwen2.5-7B.py:196:29
(EngineCore_DP0 pid=478360) 	mad.wide.s32 	%rd16, %r84, 4, %rd2;
(EngineCore_DP0 pid=478360) 	.loc	1 196 39                        // quant_slide_tuned_Qwen2.5-7B.py:196:39
(EngineCore_DP0 pid=478360) 	// begin inline asm
(EngineCore_DP0 pid=478360) 	@%p17 st.global.v2.b32 [ %rd16 + 0 ], { %r82, %r83 };
(EngineCore_DP0 pid=478360) 	// end inline asm
(EngineCore_DP0 pid=478360) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=478360) 	add.s32 	%r138, %r138, 1024;
(EngineCore_DP0 pid=478360) 	setp.lt.s32 	%p26, %r138, %r15;
(EngineCore_DP0 pid=478360) 	@%p26 bra 	$L__BB0_6;
(EngineCore_DP0 pid=478360) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=478360) 	.loc	1 167 4                         // quant_slide_tuned_Qwen2.5-7B.py:167:4
(EngineCore_DP0 pid=478360) 	ret;
(EngineCore_DP0 pid=478360) $L__tmp3:
(EngineCore_DP0 pid=478360) $L__func_end0:
(EngineCore_DP0 pid=478360)                                         // -- End function
(EngineCore_DP0 pid=478360) }
(EngineCore_DP0 pid=478360) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py"
(EngineCore_DP0 pid=478360) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=478360) 	.section	.debug_abbrev
(EngineCore_DP0 pid=478360) 	{
(EngineCore_DP0 pid=478360) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=478360) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=478360) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=478360) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=478360) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=478360) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=478360) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=478360) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=478360) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=478360) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=478360) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=478360) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=478360) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=478360) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=478360) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=478360) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=478360) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=478360) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=478360) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=478360) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=478360) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=478360) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=478360) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=478360) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=478360) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=478360) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=478360) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=478360) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=478360) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=478360) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=478360) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=478360) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=478360) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=478360) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=478360) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=478360) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=478360) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=478360) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=478360) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=478360) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=478360) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=478360) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=478360) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=478360) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=478360) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=478360) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=478360) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=478360) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=478360) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=478360) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=478360) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=478360) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=478360) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=478360) 	}
(EngineCore_DP0 pid=478360) 	.section	.debug_info
(EngineCore_DP0 pid=478360) 	{
(EngineCore_DP0 pid=478360) .b32 221                                // Length of Unit
(EngineCore_DP0 pid=478360) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=478360) .b8 0
(EngineCore_DP0 pid=478360) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=478360) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=478360) .b8 1                                   // Abbrev [1] 0xb:0xd6 DW_TAG_compile_unit
(EngineCore_DP0 pid=478360) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=478360) .b8 114
(EngineCore_DP0 pid=478360) .b8 105
(EngineCore_DP0 pid=478360) .b8 116
(EngineCore_DP0 pid=478360) .b8 111
(EngineCore_DP0 pid=478360) .b8 110
(EngineCore_DP0 pid=478360) .b8 0
(EngineCore_DP0 pid=478360) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=478360) .b8 0
(EngineCore_DP0 pid=478360) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=478360) .b8 117
(EngineCore_DP0 pid=478360) .b8 97
(EngineCore_DP0 pid=478360) .b8 110
(EngineCore_DP0 pid=478360) .b8 116
(EngineCore_DP0 pid=478360) .b8 95
(EngineCore_DP0 pid=478360) .b8 115
(EngineCore_DP0 pid=478360) .b8 108
(EngineCore_DP0 pid=478360) .b8 105
(EngineCore_DP0 pid=478360) .b8 100
(EngineCore_DP0 pid=478360) .b8 101
(EngineCore_DP0 pid=478360) .b8 95
(EngineCore_DP0 pid=478360) .b8 116
(EngineCore_DP0 pid=478360) .b8 117
(EngineCore_DP0 pid=478360) .b8 110
(EngineCore_DP0 pid=478360) .b8 101
(EngineCore_DP0 pid=478360) .b8 100
(EngineCore_DP0 pid=478360) .b8 95
(EngineCore_DP0 pid=478360) .b8 81
(EngineCore_DP0 pid=478360) .b8 119
(EngineCore_DP0 pid=478360) .b8 101
(EngineCore_DP0 pid=478360) .b8 110
(EngineCore_DP0 pid=478360) .b8 50
(EngineCore_DP0 pid=478360) .b8 46
(EngineCore_DP0 pid=478360) .b8 53
(EngineCore_DP0 pid=478360) .b8 45
(EngineCore_DP0 pid=478360) .b8 55
(EngineCore_DP0 pid=478360) .b8 66
(EngineCore_DP0 pid=478360) .b8 46
(EngineCore_DP0 pid=478360) .b8 112
(EngineCore_DP0 pid=478360) .b8 121
(EngineCore_DP0 pid=478360) .b8 0
(EngineCore_DP0 pid=478360) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=478360) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=478360) .b8 114
(EngineCore_DP0 pid=478360) .b8 111
(EngineCore_DP0 pid=478360) .b8 111
(EngineCore_DP0 pid=478360) .b8 116
(EngineCore_DP0 pid=478360) .b8 47
(EngineCore_DP0 pid=478360) .b8 118
(EngineCore_DP0 pid=478360) .b8 108
(EngineCore_DP0 pid=478360) .b8 108
(EngineCore_DP0 pid=478360) .b8 109
(EngineCore_DP0 pid=478360) .b8 98
(EngineCore_DP0 pid=478360) .b8 101
(EngineCore_DP0 pid=478360) .b8 110
(EngineCore_DP0 pid=478360) .b8 99
(EngineCore_DP0 pid=478360) .b8 104
(EngineCore_DP0 pid=478360) .b8 47
(EngineCore_DP0 pid=478360) .b8 115
(EngineCore_DP0 pid=478360) .b8 108
(EngineCore_DP0 pid=478360) .b8 105
(EngineCore_DP0 pid=478360) .b8 100
(EngineCore_DP0 pid=478360) .b8 101
(EngineCore_DP0 pid=478360) .b8 115
(EngineCore_DP0 pid=478360) .b8 112
(EngineCore_DP0 pid=478360) .b8 97
(EngineCore_DP0 pid=478360) .b8 114
(EngineCore_DP0 pid=478360) .b8 115
(EngineCore_DP0 pid=478360) .b8 101
(EngineCore_DP0 pid=478360) .b8 47
(EngineCore_DP0 pid=478360) .b8 99
(EngineCore_DP0 pid=478360) .b8 115
(EngineCore_DP0 pid=478360) .b8 114
(EngineCore_DP0 pid=478360) .b8 99
(EngineCore_DP0 pid=478360) .b8 47
(EngineCore_DP0 pid=478360) .b8 102
(EngineCore_DP0 pid=478360) .b8 117
(EngineCore_DP0 pid=478360) .b8 115
(EngineCore_DP0 pid=478360) .b8 101
(EngineCore_DP0 pid=478360) .b8 100
(EngineCore_DP0 pid=478360) .b8 95
(EngineCore_DP0 pid=478360) .b8 113
(EngineCore_DP0 pid=478360) .b8 117
(EngineCore_DP0 pid=478360) .b8 97
(EngineCore_DP0 pid=478360) .b8 110
(EngineCore_DP0 pid=478360) .b8 116
(EngineCore_DP0 pid=478360) .b8 95
(EngineCore_DP0 pid=478360) .b8 115
(EngineCore_DP0 pid=478360) .b8 108
(EngineCore_DP0 pid=478360) .b8 105
(EngineCore_DP0 pid=478360) .b8 100
(EngineCore_DP0 pid=478360) .b8 101
(EngineCore_DP0 pid=478360) .b8 95
(EngineCore_DP0 pid=478360) .b8 116
(EngineCore_DP0 pid=478360) .b8 114
(EngineCore_DP0 pid=478360) .b8 105
(EngineCore_DP0 pid=478360) .b8 116
(EngineCore_DP0 pid=478360) .b8 111
(EngineCore_DP0 pid=478360) .b8 110
(EngineCore_DP0 pid=478360) .b8 47
(EngineCore_DP0 pid=478360) .b8 98
(EngineCore_DP0 pid=478360) .b8 117
(EngineCore_DP0 pid=478360) .b8 105
(EngineCore_DP0 pid=478360) .b8 108
(EngineCore_DP0 pid=478360) .b8 100
(EngineCore_DP0 pid=478360) .b8 47
(EngineCore_DP0 pid=478360) .b8 71
(EngineCore_DP0 pid=478360) .b8 66
(EngineCore_DP0 pid=478360) .b8 49
(EngineCore_DP0 pid=478360) .b8 48
(EngineCore_DP0 pid=478360) .b8 95
(EngineCore_DP0 pid=478360) .b8 99
(EngineCore_DP0 pid=478360) .b8 99
(EngineCore_DP0 pid=478360) .b8 49
(EngineCore_DP0 pid=478360) .b8 50
(EngineCore_DP0 pid=478360) .b8 49
(EngineCore_DP0 pid=478360) .b8 95
(EngineCore_DP0 pid=478360) .b8 112
(EngineCore_DP0 pid=478360) .b8 121
(EngineCore_DP0 pid=478360) .b8 51
(EngineCore_DP0 pid=478360) .b8 49
(EngineCore_DP0 pid=478360) .b8 50
(EngineCore_DP0 pid=478360) .b8 95
(EngineCore_DP0 pid=478360) .b8 99
(EngineCore_DP0 pid=478360) .b8 117
(EngineCore_DP0 pid=478360) .b8 49
(EngineCore_DP0 pid=478360) .b8 50
(EngineCore_DP0 pid=478360) .b8 57
(EngineCore_DP0 pid=478360) .b8 95
(EngineCore_DP0 pid=478360) .b8 97
(EngineCore_DP0 pid=478360) .b8 97
(EngineCore_DP0 pid=478360) .b8 114
(EngineCore_DP0 pid=478360) .b8 99
(EngineCore_DP0 pid=478360) .b8 104
(EngineCore_DP0 pid=478360) .b8 54
(EngineCore_DP0 pid=478360) .b8 52
(EngineCore_DP0 pid=478360) .b8 0
(EngineCore_DP0 pid=478360) .b8 2                                   // Abbrev [2] 0x98:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=478360) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=478360) .b8 113
(EngineCore_DP0 pid=478360) .b8 117
(EngineCore_DP0 pid=478360) .b8 97
(EngineCore_DP0 pid=478360) .b8 110
(EngineCore_DP0 pid=478360) .b8 116
(EngineCore_DP0 pid=478360) .b8 95
(EngineCore_DP0 pid=478360) .b8 115
(EngineCore_DP0 pid=478360) .b8 108
(EngineCore_DP0 pid=478360) .b8 105
(EngineCore_DP0 pid=478360) .b8 100
(EngineCore_DP0 pid=478360) .b8 101
(EngineCore_DP0 pid=478360) .b8 95
(EngineCore_DP0 pid=478360) .b8 102
(EngineCore_DP0 pid=478360) .b8 112
(EngineCore_DP0 pid=478360) .b8 56
(EngineCore_DP0 pid=478360) .b8 95
(EngineCore_DP0 pid=478360) .b8 107
(EngineCore_DP0 pid=478360) .b8 101
(EngineCore_DP0 pid=478360) .b8 114
(EngineCore_DP0 pid=478360) .b8 110
(EngineCore_DP0 pid=478360) .b8 101
(EngineCore_DP0 pid=478360) .b8 108
(EngineCore_DP0 pid=478360) .b8 0
(EngineCore_DP0 pid=478360) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=478360) .b8 3                                   // Abbrev [3] 0xb2:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=478360) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=478360) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=478360) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=478360) .b8 4                                   // Abbrev [4] 0xc7:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=478360) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=478360) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=478360) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=478360) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=478360) .b8 157                                 // DW_AT_call_line
(EngineCore_DP0 pid=478360) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=478360) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=478360) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=478360) 	}
(EngineCore_DP0 pid=478360) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=478360) 
(EngineCore_DP0 pid=478360) ================================================================
(EngineCore_DP0 pid=478360) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=478360) 
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpbf_57iw0.ptx', '-o', '/tmp/tmpbf_57iw0.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866] 
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866] 
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866] 
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpbf_57iw0.ptx -o /tmp/tmpbf_57iw0.ptx.o
(EngineCore_DP0 pid=478360) ERROR 01-25 21:29:45 [core.py:866] 

STDERR:
[2026-01-25 21:28:41] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:28:41] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:28:41] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:28:41] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:28:41] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:28:41] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:28:41] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:28:41] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:28:41] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:28:41] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:28:41] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:28:41] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:28:41] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:28:41] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:28:44] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:28:44] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:28:44] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:28:44] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:28:44] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:28:44] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:28:44] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:28:44] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:28:44] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:28:44] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:28:44] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:28:44] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:28:44] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:28:44] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=478360) [2026-01-25 21:28:45] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=478360) [2026-01-25 21:28:45] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=478360) [2026-01-25 21:28:45] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=478360) [2026-01-25 21:28:45] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=478360) [2026-01-25 21:28:45] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=478360) [2026-01-25 21:28:45] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=478360) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=478360) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:23<00:23, 23.63s/it]
(EngineCore_DP0 pid=478360) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:57<00:00, 29.44s/it]
(EngineCore_DP0 pid=478360) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:57<00:00, 28.57s/it]
(EngineCore_DP0 pid=478360) 
(EngineCore_DP0 pid=478360) [2026-01-25 21:29:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=478360) [2026-01-25 21:29:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 13860864 bytes
(EngineCore_DP0 pid=478360) [2026-01-25 21:29:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=478360) [2026-01-25 21:29:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10780672 bytes
(EngineCore_DP0 pid=478360) [2026-01-25 21:29:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=478360) [2026-01-25 21:29:44] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 113967104 bytes
(EngineCore_DP0 pid=478360) [2026-01-25 21:29:44] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=478360) [2026-01-25 21:29:44] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 56655872 bytes
(EngineCore_DP0 pid=478360) Process EngineCore_DP0:
(EngineCore_DP0 pid=478360) Traceback (most recent call last):
(EngineCore_DP0 pid=478360)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=478360)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=478360)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=478360)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=478360) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpbf_57iw0.ptx', '-o', '/tmp/tmpbf_57iw0.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=478360) 
(EngineCore_DP0 pid=478360) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=478360) 
(EngineCore_DP0 pid=478360) Traceback (most recent call last):
(EngineCore_DP0 pid=478360)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=478360)     self.run()
(EngineCore_DP0 pid=478360)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=478360)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=478360)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=478360)     raise e
(EngineCore_DP0 pid=478360)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=478360)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=478360)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=478360)     super().__init__(
(EngineCore_DP0 pid=478360)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=478360)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=478360)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=478360)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=478360)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=478360)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=478360)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=478360)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=478360)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=478360)     return func(*args, **kwargs)
(EngineCore_DP0 pid=478360)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=478360)     return func(*args, **kwargs)
(EngineCore_DP0 pid=478360)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=478360)     self.model_runner.profile_run()
(EngineCore_DP0 pid=478360)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=478360)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=478360)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=478360)     return func(*args, **kwargs)
(EngineCore_DP0 pid=478360)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=478360)     outputs = self.model(
(EngineCore_DP0 pid=478360)               ^^^^^^^^^^^
(EngineCore_DP0 pid=478360)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=478360)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=478360)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=478360)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=478360)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=478360)     hidden_states = self.model(
(EngineCore_DP0 pid=478360)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=478360)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=478360)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=478360)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=478360)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=478360)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=478360)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=478360)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=478360)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=478360)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=478360)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=478360)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=478360)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=478360)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=478360)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=478360)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=478360)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=478360)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=478360)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=478360)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=478360)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=478360)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=478360)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=478360)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=478360)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=478360)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=478360)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=478360)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=478360)     return self._linear_fn(
(EngineCore_DP0 pid=478360)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=478360)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=478360)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=478360)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=478360)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=478360)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=478360)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=478360)     return fn(input, L)
(EngineCore_DP0 pid=478360)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=478360)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=478360)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=478360)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=478360)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=478360)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=478360)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=478360)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=478360)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=478360)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=478360)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=478360)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=478360)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=478360)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=478360)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=478360)     raise PTXASError(error)
(EngineCore_DP0 pid=478360) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=478360) `ptxas` stderr:
(EngineCore_DP0 pid=478360) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=478360) 
(EngineCore_DP0 pid=478360) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpbf_57iw0.ptx -o /tmp/tmpbf_57iw0.ptx.o
(EngineCore_DP0 pid=478360) 
[rank0]:[W125 21:29:45.536521086 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=4096

========== M=8192 ==========
Time: 2026-01-25 21:29:47
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Qwen2.5-7B-FP8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:29:54 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 21:29:54 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=479548) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=479548) 
(EngineCore_DP0 pid=479548) 
(EngineCore_DP0 pid=479548) ================================================================
(EngineCore_DP0 pid=479548) Internal Triton PTX codegen error
(EngineCore_DP0 pid=479548) `ptxas` stderr:
(EngineCore_DP0 pid=479548) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=479548) 
(EngineCore_DP0 pid=479548) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmph3g637ba.ptx -o /tmp/tmph3g637ba.ptx.o
(EngineCore_DP0 pid=479548) 
(EngineCore_DP0 pid=479548) 
(EngineCore_DP0 pid=479548) //
(EngineCore_DP0 pid=479548) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=479548) //
(EngineCore_DP0 pid=479548) 
(EngineCore_DP0 pid=479548) .version 8.7
(EngineCore_DP0 pid=479548) .target sm_121a
(EngineCore_DP0 pid=479548) .address_size 64
(EngineCore_DP0 pid=479548) 
(EngineCore_DP0 pid=479548) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=479548) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=479548)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=479548) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=479548) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=479548) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=479548) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=479548) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=479548) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=479548) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=479548) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=479548) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=479548) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=479548) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=479548) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=479548) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=479548) )
(EngineCore_DP0 pid=479548) .reqntid 512
(EngineCore_DP0 pid=479548) {
(EngineCore_DP0 pid=479548) 	.reg .pred 	%p<29>;
(EngineCore_DP0 pid=479548) 	.reg .b16 	%rs<73>;
(EngineCore_DP0 pid=479548) 	.reg .b32 	%r<148>;
(EngineCore_DP0 pid=479548) 	.reg .b64 	%rd<18>;
(EngineCore_DP0 pid=479548) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=479548) $L__func_begin0:
(EngineCore_DP0 pid=479548) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=479548) 
(EngineCore_DP0 pid=479548) // %bb.0:
(EngineCore_DP0 pid=479548) 	ld.param.b32 	%r21, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=479548) 	ld.param.b32 	%r20, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=479548) 	ld.param.b32 	%r19, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=479548) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=479548) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=479548) $L__tmp0:
(EngineCore_DP0 pid=479548) 	.loc	1 143 24                        // quant_slide_tuned_Qwen2.5-7B.py:143:24
(EngineCore_DP0 pid=479548) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=479548) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=479548) 	.loc	1 148 26                        // quant_slide_tuned_Qwen2.5-7B.py:148:26
(EngineCore_DP0 pid=479548) 	mul.lo.s32 	%r24, %r23, %r1;
(EngineCore_DP0 pid=479548) 	.loc	1 148 20                        // quant_slide_tuned_Qwen2.5-7B.py:148:20
(EngineCore_DP0 pid=479548) 	mad.wide.s32 	%rd1, %r24, 2, %rd4;
(EngineCore_DP0 pid=479548) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=479548) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=479548) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=479548) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=479548) 	setp.lt.s32 	%p1, %r20, 1;
(EngineCore_DP0 pid=479548) 	mov.b32 	%r146, 0f2B8CBCCC;
(EngineCore_DP0 pid=479548) 	setp.eq.b32 	%p28, %r2, 0;
(EngineCore_DP0 pid=479548) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=479548) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=479548) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=479548) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=479548) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=479548) 	shr.u32 	%r33, %r2, 3;
(EngineCore_DP0 pid=479548) 	and.b32 	%r34, %r33, 60;
(EngineCore_DP0 pid=479548) 	mov.b32 	%r35, global_smem;
(EngineCore_DP0 pid=479548) 	add.s32 	%r53, %r35, %r34;
(EngineCore_DP0 pid=479548) 	shl.b32 	%r36, %r2, 2;
(EngineCore_DP0 pid=479548) 	add.s32 	%r56, %r35, %r36;
(EngineCore_DP0 pid=479548) 	mov.b32 	%r41, 0;
(EngineCore_DP0 pid=479548) 	mov.b32 	%r144, 0f00000000;
(EngineCore_DP0 pid=479548) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=479548) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=479548) 	mov.b32 	%r145, %r41;
(EngineCore_DP0 pid=479548) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=479548) 	.loc	1 154 19                        // quant_slide_tuned_Qwen2.5-7B.py:154:19
(EngineCore_DP0 pid=479548) 	add.s32 	%r59, %r4, %r145;
(EngineCore_DP0 pid=479548) 	.loc	1 155 22                        // quant_slide_tuned_Qwen2.5-7B.py:155:22
(EngineCore_DP0 pid=479548) 	add.s32 	%r60, %r59, 4096;
(EngineCore_DP0 pid=479548) 	setp.lt.s32 	%p2, %r59, %r19;
(EngineCore_DP0 pid=479548) 	setp.lt.s32 	%p3, %r60, %r19;
(EngineCore_DP0 pid=479548) 	.loc	1 156 29                        // quant_slide_tuned_Qwen2.5-7B.py:156:29
(EngineCore_DP0 pid=479548) 	mad.wide.s32 	%rd6, %r59, 2, %rd1;
(EngineCore_DP0 pid=479548) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=479548) 	.loc	1 156 21                        // quant_slide_tuned_Qwen2.5-7B.py:156:21
(EngineCore_DP0 pid=479548) 	// begin inline asm
(EngineCore_DP0 pid=479548) 	mov.u32 %r37, %r41;
(EngineCore_DP0 pid=479548) 	mov.u32 %r38, %r41;
(EngineCore_DP0 pid=479548) 	mov.u32 %r39, %r41;
(EngineCore_DP0 pid=479548) 	mov.u32 %r40, %r41;
(EngineCore_DP0 pid=479548) 	@%p2 ld.global.v4.b32 { %r37, %r38, %r39, %r40 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=479548) 	// end inline asm
(EngineCore_DP0 pid=479548) 	mov.b32 	{%rs1, %rs2}, %r37;
(EngineCore_DP0 pid=479548) 	mov.b32 	{%rs3, %rs4}, %r38;
(EngineCore_DP0 pid=479548) 	mov.b32 	{%rs5, %rs6}, %r39;
(EngineCore_DP0 pid=479548) 	mov.b32 	{%rs7, %rs8}, %r40;
(EngineCore_DP0 pid=479548) 	// begin inline asm
(EngineCore_DP0 pid=479548) 	mov.u32 %r45, %r41;
(EngineCore_DP0 pid=479548) 	mov.u32 %r46, %r41;
(EngineCore_DP0 pid=479548) 	mov.u32 %r47, %r41;
(EngineCore_DP0 pid=479548) 	mov.u32 %r48, %r41;
(EngineCore_DP0 pid=479548) 	@%p3 ld.global.v4.b32 { %r45, %r46, %r47, %r48 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=479548) 	// end inline asm
(EngineCore_DP0 pid=479548) 	mov.b32 	{%rs9, %rs10}, %r45;
(EngineCore_DP0 pid=479548) 	mov.b32 	{%rs11, %rs12}, %r46;
(EngineCore_DP0 pid=479548) 	mov.b32 	{%rs13, %rs14}, %r47;
(EngineCore_DP0 pid=479548) 	mov.b32 	{%rs15, %rs16}, %r48;
(EngineCore_DP0 pid=479548) 	.loc	1 157 50                        // quant_slide_tuned_Qwen2.5-7B.py:157:50
(EngineCore_DP0 pid=479548) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=479548) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=479548) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=479548) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=479548) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=479548) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=479548) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=479548) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=479548) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=479548) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=479548) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=479548) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=479548) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=479548) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=479548) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=479548) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=479548) $L__tmp1:
(EngineCore_DP0 pid=479548) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=479548) 	bar.sync 	0;
(EngineCore_DP0 pid=479548) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=479548) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=479548) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=479548) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=479548) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=479548) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=479548) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=479548) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=479548) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=479548) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=479548) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=479548) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=479548) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=479548) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=479548) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=479548) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=479548) 	cvt.f32.bf16 	%r61, %rs47;
(EngineCore_DP0 pid=479548) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=479548) 	shfl.sync.bfly.b32 	%r62, %r61, 16, 31, -1;
(EngineCore_DP0 pid=479548) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=479548) 	max.f32 	%r63, %r61, %r62;
(EngineCore_DP0 pid=479548) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=479548) 	shfl.sync.bfly.b32 	%r64, %r63, 8, 31, -1;
(EngineCore_DP0 pid=479548) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=479548) 	max.f32 	%r65, %r63, %r64;
(EngineCore_DP0 pid=479548) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=479548) 	shfl.sync.bfly.b32 	%r66, %r65, 4, 31, -1;
(EngineCore_DP0 pid=479548) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=479548) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=479548) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=479548) 	shfl.sync.bfly.b32 	%r68, %r67, 2, 31, -1;
(EngineCore_DP0 pid=479548) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=479548) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=479548) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=479548) 	shfl.sync.bfly.b32 	%r70, %r69, 1, 31, -1;
(EngineCore_DP0 pid=479548) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=479548) 	max.f32 	%r54, %r69, %r70;
(EngineCore_DP0 pid=479548) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=479548) 	// begin inline asm
(EngineCore_DP0 pid=479548) 	@%p4 st.shared.b32 [ %r53 + 0 ], %r54;
(EngineCore_DP0 pid=479548) 	// end inline asm
(EngineCore_DP0 pid=479548) 	bar.sync 	0;
(EngineCore_DP0 pid=479548) 	// begin inline asm
(EngineCore_DP0 pid=479548) 	@%p5 ld.shared.b32 %r55, [ %r56 + 0 ];
(EngineCore_DP0 pid=479548) 	// end inline asm
(EngineCore_DP0 pid=479548) 	shfl.sync.bfly.b32 	%r71, %r55, 8, 31, -1;
(EngineCore_DP0 pid=479548) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=479548) 	max.f32 	%r72, %r55, %r71;
(EngineCore_DP0 pid=479548) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=479548) 	shfl.sync.bfly.b32 	%r73, %r72, 4, 31, -1;
(EngineCore_DP0 pid=479548) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=479548) 	max.f32 	%r74, %r72, %r73;
(EngineCore_DP0 pid=479548) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=479548) 	shfl.sync.bfly.b32 	%r75, %r74, 2, 31, -1;
(EngineCore_DP0 pid=479548) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=479548) 	max.f32 	%r76, %r74, %r75;
(EngineCore_DP0 pid=479548) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=479548) 	shfl.sync.bfly.b32 	%r77, %r76, 1, 31, -1;
(EngineCore_DP0 pid=479548) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=479548) 	max.f32 	%r58, %r76, %r77;
(EngineCore_DP0 pid=479548) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=479548) 	// begin inline asm
(EngineCore_DP0 pid=479548) 	@%p28 st.shared.b32 [ %r56 + 0 ], %r58;
(EngineCore_DP0 pid=479548) 	// end inline asm
(EngineCore_DP0 pid=479548) 	bar.sync 	0;
(EngineCore_DP0 pid=479548) 	ld.shared.b32 	%r78, [global_smem];
(EngineCore_DP0 pid=479548) $L__tmp2:
(EngineCore_DP0 pid=479548) 	.loc	1 157 36                        // quant_slide_tuned_Qwen2.5-7B.py:157:36
(EngineCore_DP0 pid=479548) 	max.f32 	%r144, %r144, %r78;
(EngineCore_DP0 pid=479548) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=479548) 	add.s32 	%r145, %r145, 8192;
(EngineCore_DP0 pid=479548) 	setp.lt.s32 	%p7, %r145, %r20;
(EngineCore_DP0 pid=479548) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=479548) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=479548) 	.loc	1 159 32                        // quant_slide_tuned_Qwen2.5-7B.py:159:32
(EngineCore_DP0 pid=479548) 	max.f32 	%r146, %r144, 0f2B8CBCCC;
(EngineCore_DP0 pid=479548) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=479548) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-7B.py:0:32
(EngineCore_DP0 pid=479548) 	mov.b32 	%r80, 0f43E00000;
(EngineCore_DP0 pid=479548) 	.loc	1 160 32                        // quant_slide_tuned_Qwen2.5-7B.py:160:32
(EngineCore_DP0 pid=479548) 	div.full.f32 	%r81, %r146, %r80;
(EngineCore_DP0 pid=479548) 	.loc	1 160 41                        // quant_slide_tuned_Qwen2.5-7B.py:160:41
(EngineCore_DP0 pid=479548) 	max.f32 	%r79, %r81, 0f36924925;
(EngineCore_DP0 pid=479548) 	.loc	1 162 25                        // quant_slide_tuned_Qwen2.5-7B.py:162:25
(EngineCore_DP0 pid=479548) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=479548) 	.loc	1 162 30                        // quant_slide_tuned_Qwen2.5-7B.py:162:30
(EngineCore_DP0 pid=479548) 	// begin inline asm
(EngineCore_DP0 pid=479548) 	@%p28 st.global.b32 [ %rd8 + 0 ], { %r79 };
(EngineCore_DP0 pid=479548) 	// end inline asm
(EngineCore_DP0 pid=479548) 	.loc	1 165 29                        // quant_slide_tuned_Qwen2.5-7B.py:165:29
(EngineCore_DP0 pid=479548) 	shl.b32 	%r15, %r21, 1;
(EngineCore_DP0 pid=479548) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=479548) 	setp.lt.s32 	%p9, %r15, 1;
(EngineCore_DP0 pid=479548) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=479548) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=479548) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-7B.py:0:41
(EngineCore_DP0 pid=479548) 	ld.param.b32 	%r25, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=479548) 	shr.s32 	%r26, %r25, 31;
(EngineCore_DP0 pid=479548) 	shr.u32 	%r27, %r26, 30;
(EngineCore_DP0 pid=479548) 	add.s32 	%r28, %r25, %r27;
(EngineCore_DP0 pid=479548) 	shr.s32 	%r29, %r28, 2;
(EngineCore_DP0 pid=479548) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=479548) 	mul.lo.s32 	%r30, %r29, %r1;
(EngineCore_DP0 pid=479548) 	mad.wide.s32 	%rd2, %r30, 4, %rd5;
(EngineCore_DP0 pid=479548) 	div.full.f32 	%r14, %r80, %r146;
(EngineCore_DP0 pid=479548) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=479548) 	mov.b32 	%r147, 0;
(EngineCore_DP0 pid=479548) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=479548)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=479548) 	.loc	1 168 31                        // quant_slide_tuned_Qwen2.5-7B.py:168:31
(EngineCore_DP0 pid=479548) 	add.s32 	%r93, %r16, %r147;
(EngineCore_DP0 pid=479548) 	.loc	1 169 30                        // quant_slide_tuned_Qwen2.5-7B.py:169:30
(EngineCore_DP0 pid=479548) 	add.s32 	%r94, %r147, 1;
(EngineCore_DP0 pid=479548) 	setp.lt.s32 	%p18, %r93, %r15;
(EngineCore_DP0 pid=479548) 	.loc	1 172 24                        // quant_slide_tuned_Qwen2.5-7B.py:172:24
(EngineCore_DP0 pid=479548) 	shr.u32 	%r95, %r93, 1;
(EngineCore_DP0 pid=479548) 	.loc	1 173 23                        // quant_slide_tuned_Qwen2.5-7B.py:173:23
(EngineCore_DP0 pid=479548) 	shr.u32 	%r96, %r94, 31;
(EngineCore_DP0 pid=479548) 	add.s32 	%r97, %r94, %r96;
(EngineCore_DP0 pid=479548) 	and.b32 	%r98, %r97, 2147483646;
(EngineCore_DP0 pid=479548) 	sub.s32 	%r99, %r94, %r98;
(EngineCore_DP0 pid=479548) 	.loc	1 174 22                        // quant_slide_tuned_Qwen2.5-7B.py:174:22
(EngineCore_DP0 pid=479548) 	mul.lo.s32 	%r100, %r95, 6;
(EngineCore_DP0 pid=479548) 	.loc	1 174 30                        // quant_slide_tuned_Qwen2.5-7B.py:174:30
(EngineCore_DP0 pid=479548) 	shl.b32 	%r101, %r99, 1;
(EngineCore_DP0 pid=479548) 	.loc	1 174 26                        // quant_slide_tuned_Qwen2.5-7B.py:174:26
(EngineCore_DP0 pid=479548) 	add.s32 	%r102, %r100, %r101;
(EngineCore_DP0 pid=479548) 	.loc	1 177 53                        // quant_slide_tuned_Qwen2.5-7B.py:177:53
(EngineCore_DP0 pid=479548) 	setp.lt.s32 	%p19, %r100, %r19;
(EngineCore_DP0 pid=479548) 	setp.lt.s32 	%p20, %r102, %r19;
(EngineCore_DP0 pid=479548) 	.loc	1 177 37                        // quant_slide_tuned_Qwen2.5-7B.py:177:37
(EngineCore_DP0 pid=479548) 	and.pred 	%p10, %p18, %p19;
(EngineCore_DP0 pid=479548) 	and.pred 	%p11, %p18, %p20;
(EngineCore_DP0 pid=479548) 	.loc	1 176 29                        // quant_slide_tuned_Qwen2.5-7B.py:176:29
(EngineCore_DP0 pid=479548) 	mad.wide.s32 	%rd9, %r100, 2, %rd1;
(EngineCore_DP0 pid=479548) 	mad.wide.s32 	%rd10, %r102, 2, %rd1;
(EngineCore_DP0 pid=479548) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=479548) 	.loc	1 176 21                        // quant_slide_tuned_Qwen2.5-7B.py:176:21
(EngineCore_DP0 pid=479548) 	// begin inline asm
(EngineCore_DP0 pid=479548) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=479548) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=479548) 	// end inline asm
(EngineCore_DP0 pid=479548) 	// begin inline asm
(EngineCore_DP0 pid=479548) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=479548) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=479548) 	// end inline asm
(EngineCore_DP0 pid=479548) 	.loc	1 177 79                        // quant_slide_tuned_Qwen2.5-7B.py:177:79
(EngineCore_DP0 pid=479548) 	cvt.f32.bf16 	%r103, %rs48;
(EngineCore_DP0 pid=479548) 	cvt.f32.bf16 	%r104, %rs50;
(EngineCore_DP0 pid=479548) 	.loc	1 179 48                        // quant_slide_tuned_Qwen2.5-7B.py:179:48
(EngineCore_DP0 pid=479548) 	or.b32 	%r105, %r100, 1;
(EngineCore_DP0 pid=479548) 	or.b32 	%r106, %r102, 1;
(EngineCore_DP0 pid=479548) 	.loc	1 179 53                        // quant_slide_tuned_Qwen2.5-7B.py:179:53
(EngineCore_DP0 pid=479548) 	setp.lt.s32 	%p21, %r105, %r19;
(EngineCore_DP0 pid=479548) 	setp.lt.s32 	%p22, %r106, %r19;
(EngineCore_DP0 pid=479548) 	.loc	1 179 37                        // quant_slide_tuned_Qwen2.5-7B.py:179:37
(EngineCore_DP0 pid=479548) 	and.pred 	%p12, %p18, %p21;
(EngineCore_DP0 pid=479548) 	and.pred 	%p13, %p18, %p22;
(EngineCore_DP0 pid=479548) 	.loc	1 178 39                        // quant_slide_tuned_Qwen2.5-7B.py:178:39
(EngineCore_DP0 pid=479548) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=479548) 	add.s64 	%rd12, %rd10, 2;
(EngineCore_DP0 pid=479548) 	.loc	1 178 21                        // quant_slide_tuned_Qwen2.5-7B.py:178:21
(EngineCore_DP0 pid=479548) 	// begin inline asm
(EngineCore_DP0 pid=479548) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=479548) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=479548) 	// end inline asm
(EngineCore_DP0 pid=479548) 	// begin inline asm
(EngineCore_DP0 pid=479548) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=479548) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=479548) 	// end inline asm
(EngineCore_DP0 pid=479548) 	.loc	1 179 79                        // quant_slide_tuned_Qwen2.5-7B.py:179:79
(EngineCore_DP0 pid=479548) 	cvt.f32.bf16 	%r107, %rs52;
(EngineCore_DP0 pid=479548) 	cvt.f32.bf16 	%r108, %rs54;
(EngineCore_DP0 pid=479548) 	.loc	1 181 48                        // quant_slide_tuned_Qwen2.5-7B.py:181:48
(EngineCore_DP0 pid=479548) 	add.s32 	%r109, %r100, 2;
(EngineCore_DP0 pid=479548) 	add.s32 	%r110, %r102, 2;
(EngineCore_DP0 pid=479548) 	.loc	1 181 53                        // quant_slide_tuned_Qwen2.5-7B.py:181:53
(EngineCore_DP0 pid=479548) 	setp.lt.s32 	%p23, %r109, %r19;
(EngineCore_DP0 pid=479548) 	setp.lt.s32 	%p24, %r110, %r19;
(EngineCore_DP0 pid=479548) 	.loc	1 181 37                        // quant_slide_tuned_Qwen2.5-7B.py:181:37
(EngineCore_DP0 pid=479548) 	and.pred 	%p14, %p18, %p23;
(EngineCore_DP0 pid=479548) 	and.pred 	%p15, %p18, %p24;
(EngineCore_DP0 pid=479548) 	.loc	1 180 39                        // quant_slide_tuned_Qwen2.5-7B.py:180:39
(EngineCore_DP0 pid=479548) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=479548) 	add.s64 	%rd14, %rd10, 4;
(EngineCore_DP0 pid=479548) 	.loc	1 180 21                        // quant_slide_tuned_Qwen2.5-7B.py:180:21
(EngineCore_DP0 pid=479548) 	// begin inline asm
(EngineCore_DP0 pid=479548) 	mov.u16 %rs56, %rs49;
(EngineCore_DP0 pid=479548) 	@%p14 ld.global.b16 { %rs56 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=479548) 	// end inline asm
(EngineCore_DP0 pid=479548) 	// begin inline asm
(EngineCore_DP0 pid=479548) 	mov.u16 %rs58, %rs49;
(EngineCore_DP0 pid=479548) 	@%p15 ld.global.b16 { %rs58 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=479548) 	// end inline asm
(EngineCore_DP0 pid=479548) 	.loc	1 181 79                        // quant_slide_tuned_Qwen2.5-7B.py:181:79
(EngineCore_DP0 pid=479548) 	cvt.f32.bf16 	%r111, %rs56;
(EngineCore_DP0 pid=479548) 	cvt.f32.bf16 	%r112, %rs58;
(EngineCore_DP0 pid=479548) 	.loc	1 183 48                        // quant_slide_tuned_Qwen2.5-7B.py:183:48
(EngineCore_DP0 pid=479548) 	add.s32 	%r113, %r100, 3;
(EngineCore_DP0 pid=479548) 	add.s32 	%r114, %r102, 3;
(EngineCore_DP0 pid=479548) 	.loc	1 183 53                        // quant_slide_tuned_Qwen2.5-7B.py:183:53
(EngineCore_DP0 pid=479548) 	setp.lt.s32 	%p25, %r113, %r19;
(EngineCore_DP0 pid=479548) 	setp.lt.s32 	%p26, %r114, %r19;
(EngineCore_DP0 pid=479548) 	.loc	1 183 37                        // quant_slide_tuned_Qwen2.5-7B.py:183:37
(EngineCore_DP0 pid=479548) 	and.pred 	%p16, %p18, %p25;
(EngineCore_DP0 pid=479548) 	and.pred 	%p17, %p18, %p26;
(EngineCore_DP0 pid=479548) 	.loc	1 182 39                        // quant_slide_tuned_Qwen2.5-7B.py:182:39
(EngineCore_DP0 pid=479548) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=479548) 	add.s64 	%rd16, %rd10, 6;
(EngineCore_DP0 pid=479548) 	.loc	1 182 21                        // quant_slide_tuned_Qwen2.5-7B.py:182:21
(EngineCore_DP0 pid=479548) 	// begin inline asm
(EngineCore_DP0 pid=479548) 	mov.u16 %rs60, %rs49;
(EngineCore_DP0 pid=479548) 	@%p16 ld.global.b16 { %rs60 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=479548) 	// end inline asm
(EngineCore_DP0 pid=479548) 	// begin inline asm
(EngineCore_DP0 pid=479548) 	mov.u16 %rs62, %rs49;
(EngineCore_DP0 pid=479548) 	@%p17 ld.global.b16 { %rs62 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=479548) 	// end inline asm
(EngineCore_DP0 pid=479548) 	.loc	1 183 79                        // quant_slide_tuned_Qwen2.5-7B.py:183:79
(EngineCore_DP0 pid=479548) 	cvt.f32.bf16 	%r115, %rs60;
(EngineCore_DP0 pid=479548) 	cvt.f32.bf16 	%r116, %rs62;
(EngineCore_DP0 pid=479548) 	.loc	1 185 27                        // quant_slide_tuned_Qwen2.5-7B.py:185:27
(EngineCore_DP0 pid=479548) 	mul.f32 	%r117, %r14, %r103;
(EngineCore_DP0 pid=479548) 	mul.f32 	%r118, %r14, %r104;
(EngineCore_DP0 pid=479548) 	mov.b32 	%r119, 0f43E00000;
(EngineCore_DP0 pid=479548) 	.loc	1 185 48                        // quant_slide_tuned_Qwen2.5-7B.py:185:48
(EngineCore_DP0 pid=479548) 	min.xorsign.abs.f32 	%r83, %r117, %r119;
(EngineCore_DP0 pid=479548) 	min.xorsign.abs.f32 	%r84, %r118, %r119;
(EngineCore_DP0 pid=479548) 	.loc	1 185 60                        // quant_slide_tuned_Qwen2.5-7B.py:185:60
(EngineCore_DP0 pid=479548) 	// begin inline asm
(EngineCore_DP0 pid=479548) 	cvt.rn.satfinite.e4m3x2.f32  %rs64, %r84, %r83; 
(EngineCore_DP0 pid=479548) 
(EngineCore_DP0 pid=479548) 	// end inline asm
(EngineCore_DP0 pid=479548) 	shr.u16 	%rs68, %rs64, 8;
(EngineCore_DP0 pid=479548) 	.loc	1 186 27                        // quant_slide_tuned_Qwen2.5-7B.py:186:27
(EngineCore_DP0 pid=479548) 	mul.f32 	%r120, %r14, %r107;
(EngineCore_DP0 pid=479548) 	mul.f32 	%r121, %r14, %r108;
(EngineCore_DP0 pid=479548) 	.loc	1 186 48                        // quant_slide_tuned_Qwen2.5-7B.py:186:48
(EngineCore_DP0 pid=479548) 	min.xorsign.abs.f32 	%r85, %r120, %r119;
(EngineCore_DP0 pid=479548) 	min.xorsign.abs.f32 	%r86, %r121, %r119;
(EngineCore_DP0 pid=479548) 	.loc	1 186 60                        // quant_slide_tuned_Qwen2.5-7B.py:186:60
(EngineCore_DP0 pid=479548) 	// begin inline asm
(EngineCore_DP0 pid=479548) 	cvt.rn.satfinite.e4m3x2.f32  %rs65, %r86, %r85; 
(EngineCore_DP0 pid=479548) 
(EngineCore_DP0 pid=479548) 	// end inline asm
(EngineCore_DP0 pid=479548) 	shr.u16 	%rs69, %rs65, 8;
(EngineCore_DP0 pid=479548) 	.loc	1 187 27                        // quant_slide_tuned_Qwen2.5-7B.py:187:27
(EngineCore_DP0 pid=479548) 	mul.f32 	%r122, %r14, %r111;
(EngineCore_DP0 pid=479548) 	mul.f32 	%r123, %r14, %r112;
(EngineCore_DP0 pid=479548) 	.loc	1 187 48                        // quant_slide_tuned_Qwen2.5-7B.py:187:48
(EngineCore_DP0 pid=479548) 	min.xorsign.abs.f32 	%r87, %r122, %r119;
(EngineCore_DP0 pid=479548) 	min.xorsign.abs.f32 	%r88, %r123, %r119;
(EngineCore_DP0 pid=479548) 	.loc	1 187 60                        // quant_slide_tuned_Qwen2.5-7B.py:187:60
(EngineCore_DP0 pid=479548) 	// begin inline asm
(EngineCore_DP0 pid=479548) 	cvt.rn.satfinite.e4m3x2.f32  %rs66, %r88, %r87; 
(EngineCore_DP0 pid=479548) 
(EngineCore_DP0 pid=479548) 	// end inline asm
(EngineCore_DP0 pid=479548) 	shr.u16 	%rs70, %rs66, 8;
(EngineCore_DP0 pid=479548) 	.loc	1 188 27                        // quant_slide_tuned_Qwen2.5-7B.py:188:27
(EngineCore_DP0 pid=479548) 	mul.f32 	%r124, %r14, %r115;
(EngineCore_DP0 pid=479548) 	mul.f32 	%r125, %r14, %r116;
(EngineCore_DP0 pid=479548) 	.loc	1 188 48                        // quant_slide_tuned_Qwen2.5-7B.py:188:48
(EngineCore_DP0 pid=479548) 	min.xorsign.abs.f32 	%r89, %r124, %r119;
(EngineCore_DP0 pid=479548) 	min.xorsign.abs.f32 	%r90, %r125, %r119;
(EngineCore_DP0 pid=479548) 	.loc	1 188 60                        // quant_slide_tuned_Qwen2.5-7B.py:188:60
(EngineCore_DP0 pid=479548) 	// begin inline asm
(EngineCore_DP0 pid=479548) 	cvt.rn.satfinite.e4m3x2.f32  %rs67, %r90, %r89; 
(EngineCore_DP0 pid=479548) 
(EngineCore_DP0 pid=479548) 	// end inline asm
(EngineCore_DP0 pid=479548) 	shr.u16 	%rs71, %rs67, 8;
(EngineCore_DP0 pid=479548) 	.loc	1 190 45                        // quant_slide_tuned_Qwen2.5-7B.py:190:45
(EngineCore_DP0 pid=479548) 	cvt.u32.u16 	%r126, %rs64;
(EngineCore_DP0 pid=479548) 	and.b32 	%r127, %r126, 255;
(EngineCore_DP0 pid=479548) 	cvt.u32.u16 	%r128, %rs68;
(EngineCore_DP0 pid=479548) 	.loc	1 192 45                        // quant_slide_tuned_Qwen2.5-7B.py:192:45
(EngineCore_DP0 pid=479548) 	cvt.u32.u16 	%r129, %rs66;
(EngineCore_DP0 pid=479548) 	and.b32 	%r130, %r129, 255;
(EngineCore_DP0 pid=479548) 	cvt.u32.u16 	%r131, %rs70;
(EngineCore_DP0 pid=479548) 	.loc	1 193 45                        // quant_slide_tuned_Qwen2.5-7B.py:193:45
(EngineCore_DP0 pid=479548) 	cvt.u32.u16 	%r132, %rs67;
(EngineCore_DP0 pid=479548) 	cvt.u32.u16 	%r133, %rs71;
(EngineCore_DP0 pid=479548) 	.loc	1 195 30                        // quant_slide_tuned_Qwen2.5-7B.py:195:30
(EngineCore_DP0 pid=479548) 	and.b16 	%rs72, %rs65, 255;
(EngineCore_DP0 pid=479548) 	mul.wide.u16 	%r134, %rs72, 256;
(EngineCore_DP0 pid=479548) 	mul.wide.u16 	%r135, %rs69, 256;
(EngineCore_DP0 pid=479548) 	.loc	1 195 24                        // quant_slide_tuned_Qwen2.5-7B.py:195:24
(EngineCore_DP0 pid=479548) 	or.b32 	%r136, %r134, %r127;
(EngineCore_DP0 pid=479548) 	or.b32 	%r137, %r135, %r128;
(EngineCore_DP0 pid=479548) 	.loc	1 195 42                        // quant_slide_tuned_Qwen2.5-7B.py:195:42
(EngineCore_DP0 pid=479548) 	shl.b32 	%r138, %r130, 16;
(EngineCore_DP0 pid=479548) 	shl.b32 	%r139, %r131, 16;
(EngineCore_DP0 pid=479548) 	.loc	1 195 36                        // quant_slide_tuned_Qwen2.5-7B.py:195:36
(EngineCore_DP0 pid=479548) 	or.b32 	%r140, %r136, %r138;
(EngineCore_DP0 pid=479548) 	or.b32 	%r141, %r137, %r139;
(EngineCore_DP0 pid=479548) 	.loc	1 195 55                        // quant_slide_tuned_Qwen2.5-7B.py:195:55
(EngineCore_DP0 pid=479548) 	shl.b32 	%r142, %r132, 24;
(EngineCore_DP0 pid=479548) 	shl.b32 	%r143, %r133, 24;
(EngineCore_DP0 pid=479548) 	.loc	1 195 49                        // quant_slide_tuned_Qwen2.5-7B.py:195:49
(EngineCore_DP0 pid=479548) 	or.b32 	%r91, %r140, %r142;
(EngineCore_DP0 pid=479548) 	or.b32 	%r92, %r141, %r143;
(EngineCore_DP0 pid=479548) 	.loc	1 196 29                        // quant_slide_tuned_Qwen2.5-7B.py:196:29
(EngineCore_DP0 pid=479548) 	mad.wide.s32 	%rd17, %r93, 4, %rd2;
(EngineCore_DP0 pid=479548) 	.loc	1 196 39                        // quant_slide_tuned_Qwen2.5-7B.py:196:39
(EngineCore_DP0 pid=479548) 	// begin inline asm
(EngineCore_DP0 pid=479548) 	@%p18 st.global.v2.b32 [ %rd17 + 0 ], { %r91, %r92 };
(EngineCore_DP0 pid=479548) 	// end inline asm
(EngineCore_DP0 pid=479548) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=479548) 	add.s32 	%r147, %r147, 1024;
(EngineCore_DP0 pid=479548) 	setp.lt.s32 	%p27, %r147, %r15;
(EngineCore_DP0 pid=479548) 	@%p27 bra 	$L__BB0_6;
(EngineCore_DP0 pid=479548) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=479548) 	.loc	1 167 4                         // quant_slide_tuned_Qwen2.5-7B.py:167:4
(EngineCore_DP0 pid=479548) 	ret;
(EngineCore_DP0 pid=479548) $L__tmp3:
(EngineCore_DP0 pid=479548) $L__func_end0:
(EngineCore_DP0 pid=479548)                                         // -- End function
(EngineCore_DP0 pid=479548) }
(EngineCore_DP0 pid=479548) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py"
(EngineCore_DP0 pid=479548) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=479548) 	.section	.debug_abbrev
(EngineCore_DP0 pid=479548) 	{
(EngineCore_DP0 pid=479548) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=479548) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=479548) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=479548) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=479548) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=479548) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=479548) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=479548) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=479548) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=479548) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=479548) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=479548) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=479548) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=479548) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=479548) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=479548) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=479548) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=479548) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=479548) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=479548) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=479548) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=479548) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=479548) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=479548) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=479548) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=479548) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=479548) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=479548) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=479548) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=479548) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=479548) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=479548) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=479548) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=479548) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=479548) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=479548) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=479548) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=479548) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=479548) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=479548) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=479548) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=479548) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=479548) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=479548) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=479548) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=479548) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=479548) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=479548) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=479548) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=479548) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=479548) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=479548) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=479548) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=479548) 	}
(EngineCore_DP0 pid=479548) 	.section	.debug_info
(EngineCore_DP0 pid=479548) 	{
(EngineCore_DP0 pid=479548) .b32 221                                // Length of Unit
(EngineCore_DP0 pid=479548) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=479548) .b8 0
(EngineCore_DP0 pid=479548) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=479548) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=479548) .b8 1                                   // Abbrev [1] 0xb:0xd6 DW_TAG_compile_unit
(EngineCore_DP0 pid=479548) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=479548) .b8 114
(EngineCore_DP0 pid=479548) .b8 105
(EngineCore_DP0 pid=479548) .b8 116
(EngineCore_DP0 pid=479548) .b8 111
(EngineCore_DP0 pid=479548) .b8 110
(EngineCore_DP0 pid=479548) .b8 0
(EngineCore_DP0 pid=479548) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=479548) .b8 0
(EngineCore_DP0 pid=479548) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=479548) .b8 117
(EngineCore_DP0 pid=479548) .b8 97
(EngineCore_DP0 pid=479548) .b8 110
(EngineCore_DP0 pid=479548) .b8 116
(EngineCore_DP0 pid=479548) .b8 95
(EngineCore_DP0 pid=479548) .b8 115
(EngineCore_DP0 pid=479548) .b8 108
(EngineCore_DP0 pid=479548) .b8 105
(EngineCore_DP0 pid=479548) .b8 100
(EngineCore_DP0 pid=479548) .b8 101
(EngineCore_DP0 pid=479548) .b8 95
(EngineCore_DP0 pid=479548) .b8 116
(EngineCore_DP0 pid=479548) .b8 117
(EngineCore_DP0 pid=479548) .b8 110
(EngineCore_DP0 pid=479548) .b8 101
(EngineCore_DP0 pid=479548) .b8 100
(EngineCore_DP0 pid=479548) .b8 95
(EngineCore_DP0 pid=479548) .b8 81
(EngineCore_DP0 pid=479548) .b8 119
(EngineCore_DP0 pid=479548) .b8 101
(EngineCore_DP0 pid=479548) .b8 110
(EngineCore_DP0 pid=479548) .b8 50
(EngineCore_DP0 pid=479548) .b8 46
(EngineCore_DP0 pid=479548) .b8 53
(EngineCore_DP0 pid=479548) .b8 45
(EngineCore_DP0 pid=479548) .b8 55
(EngineCore_DP0 pid=479548) .b8 66
(EngineCore_DP0 pid=479548) .b8 46
(EngineCore_DP0 pid=479548) .b8 112
(EngineCore_DP0 pid=479548) .b8 121
(EngineCore_DP0 pid=479548) .b8 0
(EngineCore_DP0 pid=479548) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=479548) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=479548) .b8 114
(EngineCore_DP0 pid=479548) .b8 111
(EngineCore_DP0 pid=479548) .b8 111
(EngineCore_DP0 pid=479548) .b8 116
(EngineCore_DP0 pid=479548) .b8 47
(EngineCore_DP0 pid=479548) .b8 118
(EngineCore_DP0 pid=479548) .b8 108
(EngineCore_DP0 pid=479548) .b8 108
(EngineCore_DP0 pid=479548) .b8 109
(EngineCore_DP0 pid=479548) .b8 98
(EngineCore_DP0 pid=479548) .b8 101
(EngineCore_DP0 pid=479548) .b8 110
(EngineCore_DP0 pid=479548) .b8 99
(EngineCore_DP0 pid=479548) .b8 104
(EngineCore_DP0 pid=479548) .b8 47
(EngineCore_DP0 pid=479548) .b8 115
(EngineCore_DP0 pid=479548) .b8 108
(EngineCore_DP0 pid=479548) .b8 105
(EngineCore_DP0 pid=479548) .b8 100
(EngineCore_DP0 pid=479548) .b8 101
(EngineCore_DP0 pid=479548) .b8 115
(EngineCore_DP0 pid=479548) .b8 112
(EngineCore_DP0 pid=479548) .b8 97
(EngineCore_DP0 pid=479548) .b8 114
(EngineCore_DP0 pid=479548) .b8 115
(EngineCore_DP0 pid=479548) .b8 101
(EngineCore_DP0 pid=479548) .b8 47
(EngineCore_DP0 pid=479548) .b8 99
(EngineCore_DP0 pid=479548) .b8 115
(EngineCore_DP0 pid=479548) .b8 114
(EngineCore_DP0 pid=479548) .b8 99
(EngineCore_DP0 pid=479548) .b8 47
(EngineCore_DP0 pid=479548) .b8 102
(EngineCore_DP0 pid=479548) .b8 117
(EngineCore_DP0 pid=479548) .b8 115
(EngineCore_DP0 pid=479548) .b8 101
(EngineCore_DP0 pid=479548) .b8 100
(EngineCore_DP0 pid=479548) .b8 95
(EngineCore_DP0 pid=479548) .b8 113
(EngineCore_DP0 pid=479548) .b8 117
(EngineCore_DP0 pid=479548) .b8 97
(EngineCore_DP0 pid=479548) .b8 110
(EngineCore_DP0 pid=479548) .b8 116
(EngineCore_DP0 pid=479548) .b8 95
(EngineCore_DP0 pid=479548) .b8 115
(EngineCore_DP0 pid=479548) .b8 108
(EngineCore_DP0 pid=479548) .b8 105
(EngineCore_DP0 pid=479548) .b8 100
(EngineCore_DP0 pid=479548) .b8 101
(EngineCore_DP0 pid=479548) .b8 95
(EngineCore_DP0 pid=479548) .b8 116
(EngineCore_DP0 pid=479548) .b8 114
(EngineCore_DP0 pid=479548) .b8 105
(EngineCore_DP0 pid=479548) .b8 116
(EngineCore_DP0 pid=479548) .b8 111
(EngineCore_DP0 pid=479548) .b8 110
(EngineCore_DP0 pid=479548) .b8 47
(EngineCore_DP0 pid=479548) .b8 98
(EngineCore_DP0 pid=479548) .b8 117
(EngineCore_DP0 pid=479548) .b8 105
(EngineCore_DP0 pid=479548) .b8 108
(EngineCore_DP0 pid=479548) .b8 100
(EngineCore_DP0 pid=479548) .b8 47
(EngineCore_DP0 pid=479548) .b8 71
(EngineCore_DP0 pid=479548) .b8 66
(EngineCore_DP0 pid=479548) .b8 49
(EngineCore_DP0 pid=479548) .b8 48
(EngineCore_DP0 pid=479548) .b8 95
(EngineCore_DP0 pid=479548) .b8 99
(EngineCore_DP0 pid=479548) .b8 99
(EngineCore_DP0 pid=479548) .b8 49
(EngineCore_DP0 pid=479548) .b8 50
(EngineCore_DP0 pid=479548) .b8 49
(EngineCore_DP0 pid=479548) .b8 95
(EngineCore_DP0 pid=479548) .b8 112
(EngineCore_DP0 pid=479548) .b8 121
(EngineCore_DP0 pid=479548) .b8 51
(EngineCore_DP0 pid=479548) .b8 49
(EngineCore_DP0 pid=479548) .b8 50
(EngineCore_DP0 pid=479548) .b8 95
(EngineCore_DP0 pid=479548) .b8 99
(EngineCore_DP0 pid=479548) .b8 117
(EngineCore_DP0 pid=479548) .b8 49
(EngineCore_DP0 pid=479548) .b8 50
(EngineCore_DP0 pid=479548) .b8 57
(EngineCore_DP0 pid=479548) .b8 95
(EngineCore_DP0 pid=479548) .b8 97
(EngineCore_DP0 pid=479548) .b8 97
(EngineCore_DP0 pid=479548) .b8 114
(EngineCore_DP0 pid=479548) .b8 99
(EngineCore_DP0 pid=479548) .b8 104
(EngineCore_DP0 pid=479548) .b8 54
(EngineCore_DP0 pid=479548) .b8 52
(EngineCore_DP0 pid=479548) .b8 0
(EngineCore_DP0 pid=479548) .b8 2                                   // Abbrev [2] 0x98:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=479548) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=479548) .b8 113
(EngineCore_DP0 pid=479548) .b8 117
(EngineCore_DP0 pid=479548) .b8 97
(EngineCore_DP0 pid=479548) .b8 110
(EngineCore_DP0 pid=479548) .b8 116
(EngineCore_DP0 pid=479548) .b8 95
(EngineCore_DP0 pid=479548) .b8 115
(EngineCore_DP0 pid=479548) .b8 108
(EngineCore_DP0 pid=479548) .b8 105
(EngineCore_DP0 pid=479548) .b8 100
(EngineCore_DP0 pid=479548) .b8 101
(EngineCore_DP0 pid=479548) .b8 95
(EngineCore_DP0 pid=479548) .b8 102
(EngineCore_DP0 pid=479548) .b8 112
(EngineCore_DP0 pid=479548) .b8 56
(EngineCore_DP0 pid=479548) .b8 95
(EngineCore_DP0 pid=479548) .b8 107
(EngineCore_DP0 pid=479548) .b8 101
(EngineCore_DP0 pid=479548) .b8 114
(EngineCore_DP0 pid=479548) .b8 110
(EngineCore_DP0 pid=479548) .b8 101
(EngineCore_DP0 pid=479548) .b8 108
(EngineCore_DP0 pid=479548) .b8 0
(EngineCore_DP0 pid=479548) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=479548) .b8 3                                   // Abbrev [3] 0xb2:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=479548) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=479548) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=479548) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=479548) .b8 4                                   // Abbrev [4] 0xc7:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=479548) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=479548) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=479548) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=479548) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=479548) .b8 157                                 // DW_AT_call_line
(EngineCore_DP0 pid=479548) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=479548) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=479548) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=479548) 	}
(EngineCore_DP0 pid=479548) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=479548) 
(EngineCore_DP0 pid=479548) ================================================================
(EngineCore_DP0 pid=479548) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=479548) 
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmph3g637ba.ptx', '-o', '/tmp/tmph3g637ba.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866] 
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866] 
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866] 
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmph3g637ba.ptx -o /tmp/tmph3g637ba.ptx.o
(EngineCore_DP0 pid=479548) ERROR 01-25 21:30:57 [core.py:866] 

STDERR:
[2026-01-25 21:29:54] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:29:54] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:29:54] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:29:54] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:29:54] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:29:54] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:29:54] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:29:54] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:29:54] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:29:54] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:29:54] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:29:54] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:29:54] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:29:54] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:29:57] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:29:57] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:29:57] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:29:57] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:29:57] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:29:57] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:29:57] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:29:57] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:29:57] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:29:57] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:29:57] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:29:57] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:29:57] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:29:57] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=479548) [2026-01-25 21:29:58] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=479548) [2026-01-25 21:29:58] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=479548) [2026-01-25 21:29:58] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=479548) [2026-01-25 21:29:58] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=479548) [2026-01-25 21:29:58] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=479548) [2026-01-25 21:29:58] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=479548) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=479548) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:23<00:23, 23.62s/it]
(EngineCore_DP0 pid=479548) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:56<00:00, 29.32s/it]
(EngineCore_DP0 pid=479548) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:56<00:00, 28.47s/it]
(EngineCore_DP0 pid=479548) 
(EngineCore_DP0 pid=479548) [2026-01-25 21:30:56] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=479548) [2026-01-25 21:30:56] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 13860864 bytes
(EngineCore_DP0 pid=479548) [2026-01-25 21:30:56] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=479548) [2026-01-25 21:30:56] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10780672 bytes
(EngineCore_DP0 pid=479548) [2026-01-25 21:30:56] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=479548) [2026-01-25 21:30:56] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 113967104 bytes
(EngineCore_DP0 pid=479548) [2026-01-25 21:30:56] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=479548) [2026-01-25 21:30:56] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 56655872 bytes
(EngineCore_DP0 pid=479548) Process EngineCore_DP0:
(EngineCore_DP0 pid=479548) Traceback (most recent call last):
(EngineCore_DP0 pid=479548)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=479548)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=479548)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=479548)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=479548) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmph3g637ba.ptx', '-o', '/tmp/tmph3g637ba.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=479548) 
(EngineCore_DP0 pid=479548) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=479548) 
(EngineCore_DP0 pid=479548) Traceback (most recent call last):
(EngineCore_DP0 pid=479548)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=479548)     self.run()
(EngineCore_DP0 pid=479548)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=479548)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=479548)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=479548)     raise e
(EngineCore_DP0 pid=479548)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=479548)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=479548)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=479548)     super().__init__(
(EngineCore_DP0 pid=479548)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=479548)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=479548)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=479548)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=479548)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=479548)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=479548)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=479548)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=479548)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=479548)     return func(*args, **kwargs)
(EngineCore_DP0 pid=479548)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=479548)     return func(*args, **kwargs)
(EngineCore_DP0 pid=479548)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=479548)     self.model_runner.profile_run()
(EngineCore_DP0 pid=479548)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=479548)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=479548)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=479548)     return func(*args, **kwargs)
(EngineCore_DP0 pid=479548)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=479548)     outputs = self.model(
(EngineCore_DP0 pid=479548)               ^^^^^^^^^^^
(EngineCore_DP0 pid=479548)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=479548)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=479548)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=479548)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=479548)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=479548)     hidden_states = self.model(
(EngineCore_DP0 pid=479548)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=479548)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=479548)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=479548)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=479548)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=479548)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=479548)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=479548)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=479548)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=479548)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=479548)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=479548)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=479548)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=479548)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=479548)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=479548)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=479548)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=479548)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=479548)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=479548)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=479548)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=479548)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=479548)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=479548)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=479548)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=479548)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=479548)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=479548)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=479548)     return self._linear_fn(
(EngineCore_DP0 pid=479548)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=479548)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=479548)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=479548)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=479548)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=479548)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=479548)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=479548)     return fn(input, L)
(EngineCore_DP0 pid=479548)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=479548)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=479548)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=479548)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=479548)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=479548)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=479548)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=479548)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=479548)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=479548)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=479548)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=479548)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=479548)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=479548)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=479548)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=479548)     raise PTXASError(error)
(EngineCore_DP0 pid=479548) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=479548) `ptxas` stderr:
(EngineCore_DP0 pid=479548) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=479548) 
(EngineCore_DP0 pid=479548) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmph3g637ba.ptx -o /tmp/tmph3g637ba.ptx.o
(EngineCore_DP0 pid=479548) 
[rank0]:[W125 21:30:57.088354680 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=8192

========== M=16384 ==========
Time: 2026-01-25 21:30:59
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Qwen2.5-7B-FP8_M16384.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:31:10 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 21:31:10 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=480792) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=480792) 
(EngineCore_DP0 pid=480792) 
(EngineCore_DP0 pid=480792) ================================================================
(EngineCore_DP0 pid=480792) Internal Triton PTX codegen error
(EngineCore_DP0 pid=480792) `ptxas` stderr:
(EngineCore_DP0 pid=480792) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=480792) 
(EngineCore_DP0 pid=480792) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp81em_5bj.ptx -o /tmp/tmp81em_5bj.ptx.o
(EngineCore_DP0 pid=480792) 
(EngineCore_DP0 pid=480792) 
(EngineCore_DP0 pid=480792) //
(EngineCore_DP0 pid=480792) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=480792) //
(EngineCore_DP0 pid=480792) 
(EngineCore_DP0 pid=480792) .version 8.7
(EngineCore_DP0 pid=480792) .target sm_121a
(EngineCore_DP0 pid=480792) .address_size 64
(EngineCore_DP0 pid=480792) 
(EngineCore_DP0 pid=480792) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=480792) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=480792)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=480792) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=480792) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=480792) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=480792) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=480792) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=480792) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=480792) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=480792) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=480792) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=480792) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=480792) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=480792) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=480792) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=480792) )
(EngineCore_DP0 pid=480792) .reqntid 512
(EngineCore_DP0 pid=480792) {
(EngineCore_DP0 pid=480792) 	.reg .pred 	%p<29>;
(EngineCore_DP0 pid=480792) 	.reg .b16 	%rs<73>;
(EngineCore_DP0 pid=480792) 	.reg .b32 	%r<148>;
(EngineCore_DP0 pid=480792) 	.reg .b64 	%rd<18>;
(EngineCore_DP0 pid=480792) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=480792) $L__func_begin0:
(EngineCore_DP0 pid=480792) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=480792) 
(EngineCore_DP0 pid=480792) // %bb.0:
(EngineCore_DP0 pid=480792) 	ld.param.b32 	%r21, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=480792) 	ld.param.b32 	%r20, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=480792) 	ld.param.b32 	%r19, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=480792) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=480792) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=480792) $L__tmp0:
(EngineCore_DP0 pid=480792) 	.loc	1 143 24                        // quant_slide_tuned_Qwen2.5-7B.py:143:24
(EngineCore_DP0 pid=480792) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=480792) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=480792) 	.loc	1 148 26                        // quant_slide_tuned_Qwen2.5-7B.py:148:26
(EngineCore_DP0 pid=480792) 	mul.lo.s32 	%r24, %r23, %r1;
(EngineCore_DP0 pid=480792) 	.loc	1 148 20                        // quant_slide_tuned_Qwen2.5-7B.py:148:20
(EngineCore_DP0 pid=480792) 	mad.wide.s32 	%rd1, %r24, 2, %rd4;
(EngineCore_DP0 pid=480792) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=480792) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=480792) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=480792) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=480792) 	setp.lt.s32 	%p1, %r20, 1;
(EngineCore_DP0 pid=480792) 	mov.b32 	%r146, 0f2B8CBCCC;
(EngineCore_DP0 pid=480792) 	setp.eq.b32 	%p28, %r2, 0;
(EngineCore_DP0 pid=480792) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=480792) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=480792) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=480792) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=480792) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=480792) 	shr.u32 	%r33, %r2, 3;
(EngineCore_DP0 pid=480792) 	and.b32 	%r34, %r33, 60;
(EngineCore_DP0 pid=480792) 	mov.b32 	%r35, global_smem;
(EngineCore_DP0 pid=480792) 	add.s32 	%r53, %r35, %r34;
(EngineCore_DP0 pid=480792) 	shl.b32 	%r36, %r2, 2;
(EngineCore_DP0 pid=480792) 	add.s32 	%r56, %r35, %r36;
(EngineCore_DP0 pid=480792) 	mov.b32 	%r41, 0;
(EngineCore_DP0 pid=480792) 	mov.b32 	%r144, 0f00000000;
(EngineCore_DP0 pid=480792) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=480792) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=480792) 	mov.b32 	%r145, %r41;
(EngineCore_DP0 pid=480792) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=480792) 	.loc	1 154 19                        // quant_slide_tuned_Qwen2.5-7B.py:154:19
(EngineCore_DP0 pid=480792) 	add.s32 	%r59, %r4, %r145;
(EngineCore_DP0 pid=480792) 	.loc	1 155 22                        // quant_slide_tuned_Qwen2.5-7B.py:155:22
(EngineCore_DP0 pid=480792) 	add.s32 	%r60, %r59, 4096;
(EngineCore_DP0 pid=480792) 	setp.lt.s32 	%p2, %r59, %r19;
(EngineCore_DP0 pid=480792) 	setp.lt.s32 	%p3, %r60, %r19;
(EngineCore_DP0 pid=480792) 	.loc	1 156 29                        // quant_slide_tuned_Qwen2.5-7B.py:156:29
(EngineCore_DP0 pid=480792) 	mad.wide.s32 	%rd6, %r59, 2, %rd1;
(EngineCore_DP0 pid=480792) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=480792) 	.loc	1 156 21                        // quant_slide_tuned_Qwen2.5-7B.py:156:21
(EngineCore_DP0 pid=480792) 	// begin inline asm
(EngineCore_DP0 pid=480792) 	mov.u32 %r37, %r41;
(EngineCore_DP0 pid=480792) 	mov.u32 %r38, %r41;
(EngineCore_DP0 pid=480792) 	mov.u32 %r39, %r41;
(EngineCore_DP0 pid=480792) 	mov.u32 %r40, %r41;
(EngineCore_DP0 pid=480792) 	@%p2 ld.global.v4.b32 { %r37, %r38, %r39, %r40 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=480792) 	// end inline asm
(EngineCore_DP0 pid=480792) 	mov.b32 	{%rs1, %rs2}, %r37;
(EngineCore_DP0 pid=480792) 	mov.b32 	{%rs3, %rs4}, %r38;
(EngineCore_DP0 pid=480792) 	mov.b32 	{%rs5, %rs6}, %r39;
(EngineCore_DP0 pid=480792) 	mov.b32 	{%rs7, %rs8}, %r40;
(EngineCore_DP0 pid=480792) 	// begin inline asm
(EngineCore_DP0 pid=480792) 	mov.u32 %r45, %r41;
(EngineCore_DP0 pid=480792) 	mov.u32 %r46, %r41;
(EngineCore_DP0 pid=480792) 	mov.u32 %r47, %r41;
(EngineCore_DP0 pid=480792) 	mov.u32 %r48, %r41;
(EngineCore_DP0 pid=480792) 	@%p3 ld.global.v4.b32 { %r45, %r46, %r47, %r48 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=480792) 	// end inline asm
(EngineCore_DP0 pid=480792) 	mov.b32 	{%rs9, %rs10}, %r45;
(EngineCore_DP0 pid=480792) 	mov.b32 	{%rs11, %rs12}, %r46;
(EngineCore_DP0 pid=480792) 	mov.b32 	{%rs13, %rs14}, %r47;
(EngineCore_DP0 pid=480792) 	mov.b32 	{%rs15, %rs16}, %r48;
(EngineCore_DP0 pid=480792) 	.loc	1 157 50                        // quant_slide_tuned_Qwen2.5-7B.py:157:50
(EngineCore_DP0 pid=480792) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=480792) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=480792) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=480792) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=480792) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=480792) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=480792) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=480792) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=480792) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=480792) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=480792) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=480792) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=480792) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=480792) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=480792) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=480792) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=480792) $L__tmp1:
(EngineCore_DP0 pid=480792) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=480792) 	bar.sync 	0;
(EngineCore_DP0 pid=480792) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=480792) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=480792) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=480792) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=480792) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=480792) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=480792) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=480792) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=480792) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=480792) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=480792) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=480792) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=480792) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=480792) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=480792) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=480792) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=480792) 	cvt.f32.bf16 	%r61, %rs47;
(EngineCore_DP0 pid=480792) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=480792) 	shfl.sync.bfly.b32 	%r62, %r61, 16, 31, -1;
(EngineCore_DP0 pid=480792) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=480792) 	max.f32 	%r63, %r61, %r62;
(EngineCore_DP0 pid=480792) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=480792) 	shfl.sync.bfly.b32 	%r64, %r63, 8, 31, -1;
(EngineCore_DP0 pid=480792) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=480792) 	max.f32 	%r65, %r63, %r64;
(EngineCore_DP0 pid=480792) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=480792) 	shfl.sync.bfly.b32 	%r66, %r65, 4, 31, -1;
(EngineCore_DP0 pid=480792) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=480792) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=480792) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=480792) 	shfl.sync.bfly.b32 	%r68, %r67, 2, 31, -1;
(EngineCore_DP0 pid=480792) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=480792) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=480792) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=480792) 	shfl.sync.bfly.b32 	%r70, %r69, 1, 31, -1;
(EngineCore_DP0 pid=480792) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=480792) 	max.f32 	%r54, %r69, %r70;
(EngineCore_DP0 pid=480792) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=480792) 	// begin inline asm
(EngineCore_DP0 pid=480792) 	@%p4 st.shared.b32 [ %r53 + 0 ], %r54;
(EngineCore_DP0 pid=480792) 	// end inline asm
(EngineCore_DP0 pid=480792) 	bar.sync 	0;
(EngineCore_DP0 pid=480792) 	// begin inline asm
(EngineCore_DP0 pid=480792) 	@%p5 ld.shared.b32 %r55, [ %r56 + 0 ];
(EngineCore_DP0 pid=480792) 	// end inline asm
(EngineCore_DP0 pid=480792) 	shfl.sync.bfly.b32 	%r71, %r55, 8, 31, -1;
(EngineCore_DP0 pid=480792) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=480792) 	max.f32 	%r72, %r55, %r71;
(EngineCore_DP0 pid=480792) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=480792) 	shfl.sync.bfly.b32 	%r73, %r72, 4, 31, -1;
(EngineCore_DP0 pid=480792) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=480792) 	max.f32 	%r74, %r72, %r73;
(EngineCore_DP0 pid=480792) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=480792) 	shfl.sync.bfly.b32 	%r75, %r74, 2, 31, -1;
(EngineCore_DP0 pid=480792) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=480792) 	max.f32 	%r76, %r74, %r75;
(EngineCore_DP0 pid=480792) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=480792) 	shfl.sync.bfly.b32 	%r77, %r76, 1, 31, -1;
(EngineCore_DP0 pid=480792) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=480792) 	max.f32 	%r58, %r76, %r77;
(EngineCore_DP0 pid=480792) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=480792) 	// begin inline asm
(EngineCore_DP0 pid=480792) 	@%p28 st.shared.b32 [ %r56 + 0 ], %r58;
(EngineCore_DP0 pid=480792) 	// end inline asm
(EngineCore_DP0 pid=480792) 	bar.sync 	0;
(EngineCore_DP0 pid=480792) 	ld.shared.b32 	%r78, [global_smem];
(EngineCore_DP0 pid=480792) $L__tmp2:
(EngineCore_DP0 pid=480792) 	.loc	1 157 36                        // quant_slide_tuned_Qwen2.5-7B.py:157:36
(EngineCore_DP0 pid=480792) 	max.f32 	%r144, %r144, %r78;
(EngineCore_DP0 pid=480792) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=480792) 	add.s32 	%r145, %r145, 8192;
(EngineCore_DP0 pid=480792) 	setp.lt.s32 	%p7, %r145, %r20;
(EngineCore_DP0 pid=480792) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=480792) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=480792) 	.loc	1 159 32                        // quant_slide_tuned_Qwen2.5-7B.py:159:32
(EngineCore_DP0 pid=480792) 	max.f32 	%r146, %r144, 0f2B8CBCCC;
(EngineCore_DP0 pid=480792) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=480792) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-7B.py:0:32
(EngineCore_DP0 pid=480792) 	mov.b32 	%r80, 0f43E00000;
(EngineCore_DP0 pid=480792) 	.loc	1 160 32                        // quant_slide_tuned_Qwen2.5-7B.py:160:32
(EngineCore_DP0 pid=480792) 	div.full.f32 	%r81, %r146, %r80;
(EngineCore_DP0 pid=480792) 	.loc	1 160 41                        // quant_slide_tuned_Qwen2.5-7B.py:160:41
(EngineCore_DP0 pid=480792) 	max.f32 	%r79, %r81, 0f36924925;
(EngineCore_DP0 pid=480792) 	.loc	1 162 25                        // quant_slide_tuned_Qwen2.5-7B.py:162:25
(EngineCore_DP0 pid=480792) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=480792) 	.loc	1 162 30                        // quant_slide_tuned_Qwen2.5-7B.py:162:30
(EngineCore_DP0 pid=480792) 	// begin inline asm
(EngineCore_DP0 pid=480792) 	@%p28 st.global.b32 [ %rd8 + 0 ], { %r79 };
(EngineCore_DP0 pid=480792) 	// end inline asm
(EngineCore_DP0 pid=480792) 	.loc	1 165 29                        // quant_slide_tuned_Qwen2.5-7B.py:165:29
(EngineCore_DP0 pid=480792) 	shl.b32 	%r15, %r21, 1;
(EngineCore_DP0 pid=480792) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=480792) 	setp.lt.s32 	%p9, %r15, 1;
(EngineCore_DP0 pid=480792) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=480792) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=480792) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-7B.py:0:41
(EngineCore_DP0 pid=480792) 	ld.param.b32 	%r25, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=480792) 	shr.s32 	%r26, %r25, 31;
(EngineCore_DP0 pid=480792) 	shr.u32 	%r27, %r26, 30;
(EngineCore_DP0 pid=480792) 	add.s32 	%r28, %r25, %r27;
(EngineCore_DP0 pid=480792) 	shr.s32 	%r29, %r28, 2;
(EngineCore_DP0 pid=480792) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=480792) 	mul.lo.s32 	%r30, %r29, %r1;
(EngineCore_DP0 pid=480792) 	mad.wide.s32 	%rd2, %r30, 4, %rd5;
(EngineCore_DP0 pid=480792) 	div.full.f32 	%r14, %r80, %r146;
(EngineCore_DP0 pid=480792) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=480792) 	mov.b32 	%r147, 0;
(EngineCore_DP0 pid=480792) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=480792)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=480792) 	.loc	1 168 31                        // quant_slide_tuned_Qwen2.5-7B.py:168:31
(EngineCore_DP0 pid=480792) 	add.s32 	%r93, %r16, %r147;
(EngineCore_DP0 pid=480792) 	.loc	1 169 30                        // quant_slide_tuned_Qwen2.5-7B.py:169:30
(EngineCore_DP0 pid=480792) 	add.s32 	%r94, %r147, 1;
(EngineCore_DP0 pid=480792) 	setp.lt.s32 	%p18, %r93, %r15;
(EngineCore_DP0 pid=480792) 	.loc	1 172 24                        // quant_slide_tuned_Qwen2.5-7B.py:172:24
(EngineCore_DP0 pid=480792) 	shr.u32 	%r95, %r93, 1;
(EngineCore_DP0 pid=480792) 	.loc	1 173 23                        // quant_slide_tuned_Qwen2.5-7B.py:173:23
(EngineCore_DP0 pid=480792) 	shr.u32 	%r96, %r94, 31;
(EngineCore_DP0 pid=480792) 	add.s32 	%r97, %r94, %r96;
(EngineCore_DP0 pid=480792) 	and.b32 	%r98, %r97, 2147483646;
(EngineCore_DP0 pid=480792) 	sub.s32 	%r99, %r94, %r98;
(EngineCore_DP0 pid=480792) 	.loc	1 174 22                        // quant_slide_tuned_Qwen2.5-7B.py:174:22
(EngineCore_DP0 pid=480792) 	mul.lo.s32 	%r100, %r95, 6;
(EngineCore_DP0 pid=480792) 	.loc	1 174 30                        // quant_slide_tuned_Qwen2.5-7B.py:174:30
(EngineCore_DP0 pid=480792) 	shl.b32 	%r101, %r99, 1;
(EngineCore_DP0 pid=480792) 	.loc	1 174 26                        // quant_slide_tuned_Qwen2.5-7B.py:174:26
(EngineCore_DP0 pid=480792) 	add.s32 	%r102, %r100, %r101;
(EngineCore_DP0 pid=480792) 	.loc	1 177 53                        // quant_slide_tuned_Qwen2.5-7B.py:177:53
(EngineCore_DP0 pid=480792) 	setp.lt.s32 	%p19, %r100, %r19;
(EngineCore_DP0 pid=480792) 	setp.lt.s32 	%p20, %r102, %r19;
(EngineCore_DP0 pid=480792) 	.loc	1 177 37                        // quant_slide_tuned_Qwen2.5-7B.py:177:37
(EngineCore_DP0 pid=480792) 	and.pred 	%p10, %p18, %p19;
(EngineCore_DP0 pid=480792) 	and.pred 	%p11, %p18, %p20;
(EngineCore_DP0 pid=480792) 	.loc	1 176 29                        // quant_slide_tuned_Qwen2.5-7B.py:176:29
(EngineCore_DP0 pid=480792) 	mad.wide.s32 	%rd9, %r100, 2, %rd1;
(EngineCore_DP0 pid=480792) 	mad.wide.s32 	%rd10, %r102, 2, %rd1;
(EngineCore_DP0 pid=480792) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=480792) 	.loc	1 176 21                        // quant_slide_tuned_Qwen2.5-7B.py:176:21
(EngineCore_DP0 pid=480792) 	// begin inline asm
(EngineCore_DP0 pid=480792) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=480792) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=480792) 	// end inline asm
(EngineCore_DP0 pid=480792) 	// begin inline asm
(EngineCore_DP0 pid=480792) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=480792) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=480792) 	// end inline asm
(EngineCore_DP0 pid=480792) 	.loc	1 177 79                        // quant_slide_tuned_Qwen2.5-7B.py:177:79
(EngineCore_DP0 pid=480792) 	cvt.f32.bf16 	%r103, %rs48;
(EngineCore_DP0 pid=480792) 	cvt.f32.bf16 	%r104, %rs50;
(EngineCore_DP0 pid=480792) 	.loc	1 179 48                        // quant_slide_tuned_Qwen2.5-7B.py:179:48
(EngineCore_DP0 pid=480792) 	or.b32 	%r105, %r100, 1;
(EngineCore_DP0 pid=480792) 	or.b32 	%r106, %r102, 1;
(EngineCore_DP0 pid=480792) 	.loc	1 179 53                        // quant_slide_tuned_Qwen2.5-7B.py:179:53
(EngineCore_DP0 pid=480792) 	setp.lt.s32 	%p21, %r105, %r19;
(EngineCore_DP0 pid=480792) 	setp.lt.s32 	%p22, %r106, %r19;
(EngineCore_DP0 pid=480792) 	.loc	1 179 37                        // quant_slide_tuned_Qwen2.5-7B.py:179:37
(EngineCore_DP0 pid=480792) 	and.pred 	%p12, %p18, %p21;
(EngineCore_DP0 pid=480792) 	and.pred 	%p13, %p18, %p22;
(EngineCore_DP0 pid=480792) 	.loc	1 178 39                        // quant_slide_tuned_Qwen2.5-7B.py:178:39
(EngineCore_DP0 pid=480792) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=480792) 	add.s64 	%rd12, %rd10, 2;
(EngineCore_DP0 pid=480792) 	.loc	1 178 21                        // quant_slide_tuned_Qwen2.5-7B.py:178:21
(EngineCore_DP0 pid=480792) 	// begin inline asm
(EngineCore_DP0 pid=480792) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=480792) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=480792) 	// end inline asm
(EngineCore_DP0 pid=480792) 	// begin inline asm
(EngineCore_DP0 pid=480792) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=480792) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=480792) 	// end inline asm
(EngineCore_DP0 pid=480792) 	.loc	1 179 79                        // quant_slide_tuned_Qwen2.5-7B.py:179:79
(EngineCore_DP0 pid=480792) 	cvt.f32.bf16 	%r107, %rs52;
(EngineCore_DP0 pid=480792) 	cvt.f32.bf16 	%r108, %rs54;
(EngineCore_DP0 pid=480792) 	.loc	1 181 48                        // quant_slide_tuned_Qwen2.5-7B.py:181:48
(EngineCore_DP0 pid=480792) 	add.s32 	%r109, %r100, 2;
(EngineCore_DP0 pid=480792) 	add.s32 	%r110, %r102, 2;
(EngineCore_DP0 pid=480792) 	.loc	1 181 53                        // quant_slide_tuned_Qwen2.5-7B.py:181:53
(EngineCore_DP0 pid=480792) 	setp.lt.s32 	%p23, %r109, %r19;
(EngineCore_DP0 pid=480792) 	setp.lt.s32 	%p24, %r110, %r19;
(EngineCore_DP0 pid=480792) 	.loc	1 181 37                        // quant_slide_tuned_Qwen2.5-7B.py:181:37
(EngineCore_DP0 pid=480792) 	and.pred 	%p14, %p18, %p23;
(EngineCore_DP0 pid=480792) 	and.pred 	%p15, %p18, %p24;
(EngineCore_DP0 pid=480792) 	.loc	1 180 39                        // quant_slide_tuned_Qwen2.5-7B.py:180:39
(EngineCore_DP0 pid=480792) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=480792) 	add.s64 	%rd14, %rd10, 4;
(EngineCore_DP0 pid=480792) 	.loc	1 180 21                        // quant_slide_tuned_Qwen2.5-7B.py:180:21
(EngineCore_DP0 pid=480792) 	// begin inline asm
(EngineCore_DP0 pid=480792) 	mov.u16 %rs56, %rs49;
(EngineCore_DP0 pid=480792) 	@%p14 ld.global.b16 { %rs56 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=480792) 	// end inline asm
(EngineCore_DP0 pid=480792) 	// begin inline asm
(EngineCore_DP0 pid=480792) 	mov.u16 %rs58, %rs49;
(EngineCore_DP0 pid=480792) 	@%p15 ld.global.b16 { %rs58 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=480792) 	// end inline asm
(EngineCore_DP0 pid=480792) 	.loc	1 181 79                        // quant_slide_tuned_Qwen2.5-7B.py:181:79
(EngineCore_DP0 pid=480792) 	cvt.f32.bf16 	%r111, %rs56;
(EngineCore_DP0 pid=480792) 	cvt.f32.bf16 	%r112, %rs58;
(EngineCore_DP0 pid=480792) 	.loc	1 183 48                        // quant_slide_tuned_Qwen2.5-7B.py:183:48
(EngineCore_DP0 pid=480792) 	add.s32 	%r113, %r100, 3;
(EngineCore_DP0 pid=480792) 	add.s32 	%r114, %r102, 3;
(EngineCore_DP0 pid=480792) 	.loc	1 183 53                        // quant_slide_tuned_Qwen2.5-7B.py:183:53
(EngineCore_DP0 pid=480792) 	setp.lt.s32 	%p25, %r113, %r19;
(EngineCore_DP0 pid=480792) 	setp.lt.s32 	%p26, %r114, %r19;
(EngineCore_DP0 pid=480792) 	.loc	1 183 37                        // quant_slide_tuned_Qwen2.5-7B.py:183:37
(EngineCore_DP0 pid=480792) 	and.pred 	%p16, %p18, %p25;
(EngineCore_DP0 pid=480792) 	and.pred 	%p17, %p18, %p26;
(EngineCore_DP0 pid=480792) 	.loc	1 182 39                        // quant_slide_tuned_Qwen2.5-7B.py:182:39
(EngineCore_DP0 pid=480792) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=480792) 	add.s64 	%rd16, %rd10, 6;
(EngineCore_DP0 pid=480792) 	.loc	1 182 21                        // quant_slide_tuned_Qwen2.5-7B.py:182:21
(EngineCore_DP0 pid=480792) 	// begin inline asm
(EngineCore_DP0 pid=480792) 	mov.u16 %rs60, %rs49;
(EngineCore_DP0 pid=480792) 	@%p16 ld.global.b16 { %rs60 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=480792) 	// end inline asm
(EngineCore_DP0 pid=480792) 	// begin inline asm
(EngineCore_DP0 pid=480792) 	mov.u16 %rs62, %rs49;
(EngineCore_DP0 pid=480792) 	@%p17 ld.global.b16 { %rs62 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=480792) 	// end inline asm
(EngineCore_DP0 pid=480792) 	.loc	1 183 79                        // quant_slide_tuned_Qwen2.5-7B.py:183:79
(EngineCore_DP0 pid=480792) 	cvt.f32.bf16 	%r115, %rs60;
(EngineCore_DP0 pid=480792) 	cvt.f32.bf16 	%r116, %rs62;
(EngineCore_DP0 pid=480792) 	.loc	1 185 27                        // quant_slide_tuned_Qwen2.5-7B.py:185:27
(EngineCore_DP0 pid=480792) 	mul.f32 	%r117, %r14, %r103;
(EngineCore_DP0 pid=480792) 	mul.f32 	%r118, %r14, %r104;
(EngineCore_DP0 pid=480792) 	mov.b32 	%r119, 0f43E00000;
(EngineCore_DP0 pid=480792) 	.loc	1 185 48                        // quant_slide_tuned_Qwen2.5-7B.py:185:48
(EngineCore_DP0 pid=480792) 	min.xorsign.abs.f32 	%r83, %r117, %r119;
(EngineCore_DP0 pid=480792) 	min.xorsign.abs.f32 	%r84, %r118, %r119;
(EngineCore_DP0 pid=480792) 	.loc	1 185 60                        // quant_slide_tuned_Qwen2.5-7B.py:185:60
(EngineCore_DP0 pid=480792) 	// begin inline asm
(EngineCore_DP0 pid=480792) 	cvt.rn.satfinite.e4m3x2.f32  %rs64, %r84, %r83; 
(EngineCore_DP0 pid=480792) 
(EngineCore_DP0 pid=480792) 	// end inline asm
(EngineCore_DP0 pid=480792) 	shr.u16 	%rs68, %rs64, 8;
(EngineCore_DP0 pid=480792) 	.loc	1 186 27                        // quant_slide_tuned_Qwen2.5-7B.py:186:27
(EngineCore_DP0 pid=480792) 	mul.f32 	%r120, %r14, %r107;
(EngineCore_DP0 pid=480792) 	mul.f32 	%r121, %r14, %r108;
(EngineCore_DP0 pid=480792) 	.loc	1 186 48                        // quant_slide_tuned_Qwen2.5-7B.py:186:48
(EngineCore_DP0 pid=480792) 	min.xorsign.abs.f32 	%r85, %r120, %r119;
(EngineCore_DP0 pid=480792) 	min.xorsign.abs.f32 	%r86, %r121, %r119;
(EngineCore_DP0 pid=480792) 	.loc	1 186 60                        // quant_slide_tuned_Qwen2.5-7B.py:186:60
(EngineCore_DP0 pid=480792) 	// begin inline asm
(EngineCore_DP0 pid=480792) 	cvt.rn.satfinite.e4m3x2.f32  %rs65, %r86, %r85; 
(EngineCore_DP0 pid=480792) 
(EngineCore_DP0 pid=480792) 	// end inline asm
(EngineCore_DP0 pid=480792) 	shr.u16 	%rs69, %rs65, 8;
(EngineCore_DP0 pid=480792) 	.loc	1 187 27                        // quant_slide_tuned_Qwen2.5-7B.py:187:27
(EngineCore_DP0 pid=480792) 	mul.f32 	%r122, %r14, %r111;
(EngineCore_DP0 pid=480792) 	mul.f32 	%r123, %r14, %r112;
(EngineCore_DP0 pid=480792) 	.loc	1 187 48                        // quant_slide_tuned_Qwen2.5-7B.py:187:48
(EngineCore_DP0 pid=480792) 	min.xorsign.abs.f32 	%r87, %r122, %r119;
(EngineCore_DP0 pid=480792) 	min.xorsign.abs.f32 	%r88, %r123, %r119;
(EngineCore_DP0 pid=480792) 	.loc	1 187 60                        // quant_slide_tuned_Qwen2.5-7B.py:187:60
(EngineCore_DP0 pid=480792) 	// begin inline asm
(EngineCore_DP0 pid=480792) 	cvt.rn.satfinite.e4m3x2.f32  %rs66, %r88, %r87; 
(EngineCore_DP0 pid=480792) 
(EngineCore_DP0 pid=480792) 	// end inline asm
(EngineCore_DP0 pid=480792) 	shr.u16 	%rs70, %rs66, 8;
(EngineCore_DP0 pid=480792) 	.loc	1 188 27                        // quant_slide_tuned_Qwen2.5-7B.py:188:27
(EngineCore_DP0 pid=480792) 	mul.f32 	%r124, %r14, %r115;
(EngineCore_DP0 pid=480792) 	mul.f32 	%r125, %r14, %r116;
(EngineCore_DP0 pid=480792) 	.loc	1 188 48                        // quant_slide_tuned_Qwen2.5-7B.py:188:48
(EngineCore_DP0 pid=480792) 	min.xorsign.abs.f32 	%r89, %r124, %r119;
(EngineCore_DP0 pid=480792) 	min.xorsign.abs.f32 	%r90, %r125, %r119;
(EngineCore_DP0 pid=480792) 	.loc	1 188 60                        // quant_slide_tuned_Qwen2.5-7B.py:188:60
(EngineCore_DP0 pid=480792) 	// begin inline asm
(EngineCore_DP0 pid=480792) 	cvt.rn.satfinite.e4m3x2.f32  %rs67, %r90, %r89; 
(EngineCore_DP0 pid=480792) 
(EngineCore_DP0 pid=480792) 	// end inline asm
(EngineCore_DP0 pid=480792) 	shr.u16 	%rs71, %rs67, 8;
(EngineCore_DP0 pid=480792) 	.loc	1 190 45                        // quant_slide_tuned_Qwen2.5-7B.py:190:45
(EngineCore_DP0 pid=480792) 	cvt.u32.u16 	%r126, %rs64;
(EngineCore_DP0 pid=480792) 	and.b32 	%r127, %r126, 255;
(EngineCore_DP0 pid=480792) 	cvt.u32.u16 	%r128, %rs68;
(EngineCore_DP0 pid=480792) 	.loc	1 192 45                        // quant_slide_tuned_Qwen2.5-7B.py:192:45
(EngineCore_DP0 pid=480792) 	cvt.u32.u16 	%r129, %rs66;
(EngineCore_DP0 pid=480792) 	and.b32 	%r130, %r129, 255;
(EngineCore_DP0 pid=480792) 	cvt.u32.u16 	%r131, %rs70;
(EngineCore_DP0 pid=480792) 	.loc	1 193 45                        // quant_slide_tuned_Qwen2.5-7B.py:193:45
(EngineCore_DP0 pid=480792) 	cvt.u32.u16 	%r132, %rs67;
(EngineCore_DP0 pid=480792) 	cvt.u32.u16 	%r133, %rs71;
(EngineCore_DP0 pid=480792) 	.loc	1 195 30                        // quant_slide_tuned_Qwen2.5-7B.py:195:30
(EngineCore_DP0 pid=480792) 	and.b16 	%rs72, %rs65, 255;
(EngineCore_DP0 pid=480792) 	mul.wide.u16 	%r134, %rs72, 256;
(EngineCore_DP0 pid=480792) 	mul.wide.u16 	%r135, %rs69, 256;
(EngineCore_DP0 pid=480792) 	.loc	1 195 24                        // quant_slide_tuned_Qwen2.5-7B.py:195:24
(EngineCore_DP0 pid=480792) 	or.b32 	%r136, %r134, %r127;
(EngineCore_DP0 pid=480792) 	or.b32 	%r137, %r135, %r128;
(EngineCore_DP0 pid=480792) 	.loc	1 195 42                        // quant_slide_tuned_Qwen2.5-7B.py:195:42
(EngineCore_DP0 pid=480792) 	shl.b32 	%r138, %r130, 16;
(EngineCore_DP0 pid=480792) 	shl.b32 	%r139, %r131, 16;
(EngineCore_DP0 pid=480792) 	.loc	1 195 36                        // quant_slide_tuned_Qwen2.5-7B.py:195:36
(EngineCore_DP0 pid=480792) 	or.b32 	%r140, %r136, %r138;
(EngineCore_DP0 pid=480792) 	or.b32 	%r141, %r137, %r139;
(EngineCore_DP0 pid=480792) 	.loc	1 195 55                        // quant_slide_tuned_Qwen2.5-7B.py:195:55
(EngineCore_DP0 pid=480792) 	shl.b32 	%r142, %r132, 24;
(EngineCore_DP0 pid=480792) 	shl.b32 	%r143, %r133, 24;
(EngineCore_DP0 pid=480792) 	.loc	1 195 49                        // quant_slide_tuned_Qwen2.5-7B.py:195:49
(EngineCore_DP0 pid=480792) 	or.b32 	%r91, %r140, %r142;
(EngineCore_DP0 pid=480792) 	or.b32 	%r92, %r141, %r143;
(EngineCore_DP0 pid=480792) 	.loc	1 196 29                        // quant_slide_tuned_Qwen2.5-7B.py:196:29
(EngineCore_DP0 pid=480792) 	mad.wide.s32 	%rd17, %r93, 4, %rd2;
(EngineCore_DP0 pid=480792) 	.loc	1 196 39                        // quant_slide_tuned_Qwen2.5-7B.py:196:39
(EngineCore_DP0 pid=480792) 	// begin inline asm
(EngineCore_DP0 pid=480792) 	@%p18 st.global.v2.b32 [ %rd17 + 0 ], { %r91, %r92 };
(EngineCore_DP0 pid=480792) 	// end inline asm
(EngineCore_DP0 pid=480792) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=480792) 	add.s32 	%r147, %r147, 1024;
(EngineCore_DP0 pid=480792) 	setp.lt.s32 	%p27, %r147, %r15;
(EngineCore_DP0 pid=480792) 	@%p27 bra 	$L__BB0_6;
(EngineCore_DP0 pid=480792) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=480792) 	.loc	1 167 4                         // quant_slide_tuned_Qwen2.5-7B.py:167:4
(EngineCore_DP0 pid=480792) 	ret;
(EngineCore_DP0 pid=480792) $L__tmp3:
(EngineCore_DP0 pid=480792) $L__func_end0:
(EngineCore_DP0 pid=480792)                                         // -- End function
(EngineCore_DP0 pid=480792) }
(EngineCore_DP0 pid=480792) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py"
(EngineCore_DP0 pid=480792) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=480792) 	.section	.debug_abbrev
(EngineCore_DP0 pid=480792) 	{
(EngineCore_DP0 pid=480792) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=480792) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=480792) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=480792) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=480792) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=480792) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=480792) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=480792) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=480792) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=480792) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=480792) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=480792) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=480792) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=480792) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=480792) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=480792) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=480792) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=480792) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=480792) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=480792) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=480792) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=480792) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=480792) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=480792) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=480792) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=480792) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=480792) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=480792) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=480792) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=480792) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=480792) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=480792) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=480792) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=480792) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=480792) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=480792) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=480792) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=480792) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=480792) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=480792) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=480792) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=480792) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=480792) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=480792) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=480792) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=480792) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=480792) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=480792) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=480792) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=480792) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=480792) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=480792) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=480792) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=480792) 	}
(EngineCore_DP0 pid=480792) 	.section	.debug_info
(EngineCore_DP0 pid=480792) 	{
(EngineCore_DP0 pid=480792) .b32 221                                // Length of Unit
(EngineCore_DP0 pid=480792) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=480792) .b8 0
(EngineCore_DP0 pid=480792) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=480792) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=480792) .b8 1                                   // Abbrev [1] 0xb:0xd6 DW_TAG_compile_unit
(EngineCore_DP0 pid=480792) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=480792) .b8 114
(EngineCore_DP0 pid=480792) .b8 105
(EngineCore_DP0 pid=480792) .b8 116
(EngineCore_DP0 pid=480792) .b8 111
(EngineCore_DP0 pid=480792) .b8 110
(EngineCore_DP0 pid=480792) .b8 0
(EngineCore_DP0 pid=480792) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=480792) .b8 0
(EngineCore_DP0 pid=480792) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=480792) .b8 117
(EngineCore_DP0 pid=480792) .b8 97
(EngineCore_DP0 pid=480792) .b8 110
(EngineCore_DP0 pid=480792) .b8 116
(EngineCore_DP0 pid=480792) .b8 95
(EngineCore_DP0 pid=480792) .b8 115
(EngineCore_DP0 pid=480792) .b8 108
(EngineCore_DP0 pid=480792) .b8 105
(EngineCore_DP0 pid=480792) .b8 100
(EngineCore_DP0 pid=480792) .b8 101
(EngineCore_DP0 pid=480792) .b8 95
(EngineCore_DP0 pid=480792) .b8 116
(EngineCore_DP0 pid=480792) .b8 117
(EngineCore_DP0 pid=480792) .b8 110
(EngineCore_DP0 pid=480792) .b8 101
(EngineCore_DP0 pid=480792) .b8 100
(EngineCore_DP0 pid=480792) .b8 95
(EngineCore_DP0 pid=480792) .b8 81
(EngineCore_DP0 pid=480792) .b8 119
(EngineCore_DP0 pid=480792) .b8 101
(EngineCore_DP0 pid=480792) .b8 110
(EngineCore_DP0 pid=480792) .b8 50
(EngineCore_DP0 pid=480792) .b8 46
(EngineCore_DP0 pid=480792) .b8 53
(EngineCore_DP0 pid=480792) .b8 45
(EngineCore_DP0 pid=480792) .b8 55
(EngineCore_DP0 pid=480792) .b8 66
(EngineCore_DP0 pid=480792) .b8 46
(EngineCore_DP0 pid=480792) .b8 112
(EngineCore_DP0 pid=480792) .b8 121
(EngineCore_DP0 pid=480792) .b8 0
(EngineCore_DP0 pid=480792) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=480792) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=480792) .b8 114
(EngineCore_DP0 pid=480792) .b8 111
(EngineCore_DP0 pid=480792) .b8 111
(EngineCore_DP0 pid=480792) .b8 116
(EngineCore_DP0 pid=480792) .b8 47
(EngineCore_DP0 pid=480792) .b8 118
(EngineCore_DP0 pid=480792) .b8 108
(EngineCore_DP0 pid=480792) .b8 108
(EngineCore_DP0 pid=480792) .b8 109
(EngineCore_DP0 pid=480792) .b8 98
(EngineCore_DP0 pid=480792) .b8 101
(EngineCore_DP0 pid=480792) .b8 110
(EngineCore_DP0 pid=480792) .b8 99
(EngineCore_DP0 pid=480792) .b8 104
(EngineCore_DP0 pid=480792) .b8 47
(EngineCore_DP0 pid=480792) .b8 115
(EngineCore_DP0 pid=480792) .b8 108
(EngineCore_DP0 pid=480792) .b8 105
(EngineCore_DP0 pid=480792) .b8 100
(EngineCore_DP0 pid=480792) .b8 101
(EngineCore_DP0 pid=480792) .b8 115
(EngineCore_DP0 pid=480792) .b8 112
(EngineCore_DP0 pid=480792) .b8 97
(EngineCore_DP0 pid=480792) .b8 114
(EngineCore_DP0 pid=480792) .b8 115
(EngineCore_DP0 pid=480792) .b8 101
(EngineCore_DP0 pid=480792) .b8 47
(EngineCore_DP0 pid=480792) .b8 99
(EngineCore_DP0 pid=480792) .b8 115
(EngineCore_DP0 pid=480792) .b8 114
(EngineCore_DP0 pid=480792) .b8 99
(EngineCore_DP0 pid=480792) .b8 47
(EngineCore_DP0 pid=480792) .b8 102
(EngineCore_DP0 pid=480792) .b8 117
(EngineCore_DP0 pid=480792) .b8 115
(EngineCore_DP0 pid=480792) .b8 101
(EngineCore_DP0 pid=480792) .b8 100
(EngineCore_DP0 pid=480792) .b8 95
(EngineCore_DP0 pid=480792) .b8 113
(EngineCore_DP0 pid=480792) .b8 117
(EngineCore_DP0 pid=480792) .b8 97
(EngineCore_DP0 pid=480792) .b8 110
(EngineCore_DP0 pid=480792) .b8 116
(EngineCore_DP0 pid=480792) .b8 95
(EngineCore_DP0 pid=480792) .b8 115
(EngineCore_DP0 pid=480792) .b8 108
(EngineCore_DP0 pid=480792) .b8 105
(EngineCore_DP0 pid=480792) .b8 100
(EngineCore_DP0 pid=480792) .b8 101
(EngineCore_DP0 pid=480792) .b8 95
(EngineCore_DP0 pid=480792) .b8 116
(EngineCore_DP0 pid=480792) .b8 114
(EngineCore_DP0 pid=480792) .b8 105
(EngineCore_DP0 pid=480792) .b8 116
(EngineCore_DP0 pid=480792) .b8 111
(EngineCore_DP0 pid=480792) .b8 110
(EngineCore_DP0 pid=480792) .b8 47
(EngineCore_DP0 pid=480792) .b8 98
(EngineCore_DP0 pid=480792) .b8 117
(EngineCore_DP0 pid=480792) .b8 105
(EngineCore_DP0 pid=480792) .b8 108
(EngineCore_DP0 pid=480792) .b8 100
(EngineCore_DP0 pid=480792) .b8 47
(EngineCore_DP0 pid=480792) .b8 71
(EngineCore_DP0 pid=480792) .b8 66
(EngineCore_DP0 pid=480792) .b8 49
(EngineCore_DP0 pid=480792) .b8 48
(EngineCore_DP0 pid=480792) .b8 95
(EngineCore_DP0 pid=480792) .b8 99
(EngineCore_DP0 pid=480792) .b8 99
(EngineCore_DP0 pid=480792) .b8 49
(EngineCore_DP0 pid=480792) .b8 50
(EngineCore_DP0 pid=480792) .b8 49
(EngineCore_DP0 pid=480792) .b8 95
(EngineCore_DP0 pid=480792) .b8 112
(EngineCore_DP0 pid=480792) .b8 121
(EngineCore_DP0 pid=480792) .b8 51
(EngineCore_DP0 pid=480792) .b8 49
(EngineCore_DP0 pid=480792) .b8 50
(EngineCore_DP0 pid=480792) .b8 95
(EngineCore_DP0 pid=480792) .b8 99
(EngineCore_DP0 pid=480792) .b8 117
(EngineCore_DP0 pid=480792) .b8 49
(EngineCore_DP0 pid=480792) .b8 50
(EngineCore_DP0 pid=480792) .b8 57
(EngineCore_DP0 pid=480792) .b8 95
(EngineCore_DP0 pid=480792) .b8 97
(EngineCore_DP0 pid=480792) .b8 97
(EngineCore_DP0 pid=480792) .b8 114
(EngineCore_DP0 pid=480792) .b8 99
(EngineCore_DP0 pid=480792) .b8 104
(EngineCore_DP0 pid=480792) .b8 54
(EngineCore_DP0 pid=480792) .b8 52
(EngineCore_DP0 pid=480792) .b8 0
(EngineCore_DP0 pid=480792) .b8 2                                   // Abbrev [2] 0x98:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=480792) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=480792) .b8 113
(EngineCore_DP0 pid=480792) .b8 117
(EngineCore_DP0 pid=480792) .b8 97
(EngineCore_DP0 pid=480792) .b8 110
(EngineCore_DP0 pid=480792) .b8 116
(EngineCore_DP0 pid=480792) .b8 95
(EngineCore_DP0 pid=480792) .b8 115
(EngineCore_DP0 pid=480792) .b8 108
(EngineCore_DP0 pid=480792) .b8 105
(EngineCore_DP0 pid=480792) .b8 100
(EngineCore_DP0 pid=480792) .b8 101
(EngineCore_DP0 pid=480792) .b8 95
(EngineCore_DP0 pid=480792) .b8 102
(EngineCore_DP0 pid=480792) .b8 112
(EngineCore_DP0 pid=480792) .b8 56
(EngineCore_DP0 pid=480792) .b8 95
(EngineCore_DP0 pid=480792) .b8 107
(EngineCore_DP0 pid=480792) .b8 101
(EngineCore_DP0 pid=480792) .b8 114
(EngineCore_DP0 pid=480792) .b8 110
(EngineCore_DP0 pid=480792) .b8 101
(EngineCore_DP0 pid=480792) .b8 108
(EngineCore_DP0 pid=480792) .b8 0
(EngineCore_DP0 pid=480792) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=480792) .b8 3                                   // Abbrev [3] 0xb2:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=480792) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=480792) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=480792) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=480792) .b8 4                                   // Abbrev [4] 0xc7:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=480792) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=480792) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=480792) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=480792) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=480792) .b8 157                                 // DW_AT_call_line
(EngineCore_DP0 pid=480792) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=480792) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=480792) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=480792) 	}
(EngineCore_DP0 pid=480792) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=480792) 
(EngineCore_DP0 pid=480792) ================================================================
(EngineCore_DP0 pid=480792) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=480792) 
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp81em_5bj.ptx', '-o', '/tmp/tmp81em_5bj.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866] 
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866] 
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866] 
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp81em_5bj.ptx -o /tmp/tmp81em_5bj.ptx.o
(EngineCore_DP0 pid=480792) ERROR 01-25 21:32:14 [core.py:866] 

STDERR:
[2026-01-25 21:31:10] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:31:10] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:31:10] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:31:10] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:31:10] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:31:10] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:31:10] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:31:10] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:31:10] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:31:10] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:31:10] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:31:10] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:31:10] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:31:10] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:31:13] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:31:13] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:31:13] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:31:13] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:31:13] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:31:13] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:31:13] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:31:13] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:31:13] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:31:13] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:31:13] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:31:13] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:31:13] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:31:13] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=480792) [2026-01-25 21:31:14] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=480792) [2026-01-25 21:31:14] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=480792) [2026-01-25 21:31:14] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=480792) [2026-01-25 21:31:14] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=480792) [2026-01-25 21:31:14] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=480792) [2026-01-25 21:31:14] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=480792) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=480792) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:23<00:23, 23.74s/it]
(EngineCore_DP0 pid=480792) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:57<00:00, 29.37s/it]
(EngineCore_DP0 pid=480792) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:57<00:00, 28.52s/it]
(EngineCore_DP0 pid=480792) 
(EngineCore_DP0 pid=480792) [2026-01-25 21:32:12] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=480792) [2026-01-25 21:32:13] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 13860864 bytes
(EngineCore_DP0 pid=480792) [2026-01-25 21:32:13] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=480792) [2026-01-25 21:32:13] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10780672 bytes
(EngineCore_DP0 pid=480792) [2026-01-25 21:32:13] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=480792) [2026-01-25 21:32:13] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 113967104 bytes
(EngineCore_DP0 pid=480792) [2026-01-25 21:32:13] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=480792) [2026-01-25 21:32:13] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 56655872 bytes
(EngineCore_DP0 pid=480792) Process EngineCore_DP0:
(EngineCore_DP0 pid=480792) Traceback (most recent call last):
(EngineCore_DP0 pid=480792)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=480792)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=480792)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=480792)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=480792) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp81em_5bj.ptx', '-o', '/tmp/tmp81em_5bj.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=480792) 
(EngineCore_DP0 pid=480792) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=480792) 
(EngineCore_DP0 pid=480792) Traceback (most recent call last):
(EngineCore_DP0 pid=480792)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=480792)     self.run()
(EngineCore_DP0 pid=480792)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=480792)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=480792)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=480792)     raise e
(EngineCore_DP0 pid=480792)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=480792)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=480792)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=480792)     super().__init__(
(EngineCore_DP0 pid=480792)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=480792)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=480792)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=480792)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=480792)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=480792)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=480792)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=480792)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=480792)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=480792)     return func(*args, **kwargs)
(EngineCore_DP0 pid=480792)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=480792)     return func(*args, **kwargs)
(EngineCore_DP0 pid=480792)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=480792)     self.model_runner.profile_run()
(EngineCore_DP0 pid=480792)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=480792)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=480792)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=480792)     return func(*args, **kwargs)
(EngineCore_DP0 pid=480792)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=480792)     outputs = self.model(
(EngineCore_DP0 pid=480792)               ^^^^^^^^^^^
(EngineCore_DP0 pid=480792)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=480792)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=480792)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=480792)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=480792)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=480792)     hidden_states = self.model(
(EngineCore_DP0 pid=480792)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=480792)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=480792)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=480792)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=480792)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=480792)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=480792)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=480792)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=480792)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=480792)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=480792)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=480792)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=480792)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=480792)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=480792)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=480792)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=480792)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=480792)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=480792)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=480792)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=480792)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=480792)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=480792)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=480792)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=480792)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=480792)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=480792)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=480792)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=480792)     return self._linear_fn(
(EngineCore_DP0 pid=480792)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=480792)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=480792)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=480792)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=480792)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=480792)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=480792)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=480792)     return fn(input, L)
(EngineCore_DP0 pid=480792)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=480792)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=480792)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=480792)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=480792)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=480792)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=480792)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=480792)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=480792)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=480792)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=480792)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=480792)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=480792)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=480792)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=480792)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=480792)     raise PTXASError(error)
(EngineCore_DP0 pid=480792) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=480792) `ptxas` stderr:
(EngineCore_DP0 pid=480792) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=480792) 
(EngineCore_DP0 pid=480792) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp81em_5bj.ptx -o /tmp/tmp81em_5bj.ptx.o
(EngineCore_DP0 pid=480792) 
[rank0]:[W125 21:32:14.634807462 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=16384

========== M=32768 ==========
Time: 2026-01-25 21:32:16
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Qwen2.5-7B-FP8_M32768.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:32:33 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 21:32:34 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=482156) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=482156) 
(EngineCore_DP0 pid=482156) 
(EngineCore_DP0 pid=482156) ================================================================
(EngineCore_DP0 pid=482156) Internal Triton PTX codegen error
(EngineCore_DP0 pid=482156) `ptxas` stderr:
(EngineCore_DP0 pid=482156) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=482156) 
(EngineCore_DP0 pid=482156) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpo_pzp1cc.ptx -o /tmp/tmpo_pzp1cc.ptx.o
(EngineCore_DP0 pid=482156) 
(EngineCore_DP0 pid=482156) 
(EngineCore_DP0 pid=482156) //
(EngineCore_DP0 pid=482156) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=482156) //
(EngineCore_DP0 pid=482156) 
(EngineCore_DP0 pid=482156) .version 8.7
(EngineCore_DP0 pid=482156) .target sm_121a
(EngineCore_DP0 pid=482156) .address_size 64
(EngineCore_DP0 pid=482156) 
(EngineCore_DP0 pid=482156) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=482156) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=482156)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=482156) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=482156) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=482156) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=482156) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=482156) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=482156) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=482156) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=482156) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=482156) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=482156) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=482156) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=482156) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=482156) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=482156) )
(EngineCore_DP0 pid=482156) .reqntid 512
(EngineCore_DP0 pid=482156) {
(EngineCore_DP0 pid=482156) 	.reg .pred 	%p<28>;
(EngineCore_DP0 pid=482156) 	.reg .b16 	%rs<49>;
(EngineCore_DP0 pid=482156) 	.reg .b32 	%r<139>;
(EngineCore_DP0 pid=482156) 	.reg .b64 	%rd<17>;
(EngineCore_DP0 pid=482156) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=482156) $L__func_begin0:
(EngineCore_DP0 pid=482156) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=482156) 
(EngineCore_DP0 pid=482156) // %bb.0:
(EngineCore_DP0 pid=482156) 	ld.param.b32 	%r21, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=482156) 	ld.param.b32 	%r20, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=482156) 	ld.param.b32 	%r19, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=482156) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=482156) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=482156) $L__tmp0:
(EngineCore_DP0 pid=482156) 	.loc	1 143 24                        // quant_slide_tuned_Qwen2.5-7B.py:143:24
(EngineCore_DP0 pid=482156) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=482156) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=482156) 	.loc	1 148 26                        // quant_slide_tuned_Qwen2.5-7B.py:148:26
(EngineCore_DP0 pid=482156) 	mul.lo.s32 	%r24, %r23, %r1;
(EngineCore_DP0 pid=482156) 	.loc	1 148 20                        // quant_slide_tuned_Qwen2.5-7B.py:148:20
(EngineCore_DP0 pid=482156) 	mad.wide.s32 	%rd1, %r24, 2, %rd4;
(EngineCore_DP0 pid=482156) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=482156) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=482156) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=482156) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=482156) 	setp.lt.s32 	%p1, %r20, 1;
(EngineCore_DP0 pid=482156) 	mov.b32 	%r137, 0f2B8CBCCC;
(EngineCore_DP0 pid=482156) 	setp.eq.b32 	%p27, %r2, 0;
(EngineCore_DP0 pid=482156) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=482156) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=482156) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=482156) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=482156) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=482156) 	shr.u32 	%r33, %r2, 3;
(EngineCore_DP0 pid=482156) 	and.b32 	%r34, %r33, 60;
(EngineCore_DP0 pid=482156) 	mov.b32 	%r35, global_smem;
(EngineCore_DP0 pid=482156) 	add.s32 	%r45, %r35, %r34;
(EngineCore_DP0 pid=482156) 	shl.b32 	%r36, %r2, 2;
(EngineCore_DP0 pid=482156) 	add.s32 	%r48, %r35, %r36;
(EngineCore_DP0 pid=482156) 	mov.b32 	%r41, 0;
(EngineCore_DP0 pid=482156) 	mov.b32 	%r135, 0f00000000;
(EngineCore_DP0 pid=482156) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=482156) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=482156) 	mov.b32 	%r136, %r41;
(EngineCore_DP0 pid=482156) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=482156) 	.loc	1 155 22                        // quant_slide_tuned_Qwen2.5-7B.py:155:22
(EngineCore_DP0 pid=482156) 	add.s32 	%r51, %r4, %r136;
(EngineCore_DP0 pid=482156) 	setp.lt.s32 	%p2, %r51, %r19;
(EngineCore_DP0 pid=482156) 	.loc	1 156 29                        // quant_slide_tuned_Qwen2.5-7B.py:156:29
(EngineCore_DP0 pid=482156) 	mad.wide.s32 	%rd6, %r51, 2, %rd1;
(EngineCore_DP0 pid=482156) 	.loc	1 156 21                        // quant_slide_tuned_Qwen2.5-7B.py:156:21
(EngineCore_DP0 pid=482156) 	// begin inline asm
(EngineCore_DP0 pid=482156) 	mov.u32 %r37, %r41;
(EngineCore_DP0 pid=482156) 	mov.u32 %r38, %r41;
(EngineCore_DP0 pid=482156) 	mov.u32 %r39, %r41;
(EngineCore_DP0 pid=482156) 	mov.u32 %r40, %r41;
(EngineCore_DP0 pid=482156) 	@%p2 ld.global.v4.b32 { %r37, %r38, %r39, %r40 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=482156) 	// end inline asm
(EngineCore_DP0 pid=482156) 	mov.b32 	{%rs1, %rs2}, %r37;
(EngineCore_DP0 pid=482156) 	mov.b32 	{%rs3, %rs4}, %r38;
(EngineCore_DP0 pid=482156) 	mov.b32 	{%rs5, %rs6}, %r39;
(EngineCore_DP0 pid=482156) 	mov.b32 	{%rs7, %rs8}, %r40;
(EngineCore_DP0 pid=482156) 	.loc	1 157 50                        // quant_slide_tuned_Qwen2.5-7B.py:157:50
(EngineCore_DP0 pid=482156) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=482156) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=482156) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=482156) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=482156) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=482156) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=482156) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=482156) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=482156) $L__tmp1:
(EngineCore_DP0 pid=482156) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=482156) 	bar.sync 	0;
(EngineCore_DP0 pid=482156) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=482156) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=482156) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=482156) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=482156) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=482156) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=482156) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=482156) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=482156) 	cvt.f32.bf16 	%r52, %rs23;
(EngineCore_DP0 pid=482156) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=482156) 	shfl.sync.bfly.b32 	%r53, %r52, 16, 31, -1;
(EngineCore_DP0 pid=482156) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=482156) 	max.f32 	%r54, %r52, %r53;
(EngineCore_DP0 pid=482156) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=482156) 	shfl.sync.bfly.b32 	%r55, %r54, 8, 31, -1;
(EngineCore_DP0 pid=482156) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=482156) 	max.f32 	%r56, %r54, %r55;
(EngineCore_DP0 pid=482156) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=482156) 	shfl.sync.bfly.b32 	%r57, %r56, 4, 31, -1;
(EngineCore_DP0 pid=482156) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=482156) 	max.f32 	%r58, %r56, %r57;
(EngineCore_DP0 pid=482156) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=482156) 	shfl.sync.bfly.b32 	%r59, %r58, 2, 31, -1;
(EngineCore_DP0 pid=482156) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=482156) 	max.f32 	%r60, %r58, %r59;
(EngineCore_DP0 pid=482156) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=482156) 	shfl.sync.bfly.b32 	%r61, %r60, 1, 31, -1;
(EngineCore_DP0 pid=482156) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=482156) 	max.f32 	%r46, %r60, %r61;
(EngineCore_DP0 pid=482156) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=482156) 	// begin inline asm
(EngineCore_DP0 pid=482156) 	@%p3 st.shared.b32 [ %r45 + 0 ], %r46;
(EngineCore_DP0 pid=482156) 	// end inline asm
(EngineCore_DP0 pid=482156) 	bar.sync 	0;
(EngineCore_DP0 pid=482156) 	// begin inline asm
(EngineCore_DP0 pid=482156) 	@%p4 ld.shared.b32 %r47, [ %r48 + 0 ];
(EngineCore_DP0 pid=482156) 	// end inline asm
(EngineCore_DP0 pid=482156) 	shfl.sync.bfly.b32 	%r62, %r47, 8, 31, -1;
(EngineCore_DP0 pid=482156) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=482156) 	max.f32 	%r63, %r47, %r62;
(EngineCore_DP0 pid=482156) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=482156) 	shfl.sync.bfly.b32 	%r64, %r63, 4, 31, -1;
(EngineCore_DP0 pid=482156) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=482156) 	max.f32 	%r65, %r63, %r64;
(EngineCore_DP0 pid=482156) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=482156) 	shfl.sync.bfly.b32 	%r66, %r65, 2, 31, -1;
(EngineCore_DP0 pid=482156) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=482156) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=482156) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=482156) 	shfl.sync.bfly.b32 	%r68, %r67, 1, 31, -1;
(EngineCore_DP0 pid=482156) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=482156) 	max.f32 	%r50, %r67, %r68;
(EngineCore_DP0 pid=482156) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=482156) 	// begin inline asm
(EngineCore_DP0 pid=482156) 	@%p27 st.shared.b32 [ %r48 + 0 ], %r50;
(EngineCore_DP0 pid=482156) 	// end inline asm
(EngineCore_DP0 pid=482156) 	bar.sync 	0;
(EngineCore_DP0 pid=482156) 	ld.shared.b32 	%r69, [global_smem];
(EngineCore_DP0 pid=482156) $L__tmp2:
(EngineCore_DP0 pid=482156) 	.loc	1 157 36                        // quant_slide_tuned_Qwen2.5-7B.py:157:36
(EngineCore_DP0 pid=482156) 	max.f32 	%r135, %r135, %r69;
(EngineCore_DP0 pid=482156) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=482156) 	add.s32 	%r136, %r136, 4096;
(EngineCore_DP0 pid=482156) 	setp.lt.s32 	%p6, %r136, %r20;
(EngineCore_DP0 pid=482156) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=482156) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=482156) 	.loc	1 159 32                        // quant_slide_tuned_Qwen2.5-7B.py:159:32
(EngineCore_DP0 pid=482156) 	max.f32 	%r137, %r135, 0f2B8CBCCC;
(EngineCore_DP0 pid=482156) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=482156) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-7B.py:0:32
(EngineCore_DP0 pid=482156) 	mov.b32 	%r71, 0f43E00000;
(EngineCore_DP0 pid=482156) 	.loc	1 160 32                        // quant_slide_tuned_Qwen2.5-7B.py:160:32
(EngineCore_DP0 pid=482156) 	div.full.f32 	%r72, %r137, %r71;
(EngineCore_DP0 pid=482156) 	.loc	1 160 41                        // quant_slide_tuned_Qwen2.5-7B.py:160:41
(EngineCore_DP0 pid=482156) 	max.f32 	%r70, %r72, 0f36924925;
(EngineCore_DP0 pid=482156) 	.loc	1 162 25                        // quant_slide_tuned_Qwen2.5-7B.py:162:25
(EngineCore_DP0 pid=482156) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=482156) 	.loc	1 162 30                        // quant_slide_tuned_Qwen2.5-7B.py:162:30
(EngineCore_DP0 pid=482156) 	// begin inline asm
(EngineCore_DP0 pid=482156) 	@%p27 st.global.b32 [ %rd7 + 0 ], { %r70 };
(EngineCore_DP0 pid=482156) 	// end inline asm
(EngineCore_DP0 pid=482156) 	.loc	1 165 29                        // quant_slide_tuned_Qwen2.5-7B.py:165:29
(EngineCore_DP0 pid=482156) 	shl.b32 	%r15, %r21, 1;
(EngineCore_DP0 pid=482156) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=482156) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=482156) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=482156) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=482156) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-7B.py:0:41
(EngineCore_DP0 pid=482156) 	ld.param.b32 	%r25, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=482156) 	shr.s32 	%r26, %r25, 31;
(EngineCore_DP0 pid=482156) 	shr.u32 	%r27, %r26, 30;
(EngineCore_DP0 pid=482156) 	add.s32 	%r28, %r25, %r27;
(EngineCore_DP0 pid=482156) 	shr.s32 	%r29, %r28, 2;
(EngineCore_DP0 pid=482156) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=482156) 	mul.lo.s32 	%r30, %r29, %r1;
(EngineCore_DP0 pid=482156) 	mad.wide.s32 	%rd2, %r30, 4, %rd5;
(EngineCore_DP0 pid=482156) 	div.full.f32 	%r14, %r71, %r137;
(EngineCore_DP0 pid=482156) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=482156) 	mov.b32 	%r138, 0;
(EngineCore_DP0 pid=482156) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=482156)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=482156) 	.loc	1 168 31                        // quant_slide_tuned_Qwen2.5-7B.py:168:31
(EngineCore_DP0 pid=482156) 	add.s32 	%r84, %r16, %r138;
(EngineCore_DP0 pid=482156) 	.loc	1 169 30                        // quant_slide_tuned_Qwen2.5-7B.py:169:30
(EngineCore_DP0 pid=482156) 	add.s32 	%r85, %r138, 1;
(EngineCore_DP0 pid=482156) 	setp.lt.s32 	%p17, %r84, %r15;
(EngineCore_DP0 pid=482156) 	.loc	1 172 24                        // quant_slide_tuned_Qwen2.5-7B.py:172:24
(EngineCore_DP0 pid=482156) 	shr.u32 	%r86, %r84, 1;
(EngineCore_DP0 pid=482156) 	.loc	1 173 23                        // quant_slide_tuned_Qwen2.5-7B.py:173:23
(EngineCore_DP0 pid=482156) 	shr.u32 	%r87, %r85, 31;
(EngineCore_DP0 pid=482156) 	add.s32 	%r88, %r85, %r87;
(EngineCore_DP0 pid=482156) 	and.b32 	%r89, %r88, 2147483646;
(EngineCore_DP0 pid=482156) 	sub.s32 	%r90, %r85, %r89;
(EngineCore_DP0 pid=482156) 	.loc	1 174 22                        // quant_slide_tuned_Qwen2.5-7B.py:174:22
(EngineCore_DP0 pid=482156) 	mul.lo.s32 	%r91, %r86, 6;
(EngineCore_DP0 pid=482156) 	.loc	1 174 30                        // quant_slide_tuned_Qwen2.5-7B.py:174:30
(EngineCore_DP0 pid=482156) 	shl.b32 	%r92, %r90, 1;
(EngineCore_DP0 pid=482156) 	.loc	1 174 26                        // quant_slide_tuned_Qwen2.5-7B.py:174:26
(EngineCore_DP0 pid=482156) 	add.s32 	%r93, %r91, %r92;
(EngineCore_DP0 pid=482156) 	.loc	1 177 53                        // quant_slide_tuned_Qwen2.5-7B.py:177:53
(EngineCore_DP0 pid=482156) 	setp.lt.s32 	%p18, %r91, %r19;
(EngineCore_DP0 pid=482156) 	setp.lt.s32 	%p19, %r93, %r19;
(EngineCore_DP0 pid=482156) 	.loc	1 177 37                        // quant_slide_tuned_Qwen2.5-7B.py:177:37
(EngineCore_DP0 pid=482156) 	and.pred 	%p9, %p17, %p18;
(EngineCore_DP0 pid=482156) 	and.pred 	%p10, %p17, %p19;
(EngineCore_DP0 pid=482156) 	.loc	1 176 29                        // quant_slide_tuned_Qwen2.5-7B.py:176:29
(EngineCore_DP0 pid=482156) 	mad.wide.s32 	%rd8, %r91, 2, %rd1;
(EngineCore_DP0 pid=482156) 	mad.wide.s32 	%rd9, %r93, 2, %rd1;
(EngineCore_DP0 pid=482156) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=482156) 	.loc	1 176 21                        // quant_slide_tuned_Qwen2.5-7B.py:176:21
(EngineCore_DP0 pid=482156) 	// begin inline asm
(EngineCore_DP0 pid=482156) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=482156) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=482156) 	// end inline asm
(EngineCore_DP0 pid=482156) 	// begin inline asm
(EngineCore_DP0 pid=482156) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=482156) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=482156) 	// end inline asm
(EngineCore_DP0 pid=482156) 	.loc	1 177 79                        // quant_slide_tuned_Qwen2.5-7B.py:177:79
(EngineCore_DP0 pid=482156) 	cvt.f32.bf16 	%r94, %rs24;
(EngineCore_DP0 pid=482156) 	cvt.f32.bf16 	%r95, %rs26;
(EngineCore_DP0 pid=482156) 	.loc	1 179 48                        // quant_slide_tuned_Qwen2.5-7B.py:179:48
(EngineCore_DP0 pid=482156) 	or.b32 	%r96, %r91, 1;
(EngineCore_DP0 pid=482156) 	or.b32 	%r97, %r93, 1;
(EngineCore_DP0 pid=482156) 	.loc	1 179 53                        // quant_slide_tuned_Qwen2.5-7B.py:179:53
(EngineCore_DP0 pid=482156) 	setp.lt.s32 	%p20, %r96, %r19;
(EngineCore_DP0 pid=482156) 	setp.lt.s32 	%p21, %r97, %r19;
(EngineCore_DP0 pid=482156) 	.loc	1 179 37                        // quant_slide_tuned_Qwen2.5-7B.py:179:37
(EngineCore_DP0 pid=482156) 	and.pred 	%p11, %p17, %p20;
(EngineCore_DP0 pid=482156) 	and.pred 	%p12, %p17, %p21;
(EngineCore_DP0 pid=482156) 	.loc	1 178 39                        // quant_slide_tuned_Qwen2.5-7B.py:178:39
(EngineCore_DP0 pid=482156) 	add.s64 	%rd10, %rd8, 2;
(EngineCore_DP0 pid=482156) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=482156) 	.loc	1 178 21                        // quant_slide_tuned_Qwen2.5-7B.py:178:21
(EngineCore_DP0 pid=482156) 	// begin inline asm
(EngineCore_DP0 pid=482156) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=482156) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=482156) 	// end inline asm
(EngineCore_DP0 pid=482156) 	// begin inline asm
(EngineCore_DP0 pid=482156) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=482156) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=482156) 	// end inline asm
(EngineCore_DP0 pid=482156) 	.loc	1 179 79                        // quant_slide_tuned_Qwen2.5-7B.py:179:79
(EngineCore_DP0 pid=482156) 	cvt.f32.bf16 	%r98, %rs28;
(EngineCore_DP0 pid=482156) 	cvt.f32.bf16 	%r99, %rs30;
(EngineCore_DP0 pid=482156) 	.loc	1 181 48                        // quant_slide_tuned_Qwen2.5-7B.py:181:48
(EngineCore_DP0 pid=482156) 	add.s32 	%r100, %r91, 2;
(EngineCore_DP0 pid=482156) 	add.s32 	%r101, %r93, 2;
(EngineCore_DP0 pid=482156) 	.loc	1 181 53                        // quant_slide_tuned_Qwen2.5-7B.py:181:53
(EngineCore_DP0 pid=482156) 	setp.lt.s32 	%p22, %r100, %r19;
(EngineCore_DP0 pid=482156) 	setp.lt.s32 	%p23, %r101, %r19;
(EngineCore_DP0 pid=482156) 	.loc	1 181 37                        // quant_slide_tuned_Qwen2.5-7B.py:181:37
(EngineCore_DP0 pid=482156) 	and.pred 	%p13, %p17, %p22;
(EngineCore_DP0 pid=482156) 	and.pred 	%p14, %p17, %p23;
(EngineCore_DP0 pid=482156) 	.loc	1 180 39                        // quant_slide_tuned_Qwen2.5-7B.py:180:39
(EngineCore_DP0 pid=482156) 	add.s64 	%rd12, %rd8, 4;
(EngineCore_DP0 pid=482156) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=482156) 	.loc	1 180 21                        // quant_slide_tuned_Qwen2.5-7B.py:180:21
(EngineCore_DP0 pid=482156) 	// begin inline asm
(EngineCore_DP0 pid=482156) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=482156) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=482156) 	// end inline asm
(EngineCore_DP0 pid=482156) 	// begin inline asm
(EngineCore_DP0 pid=482156) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=482156) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=482156) 	// end inline asm
(EngineCore_DP0 pid=482156) 	.loc	1 181 79                        // quant_slide_tuned_Qwen2.5-7B.py:181:79
(EngineCore_DP0 pid=482156) 	cvt.f32.bf16 	%r102, %rs32;
(EngineCore_DP0 pid=482156) 	cvt.f32.bf16 	%r103, %rs34;
(EngineCore_DP0 pid=482156) 	.loc	1 183 48                        // quant_slide_tuned_Qwen2.5-7B.py:183:48
(EngineCore_DP0 pid=482156) 	add.s32 	%r104, %r91, 3;
(EngineCore_DP0 pid=482156) 	add.s32 	%r105, %r93, 3;
(EngineCore_DP0 pid=482156) 	.loc	1 183 53                        // quant_slide_tuned_Qwen2.5-7B.py:183:53
(EngineCore_DP0 pid=482156) 	setp.lt.s32 	%p24, %r104, %r19;
(EngineCore_DP0 pid=482156) 	setp.lt.s32 	%p25, %r105, %r19;
(EngineCore_DP0 pid=482156) 	.loc	1 183 37                        // quant_slide_tuned_Qwen2.5-7B.py:183:37
(EngineCore_DP0 pid=482156) 	and.pred 	%p15, %p17, %p24;
(EngineCore_DP0 pid=482156) 	and.pred 	%p16, %p17, %p25;
(EngineCore_DP0 pid=482156) 	.loc	1 182 39                        // quant_slide_tuned_Qwen2.5-7B.py:182:39
(EngineCore_DP0 pid=482156) 	add.s64 	%rd14, %rd8, 6;
(EngineCore_DP0 pid=482156) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=482156) 	.loc	1 182 21                        // quant_slide_tuned_Qwen2.5-7B.py:182:21
(EngineCore_DP0 pid=482156) 	// begin inline asm
(EngineCore_DP0 pid=482156) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=482156) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=482156) 	// end inline asm
(EngineCore_DP0 pid=482156) 	// begin inline asm
(EngineCore_DP0 pid=482156) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=482156) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=482156) 	// end inline asm
(EngineCore_DP0 pid=482156) 	.loc	1 183 79                        // quant_slide_tuned_Qwen2.5-7B.py:183:79
(EngineCore_DP0 pid=482156) 	cvt.f32.bf16 	%r106, %rs36;
(EngineCore_DP0 pid=482156) 	cvt.f32.bf16 	%r107, %rs38;
(EngineCore_DP0 pid=482156) 	.loc	1 185 27                        // quant_slide_tuned_Qwen2.5-7B.py:185:27
(EngineCore_DP0 pid=482156) 	mul.f32 	%r108, %r14, %r94;
(EngineCore_DP0 pid=482156) 	mul.f32 	%r109, %r14, %r95;
(EngineCore_DP0 pid=482156) 	mov.b32 	%r110, 0f43E00000;
(EngineCore_DP0 pid=482156) 	.loc	1 185 48                        // quant_slide_tuned_Qwen2.5-7B.py:185:48
(EngineCore_DP0 pid=482156) 	min.xorsign.abs.f32 	%r74, %r108, %r110;
(EngineCore_DP0 pid=482156) 	min.xorsign.abs.f32 	%r75, %r109, %r110;
(EngineCore_DP0 pid=482156) 	.loc	1 185 60                        // quant_slide_tuned_Qwen2.5-7B.py:185:60
(EngineCore_DP0 pid=482156) 	// begin inline asm
(EngineCore_DP0 pid=482156) 	cvt.rn.satfinite.e4m3x2.f32  %rs40, %r75, %r74; 
(EngineCore_DP0 pid=482156) 
(EngineCore_DP0 pid=482156) 	// end inline asm
(EngineCore_DP0 pid=482156) 	shr.u16 	%rs44, %rs40, 8;
(EngineCore_DP0 pid=482156) 	.loc	1 186 27                        // quant_slide_tuned_Qwen2.5-7B.py:186:27
(EngineCore_DP0 pid=482156) 	mul.f32 	%r111, %r14, %r98;
(EngineCore_DP0 pid=482156) 	mul.f32 	%r112, %r14, %r99;
(EngineCore_DP0 pid=482156) 	.loc	1 186 48                        // quant_slide_tuned_Qwen2.5-7B.py:186:48
(EngineCore_DP0 pid=482156) 	min.xorsign.abs.f32 	%r76, %r111, %r110;
(EngineCore_DP0 pid=482156) 	min.xorsign.abs.f32 	%r77, %r112, %r110;
(EngineCore_DP0 pid=482156) 	.loc	1 186 60                        // quant_slide_tuned_Qwen2.5-7B.py:186:60
(EngineCore_DP0 pid=482156) 	// begin inline asm
(EngineCore_DP0 pid=482156) 	cvt.rn.satfinite.e4m3x2.f32  %rs41, %r77, %r76; 
(EngineCore_DP0 pid=482156) 
(EngineCore_DP0 pid=482156) 	// end inline asm
(EngineCore_DP0 pid=482156) 	shr.u16 	%rs45, %rs41, 8;
(EngineCore_DP0 pid=482156) 	.loc	1 187 27                        // quant_slide_tuned_Qwen2.5-7B.py:187:27
(EngineCore_DP0 pid=482156) 	mul.f32 	%r113, %r14, %r102;
(EngineCore_DP0 pid=482156) 	mul.f32 	%r114, %r14, %r103;
(EngineCore_DP0 pid=482156) 	.loc	1 187 48                        // quant_slide_tuned_Qwen2.5-7B.py:187:48
(EngineCore_DP0 pid=482156) 	min.xorsign.abs.f32 	%r78, %r113, %r110;
(EngineCore_DP0 pid=482156) 	min.xorsign.abs.f32 	%r79, %r114, %r110;
(EngineCore_DP0 pid=482156) 	.loc	1 187 60                        // quant_slide_tuned_Qwen2.5-7B.py:187:60
(EngineCore_DP0 pid=482156) 	// begin inline asm
(EngineCore_DP0 pid=482156) 	cvt.rn.satfinite.e4m3x2.f32  %rs42, %r79, %r78; 
(EngineCore_DP0 pid=482156) 
(EngineCore_DP0 pid=482156) 	// end inline asm
(EngineCore_DP0 pid=482156) 	shr.u16 	%rs46, %rs42, 8;
(EngineCore_DP0 pid=482156) 	.loc	1 188 27                        // quant_slide_tuned_Qwen2.5-7B.py:188:27
(EngineCore_DP0 pid=482156) 	mul.f32 	%r115, %r14, %r106;
(EngineCore_DP0 pid=482156) 	mul.f32 	%r116, %r14, %r107;
(EngineCore_DP0 pid=482156) 	.loc	1 188 48                        // quant_slide_tuned_Qwen2.5-7B.py:188:48
(EngineCore_DP0 pid=482156) 	min.xorsign.abs.f32 	%r80, %r115, %r110;
(EngineCore_DP0 pid=482156) 	min.xorsign.abs.f32 	%r81, %r116, %r110;
(EngineCore_DP0 pid=482156) 	.loc	1 188 60                        // quant_slide_tuned_Qwen2.5-7B.py:188:60
(EngineCore_DP0 pid=482156) 	// begin inline asm
(EngineCore_DP0 pid=482156) 	cvt.rn.satfinite.e4m3x2.f32  %rs43, %r81, %r80; 
(EngineCore_DP0 pid=482156) 
(EngineCore_DP0 pid=482156) 	// end inline asm
(EngineCore_DP0 pid=482156) 	shr.u16 	%rs47, %rs43, 8;
(EngineCore_DP0 pid=482156) 	.loc	1 190 45                        // quant_slide_tuned_Qwen2.5-7B.py:190:45
(EngineCore_DP0 pid=482156) 	cvt.u32.u16 	%r117, %rs40;
(EngineCore_DP0 pid=482156) 	and.b32 	%r118, %r117, 255;
(EngineCore_DP0 pid=482156) 	cvt.u32.u16 	%r119, %rs44;
(EngineCore_DP0 pid=482156) 	.loc	1 192 45                        // quant_slide_tuned_Qwen2.5-7B.py:192:45
(EngineCore_DP0 pid=482156) 	cvt.u32.u16 	%r120, %rs42;
(EngineCore_DP0 pid=482156) 	and.b32 	%r121, %r120, 255;
(EngineCore_DP0 pid=482156) 	cvt.u32.u16 	%r122, %rs46;
(EngineCore_DP0 pid=482156) 	.loc	1 193 45                        // quant_slide_tuned_Qwen2.5-7B.py:193:45
(EngineCore_DP0 pid=482156) 	cvt.u32.u16 	%r123, %rs43;
(EngineCore_DP0 pid=482156) 	cvt.u32.u16 	%r124, %rs47;
(EngineCore_DP0 pid=482156) 	.loc	1 195 30                        // quant_slide_tuned_Qwen2.5-7B.py:195:30
(EngineCore_DP0 pid=482156) 	and.b16 	%rs48, %rs41, 255;
(EngineCore_DP0 pid=482156) 	mul.wide.u16 	%r125, %rs48, 256;
(EngineCore_DP0 pid=482156) 	mul.wide.u16 	%r126, %rs45, 256;
(EngineCore_DP0 pid=482156) 	.loc	1 195 24                        // quant_slide_tuned_Qwen2.5-7B.py:195:24
(EngineCore_DP0 pid=482156) 	or.b32 	%r127, %r125, %r118;
(EngineCore_DP0 pid=482156) 	or.b32 	%r128, %r126, %r119;
(EngineCore_DP0 pid=482156) 	.loc	1 195 42                        // quant_slide_tuned_Qwen2.5-7B.py:195:42
(EngineCore_DP0 pid=482156) 	shl.b32 	%r129, %r121, 16;
(EngineCore_DP0 pid=482156) 	shl.b32 	%r130, %r122, 16;
(EngineCore_DP0 pid=482156) 	.loc	1 195 36                        // quant_slide_tuned_Qwen2.5-7B.py:195:36
(EngineCore_DP0 pid=482156) 	or.b32 	%r131, %r127, %r129;
(EngineCore_DP0 pid=482156) 	or.b32 	%r132, %r128, %r130;
(EngineCore_DP0 pid=482156) 	.loc	1 195 55                        // quant_slide_tuned_Qwen2.5-7B.py:195:55
(EngineCore_DP0 pid=482156) 	shl.b32 	%r133, %r123, 24;
(EngineCore_DP0 pid=482156) 	shl.b32 	%r134, %r124, 24;
(EngineCore_DP0 pid=482156) 	.loc	1 195 49                        // quant_slide_tuned_Qwen2.5-7B.py:195:49
(EngineCore_DP0 pid=482156) 	or.b32 	%r82, %r131, %r133;
(EngineCore_DP0 pid=482156) 	or.b32 	%r83, %r132, %r134;
(EngineCore_DP0 pid=482156) 	.loc	1 196 29                        // quant_slide_tuned_Qwen2.5-7B.py:196:29
(EngineCore_DP0 pid=482156) 	mad.wide.s32 	%rd16, %r84, 4, %rd2;
(EngineCore_DP0 pid=482156) 	.loc	1 196 39                        // quant_slide_tuned_Qwen2.5-7B.py:196:39
(EngineCore_DP0 pid=482156) 	// begin inline asm
(EngineCore_DP0 pid=482156) 	@%p17 st.global.v2.b32 [ %rd16 + 0 ], { %r82, %r83 };
(EngineCore_DP0 pid=482156) 	// end inline asm
(EngineCore_DP0 pid=482156) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=482156) 	add.s32 	%r138, %r138, 1024;
(EngineCore_DP0 pid=482156) 	setp.lt.s32 	%p26, %r138, %r15;
(EngineCore_DP0 pid=482156) 	@%p26 bra 	$L__BB0_6;
(EngineCore_DP0 pid=482156) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=482156) 	.loc	1 167 4                         // quant_slide_tuned_Qwen2.5-7B.py:167:4
(EngineCore_DP0 pid=482156) 	ret;
(EngineCore_DP0 pid=482156) $L__tmp3:
(EngineCore_DP0 pid=482156) $L__func_end0:
(EngineCore_DP0 pid=482156)                                         // -- End function
(EngineCore_DP0 pid=482156) }
(EngineCore_DP0 pid=482156) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py"
(EngineCore_DP0 pid=482156) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=482156) 	.section	.debug_abbrev
(EngineCore_DP0 pid=482156) 	{
(EngineCore_DP0 pid=482156) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=482156) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=482156) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=482156) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=482156) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=482156) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=482156) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=482156) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=482156) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=482156) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=482156) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=482156) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=482156) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=482156) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=482156) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=482156) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=482156) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=482156) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=482156) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=482156) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=482156) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=482156) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=482156) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=482156) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=482156) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=482156) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=482156) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=482156) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=482156) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=482156) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=482156) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=482156) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=482156) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=482156) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=482156) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=482156) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=482156) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=482156) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=482156) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=482156) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=482156) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=482156) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=482156) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=482156) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=482156) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=482156) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=482156) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=482156) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=482156) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=482156) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=482156) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=482156) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=482156) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=482156) 	}
(EngineCore_DP0 pid=482156) 	.section	.debug_info
(EngineCore_DP0 pid=482156) 	{
(EngineCore_DP0 pid=482156) .b32 221                                // Length of Unit
(EngineCore_DP0 pid=482156) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=482156) .b8 0
(EngineCore_DP0 pid=482156) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=482156) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=482156) .b8 1                                   // Abbrev [1] 0xb:0xd6 DW_TAG_compile_unit
(EngineCore_DP0 pid=482156) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=482156) .b8 114
(EngineCore_DP0 pid=482156) .b8 105
(EngineCore_DP0 pid=482156) .b8 116
(EngineCore_DP0 pid=482156) .b8 111
(EngineCore_DP0 pid=482156) .b8 110
(EngineCore_DP0 pid=482156) .b8 0
(EngineCore_DP0 pid=482156) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=482156) .b8 0
(EngineCore_DP0 pid=482156) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=482156) .b8 117
(EngineCore_DP0 pid=482156) .b8 97
(EngineCore_DP0 pid=482156) .b8 110
(EngineCore_DP0 pid=482156) .b8 116
(EngineCore_DP0 pid=482156) .b8 95
(EngineCore_DP0 pid=482156) .b8 115
(EngineCore_DP0 pid=482156) .b8 108
(EngineCore_DP0 pid=482156) .b8 105
(EngineCore_DP0 pid=482156) .b8 100
(EngineCore_DP0 pid=482156) .b8 101
(EngineCore_DP0 pid=482156) .b8 95
(EngineCore_DP0 pid=482156) .b8 116
(EngineCore_DP0 pid=482156) .b8 117
(EngineCore_DP0 pid=482156) .b8 110
(EngineCore_DP0 pid=482156) .b8 101
(EngineCore_DP0 pid=482156) .b8 100
(EngineCore_DP0 pid=482156) .b8 95
(EngineCore_DP0 pid=482156) .b8 81
(EngineCore_DP0 pid=482156) .b8 119
(EngineCore_DP0 pid=482156) .b8 101
(EngineCore_DP0 pid=482156) .b8 110
(EngineCore_DP0 pid=482156) .b8 50
(EngineCore_DP0 pid=482156) .b8 46
(EngineCore_DP0 pid=482156) .b8 53
(EngineCore_DP0 pid=482156) .b8 45
(EngineCore_DP0 pid=482156) .b8 55
(EngineCore_DP0 pid=482156) .b8 66
(EngineCore_DP0 pid=482156) .b8 46
(EngineCore_DP0 pid=482156) .b8 112
(EngineCore_DP0 pid=482156) .b8 121
(EngineCore_DP0 pid=482156) .b8 0
(EngineCore_DP0 pid=482156) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=482156) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=482156) .b8 114
(EngineCore_DP0 pid=482156) .b8 111
(EngineCore_DP0 pid=482156) .b8 111
(EngineCore_DP0 pid=482156) .b8 116
(EngineCore_DP0 pid=482156) .b8 47
(EngineCore_DP0 pid=482156) .b8 118
(EngineCore_DP0 pid=482156) .b8 108
(EngineCore_DP0 pid=482156) .b8 108
(EngineCore_DP0 pid=482156) .b8 109
(EngineCore_DP0 pid=482156) .b8 98
(EngineCore_DP0 pid=482156) .b8 101
(EngineCore_DP0 pid=482156) .b8 110
(EngineCore_DP0 pid=482156) .b8 99
(EngineCore_DP0 pid=482156) .b8 104
(EngineCore_DP0 pid=482156) .b8 47
(EngineCore_DP0 pid=482156) .b8 115
(EngineCore_DP0 pid=482156) .b8 108
(EngineCore_DP0 pid=482156) .b8 105
(EngineCore_DP0 pid=482156) .b8 100
(EngineCore_DP0 pid=482156) .b8 101
(EngineCore_DP0 pid=482156) .b8 115
(EngineCore_DP0 pid=482156) .b8 112
(EngineCore_DP0 pid=482156) .b8 97
(EngineCore_DP0 pid=482156) .b8 114
(EngineCore_DP0 pid=482156) .b8 115
(EngineCore_DP0 pid=482156) .b8 101
(EngineCore_DP0 pid=482156) .b8 47
(EngineCore_DP0 pid=482156) .b8 99
(EngineCore_DP0 pid=482156) .b8 115
(EngineCore_DP0 pid=482156) .b8 114
(EngineCore_DP0 pid=482156) .b8 99
(EngineCore_DP0 pid=482156) .b8 47
(EngineCore_DP0 pid=482156) .b8 102
(EngineCore_DP0 pid=482156) .b8 117
(EngineCore_DP0 pid=482156) .b8 115
(EngineCore_DP0 pid=482156) .b8 101
(EngineCore_DP0 pid=482156) .b8 100
(EngineCore_DP0 pid=482156) .b8 95
(EngineCore_DP0 pid=482156) .b8 113
(EngineCore_DP0 pid=482156) .b8 117
(EngineCore_DP0 pid=482156) .b8 97
(EngineCore_DP0 pid=482156) .b8 110
(EngineCore_DP0 pid=482156) .b8 116
(EngineCore_DP0 pid=482156) .b8 95
(EngineCore_DP0 pid=482156) .b8 115
(EngineCore_DP0 pid=482156) .b8 108
(EngineCore_DP0 pid=482156) .b8 105
(EngineCore_DP0 pid=482156) .b8 100
(EngineCore_DP0 pid=482156) .b8 101
(EngineCore_DP0 pid=482156) .b8 95
(EngineCore_DP0 pid=482156) .b8 116
(EngineCore_DP0 pid=482156) .b8 114
(EngineCore_DP0 pid=482156) .b8 105
(EngineCore_DP0 pid=482156) .b8 116
(EngineCore_DP0 pid=482156) .b8 111
(EngineCore_DP0 pid=482156) .b8 110
(EngineCore_DP0 pid=482156) .b8 47
(EngineCore_DP0 pid=482156) .b8 98
(EngineCore_DP0 pid=482156) .b8 117
(EngineCore_DP0 pid=482156) .b8 105
(EngineCore_DP0 pid=482156) .b8 108
(EngineCore_DP0 pid=482156) .b8 100
(EngineCore_DP0 pid=482156) .b8 47
(EngineCore_DP0 pid=482156) .b8 71
(EngineCore_DP0 pid=482156) .b8 66
(EngineCore_DP0 pid=482156) .b8 49
(EngineCore_DP0 pid=482156) .b8 48
(EngineCore_DP0 pid=482156) .b8 95
(EngineCore_DP0 pid=482156) .b8 99
(EngineCore_DP0 pid=482156) .b8 99
(EngineCore_DP0 pid=482156) .b8 49
(EngineCore_DP0 pid=482156) .b8 50
(EngineCore_DP0 pid=482156) .b8 49
(EngineCore_DP0 pid=482156) .b8 95
(EngineCore_DP0 pid=482156) .b8 112
(EngineCore_DP0 pid=482156) .b8 121
(EngineCore_DP0 pid=482156) .b8 51
(EngineCore_DP0 pid=482156) .b8 49
(EngineCore_DP0 pid=482156) .b8 50
(EngineCore_DP0 pid=482156) .b8 95
(EngineCore_DP0 pid=482156) .b8 99
(EngineCore_DP0 pid=482156) .b8 117
(EngineCore_DP0 pid=482156) .b8 49
(EngineCore_DP0 pid=482156) .b8 50
(EngineCore_DP0 pid=482156) .b8 57
(EngineCore_DP0 pid=482156) .b8 95
(EngineCore_DP0 pid=482156) .b8 97
(EngineCore_DP0 pid=482156) .b8 97
(EngineCore_DP0 pid=482156) .b8 114
(EngineCore_DP0 pid=482156) .b8 99
(EngineCore_DP0 pid=482156) .b8 104
(EngineCore_DP0 pid=482156) .b8 54
(EngineCore_DP0 pid=482156) .b8 52
(EngineCore_DP0 pid=482156) .b8 0
(EngineCore_DP0 pid=482156) .b8 2                                   // Abbrev [2] 0x98:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=482156) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=482156) .b8 113
(EngineCore_DP0 pid=482156) .b8 117
(EngineCore_DP0 pid=482156) .b8 97
(EngineCore_DP0 pid=482156) .b8 110
(EngineCore_DP0 pid=482156) .b8 116
(EngineCore_DP0 pid=482156) .b8 95
(EngineCore_DP0 pid=482156) .b8 115
(EngineCore_DP0 pid=482156) .b8 108
(EngineCore_DP0 pid=482156) .b8 105
(EngineCore_DP0 pid=482156) .b8 100
(EngineCore_DP0 pid=482156) .b8 101
(EngineCore_DP0 pid=482156) .b8 95
(EngineCore_DP0 pid=482156) .b8 102
(EngineCore_DP0 pid=482156) .b8 112
(EngineCore_DP0 pid=482156) .b8 56
(EngineCore_DP0 pid=482156) .b8 95
(EngineCore_DP0 pid=482156) .b8 107
(EngineCore_DP0 pid=482156) .b8 101
(EngineCore_DP0 pid=482156) .b8 114
(EngineCore_DP0 pid=482156) .b8 110
(EngineCore_DP0 pid=482156) .b8 101
(EngineCore_DP0 pid=482156) .b8 108
(EngineCore_DP0 pid=482156) .b8 0
(EngineCore_DP0 pid=482156) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=482156) .b8 3                                   // Abbrev [3] 0xb2:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=482156) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=482156) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=482156) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=482156) .b8 4                                   // Abbrev [4] 0xc7:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=482156) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=482156) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=482156) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=482156) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=482156) .b8 157                                 // DW_AT_call_line
(EngineCore_DP0 pid=482156) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=482156) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=482156) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=482156) 	}
(EngineCore_DP0 pid=482156) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=482156) 
(EngineCore_DP0 pid=482156) ================================================================
(EngineCore_DP0 pid=482156) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=482156) 
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpo_pzp1cc.ptx', '-o', '/tmp/tmpo_pzp1cc.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866] 
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866] 
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866] 
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpo_pzp1cc.ptx -o /tmp/tmpo_pzp1cc.ptx.o
(EngineCore_DP0 pid=482156) ERROR 01-25 21:33:36 [core.py:866] 

STDERR:
[2026-01-25 21:32:33] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:32:33] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:32:33] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:32:33] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:32:33] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:32:33] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:32:33] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:32:33] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:32:33] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:32:33] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:32:33] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:32:33] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:32:33] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:32:33] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:32:37] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:32:37] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:32:37] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:32:37] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:32:37] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:32:37] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:32:37] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:32:37] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:32:37] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:32:37] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:32:37] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:32:37] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:32:37] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:32:37] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=482156) [2026-01-25 21:32:38] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=482156) [2026-01-25 21:32:38] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=482156) [2026-01-25 21:32:38] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=482156) [2026-01-25 21:32:38] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=482156) [2026-01-25 21:32:38] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=482156) [2026-01-25 21:32:38] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=482156) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=482156) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:23<00:23, 23.34s/it]
(EngineCore_DP0 pid=482156) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:56<00:00, 28.94s/it]
(EngineCore_DP0 pid=482156) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:56<00:00, 28.10s/it]
(EngineCore_DP0 pid=482156) 
(EngineCore_DP0 pid=482156) [2026-01-25 21:33:35] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=482156) [2026-01-25 21:33:35] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 13860864 bytes
(EngineCore_DP0 pid=482156) [2026-01-25 21:33:35] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=482156) [2026-01-25 21:33:35] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10780672 bytes
(EngineCore_DP0 pid=482156) [2026-01-25 21:33:35] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=482156) [2026-01-25 21:33:35] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 113967104 bytes
(EngineCore_DP0 pid=482156) [2026-01-25 21:33:35] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=482156) [2026-01-25 21:33:35] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 56655872 bytes
(EngineCore_DP0 pid=482156) Process EngineCore_DP0:
(EngineCore_DP0 pid=482156) Traceback (most recent call last):
(EngineCore_DP0 pid=482156)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=482156)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=482156)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=482156)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=482156) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpo_pzp1cc.ptx', '-o', '/tmp/tmpo_pzp1cc.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=482156) 
(EngineCore_DP0 pid=482156) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=482156) 
(EngineCore_DP0 pid=482156) Traceback (most recent call last):
(EngineCore_DP0 pid=482156)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=482156)     self.run()
(EngineCore_DP0 pid=482156)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=482156)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=482156)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=482156)     raise e
(EngineCore_DP0 pid=482156)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=482156)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=482156)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=482156)     super().__init__(
(EngineCore_DP0 pid=482156)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=482156)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=482156)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=482156)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=482156)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=482156)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=482156)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=482156)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=482156)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=482156)     return func(*args, **kwargs)
(EngineCore_DP0 pid=482156)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=482156)     return func(*args, **kwargs)
(EngineCore_DP0 pid=482156)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=482156)     self.model_runner.profile_run()
(EngineCore_DP0 pid=482156)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=482156)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=482156)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=482156)     return func(*args, **kwargs)
(EngineCore_DP0 pid=482156)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=482156)     outputs = self.model(
(EngineCore_DP0 pid=482156)               ^^^^^^^^^^^
(EngineCore_DP0 pid=482156)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=482156)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=482156)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=482156)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=482156)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=482156)     hidden_states = self.model(
(EngineCore_DP0 pid=482156)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=482156)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=482156)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=482156)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=482156)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=482156)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=482156)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=482156)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=482156)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=482156)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=482156)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=482156)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=482156)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=482156)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=482156)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=482156)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=482156)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=482156)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=482156)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=482156)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=482156)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=482156)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=482156)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=482156)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=482156)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=482156)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=482156)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=482156)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=482156)     return self._linear_fn(
(EngineCore_DP0 pid=482156)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=482156)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=482156)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=482156)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=482156)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=482156)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=482156)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=482156)     return fn(input, L)
(EngineCore_DP0 pid=482156)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=482156)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=482156)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=482156)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=482156)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=482156)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=482156)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=482156)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=482156)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=482156)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=482156)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=482156)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=482156)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=482156)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=482156)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=482156)     raise PTXASError(error)
(EngineCore_DP0 pid=482156) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=482156) `ptxas` stderr:
(EngineCore_DP0 pid=482156) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=482156) 
(EngineCore_DP0 pid=482156) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpo_pzp1cc.ptx -o /tmp/tmpo_pzp1cc.ptx.o
(EngineCore_DP0 pid=482156) 
[rank0]:[W125 21:33:37.219611009 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=32768

========== M=65536 ==========
Time: 2026-01-25 21:33:38
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Qwen2.5-7B-FP8_M65536.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:34:11 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 21:34:11 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=483676) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=483676) 
(EngineCore_DP0 pid=483676) 
(EngineCore_DP0 pid=483676) ================================================================
(EngineCore_DP0 pid=483676) Internal Triton PTX codegen error
(EngineCore_DP0 pid=483676) `ptxas` stderr:
(EngineCore_DP0 pid=483676) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=483676) 
(EngineCore_DP0 pid=483676) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpvccue8qz.ptx -o /tmp/tmpvccue8qz.ptx.o
(EngineCore_DP0 pid=483676) 
(EngineCore_DP0 pid=483676) 
(EngineCore_DP0 pid=483676) //
(EngineCore_DP0 pid=483676) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=483676) //
(EngineCore_DP0 pid=483676) 
(EngineCore_DP0 pid=483676) .version 8.7
(EngineCore_DP0 pid=483676) .target sm_121a
(EngineCore_DP0 pid=483676) .address_size 64
(EngineCore_DP0 pid=483676) 
(EngineCore_DP0 pid=483676) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=483676) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=483676)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=483676) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=483676) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=483676) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=483676) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=483676) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=483676) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=483676) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=483676) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=483676) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=483676) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=483676) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=483676) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=483676) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=483676) )
(EngineCore_DP0 pid=483676) .reqntid 512
(EngineCore_DP0 pid=483676) {
(EngineCore_DP0 pid=483676) 	.reg .pred 	%p<21>;
(EngineCore_DP0 pid=483676) 	.reg .b16 	%rs<61>;
(EngineCore_DP0 pid=483676) 	.reg .b32 	%r<126>;
(EngineCore_DP0 pid=483676) 	.reg .b64 	%rd<14>;
(EngineCore_DP0 pid=483676) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=483676) $L__func_begin0:
(EngineCore_DP0 pid=483676) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=483676) 
(EngineCore_DP0 pid=483676) // %bb.0:
(EngineCore_DP0 pid=483676) 	ld.param.b32 	%r20, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=483676) 	ld.param.b32 	%r19, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=483676) 	ld.param.b32 	%r18, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=483676) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=483676) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=483676) $L__tmp0:
(EngineCore_DP0 pid=483676) 	.loc	1 143 24                        // quant_slide_tuned_Qwen2.5-7B.py:143:24
(EngineCore_DP0 pid=483676) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=483676) 	ld.param.b32 	%r22, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=483676) 	.loc	1 148 26                        // quant_slide_tuned_Qwen2.5-7B.py:148:26
(EngineCore_DP0 pid=483676) 	mul.lo.s32 	%r23, %r22, %r1;
(EngineCore_DP0 pid=483676) 	.loc	1 148 20                        // quant_slide_tuned_Qwen2.5-7B.py:148:20
(EngineCore_DP0 pid=483676) 	mad.wide.s32 	%rd1, %r23, 2, %rd4;
(EngineCore_DP0 pid=483676) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=483676) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=483676) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=483676) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=483676) 	setp.lt.s32 	%p1, %r19, 1;
(EngineCore_DP0 pid=483676) 	mov.b32 	%r124, 0f2B8CBCCC;
(EngineCore_DP0 pid=483676) 	setp.eq.b32 	%p20, %r2, 0;
(EngineCore_DP0 pid=483676) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=483676) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=483676) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=483676) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=483676) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=483676) 	shr.u32 	%r32, %r2, 3;
(EngineCore_DP0 pid=483676) 	and.b32 	%r33, %r32, 60;
(EngineCore_DP0 pid=483676) 	mov.b32 	%r34, global_smem;
(EngineCore_DP0 pid=483676) 	add.s32 	%r52, %r34, %r33;
(EngineCore_DP0 pid=483676) 	shl.b32 	%r35, %r2, 2;
(EngineCore_DP0 pid=483676) 	add.s32 	%r55, %r34, %r35;
(EngineCore_DP0 pid=483676) 	mov.b32 	%r40, 0;
(EngineCore_DP0 pid=483676) 	mov.b32 	%r122, 0f00000000;
(EngineCore_DP0 pid=483676) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=483676) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=483676) 	mov.b32 	%r123, %r40;
(EngineCore_DP0 pid=483676) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=483676) 	.loc	1 154 19                        // quant_slide_tuned_Qwen2.5-7B.py:154:19
(EngineCore_DP0 pid=483676) 	add.s32 	%r58, %r4, %r123;
(EngineCore_DP0 pid=483676) 	.loc	1 155 22                        // quant_slide_tuned_Qwen2.5-7B.py:155:22
(EngineCore_DP0 pid=483676) 	add.s32 	%r59, %r58, 4096;
(EngineCore_DP0 pid=483676) 	setp.lt.s32 	%p2, %r58, %r18;
(EngineCore_DP0 pid=483676) 	setp.lt.s32 	%p3, %r59, %r18;
(EngineCore_DP0 pid=483676) 	.loc	1 156 29                        // quant_slide_tuned_Qwen2.5-7B.py:156:29
(EngineCore_DP0 pid=483676) 	mad.wide.s32 	%rd6, %r58, 2, %rd1;
(EngineCore_DP0 pid=483676) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=483676) 	.loc	1 156 21                        // quant_slide_tuned_Qwen2.5-7B.py:156:21
(EngineCore_DP0 pid=483676) 	// begin inline asm
(EngineCore_DP0 pid=483676) 	mov.u32 %r36, %r40;
(EngineCore_DP0 pid=483676) 	mov.u32 %r37, %r40;
(EngineCore_DP0 pid=483676) 	mov.u32 %r38, %r40;
(EngineCore_DP0 pid=483676) 	mov.u32 %r39, %r40;
(EngineCore_DP0 pid=483676) 	@%p2 ld.global.v4.b32 { %r36, %r37, %r38, %r39 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=483676) 	// end inline asm
(EngineCore_DP0 pid=483676) 	mov.b32 	{%rs1, %rs2}, %r36;
(EngineCore_DP0 pid=483676) 	mov.b32 	{%rs3, %rs4}, %r37;
(EngineCore_DP0 pid=483676) 	mov.b32 	{%rs5, %rs6}, %r38;
(EngineCore_DP0 pid=483676) 	mov.b32 	{%rs7, %rs8}, %r39;
(EngineCore_DP0 pid=483676) 	// begin inline asm
(EngineCore_DP0 pid=483676) 	mov.u32 %r44, %r40;
(EngineCore_DP0 pid=483676) 	mov.u32 %r45, %r40;
(EngineCore_DP0 pid=483676) 	mov.u32 %r46, %r40;
(EngineCore_DP0 pid=483676) 	mov.u32 %r47, %r40;
(EngineCore_DP0 pid=483676) 	@%p3 ld.global.v4.b32 { %r44, %r45, %r46, %r47 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=483676) 	// end inline asm
(EngineCore_DP0 pid=483676) 	mov.b32 	{%rs9, %rs10}, %r44;
(EngineCore_DP0 pid=483676) 	mov.b32 	{%rs11, %rs12}, %r45;
(EngineCore_DP0 pid=483676) 	mov.b32 	{%rs13, %rs14}, %r46;
(EngineCore_DP0 pid=483676) 	mov.b32 	{%rs15, %rs16}, %r47;
(EngineCore_DP0 pid=483676) 	.loc	1 157 50                        // quant_slide_tuned_Qwen2.5-7B.py:157:50
(EngineCore_DP0 pid=483676) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=483676) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=483676) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=483676) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=483676) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=483676) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=483676) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=483676) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=483676) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=483676) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=483676) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=483676) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=483676) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=483676) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=483676) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=483676) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=483676) $L__tmp1:
(EngineCore_DP0 pid=483676) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=483676) 	bar.sync 	0;
(EngineCore_DP0 pid=483676) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=483676) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=483676) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=483676) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=483676) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=483676) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=483676) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=483676) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=483676) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=483676) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=483676) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=483676) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=483676) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=483676) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=483676) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=483676) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=483676) 	cvt.f32.bf16 	%r60, %rs47;
(EngineCore_DP0 pid=483676) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=483676) 	shfl.sync.bfly.b32 	%r61, %r60, 16, 31, -1;
(EngineCore_DP0 pid=483676) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=483676) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=483676) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=483676) 	shfl.sync.bfly.b32 	%r63, %r62, 8, 31, -1;
(EngineCore_DP0 pid=483676) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=483676) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=483676) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=483676) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=483676) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=483676) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=483676) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=483676) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=483676) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=483676) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=483676) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=483676) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=483676) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=483676) 	max.f32 	%r53, %r68, %r69;
(EngineCore_DP0 pid=483676) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=483676) 	// begin inline asm
(EngineCore_DP0 pid=483676) 	@%p4 st.shared.b32 [ %r52 + 0 ], %r53;
(EngineCore_DP0 pid=483676) 	// end inline asm
(EngineCore_DP0 pid=483676) 	bar.sync 	0;
(EngineCore_DP0 pid=483676) 	// begin inline asm
(EngineCore_DP0 pid=483676) 	@%p5 ld.shared.b32 %r54, [ %r55 + 0 ];
(EngineCore_DP0 pid=483676) 	// end inline asm
(EngineCore_DP0 pid=483676) 	shfl.sync.bfly.b32 	%r70, %r54, 8, 31, -1;
(EngineCore_DP0 pid=483676) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=483676) 	max.f32 	%r71, %r54, %r70;
(EngineCore_DP0 pid=483676) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=483676) 	shfl.sync.bfly.b32 	%r72, %r71, 4, 31, -1;
(EngineCore_DP0 pid=483676) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=483676) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=483676) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=483676) 	shfl.sync.bfly.b32 	%r74, %r73, 2, 31, -1;
(EngineCore_DP0 pid=483676) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=483676) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=483676) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=483676) 	shfl.sync.bfly.b32 	%r76, %r75, 1, 31, -1;
(EngineCore_DP0 pid=483676) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=483676) 	max.f32 	%r57, %r75, %r76;
(EngineCore_DP0 pid=483676) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=483676) 	// begin inline asm
(EngineCore_DP0 pid=483676) 	@%p20 st.shared.b32 [ %r55 + 0 ], %r57;
(EngineCore_DP0 pid=483676) 	// end inline asm
(EngineCore_DP0 pid=483676) 	bar.sync 	0;
(EngineCore_DP0 pid=483676) 	ld.shared.b32 	%r77, [global_smem];
(EngineCore_DP0 pid=483676) $L__tmp2:
(EngineCore_DP0 pid=483676) 	.loc	1 157 36                        // quant_slide_tuned_Qwen2.5-7B.py:157:36
(EngineCore_DP0 pid=483676) 	max.f32 	%r122, %r122, %r77;
(EngineCore_DP0 pid=483676) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=483676) 	add.s32 	%r123, %r123, 8192;
(EngineCore_DP0 pid=483676) 	setp.lt.s32 	%p7, %r123, %r19;
(EngineCore_DP0 pid=483676) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=483676) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=483676) 	.loc	1 159 32                        // quant_slide_tuned_Qwen2.5-7B.py:159:32
(EngineCore_DP0 pid=483676) 	max.f32 	%r124, %r122, 0f2B8CBCCC;
(EngineCore_DP0 pid=483676) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=483676) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-7B.py:0:32
(EngineCore_DP0 pid=483676) 	mov.b32 	%r79, 0f43E00000;
(EngineCore_DP0 pid=483676) 	.loc	1 160 32                        // quant_slide_tuned_Qwen2.5-7B.py:160:32
(EngineCore_DP0 pid=483676) 	div.full.f32 	%r80, %r124, %r79;
(EngineCore_DP0 pid=483676) 	.loc	1 160 41                        // quant_slide_tuned_Qwen2.5-7B.py:160:41
(EngineCore_DP0 pid=483676) 	max.f32 	%r78, %r80, 0f36924925;
(EngineCore_DP0 pid=483676) 	.loc	1 162 25                        // quant_slide_tuned_Qwen2.5-7B.py:162:25
(EngineCore_DP0 pid=483676) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=483676) 	.loc	1 162 30                        // quant_slide_tuned_Qwen2.5-7B.py:162:30
(EngineCore_DP0 pid=483676) 	// begin inline asm
(EngineCore_DP0 pid=483676) 	@%p20 st.global.b32 [ %rd8 + 0 ], { %r78 };
(EngineCore_DP0 pid=483676) 	// end inline asm
(EngineCore_DP0 pid=483676) 	.loc	1 165 29                        // quant_slide_tuned_Qwen2.5-7B.py:165:29
(EngineCore_DP0 pid=483676) 	shl.b32 	%r15, %r20, 1;
(EngineCore_DP0 pid=483676) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=483676) 	setp.lt.s32 	%p9, %r15, 1;
(EngineCore_DP0 pid=483676) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=483676) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=483676) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-7B.py:0:41
(EngineCore_DP0 pid=483676) 	ld.param.b32 	%r24, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=483676) 	shr.s32 	%r25, %r24, 31;
(EngineCore_DP0 pid=483676) 	shr.u32 	%r26, %r25, 30;
(EngineCore_DP0 pid=483676) 	add.s32 	%r27, %r24, %r26;
(EngineCore_DP0 pid=483676) 	shr.s32 	%r28, %r27, 2;
(EngineCore_DP0 pid=483676) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=483676) 	mul.lo.s32 	%r29, %r28, %r1;
(EngineCore_DP0 pid=483676) 	mad.wide.s32 	%rd2, %r29, 4, %rd5;
(EngineCore_DP0 pid=483676) 	div.full.f32 	%r14, %r79, %r124;
(EngineCore_DP0 pid=483676) 	mov.b32 	%r125, 0;
(EngineCore_DP0 pid=483676) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=483676)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=483676) 	.loc	1 169 30                        // quant_slide_tuned_Qwen2.5-7B.py:169:30
(EngineCore_DP0 pid=483676) 	add.s32 	%r92, %r3, %r125;
(EngineCore_DP0 pid=483676) 	setp.lt.s32 	%p14, %r92, %r15;
(EngineCore_DP0 pid=483676) 	.loc	1 172 24                        // quant_slide_tuned_Qwen2.5-7B.py:172:24
(EngineCore_DP0 pid=483676) 	shr.u32 	%r93, %r92, 31;
(EngineCore_DP0 pid=483676) 	add.s32 	%r94, %r92, %r93;
(EngineCore_DP0 pid=483676) 	shr.u32 	%r95, %r94, 1;
(EngineCore_DP0 pid=483676) 	.loc	1 173 23                        // quant_slide_tuned_Qwen2.5-7B.py:173:23
(EngineCore_DP0 pid=483676) 	and.b32 	%r96, %r94, 2147483646;
(EngineCore_DP0 pid=483676) 	sub.s32 	%r97, %r92, %r96;
(EngineCore_DP0 pid=483676) 	.loc	1 174 30                        // quant_slide_tuned_Qwen2.5-7B.py:174:30
(EngineCore_DP0 pid=483676) 	shl.b32 	%r98, %r97, 1;
(EngineCore_DP0 pid=483676) 	.loc	1 174 26                        // quant_slide_tuned_Qwen2.5-7B.py:174:26
(EngineCore_DP0 pid=483676) 	mad.lo.s32 	%r99, %r95, 6, %r98;
(EngineCore_DP0 pid=483676) 	.loc	1 177 53                        // quant_slide_tuned_Qwen2.5-7B.py:177:53
(EngineCore_DP0 pid=483676) 	setp.lt.s32 	%p15, %r99, %r18;
(EngineCore_DP0 pid=483676) 	.loc	1 177 37                        // quant_slide_tuned_Qwen2.5-7B.py:177:37
(EngineCore_DP0 pid=483676) 	and.pred 	%p10, %p14, %p15;
(EngineCore_DP0 pid=483676) 	.loc	1 176 29                        // quant_slide_tuned_Qwen2.5-7B.py:176:29
(EngineCore_DP0 pid=483676) 	mad.wide.s32 	%rd9, %r99, 2, %rd1;
(EngineCore_DP0 pid=483676) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=483676) 	.loc	1 176 21                        // quant_slide_tuned_Qwen2.5-7B.py:176:21
(EngineCore_DP0 pid=483676) 	// begin inline asm
(EngineCore_DP0 pid=483676) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=483676) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=483676) 	// end inline asm
(EngineCore_DP0 pid=483676) 	.loc	1 177 79                        // quant_slide_tuned_Qwen2.5-7B.py:177:79
(EngineCore_DP0 pid=483676) 	cvt.f32.bf16 	%r100, %rs48;
(EngineCore_DP0 pid=483676) 	.loc	1 179 48                        // quant_slide_tuned_Qwen2.5-7B.py:179:48
(EngineCore_DP0 pid=483676) 	or.b32 	%r101, %r99, 1;
(EngineCore_DP0 pid=483676) 	.loc	1 179 53                        // quant_slide_tuned_Qwen2.5-7B.py:179:53
(EngineCore_DP0 pid=483676) 	setp.lt.s32 	%p16, %r101, %r18;
(EngineCore_DP0 pid=483676) 	.loc	1 179 37                        // quant_slide_tuned_Qwen2.5-7B.py:179:37
(EngineCore_DP0 pid=483676) 	and.pred 	%p11, %p14, %p16;
(EngineCore_DP0 pid=483676) 	.loc	1 178 39                        // quant_slide_tuned_Qwen2.5-7B.py:178:39
(EngineCore_DP0 pid=483676) 	add.s64 	%rd10, %rd9, 2;
(EngineCore_DP0 pid=483676) 	.loc	1 178 21                        // quant_slide_tuned_Qwen2.5-7B.py:178:21
(EngineCore_DP0 pid=483676) 	// begin inline asm
(EngineCore_DP0 pid=483676) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=483676) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=483676) 	// end inline asm
(EngineCore_DP0 pid=483676) 	.loc	1 179 79                        // quant_slide_tuned_Qwen2.5-7B.py:179:79
(EngineCore_DP0 pid=483676) 	cvt.f32.bf16 	%r102, %rs50;
(EngineCore_DP0 pid=483676) 	.loc	1 181 48                        // quant_slide_tuned_Qwen2.5-7B.py:181:48
(EngineCore_DP0 pid=483676) 	add.s32 	%r103, %r99, 2;
(EngineCore_DP0 pid=483676) 	.loc	1 181 53                        // quant_slide_tuned_Qwen2.5-7B.py:181:53
(EngineCore_DP0 pid=483676) 	setp.lt.s32 	%p17, %r103, %r18;
(EngineCore_DP0 pid=483676) 	.loc	1 181 37                        // quant_slide_tuned_Qwen2.5-7B.py:181:37
(EngineCore_DP0 pid=483676) 	and.pred 	%p12, %p14, %p17;
(EngineCore_DP0 pid=483676) 	.loc	1 180 39                        // quant_slide_tuned_Qwen2.5-7B.py:180:39
(EngineCore_DP0 pid=483676) 	add.s64 	%rd11, %rd9, 4;
(EngineCore_DP0 pid=483676) 	.loc	1 180 21                        // quant_slide_tuned_Qwen2.5-7B.py:180:21
(EngineCore_DP0 pid=483676) 	// begin inline asm
(EngineCore_DP0 pid=483676) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=483676) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=483676) 	// end inline asm
(EngineCore_DP0 pid=483676) 	.loc	1 181 79                        // quant_slide_tuned_Qwen2.5-7B.py:181:79
(EngineCore_DP0 pid=483676) 	cvt.f32.bf16 	%r104, %rs52;
(EngineCore_DP0 pid=483676) 	.loc	1 183 48                        // quant_slide_tuned_Qwen2.5-7B.py:183:48
(EngineCore_DP0 pid=483676) 	add.s32 	%r105, %r99, 3;
(EngineCore_DP0 pid=483676) 	.loc	1 183 53                        // quant_slide_tuned_Qwen2.5-7B.py:183:53
(EngineCore_DP0 pid=483676) 	setp.lt.s32 	%p18, %r105, %r18;
(EngineCore_DP0 pid=483676) 	.loc	1 183 37                        // quant_slide_tuned_Qwen2.5-7B.py:183:37
(EngineCore_DP0 pid=483676) 	and.pred 	%p13, %p14, %p18;
(EngineCore_DP0 pid=483676) 	.loc	1 182 39                        // quant_slide_tuned_Qwen2.5-7B.py:182:39
(EngineCore_DP0 pid=483676) 	add.s64 	%rd12, %rd9, 6;
(EngineCore_DP0 pid=483676) 	.loc	1 182 21                        // quant_slide_tuned_Qwen2.5-7B.py:182:21
(EngineCore_DP0 pid=483676) 	// begin inline asm
(EngineCore_DP0 pid=483676) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=483676) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=483676) 	// end inline asm
(EngineCore_DP0 pid=483676) 	.loc	1 183 79                        // quant_slide_tuned_Qwen2.5-7B.py:183:79
(EngineCore_DP0 pid=483676) 	cvt.f32.bf16 	%r106, %rs54;
(EngineCore_DP0 pid=483676) 	.loc	1 185 27                        // quant_slide_tuned_Qwen2.5-7B.py:185:27
(EngineCore_DP0 pid=483676) 	mul.f32 	%r107, %r14, %r100;
(EngineCore_DP0 pid=483676) 	mov.b32 	%r108, 0f43E00000;
(EngineCore_DP0 pid=483676) 	.loc	1 185 48                        // quant_slide_tuned_Qwen2.5-7B.py:185:48
(EngineCore_DP0 pid=483676) 	min.xorsign.abs.f32 	%r82, %r107, %r108;
(EngineCore_DP0 pid=483676) 	.loc	1 185 60                        // quant_slide_tuned_Qwen2.5-7B.py:185:60
(EngineCore_DP0 pid=483676) 	// begin inline asm
(EngineCore_DP0 pid=483676) 	cvt.rn.satfinite.e4m3x2.f32  %rs56, %r83, %r82; 
(EngineCore_DP0 pid=483676) 
(EngineCore_DP0 pid=483676) 	// end inline asm
(EngineCore_DP0 pid=483676) 	.loc	1 186 27                        // quant_slide_tuned_Qwen2.5-7B.py:186:27
(EngineCore_DP0 pid=483676) 	mul.f32 	%r109, %r14, %r102;
(EngineCore_DP0 pid=483676) 	.loc	1 186 48                        // quant_slide_tuned_Qwen2.5-7B.py:186:48
(EngineCore_DP0 pid=483676) 	min.xorsign.abs.f32 	%r84, %r109, %r108;
(EngineCore_DP0 pid=483676) 	.loc	1 186 60                        // quant_slide_tuned_Qwen2.5-7B.py:186:60
(EngineCore_DP0 pid=483676) 	// begin inline asm
(EngineCore_DP0 pid=483676) 	cvt.rn.satfinite.e4m3x2.f32  %rs57, %r85, %r84; 
(EngineCore_DP0 pid=483676) 
(EngineCore_DP0 pid=483676) 	// end inline asm
(EngineCore_DP0 pid=483676) 	.loc	1 187 27                        // quant_slide_tuned_Qwen2.5-7B.py:187:27
(EngineCore_DP0 pid=483676) 	mul.f32 	%r110, %r14, %r104;
(EngineCore_DP0 pid=483676) 	.loc	1 187 48                        // quant_slide_tuned_Qwen2.5-7B.py:187:48
(EngineCore_DP0 pid=483676) 	min.xorsign.abs.f32 	%r86, %r110, %r108;
(EngineCore_DP0 pid=483676) 	.loc	1 187 60                        // quant_slide_tuned_Qwen2.5-7B.py:187:60
(EngineCore_DP0 pid=483676) 	// begin inline asm
(EngineCore_DP0 pid=483676) 	cvt.rn.satfinite.e4m3x2.f32  %rs58, %r87, %r86; 
(EngineCore_DP0 pid=483676) 
(EngineCore_DP0 pid=483676) 	// end inline asm
(EngineCore_DP0 pid=483676) 	.loc	1 188 27                        // quant_slide_tuned_Qwen2.5-7B.py:188:27
(EngineCore_DP0 pid=483676) 	mul.f32 	%r111, %r14, %r106;
(EngineCore_DP0 pid=483676) 	.loc	1 188 48                        // quant_slide_tuned_Qwen2.5-7B.py:188:48
(EngineCore_DP0 pid=483676) 	min.xorsign.abs.f32 	%r88, %r111, %r108;
(EngineCore_DP0 pid=483676) 	.loc	1 188 60                        // quant_slide_tuned_Qwen2.5-7B.py:188:60
(EngineCore_DP0 pid=483676) 	// begin inline asm
(EngineCore_DP0 pid=483676) 	cvt.rn.satfinite.e4m3x2.f32  %rs59, %r89, %r88; 
(EngineCore_DP0 pid=483676) 
(EngineCore_DP0 pid=483676) 	// end inline asm
(EngineCore_DP0 pid=483676) 	.loc	1 190 45                        // quant_slide_tuned_Qwen2.5-7B.py:190:45
(EngineCore_DP0 pid=483676) 	cvt.u32.u16 	%r112, %rs56;
(EngineCore_DP0 pid=483676) 	and.b32 	%r113, %r112, 255;
(EngineCore_DP0 pid=483676) 	.loc	1 192 45                        // quant_slide_tuned_Qwen2.5-7B.py:192:45
(EngineCore_DP0 pid=483676) 	cvt.u32.u16 	%r114, %rs58;
(EngineCore_DP0 pid=483676) 	and.b32 	%r115, %r114, 255;
(EngineCore_DP0 pid=483676) 	.loc	1 193 45                        // quant_slide_tuned_Qwen2.5-7B.py:193:45
(EngineCore_DP0 pid=483676) 	cvt.u32.u16 	%r116, %rs59;
(EngineCore_DP0 pid=483676) 	.loc	1 195 30                        // quant_slide_tuned_Qwen2.5-7B.py:195:30
(EngineCore_DP0 pid=483676) 	and.b16 	%rs60, %rs57, 255;
(EngineCore_DP0 pid=483676) 	mul.wide.u16 	%r117, %rs60, 256;
(EngineCore_DP0 pid=483676) 	.loc	1 195 24                        // quant_slide_tuned_Qwen2.5-7B.py:195:24
(EngineCore_DP0 pid=483676) 	or.b32 	%r118, %r117, %r113;
(EngineCore_DP0 pid=483676) 	.loc	1 195 42                        // quant_slide_tuned_Qwen2.5-7B.py:195:42
(EngineCore_DP0 pid=483676) 	shl.b32 	%r119, %r115, 16;
(EngineCore_DP0 pid=483676) 	.loc	1 195 36                        // quant_slide_tuned_Qwen2.5-7B.py:195:36
(EngineCore_DP0 pid=483676) 	or.b32 	%r120, %r118, %r119;
(EngineCore_DP0 pid=483676) 	.loc	1 195 55                        // quant_slide_tuned_Qwen2.5-7B.py:195:55
(EngineCore_DP0 pid=483676) 	shl.b32 	%r121, %r116, 24;
(EngineCore_DP0 pid=483676) 	.loc	1 195 49                        // quant_slide_tuned_Qwen2.5-7B.py:195:49
(EngineCore_DP0 pid=483676) 	or.b32 	%r90, %r120, %r121;
(EngineCore_DP0 pid=483676) 	.loc	1 196 29                        // quant_slide_tuned_Qwen2.5-7B.py:196:29
(EngineCore_DP0 pid=483676) 	mad.wide.s32 	%rd13, %r92, 4, %rd2;
(EngineCore_DP0 pid=483676) 	.loc	1 196 39                        // quant_slide_tuned_Qwen2.5-7B.py:196:39
(EngineCore_DP0 pid=483676) 	// begin inline asm
(EngineCore_DP0 pid=483676) 	@%p14 st.global.b32 [ %rd13 + 0 ], { %r90 };
(EngineCore_DP0 pid=483676) 	// end inline asm
(EngineCore_DP0 pid=483676) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=483676) 	add.s32 	%r125, %r125, 512;
(EngineCore_DP0 pid=483676) 	setp.lt.s32 	%p19, %r125, %r15;
(EngineCore_DP0 pid=483676) 	@%p19 bra 	$L__BB0_6;
(EngineCore_DP0 pid=483676) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=483676) 	.loc	1 167 4                         // quant_slide_tuned_Qwen2.5-7B.py:167:4
(EngineCore_DP0 pid=483676) 	ret;
(EngineCore_DP0 pid=483676) $L__tmp3:
(EngineCore_DP0 pid=483676) $L__func_end0:
(EngineCore_DP0 pid=483676)                                         // -- End function
(EngineCore_DP0 pid=483676) }
(EngineCore_DP0 pid=483676) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py"
(EngineCore_DP0 pid=483676) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=483676) 	.section	.debug_abbrev
(EngineCore_DP0 pid=483676) 	{
(EngineCore_DP0 pid=483676) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=483676) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=483676) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=483676) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=483676) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=483676) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=483676) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=483676) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=483676) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=483676) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=483676) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=483676) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=483676) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=483676) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=483676) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=483676) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=483676) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=483676) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=483676) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=483676) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=483676) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=483676) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=483676) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=483676) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=483676) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=483676) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=483676) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=483676) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=483676) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=483676) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=483676) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=483676) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=483676) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=483676) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=483676) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=483676) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=483676) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=483676) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=483676) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=483676) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=483676) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=483676) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=483676) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=483676) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=483676) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=483676) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=483676) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=483676) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=483676) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=483676) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=483676) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=483676) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=483676) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=483676) 	}
(EngineCore_DP0 pid=483676) 	.section	.debug_info
(EngineCore_DP0 pid=483676) 	{
(EngineCore_DP0 pid=483676) .b32 221                                // Length of Unit
(EngineCore_DP0 pid=483676) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=483676) .b8 0
(EngineCore_DP0 pid=483676) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=483676) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=483676) .b8 1                                   // Abbrev [1] 0xb:0xd6 DW_TAG_compile_unit
(EngineCore_DP0 pid=483676) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=483676) .b8 114
(EngineCore_DP0 pid=483676) .b8 105
(EngineCore_DP0 pid=483676) .b8 116
(EngineCore_DP0 pid=483676) .b8 111
(EngineCore_DP0 pid=483676) .b8 110
(EngineCore_DP0 pid=483676) .b8 0
(EngineCore_DP0 pid=483676) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=483676) .b8 0
(EngineCore_DP0 pid=483676) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=483676) .b8 117
(EngineCore_DP0 pid=483676) .b8 97
(EngineCore_DP0 pid=483676) .b8 110
(EngineCore_DP0 pid=483676) .b8 116
(EngineCore_DP0 pid=483676) .b8 95
(EngineCore_DP0 pid=483676) .b8 115
(EngineCore_DP0 pid=483676) .b8 108
(EngineCore_DP0 pid=483676) .b8 105
(EngineCore_DP0 pid=483676) .b8 100
(EngineCore_DP0 pid=483676) .b8 101
(EngineCore_DP0 pid=483676) .b8 95
(EngineCore_DP0 pid=483676) .b8 116
(EngineCore_DP0 pid=483676) .b8 117
(EngineCore_DP0 pid=483676) .b8 110
(EngineCore_DP0 pid=483676) .b8 101
(EngineCore_DP0 pid=483676) .b8 100
(EngineCore_DP0 pid=483676) .b8 95
(EngineCore_DP0 pid=483676) .b8 81
(EngineCore_DP0 pid=483676) .b8 119
(EngineCore_DP0 pid=483676) .b8 101
(EngineCore_DP0 pid=483676) .b8 110
(EngineCore_DP0 pid=483676) .b8 50
(EngineCore_DP0 pid=483676) .b8 46
(EngineCore_DP0 pid=483676) .b8 53
(EngineCore_DP0 pid=483676) .b8 45
(EngineCore_DP0 pid=483676) .b8 55
(EngineCore_DP0 pid=483676) .b8 66
(EngineCore_DP0 pid=483676) .b8 46
(EngineCore_DP0 pid=483676) .b8 112
(EngineCore_DP0 pid=483676) .b8 121
(EngineCore_DP0 pid=483676) .b8 0
(EngineCore_DP0 pid=483676) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=483676) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=483676) .b8 114
(EngineCore_DP0 pid=483676) .b8 111
(EngineCore_DP0 pid=483676) .b8 111
(EngineCore_DP0 pid=483676) .b8 116
(EngineCore_DP0 pid=483676) .b8 47
(EngineCore_DP0 pid=483676) .b8 118
(EngineCore_DP0 pid=483676) .b8 108
(EngineCore_DP0 pid=483676) .b8 108
(EngineCore_DP0 pid=483676) .b8 109
(EngineCore_DP0 pid=483676) .b8 98
(EngineCore_DP0 pid=483676) .b8 101
(EngineCore_DP0 pid=483676) .b8 110
(EngineCore_DP0 pid=483676) .b8 99
(EngineCore_DP0 pid=483676) .b8 104
(EngineCore_DP0 pid=483676) .b8 47
(EngineCore_DP0 pid=483676) .b8 115
(EngineCore_DP0 pid=483676) .b8 108
(EngineCore_DP0 pid=483676) .b8 105
(EngineCore_DP0 pid=483676) .b8 100
(EngineCore_DP0 pid=483676) .b8 101
(EngineCore_DP0 pid=483676) .b8 115
(EngineCore_DP0 pid=483676) .b8 112
(EngineCore_DP0 pid=483676) .b8 97
(EngineCore_DP0 pid=483676) .b8 114
(EngineCore_DP0 pid=483676) .b8 115
(EngineCore_DP0 pid=483676) .b8 101
(EngineCore_DP0 pid=483676) .b8 47
(EngineCore_DP0 pid=483676) .b8 99
(EngineCore_DP0 pid=483676) .b8 115
(EngineCore_DP0 pid=483676) .b8 114
(EngineCore_DP0 pid=483676) .b8 99
(EngineCore_DP0 pid=483676) .b8 47
(EngineCore_DP0 pid=483676) .b8 102
(EngineCore_DP0 pid=483676) .b8 117
(EngineCore_DP0 pid=483676) .b8 115
(EngineCore_DP0 pid=483676) .b8 101
(EngineCore_DP0 pid=483676) .b8 100
(EngineCore_DP0 pid=483676) .b8 95
(EngineCore_DP0 pid=483676) .b8 113
(EngineCore_DP0 pid=483676) .b8 117
(EngineCore_DP0 pid=483676) .b8 97
(EngineCore_DP0 pid=483676) .b8 110
(EngineCore_DP0 pid=483676) .b8 116
(EngineCore_DP0 pid=483676) .b8 95
(EngineCore_DP0 pid=483676) .b8 115
(EngineCore_DP0 pid=483676) .b8 108
(EngineCore_DP0 pid=483676) .b8 105
(EngineCore_DP0 pid=483676) .b8 100
(EngineCore_DP0 pid=483676) .b8 101
(EngineCore_DP0 pid=483676) .b8 95
(EngineCore_DP0 pid=483676) .b8 116
(EngineCore_DP0 pid=483676) .b8 114
(EngineCore_DP0 pid=483676) .b8 105
(EngineCore_DP0 pid=483676) .b8 116
(EngineCore_DP0 pid=483676) .b8 111
(EngineCore_DP0 pid=483676) .b8 110
(EngineCore_DP0 pid=483676) .b8 47
(EngineCore_DP0 pid=483676) .b8 98
(EngineCore_DP0 pid=483676) .b8 117
(EngineCore_DP0 pid=483676) .b8 105
(EngineCore_DP0 pid=483676) .b8 108
(EngineCore_DP0 pid=483676) .b8 100
(EngineCore_DP0 pid=483676) .b8 47
(EngineCore_DP0 pid=483676) .b8 71
(EngineCore_DP0 pid=483676) .b8 66
(EngineCore_DP0 pid=483676) .b8 49
(EngineCore_DP0 pid=483676) .b8 48
(EngineCore_DP0 pid=483676) .b8 95
(EngineCore_DP0 pid=483676) .b8 99
(EngineCore_DP0 pid=483676) .b8 99
(EngineCore_DP0 pid=483676) .b8 49
(EngineCore_DP0 pid=483676) .b8 50
(EngineCore_DP0 pid=483676) .b8 49
(EngineCore_DP0 pid=483676) .b8 95
(EngineCore_DP0 pid=483676) .b8 112
(EngineCore_DP0 pid=483676) .b8 121
(EngineCore_DP0 pid=483676) .b8 51
(EngineCore_DP0 pid=483676) .b8 49
(EngineCore_DP0 pid=483676) .b8 50
(EngineCore_DP0 pid=483676) .b8 95
(EngineCore_DP0 pid=483676) .b8 99
(EngineCore_DP0 pid=483676) .b8 117
(EngineCore_DP0 pid=483676) .b8 49
(EngineCore_DP0 pid=483676) .b8 50
(EngineCore_DP0 pid=483676) .b8 57
(EngineCore_DP0 pid=483676) .b8 95
(EngineCore_DP0 pid=483676) .b8 97
(EngineCore_DP0 pid=483676) .b8 97
(EngineCore_DP0 pid=483676) .b8 114
(EngineCore_DP0 pid=483676) .b8 99
(EngineCore_DP0 pid=483676) .b8 104
(EngineCore_DP0 pid=483676) .b8 54
(EngineCore_DP0 pid=483676) .b8 52
(EngineCore_DP0 pid=483676) .b8 0
(EngineCore_DP0 pid=483676) .b8 2                                   // Abbrev [2] 0x98:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=483676) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=483676) .b8 113
(EngineCore_DP0 pid=483676) .b8 117
(EngineCore_DP0 pid=483676) .b8 97
(EngineCore_DP0 pid=483676) .b8 110
(EngineCore_DP0 pid=483676) .b8 116
(EngineCore_DP0 pid=483676) .b8 95
(EngineCore_DP0 pid=483676) .b8 115
(EngineCore_DP0 pid=483676) .b8 108
(EngineCore_DP0 pid=483676) .b8 105
(EngineCore_DP0 pid=483676) .b8 100
(EngineCore_DP0 pid=483676) .b8 101
(EngineCore_DP0 pid=483676) .b8 95
(EngineCore_DP0 pid=483676) .b8 102
(EngineCore_DP0 pid=483676) .b8 112
(EngineCore_DP0 pid=483676) .b8 56
(EngineCore_DP0 pid=483676) .b8 95
(EngineCore_DP0 pid=483676) .b8 107
(EngineCore_DP0 pid=483676) .b8 101
(EngineCore_DP0 pid=483676) .b8 114
(EngineCore_DP0 pid=483676) .b8 110
(EngineCore_DP0 pid=483676) .b8 101
(EngineCore_DP0 pid=483676) .b8 108
(EngineCore_DP0 pid=483676) .b8 0
(EngineCore_DP0 pid=483676) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=483676) .b8 3                                   // Abbrev [3] 0xb2:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=483676) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=483676) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=483676) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=483676) .b8 4                                   // Abbrev [4] 0xc7:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=483676) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=483676) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=483676) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=483676) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=483676) .b8 157                                 // DW_AT_call_line
(EngineCore_DP0 pid=483676) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=483676) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=483676) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=483676) 	}
(EngineCore_DP0 pid=483676) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=483676) 
(EngineCore_DP0 pid=483676) ================================================================
(EngineCore_DP0 pid=483676) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=483676) 
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpvccue8qz.ptx', '-o', '/tmp/tmpvccue8qz.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866] 
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866] 
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866] 
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpvccue8qz.ptx -o /tmp/tmpvccue8qz.ptx.o
(EngineCore_DP0 pid=483676) ERROR 01-25 21:35:15 [core.py:866] 

STDERR:
[2026-01-25 21:34:10] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:34:10] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:34:10] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:34:10] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:34:10] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:34:10] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:34:10] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:34:10] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:34:11] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:34:11] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:34:11] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:34:11] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:34:11] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:34:11] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:34:14] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:34:14] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:34:14] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:34:14] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:34:14] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:34:14] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:34:14] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:34:14] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:34:14] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:34:14] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:34:14] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:34:14] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:34:14] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:34:14] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=483676) [2026-01-25 21:34:15] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=483676) [2026-01-25 21:34:15] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=483676) [2026-01-25 21:34:15] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=483676) [2026-01-25 21:34:15] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=483676) [2026-01-25 21:34:15] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=483676) [2026-01-25 21:34:15] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=483676) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=483676) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:24<00:24, 24.04s/it]
(EngineCore_DP0 pid=483676) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:57<00:00, 29.61s/it]
(EngineCore_DP0 pid=483676) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:57<00:00, 28.78s/it]
(EngineCore_DP0 pid=483676) 
(EngineCore_DP0 pid=483676) [2026-01-25 21:35:14] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=483676) [2026-01-25 21:35:14] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 13860864 bytes
(EngineCore_DP0 pid=483676) [2026-01-25 21:35:14] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=483676) [2026-01-25 21:35:14] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10780672 bytes
(EngineCore_DP0 pid=483676) [2026-01-25 21:35:14] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=483676) [2026-01-25 21:35:14] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 113967104 bytes
(EngineCore_DP0 pid=483676) [2026-01-25 21:35:14] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=483676) [2026-01-25 21:35:14] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 56655872 bytes
(EngineCore_DP0 pid=483676) Process EngineCore_DP0:
(EngineCore_DP0 pid=483676) Traceback (most recent call last):
(EngineCore_DP0 pid=483676)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=483676)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=483676)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=483676)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=483676) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpvccue8qz.ptx', '-o', '/tmp/tmpvccue8qz.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=483676) 
(EngineCore_DP0 pid=483676) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=483676) 
(EngineCore_DP0 pid=483676) Traceback (most recent call last):
(EngineCore_DP0 pid=483676)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=483676)     self.run()
(EngineCore_DP0 pid=483676)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=483676)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=483676)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=483676)     raise e
(EngineCore_DP0 pid=483676)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=483676)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=483676)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=483676)     super().__init__(
(EngineCore_DP0 pid=483676)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=483676)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=483676)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=483676)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=483676)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=483676)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=483676)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=483676)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=483676)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=483676)     return func(*args, **kwargs)
(EngineCore_DP0 pid=483676)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=483676)     return func(*args, **kwargs)
(EngineCore_DP0 pid=483676)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=483676)     self.model_runner.profile_run()
(EngineCore_DP0 pid=483676)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=483676)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=483676)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=483676)     return func(*args, **kwargs)
(EngineCore_DP0 pid=483676)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=483676)     outputs = self.model(
(EngineCore_DP0 pid=483676)               ^^^^^^^^^^^
(EngineCore_DP0 pid=483676)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=483676)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=483676)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=483676)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=483676)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=483676)     hidden_states = self.model(
(EngineCore_DP0 pid=483676)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=483676)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=483676)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=483676)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=483676)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=483676)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=483676)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=483676)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=483676)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=483676)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=483676)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=483676)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=483676)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=483676)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=483676)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=483676)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=483676)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=483676)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=483676)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=483676)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=483676)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=483676)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=483676)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=483676)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=483676)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=483676)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=483676)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=483676)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=483676)     return self._linear_fn(
(EngineCore_DP0 pid=483676)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=483676)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=483676)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=483676)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=483676)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=483676)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=483676)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=483676)     return fn(input, L)
(EngineCore_DP0 pid=483676)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=483676)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=483676)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=483676)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=483676)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=483676)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=483676)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=483676)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=483676)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=483676)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=483676)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=483676)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=483676)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=483676)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=483676)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=483676)     raise PTXASError(error)
(EngineCore_DP0 pid=483676) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=483676) `ptxas` stderr:
(EngineCore_DP0 pid=483676) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=483676) 
(EngineCore_DP0 pid=483676) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpvccue8qz.ptx -o /tmp/tmpvccue8qz.ptx.o
(EngineCore_DP0 pid=483676) 
[rank0]:[W125 21:35:15.914712426 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=65536

========== M=16 ==========
Time: 2026-01-26 02:38:38
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6
Params: prompt_len=16, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6 --dataset-name random --input-len 16 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 17 --max-num-batched-tokens 17 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-FP8_M16.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 02:38:41 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 02:38:41 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=755552) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=755552) WARNING 01-26 02:39:02 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 83.39 requests/s, 1417.68 total tokens/s, 83.39 output tokens/s
Total num prompt tokens:  2048
Total num output tokens:  128

STDERR:
[2026-01-26 02:38:41] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 02:38:41] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 02:38:41] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 02:38:41] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:38:41] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:38:41] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:38:41] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:38:41] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:38:41] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 02:38:41] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:38:41] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:38:41] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:38:41] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:38:41] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 02:38:45] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 02:38:45] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 02:38:45] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 02:38:45] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:38:45] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:38:45] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:38:45] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:38:45] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:38:45] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 02:38:45] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:38:45] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:38:45] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:38:45] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:38:45] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=755552) [2026-01-26 02:38:46] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=755552) [2026-01-26 02:38:46] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=755552) [2026-01-26 02:38:46] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=755552) [2026-01-26 02:38:46] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=755552) [2026-01-26 02:38:46] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=755552) [2026-01-26 02:38:46] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=755552) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=755552) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.25s/it]
(EngineCore_DP0 pid=755552) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.25s/it]
(EngineCore_DP0 pid=755552) 
(EngineCore_DP0 pid=755552) [2026-01-26 02:38:56] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=755552) [2026-01-26 02:38:56] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5308416 bytes
(EngineCore_DP0 pid=755552) [2026-01-26 02:38:56] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=755552) [2026-01-26 02:38:56] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3538944 bytes
(EngineCore_DP0 pid=755552) [2026-01-26 02:38:56] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=755552) [2026-01-26 02:38:56] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 28311552 bytes
(EngineCore_DP0 pid=755552) [2026-01-26 02:38:56] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=755552) [2026-01-26 02:38:56] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14024704 bytes
(EngineCore_DP0 pid=755552) 2026-01-26 02:39:01,551 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=755552) 2026-01-26 02:39:01,558 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 12785.08it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:24,  5.09it/s, est. speed input: 81.50 toks/s, output: 5.09 toks/s]
Processed prompts:   9%|         | 11/128 [00:00<00:02, 43.01it/s, est. speed input: 572.07 toks/s, output: 35.75 toks/s]
Processed prompts:  16%|        | 21/128 [00:00<00:01, 62.87it/s, est. speed input: 816.11 toks/s, output: 51.01 toks/s]
Processed prompts:  24%|       | 31/128 [00:00<00:01, 74.51it/s, est. speed input: 962.18 toks/s, output: 60.13 toks/s]
Processed prompts:  32%|      | 41/128 [00:00<00:01, 81.45it/s, est. speed input: 1057.31 toks/s, output: 66.08 toks/s]
Processed prompts:  40%|      | 51/128 [00:00<00:00, 86.39it/s, est. speed input: 1127.58 toks/s, output: 70.47 toks/s]
Processed prompts:  48%|     | 61/128 [00:00<00:00, 89.84it/s, est. speed input: 1181.21 toks/s, output: 73.82 toks/s]
Processed prompts:  55%|    | 71/128 [00:00<00:00, 91.95it/s, est. speed input: 1221.84 toks/s, output: 76.36 toks/s]
Processed prompts:  63%|   | 81/128 [00:01<00:00, 93.43it/s, est. speed input: 1254.48 toks/s, output: 78.40 toks/s]
Processed prompts:  71%|   | 91/128 [00:01<00:00, 94.42it/s, est. speed input: 1281.08 toks/s, output: 80.07 toks/s]
Processed prompts:  79%|  | 101/128 [00:01<00:00, 95.08it/s, est. speed input: 1303.17 toks/s, output: 81.45 toks/s]
Processed prompts:  87%| | 111/128 [00:01<00:00, 94.32it/s, est. speed input: 1317.50 toks/s, output: 82.34 toks/s]
Processed prompts:  95%|| 121/128 [00:01<00:00, 94.98it/s, est. speed input: 1333.71 toks/s, output: 83.36 toks/s]
Processed prompts: 100%|| 128/128 [00:01<00:00, 94.98it/s, est. speed input: 1343.91 toks/s, output: 83.99 toks/s]
Processed prompts: 100%|| 128/128 [00:01<00:00, 83.98it/s, est. speed input: 1343.91 toks/s, output: 83.99 toks/s]
[rank0]:[W126 02:39:04.246274132 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=128 ==========
Time: 2026-01-26 02:39:06
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6
Params: prompt_len=128, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6 --dataset-name random --input-len 128 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 129 --max-num-batched-tokens 129 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-FP8_M128.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 02:39:09 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 02:39:10 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=756149) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=756149) WARNING 01-26 02:39:30 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 74.03 requests/s, 9550.17 total tokens/s, 74.03 output tokens/s
Total num prompt tokens:  16384
Total num output tokens:  128

STDERR:
[2026-01-26 02:39:09] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 02:39:09] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 02:39:09] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 02:39:09] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:39:09] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:39:09] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:39:09] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:39:09] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:39:09] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 02:39:09] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:39:09] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:39:09] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:39:09] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:39:09] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 02:39:13] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 02:39:13] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 02:39:13] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 02:39:13] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:39:13] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:39:13] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:39:13] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:39:13] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:39:13] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 02:39:13] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:39:13] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:39:13] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:39:13] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:39:13] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=756149) [2026-01-26 02:39:14] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=756149) [2026-01-26 02:39:14] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=756149) [2026-01-26 02:39:14] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=756149) [2026-01-26 02:39:14] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=756149) [2026-01-26 02:39:14] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=756149) [2026-01-26 02:39:14] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=756149) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=756149) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.16s/it]
(EngineCore_DP0 pid=756149) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.16s/it]
(EngineCore_DP0 pid=756149) 
(EngineCore_DP0 pid=756149) [2026-01-26 02:39:24] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=756149) [2026-01-26 02:39:24] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5308416 bytes
(EngineCore_DP0 pid=756149) [2026-01-26 02:39:24] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=756149) [2026-01-26 02:39:24] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3538944 bytes
(EngineCore_DP0 pid=756149) [2026-01-26 02:39:24] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=756149) [2026-01-26 02:39:24] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 28311552 bytes
(EngineCore_DP0 pid=756149) [2026-01-26 02:39:24] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=756149) [2026-01-26 02:39:24] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14024704 bytes
(EngineCore_DP0 pid=756149) 2026-01-26 02:39:29,368 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=756149) 2026-01-26 02:39:29,376 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 3714.78it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:23,  5.48it/s, est. speed input: 701.43 toks/s, output: 5.48 toks/s]
Processed prompts:   7%|         | 9/128 [00:00<00:03, 37.47it/s, est. speed input: 4014.70 toks/s, output: 31.36 toks/s]
Processed prompts:  14%|        | 18/128 [00:00<00:01, 55.68it/s, est. speed input: 5826.90 toks/s, output: 45.52 toks/s]
Processed prompts:  21%|        | 27/128 [00:00<00:01, 66.37it/s, est. speed input: 6906.09 toks/s, output: 53.95 toks/s]
Processed prompts:  28%|       | 36/128 [00:00<00:01, 71.88it/s, est. speed input: 7555.92 toks/s, output: 59.03 toks/s]
Processed prompts:  35%|      | 45/128 [00:00<00:01, 76.31it/s, est. speed input: 8056.70 toks/s, output: 62.94 toks/s]
Processed prompts:  42%|     | 54/128 [00:00<00:00, 79.42it/s, est. speed input: 8436.09 toks/s, output: 65.90 toks/s]
Processed prompts:  49%|     | 63/128 [00:00<00:00, 80.40it/s, est. speed input: 8685.43 toks/s, output: 67.85 toks/s]
Processed prompts:  56%|    | 72/128 [00:01<00:00, 82.07it/s, est. speed input: 8919.44 toks/s, output: 69.68 toks/s]
Processed prompts:  63%|   | 81/128 [00:01<00:00, 83.13it/s, est. speed input: 9107.10 toks/s, output: 71.15 toks/s]
Processed prompts:  70%|   | 90/128 [00:01<00:00, 84.00it/s, est. speed input: 9267.28 toks/s, output: 72.40 toks/s]
Processed prompts:  77%|  | 99/128 [00:01<00:00, 84.71it/s, est. speed input: 9405.59 toks/s, output: 73.48 toks/s]
Processed prompts:  84%| | 108/128 [00:01<00:00, 84.93it/s, est. speed input: 9516.41 toks/s, output: 74.35 toks/s]
Processed prompts:  91%|| 117/128 [00:01<00:00, 84.85it/s, est. speed input: 9606.60 toks/s, output: 75.05 toks/s]
Processed prompts:  98%|| 126/128 [00:01<00:00, 83.68it/s, est. speed input: 9657.95 toks/s, output: 75.45 toks/s]
Processed prompts: 100%|| 128/128 [00:01<00:00, 83.68it/s, est. speed input: 9674.34 toks/s, output: 75.58 toks/s]
Processed prompts: 100%|| 128/128 [00:01<00:00, 75.58it/s, est. speed input: 9674.34 toks/s, output: 75.58 toks/s]
[rank0]:[W126 02:39:31.134291575 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=256 ==========
Time: 2026-01-26 02:39:34
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6
Params: prompt_len=256, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6 --dataset-name random --input-len 256 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 257 --max-num-batched-tokens 257 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-FP8_M256.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 02:39:37 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 02:39:37 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=756739) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=756739) WARNING 01-26 02:39:57 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 65.34 requests/s, 16791.21 total tokens/s, 65.34 output tokens/s
Total num prompt tokens:  32768
Total num output tokens:  128

STDERR:
[2026-01-26 02:39:37] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 02:39:37] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 02:39:37] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 02:39:37] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:39:37] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:39:37] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:39:37] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:39:37] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:39:37] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 02:39:37] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:39:37] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:39:37] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:39:37] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:39:37] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 02:39:41] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 02:39:41] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 02:39:41] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 02:39:41] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:39:41] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:39:41] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:39:41] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:39:41] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 02:39:41] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 02:39:41] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:39:41] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:39:41] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:39:41] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:39:41] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=756739) [2026-01-26 02:39:42] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=756739) [2026-01-26 02:39:42] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=756739) [2026-01-26 02:39:42] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=756739) [2026-01-26 02:39:42] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=756739) [2026-01-26 02:39:42] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=756739) [2026-01-26 02:39:42] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=756739) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=756739) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.15s/it]
(EngineCore_DP0 pid=756739) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.15s/it]
(EngineCore_DP0 pid=756739) 
(EngineCore_DP0 pid=756739) [2026-01-26 02:39:51] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=756739) [2026-01-26 02:39:51] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5308416 bytes
(EngineCore_DP0 pid=756739) [2026-01-26 02:39:51] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=756739) [2026-01-26 02:39:51] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3538944 bytes
(EngineCore_DP0 pid=756739) [2026-01-26 02:39:51] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=756739) [2026-01-26 02:39:51] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 28311552 bytes
(EngineCore_DP0 pid=756739) [2026-01-26 02:39:51] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=756739) [2026-01-26 02:39:51] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14024704 bytes
(EngineCore_DP0 pid=756739) 2026-01-26 02:39:57,030 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=756739) 2026-01-26 02:39:57,037 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 2244.47it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:21,  5.94it/s, est. speed input: 1521.98 toks/s, output: 5.94 toks/s]
Processed prompts:   7%|         | 9/128 [00:00<00:03, 38.35it/s, est. speed input: 8308.55 toks/s, output: 32.45 toks/s]
Processed prompts:  13%|        | 17/128 [00:00<00:02, 52.81it/s, est. speed input: 11294.52 toks/s, output: 44.12 toks/s]
Processed prompts:  20%|        | 25/128 [00:00<00:01, 60.94it/s, est. speed input: 13016.98 toks/s, output: 50.85 toks/s]
Processed prompts:  26%|       | 33/128 [00:00<00:01, 65.45it/s, est. speed input: 14085.97 toks/s, output: 55.02 toks/s]
Processed prompts:  32%|      | 41/128 [00:00<00:01, 68.03it/s, est. speed input: 14802.80 toks/s, output: 57.82 toks/s]
Processed prompts:  38%|      | 49/128 [00:00<00:01, 69.23it/s, est. speed input: 15286.53 toks/s, output: 59.71 toks/s]
Processed prompts:  45%|     | 57/128 [00:00<00:01, 70.53it/s, est. speed input: 15696.18 toks/s, output: 61.31 toks/s]
Processed prompts:  51%|     | 65/128 [00:01<00:00, 71.68it/s, est. speed input: 16041.31 toks/s, output: 62.66 toks/s]
Processed prompts:  57%|    | 73/128 [00:01<00:00, 72.46it/s, est. speed input: 16320.38 toks/s, output: 63.75 toks/s]
Processed prompts:  63%|   | 81/128 [00:01<00:00, 72.05it/s, est. speed input: 16489.67 toks/s, output: 64.41 toks/s]
Processed prompts:  70%|   | 89/128 [00:01<00:00, 72.27it/s, est. speed input: 16661.68 toks/s, output: 65.08 toks/s]
Processed prompts:  76%|  | 97/128 [00:01<00:00, 72.56it/s, est. speed input: 16815.77 toks/s, output: 65.69 toks/s]
Processed prompts:  82%| | 105/128 [00:01<00:00, 72.27it/s, est. speed input: 16922.59 toks/s, output: 66.10 toks/s]
Processed prompts:  88%| | 113/128 [00:01<00:00, 72.66it/s, est. speed input: 17045.35 toks/s, output: 66.58 toks/s]
Processed prompts:  95%|| 121/128 [00:01<00:00, 72.80it/s, est. speed input: 17146.68 toks/s, output: 66.98 toks/s]
Processed prompts: 100%|| 128/128 [00:01<00:00, 72.80it/s, est. speed input: 17235.79 toks/s, output: 67.33 toks/s]
Processed prompts: 100%|| 128/128 [00:01<00:00, 67.32it/s, est. speed input: 17235.79 toks/s, output: 67.33 toks/s]
[rank0]:[W126 02:39:59.002813573 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-26 04:20:21
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-FP8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 04:20:25 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 04:20:25 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=853026) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=853026) WARNING 01-26 04:20:45 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 50.96 requests/s, 26142.82 total tokens/s, 50.96 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-26 04:20:25] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 04:20:25] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 04:20:25] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 04:20:25] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:20:25] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:20:25] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:20:25] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:20:25] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:20:25] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 04:20:25] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 04:20:25] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:20:25] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:20:25] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:20:25] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 04:20:28] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 04:20:28] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 04:20:28] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 04:20:28] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:20:28] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:20:28] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:20:28] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:20:28] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:20:28] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 04:20:28] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 04:20:28] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:20:28] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:20:28] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:20:28] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=853026) [2026-01-26 04:20:29] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=853026) [2026-01-26 04:20:29] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=853026) [2026-01-26 04:20:29] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=853026) [2026-01-26 04:20:29] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=853026) [2026-01-26 04:20:29] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=853026) [2026-01-26 04:20:29] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=853026) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=853026) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.20s/it]
(EngineCore_DP0 pid=853026) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.20s/it]
(EngineCore_DP0 pid=853026) 
(EngineCore_DP0 pid=853026) [2026-01-26 04:20:39] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=853026) [2026-01-26 04:20:39] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5308416 bytes
(EngineCore_DP0 pid=853026) [2026-01-26 04:20:39] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=853026) [2026-01-26 04:20:39] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3538944 bytes
(EngineCore_DP0 pid=853026) [2026-01-26 04:20:39] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=853026) [2026-01-26 04:20:39] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 28311552 bytes
(EngineCore_DP0 pid=853026) [2026-01-26 04:20:39] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=853026) [2026-01-26 04:20:39] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14024704 bytes
(EngineCore_DP0 pid=853026) 2026-01-26 04:20:44,441 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=853026) 2026-01-26 04:20:44,448 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  96%|| 123/128 [00:00<00:00, 1228.04it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 1223.68it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|         | 7/128 [00:00<00:02, 60.37it/s, est. speed input: 30911.82 toks/s, output: 60.37 toks/s]
Processed prompts:  11%|         | 14/128 [00:00<00:02, 55.97it/s, est. speed input: 28974.88 toks/s, output: 56.59 toks/s]
Processed prompts:  16%|        | 20/128 [00:00<00:01, 54.63it/s, est. speed input: 28376.82 toks/s, output: 55.42 toks/s]
Processed prompts:  20%|        | 26/128 [00:00<00:01, 54.00it/s, est. speed input: 28077.94 toks/s, output: 54.84 toks/s]
Processed prompts:  25%|       | 32/128 [00:00<00:01, 52.90it/s, est. speed input: 27682.40 toks/s, output: 54.07 toks/s]
Processed prompts:  30%|       | 38/128 [00:00<00:01, 52.92it/s, est. speed input: 27591.59 toks/s, output: 53.89 toks/s]
Processed prompts:  34%|      | 44/128 [00:00<00:01, 53.19it/s, est. speed input: 27582.08 toks/s, output: 53.87 toks/s]
Processed prompts:  39%|      | 50/128 [00:00<00:01, 53.02it/s, est. speed input: 27506.68 toks/s, output: 53.72 toks/s]
Processed prompts:  44%|     | 56/128 [00:01<00:01, 53.03it/s, est. speed input: 27468.95 toks/s, output: 53.65 toks/s]
Processed prompts:  48%|     | 62/128 [00:01<00:01, 53.12it/s, est. speed input: 27453.62 toks/s, output: 53.62 toks/s]
Processed prompts:  53%|    | 68/128 [00:01<00:01, 52.91it/s, est. speed input: 27398.48 toks/s, output: 53.51 toks/s]
Processed prompts:  58%|    | 74/128 [00:01<00:01, 53.24it/s, est. speed input: 27418.96 toks/s, output: 53.55 toks/s]
Processed prompts:  62%|   | 80/128 [00:01<00:00, 52.98it/s, est. speed input: 27373.64 toks/s, output: 53.46 toks/s]
Processed prompts:  67%|   | 86/128 [00:01<00:00, 52.41it/s, est. speed input: 27287.02 toks/s, output: 53.29 toks/s]
Processed prompts:  72%|  | 92/128 [00:01<00:00, 52.32it/s, est. speed input: 27246.20 toks/s, output: 53.21 toks/s]
Processed prompts:  77%|  | 98/128 [00:01<00:00, 52.73it/s, est. speed input: 27261.21 toks/s, output: 53.24 toks/s]
Processed prompts:  81%| | 104/128 [00:01<00:00, 52.93it/s, est. speed input: 27265.80 toks/s, output: 53.25 toks/s]
Processed prompts:  86%| | 110/128 [00:02<00:00, 53.06it/s, est. speed input: 27269.31 toks/s, output: 53.26 toks/s]
Processed prompts:  91%| | 116/128 [00:02<00:00, 52.93it/s, est. speed input: 27252.42 toks/s, output: 53.23 toks/s]
Processed prompts:  95%|| 122/128 [00:02<00:00, 52.99it/s, est. speed input: 27250.15 toks/s, output: 53.22 toks/s]
Processed prompts: 100%|| 128/128 [00:02<00:00, 52.92it/s, est. speed input: 27238.48 toks/s, output: 53.20 toks/s]
Processed prompts: 100%|| 128/128 [00:02<00:00, 52.92it/s, est. speed input: 27238.48 toks/s, output: 53.20 toks/s]
Processed prompts: 100%|| 128/128 [00:02<00:00, 53.20it/s, est. speed input: 27238.48 toks/s, output: 53.20 toks/s]
[rank0]:[W126 04:20:47.007254158 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-26 04:20:50
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-FP8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 04:20:54 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 04:20:54 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=853779) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=853779) WARNING 01-26 04:21:13 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 27.57 requests/s, 28257.24 total tokens/s, 27.57 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-26 04:20:53] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 04:20:53] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 04:20:53] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 04:20:53] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:20:53] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:20:53] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:20:53] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:20:53] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:20:53] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 04:20:53] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 04:20:53] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:20:53] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:20:53] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:20:53] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 04:20:57] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 04:20:57] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 04:20:57] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 04:20:57] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:20:57] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:20:57] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:20:57] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:20:57] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:20:57] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 04:20:57] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 04:20:57] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:20:57] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:20:57] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:20:57] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=853779) [2026-01-26 04:20:58] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=853779) [2026-01-26 04:20:58] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=853779) [2026-01-26 04:20:58] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=853779) [2026-01-26 04:20:58] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=853779) [2026-01-26 04:20:58] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=853779) [2026-01-26 04:20:58] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=853779) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=853779) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.16s/it]
(EngineCore_DP0 pid=853779) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.16s/it]
(EngineCore_DP0 pid=853779) 
(EngineCore_DP0 pid=853779) [2026-01-26 04:21:08] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=853779) [2026-01-26 04:21:08] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5308416 bytes
(EngineCore_DP0 pid=853779) [2026-01-26 04:21:08] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=853779) [2026-01-26 04:21:08] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3538944 bytes
(EngineCore_DP0 pid=853779) [2026-01-26 04:21:08] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=853779) [2026-01-26 04:21:08] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 28311552 bytes
(EngineCore_DP0 pid=853779) [2026-01-26 04:21:08] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=853779) [2026-01-26 04:21:08] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14024704 bytes
(EngineCore_DP0 pid=853779) 2026-01-26 04:21:13,221 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=853779) 2026-01-26 04:21:13,228 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  45%|     | 57/128 [00:00<00:00, 560.20it/s]
Adding requests:  89%| | 114/128 [00:00<00:00, 498.54it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 505.64it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|         | 8/128 [00:00<00:01, 72.09it/s, est. speed input: 73836.65 toks/s, output: 72.10 toks/s]
Processed prompts:  12%|        | 16/128 [00:00<00:02, 37.63it/s, est. speed input: 41511.18 toks/s, output: 40.54 toks/s]
Processed prompts:  16%|        | 21/128 [00:00<00:03, 33.77it/s, est. speed input: 37614.30 toks/s, output: 36.73 toks/s]
Processed prompts:  20%|        | 25/128 [00:00<00:03, 32.02it/s, est. speed input: 35901.72 toks/s, output: 35.06 toks/s]
Processed prompts:  23%|       | 29/128 [00:00<00:03, 30.84it/s, est. speed input: 34749.40 toks/s, output: 33.93 toks/s]
Processed prompts:  26%|       | 33/128 [00:01<00:03, 29.66it/s, est. speed input: 33724.95 toks/s, output: 32.93 toks/s]
Processed prompts:  29%|       | 37/128 [00:01<00:03, 29.20it/s, est. speed input: 33116.99 toks/s, output: 32.34 toks/s]
Processed prompts:  31%|      | 40/128 [00:01<00:03, 28.96it/s, est. speed input: 32759.20 toks/s, output: 31.99 toks/s]
Processed prompts:  34%|      | 43/128 [00:01<00:02, 28.81it/s, est. speed input: 32469.05 toks/s, output: 31.71 toks/s]
Processed prompts:  36%|      | 46/128 [00:01<00:02, 28.69it/s, est. speed input: 32221.93 toks/s, output: 31.47 toks/s]
Processed prompts:  38%|      | 49/128 [00:01<00:02, 28.53it/s, est. speed input: 31988.46 toks/s, output: 31.24 toks/s]
Processed prompts:  41%|      | 52/128 [00:01<00:02, 28.61it/s, est. speed input: 31833.06 toks/s, output: 31.09 toks/s]
Processed prompts:  43%|     | 55/128 [00:01<00:02, 28.30it/s, est. speed input: 31611.97 toks/s, output: 30.87 toks/s]
Processed prompts:  45%|     | 58/128 [00:01<00:02, 28.19it/s, est. speed input: 31440.86 toks/s, output: 30.70 toks/s]
Processed prompts:  48%|     | 61/128 [00:01<00:02, 28.04it/s, est. speed input: 31273.96 toks/s, output: 30.54 toks/s]
Processed prompts:  50%|     | 64/128 [00:02<00:02, 27.56it/s, est. speed input: 31050.09 toks/s, output: 30.32 toks/s]
Processed prompts:  52%|    | 67/128 [00:02<00:02, 27.74it/s, est. speed input: 30945.04 toks/s, output: 30.22 toks/s]
Processed prompts:  55%|    | 70/128 [00:02<00:02, 28.04it/s, est. speed input: 30879.02 toks/s, output: 30.16 toks/s]
Processed prompts:  57%|    | 73/128 [00:02<00:01, 28.16it/s, est. speed input: 30802.08 toks/s, output: 30.08 toks/s]
Processed prompts:  59%|    | 76/128 [00:02<00:01, 28.25it/s, est. speed input: 30732.78 toks/s, output: 30.01 toks/s]
Processed prompts:  62%|   | 79/128 [00:02<00:01, 28.32it/s, est. speed input: 30670.40 toks/s, output: 29.95 toks/s]
Processed prompts:  64%|   | 82/128 [00:02<00:01, 28.32it/s, est. speed input: 30605.16 toks/s, output: 29.89 toks/s]
Processed prompts:  66%|   | 85/128 [00:02<00:01, 28.14it/s, est. speed input: 30521.77 toks/s, output: 29.81 toks/s]
Processed prompts:  69%|   | 88/128 [00:02<00:01, 28.22it/s, est. speed input: 30470.83 toks/s, output: 29.76 toks/s]
Processed prompts:  71%|   | 91/128 [00:03<00:01, 28.15it/s, est. speed input: 30407.03 toks/s, output: 29.69 toks/s]
Processed prompts:  73%|  | 94/128 [00:03<00:01, 27.82it/s, est. speed input: 30314.29 toks/s, output: 29.60 toks/s]
Processed prompts:  76%|  | 97/128 [00:03<00:01, 27.93it/s, est. speed input: 30266.98 toks/s, output: 29.56 toks/s]
Processed prompts:  78%|  | 100/128 [00:03<00:01, 27.98it/s, est. speed input: 30220.33 toks/s, output: 29.51 toks/s]
Processed prompts:  80%|  | 103/128 [00:03<00:00, 28.19it/s, est. speed input: 30194.62 toks/s, output: 29.49 toks/s]
Processed prompts:  83%| | 106/128 [00:03<00:00, 28.24it/s, est. speed input: 30160.66 toks/s, output: 29.45 toks/s]
Processed prompts:  85%| | 109/128 [00:03<00:00, 28.24it/s, est. speed input: 30125.35 toks/s, output: 29.42 toks/s]
Processed prompts:  88%| | 112/128 [00:03<00:00, 28.20it/s, est. speed input: 30087.98 toks/s, output: 29.38 toks/s]
Processed prompts:  90%| | 115/128 [00:03<00:00, 28.10it/s, est. speed input: 30045.03 toks/s, output: 29.34 toks/s]
Processed prompts:  92%|| 118/128 [00:04<00:00, 28.17it/s, est. speed input: 30017.49 toks/s, output: 29.31 toks/s]
Processed prompts:  95%|| 121/128 [00:04<00:00, 27.80it/s, est. speed input: 29953.08 toks/s, output: 29.25 toks/s]
Processed prompts:  97%|| 124/128 [00:04<00:00, 27.75it/s, est. speed input: 29911.39 toks/s, output: 29.21 toks/s]
Processed prompts:  99%|| 127/128 [00:04<00:00, 27.73it/s, est. speed input: 29872.39 toks/s, output: 29.17 toks/s]
Processed prompts: 100%|| 128/128 [00:04<00:00, 27.73it/s, est. speed input: 29864.57 toks/s, output: 29.16 toks/s]
Processed prompts: 100%|| 128/128 [00:04<00:00, 29.16it/s, est. speed input: 29864.57 toks/s, output: 29.16 toks/s]
[rank0]:[W126 04:21:18.927928512 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-26 04:21:21
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-FP8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 04:21:25 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 04:21:25 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=854425) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=854425) WARNING 01-26 04:21:45 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 29.57 requests/s, 30312.13 total tokens/s, 29.57 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-26 04:21:25] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 04:21:25] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 04:21:25] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 04:21:25] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:21:25] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:21:25] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:21:25] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:21:25] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:21:25] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 04:21:25] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 04:21:25] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:21:25] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:21:25] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:21:25] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 04:21:28] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 04:21:28] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 04:21:28] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 04:21:28] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:21:28] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:21:28] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:21:28] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:21:28] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:21:28] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 04:21:28] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 04:21:28] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:21:28] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:21:28] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:21:28] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=854425) [2026-01-26 04:21:29] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=854425) [2026-01-26 04:21:29] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=854425) [2026-01-26 04:21:29] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=854425) [2026-01-26 04:21:29] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=854425) [2026-01-26 04:21:29] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=854425) [2026-01-26 04:21:29] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=854425) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=854425) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.10s/it]
(EngineCore_DP0 pid=854425) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.10s/it]
(EngineCore_DP0 pid=854425) 
(EngineCore_DP0 pid=854425) [2026-01-26 04:21:39] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=854425) [2026-01-26 04:21:39] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5308416 bytes
(EngineCore_DP0 pid=854425) [2026-01-26 04:21:39] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=854425) [2026-01-26 04:21:39] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3538944 bytes
(EngineCore_DP0 pid=854425) [2026-01-26 04:21:39] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=854425) [2026-01-26 04:21:39] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 28311552 bytes
(EngineCore_DP0 pid=854425) [2026-01-26 04:21:39] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=854425) [2026-01-26 04:21:39] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14024704 bytes
(EngineCore_DP0 pid=854425) 2026-01-26 04:21:44,542 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=854425) 2026-01-26 04:21:44,548 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  23%|       | 58/256 [00:00<00:00, 577.24it/s]
Adding requests:  45%|     | 116/256 [00:00<00:00, 539.36it/s]
Adding requests:  67%|   | 171/256 [00:00<00:00, 526.93it/s]
Adding requests:  88%| | 224/256 [00:00<00:00, 523.07it/s]
Adding requests: 100%|| 256/256 [00:00<00:00, 527.88it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|         | 14/256 [00:00<00:02, 104.32it/s, est. speed input: 106840.17 toks/s, output: 104.33 toks/s]
Processed prompts:  10%|         | 25/256 [00:00<00:04, 48.68it/s, est. speed input: 54754.73 toks/s, output: 53.47 toks/s]   
Processed prompts:  12%|        | 32/256 [00:00<00:05, 38.07it/s, est. speed input: 44599.10 toks/s, output: 43.55 toks/s]
Processed prompts:  14%|        | 37/256 [00:00<00:05, 37.58it/s, est. speed input: 43402.38 toks/s, output: 42.38 toks/s]
Processed prompts:  16%|        | 42/256 [00:01<00:06, 33.43it/s, est. speed input: 40232.25 toks/s, output: 39.29 toks/s]
Processed prompts:  18%|        | 46/256 [00:01<00:06, 32.53it/s, est. speed input: 39157.41 toks/s, output: 38.24 toks/s]
Processed prompts:  20%|        | 50/256 [00:01<00:06, 31.86it/s, est. speed input: 38311.85 toks/s, output: 37.41 toks/s]
Processed prompts:  21%|        | 54/256 [00:01<00:06, 31.43it/s, est. speed input: 37652.94 toks/s, output: 36.77 toks/s]
Processed prompts:  23%|       | 58/256 [00:01<00:06, 31.04it/s, est. speed input: 37082.94 toks/s, output: 36.21 toks/s]
Processed prompts:  24%|       | 62/256 [00:01<00:06, 30.73it/s, est. speed input: 36589.09 toks/s, output: 35.73 toks/s]
Processed prompts:  26%|       | 66/256 [00:01<00:06, 30.40it/s, est. speed input: 36134.94 toks/s, output: 35.29 toks/s]
Processed prompts:  27%|       | 70/256 [00:02<00:06, 30.36it/s, est. speed input: 35794.70 toks/s, output: 34.96 toks/s]
Processed prompts:  29%|       | 74/256 [00:02<00:06, 30.16it/s, est. speed input: 35455.17 toks/s, output: 34.62 toks/s]
Processed prompts:  30%|       | 78/256 [00:02<00:05, 30.11it/s, est. speed input: 35175.76 toks/s, output: 34.35 toks/s]
Processed prompts:  32%|      | 82/256 [00:02<00:05, 30.15it/s, est. speed input: 34944.59 toks/s, output: 34.13 toks/s]
Processed prompts:  34%|      | 86/256 [00:02<00:05, 30.21it/s, est. speed input: 34743.14 toks/s, output: 33.93 toks/s]
Processed prompts:  35%|      | 90/256 [00:02<00:05, 30.06it/s, est. speed input: 34526.89 toks/s, output: 33.72 toks/s]
Processed prompts:  37%|      | 94/256 [00:02<00:05, 30.22it/s, est. speed input: 34378.48 toks/s, output: 33.57 toks/s]
Processed prompts:  38%|      | 98/256 [00:02<00:05, 29.88it/s, est. speed input: 34164.63 toks/s, output: 33.36 toks/s]
Processed prompts:  40%|      | 102/256 [00:03<00:05, 30.17it/s, est. speed input: 34056.15 toks/s, output: 33.26 toks/s]
Processed prompts:  41%|     | 106/256 [00:03<00:04, 30.08it/s, est. speed input: 33911.91 toks/s, output: 33.12 toks/s]
Processed prompts:  43%|     | 110/256 [00:03<00:04, 30.29it/s, est. speed input: 33818.13 toks/s, output: 33.03 toks/s]
Processed prompts:  45%|     | 114/256 [00:03<00:04, 30.20it/s, est. speed input: 33699.30 toks/s, output: 32.91 toks/s]
Processed prompts:  46%|     | 118/256 [00:03<00:04, 30.13it/s, est. speed input: 33587.87 toks/s, output: 32.80 toks/s]
Processed prompts:  48%|     | 122/256 [00:03<00:04, 30.17it/s, est. speed input: 33495.92 toks/s, output: 32.71 toks/s]
Processed prompts:  49%|     | 126/256 [00:03<00:04, 30.19it/s, est. speed input: 33409.38 toks/s, output: 32.63 toks/s]
Processed prompts:  51%|     | 130/256 [00:04<00:04, 29.80it/s, est. speed input: 33277.76 toks/s, output: 32.50 toks/s]
Processed prompts:  52%|    | 134/256 [00:04<00:04, 29.78it/s, est. speed input: 33185.92 toks/s, output: 32.41 toks/s]
Processed prompts:  54%|    | 138/256 [00:04<00:03, 29.97it/s, est. speed input: 33123.09 toks/s, output: 32.35 toks/s]
Processed prompts:  55%|    | 142/256 [00:04<00:03, 29.99it/s, est. speed input: 33051.08 toks/s, output: 32.28 toks/s]
Processed prompts:  57%|    | 146/256 [00:04<00:03, 30.09it/s, est. speed input: 32993.39 toks/s, output: 32.22 toks/s]
Processed prompts:  59%|    | 150/256 [00:04<00:03, 30.22it/s, est. speed input: 32945.04 toks/s, output: 32.17 toks/s]
Processed prompts:  60%|    | 154/256 [00:04<00:03, 30.23it/s, est. speed input: 32890.85 toks/s, output: 32.12 toks/s]
Processed prompts:  62%|   | 158/256 [00:04<00:03, 30.22it/s, est. speed input: 32837.25 toks/s, output: 32.07 toks/s]
Processed prompts:  63%|   | 162/256 [00:05<00:03, 29.88it/s, est. speed input: 32755.72 toks/s, output: 31.99 toks/s]
Processed prompts:  65%|   | 166/256 [00:05<00:03, 29.79it/s, est. speed input: 32691.41 toks/s, output: 31.92 toks/s]
Processed prompts:  66%|   | 170/256 [00:05<00:02, 30.09it/s, est. speed input: 32664.12 toks/s, output: 31.90 toks/s]
Processed prompts:  68%|   | 174/256 [00:05<00:02, 30.14it/s, est. speed input: 32623.14 toks/s, output: 31.86 toks/s]
Processed prompts:  70%|   | 178/256 [00:05<00:02, 30.07it/s, est. speed input: 32575.64 toks/s, output: 31.81 toks/s]
Processed prompts:  71%|   | 182/256 [00:05<00:02, 30.00it/s, est. speed input: 32527.95 toks/s, output: 31.77 toks/s]
Processed prompts:  73%|  | 186/256 [00:05<00:02, 30.01it/s, est. speed input: 32488.19 toks/s, output: 31.73 toks/s]
Processed prompts:  74%|  | 190/256 [00:05<00:02, 30.04it/s, est. speed input: 32451.02 toks/s, output: 31.69 toks/s]
Processed prompts:  76%|  | 194/256 [00:06<00:02, 29.68it/s, est. speed input: 32386.03 toks/s, output: 31.63 toks/s]
Processed prompts:  77%|  | 198/256 [00:06<00:01, 29.87it/s, est. speed input: 32357.67 toks/s, output: 31.60 toks/s]
Processed prompts:  79%|  | 202/256 [00:06<00:01, 29.97it/s, est. speed input: 32328.05 toks/s, output: 31.57 toks/s]
Processed prompts:  80%|  | 206/256 [00:06<00:01, 29.93it/s, est. speed input: 32291.53 toks/s, output: 31.53 toks/s]
Processed prompts:  82%| | 210/256 [00:06<00:01, 30.02it/s, est. speed input: 32265.50 toks/s, output: 31.51 toks/s]
Processed prompts:  84%| | 214/256 [00:06<00:01, 29.90it/s, est. speed input: 32227.37 toks/s, output: 31.47 toks/s]
Processed prompts:  85%| | 218/256 [00:06<00:01, 30.17it/s, est. speed input: 32214.17 toks/s, output: 31.46 toks/s]
Processed prompts:  87%| | 222/256 [00:07<00:01, 30.09it/s, est. speed input: 32184.26 toks/s, output: 31.43 toks/s]
Processed prompts:  88%| | 226/256 [00:07<00:01, 29.82it/s, est. speed input: 32141.25 toks/s, output: 31.39 toks/s]
Processed prompts:  90%| | 230/256 [00:07<00:00, 29.82it/s, est. speed input: 32111.84 toks/s, output: 31.36 toks/s]
Processed prompts:  91%|| 234/256 [00:07<00:00, 29.94it/s, est. speed input: 32091.34 toks/s, output: 31.34 toks/s]
Processed prompts:  93%|| 238/256 [00:07<00:00, 29.74it/s, est. speed input: 32053.48 toks/s, output: 31.30 toks/s]
Processed prompts:  95%|| 242/256 [00:07<00:00, 29.67it/s, est. speed input: 32020.90 toks/s, output: 31.27 toks/s]
Processed prompts:  96%|| 246/256 [00:07<00:00, 29.78it/s, est. speed input: 31999.62 toks/s, output: 31.25 toks/s]
Processed prompts:  98%|| 250/256 [00:08<00:00, 30.06it/s, est. speed input: 31990.98 toks/s, output: 31.24 toks/s]
Processed prompts:  99%|| 254/256 [00:08<00:00, 30.08it/s, est. speed input: 31972.58 toks/s, output: 31.22 toks/s]
Processed prompts: 100%|| 256/256 [00:08<00:00, 30.08it/s, est. speed input: 32086.23 toks/s, output: 31.33 toks/s]
Processed prompts: 100%|| 256/256 [00:08<00:00, 31.33it/s, est. speed input: 32086.23 toks/s, output: 31.33 toks/s]
[rank0]:[W126 04:21:54.293025158 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-26 04:21:56
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-FP8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 04:22:01 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 04:22:01 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=855177) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=855177) WARNING 01-26 04:22:21 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 28.96 requests/s, 29679.89 total tokens/s, 28.96 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-26 04:22:01] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 04:22:01] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 04:22:01] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 04:22:01] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:22:01] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:22:01] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:22:01] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:22:01] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:22:01] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 04:22:01] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 04:22:01] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:22:01] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:22:01] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:22:01] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 04:22:04] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 04:22:04] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 04:22:04] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 04:22:04] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:22:04] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:22:04] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:22:04] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:22:04] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:22:04] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 04:22:04] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 04:22:04] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:22:04] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:22:04] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:22:04] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=855177) [2026-01-26 04:22:05] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=855177) [2026-01-26 04:22:05] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=855177) [2026-01-26 04:22:05] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=855177) [2026-01-26 04:22:05] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=855177) [2026-01-26 04:22:05] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=855177) [2026-01-26 04:22:05] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=855177) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=855177) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.14s/it]
(EngineCore_DP0 pid=855177) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.14s/it]
(EngineCore_DP0 pid=855177) 
(EngineCore_DP0 pid=855177) [2026-01-26 04:22:15] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=855177) [2026-01-26 04:22:15] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5308416 bytes
(EngineCore_DP0 pid=855177) [2026-01-26 04:22:15] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=855177) [2026-01-26 04:22:15] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3538944 bytes
(EngineCore_DP0 pid=855177) [2026-01-26 04:22:15] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=855177) [2026-01-26 04:22:15] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 28311552 bytes
(EngineCore_DP0 pid=855177) [2026-01-26 04:22:15] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=855177) [2026-01-26 04:22:15] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14024704 bytes
(EngineCore_DP0 pid=855177) 2026-01-26 04:22:20,619 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=855177) 2026-01-26 04:22:20,626 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:  11%|         | 57/512 [00:00<00:00, 563.65it/s]
Adding requests:  22%|       | 114/512 [00:00<00:00, 530.04it/s]
Adding requests:  33%|      | 168/512 [00:00<00:00, 511.57it/s]
Adding requests:  43%|     | 220/512 [00:00<00:00, 503.73it/s]
Adding requests:  53%|    | 271/512 [00:00<00:00, 502.88it/s]
Adding requests:  63%|   | 322/512 [00:00<00:00, 488.09it/s]
Adding requests:  73%|  | 374/512 [00:00<00:00, 494.66it/s]
Adding requests:  83%| | 424/512 [00:00<00:00, 490.14it/s]
Adding requests:  93%|| 474/512 [00:00<00:00, 489.25it/s]
Adding requests: 100%|| 512/512 [00:01<00:00, 495.75it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|         | 30/512 [00:00<00:03, 141.89it/s, est. speed input: 145303.31 toks/s, output: 141.89 toks/s]
Processed prompts:   9%|         | 45/512 [00:00<00:07, 64.40it/s, est. speed input: 74029.94 toks/s, output: 72.29 toks/s]   
Processed prompts:  10%|         | 53/512 [00:00<00:09, 49.61it/s, est. speed input: 60277.64 toks/s, output: 58.86 toks/s]
Processed prompts:  12%|        | 59/512 [00:01<00:11, 39.34it/s, est. speed input: 51414.21 toks/s, output: 50.21 toks/s]
Processed prompts:  12%|        | 64/512 [00:01<00:11, 38.71it/s, est. speed input: 49918.52 toks/s, output: 48.75 toks/s]
Processed prompts:  13%|        | 69/512 [00:01<00:11, 38.29it/s, est. speed input: 48781.11 toks/s, output: 47.64 toks/s]
Processed prompts:  14%|        | 73/512 [00:01<00:12, 36.01it/s, est. speed input: 47132.83 toks/s, output: 46.03 toks/s]
Processed prompts:  15%|        | 77/512 [00:01<00:12, 34.12it/s, est. speed input: 45718.45 toks/s, output: 44.65 toks/s]
Processed prompts:  16%|        | 81/512 [00:01<00:13, 32.51it/s, est. speed input: 44449.48 toks/s, output: 43.41 toks/s]
Processed prompts:  17%|        | 85/512 [00:02<00:13, 31.70it/s, est. speed input: 43492.83 toks/s, output: 42.47 toks/s]
Processed prompts:  17%|        | 89/512 [00:02<00:13, 30.97it/s, est. speed input: 42615.37 toks/s, output: 41.62 toks/s]
Processed prompts:  18%|        | 93/512 [00:02<00:13, 30.47it/s, est. speed input: 41853.24 toks/s, output: 40.87 toks/s]
Processed prompts:  19%|        | 97/512 [00:02<00:13, 30.04it/s, est. speed input: 41158.50 toks/s, output: 40.19 toks/s]
Processed prompts:  20%|        | 100/512 [00:02<00:14, 27.65it/s, est. speed input: 40152.73 toks/s, output: 39.21 toks/s]
Processed prompts:  20%|        | 103/512 [00:02<00:15, 26.00it/s, est. speed input: 39263.62 toks/s, output: 38.34 toks/s]
Processed prompts:  21%|        | 106/512 [00:02<00:16, 24.81it/s, est. speed input: 38453.57 toks/s, output: 37.55 toks/s]
Processed prompts:  21%|       | 110/512 [00:02<00:15, 25.67it/s, est. speed input: 37954.87 toks/s, output: 37.07 toks/s]
Processed prompts:  22%|       | 114/512 [00:03<00:14, 26.81it/s, est. speed input: 37619.53 toks/s, output: 36.74 toks/s]
Processed prompts:  23%|       | 118/512 [00:03<00:14, 27.52it/s, est. speed input: 37293.07 toks/s, output: 36.42 toks/s]
Processed prompts:  24%|       | 122/512 [00:03<00:13, 28.16it/s, est. speed input: 37018.53 toks/s, output: 36.15 toks/s]
Processed prompts:  25%|       | 126/512 [00:03<00:13, 28.46it/s, est. speed input: 36739.14 toks/s, output: 35.88 toks/s]
Processed prompts:  25%|       | 130/512 [00:03<00:13, 28.78it/s, est. speed input: 36498.13 toks/s, output: 35.64 toks/s]
Processed prompts:  26%|       | 134/512 [00:03<00:13, 28.91it/s, est. speed input: 36260.57 toks/s, output: 35.41 toks/s]
Processed prompts:  27%|       | 138/512 [00:03<00:12, 29.20it/s, est. speed input: 36066.34 toks/s, output: 35.22 toks/s]
Processed prompts:  28%|       | 142/512 [00:04<00:12, 28.99it/s, est. speed input: 35829.67 toks/s, output: 34.99 toks/s]
Processed prompts:  29%|       | 146/512 [00:04<00:12, 29.13it/s, est. speed input: 35645.38 toks/s, output: 34.81 toks/s]
Processed prompts:  29%|       | 150/512 [00:04<00:12, 29.10it/s, est. speed input: 35457.15 toks/s, output: 34.63 toks/s]
Processed prompts:  30%|       | 154/512 [00:04<00:12, 29.14it/s, est. speed input: 35288.68 toks/s, output: 34.46 toks/s]
Processed prompts:  31%|       | 158/512 [00:04<00:12, 29.11it/s, est. speed input: 35122.03 toks/s, output: 34.30 toks/s]
Processed prompts:  32%|      | 162/512 [00:04<00:11, 29.22it/s, est. speed input: 34980.90 toks/s, output: 34.16 toks/s]
Processed prompts:  32%|      | 166/512 [00:04<00:11, 29.12it/s, est. speed input: 34827.60 toks/s, output: 34.01 toks/s]
Processed prompts:  33%|      | 170/512 [00:05<00:11, 28.87it/s, est. speed input: 34663.92 toks/s, output: 33.85 toks/s]
Processed prompts:  34%|      | 174/512 [00:05<00:11, 28.97it/s, est. speed input: 34537.56 toks/s, output: 33.73 toks/s]
Processed prompts:  35%|      | 178/512 [00:05<00:11, 29.08it/s, est. speed input: 34421.13 toks/s, output: 33.61 toks/s]
Processed prompts:  36%|      | 182/512 [00:05<00:11, 29.09it/s, est. speed input: 34305.20 toks/s, output: 33.50 toks/s]
Processed prompts:  36%|      | 186/512 [00:05<00:11, 29.05it/s, est. speed input: 34189.84 toks/s, output: 33.39 toks/s]
Processed prompts:  37%|      | 190/512 [00:05<00:11, 29.09it/s, est. speed input: 34086.31 toks/s, output: 33.29 toks/s]
Processed prompts:  38%|      | 194/512 [00:05<00:10, 29.14it/s, est. speed input: 33989.64 toks/s, output: 33.19 toks/s]
Processed prompts:  39%|      | 198/512 [00:05<00:10, 29.04it/s, est. speed input: 33886.13 toks/s, output: 33.09 toks/s]
Processed prompts:  39%|      | 202/512 [00:06<00:10, 28.91it/s, est. speed input: 33780.78 toks/s, output: 32.99 toks/s]
Processed prompts:  40%|      | 206/512 [00:06<00:10, 29.01it/s, est. speed input: 33697.14 toks/s, output: 32.91 toks/s]
Processed prompts:  41%|      | 210/512 [00:06<00:10, 29.14it/s, est. speed input: 33621.95 toks/s, output: 32.83 toks/s]
Processed prompts:  42%|     | 214/512 [00:06<00:10, 29.20it/s, est. speed input: 33547.59 toks/s, output: 32.76 toks/s]
Processed prompts:  43%|     | 218/512 [00:06<00:10, 29.36it/s, est. speed input: 33484.77 toks/s, output: 32.70 toks/s]
Processed prompts:  43%|     | 222/512 [00:06<00:09, 29.47it/s, est. speed input: 33424.98 toks/s, output: 32.64 toks/s]
Processed prompts:  44%|     | 226/512 [00:06<00:09, 29.47it/s, est. speed input: 33361.47 toks/s, output: 32.58 toks/s]
Processed prompts:  45%|     | 230/512 [00:07<00:09, 29.37it/s, est. speed input: 33293.26 toks/s, output: 32.51 toks/s]
Processed prompts:  46%|     | 234/512 [00:07<00:09, 29.18it/s, est. speed input: 33218.37 toks/s, output: 32.44 toks/s]
Processed prompts:  46%|     | 238/512 [00:07<00:09, 29.11it/s, est. speed input: 33151.39 toks/s, output: 32.37 toks/s]
Processed prompts:  47%|     | 242/512 [00:07<00:09, 29.11it/s, est. speed input: 33090.09 toks/s, output: 32.31 toks/s]
Processed prompts:  48%|     | 246/512 [00:07<00:09, 29.16it/s, est. speed input: 33034.44 toks/s, output: 32.26 toks/s]
Processed prompts:  49%|     | 250/512 [00:07<00:08, 29.17it/s, est. speed input: 32978.97 toks/s, output: 32.21 toks/s]
Processed prompts:  50%|     | 254/512 [00:07<00:08, 29.36it/s, est. speed input: 32937.26 toks/s, output: 32.17 toks/s]
Processed prompts:  50%|     | 258/512 [00:08<00:08, 29.37it/s, est. speed input: 32889.25 toks/s, output: 32.12 toks/s]
Processed prompts:  51%|     | 262/512 [00:08<00:08, 29.34it/s, est. speed input: 32840.50 toks/s, output: 32.07 toks/s]
Processed prompts:  52%|    | 266/512 [00:08<00:08, 29.07it/s, est. speed input: 32778.25 toks/s, output: 32.01 toks/s]
Processed prompts:  53%|    | 270/512 [00:08<00:08, 29.05it/s, est. speed input: 32727.43 toks/s, output: 31.96 toks/s]
Processed prompts:  54%|    | 274/512 [00:08<00:08, 29.16it/s, est. speed input: 32686.58 toks/s, output: 31.92 toks/s]
Processed prompts:  54%|    | 278/512 [00:08<00:08, 29.12it/s, est. speed input: 32639.58 toks/s, output: 31.87 toks/s]
Processed prompts:  55%|    | 282/512 [00:08<00:07, 29.37it/s, est. speed input: 32610.12 toks/s, output: 31.85 toks/s]
Processed prompts:  56%|    | 286/512 [00:08<00:07, 29.37it/s, est. speed input: 32571.97 toks/s, output: 31.81 toks/s]
Processed prompts:  57%|    | 290/512 [00:09<00:07, 29.28it/s, est. speed input: 32529.69 toks/s, output: 31.77 toks/s]
Processed prompts:  57%|    | 294/512 [00:09<00:07, 28.96it/s, est. speed input: 32474.18 toks/s, output: 31.71 toks/s]
Processed prompts:  58%|    | 298/512 [00:09<00:07, 29.07it/s, est. speed input: 32439.08 toks/s, output: 31.68 toks/s]
Processed prompts:  59%|    | 302/512 [00:09<00:07, 29.08it/s, est. speed input: 32401.16 toks/s, output: 31.64 toks/s]
Processed prompts:  60%|    | 306/512 [00:09<00:07, 29.11it/s, est. speed input: 32365.37 toks/s, output: 31.61 toks/s]
Processed prompts:  61%|    | 310/512 [00:09<00:06, 29.18it/s, est. speed input: 32333.44 toks/s, output: 31.58 toks/s]
Processed prompts:  61%|   | 314/512 [00:09<00:06, 29.29it/s, est. speed input: 32305.20 toks/s, output: 31.55 toks/s]
Processed prompts:  62%|   | 318/512 [00:10<00:06, 29.24it/s, est. speed input: 32271.53 toks/s, output: 31.52 toks/s]
Processed prompts:  63%|   | 322/512 [00:10<00:06, 29.33it/s, est. speed input: 32244.58 toks/s, output: 31.49 toks/s]
Processed prompts:  64%|   | 326/512 [00:10<00:06, 28.98it/s, est. speed input: 32198.66 toks/s, output: 31.44 toks/s]
Processed prompts:  64%|   | 330/512 [00:10<00:06, 28.97it/s, est. speed input: 32164.99 toks/s, output: 31.41 toks/s]
Processed prompts:  65%|   | 334/512 [00:10<00:06, 29.14it/s, est. speed input: 32140.69 toks/s, output: 31.39 toks/s]
Processed prompts:  66%|   | 338/512 [00:10<00:05, 29.12it/s, est. speed input: 32110.16 toks/s, output: 31.36 toks/s]
Processed prompts:  67%|   | 342/512 [00:10<00:05, 29.57it/s, est. speed input: 32102.10 toks/s, output: 31.35 toks/s]
Processed prompts:  68%|   | 346/512 [00:11<00:05, 29.64it/s, est. speed input: 32082.92 toks/s, output: 31.33 toks/s]
Processed prompts:  68%|   | 350/512 [00:11<00:05, 29.51it/s, est. speed input: 32056.39 toks/s, output: 31.31 toks/s]
Processed prompts:  69%|   | 354/512 [00:11<00:05, 29.46it/s, est. speed input: 32032.11 toks/s, output: 31.28 toks/s]
Processed prompts:  70%|   | 358/512 [00:11<00:05, 29.20it/s, est. speed input: 31998.77 toks/s, output: 31.25 toks/s]
Processed prompts:  71%|   | 362/512 [00:11<00:05, 29.16it/s, est. speed input: 31972.26 toks/s, output: 31.22 toks/s]
Processed prompts:  71%|  | 366/512 [00:11<00:04, 29.25it/s, est. speed input: 31951.29 toks/s, output: 31.20 toks/s]
Processed prompts:  72%|  | 370/512 [00:11<00:04, 29.16it/s, est. speed input: 31924.32 toks/s, output: 31.18 toks/s]
Processed prompts:  73%|  | 374/512 [00:12<00:04, 29.05it/s, est. speed input: 31896.42 toks/s, output: 31.15 toks/s]
Processed prompts:  74%|  | 378/512 [00:12<00:04, 29.00it/s, est. speed input: 31870.14 toks/s, output: 31.12 toks/s]
Processed prompts:  75%|  | 382/512 [00:12<00:04, 29.17it/s, est. speed input: 31852.38 toks/s, output: 31.11 toks/s]
Processed prompts:  75%|  | 386/512 [00:12<00:04, 29.09it/s, est. speed input: 31827.28 toks/s, output: 31.08 toks/s]
Processed prompts:  76%|  | 390/512 [00:12<00:04, 28.76it/s, est. speed input: 31791.72 toks/s, output: 31.05 toks/s]
Processed prompts:  77%|  | 394/512 [00:12<00:04, 28.92it/s, est. speed input: 31772.64 toks/s, output: 31.03 toks/s]
Processed prompts:  78%|  | 398/512 [00:12<00:03, 28.96it/s, est. speed input: 31750.74 toks/s, output: 31.01 toks/s]
Processed prompts:  79%|  | 402/512 [00:12<00:03, 29.02it/s, est. speed input: 31730.84 toks/s, output: 30.99 toks/s]
Processed prompts:  79%|  | 406/512 [00:13<00:03, 29.07it/s, est. speed input: 31711.52 toks/s, output: 30.97 toks/s]
Processed prompts:  80%|  | 410/512 [00:13<00:03, 29.11it/s, est. speed input: 31692.76 toks/s, output: 30.95 toks/s]
Processed prompts:  81%|  | 414/512 [00:13<00:03, 29.23it/s, est. speed input: 31677.96 toks/s, output: 30.94 toks/s]
Processed prompts:  82%| | 418/512 [00:13<00:03, 28.85it/s, est. speed input: 31646.07 toks/s, output: 30.90 toks/s]
Processed prompts:  82%| | 422/512 [00:13<00:03, 28.94it/s, est. speed input: 31628.14 toks/s, output: 30.89 toks/s]
Processed prompts:  83%| | 426/512 [00:13<00:02, 29.08it/s, est. speed input: 31613.13 toks/s, output: 30.87 toks/s]
Processed prompts:  84%| | 430/512 [00:13<00:02, 29.22it/s, est. speed input: 31599.91 toks/s, output: 30.86 toks/s]
Processed prompts:  85%| | 434/512 [00:14<00:02, 29.39it/s, est. speed input: 31589.67 toks/s, output: 30.85 toks/s]
Processed prompts:  86%| | 438/512 [00:14<00:02, 29.27it/s, est. speed input: 31571.24 toks/s, output: 30.83 toks/s]
Processed prompts:  86%| | 442/512 [00:14<00:02, 29.25it/s, est. speed input: 31555.26 toks/s, output: 30.82 toks/s]
Processed prompts:  87%| | 446/512 [00:14<00:02, 29.30it/s, est. speed input: 31541.74 toks/s, output: 30.80 toks/s]
Processed prompts:  88%| | 450/512 [00:14<00:02, 29.78it/s, est. speed input: 31543.29 toks/s, output: 30.80 toks/s]
Processed prompts:  89%| | 454/512 [00:14<00:01, 29.63it/s, est. speed input: 31528.85 toks/s, output: 30.79 toks/s]
Processed prompts:  89%| | 458/512 [00:14<00:01, 29.44it/s, est. speed input: 31511.99 toks/s, output: 30.77 toks/s]
Processed prompts:  90%| | 462/512 [00:15<00:01, 29.41it/s, est. speed input: 31498.82 toks/s, output: 30.76 toks/s]
Processed prompts:  91%| | 466/512 [00:15<00:01, 29.39it/s, est. speed input: 31485.48 toks/s, output: 30.75 toks/s]
Processed prompts:  92%|| 470/512 [00:15<00:01, 29.41it/s, est. speed input: 31473.73 toks/s, output: 30.74 toks/s]
Processed prompts:  93%|| 474/512 [00:15<00:01, 29.45it/s, est. speed input: 31463.17 toks/s, output: 30.73 toks/s]
Processed prompts:  93%|| 478/512 [00:15<00:01, 29.36it/s, est. speed input: 31448.87 toks/s, output: 30.71 toks/s]
Processed prompts:  94%|| 482/512 [00:15<00:01, 29.01it/s, est. speed input: 31426.11 toks/s, output: 30.69 toks/s]
Processed prompts:  95%|| 486/512 [00:15<00:00, 29.08it/s, est. speed input: 31413.12 toks/s, output: 30.68 toks/s]
Processed prompts:  96%|| 490/512 [00:15<00:00, 29.16it/s, est. speed input: 31401.46 toks/s, output: 30.67 toks/s]
Processed prompts:  96%|| 494/512 [00:16<00:00, 29.14it/s, est. speed input: 31387.71 toks/s, output: 30.65 toks/s]
Processed prompts:  97%|| 498/512 [00:16<00:00, 29.12it/s, est. speed input: 31374.11 toks/s, output: 30.64 toks/s]
Processed prompts:  98%|| 502/512 [00:16<00:00, 29.25it/s, est. speed input: 31365.13 toks/s, output: 30.63 toks/s]
Processed prompts:  99%|| 506/512 [00:16<00:00, 29.21it/s, est. speed input: 31352.15 toks/s, output: 30.62 toks/s]
Processed prompts: 100%|| 510/512 [00:16<00:00, 30.24it/s, est. speed input: 31369.45 toks/s, output: 30.63 toks/s]
Processed prompts: 100%|| 512/512 [00:16<00:00, 30.24it/s, est. speed input: 31492.28 toks/s, output: 30.75 toks/s]
Processed prompts: 100%|| 512/512 [00:16<00:00, 30.75it/s, est. speed input: 31492.28 toks/s, output: 30.75 toks/s]
[rank0]:[W126 04:22:39.445433490 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-26 04:22:41
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-FP8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 04:22:47 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 04:22:47 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=856022) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=856022) WARNING 01-26 04:23:08 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 28.77 requests/s, 29489.53 total tokens/s, 28.77 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-26 04:22:47] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 04:22:47] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 04:22:47] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 04:22:47] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:22:47] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:22:47] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:22:47] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:22:47] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:22:47] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 04:22:47] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 04:22:47] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:22:47] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:22:47] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:22:47] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 04:22:51] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 04:22:51] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 04:22:51] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 04:22:51] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:22:51] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:22:51] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:22:51] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:22:51] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 04:22:51] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 04:22:51] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 04:22:51] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:22:51] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:22:51] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:22:51] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=856022) [2026-01-26 04:22:52] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=856022) [2026-01-26 04:22:52] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=856022) [2026-01-26 04:22:52] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=856022) [2026-01-26 04:22:52] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=856022) [2026-01-26 04:22:52] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=856022) [2026-01-26 04:22:52] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=856022) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=856022) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.01s/it]
(EngineCore_DP0 pid=856022) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.01s/it]
(EngineCore_DP0 pid=856022) 
(EngineCore_DP0 pid=856022) [2026-01-26 04:23:01] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=856022) [2026-01-26 04:23:01] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5308416 bytes
(EngineCore_DP0 pid=856022) [2026-01-26 04:23:01] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=856022) [2026-01-26 04:23:01] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3538944 bytes
(EngineCore_DP0 pid=856022) [2026-01-26 04:23:01] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=856022) [2026-01-26 04:23:01] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 28311552 bytes
(EngineCore_DP0 pid=856022) [2026-01-26 04:23:01] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=856022) [2026-01-26 04:23:01] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14024704 bytes
(EngineCore_DP0 pid=856022) 2026-01-26 04:23:07,319 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=856022) 2026-01-26 04:23:07,370 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   5%|         | 55/1024 [00:00<00:01, 541.36it/s]
Adding requests:  11%|         | 110/1024 [00:00<00:01, 524.09it/s]
Adding requests:  16%|        | 163/1024 [00:00<00:01, 501.09it/s]
Adding requests:  21%|        | 214/1024 [00:00<00:01, 496.55it/s]
Adding requests:  26%|       | 264/1024 [00:00<00:01, 486.73it/s]
Adding requests:  31%|       | 314/1024 [00:00<00:01, 488.97it/s]
Adding requests:  35%|      | 363/1024 [00:00<00:01, 484.30it/s]
Adding requests:  40%|      | 412/1024 [00:00<00:01, 479.42it/s]
Adding requests:  45%|     | 460/1024 [00:00<00:01, 478.62it/s]
Adding requests:  50%|     | 508/1024 [00:01<00:01, 470.09it/s]
Adding requests:  54%|    | 556/1024 [00:01<00:01, 454.43it/s]
Adding requests:  59%|    | 605/1024 [00:01<00:00, 462.47it/s]
Adding requests:  64%|   | 652/1024 [00:01<00:00, 450.04it/s]
Adding requests:  68%|   | 700/1024 [00:01<00:00, 458.50it/s]
Adding requests:  73%|  | 746/1024 [00:01<00:00, 451.11it/s]
Adding requests:  78%|  | 796/1024 [00:01<00:00, 462.77it/s]
Adding requests:  82%| | 843/1024 [00:01<00:00, 451.54it/s]
Adding requests:  87%| | 890/1024 [00:01<00:00, 454.90it/s]
Adding requests:  92%|| 937/1024 [00:01<00:00, 458.44it/s]
Adding requests:  96%|| 986/1024 [00:02<00:00, 465.63it/s]
Adding requests: 100%|| 1024/1024 [00:02<00:00, 470.02it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|         | 58/1024 [00:00<00:03, 295.57it/s, est. speed input: 302708.37 toks/s, output: 295.58 toks/s]
Processed prompts:   9%|         | 88/1024 [00:01<00:12, 72.57it/s, est. speed input: 87345.71 toks/s, output: 85.30 toks/s]   
Processed prompts:  10%|         | 103/1024 [00:01<00:17, 52.37it/s, est. speed input: 66720.80 toks/s, output: 65.16 toks/s]
Processed prompts:  11%|         | 113/1024 [00:01<00:18, 48.26it/s, est. speed input: 62162.38 toks/s, output: 60.71 toks/s]
Processed prompts:  12%|        | 120/1024 [00:02<00:21, 42.38it/s, est. speed input: 57488.83 toks/s, output: 56.14 toks/s]
Processed prompts:  12%|        | 126/1024 [00:02<00:24, 36.86it/s, est. speed input: 53470.50 toks/s, output: 52.22 toks/s]
Processed prompts:  13%|        | 131/1024 [00:02<00:28, 31.56it/s, est. speed input: 49827.23 toks/s, output: 48.66 toks/s]
Processed prompts:  13%|        | 138/1024 [00:02<00:29, 29.72it/s, est. speed input: 47561.70 toks/s, output: 46.45 toks/s]
Processed prompts:  14%|        | 146/1024 [00:03<00:29, 29.47it/s, est. speed input: 46023.03 toks/s, output: 44.94 toks/s]
Processed prompts:  15%|        | 154/1024 [00:03<00:29, 29.22it/s, est. speed input: 44699.95 toks/s, output: 43.65 toks/s]
Processed prompts:  16%|        | 162/1024 [00:03<00:29, 29.04it/s, est. speed input: 43569.83 toks/s, output: 42.55 toks/s]
Processed prompts:  17%|        | 170/1024 [00:04<00:29, 29.06it/s, est. speed input: 42642.20 toks/s, output: 41.64 toks/s]
Processed prompts:  17%|        | 178/1024 [00:04<00:29, 29.03it/s, est. speed input: 41819.04 toks/s, output: 40.84 toks/s]
Processed prompts:  18%|        | 186/1024 [00:04<00:28, 28.97it/s, est. speed input: 41082.55 toks/s, output: 40.12 toks/s]
Processed prompts:  19%|        | 194/1024 [00:04<00:28, 28.87it/s, est. speed input: 40415.32 toks/s, output: 39.47 toks/s]
Processed prompts:  20%|        | 202/1024 [00:05<00:28, 28.88it/s, est. speed input: 39837.87 toks/s, output: 38.90 toks/s]
Processed prompts:  21%|        | 210/1024 [00:05<00:28, 28.96it/s, est. speed input: 39335.75 toks/s, output: 38.41 toks/s]
Processed prompts:  21%|       | 218/1024 [00:05<00:27, 28.94it/s, est. speed input: 38865.60 toks/s, output: 37.95 toks/s]
Processed prompts:  22%|       | 226/1024 [00:06<00:27, 28.76it/s, est. speed input: 38405.66 toks/s, output: 37.51 toks/s]
Processed prompts:  23%|       | 234/1024 [00:06<00:27, 28.82it/s, est. speed input: 38022.08 toks/s, output: 37.13 toks/s]
Processed prompts:  24%|       | 242/1024 [00:06<00:27, 28.81it/s, est. speed input: 37660.68 toks/s, output: 36.78 toks/s]
Processed prompts:  24%|       | 250/1024 [00:06<00:26, 28.82it/s, est. speed input: 37332.20 toks/s, output: 36.46 toks/s]
Processed prompts:  25%|       | 258/1024 [00:07<00:26, 28.67it/s, est. speed input: 37003.17 toks/s, output: 36.14 toks/s]
Processed prompts:  26%|       | 266/1024 [00:07<00:26, 28.77it/s, est. speed input: 36731.96 toks/s, output: 35.87 toks/s]
Processed prompts:  27%|       | 274/1024 [00:07<00:25, 28.89it/s, est. speed input: 36487.68 toks/s, output: 35.63 toks/s]
Processed prompts:  28%|       | 282/1024 [00:07<00:25, 28.92it/s, est. speed input: 36252.16 toks/s, output: 35.40 toks/s]
Processed prompts:  28%|       | 290/1024 [00:08<00:25, 28.75it/s, est. speed input: 36005.92 toks/s, output: 35.16 toks/s]
Processed prompts:  29%|       | 298/1024 [00:08<00:25, 28.85it/s, est. speed input: 35804.08 toks/s, output: 34.96 toks/s]
Processed prompts:  30%|       | 306/1024 [00:08<00:24, 28.94it/s, est. speed input: 35618.66 toks/s, output: 34.78 toks/s]
Processed prompts:  31%|       | 314/1024 [00:09<00:24, 28.91it/s, est. speed input: 35432.97 toks/s, output: 34.60 toks/s]
Processed prompts:  31%|      | 322/1024 [00:09<00:24, 28.78it/s, est. speed input: 35244.99 toks/s, output: 34.42 toks/s]
Processed prompts:  32%|      | 330/1024 [00:09<00:24, 28.80it/s, est. speed input: 35080.57 toks/s, output: 34.26 toks/s]
Processed prompts:  33%|      | 338/1024 [00:09<00:23, 28.99it/s, est. speed input: 34945.44 toks/s, output: 34.13 toks/s]
Processed prompts:  34%|      | 346/1024 [00:10<00:23, 28.86it/s, est. speed input: 34789.06 toks/s, output: 33.97 toks/s]
Processed prompts:  35%|      | 354/1024 [00:10<00:23, 28.86it/s, est. speed input: 34650.39 toks/s, output: 33.84 toks/s]
Processed prompts:  35%|      | 362/1024 [00:10<00:22, 28.91it/s, est. speed input: 34523.71 toks/s, output: 33.71 toks/s]
Processed prompts:  36%|      | 370/1024 [00:11<00:22, 28.91it/s, est. speed input: 34399.79 toks/s, output: 33.59 toks/s]
Processed prompts:  37%|      | 378/1024 [00:11<00:22, 28.69it/s, est. speed input: 34261.29 toks/s, output: 33.46 toks/s]
Processed prompts:  38%|      | 386/1024 [00:11<00:22, 28.85it/s, est. speed input: 34158.75 toks/s, output: 33.36 toks/s]
Processed prompts:  38%|      | 394/1024 [00:11<00:21, 28.89it/s, est. speed input: 34054.43 toks/s, output: 33.26 toks/s]
Processed prompts:  39%|      | 402/1024 [00:12<00:21, 28.93it/s, est. speed input: 33955.60 toks/s, output: 33.16 toks/s]
Processed prompts:  40%|      | 410/1024 [00:12<00:21, 28.85it/s, est. speed input: 33851.92 toks/s, output: 33.06 toks/s]
Processed prompts:  41%|      | 418/1024 [00:12<00:21, 28.85it/s, est. speed input: 33757.86 toks/s, output: 32.97 toks/s]
Processed prompts:  42%|     | 426/1024 [00:12<00:20, 28.84it/s, est. speed input: 33667.17 toks/s, output: 32.88 toks/s]
Processed prompts:  42%|     | 434/1024 [00:13<00:20, 28.85it/s, est. speed input: 33581.01 toks/s, output: 32.79 toks/s]
Processed prompts:  43%|     | 442/1024 [00:13<00:20, 28.71it/s, est. speed input: 33486.70 toks/s, output: 32.70 toks/s]
Processed prompts:  44%|     | 450/1024 [00:13<00:19, 29.33it/s, est. speed input: 33451.57 toks/s, output: 32.67 toks/s]
Processed prompts:  45%|     | 458/1024 [00:14<00:19, 29.16it/s, est. speed input: 33372.92 toks/s, output: 32.59 toks/s]
Processed prompts:  46%|     | 466/1024 [00:14<00:19, 29.08it/s, est. speed input: 33299.59 toks/s, output: 32.52 toks/s]
Processed prompts:  46%|     | 474/1024 [00:14<00:19, 28.87it/s, est. speed input: 33218.46 toks/s, output: 32.44 toks/s]
Processed prompts:  47%|     | 482/1024 [00:14<00:18, 28.88it/s, est. speed input: 33151.17 toks/s, output: 32.37 toks/s]
Processed prompts:  48%|     | 490/1024 [00:15<00:18, 28.93it/s, est. speed input: 33088.83 toks/s, output: 32.31 toks/s]
Processed prompts:  49%|     | 498/1024 [00:15<00:18, 28.94it/s, est. speed input: 33027.42 toks/s, output: 32.25 toks/s]
Processed prompts:  49%|     | 506/1024 [00:15<00:18, 28.77it/s, est. speed input: 32956.62 toks/s, output: 32.18 toks/s]
Processed prompts:  50%|     | 514/1024 [00:15<00:17, 28.87it/s, est. speed input: 32902.13 toks/s, output: 32.13 toks/s]
Processed prompts:  51%|     | 522/1024 [00:16<00:17, 28.86it/s, est. speed input: 32844.72 toks/s, output: 32.07 toks/s]
Processed prompts:  52%|    | 530/1024 [00:16<00:17, 28.82it/s, est. speed input: 32787.45 toks/s, output: 32.02 toks/s]
Processed prompts:  53%|    | 538/1024 [00:16<00:16, 28.75it/s, est. speed input: 32728.70 toks/s, output: 31.96 toks/s]
Processed prompts:  53%|    | 546/1024 [00:17<00:16, 28.75it/s, est. speed input: 32675.09 toks/s, output: 31.91 toks/s]
Processed prompts:  54%|    | 554/1024 [00:17<00:16, 28.86it/s, est. speed input: 32630.15 toks/s, output: 31.87 toks/s]
Processed prompts:  55%|    | 562/1024 [00:17<00:16, 28.79it/s, est. speed input: 32577.76 toks/s, output: 31.81 toks/s]
Processed prompts:  56%|    | 570/1024 [00:17<00:15, 28.83it/s, est. speed input: 32531.85 toks/s, output: 31.77 toks/s]
Processed prompts:  56%|    | 578/1024 [00:18<00:15, 28.89it/s, est. speed input: 32489.46 toks/s, output: 31.73 toks/s]
Processed prompts:  57%|    | 586/1024 [00:18<00:15, 28.89it/s, est. speed input: 32445.87 toks/s, output: 31.69 toks/s]
Processed prompts:  58%|    | 594/1024 [00:18<00:14, 28.77it/s, est. speed input: 32397.33 toks/s, output: 31.64 toks/s]
Processed prompts:  59%|    | 602/1024 [00:19<00:14, 28.82it/s, est. speed input: 32357.29 toks/s, output: 31.60 toks/s]
Processed prompts:  60%|    | 610/1024 [00:19<00:14, 28.83it/s, est. speed input: 32317.04 toks/s, output: 31.56 toks/s]
Processed prompts:  60%|    | 618/1024 [00:19<00:14, 28.88it/s, est. speed input: 32279.93 toks/s, output: 31.52 toks/s]
Processed prompts:  61%|    | 626/1024 [00:19<00:13, 28.74it/s, est. speed input: 32235.19 toks/s, output: 31.48 toks/s]
Processed prompts:  62%|   | 634/1024 [00:20<00:13, 28.80it/s, est. speed input: 32199.51 toks/s, output: 31.44 toks/s]
Processed prompts:  63%|   | 642/1024 [00:20<00:13, 28.85it/s, est. speed input: 32164.93 toks/s, output: 31.41 toks/s]
Processed prompts:  63%|   | 650/1024 [00:20<00:12, 28.89it/s, est. speed input: 32131.83 toks/s, output: 31.38 toks/s]
Processed prompts:  64%|   | 658/1024 [00:20<00:12, 28.77it/s, est. speed input: 32092.57 toks/s, output: 31.34 toks/s]
Processed prompts:  65%|   | 666/1024 [00:21<00:12, 28.87it/s, est. speed input: 32063.04 toks/s, output: 31.31 toks/s]
Processed prompts:  66%|   | 674/1024 [00:21<00:12, 28.96it/s, est. speed input: 32035.26 toks/s, output: 31.28 toks/s]
Processed prompts:  67%|   | 682/1024 [00:21<00:11, 28.99it/s, est. speed input: 32006.36 toks/s, output: 31.26 toks/s]
Processed prompts:  67%|   | 690/1024 [00:22<00:11, 28.76it/s, est. speed input: 31966.76 toks/s, output: 31.22 toks/s]
Processed prompts:  68%|   | 698/1024 [00:22<00:11, 28.80it/s, est. speed input: 31937.44 toks/s, output: 31.19 toks/s]
Processed prompts:  69%|   | 706/1024 [00:22<00:11, 28.82it/s, est. speed input: 31908.18 toks/s, output: 31.16 toks/s]
Processed prompts:  70%|   | 714/1024 [00:22<00:10, 28.90it/s, est. speed input: 31882.76 toks/s, output: 31.14 toks/s]
Processed prompts:  71%|   | 722/1024 [00:23<00:10, 28.74it/s, est. speed input: 31848.29 toks/s, output: 31.10 toks/s]
Processed prompts:  71%|  | 730/1024 [00:23<00:10, 28.81it/s, est. speed input: 31822.59 toks/s, output: 31.08 toks/s]
Processed prompts:  72%|  | 738/1024 [00:23<00:09, 28.87it/s, est. speed input: 31798.09 toks/s, output: 31.05 toks/s]
Processed prompts:  73%|  | 746/1024 [00:24<00:09, 28.93it/s, est. speed input: 31774.74 toks/s, output: 31.03 toks/s]
Processed prompts:  74%|  | 754/1024 [00:24<00:09, 28.76it/s, est. speed input: 31743.45 toks/s, output: 31.00 toks/s]
Processed prompts:  74%|  | 762/1024 [00:24<00:09, 28.84it/s, est. speed input: 31720.91 toks/s, output: 30.98 toks/s]
Processed prompts:  75%|  | 770/1024 [00:24<00:08, 28.84it/s, est. speed input: 31696.37 toks/s, output: 30.95 toks/s]
Processed prompts:  76%|  | 778/1024 [00:25<00:08, 28.76it/s, est. speed input: 31669.18 toks/s, output: 30.93 toks/s]
Processed prompts:  77%|  | 786/1024 [00:25<00:08, 28.81it/s, est. speed input: 31646.84 toks/s, output: 30.91 toks/s]
Processed prompts:  78%|  | 794/1024 [00:25<00:07, 28.78it/s, est. speed input: 31622.40 toks/s, output: 30.88 toks/s]
Processed prompts:  78%|  | 802/1024 [00:25<00:07, 28.81it/s, est. speed input: 31600.87 toks/s, output: 30.86 toks/s]
Processed prompts:  79%|  | 810/1024 [00:26<00:07, 28.69it/s, est. speed input: 31574.02 toks/s, output: 30.83 toks/s]
Processed prompts:  80%|  | 818/1024 [00:26<00:07, 28.69it/s, est. speed input: 31550.89 toks/s, output: 30.81 toks/s]
Processed prompts:  81%|  | 826/1024 [00:26<00:06, 28.73it/s, est. speed input: 31529.93 toks/s, output: 30.79 toks/s]
Processed prompts:  81%| | 834/1024 [00:27<00:06, 28.76it/s, est. speed input: 31509.18 toks/s, output: 30.77 toks/s]
Processed prompts:  82%| | 842/1024 [00:27<00:06, 28.71it/s, est. speed input: 31486.38 toks/s, output: 30.75 toks/s]
Processed prompts:  83%| | 850/1024 [00:27<00:06, 28.76it/s, est. speed input: 31467.42 toks/s, output: 30.73 toks/s]
Processed prompts:  84%| | 858/1024 [00:27<00:05, 28.84it/s, est. speed input: 31450.16 toks/s, output: 30.71 toks/s]
Processed prompts:  85%| | 866/1024 [00:28<00:05, 28.84it/s, est. speed input: 31431.22 toks/s, output: 30.69 toks/s]
Processed prompts:  85%| | 874/1024 [00:28<00:05, 28.68it/s, est. speed input: 31407.05 toks/s, output: 30.67 toks/s]
Processed prompts:  86%| | 882/1024 [00:28<00:04, 28.76it/s, est. speed input: 31390.06 toks/s, output: 30.65 toks/s]
Processed prompts:  87%| | 890/1024 [00:29<00:04, 28.76it/s, est. speed input: 31371.60 toks/s, output: 30.64 toks/s]
Processed prompts:  88%| | 898/1024 [00:29<00:04, 28.80it/s, est. speed input: 31354.86 toks/s, output: 30.62 toks/s]
Processed prompts:  88%| | 906/1024 [00:29<00:04, 28.70it/s, est. speed input: 31333.74 toks/s, output: 30.60 toks/s]
Processed prompts:  89%| | 914/1024 [00:29<00:03, 28.72it/s, est. speed input: 31316.53 toks/s, output: 30.58 toks/s]
Processed prompts:  90%| | 922/1024 [00:30<00:03, 28.78it/s, est. speed input: 31300.75 toks/s, output: 30.57 toks/s]
Processed prompts:  91%| | 930/1024 [00:30<00:03, 28.88it/s, est. speed input: 31287.32 toks/s, output: 30.55 toks/s]
Processed prompts:  92%|| 938/1024 [00:30<00:02, 29.87it/s, est. speed input: 31303.16 toks/s, output: 30.57 toks/s]
Processed prompts:  92%|| 946/1024 [00:30<00:02, 29.61it/s, est. speed input: 31288.99 toks/s, output: 30.56 toks/s]
Processed prompts:  93%|| 954/1024 [00:31<00:02, 29.38it/s, est. speed input: 31273.44 toks/s, output: 30.54 toks/s]
Processed prompts:  94%|| 962/1024 [00:31<00:02, 29.19it/s, est. speed input: 31257.32 toks/s, output: 30.52 toks/s]
Processed prompts:  95%|| 970/1024 [00:31<00:01, 28.95it/s, est. speed input: 31238.11 toks/s, output: 30.51 toks/s]
Processed prompts:  96%|| 978/1024 [00:32<00:01, 28.93it/s, est. speed input: 31223.67 toks/s, output: 30.49 toks/s]
Processed prompts:  96%|| 986/1024 [00:32<00:01, 30.08it/s, est. speed input: 31244.20 toks/s, output: 30.51 toks/s]
Processed prompts:  97%|| 994/1024 [00:32<00:01, 29.63it/s, est. speed input: 31227.73 toks/s, output: 30.50 toks/s]
Processed prompts:  98%|| 1002/1024 [00:32<00:00, 29.25it/s, est. speed input: 31209.20 toks/s, output: 30.48 toks/s]
Processed prompts:  99%|| 1010/1024 [00:33<00:00, 29.09it/s, est. speed input: 31194.28 toks/s, output: 30.46 toks/s]
Processed prompts:  99%|| 1018/1024 [00:33<00:00, 29.69it/s, est. speed input: 31199.97 toks/s, output: 30.47 toks/s]
Processed prompts: 100%|| 1024/1024 [00:33<00:00, 29.69it/s, est. speed input: 31383.73 toks/s, output: 30.65 toks/s]
Processed prompts: 100%|| 1024/1024 [00:33<00:00, 30.65it/s, est. speed input: 31383.73 toks/s, output: 30.65 toks/s]
[rank0]:[W126 04:23:44.215394099 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-26 04:23:46
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-FP8_M16384.json --enforce-eager


========== M=512 ==========
Time: 2026-01-26 08:14:17
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-FP8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:14:21 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 08:14:21 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1061635) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1061635) WARNING 01-26 08:14:41 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 51.43 requests/s, 26383.52 total tokens/s, 51.43 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-26 08:14:21] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:14:21] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:14:21] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:14:21] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:14:21] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:14:21] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:14:21] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:14:21] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:14:21] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:14:21] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:14:21] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:14:21] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:14:21] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:14:21] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:14:24] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:14:24] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:14:24] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:14:24] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:14:24] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:14:24] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:14:24] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:14:24] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:14:24] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:14:24] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:14:24] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:14:24] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:14:24] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:14:24] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1061635) [2026-01-26 08:14:25] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1061635) [2026-01-26 08:14:25] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1061635) [2026-01-26 08:14:25] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1061635) [2026-01-26 08:14:25] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1061635) [2026-01-26 08:14:25] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1061635) [2026-01-26 08:14:25] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1061635) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1061635) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.24s/it]
(EngineCore_DP0 pid=1061635) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.24s/it]
(EngineCore_DP0 pid=1061635) 
(EngineCore_DP0 pid=1061635) [2026-01-26 08:14:35] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=1061635) [2026-01-26 08:14:35] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5308416 bytes
(EngineCore_DP0 pid=1061635) [2026-01-26 08:14:35] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=1061635) [2026-01-26 08:14:35] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3538944 bytes
(EngineCore_DP0 pid=1061635) [2026-01-26 08:14:35] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=1061635) [2026-01-26 08:14:35] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 28311552 bytes
(EngineCore_DP0 pid=1061635) [2026-01-26 08:14:35] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=1061635) [2026-01-26 08:14:35] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14024704 bytes
(EngineCore_DP0 pid=1061635) 2026-01-26 08:14:40,451 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1061635) 2026-01-26 08:14:40,458 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  87%| | 111/128 [00:00<00:00, 1106.22it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 1075.49it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|         | 8/128 [00:00<00:01, 76.31it/s, est. speed input: 39074.37 toks/s, output: 76.31 toks/s]
Processed prompts:  12%|        | 16/128 [00:00<00:01, 60.86it/s, est. speed input: 32141.88 toks/s, output: 62.77 toks/s]
Processed prompts:  18%|        | 23/128 [00:00<00:01, 57.17it/s, est. speed input: 30392.98 toks/s, output: 59.36 toks/s]
Processed prompts:  23%|       | 29/128 [00:00<00:01, 54.93it/s, est. speed input: 29406.53 toks/s, output: 57.43 toks/s]
Processed prompts:  27%|       | 35/128 [00:00<00:01, 54.28it/s, est. speed input: 28990.36 toks/s, output: 56.62 toks/s]
Processed prompts:  32%|      | 41/128 [00:00<00:01, 53.79it/s, est. speed input: 28683.15 toks/s, output: 56.02 toks/s]
Processed prompts:  37%|      | 47/128 [00:00<00:01, 53.99it/s, est. speed input: 28576.83 toks/s, output: 55.81 toks/s]
Processed prompts:  41%|     | 53/128 [00:00<00:01, 53.49it/s, est. speed input: 28368.90 toks/s, output: 55.41 toks/s]
Processed prompts:  46%|     | 59/128 [00:01<00:01, 53.54it/s, est. speed input: 28275.57 toks/s, output: 55.22 toks/s]
Processed prompts:  51%|     | 65/128 [00:01<00:01, 53.36it/s, est. speed input: 28162.34 toks/s, output: 55.00 toks/s]
Processed prompts:  55%|    | 71/128 [00:01<00:01, 53.33it/s, est. speed input: 28086.19 toks/s, output: 54.85 toks/s]
Processed prompts:  60%|    | 77/128 [00:01<00:00, 53.20it/s, est. speed input: 28004.11 toks/s, output: 54.70 toks/s]
Processed prompts:  65%|   | 83/128 [00:01<00:00, 53.05it/s, est. speed input: 27928.15 toks/s, output: 54.55 toks/s]
Processed prompts:  70%|   | 89/128 [00:01<00:00, 52.43it/s, est. speed input: 27800.10 toks/s, output: 54.30 toks/s]
Processed prompts:  74%|  | 95/128 [00:01<00:00, 52.79it/s, est. speed input: 27778.61 toks/s, output: 54.25 toks/s]
Processed prompts:  79%|  | 101/128 [00:01<00:00, 53.06it/s, est. speed input: 27761.11 toks/s, output: 54.22 toks/s]
Processed prompts:  84%| | 107/128 [00:01<00:00, 53.27it/s, est. speed input: 27748.06 toks/s, output: 54.19 toks/s]
Processed prompts:  88%| | 113/128 [00:02<00:00, 53.42it/s, est. speed input: 27736.20 toks/s, output: 54.17 toks/s]
Processed prompts:  93%|| 119/128 [00:02<00:00, 53.13it/s, est. speed input: 27692.35 toks/s, output: 54.08 toks/s]
Processed prompts:  98%|| 125/128 [00:02<00:00, 53.18it/s, est. speed input: 27671.35 toks/s, output: 54.05 toks/s]
Processed prompts: 100%|| 128/128 [00:02<00:00, 53.18it/s, est. speed input: 27667.05 toks/s, output: 54.04 toks/s]
Processed prompts: 100%|| 128/128 [00:02<00:00, 54.03it/s, est. speed input: 27667.05 toks/s, output: 54.04 toks/s]
[rank0]:[W126 08:14:43.977159759 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-26 08:14:45
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-FP8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:14:49 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 08:14:49 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1062238) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1062238) WARNING 01-26 08:15:09 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 27.80 requests/s, 28497.51 total tokens/s, 27.80 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-26 08:14:49] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:14:49] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:14:49] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:14:49] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:14:49] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:14:49] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:14:49] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:14:49] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:14:49] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:14:49] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:14:49] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:14:49] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:14:49] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:14:49] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:14:53] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:14:53] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:14:53] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:14:53] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:14:53] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:14:53] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:14:53] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:14:53] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:14:53] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:14:53] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:14:53] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:14:53] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:14:53] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:14:53] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1062238) [2026-01-26 08:14:54] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1062238) [2026-01-26 08:14:54] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1062238) [2026-01-26 08:14:54] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1062238) [2026-01-26 08:14:54] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1062238) [2026-01-26 08:14:54] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1062238) [2026-01-26 08:14:54] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1062238) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1062238) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.27s/it]
(EngineCore_DP0 pid=1062238) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.27s/it]
(EngineCore_DP0 pid=1062238) 
(EngineCore_DP0 pid=1062238) [2026-01-26 08:15:03] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=1062238) [2026-01-26 08:15:04] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5308416 bytes
(EngineCore_DP0 pid=1062238) [2026-01-26 08:15:04] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=1062238) [2026-01-26 08:15:04] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3538944 bytes
(EngineCore_DP0 pid=1062238) [2026-01-26 08:15:04] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=1062238) [2026-01-26 08:15:04] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 28311552 bytes
(EngineCore_DP0 pid=1062238) [2026-01-26 08:15:04] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=1062238) [2026-01-26 08:15:04] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14024704 bytes
(EngineCore_DP0 pid=1062238) 2026-01-26 08:15:09,163 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1062238) 2026-01-26 08:15:09,169 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  45%|     | 58/128 [00:00<00:00, 578.43it/s]
Adding requests:  91%| | 116/128 [00:00<00:00, 544.18it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 547.00it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|         | 8/128 [00:00<00:01, 61.36it/s, est. speed input: 62840.96 toks/s, output: 61.36 toks/s]
Processed prompts:  12%|        | 15/128 [00:00<00:03, 37.18it/s, est. speed input: 40637.20 toks/s, output: 39.68 toks/s]
Processed prompts:  16%|        | 20/128 [00:00<00:03, 33.25it/s, est. speed input: 36809.66 toks/s, output: 35.95 toks/s]
Processed prompts:  19%|        | 24/128 [00:00<00:03, 31.78it/s, est. speed input: 35323.70 toks/s, output: 34.50 toks/s]
Processed prompts:  22%|       | 28/128 [00:00<00:03, 30.57it/s, est. speed input: 34193.87 toks/s, output: 33.39 toks/s]
Processed prompts:  25%|       | 32/128 [00:00<00:03, 29.94it/s, est. speed input: 33482.95 toks/s, output: 32.70 toks/s]
Processed prompts:  28%|       | 36/128 [00:01<00:03, 29.14it/s, est. speed input: 32780.78 toks/s, output: 32.01 toks/s]
Processed prompts:  30%|       | 39/128 [00:01<00:03, 28.95it/s, est. speed input: 32458.52 toks/s, output: 31.70 toks/s]
Processed prompts:  33%|      | 42/128 [00:01<00:02, 28.84it/s, est. speed input: 32203.81 toks/s, output: 31.45 toks/s]
Processed prompts:  35%|      | 45/128 [00:01<00:02, 28.70it/s, est. speed input: 31968.54 toks/s, output: 31.22 toks/s]
Processed prompts:  38%|      | 48/128 [00:01<00:02, 28.70it/s, est. speed input: 31792.97 toks/s, output: 31.05 toks/s]
Processed prompts:  40%|      | 51/128 [00:01<00:02, 28.78it/s, est. speed input: 31661.43 toks/s, output: 30.92 toks/s]
Processed prompts:  42%|     | 54/128 [00:01<00:02, 28.78it/s, est. speed input: 31531.78 toks/s, output: 30.79 toks/s]
Processed prompts:  45%|     | 57/128 [00:01<00:02, 28.86it/s, est. speed input: 31432.28 toks/s, output: 30.70 toks/s]
Processed prompts:  47%|     | 60/128 [00:01<00:02, 28.75it/s, est. speed input: 31310.67 toks/s, output: 30.58 toks/s]
Processed prompts:  49%|     | 63/128 [00:02<00:02, 28.38it/s, est. speed input: 31146.26 toks/s, output: 30.42 toks/s]
Processed prompts:  52%|    | 66/128 [00:02<00:02, 28.37it/s, est. speed input: 31043.65 toks/s, output: 30.32 toks/s]
Processed prompts:  54%|    | 69/128 [00:02<00:02, 28.51it/s, est. speed input: 30974.55 toks/s, output: 30.25 toks/s]
Processed prompts:  56%|    | 72/128 [00:02<00:01, 28.51it/s, est. speed input: 30895.73 toks/s, output: 30.17 toks/s]
Processed prompts:  59%|    | 75/128 [00:02<00:01, 28.34it/s, est. speed input: 30798.06 toks/s, output: 30.08 toks/s]
Processed prompts:  61%|    | 78/128 [00:02<00:01, 28.30it/s, est. speed input: 30720.10 toks/s, output: 30.00 toks/s]
Processed prompts:  63%|   | 81/128 [00:02<00:01, 28.38it/s, est. speed input: 30662.76 toks/s, output: 29.94 toks/s]
Processed prompts:  66%|   | 84/128 [00:02<00:01, 28.28it/s, est. speed input: 30588.88 toks/s, output: 29.87 toks/s]
Processed prompts:  68%|   | 87/128 [00:02<00:01, 28.34it/s, est. speed input: 30537.85 toks/s, output: 29.82 toks/s]
Processed prompts:  70%|   | 90/128 [00:03<00:01, 28.54it/s, est. speed input: 30509.65 toks/s, output: 29.79 toks/s]
Processed prompts:  73%|  | 93/128 [00:03<00:01, 28.32it/s, est. speed input: 30439.46 toks/s, output: 29.73 toks/s]
Processed prompts:  75%|  | 96/128 [00:03<00:01, 28.36it/s, est. speed input: 30396.93 toks/s, output: 29.68 toks/s]
Processed prompts:  77%|  | 99/128 [00:03<00:01, 28.42it/s, est. speed input: 30361.01 toks/s, output: 29.65 toks/s]
Processed prompts:  80%|  | 102/128 [00:03<00:00, 28.43it/s, est. speed input: 30323.46 toks/s, output: 29.61 toks/s]
Processed prompts:  82%| | 105/128 [00:03<00:00, 28.49it/s, est. speed input: 30293.89 toks/s, output: 29.58 toks/s]
Processed prompts:  84%| | 108/128 [00:03<00:00, 28.30it/s, est. speed input: 30241.66 toks/s, output: 29.53 toks/s]
Processed prompts:  87%| | 111/128 [00:03<00:00, 28.45it/s, est. speed input: 30220.75 toks/s, output: 29.51 toks/s]
Processed prompts:  89%| | 114/128 [00:03<00:00, 28.37it/s, est. speed input: 30183.67 toks/s, output: 29.48 toks/s]
Processed prompts:  91%|| 117/128 [00:03<00:00, 28.26it/s, est. speed input: 30143.22 toks/s, output: 29.44 toks/s]
Processed prompts:  94%|| 120/128 [00:04<00:00, 28.30it/s, est. speed input: 30115.96 toks/s, output: 29.41 toks/s]
Processed prompts:  96%|| 123/128 [00:04<00:00, 27.95it/s, est. speed input: 30055.37 toks/s, output: 29.35 toks/s]
Processed prompts:  98%|| 126/128 [00:04<00:00, 28.02it/s, est. speed input: 30025.38 toks/s, output: 29.32 toks/s]
Processed prompts: 100%|| 128/128 [00:04<00:00, 28.02it/s, est. speed input: 30002.14 toks/s, output: 29.30 toks/s]
Processed prompts: 100%|| 128/128 [00:04<00:00, 29.30it/s, est. speed input: 30002.14 toks/s, output: 29.30 toks/s]
[rank0]:[W126 08:15:14.817202651 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-26 08:15:16
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-FP8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:15:21 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 08:15:21 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1062857) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1062857) WARNING 01-26 08:15:41 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 29.57 requests/s, 30305.96 total tokens/s, 29.57 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-26 08:15:21] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:15:21] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:15:21] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:15:21] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:15:21] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:15:21] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:15:21] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:15:21] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:15:21] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:15:21] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:15:21] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:15:21] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:15:21] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:15:21] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:15:24] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:15:24] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:15:24] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:15:24] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:15:24] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:15:24] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:15:24] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:15:24] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:15:24] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:15:24] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:15:24] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:15:24] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:15:24] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:15:24] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1062857) [2026-01-26 08:15:25] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1062857) [2026-01-26 08:15:25] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1062857) [2026-01-26 08:15:25] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1062857) [2026-01-26 08:15:25] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1062857) [2026-01-26 08:15:25] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1062857) [2026-01-26 08:15:25] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1062857) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1062857) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.42s/it]
(EngineCore_DP0 pid=1062857) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.42s/it]
(EngineCore_DP0 pid=1062857) 
(EngineCore_DP0 pid=1062857) [2026-01-26 08:15:35] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=1062857) [2026-01-26 08:15:35] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5308416 bytes
(EngineCore_DP0 pid=1062857) [2026-01-26 08:15:35] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=1062857) [2026-01-26 08:15:35] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3538944 bytes
(EngineCore_DP0 pid=1062857) [2026-01-26 08:15:35] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=1062857) [2026-01-26 08:15:35] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 28311552 bytes
(EngineCore_DP0 pid=1062857) [2026-01-26 08:15:35] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=1062857) [2026-01-26 08:15:35] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14024704 bytes
(EngineCore_DP0 pid=1062857) 2026-01-26 08:15:40,543 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1062857) 2026-01-26 08:15:40,549 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  22%|       | 57/256 [00:00<00:00, 561.56it/s]
Adding requests:  45%|     | 114/256 [00:00<00:00, 530.54it/s]
Adding requests:  66%|   | 168/256 [00:00<00:00, 520.59it/s]
Adding requests:  86%| | 221/256 [00:00<00:00, 512.67it/s]
Adding requests: 100%|| 256/256 [00:00<00:00, 518.88it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|         | 14/256 [00:00<00:02, 104.93it/s, est. speed input: 107469.95 toks/s, output: 104.93 toks/s]
Processed prompts:  10%|         | 25/256 [00:00<00:04, 48.88it/s, est. speed input: 54987.97 toks/s, output: 53.70 toks/s]   
Processed prompts:  12%|        | 32/256 [00:00<00:05, 37.93it/s, est. speed input: 44514.73 toks/s, output: 43.47 toks/s]
Processed prompts:  14%|        | 37/256 [00:00<00:05, 37.88it/s, est. speed input: 43617.85 toks/s, output: 42.60 toks/s]
Processed prompts:  16%|        | 42/256 [00:01<00:06, 33.60it/s, est. speed input: 40397.53 toks/s, output: 39.45 toks/s]
Processed prompts:  18%|        | 46/256 [00:01<00:06, 32.80it/s, est. speed input: 39375.57 toks/s, output: 38.45 toks/s]
Processed prompts:  20%|        | 50/256 [00:01<00:06, 32.20it/s, est. speed input: 38568.50 toks/s, output: 37.66 toks/s]
Processed prompts:  21%|        | 54/256 [00:01<00:06, 31.54it/s, est. speed input: 37831.07 toks/s, output: 36.94 toks/s]
Processed prompts:  23%|       | 58/256 [00:01<00:06, 31.09it/s, est. speed input: 37232.34 toks/s, output: 36.36 toks/s]
Processed prompts:  24%|       | 62/256 [00:01<00:06, 30.79it/s, est. speed input: 36732.29 toks/s, output: 35.87 toks/s]
Processed prompts:  26%|       | 66/256 [00:01<00:06, 30.27it/s, est. speed input: 36216.11 toks/s, output: 35.37 toks/s]
Processed prompts:  27%|       | 70/256 [00:02<00:06, 30.15it/s, est. speed input: 35838.94 toks/s, output: 35.00 toks/s]
Processed prompts:  29%|       | 74/256 [00:02<00:06, 29.98it/s, est. speed input: 35486.08 toks/s, output: 34.65 toks/s]
Processed prompts:  30%|       | 78/256 [00:02<00:05, 30.20it/s, est. speed input: 35256.84 toks/s, output: 34.43 toks/s]
Processed prompts:  32%|      | 82/256 [00:02<00:05, 30.06it/s, est. speed input: 34987.18 toks/s, output: 34.17 toks/s]
Processed prompts:  34%|      | 86/256 [00:02<00:05, 30.32it/s, est. speed input: 34818.34 toks/s, output: 34.00 toks/s]
Processed prompts:  35%|      | 90/256 [00:02<00:05, 30.44it/s, est. speed input: 34654.32 toks/s, output: 33.84 toks/s]
Processed prompts:  37%|      | 94/256 [00:02<00:05, 30.18it/s, est. speed input: 34443.68 toks/s, output: 33.64 toks/s]
Processed prompts:  38%|      | 98/256 [00:02<00:05, 29.95it/s, est. speed input: 34243.38 toks/s, output: 33.44 toks/s]
Processed prompts:  40%|      | 102/256 [00:03<00:05, 29.99it/s, est. speed input: 34095.02 toks/s, output: 33.30 toks/s]
Processed prompts:  41%|     | 106/256 [00:03<00:05, 30.00it/s, est. speed input: 33954.13 toks/s, output: 33.16 toks/s]
Processed prompts:  43%|     | 110/256 [00:03<00:04, 29.99it/s, est. speed input: 33823.55 toks/s, output: 33.03 toks/s]
Processed prompts:  45%|     | 114/256 [00:03<00:04, 29.93it/s, est. speed input: 33695.63 toks/s, output: 32.91 toks/s]
Processed prompts:  46%|     | 118/256 [00:03<00:04, 30.04it/s, est. speed input: 33597.90 toks/s, output: 32.81 toks/s]
Processed prompts:  48%|     | 122/256 [00:03<00:04, 29.93it/s, est. speed input: 33482.12 toks/s, output: 32.70 toks/s]
Processed prompts:  49%|     | 126/256 [00:03<00:04, 29.83it/s, est. speed input: 33370.61 toks/s, output: 32.59 toks/s]
Processed prompts:  51%|     | 130/256 [00:04<00:04, 29.77it/s, est. speed input: 33268.93 toks/s, output: 32.49 toks/s]
Processed prompts:  52%|    | 134/256 [00:04<00:04, 29.79it/s, est. speed input: 33180.28 toks/s, output: 32.40 toks/s]
Processed prompts:  54%|    | 138/256 [00:04<00:03, 30.03it/s, est. speed input: 33124.27 toks/s, output: 32.35 toks/s]
Processed prompts:  55%|    | 142/256 [00:04<00:03, 30.10it/s, est. speed input: 33060.39 toks/s, output: 32.29 toks/s]
Processed prompts:  57%|    | 146/256 [00:04<00:03, 30.30it/s, est. speed input: 33015.94 toks/s, output: 32.24 toks/s]
Processed prompts:  59%|    | 150/256 [00:04<00:03, 30.37it/s, est. speed input: 32966.33 toks/s, output: 32.19 toks/s]
Processed prompts:  60%|    | 154/256 [00:04<00:03, 30.39it/s, est. speed input: 32916.80 toks/s, output: 32.15 toks/s]
Processed prompts:  62%|   | 158/256 [00:04<00:03, 30.09it/s, est. speed input: 32839.59 toks/s, output: 32.07 toks/s]
Processed prompts:  63%|   | 162/256 [00:05<00:03, 29.90it/s, est. speed input: 32768.36 toks/s, output: 32.00 toks/s]
Processed prompts:  65%|   | 166/256 [00:05<00:02, 30.21it/s, est. speed input: 32741.37 toks/s, output: 31.97 toks/s]
Processed prompts:  66%|   | 170/256 [00:05<00:02, 30.09it/s, est. speed input: 32686.18 toks/s, output: 31.92 toks/s]
Processed prompts:  68%|   | 174/256 [00:05<00:02, 30.11it/s, est. speed input: 32642.19 toks/s, output: 31.88 toks/s]
Processed prompts:  70%|   | 178/256 [00:05<00:02, 30.26it/s, est. speed input: 32611.70 toks/s, output: 31.85 toks/s]
Processed prompts:  71%|   | 182/256 [00:05<00:02, 30.01it/s, est. speed input: 32553.73 toks/s, output: 31.79 toks/s]
Processed prompts:  73%|  | 186/256 [00:05<00:02, 29.98it/s, est. speed input: 32509.92 toks/s, output: 31.75 toks/s]
Processed prompts:  74%|  | 190/256 [00:05<00:02, 29.75it/s, est. speed input: 32450.96 toks/s, output: 31.69 toks/s]
Processed prompts:  76%|  | 194/256 [00:06<00:02, 29.85it/s, est. speed input: 32415.48 toks/s, output: 31.66 toks/s]
Processed prompts:  77%|  | 198/256 [00:06<00:01, 29.84it/s, est. speed input: 32374.77 toks/s, output: 31.62 toks/s]
Processed prompts:  79%|  | 202/256 [00:06<00:01, 30.23it/s, est. speed input: 32365.57 toks/s, output: 31.61 toks/s]
Processed prompts:  80%|  | 206/256 [00:06<00:01, 30.39it/s, est. speed input: 32348.37 toks/s, output: 31.59 toks/s]
Processed prompts:  82%| | 210/256 [00:06<00:01, 30.28it/s, est. speed input: 32316.93 toks/s, output: 31.56 toks/s]
Processed prompts:  84%| | 214/256 [00:06<00:01, 30.20it/s, est. speed input: 32285.28 toks/s, output: 31.53 toks/s]
Processed prompts:  85%| | 218/256 [00:06<00:01, 30.13it/s, est. speed input: 32254.93 toks/s, output: 31.50 toks/s]
Processed prompts:  87%| | 222/256 [00:07<00:01, 29.90it/s, est. speed input: 32212.69 toks/s, output: 31.46 toks/s]
Processed prompts:  88%| | 226/256 [00:07<00:01, 29.96it/s, est. speed input: 32186.77 toks/s, output: 31.43 toks/s]
Processed prompts:  90%| | 230/256 [00:07<00:00, 29.82it/s, est. speed input: 32150.57 toks/s, output: 31.40 toks/s]
Processed prompts:  91%|| 234/256 [00:07<00:00, 30.05it/s, est. speed input: 32135.89 toks/s, output: 31.38 toks/s]
Processed prompts:  93%|| 238/256 [00:07<00:00, 30.05it/s, est. speed input: 32112.30 toks/s, output: 31.36 toks/s]
Processed prompts:  95%|| 242/256 [00:07<00:00, 30.01it/s, est. speed input: 32086.74 toks/s, output: 31.33 toks/s]
Processed prompts:  96%|| 246/256 [00:07<00:00, 29.95it/s, est. speed input: 32060.26 toks/s, output: 31.31 toks/s]
Processed prompts:  98%|| 250/256 [00:07<00:00, 29.80it/s, est. speed input: 32027.98 toks/s, output: 31.28 toks/s]
Processed prompts:  99%|| 254/256 [00:08<00:00, 29.69it/s, est. speed input: 31996.11 toks/s, output: 31.25 toks/s]
Processed prompts: 100%|| 256/256 [00:08<00:00, 29.69it/s, est. speed input: 32110.88 toks/s, output: 31.36 toks/s]
Processed prompts: 100%|| 256/256 [00:08<00:00, 31.36it/s, est. speed input: 32110.88 toks/s, output: 31.36 toks/s]
[rank0]:[W126 08:15:50.302465555 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-26 08:15:52
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-FP8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:15:57 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 08:15:57 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1063542) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1063542) WARNING 01-26 08:16:17 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 28.81 requests/s, 29531.44 total tokens/s, 28.81 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-26 08:15:57] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:15:57] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:15:57] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:15:57] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:15:57] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:15:57] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:15:57] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:15:57] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:15:57] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:15:57] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:15:57] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:15:57] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:15:57] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:15:57] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:16:00] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:16:00] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:16:00] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:16:00] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:16:00] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:16:00] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:16:00] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:16:00] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:16:00] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:16:00] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:16:00] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:16:00] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:16:00] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:16:00] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1063542) [2026-01-26 08:16:01] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1063542) [2026-01-26 08:16:01] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1063542) [2026-01-26 08:16:01] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1063542) [2026-01-26 08:16:01] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1063542) [2026-01-26 08:16:01] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1063542) [2026-01-26 08:16:01] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1063542) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1063542) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.27s/it]
(EngineCore_DP0 pid=1063542) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.27s/it]
(EngineCore_DP0 pid=1063542) 
(EngineCore_DP0 pid=1063542) [2026-01-26 08:16:11] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=1063542) [2026-01-26 08:16:11] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5308416 bytes
(EngineCore_DP0 pid=1063542) [2026-01-26 08:16:11] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=1063542) [2026-01-26 08:16:11] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3538944 bytes
(EngineCore_DP0 pid=1063542) [2026-01-26 08:16:11] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=1063542) [2026-01-26 08:16:11] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 28311552 bytes
(EngineCore_DP0 pid=1063542) [2026-01-26 08:16:11] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=1063542) [2026-01-26 08:16:11] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14024704 bytes
(EngineCore_DP0 pid=1063542) 2026-01-26 08:16:16,664 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1063542) 2026-01-26 08:16:16,670 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:  12%|        | 62/512 [00:00<00:00, 612.08it/s]
Adding requests:  24%|       | 124/512 [00:00<00:00, 578.45it/s]
Adding requests:  36%|      | 182/512 [00:00<00:00, 534.22it/s]
Adding requests:  46%|     | 236/512 [00:00<00:00, 528.84it/s]
Adding requests:  57%|    | 290/512 [00:00<00:00, 512.03it/s]
Adding requests:  67%|   | 342/512 [00:00<00:00, 499.42it/s]
Adding requests:  77%|  | 393/512 [00:00<00:00, 499.98it/s]
Adding requests:  87%| | 444/512 [00:00<00:00, 495.66it/s]
Adding requests:  96%|| 494/512 [00:00<00:00, 491.62it/s]
Adding requests: 100%|| 512/512 [00:01<00:00, 510.44it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|         | 26/512 [00:00<00:02, 190.71it/s, est. speed input: 195360.01 toks/s, output: 190.74 toks/s]
Processed prompts:   9%|         | 46/512 [00:00<00:09, 48.27it/s, est. speed input: 56602.25 toks/s, output: 55.27 toks/s]   
Processed prompts:  11%|         | 56/512 [00:01<00:10, 44.46it/s, est. speed input: 51912.91 toks/s, output: 50.70 toks/s]
Processed prompts:  12%|        | 63/512 [00:01<00:11, 38.34it/s, est. speed input: 46763.91 toks/s, output: 45.67 toks/s]
Processed prompts:  13%|        | 69/512 [00:01<00:11, 39.29it/s, est. speed input: 46549.55 toks/s, output: 45.46 toks/s]
Processed prompts:  14%|        | 74/512 [00:01<00:13, 32.09it/s, est. speed input: 42352.48 toks/s, output: 41.36 toks/s]
Processed prompts:  15%|        | 78/512 [00:01<00:13, 31.26it/s, est. speed input: 41347.22 toks/s, output: 40.38 toks/s]
Processed prompts:  16%|        | 82/512 [00:02<00:13, 30.92it/s, est. speed input: 40632.79 toks/s, output: 39.68 toks/s]
Processed prompts:  17%|        | 86/512 [00:02<00:13, 30.64it/s, est. speed input: 40010.82 toks/s, output: 39.07 toks/s]
Processed prompts:  18%|        | 90/512 [00:02<00:13, 30.16it/s, est. speed input: 39386.23 toks/s, output: 38.46 toks/s]
Processed prompts:  18%|        | 94/512 [00:02<00:13, 29.96it/s, est. speed input: 38875.62 toks/s, output: 37.96 toks/s]
Processed prompts:  19%|        | 98/512 [00:02<00:13, 29.74it/s, est. speed input: 38402.17 toks/s, output: 37.50 toks/s]
Processed prompts:  20%|        | 102/512 [00:02<00:13, 29.60it/s, est. speed input: 37981.70 toks/s, output: 37.09 toks/s]
Processed prompts:  21%|        | 106/512 [00:02<00:13, 29.31it/s, est. speed input: 37560.85 toks/s, output: 36.68 toks/s]
Processed prompts:  21%|       | 110/512 [00:03<00:13, 29.24it/s, est. speed input: 37206.96 toks/s, output: 36.33 toks/s]
Processed prompts:  22%|       | 114/512 [00:03<00:13, 29.17it/s, est. speed input: 36879.86 toks/s, output: 36.02 toks/s]
Processed prompts:  23%|       | 118/512 [00:03<00:13, 29.14it/s, est. speed input: 36584.21 toks/s, output: 35.73 toks/s]
Processed prompts:  24%|       | 122/512 [00:03<00:13, 29.16it/s, est. speed input: 36317.64 toks/s, output: 35.47 toks/s]
Processed prompts:  25%|       | 126/512 [00:03<00:13, 29.13it/s, est. speed input: 36066.03 toks/s, output: 35.22 toks/s]
Processed prompts:  25%|       | 130/512 [00:03<00:13, 29.19it/s, est. speed input: 35844.36 toks/s, output: 35.00 toks/s]
Processed prompts:  26%|       | 134/512 [00:03<00:12, 29.12it/s, est. speed input: 35622.50 toks/s, output: 34.79 toks/s]
Processed prompts:  27%|       | 138/512 [00:03<00:12, 28.84it/s, est. speed input: 35382.13 toks/s, output: 34.55 toks/s]
Processed prompts:  28%|       | 142/512 [00:04<00:12, 28.84it/s, est. speed input: 35186.20 toks/s, output: 34.36 toks/s]
Processed prompts:  29%|       | 146/512 [00:04<00:12, 28.93it/s, est. speed input: 35014.94 toks/s, output: 34.19 toks/s]
Processed prompts:  29%|       | 150/512 [00:04<00:12, 29.09it/s, est. speed input: 34865.45 toks/s, output: 34.05 toks/s]
Processed prompts:  30%|       | 154/512 [00:04<00:12, 29.19it/s, est. speed input: 34724.32 toks/s, output: 33.91 toks/s]
Processed prompts:  31%|       | 158/512 [00:04<00:12, 29.27it/s, est. speed input: 34591.77 toks/s, output: 33.78 toks/s]
Processed prompts:  32%|      | 162/512 [00:04<00:11, 29.31it/s, est. speed input: 34465.16 toks/s, output: 33.66 toks/s]
Processed prompts:  32%|      | 166/512 [00:04<00:11, 29.27it/s, est. speed input: 34338.16 toks/s, output: 33.53 toks/s]
Processed prompts:  33%|      | 170/512 [00:05<00:11, 28.91it/s, est. speed input: 34182.42 toks/s, output: 33.38 toks/s]
Processed prompts:  34%|      | 174/512 [00:05<00:11, 29.05it/s, est. speed input: 34076.37 toks/s, output: 33.28 toks/s]
Processed prompts:  35%|      | 178/512 [00:05<00:11, 29.09it/s, est. speed input: 33968.89 toks/s, output: 33.17 toks/s]
Processed prompts:  36%|      | 182/512 [00:05<00:11, 29.24it/s, est. speed input: 33878.43 toks/s, output: 33.08 toks/s]
Processed prompts:  36%|      | 186/512 [00:05<00:11, 29.24it/s, est. speed input: 33782.82 toks/s, output: 32.99 toks/s]
Processed prompts:  37%|      | 190/512 [00:05<00:11, 29.22it/s, est. speed input: 33690.52 toks/s, output: 32.90 toks/s]
Processed prompts:  38%|      | 194/512 [00:05<00:10, 29.26it/s, est. speed input: 33606.18 toks/s, output: 32.82 toks/s]
Processed prompts:  39%|      | 198/512 [00:06<00:10, 29.25it/s, est. speed input: 33523.18 toks/s, output: 32.74 toks/s]
Processed prompts:  39%|      | 202/512 [00:06<00:10, 28.85it/s, est. speed input: 33410.46 toks/s, output: 32.63 toks/s]
Processed prompts:  40%|      | 206/512 [00:06<00:10, 28.99it/s, est. speed input: 33337.14 toks/s, output: 32.56 toks/s]
Processed prompts:  41%|      | 210/512 [00:06<00:10, 29.09it/s, est. speed input: 33267.69 toks/s, output: 32.49 toks/s]
Processed prompts:  42%|     | 214/512 [00:06<00:10, 29.14it/s, est. speed input: 33199.29 toks/s, output: 32.42 toks/s]
Processed prompts:  43%|     | 218/512 [00:06<00:10, 29.16it/s, est. speed input: 33132.18 toks/s, output: 32.36 toks/s]
Processed prompts:  43%|     | 222/512 [00:06<00:09, 29.16it/s, est. speed input: 33067.02 toks/s, output: 32.29 toks/s]
Processed prompts:  44%|     | 226/512 [00:07<00:09, 29.03it/s, est. speed input: 32994.96 toks/s, output: 32.22 toks/s]
Processed prompts:  45%|     | 230/512 [00:07<00:09, 28.70it/s, est. speed input: 32907.08 toks/s, output: 32.14 toks/s]
Processed prompts:  46%|     | 234/512 [00:07<00:09, 28.98it/s, est. speed input: 32860.22 toks/s, output: 32.09 toks/s]
Processed prompts:  46%|     | 238/512 [00:07<00:09, 29.05it/s, est. speed input: 32806.29 toks/s, output: 32.04 toks/s]
Processed prompts:  47%|     | 242/512 [00:07<00:09, 29.12it/s, est. speed input: 32755.02 toks/s, output: 31.99 toks/s]
Processed prompts:  48%|     | 246/512 [00:07<00:09, 29.18it/s, est. speed input: 32706.82 toks/s, output: 31.94 toks/s]
Processed prompts:  49%|     | 250/512 [00:07<00:09, 29.10it/s, est. speed input: 32652.27 toks/s, output: 31.89 toks/s]
Processed prompts:  50%|     | 254/512 [00:07<00:08, 29.18it/s, est. speed input: 32608.26 toks/s, output: 31.84 toks/s]
Processed prompts:  50%|     | 258/512 [00:08<00:08, 29.16it/s, est. speed input: 32560.87 toks/s, output: 31.80 toks/s]
Processed prompts:  51%|     | 262/512 [00:08<00:08, 29.03it/s, est. speed input: 32507.85 toks/s, output: 31.75 toks/s]
Processed prompts:  52%|    | 266/512 [00:08<00:08, 28.93it/s, est. speed input: 32456.16 toks/s, output: 31.70 toks/s]
Processed prompts:  53%|    | 270/512 [00:08<00:08, 29.03it/s, est. speed input: 32416.59 toks/s, output: 31.66 toks/s]
Processed prompts:  54%|    | 274/512 [00:08<00:08, 29.03it/s, est. speed input: 32373.71 toks/s, output: 31.61 toks/s]
Processed prompts:  54%|    | 278/512 [00:08<00:08, 29.20it/s, est. speed input: 32342.02 toks/s, output: 31.58 toks/s]
Processed prompts:  55%|    | 282/512 [00:08<00:07, 29.02it/s, est. speed input: 32294.40 toks/s, output: 31.54 toks/s]
Processed prompts:  56%|    | 286/512 [00:09<00:07, 28.98it/s, est. speed input: 32253.07 toks/s, output: 31.50 toks/s]
Processed prompts:  57%|    | 290/512 [00:09<00:07, 29.18it/s, est. speed input: 32225.68 toks/s, output: 31.47 toks/s]
Processed prompts:  57%|    | 294/512 [00:09<00:07, 28.85it/s, est. speed input: 32173.16 toks/s, output: 31.42 toks/s]
Processed prompts:  58%|    | 298/512 [00:09<00:07, 29.04it/s, est. speed input: 32145.02 toks/s, output: 31.39 toks/s]
Processed prompts:  59%|    | 302/512 [00:09<00:07, 29.09it/s, est. speed input: 32113.30 toks/s, output: 31.36 toks/s]
Processed prompts:  60%|    | 306/512 [00:09<00:07, 29.16it/s, est. speed input: 32084.34 toks/s, output: 31.33 toks/s]
Processed prompts:  61%|    | 310/512 [00:09<00:06, 29.14it/s, est. speed input: 32052.34 toks/s, output: 31.30 toks/s]
Processed prompts:  61%|   | 314/512 [00:10<00:06, 29.05it/s, est. speed input: 32017.61 toks/s, output: 31.27 toks/s]
Processed prompts:  62%|   | 318/512 [00:10<00:06, 29.13it/s, est. speed input: 31990.73 toks/s, output: 31.24 toks/s]
Processed prompts:  63%|   | 322/512 [00:10<00:06, 29.08it/s, est. speed input: 31959.61 toks/s, output: 31.21 toks/s]
Processed prompts:  64%|   | 326/512 [00:10<00:06, 28.69it/s, est. speed input: 31911.76 toks/s, output: 31.16 toks/s]
Processed prompts:  64%|   | 330/512 [00:10<00:06, 28.82it/s, est. speed input: 31884.92 toks/s, output: 31.14 toks/s]
Processed prompts:  65%|   | 334/512 [00:10<00:06, 29.03it/s, est. speed input: 31863.98 toks/s, output: 31.12 toks/s]
Processed prompts:  66%|   | 338/512 [00:10<00:05, 29.01it/s, est. speed input: 31835.80 toks/s, output: 31.09 toks/s]
Processed prompts:  67%|   | 342/512 [00:11<00:05, 29.41it/s, est. speed input: 31827.46 toks/s, output: 31.08 toks/s]
Processed prompts:  68%|   | 346/512 [00:11<00:05, 29.23it/s, est. speed input: 31798.29 toks/s, output: 31.05 toks/s]
Processed prompts:  68%|   | 350/512 [00:11<00:05, 29.21it/s, est. speed input: 31774.94 toks/s, output: 31.03 toks/s]
Processed prompts:  69%|   | 354/512 [00:11<00:05, 28.86it/s, est. speed input: 31737.37 toks/s, output: 30.99 toks/s]
Processed prompts:  70%|   | 358/512 [00:11<00:05, 28.72it/s, est. speed input: 31704.99 toks/s, output: 30.96 toks/s]
Processed prompts:  71%|   | 362/512 [00:11<00:05, 28.98it/s, est. speed input: 31689.00 toks/s, output: 30.95 toks/s]
Processed prompts:  71%|  | 366/512 [00:11<00:05, 29.09it/s, est. speed input: 31670.17 toks/s, output: 30.93 toks/s]
Processed prompts:  72%|  | 370/512 [00:11<00:04, 29.15it/s, est. speed input: 31650.93 toks/s, output: 30.91 toks/s]
Processed prompts:  73%|  | 374/512 [00:12<00:04, 29.33it/s, est. speed input: 31637.97 toks/s, output: 30.90 toks/s]
Processed prompts:  74%|  | 378/512 [00:12<00:04, 29.23it/s, est. speed input: 31616.06 toks/s, output: 30.88 toks/s]
Processed prompts:  75%|  | 382/512 [00:12<00:04, 29.32it/s, est. speed input: 31600.94 toks/s, output: 30.86 toks/s]
Processed prompts:  75%|  | 386/512 [00:12<00:04, 29.04it/s, est. speed input: 31572.82 toks/s, output: 30.83 toks/s]
Processed prompts:  76%|  | 390/512 [00:12<00:04, 29.12it/s, est. speed input: 31555.95 toks/s, output: 30.82 toks/s]
Processed prompts:  77%|  | 394/512 [00:12<00:04, 29.09it/s, est. speed input: 31535.95 toks/s, output: 30.80 toks/s]
Processed prompts:  78%|  | 398/512 [00:12<00:03, 29.30it/s, est. speed input: 31525.63 toks/s, output: 30.79 toks/s]
Processed prompts:  79%|  | 402/512 [00:13<00:03, 29.27it/s, est. speed input: 31508.47 toks/s, output: 30.77 toks/s]
Processed prompts:  79%|  | 406/512 [00:13<00:03, 29.19it/s, est. speed input: 31489.72 toks/s, output: 30.75 toks/s]
Processed prompts:  80%|  | 410/512 [00:13<00:03, 29.28it/s, est. speed input: 31476.32 toks/s, output: 30.74 toks/s]
Processed prompts:  81%|  | 414/512 [00:13<00:03, 29.26it/s, est. speed input: 31460.63 toks/s, output: 30.72 toks/s]
Processed prompts:  82%| | 418/512 [00:13<00:03, 28.98it/s, est. speed input: 31435.48 toks/s, output: 30.70 toks/s]
Processed prompts:  82%| | 422/512 [00:13<00:03, 29.06it/s, est. speed input: 31420.76 toks/s, output: 30.68 toks/s]
Processed prompts:  83%| | 426/512 [00:13<00:02, 29.19it/s, est. speed input: 31408.83 toks/s, output: 30.67 toks/s]
Processed prompts:  84%| | 430/512 [00:14<00:02, 29.33it/s, est. speed input: 31398.97 toks/s, output: 30.66 toks/s]
Processed prompts:  85%| | 434/512 [00:14<00:02, 29.24it/s, est. speed input: 31382.75 toks/s, output: 30.65 toks/s]
Processed prompts:  86%| | 438/512 [00:14<00:02, 29.10it/s, est. speed input: 31364.20 toks/s, output: 30.63 toks/s]
Processed prompts:  86%| | 442/512 [00:14<00:02, 29.21it/s, est. speed input: 31352.76 toks/s, output: 30.62 toks/s]
Processed prompts:  87%| | 446/512 [00:14<00:02, 29.12it/s, est. speed input: 31336.41 toks/s, output: 30.60 toks/s]
Processed prompts:  88%| | 450/512 [00:14<00:02, 29.14it/s, est. speed input: 31322.97 toks/s, output: 30.59 toks/s]
Processed prompts:  89%| | 454/512 [00:14<00:01, 29.24it/s, est. speed input: 31312.56 toks/s, output: 30.58 toks/s]
Processed prompts:  89%| | 458/512 [00:14<00:01, 29.18it/s, est. speed input: 31298.02 toks/s, output: 30.56 toks/s]
Processed prompts:  90%| | 462/512 [00:15<00:01, 29.08it/s, est. speed input: 31282.00 toks/s, output: 30.55 toks/s]
Processed prompts:  91%| | 466/512 [00:15<00:01, 29.01it/s, est. speed input: 31266.14 toks/s, output: 30.53 toks/s]
Processed prompts:  92%|| 470/512 [00:15<00:01, 28.99it/s, est. speed input: 31251.42 toks/s, output: 30.52 toks/s]
Processed prompts:  93%|| 474/512 [00:15<00:01, 29.07it/s, est. speed input: 31240.24 toks/s, output: 30.51 toks/s]
Processed prompts:  93%|| 478/512 [00:15<00:01, 28.92it/s, est. speed input: 31222.46 toks/s, output: 30.49 toks/s]
Processed prompts:  94%|| 482/512 [00:15<00:01, 28.84it/s, est. speed input: 31205.95 toks/s, output: 30.47 toks/s]
Processed prompts:  95%|| 486/512 [00:15<00:00, 28.90it/s, est. speed input: 31193.35 toks/s, output: 30.46 toks/s]
Processed prompts:  96%|| 490/512 [00:16<00:00, 28.82it/s, est. speed input: 31176.98 toks/s, output: 30.45 toks/s]
Processed prompts:  96%|| 494/512 [00:16<00:00, 28.92it/s, est. speed input: 31165.83 toks/s, output: 30.44 toks/s]
Processed prompts:  97%|| 498/512 [00:16<00:00, 29.09it/s, est. speed input: 31157.79 toks/s, output: 30.43 toks/s]
Processed prompts:  98%|| 502/512 [00:16<00:00, 29.19it/s, est. speed input: 31149.39 toks/s, output: 30.42 toks/s]
Processed prompts:  99%|| 506/512 [00:16<00:00, 29.30it/s, est. speed input: 31142.19 toks/s, output: 30.41 toks/s]
Processed prompts: 100%|| 510/512 [00:16<00:00, 29.82it/s, est. speed input: 31147.80 toks/s, output: 30.42 toks/s]
Processed prompts: 100%|| 512/512 [00:16<00:00, 29.82it/s, est. speed input: 31269.73 toks/s, output: 30.54 toks/s]
Processed prompts: 100%|| 512/512 [00:16<00:00, 30.54it/s, est. speed input: 31269.73 toks/s, output: 30.54 toks/s]
[rank0]:[W126 08:16:35.601482585 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-26 08:16:37
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-FP8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:16:44 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 08:16:44 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1064390) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1064390) WARNING 01-26 08:17:04 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 28.64 requests/s, 29352.79 total tokens/s, 28.64 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-26 08:16:44] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:16:44] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:16:44] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:16:44] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:16:44] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:16:44] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:16:44] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:16:44] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:16:44] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:16:44] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:16:44] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:16:44] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:16:44] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:16:44] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:16:47] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:16:47] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:16:47] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:16:47] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:16:47] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:16:47] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:16:47] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:16:47] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:16:47] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:16:47] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:16:47] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:16:47] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:16:47] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:16:47] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1064390) [2026-01-26 08:16:48] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1064390) [2026-01-26 08:16:48] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1064390) [2026-01-26 08:16:48] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1064390) [2026-01-26 08:16:48] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1064390) [2026-01-26 08:16:48] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1064390) [2026-01-26 08:16:48] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1064390) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1064390) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.14s/it]
(EngineCore_DP0 pid=1064390) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.14s/it]
(EngineCore_DP0 pid=1064390) 
(EngineCore_DP0 pid=1064390) [2026-01-26 08:16:58] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=1064390) [2026-01-26 08:16:58] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5308416 bytes
(EngineCore_DP0 pid=1064390) [2026-01-26 08:16:58] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=1064390) [2026-01-26 08:16:58] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3538944 bytes
(EngineCore_DP0 pid=1064390) [2026-01-26 08:16:58] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=1064390) [2026-01-26 08:16:58] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 28311552 bytes
(EngineCore_DP0 pid=1064390) [2026-01-26 08:16:58] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=1064390) [2026-01-26 08:16:58] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14024704 bytes
(EngineCore_DP0 pid=1064390) 2026-01-26 08:17:03,530 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1064390) 2026-01-26 08:17:03,591 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   5%|         | 56/1024 [00:00<00:01, 558.44it/s]
Adding requests:  11%|         | 112/1024 [00:00<00:01, 544.79it/s]
Adding requests:  16%|        | 167/1024 [00:00<00:01, 513.49it/s]
Adding requests:  21%|       | 219/1024 [00:00<00:01, 508.43it/s]
Adding requests:  26%|       | 270/1024 [00:00<00:01, 502.22it/s]
Adding requests:  31%|      | 321/1024 [00:00<00:01, 495.52it/s]
Adding requests:  36%|      | 371/1024 [00:00<00:01, 491.15it/s]
Adding requests:  41%|      | 421/1024 [00:00<00:01, 492.40it/s]
Adding requests:  46%|     | 471/1024 [00:00<00:01, 489.11it/s]
Adding requests:  51%|     | 520/1024 [00:01<00:01, 475.56it/s]
Adding requests:  55%|    | 568/1024 [00:01<00:00, 468.24it/s]
Adding requests:  61%|    | 620/1024 [00:01<00:00, 482.06it/s]
Adding requests:  65%|   | 669/1024 [00:01<00:00, 479.27it/s]
Adding requests:  71%|   | 722/1024 [00:01<00:00, 492.04it/s]
Adding requests:  75%|  | 772/1024 [00:01<00:00, 476.12it/s]
Adding requests:  80%|  | 820/1024 [00:01<00:00, 465.15it/s]
Adding requests:  85%| | 867/1024 [00:01<00:00, 463.97it/s]
Adding requests:  90%| | 917/1024 [00:01<00:00, 472.53it/s]
Adding requests:  94%|| 965/1024 [00:01<00:00, 473.13it/s]
Adding requests:  99%|| 1016/1024 [00:02<00:00, 480.80it/s]
Adding requests: 100%|| 1024/1024 [00:02<00:00, 485.67it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|         | 58/1024 [00:00<00:04, 197.22it/s, est. speed input: 201983.69 toks/s, output: 197.22 toks/s]
Processed prompts:   8%|         | 78/1024 [00:00<00:11, 79.81it/s, est. speed input: 94243.68 toks/s, output: 92.03 toks/s]   
Processed prompts:   9%|         | 89/1024 [00:01<00:14, 65.62it/s, est. speed input: 80642.11 toks/s, output: 78.75 toks/s]
Processed prompts:   9%|         | 97/1024 [00:01<00:17, 53.65it/s, est. speed input: 70627.39 toks/s, output: 68.97 toks/s]
Processed prompts:  10%|         | 103/1024 [00:01<00:21, 43.51it/s, est. speed input: 62693.20 toks/s, output: 61.22 toks/s]
Processed prompts:  11%|         | 108/1024 [00:01<00:25, 35.53it/s, est. speed input: 56436.79 toks/s, output: 55.11 toks/s]
Processed prompts:  11%|         | 114/1024 [00:02<00:29, 31.08it/s, est. speed input: 52085.50 toks/s, output: 50.86 toks/s]
Processed prompts:  12%|        | 122/1024 [00:02<00:29, 30.44it/s, est. speed input: 49628.43 toks/s, output: 48.46 toks/s]
Processed prompts:  13%|        | 130/1024 [00:02<00:29, 29.99it/s, est. speed input: 47651.44 toks/s, output: 46.53 toks/s]
Processed prompts:  13%|        | 138/1024 [00:03<00:29, 29.62it/s, est. speed input: 46005.08 toks/s, output: 44.93 toks/s]
Processed prompts:  14%|        | 146/1024 [00:03<00:30, 29.19it/s, est. speed input: 44557.95 toks/s, output: 43.51 toks/s]
Processed prompts:  15%|        | 154/1024 [00:03<00:29, 29.07it/s, est. speed input: 43406.91 toks/s, output: 42.39 toks/s]
Processed prompts:  16%|        | 162/1024 [00:03<00:29, 29.05it/s, est. speed input: 42438.95 toks/s, output: 41.44 toks/s]
Processed prompts:  17%|        | 170/1024 [00:04<00:29, 28.98it/s, est. speed input: 41581.46 toks/s, output: 40.61 toks/s]
Processed prompts:  17%|        | 178/1024 [00:04<00:29, 28.83it/s, est. speed input: 40802.52 toks/s, output: 39.85 toks/s]
Processed prompts:  18%|        | 186/1024 [00:04<00:28, 28.98it/s, est. speed input: 40181.42 toks/s, output: 39.24 toks/s]
Processed prompts:  19%|        | 194/1024 [00:05<00:28, 28.93it/s, est. speed input: 39591.77 toks/s, output: 38.66 toks/s]
Processed prompts:  20%|        | 202/1024 [00:05<00:28, 28.88it/s, est. speed input: 39060.07 toks/s, output: 38.14 toks/s]
Processed prompts:  21%|        | 210/1024 [00:05<00:28, 28.72it/s, est. speed input: 38553.23 toks/s, output: 37.65 toks/s]
Processed prompts:  21%|       | 218/1024 [00:05<00:27, 28.87it/s, est. speed input: 38149.36 toks/s, output: 37.25 toks/s]
Processed prompts:  22%|       | 226/1024 [00:06<00:27, 28.93it/s, est. speed input: 37772.63 toks/s, output: 36.89 toks/s]
Processed prompts:  23%|       | 234/1024 [00:06<00:27, 28.95it/s, est. speed input: 37424.73 toks/s, output: 36.55 toks/s]
Processed prompts:  24%|       | 242/1024 [00:06<00:27, 28.81it/s, est. speed input: 37078.08 toks/s, output: 36.21 toks/s]
Processed prompts:  24%|       | 250/1024 [00:06<00:26, 28.82it/s, est. speed input: 36777.77 toks/s, output: 35.92 toks/s]
Processed prompts:  25%|       | 258/1024 [00:07<00:26, 28.85it/s, est. speed input: 36503.19 toks/s, output: 35.65 toks/s]
Processed prompts:  26%|       | 266/1024 [00:07<00:26, 28.86it/s, est. speed input: 36248.54 toks/s, output: 35.40 toks/s]
Processed prompts:  27%|       | 274/1024 [00:07<00:26, 28.75it/s, est. speed input: 35994.41 toks/s, output: 35.15 toks/s]
Processed prompts:  28%|       | 282/1024 [00:08<00:25, 28.81it/s, est. speed input: 35776.18 toks/s, output: 34.94 toks/s]
Processed prompts:  28%|       | 290/1024 [00:08<00:25, 28.79it/s, est. speed input: 35565.06 toks/s, output: 34.73 toks/s]
Processed prompts:  29%|       | 298/1024 [00:08<00:25, 28.65it/s, est. speed input: 35350.33 toks/s, output: 34.52 toks/s]
Processed prompts:  30%|       | 306/1024 [00:08<00:24, 28.74it/s, est. speed input: 35173.13 toks/s, output: 34.35 toks/s]
Processed prompts:  31%|       | 314/1024 [00:09<00:24, 28.83it/s, est. speed input: 35010.71 toks/s, output: 34.19 toks/s]
Processed prompts:  31%|      | 322/1024 [00:09<00:24, 28.85it/s, est. speed input: 34851.65 toks/s, output: 34.03 toks/s]
Processed prompts:  32%|      | 330/1024 [00:09<00:24, 28.71it/s, est. speed input: 34684.34 toks/s, output: 33.87 toks/s]
Processed prompts:  33%|      | 338/1024 [00:10<00:23, 28.84it/s, est. speed input: 34552.18 toks/s, output: 33.74 toks/s]
Processed prompts:  34%|      | 346/1024 [00:10<00:23, 28.80it/s, est. speed input: 34412.24 toks/s, output: 33.61 toks/s]
Processed prompts:  35%|      | 354/1024 [00:10<00:23, 28.82it/s, est. speed input: 34285.34 toks/s, output: 33.48 toks/s]
Processed prompts:  35%|      | 362/1024 [00:10<00:23, 28.72it/s, est. speed input: 34152.66 toks/s, output: 33.35 toks/s]
Processed prompts:  36%|      | 370/1024 [00:11<00:22, 28.76it/s, est. speed input: 34037.81 toks/s, output: 33.24 toks/s]
Processed prompts:  37%|      | 378/1024 [00:11<00:22, 28.72it/s, est. speed input: 33922.08 toks/s, output: 33.13 toks/s]
Processed prompts:  38%|      | 386/1024 [00:11<00:22, 28.77it/s, est. speed input: 33819.36 toks/s, output: 33.03 toks/s]
Processed prompts:  38%|      | 394/1024 [00:11<00:22, 28.61it/s, est. speed input: 33703.28 toks/s, output: 32.91 toks/s]
Processed prompts:  39%|      | 402/1024 [00:12<00:21, 28.75it/s, est. speed input: 33615.13 toks/s, output: 32.83 toks/s]
Processed prompts:  40%|      | 410/1024 [00:12<00:21, 28.72it/s, est. speed input: 33520.07 toks/s, output: 32.73 toks/s]
Processed prompts:  41%|      | 418/1024 [00:12<00:20, 28.86it/s, est. speed input: 33442.56 toks/s, output: 32.66 toks/s]
Processed prompts:  42%|     | 426/1024 [00:13<00:20, 28.74it/s, est. speed input: 33350.12 toks/s, output: 32.57 toks/s]
Processed prompts:  42%|     | 434/1024 [00:13<00:20, 28.73it/s, est. speed input: 33267.78 toks/s, output: 32.49 toks/s]
Processed prompts:  43%|     | 442/1024 [00:13<00:20, 28.81it/s, est. speed input: 33195.26 toks/s, output: 32.42 toks/s]
Processed prompts:  44%|     | 450/1024 [00:13<00:19, 29.26it/s, est. speed input: 33155.44 toks/s, output: 32.38 toks/s]
Processed prompts:  45%|     | 458/1024 [00:14<00:19, 28.93it/s, est. speed input: 33069.29 toks/s, output: 32.29 toks/s]
Processed prompts:  46%|     | 466/1024 [00:14<00:19, 28.90it/s, est. speed input: 33001.59 toks/s, output: 32.23 toks/s]
Processed prompts:  46%|     | 474/1024 [00:14<00:19, 28.91it/s, est. speed input: 32938.37 toks/s, output: 32.17 toks/s]
Processed prompts:  47%|     | 482/1024 [00:15<00:18, 28.77it/s, est. speed input: 32867.22 toks/s, output: 32.10 toks/s]
Processed prompts:  48%|     | 490/1024 [00:15<00:18, 28.73it/s, est. speed input: 32802.30 toks/s, output: 32.03 toks/s]
Processed prompts:  49%|     | 498/1024 [00:15<00:18, 28.79it/s, est. speed input: 32746.05 toks/s, output: 31.98 toks/s]
Processed prompts:  49%|     | 506/1024 [00:15<00:17, 28.81it/s, est. speed input: 32689.86 toks/s, output: 31.92 toks/s]
Processed prompts:  50%|     | 514/1024 [00:16<00:17, 28.67it/s, est. speed input: 32625.85 toks/s, output: 31.86 toks/s]
Processed prompts:  51%|     | 522/1024 [00:16<00:17, 28.74it/s, est. speed input: 32574.62 toks/s, output: 31.81 toks/s]
Processed prompts:  52%|    | 530/1024 [00:16<00:17, 28.77it/s, est. speed input: 32524.37 toks/s, output: 31.76 toks/s]
Processed prompts:  53%|    | 538/1024 [00:16<00:16, 28.77it/s, est. speed input: 32474.29 toks/s, output: 31.71 toks/s]
Processed prompts:  53%|    | 546/1024 [00:17<00:16, 28.60it/s, est. speed input: 32415.24 toks/s, output: 31.66 toks/s]
Processed prompts:  54%|    | 554/1024 [00:17<00:16, 28.64it/s, est. speed input: 32367.45 toks/s, output: 31.61 toks/s]
Processed prompts:  55%|    | 562/1024 [00:17<00:16, 28.68it/s, est. speed input: 32321.94 toks/s, output: 31.56 toks/s]
Processed prompts:  56%|    | 570/1024 [00:18<00:15, 28.69it/s, est. speed input: 32276.96 toks/s, output: 31.52 toks/s]
Processed prompts:  56%|    | 578/1024 [00:18<00:15, 28.61it/s, est. speed input: 32228.46 toks/s, output: 31.47 toks/s]
Processed prompts:  57%|    | 586/1024 [00:18<00:15, 28.78it/s, est. speed input: 32193.78 toks/s, output: 31.44 toks/s]
Processed prompts:  58%|    | 594/1024 [00:18<00:14, 28.82it/s, est. speed input: 32155.95 toks/s, output: 31.40 toks/s]
Processed prompts:  59%|    | 602/1024 [00:19<00:14, 28.82it/s, est. speed input: 32117.59 toks/s, output: 31.36 toks/s]
Processed prompts:  60%|    | 610/1024 [00:19<00:14, 28.66it/s, est. speed input: 32072.07 toks/s, output: 31.32 toks/s]
Processed prompts:  60%|    | 618/1024 [00:19<00:14, 28.69it/s, est. speed input: 32035.39 toks/s, output: 31.28 toks/s]
Processed prompts:  61%|    | 626/1024 [00:20<00:13, 28.73it/s, est. speed input: 32000.56 toks/s, output: 31.25 toks/s]
Processed prompts:  62%|   | 634/1024 [00:20<00:13, 28.75it/s, est. speed input: 31966.00 toks/s, output: 31.22 toks/s]
Processed prompts:  63%|   | 642/1024 [00:20<00:13, 28.57it/s, est. speed input: 31922.87 toks/s, output: 31.17 toks/s]
Processed prompts:  63%|   | 650/1024 [00:20<00:13, 28.66it/s, est. speed input: 31891.66 toks/s, output: 31.14 toks/s]
Processed prompts:  64%|   | 658/1024 [00:21<00:12, 28.72it/s, est. speed input: 31860.74 toks/s, output: 31.11 toks/s]
Processed prompts:  65%|   | 666/1024 [00:21<00:12, 28.75it/s, est. speed input: 31830.68 toks/s, output: 31.08 toks/s]
Processed prompts:  66%|   | 674/1024 [00:21<00:12, 28.57it/s, est. speed input: 31791.57 toks/s, output: 31.05 toks/s]
Processed prompts:  67%|   | 682/1024 [00:21<00:11, 28.66it/s, est. speed input: 31763.12 toks/s, output: 31.02 toks/s]
Processed prompts:  67%|   | 690/1024 [00:22<00:11, 28.73it/s, est. speed input: 31736.16 toks/s, output: 30.99 toks/s]
Processed prompts:  68%|   | 698/1024 [00:22<00:11, 28.61it/s, est. speed input: 31701.95 toks/s, output: 30.96 toks/s]
Processed prompts:  69%|   | 706/1024 [00:22<00:11, 28.60it/s, est. speed input: 31672.30 toks/s, output: 30.93 toks/s]
Processed prompts:  70%|   | 714/1024 [00:23<00:10, 28.77it/s, est. speed input: 31650.63 toks/s, output: 30.91 toks/s]
Processed prompts:  71%|   | 722/1024 [00:23<00:10, 28.80it/s, est. speed input: 31625.89 toks/s, output: 30.88 toks/s]
Processed prompts:  71%|  | 730/1024 [00:23<00:10, 28.57it/s, est. speed input: 31590.94 toks/s, output: 30.85 toks/s]
Processed prompts:  72%|  | 738/1024 [00:23<00:09, 28.65it/s, est. speed input: 31567.06 toks/s, output: 30.83 toks/s]
Processed prompts:  73%|  | 746/1024 [00:24<00:09, 28.77it/s, est. speed input: 31546.33 toks/s, output: 30.81 toks/s]
Processed prompts:  74%|  | 754/1024 [00:24<00:09, 28.76it/s, est. speed input: 31522.39 toks/s, output: 30.78 toks/s]
Processed prompts:  74%|  | 762/1024 [00:24<00:09, 28.62it/s, est. speed input: 31493.17 toks/s, output: 30.75 toks/s]
Processed prompts:  75%|  | 770/1024 [00:25<00:08, 28.65it/s, est. speed input: 31470.29 toks/s, output: 30.73 toks/s]
Processed prompts:  76%|  | 778/1024 [00:25<00:08, 28.67it/s, est. speed input: 31447.31 toks/s, output: 30.71 toks/s]
Processed prompts:  77%|  | 786/1024 [00:25<00:08, 28.76it/s, est. speed input: 31428.02 toks/s, output: 30.69 toks/s]
Processed prompts:  78%|  | 794/1024 [00:25<00:08, 28.64it/s, est. speed input: 31402.09 toks/s, output: 30.67 toks/s]
Processed prompts:  78%|  | 802/1024 [00:26<00:07, 28.76it/s, est. speed input: 31384.80 toks/s, output: 30.65 toks/s]
Processed prompts:  79%|  | 810/1024 [00:26<00:07, 28.77it/s, est. speed input: 31364.79 toks/s, output: 30.63 toks/s]
Processed prompts:  80%|  | 818/1024 [00:26<00:07, 28.83it/s, est. speed input: 31347.34 toks/s, output: 30.61 toks/s]
Processed prompts:  81%|  | 826/1024 [00:27<00:06, 28.70it/s, est. speed input: 31323.54 toks/s, output: 30.59 toks/s]
Processed prompts:  81%| | 834/1024 [00:27<00:06, 28.73it/s, est. speed input: 31304.82 toks/s, output: 30.57 toks/s]
Processed prompts:  82%| | 842/1024 [00:27<00:06, 28.69it/s, est. speed input: 31284.45 toks/s, output: 30.55 toks/s]
Processed prompts:  83%| | 850/1024 [00:27<00:06, 28.73it/s, est. speed input: 31266.80 toks/s, output: 30.53 toks/s]
Processed prompts:  84%| | 858/1024 [00:28<00:05, 28.64it/s, est. speed input: 31245.14 toks/s, output: 30.51 toks/s]
Processed prompts:  85%| | 866/1024 [00:28<00:05, 28.62it/s, est. speed input: 31225.63 toks/s, output: 30.49 toks/s]
Processed prompts:  85%| | 874/1024 [00:28<00:05, 28.68it/s, est. speed input: 31209.23 toks/s, output: 30.48 toks/s]
Processed prompts:  86%| | 882/1024 [00:28<00:04, 28.66it/s, est. speed input: 31190.50 toks/s, output: 30.46 toks/s]
Processed prompts:  87%| | 890/1024 [00:29<00:04, 28.66it/s, est. speed input: 31172.97 toks/s, output: 30.44 toks/s]
Processed prompts:  88%| | 898/1024 [00:29<00:04, 28.62it/s, est. speed input: 31154.31 toks/s, output: 30.42 toks/s]
Processed prompts:  88%| | 906/1024 [00:29<00:04, 28.79it/s, est. speed input: 31142.74 toks/s, output: 30.41 toks/s]
Processed prompts:  89%| | 914/1024 [00:30<00:03, 28.65it/s, est. speed input: 31122.65 toks/s, output: 30.39 toks/s]
Processed prompts:  90%| | 922/1024 [00:30<00:03, 27.64it/s, est. speed input: 31071.31 toks/s, output: 30.34 toks/s]
Processed prompts:  91%| | 930/1024 [00:30<00:03, 27.98it/s, est. speed input: 31057.26 toks/s, output: 30.33 toks/s]
Processed prompts:  92%|| 938/1024 [00:30<00:02, 29.29it/s, est. speed input: 31077.86 toks/s, output: 30.35 toks/s]
Processed prompts:  92%|| 946/1024 [00:31<00:02, 29.04it/s, est. speed input: 31060.32 toks/s, output: 30.33 toks/s]
Processed prompts:  93%|| 954/1024 [00:31<00:02, 28.99it/s, est. speed input: 31047.26 toks/s, output: 30.32 toks/s]
Processed prompts:  94%|| 962/1024 [00:31<00:02, 28.91it/s, est. speed input: 31032.88 toks/s, output: 30.31 toks/s]
Processed prompts:  95%|| 970/1024 [00:32<00:01, 28.83it/s, est. speed input: 31018.02 toks/s, output: 30.29 toks/s]
Processed prompts:  96%|| 978/1024 [00:32<00:01, 28.61it/s, est. speed input: 30998.50 toks/s, output: 30.27 toks/s]
Processed prompts:  96%|| 986/1024 [00:32<00:01, 29.77it/s, est. speed input: 31018.30 toks/s, output: 30.29 toks/s]
Processed prompts:  97%|| 994/1024 [00:32<00:01, 29.42it/s, est. speed input: 31003.90 toks/s, output: 30.28 toks/s]
Processed prompts:  98%|| 1002/1024 [00:33<00:00, 29.32it/s, est. speed input: 30993.82 toks/s, output: 30.27 toks/s]
Processed prompts:  99%|| 1010/1024 [00:33<00:00, 28.99it/s, est. speed input: 30976.19 toks/s, output: 30.25 toks/s]
Processed prompts:  99%|| 1018/1024 [00:33<00:00, 29.52it/s, est. speed input: 30980.92 toks/s, output: 30.25 toks/s]
Processed prompts: 100%|| 1024/1024 [00:33<00:00, 29.52it/s, est. speed input: 31163.30 toks/s, output: 30.43 toks/s]
Processed prompts: 100%|| 1024/1024 [00:33<00:00, 30.43it/s, est. speed input: 31163.30 toks/s, output: 30.43 toks/s]
[rank0]:[W126 08:17:40.616923428 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-26 08:17:42
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-FP8_M16384.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:17:51 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 08:17:51 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1065502) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1065502) WARNING 01-26 08:18:12 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 29.52 requests/s, 30256.13 total tokens/s, 29.52 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-26 08:17:51] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:17:51] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:17:51] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:17:51] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:17:51] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:17:51] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:17:51] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:17:51] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:17:51] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:17:51] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:17:51] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:17:51] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:17:51] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:17:51] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:17:55] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:17:55] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:17:55] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:17:55] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:17:55] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:17:55] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:17:55] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:17:55] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:17:55] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:17:55] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:17:55] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:17:55] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:17:55] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:17:55] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1065502) [2026-01-26 08:17:56] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1065502) [2026-01-26 08:17:56] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1065502) [2026-01-26 08:17:56] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1065502) [2026-01-26 08:17:56] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1065502) [2026-01-26 08:17:56] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1065502) [2026-01-26 08:17:56] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1065502) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1065502) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.08s/it]
(EngineCore_DP0 pid=1065502) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.08s/it]
(EngineCore_DP0 pid=1065502) 
(EngineCore_DP0 pid=1065502) [2026-01-26 08:18:05] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=1065502) [2026-01-26 08:18:05] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5308416 bytes
(EngineCore_DP0 pid=1065502) [2026-01-26 08:18:05] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=1065502) [2026-01-26 08:18:05] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3538944 bytes
(EngineCore_DP0 pid=1065502) [2026-01-26 08:18:05] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=1065502) [2026-01-26 08:18:06] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 28311552 bytes
(EngineCore_DP0 pid=1065502) [2026-01-26 08:18:06] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=1065502) [2026-01-26 08:18:06] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14024704 bytes
(EngineCore_DP0 pid=1065502) 2026-01-26 08:18:11,435 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1065502) 2026-01-26 08:18:11,530 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   3%|         | 60/2048 [00:00<00:03, 599.33it/s]
Adding requests:   6%|         | 120/2048 [00:00<00:03, 542.21it/s]
Adding requests:   9%|         | 175/2048 [00:00<00:03, 501.29it/s]
Adding requests:  11%|         | 226/2048 [00:00<00:03, 497.50it/s]
Adding requests:  13%|        | 276/2048 [00:00<00:03, 498.32it/s]
Adding requests:  16%|        | 326/2048 [00:00<00:03, 485.84it/s]
Adding requests:  18%|        | 375/2048 [00:00<00:03, 477.00it/s]
Adding requests:  21%|        | 423/2048 [00:00<00:03, 475.01it/s]
Adding requests:  23%|       | 471/2048 [00:00<00:03, 475.90it/s]
Adding requests:  25%|       | 519/2048 [00:01<00:03, 468.33it/s]
Adding requests:  28%|       | 568/2048 [00:01<00:03, 473.96it/s]
Adding requests:  30%|       | 616/2048 [00:01<00:03, 471.42it/s]
Adding requests:  32%|      | 664/2048 [00:01<00:02, 472.15it/s]
Adding requests:  35%|      | 713/2048 [00:01<00:02, 477.00it/s]
Adding requests:  37%|      | 761/2048 [00:01<00:02, 457.40it/s]
Adding requests:  39%|      | 807/2048 [00:01<00:02, 457.24it/s]
Adding requests:  42%|     | 853/2048 [00:02<00:07, 158.48it/s]
Adding requests:  44%|     | 893/2048 [00:02<00:06, 188.84it/s]
Adding requests:  46%|     | 939/2048 [00:02<00:04, 230.10it/s]
Adding requests:  48%|     | 990/2048 [00:02<00:03, 279.67it/s]
Adding requests:  51%|     | 1038/2048 [00:02<00:03, 320.11it/s]
Adding requests:  53%|    | 1082/2048 [00:02<00:02, 343.26it/s]
Adding requests:  55%|    | 1129/2048 [00:03<00:02, 371.75it/s]
Adding requests:  58%|    | 1179/2048 [00:03<00:02, 402.56it/s]
Adding requests:  60%|    | 1229/2048 [00:03<00:01, 427.91it/s]
Adding requests:  62%|   | 1276/2048 [00:03<00:01, 437.86it/s]
Adding requests:  65%|   | 1323/2048 [00:03<00:01, 442.61it/s]
Adding requests:  67%|   | 1371/2048 [00:03<00:01, 451.20it/s]
Adding requests:  69%|   | 1421/2048 [00:03<00:01, 463.28it/s]
Adding requests:  72%|  | 1470/2048 [00:03<00:01, 468.93it/s]
Adding requests:  74%|  | 1522/2048 [00:03<00:01, 481.90it/s]
Adding requests:  77%|  | 1571/2048 [00:03<00:01, 476.22it/s]
Adding requests:  79%|  | 1620/2048 [00:04<00:00, 478.14it/s]
Adding requests:  81%| | 1669/2048 [00:04<00:00, 478.69it/s]
Adding requests:  84%| | 1718/2048 [00:04<00:00, 481.64it/s]
Adding requests:  86%| | 1767/2048 [00:04<00:00, 483.47it/s]
Adding requests:  89%| | 1816/2048 [00:04<00:00, 476.87it/s]
Adding requests:  91%| | 1864/2048 [00:04<00:00, 465.45it/s]
Adding requests:  93%|| 1912/2048 [00:04<00:00, 466.44it/s]
Adding requests:  96%|| 1959/2048 [00:04<00:00, 465.29it/s]
Adding requests:  98%|| 2006/2048 [00:04<00:00, 448.65it/s]
Adding requests: 100%|| 2048/2048 [00:05<00:00, 409.48it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   7%|         | 146/2048 [00:00<00:07, 270.76it/s, est. speed input: 277271.71 toks/s, output: 270.76 toks/s]
Processed prompts:   8%|         | 174/2048 [00:01<00:13, 141.79it/s, est. speed input: 164978.63 toks/s, output: 161.11 toks/s]
Processed prompts:   9%|         | 189/2048 [00:01<00:20, 90.36it/s, est. speed input: 120073.12 toks/s, output: 117.26 toks/s] 
Processed prompts:  10%|         | 199/2048 [00:02<00:29, 61.79it/s, est. speed input: 94604.01 toks/s, output: 92.39 toks/s]  
Processed prompts:  10%|         | 210/2048 [00:02<00:39, 47.08it/s, est. speed input: 80066.48 toks/s, output: 78.19 toks/s]
Processed prompts:  11%|         | 226/2048 [00:03<00:44, 41.06it/s, est. speed input: 71687.66 toks/s, output: 70.01 toks/s]
Processed prompts:  12%|        | 242/2048 [00:03<00:48, 37.44it/s, est. speed input: 65858.99 toks/s, output: 64.31 toks/s]
Processed prompts:  13%|        | 258/2048 [00:04<00:51, 34.98it/s, est. speed input: 61424.44 toks/s, output: 59.98 toks/s]
Processed prompts:  13%|        | 274/2048 [00:04<00:53, 33.37it/s, est. speed input: 57998.16 toks/s, output: 56.64 toks/s]
Processed prompts:  14%|        | 290/2048 [00:05<00:54, 32.19it/s, est. speed input: 55210.21 toks/s, output: 53.92 toks/s]
Processed prompts:  15%|        | 306/2048 [00:05<00:55, 31.54it/s, est. speed input: 53007.63 toks/s, output: 51.76 toks/s]
Processed prompts:  16%|        | 322/2048 [00:06<00:55, 30.97it/s, est. speed input: 51119.03 toks/s, output: 49.92 toks/s]
Processed prompts:  17%|        | 338/2048 [00:07<00:58, 29.01it/s, est. speed input: 48847.77 toks/s, output: 47.70 toks/s]
Processed prompts:  17%|        | 354/2048 [00:07<01:07, 24.92it/s, est. speed input: 45639.22 toks/s, output: 44.57 toks/s]
Processed prompts:  18%|        | 370/2048 [00:08<01:06, 25.08it/s, est. speed input: 44206.22 toks/s, output: 43.17 toks/s]
Processed prompts:  19%|        | 386/2048 [00:09<01:03, 26.29it/s, est. speed input: 43387.38 toks/s, output: 42.37 toks/s]
Processed prompts:  20%|        | 402/2048 [00:09<01:00, 27.19it/s, est. speed input: 42651.02 toks/s, output: 41.65 toks/s]
Processed prompts:  20%|        | 418/2048 [00:10<00:58, 27.95it/s, est. speed input: 42019.68 toks/s, output: 41.03 toks/s]
Processed prompts:  21%|        | 434/2048 [00:10<00:56, 28.38it/s, est. speed input: 41418.34 toks/s, output: 40.45 toks/s]
Processed prompts:  22%|       | 450/2048 [00:11<00:55, 28.98it/s, est. speed input: 40943.69 toks/s, output: 39.98 toks/s]
Processed prompts:  23%|       | 466/2048 [00:11<00:54, 29.19it/s, est. speed input: 40460.87 toks/s, output: 39.51 toks/s]
Processed prompts:  24%|       | 482/2048 [00:12<00:53, 29.41it/s, est. speed input: 40036.91 toks/s, output: 39.10 toks/s]
Processed prompts:  24%|       | 498/2048 [00:12<00:52, 29.44it/s, est. speed input: 39623.03 toks/s, output: 38.69 toks/s]
Processed prompts:  25%|       | 514/2048 [00:13<00:51, 29.57it/s, est. speed input: 39262.84 toks/s, output: 38.34 toks/s]
Processed prompts:  26%|       | 530/2048 [00:13<00:51, 29.58it/s, est. speed input: 38915.95 toks/s, output: 38.00 toks/s]
Processed prompts:  27%|       | 546/2048 [00:14<00:50, 29.65it/s, est. speed input: 38605.37 toks/s, output: 37.70 toks/s]
Processed prompts:  27%|       | 562/2048 [00:15<00:50, 29.60it/s, est. speed input: 38301.90 toks/s, output: 37.40 toks/s]
Processed prompts:  28%|       | 578/2048 [00:15<00:49, 29.68it/s, est. speed input: 38035.32 toks/s, output: 37.14 toks/s]
Processed prompts:  29%|       | 594/2048 [00:16<00:49, 29.66it/s, est. speed input: 37776.66 toks/s, output: 36.89 toks/s]
Processed prompts:  30%|       | 610/2048 [00:16<00:48, 29.72it/s, est. speed input: 37545.33 toks/s, output: 36.67 toks/s]
Processed prompts:  31%|       | 626/2048 [00:17<00:47, 29.67it/s, est. speed input: 37315.01 toks/s, output: 36.44 toks/s]
Processed prompts:  31%|      | 642/2048 [00:17<00:47, 29.74it/s, est. speed input: 37112.68 toks/s, output: 36.24 toks/s]
Processed prompts:  32%|      | 658/2048 [00:18<00:46, 29.67it/s, est. speed input: 36907.66 toks/s, output: 36.04 toks/s]
Processed prompts:  33%|      | 674/2048 [00:18<00:46, 29.71it/s, est. speed input: 36725.31 toks/s, output: 35.86 toks/s]
Processed prompts:  34%|      | 690/2048 [00:19<00:45, 29.66it/s, est. speed input: 36544.47 toks/s, output: 35.69 toks/s]
Processed prompts:  34%|      | 706/2048 [00:19<00:45, 29.70it/s, est. speed input: 36381.16 toks/s, output: 35.53 toks/s]
Processed prompts:  35%|      | 722/2048 [00:20<00:44, 29.62it/s, est. speed input: 36214.69 toks/s, output: 35.37 toks/s]
Processed prompts:  36%|      | 738/2048 [00:20<00:44, 29.71it/s, est. speed input: 36072.92 toks/s, output: 35.23 toks/s]
Processed prompts:  37%|      | 754/2048 [00:21<00:43, 29.65it/s, est. speed input: 35925.33 toks/s, output: 35.08 toks/s]
Processed prompts:  38%|      | 770/2048 [00:22<00:43, 29.67it/s, est. speed input: 35790.48 toks/s, output: 34.95 toks/s]
Processed prompts:  38%|      | 786/2048 [00:22<00:42, 29.61it/s, est. speed input: 35655.55 toks/s, output: 34.82 toks/s]
Processed prompts:  39%|      | 802/2048 [00:23<00:42, 29.66it/s, est. speed input: 35536.00 toks/s, output: 34.70 toks/s]
Processed prompts:  40%|      | 818/2048 [00:23<00:41, 29.57it/s, est. speed input: 35410.09 toks/s, output: 34.58 toks/s]
Processed prompts:  41%|      | 834/2048 [00:24<00:40, 29.67it/s, est. speed input: 35303.81 toks/s, output: 34.48 toks/s]
Processed prompts:  42%|     | 850/2048 [00:24<00:40, 29.67it/s, est. speed input: 35196.52 toks/s, output: 34.37 toks/s]
Processed prompts:  42%|     | 866/2048 [00:25<00:39, 29.67it/s, est. speed input: 35093.58 toks/s, output: 34.27 toks/s]
Processed prompts:  43%|     | 882/2048 [00:25<00:39, 29.66it/s, est. speed input: 34994.57 toks/s, output: 34.17 toks/s]
Processed prompts:  44%|     | 898/2048 [00:26<00:38, 29.68it/s, est. speed input: 34901.77 toks/s, output: 34.08 toks/s]
Processed prompts:  45%|     | 914/2048 [00:26<00:38, 29.64it/s, est. speed input: 34808.13 toks/s, output: 33.99 toks/s]
Processed prompts:  45%|     | 930/2048 [00:27<00:37, 30.14it/s, est. speed input: 34758.47 toks/s, output: 33.94 toks/s]
Processed prompts:  46%|     | 946/2048 [00:27<00:36, 29.97it/s, est. speed input: 34671.94 toks/s, output: 33.86 toks/s]
Processed prompts:  47%|     | 962/2048 [00:28<00:36, 29.87it/s, est. speed input: 34590.10 toks/s, output: 33.78 toks/s]
Processed prompts:  48%|     | 978/2048 [00:28<00:35, 30.25it/s, est. speed input: 34542.80 toks/s, output: 33.73 toks/s]
Processed prompts:  49%|     | 994/2048 [00:29<00:35, 30.08it/s, est. speed input: 34467.06 toks/s, output: 33.66 toks/s]
Processed prompts:  49%|     | 1010/2048 [00:30<00:34, 29.86it/s, est. speed input: 34387.75 toks/s, output: 33.58 toks/s]
Processed prompts:  50%|     | 1026/2048 [00:30<00:34, 29.86it/s, est. speed input: 34321.07 toks/s, output: 33.52 toks/s]
Processed prompts:  51%|     | 1042/2048 [00:31<00:33, 29.70it/s, est. speed input: 34245.95 toks/s, output: 33.44 toks/s]
Processed prompts:  52%|    | 1058/2048 [00:31<00:33, 29.72it/s, est. speed input: 34181.99 toks/s, output: 33.38 toks/s]
Processed prompts:  52%|    | 1074/2048 [00:32<00:32, 29.63it/s, est. speed input: 34113.85 toks/s, output: 33.31 toks/s]
Processed prompts:  53%|    | 1090/2048 [00:32<00:32, 29.64it/s, est. speed input: 34052.08 toks/s, output: 33.25 toks/s]
Processed prompts:  54%|    | 1106/2048 [00:33<00:31, 29.60it/s, est. speed input: 33989.56 toks/s, output: 33.19 toks/s]
Processed prompts:  55%|    | 1122/2048 [00:33<00:31, 29.63it/s, est. speed input: 33932.96 toks/s, output: 33.14 toks/s]
Processed prompts:  56%|    | 1138/2048 [00:34<00:30, 29.59it/s, est. speed input: 33874.12 toks/s, output: 33.08 toks/s]
Processed prompts:  56%|    | 1154/2048 [00:34<00:29, 30.10it/s, est. speed input: 33848.15 toks/s, output: 33.05 toks/s]
Processed prompts:  57%|    | 1170/2048 [00:35<00:29, 29.87it/s, est. speed input: 33790.09 toks/s, output: 33.00 toks/s]
Processed prompts:  58%|    | 1186/2048 [00:35<00:28, 29.80it/s, est. speed input: 33738.13 toks/s, output: 32.95 toks/s]
Processed prompts:  59%|    | 1202/2048 [00:36<00:28, 29.68it/s, est. speed input: 33684.37 toks/s, output: 32.89 toks/s]
Processed prompts:  59%|    | 1218/2048 [00:37<00:27, 29.68it/s, est. speed input: 33636.52 toks/s, output: 32.85 toks/s]
Processed prompts:  60%|    | 1234/2048 [00:37<00:27, 29.58it/s, est. speed input: 33584.70 toks/s, output: 32.80 toks/s]
Processed prompts:  61%|    | 1250/2048 [00:38<00:26, 29.66it/s, est. speed input: 33541.96 toks/s, output: 32.76 toks/s]
Processed prompts:  62%|   | 1266/2048 [00:38<00:25, 30.11it/s, est. speed input: 33521.04 toks/s, output: 32.74 toks/s]
Processed prompts:  63%|   | 1282/2048 [00:39<00:25, 30.00it/s, est. speed input: 33479.37 toks/s, output: 32.69 toks/s]
Processed prompts:  63%|   | 1298/2048 [00:39<00:24, 30.39it/s, est. speed input: 33461.46 toks/s, output: 32.68 toks/s]
Processed prompts:  64%|   | 1314/2048 [00:40<00:24, 30.24it/s, est. speed input: 33423.81 toks/s, output: 32.64 toks/s]
Processed prompts:  65%|   | 1330/2048 [00:40<00:23, 29.97it/s, est. speed input: 33378.49 toks/s, output: 32.60 toks/s]
Processed prompts:  66%|   | 1346/2048 [00:41<00:23, 29.88it/s, est. speed input: 33339.73 toks/s, output: 32.56 toks/s]
Processed prompts:  67%|   | 1362/2048 [00:41<00:23, 29.74it/s, est. speed input: 33297.66 toks/s, output: 32.52 toks/s]
Processed prompts:  67%|   | 1378/2048 [00:42<00:22, 29.74it/s, est. speed input: 33261.68 toks/s, output: 32.48 toks/s]
Processed prompts:  68%|   | 1394/2048 [00:42<00:22, 29.64it/s, est. speed input: 33221.89 toks/s, output: 32.44 toks/s]
Processed prompts:  69%|   | 1410/2048 [00:43<00:21, 29.67it/s, est. speed input: 33187.59 toks/s, output: 32.41 toks/s]
Processed prompts:  70%|   | 1426/2048 [00:44<00:20, 29.64it/s, est. speed input: 33151.78 toks/s, output: 32.37 toks/s]
Processed prompts:  70%|   | 1442/2048 [00:44<00:20, 29.66it/s, est. speed input: 33119.02 toks/s, output: 32.34 toks/s]
Processed prompts:  71%|   | 1458/2048 [00:45<00:19, 29.62it/s, est. speed input: 33084.17 toks/s, output: 32.31 toks/s]
Processed prompts:  72%|  | 1474/2048 [00:45<00:19, 29.66it/s, est. speed input: 33053.24 toks/s, output: 32.28 toks/s]
Processed prompts:  73%|  | 1490/2048 [00:46<00:18, 29.57it/s, est. speed input: 33018.09 toks/s, output: 32.24 toks/s]
Processed prompts:  74%|  | 1506/2048 [00:46<00:18, 29.64it/s, est. speed input: 32989.29 toks/s, output: 32.22 toks/s]
Processed prompts:  74%|  | 1522/2048 [00:47<00:17, 29.57it/s, est. speed input: 32956.16 toks/s, output: 32.18 toks/s]
Processed prompts:  75%|  | 1538/2048 [00:47<00:17, 29.65it/s, est. speed input: 32929.56 toks/s, output: 32.16 toks/s]
Processed prompts:  76%|  | 1554/2048 [00:48<00:16, 29.58it/s, est. speed input: 32897.97 toks/s, output: 32.13 toks/s]
Processed prompts:  77%|  | 1570/2048 [00:48<00:16, 29.60it/s, est. speed input: 32870.02 toks/s, output: 32.10 toks/s]
Processed prompts:  77%|  | 1586/2048 [00:49<00:15, 30.06it/s, est. speed input: 32860.42 toks/s, output: 32.09 toks/s]
Processed prompts:  78%|  | 1602/2048 [00:49<00:14, 30.02it/s, est. speed input: 32836.40 toks/s, output: 32.07 toks/s]
Processed prompts:  79%|  | 1618/2048 [00:50<00:14, 29.84it/s, est. speed input: 32807.26 toks/s, output: 32.04 toks/s]
Processed prompts:  80%|  | 1634/2048 [00:51<00:13, 29.81it/s, est. speed input: 32782.71 toks/s, output: 32.01 toks/s]
Processed prompts:  81%|  | 1650/2048 [00:51<00:13, 30.27it/s, est. speed input: 32776.47 toks/s, output: 32.01 toks/s]
Processed prompts:  81%| | 1666/2048 [00:52<00:12, 30.05it/s, est. speed input: 32750.31 toks/s, output: 31.98 toks/s]
Processed prompts:  82%| | 1682/2048 [00:52<00:12, 29.90it/s, est. speed input: 32724.63 toks/s, output: 31.96 toks/s]
Processed prompts:  83%| | 1698/2048 [00:53<00:11, 29.81it/s, est. speed input: 32700.04 toks/s, output: 31.93 toks/s]
Processed prompts:  84%| | 1714/2048 [00:53<00:11, 29.71it/s, est. speed input: 32674.58 toks/s, output: 31.91 toks/s]
Processed prompts:  84%| | 1730/2048 [00:54<00:10, 29.73it/s, est. speed input: 32652.90 toks/s, output: 31.89 toks/s]
Processed prompts:  85%| | 1746/2048 [00:54<00:10, 29.64it/s, est. speed input: 32627.99 toks/s, output: 31.86 toks/s]
Processed prompts:  86%| | 1762/2048 [00:55<00:09, 29.66it/s, est. speed input: 32606.37 toks/s, output: 31.84 toks/s]
Processed prompts:  87%| | 1778/2048 [00:55<00:09, 29.61it/s, est. speed input: 32583.11 toks/s, output: 31.82 toks/s]
Processed prompts:  88%| | 1794/2048 [00:56<00:08, 29.64it/s, est. speed input: 32562.50 toks/s, output: 31.80 toks/s]
Processed prompts:  88%| | 1810/2048 [00:56<00:08, 29.57it/s, est. speed input: 32538.98 toks/s, output: 31.78 toks/s]
Processed prompts:  89%| | 1826/2048 [00:57<00:07, 29.66it/s, est. speed input: 32520.88 toks/s, output: 31.76 toks/s]
Processed prompts:  90%| | 1842/2048 [00:58<00:06, 29.60it/s, est. speed input: 32499.00 toks/s, output: 31.74 toks/s]
Processed prompts:  91%| | 1858/2048 [00:58<00:06, 29.61it/s, est. speed input: 32478.93 toks/s, output: 31.72 toks/s]
Processed prompts:  92%|| 1874/2048 [00:59<00:05, 30.10it/s, est. speed input: 32475.47 toks/s, output: 31.71 toks/s]
Processed prompts:  92%|| 1890/2048 [00:59<00:05, 30.02it/s, est. speed input: 32458.01 toks/s, output: 31.70 toks/s]
Processed prompts:  93%|| 1906/2048 [01:00<00:04, 29.82it/s, est. speed input: 32436.28 toks/s, output: 31.68 toks/s]
Processed prompts:  94%|| 1922/2048 [01:00<00:04, 29.81it/s, est. speed input: 32419.16 toks/s, output: 31.66 toks/s]
Processed prompts:  95%|| 1938/2048 [01:01<00:03, 29.66it/s, est. speed input: 32397.96 toks/s, output: 31.64 toks/s]
Processed prompts:  95%|| 1954/2048 [01:01<00:03, 30.22it/s, est. speed input: 32397.71 toks/s, output: 31.64 toks/s]
Processed prompts:  96%|| 1970/2048 [01:02<00:02, 30.01it/s, est. speed input: 32378.97 toks/s, output: 31.62 toks/s]
Processed prompts:  97%|| 1986/2048 [01:02<00:02, 30.40it/s, est. speed input: 32376.83 toks/s, output: 31.62 toks/s]
Processed prompts:  98%|| 2002/2048 [01:03<00:01, 30.90it/s, est. speed input: 32380.82 toks/s, output: 31.62 toks/s]
Processed prompts:  99%|| 2018/2048 [01:03<00:00, 30.52it/s, est. speed input: 32363.90 toks/s, output: 31.61 toks/s]
Processed prompts:  99%|| 2034/2048 [01:04<00:00, 30.45it/s, est. speed input: 32352.79 toks/s, output: 31.59 toks/s]
Processed prompts: 100%|| 2048/2048 [01:04<00:00, 30.45it/s, est. speed input: 32575.38 toks/s, output: 31.81 toks/s]
Processed prompts: 100%|| 2048/2048 [01:04<00:00, 31.81it/s, est. speed input: 32575.38 toks/s, output: 31.81 toks/s]
[rank0]:[W126 08:19:22.710176304 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-26 08:19:24
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-FP8_M32768.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:19:39 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 08:19:40 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1067198) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1067198) WARNING 01-26 08:20:02 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 30.04 requests/s, 30788.69 total tokens/s, 30.04 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-26 08:19:39] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:19:39] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:19:39] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:19:39] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:19:39] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:19:39] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:19:39] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:19:39] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:19:39] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:19:39] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:19:39] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:19:39] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:19:39] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:19:39] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:19:43] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:19:43] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:19:43] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:19:43] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:19:43] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:19:43] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:19:43] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:19:43] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:19:43] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:19:43] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:19:43] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:19:43] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:19:43] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:19:43] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1067198) [2026-01-26 08:19:44] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1067198) [2026-01-26 08:19:44] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1067198) [2026-01-26 08:19:44] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1067198) [2026-01-26 08:19:44] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1067198) [2026-01-26 08:19:44] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1067198) [2026-01-26 08:19:44] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1067198) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1067198) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.05s/it]
(EngineCore_DP0 pid=1067198) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.05s/it]
(EngineCore_DP0 pid=1067198) 
(EngineCore_DP0 pid=1067198) [2026-01-26 08:19:53] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=1067198) [2026-01-26 08:19:54] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5308416 bytes
(EngineCore_DP0 pid=1067198) [2026-01-26 08:19:54] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=1067198) [2026-01-26 08:19:54] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3538944 bytes
(EngineCore_DP0 pid=1067198) [2026-01-26 08:19:54] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=1067198) [2026-01-26 08:19:54] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 28311552 bytes
(EngineCore_DP0 pid=1067198) [2026-01-26 08:19:54] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=1067198) [2026-01-26 08:19:54] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14024704 bytes
(EngineCore_DP0 pid=1067198) 2026-01-26 08:20:00,219 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1067198) 2026-01-26 08:20:00,443 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|         | 55/4096 [00:00<00:07, 542.95it/s]
Adding requests:   3%|         | 110/4096 [00:00<00:07, 503.67it/s]
Adding requests:   4%|         | 161/4096 [00:00<00:08, 477.04it/s]
Adding requests:   5%|         | 209/4096 [00:00<00:08, 461.59it/s]
Adding requests:   6%|         | 256/4096 [00:00<00:08, 462.96it/s]
Adding requests:   7%|         | 305/4096 [00:00<00:08, 469.46it/s]
Adding requests:   9%|         | 353/4096 [00:00<00:07, 469.68it/s]
Adding requests:  10%|         | 403/4096 [00:00<00:07, 475.86it/s]
Adding requests:  11%|         | 451/4096 [00:00<00:07, 470.66it/s]
Adding requests:  12%|        | 499/4096 [00:01<00:07, 471.80it/s]
Adding requests:  13%|        | 547/4096 [00:01<00:07, 459.99it/s]
Adding requests:  15%|        | 595/4096 [00:01<00:07, 460.67it/s]
Adding requests:  16%|        | 642/4096 [00:01<00:07, 456.41it/s]
Adding requests:  17%|        | 690/4096 [00:01<00:07, 460.46it/s]
Adding requests:  18%|        | 738/4096 [00:01<00:07, 463.49it/s]
Adding requests:  19%|        | 785/4096 [00:01<00:07, 462.97it/s]
Adding requests:  20%|        | 832/4096 [00:01<00:07, 454.55it/s]
Adding requests:  22%|       | 881/4096 [00:01<00:06, 463.49it/s]
Adding requests:  23%|       | 930/4096 [00:01<00:06, 469.64it/s]
Adding requests:  24%|       | 978/4096 [00:02<00:06, 472.46it/s]
Adding requests:  25%|       | 1026/4096 [00:02<00:06, 473.15it/s]
Adding requests:  26%|       | 1074/4096 [00:02<00:06, 469.91it/s]
Adding requests:  27%|       | 1122/4096 [00:02<00:06, 453.62it/s]
Adding requests:  29%|       | 1170/4096 [00:02<00:06, 459.43it/s]
Adding requests:  30%|       | 1219/4096 [00:02<00:06, 466.19it/s]
Adding requests:  31%|       | 1266/4096 [00:02<00:06, 463.76it/s]
Adding requests:  32%|      | 1313/4096 [00:02<00:06, 427.30it/s]
Adding requests:  33%|      | 1364/4096 [00:02<00:06, 448.29it/s]
Adding requests:  34%|      | 1411/4096 [00:03<00:05, 453.53it/s]
Adding requests:  36%|      | 1460/4096 [00:03<00:05, 463.75it/s]
Adding requests:  37%|      | 1508/4096 [00:03<00:05, 466.65it/s]
Adding requests:  38%|      | 1556/4096 [00:03<00:05, 469.16it/s]
Adding requests:  39%|      | 1604/4096 [00:03<00:05, 457.79it/s]
Adding requests:  40%|      | 1651/4096 [00:03<00:05, 459.65it/s]
Adding requests:  41%|     | 1699/4096 [00:03<00:05, 464.49it/s]
Adding requests:  43%|     | 1747/4096 [00:03<00:05, 467.62it/s]
Adding requests:  44%|     | 1794/4096 [00:03<00:05, 454.30it/s]
Adding requests:  45%|     | 1840/4096 [00:03<00:05, 443.91it/s]
Adding requests:  46%|     | 1886/4096 [00:04<00:04, 447.72it/s]
Adding requests:  47%|     | 1934/4096 [00:04<00:04, 455.31it/s]
Adding requests:  48%|     | 1982/4096 [00:04<00:04, 460.81it/s]
Adding requests:  50%|     | 2032/4096 [00:04<00:04, 470.01it/s]
Adding requests:  51%|     | 2080/4096 [00:04<00:04, 471.72it/s]
Adding requests:  52%|    | 2128/4096 [00:04<00:04, 455.14it/s]
Adding requests:  53%|    | 2176/4096 [00:04<00:04, 461.80it/s]
Adding requests:  54%|    | 2223/4096 [00:04<00:04, 463.00it/s]
Adding requests:  55%|    | 2270/4096 [00:04<00:04, 454.21it/s]
Adding requests:  57%|    | 2320/4096 [00:05<00:03, 465.30it/s]
Adding requests:  58%|    | 2367/4096 [00:05<00:03, 466.44it/s]
Adding requests:  59%|    | 2416/4096 [00:05<00:03, 471.35it/s]
Adding requests:  60%|    | 2464/4096 [00:05<00:03, 469.31it/s]
Adding requests:  61%|   | 2514/4096 [00:05<00:03, 478.24it/s]
Adding requests:  63%|   | 2562/4096 [00:05<00:03, 448.12it/s]
Adding requests:  64%|   | 2608/4096 [00:05<00:03, 441.60it/s]
Adding requests:  65%|   | 2655/4096 [00:05<00:03, 448.16it/s]
Adding requests:  66%|   | 2703/4096 [00:05<00:03, 454.79it/s]
Adding requests:  67%|   | 2752/4096 [00:05<00:02, 464.39it/s]
Adding requests:  68%|   | 2799/4096 [00:06<00:02, 458.86it/s]
Adding requests:  70%|   | 2850/4096 [00:06<00:02, 473.72it/s]
Adding requests:  71%|   | 2898/4096 [00:06<00:02, 468.26it/s]
Adding requests:  72%|  | 2945/4096 [00:06<00:02, 465.25it/s]
Adding requests:  73%|  | 2992/4096 [00:06<00:02, 461.94it/s]
Adding requests:  74%|  | 3040/4096 [00:06<00:02, 467.18it/s]
Adding requests:  75%|  | 3087/4096 [00:06<00:02, 462.00it/s]
Adding requests:  77%|  | 3134/4096 [00:06<00:02, 464.05it/s]
Adding requests:  78%|  | 3183/4096 [00:06<00:01, 471.16it/s]
Adding requests:  79%|  | 3231/4096 [00:06<00:01, 470.53it/s]
Adding requests:  80%|  | 3279/4096 [00:07<00:01, 468.97it/s]
Adding requests:  81%| | 3329/4096 [00:07<00:01, 476.26it/s]
Adding requests:  82%| | 3377/4096 [00:07<00:01, 466.52it/s]
Adding requests:  84%| | 3426/4096 [00:07<00:01, 470.56it/s]
Adding requests:  85%| | 3474/4096 [00:07<00:01, 454.10it/s]
Adding requests:  86%| | 3520/4096 [00:07<00:01, 450.55it/s]
Adding requests:  87%| | 3566/4096 [00:07<00:01, 450.81it/s]
Adding requests:  88%| | 3612/4096 [00:07<00:01, 447.69it/s]
Adding requests:  89%| | 3662/4096 [00:07<00:00, 460.12it/s]
Adding requests:  91%| | 3709/4096 [00:08<00:00, 460.92it/s]
Adding requests:  92%|| 3758/4096 [00:08<00:00, 469.12it/s]
Adding requests:  93%|| 3807/4096 [00:08<00:00, 473.69it/s]
Adding requests:  94%|| 3858/4096 [00:08<00:00, 482.84it/s]
Adding requests:  95%|| 3907/4096 [00:08<00:00, 443.21it/s]
Adding requests:  97%|| 3957/4096 [00:08<00:00, 456.72it/s]
Adding requests:  98%|| 4006/4096 [00:08<00:00, 465.04it/s]
Adding requests:  99%|| 4053/4096 [00:08<00:00, 460.74it/s]
Adding requests: 100%|| 4096/4096 [00:08<00:00, 462.70it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|         | 258/4096 [00:01<00:15, 255.19it/s, est. speed input: 261342.12 toks/s, output: 255.20 toks/s]
Processed prompts:   7%|         | 290/4096 [00:02<00:31, 119.30it/s, est. speed input: 142404.38 toks/s, output: 139.07 toks/s]
Processed prompts:   8%|         | 322/4096 [00:03<00:48, 77.91it/s, est. speed input: 104390.23 toks/s, output: 101.94 toks/s] 
Processed prompts:   9%|         | 354/4096 [00:04<01:03, 58.75it/s, est. speed input: 85634.86 toks/s, output: 83.63 toks/s]  
Processed prompts:   9%|         | 386/4096 [00:05<01:16, 48.26it/s, est. speed input: 74477.59 toks/s, output: 72.73 toks/s]
Processed prompts:  10%|         | 418/4096 [00:06<01:27, 41.86it/s, est. speed input: 67002.97 toks/s, output: 65.43 toks/s]
Processed prompts:  11%|         | 450/4096 [00:07<01:35, 38.06it/s, est. speed input: 61856.76 toks/s, output: 60.41 toks/s]
Processed prompts:  12%|        | 482/4096 [00:08<01:42, 35.36it/s, est. speed input: 57864.52 toks/s, output: 56.51 toks/s]
Processed prompts:  13%|        | 514/4096 [00:09<01:46, 33.59it/s, est. speed input: 54789.12 toks/s, output: 53.50 toks/s]
Processed prompts:  13%|        | 546/4096 [00:10<01:49, 32.36it/s, est. speed input: 52319.00 toks/s, output: 51.09 toks/s]
Processed prompts:  14%|        | 578/4096 [00:11<01:51, 31.54it/s, est. speed input: 50309.36 toks/s, output: 49.13 toks/s]
Processed prompts:  15%|        | 610/4096 [00:12<01:52, 30.99it/s, est. speed input: 48642.91 toks/s, output: 47.50 toks/s]
Processed prompts:  16%|        | 642/4096 [00:13<01:52, 30.61it/s, est. speed input: 47235.82 toks/s, output: 46.13 toks/s]
Processed prompts:  16%|        | 674/4096 [00:14<01:52, 30.34it/s, est. speed input: 46030.43 toks/s, output: 44.95 toks/s]
Processed prompts:  17%|        | 706/4096 [00:16<01:52, 30.13it/s, est. speed input: 44977.12 toks/s, output: 43.92 toks/s]
Processed prompts:  18%|        | 738/4096 [00:17<01:51, 30.03it/s, est. speed input: 44071.21 toks/s, output: 43.04 toks/s]
Processed prompts:  19%|        | 770/4096 [00:18<01:51, 29.91it/s, est. speed input: 43257.82 toks/s, output: 42.24 toks/s]
Processed prompts:  20%|        | 802/4096 [00:19<01:50, 29.82it/s, est. speed input: 42535.18 toks/s, output: 41.54 toks/s]
Processed prompts:  20%|        | 834/4096 [00:20<01:49, 29.79it/s, est. speed input: 41896.24 toks/s, output: 40.91 toks/s]
Processed prompts:  21%|        | 866/4096 [00:21<01:48, 29.75it/s, est. speed input: 41316.95 toks/s, output: 40.35 toks/s]
Processed prompts:  22%|       | 898/4096 [00:22<01:47, 29.70it/s, est. speed input: 40788.18 toks/s, output: 39.83 toks/s]
Processed prompts:  23%|       | 930/4096 [00:23<01:46, 29.83it/s, est. speed input: 40341.31 toks/s, output: 39.40 toks/s]
Processed prompts:  23%|       | 962/4096 [00:24<01:44, 30.05it/s, est. speed input: 39957.72 toks/s, output: 39.02 toks/s]
Processed prompts:  24%|       | 994/4096 [00:25<01:43, 29.90it/s, est. speed input: 39550.77 toks/s, output: 38.62 toks/s]
Processed prompts:  25%|       | 1026/4096 [00:26<01:42, 29.84it/s, est. speed input: 39182.96 toks/s, output: 38.26 toks/s]
Processed prompts:  26%|       | 1058/4096 [00:27<01:42, 29.78it/s, est. speed input: 38841.27 toks/s, output: 37.93 toks/s]
Processed prompts:  27%|       | 1090/4096 [00:28<01:41, 29.76it/s, est. speed input: 38527.90 toks/s, output: 37.62 toks/s]
Processed prompts:  27%|       | 1122/4096 [00:30<01:39, 29.77it/s, est. speed input: 38241.69 toks/s, output: 37.35 toks/s]
Processed prompts:  28%|       | 1154/4096 [00:31<01:38, 30.00it/s, est. speed input: 38007.42 toks/s, output: 37.12 toks/s]
Processed prompts:  29%|       | 1186/4096 [00:32<01:37, 29.91it/s, est. speed input: 37753.50 toks/s, output: 36.87 toks/s]
Processed prompts:  30%|       | 1218/4096 [00:33<01:36, 29.85it/s, est. speed input: 37515.35 toks/s, output: 36.64 toks/s]
Processed prompts:  31%|       | 1250/4096 [00:34<01:34, 30.03it/s, est. speed input: 37321.66 toks/s, output: 36.45 toks/s]
Processed prompts:  31%|      | 1282/4096 [00:35<01:33, 30.16it/s, est. speed input: 37140.31 toks/s, output: 36.27 toks/s]
Processed prompts:  32%|      | 1314/4096 [00:36<01:32, 30.00it/s, est. speed input: 36938.93 toks/s, output: 36.07 toks/s]
Processed prompts:  33%|      | 1346/4096 [00:37<01:31, 29.90it/s, est. speed input: 36750.10 toks/s, output: 35.89 toks/s]
Processed prompts:  34%|      | 1378/4096 [00:38<01:31, 29.84it/s, est. speed input: 36573.05 toks/s, output: 35.72 toks/s]
Processed prompts:  34%|      | 1410/4096 [00:39<01:30, 29.80it/s, est. speed input: 36405.62 toks/s, output: 35.55 toks/s]
Processed prompts:  35%|      | 1442/4096 [00:40<01:29, 29.77it/s, est. speed input: 36247.40 toks/s, output: 35.40 toks/s]
Processed prompts:  36%|      | 1474/4096 [00:41<01:28, 29.75it/s, est. speed input: 36097.23 toks/s, output: 35.25 toks/s]
Processed prompts:  37%|      | 1506/4096 [00:42<01:27, 29.71it/s, est. speed input: 35951.53 toks/s, output: 35.11 toks/s]
Processed prompts:  38%|      | 1538/4096 [00:43<01:26, 29.67it/s, est. speed input: 35812.37 toks/s, output: 34.97 toks/s]
Processed prompts:  38%|      | 1570/4096 [00:45<01:24, 29.90it/s, est. speed input: 35704.57 toks/s, output: 34.87 toks/s]
Processed prompts:  39%|      | 1602/4096 [00:46<01:23, 29.82it/s, est. speed input: 35579.15 toks/s, output: 34.75 toks/s]
Processed prompts:  40%|      | 1634/4096 [00:47<01:22, 29.97it/s, est. speed input: 35478.11 toks/s, output: 34.65 toks/s]
Processed prompts:  41%|      | 1666/4096 [00:48<01:21, 29.88it/s, est. speed input: 35363.66 toks/s, output: 34.53 toks/s]
Processed prompts:  41%|     | 1698/4096 [00:49<01:20, 29.78it/s, est. speed input: 35251.59 toks/s, output: 34.43 toks/s]
Processed prompts:  42%|     | 1730/4096 [00:50<01:19, 29.74it/s, est. speed input: 35146.88 toks/s, output: 34.32 toks/s]
Processed prompts:  43%|     | 1762/4096 [00:51<01:18, 29.70it/s, est. speed input: 35045.14 toks/s, output: 34.22 toks/s]
Processed prompts:  44%|     | 1794/4096 [00:52<01:17, 29.68it/s, est. speed input: 34948.53 toks/s, output: 34.13 toks/s]
Processed prompts:  45%|     | 1826/4096 [00:53<01:16, 29.66it/s, est. speed input: 34855.81 toks/s, output: 34.04 toks/s]
Processed prompts:  45%|     | 1858/4096 [00:54<01:14, 29.93it/s, est. speed input: 34787.89 toks/s, output: 33.97 toks/s]
Processed prompts:  46%|     | 1890/4096 [00:55<01:14, 29.80it/s, est. speed input: 34698.87 toks/s, output: 33.89 toks/s]
Processed prompts:  47%|     | 1922/4096 [00:56<01:13, 29.75it/s, est. speed input: 34616.50 toks/s, output: 33.81 toks/s]
Processed prompts:  48%|     | 1954/4096 [00:57<01:11, 29.92it/s, est. speed input: 34551.53 toks/s, output: 33.74 toks/s]
Processed prompts:  48%|     | 1986/4096 [00:58<01:09, 30.52it/s, est. speed input: 34521.56 toks/s, output: 33.71 toks/s]
Processed prompts:  49%|     | 2018/4096 [00:59<01:08, 30.26it/s, est. speed input: 34447.33 toks/s, output: 33.64 toks/s]
Processed prompts:  50%|     | 2050/4096 [01:01<01:07, 30.49it/s, est. speed input: 34402.12 toks/s, output: 33.60 toks/s]
Processed prompts:  51%|     | 2082/4096 [01:02<01:06, 30.48it/s, est. speed input: 34347.61 toks/s, output: 33.54 toks/s]
Processed prompts:  52%|    | 2114/4096 [01:03<01:05, 30.22it/s, est. speed input: 34279.20 toks/s, output: 33.48 toks/s]
Processed prompts:  52%|    | 2146/4096 [01:04<01:04, 30.05it/s, est. speed input: 34213.70 toks/s, output: 33.41 toks/s]
Processed prompts:  53%|    | 2178/4096 [01:05<01:02, 30.46it/s, est. speed input: 34182.61 toks/s, output: 33.38 toks/s]
Processed prompts:  54%|    | 2210/4096 [01:06<01:01, 30.76it/s, est. speed input: 34152.92 toks/s, output: 33.35 toks/s]
Processed prompts:  55%|    | 2242/4096 [01:07<01:00, 30.41it/s, est. speed input: 34091.59 toks/s, output: 33.29 toks/s]
Processed prompts:  56%|    | 2274/4096 [01:08<00:59, 30.41it/s, est. speed input: 34046.12 toks/s, output: 33.25 toks/s]
Processed prompts:  56%|    | 2306/4096 [01:09<00:58, 30.42it/s, est. speed input: 34002.51 toks/s, output: 33.21 toks/s]
Processed prompts:  57%|    | 2338/4096 [01:10<00:57, 30.42it/s, est. speed input: 33960.04 toks/s, output: 33.16 toks/s]
Processed prompts:  58%|    | 2370/4096 [01:11<00:55, 31.00it/s, est. speed input: 33949.68 toks/s, output: 33.15 toks/s]
Processed prompts:  59%|    | 2402/4096 [01:12<00:54, 30.82it/s, est. speed input: 33909.15 toks/s, output: 33.11 toks/s]
Processed prompts:  59%|    | 2434/4096 [01:13<00:54, 30.72it/s, est. speed input: 33870.75 toks/s, output: 33.08 toks/s]
Processed prompts:  60%|    | 2466/4096 [01:14<00:53, 30.64it/s, est. speed input: 33832.97 toks/s, output: 33.04 toks/s]
Processed prompts:  61%|    | 2498/4096 [01:15<00:52, 30.58it/s, est. speed input: 33795.97 toks/s, output: 33.00 toks/s]
Processed prompts:  62%|   | 2530/4096 [01:16<00:51, 30.27it/s, est. speed input: 33746.38 toks/s, output: 32.96 toks/s]
Processed prompts:  63%|   | 2562/4096 [01:17<00:50, 30.31it/s, est. speed input: 33710.86 toks/s, output: 32.92 toks/s]
Processed prompts:  63%|   | 2594/4096 [01:18<00:49, 30.38it/s, est. speed input: 33678.70 toks/s, output: 32.89 toks/s]
Processed prompts:  64%|   | 2626/4096 [01:19<00:48, 30.16it/s, est. speed input: 33633.82 toks/s, output: 32.85 toks/s]
Processed prompts:  65%|   | 2658/4096 [01:21<00:47, 29.98it/s, est. speed input: 33589.01 toks/s, output: 32.80 toks/s]
Processed prompts:  66%|   | 2690/4096 [01:22<00:46, 30.36it/s, est. speed input: 33569.84 toks/s, output: 32.78 toks/s]
Processed prompts:  66%|   | 2722/4096 [01:23<00:45, 30.10it/s, est. speed input: 33526.16 toks/s, output: 32.74 toks/s]
Processed prompts:  67%|   | 2754/4096 [01:24<00:44, 30.23it/s, est. speed input: 33498.01 toks/s, output: 32.71 toks/s]
Processed prompts:  68%|   | 2786/4096 [01:25<00:43, 30.02it/s, est. speed input: 33456.89 toks/s, output: 32.67 toks/s]
Processed prompts:  69%|   | 2818/4096 [01:26<00:42, 30.42it/s, est. speed input: 33441.37 toks/s, output: 32.66 toks/s]
Processed prompts:  70%|   | 2850/4096 [01:27<00:40, 30.42it/s, est. speed input: 33413.82 toks/s, output: 32.63 toks/s]
Processed prompts:  70%|   | 2882/4096 [01:28<00:40, 30.13it/s, est. speed input: 33374.26 toks/s, output: 32.59 toks/s]
Processed prompts:  71%|   | 2914/4096 [01:29<00:39, 29.95it/s, est. speed input: 33336.36 toks/s, output: 32.56 toks/s]
Processed prompts:  72%|  | 2946/4096 [01:30<00:38, 30.10it/s, est. speed input: 33311.48 toks/s, output: 32.53 toks/s]
Processed prompts:  73%|  | 2978/4096 [01:31<00:37, 29.91it/s, est. speed input: 33274.52 toks/s, output: 32.49 toks/s]
Processed prompts:  73%|  | 3010/4096 [01:32<00:35, 30.33it/s, est. speed input: 33261.72 toks/s, output: 32.48 toks/s]
Processed prompts:  74%|  | 3042/4096 [01:33<00:34, 30.36it/s, est. speed input: 33237.87 toks/s, output: 32.46 toks/s]
Processed prompts:  75%|  | 3074/4096 [01:34<00:33, 30.13it/s, est. speed input: 33204.80 toks/s, output: 32.43 toks/s]
Processed prompts:  76%|  | 3106/4096 [01:35<00:32, 30.78it/s, est. speed input: 33204.74 toks/s, output: 32.43 toks/s]
Processed prompts:  77%|  | 3138/4096 [01:36<00:30, 31.03it/s, est. speed input: 33196.15 toks/s, output: 32.42 toks/s]
Processed prompts:  77%|  | 3170/4096 [01:37<00:30, 30.60it/s, est. speed input: 33164.94 toks/s, output: 32.39 toks/s]
Processed prompts:  78%|  | 3202/4096 [01:38<00:28, 30.85it/s, est. speed input: 33154.82 toks/s, output: 32.38 toks/s]
Processed prompts:  79%|  | 3234/4096 [01:39<00:28, 30.73it/s, est. speed input: 33134.12 toks/s, output: 32.36 toks/s]
Processed prompts:  80%|  | 3266/4096 [01:41<00:27, 30.39it/s, est. speed input: 33104.36 toks/s, output: 32.33 toks/s]
Processed prompts:  81%|  | 3298/4096 [01:42<00:26, 30.44it/s, est. speed input: 33085.53 toks/s, output: 32.31 toks/s]
Processed prompts:  81%| | 3330/4096 [01:43<00:24, 30.77it/s, est. speed input: 33078.11 toks/s, output: 32.30 toks/s]
Processed prompts:  82%| | 3362/4096 [01:44<00:24, 30.41it/s, est. speed input: 33049.38 toks/s, output: 32.27 toks/s]
Processed prompts:  83%| | 3394/4096 [01:45<00:23, 30.15it/s, est. speed input: 33020.87 toks/s, output: 32.25 toks/s]
Processed prompts:  84%| | 3426/4096 [01:46<00:22, 30.23it/s, est. speed input: 33002.26 toks/s, output: 32.23 toks/s]
Processed prompts:  84%| | 3458/4096 [01:47<00:21, 30.27it/s, est. speed input: 32983.50 toks/s, output: 32.21 toks/s]
Processed prompts:  85%| | 3490/4096 [01:48<00:19, 30.67it/s, est. speed input: 32978.05 toks/s, output: 32.21 toks/s]
Processed prompts:  86%| | 3522/4096 [01:49<00:18, 30.35it/s, est. speed input: 32951.94 toks/s, output: 32.18 toks/s]
Processed prompts:  87%| | 3554/4096 [01:50<00:17, 30.14it/s, est. speed input: 32926.99 toks/s, output: 32.16 toks/s]
Processed prompts:  88%| | 3586/4096 [01:51<00:17, 29.96it/s, est. speed input: 32901.00 toks/s, output: 32.13 toks/s]
Processed prompts:  88%| | 3618/4096 [01:52<00:16, 29.86it/s, est. speed input: 32876.63 toks/s, output: 32.11 toks/s]
Processed prompts:  89%| | 3650/4096 [01:53<00:14, 30.02it/s, est. speed input: 32860.24 toks/s, output: 32.09 toks/s]
Processed prompts:  90%| | 3682/4096 [01:54<00:13, 30.13it/s, est. speed input: 32844.41 toks/s, output: 32.07 toks/s]
Processed prompts:  91%| | 3714/4096 [01:55<00:12, 30.23it/s, est. speed input: 32829.52 toks/s, output: 32.06 toks/s]
Processed prompts:  91%|| 3746/4096 [01:56<00:11, 30.05it/s, est. speed input: 32806.69 toks/s, output: 32.04 toks/s]
Processed prompts:  92%|| 3778/4096 [01:58<00:10, 29.94it/s, est. speed input: 32784.58 toks/s, output: 32.02 toks/s]
Processed prompts:  93%|| 3810/4096 [01:59<00:09, 30.06it/s, est. speed input: 32769.29 toks/s, output: 32.00 toks/s]
Processed prompts:  94%|| 3842/4096 [02:00<00:08, 30.40it/s, est. speed input: 32762.65 toks/s, output: 31.99 toks/s]
Processed prompts:  95%|| 3874/4096 [02:01<00:07, 30.15it/s, est. speed input: 32740.57 toks/s, output: 31.97 toks/s]
Processed prompts:  95%|| 3906/4096 [02:02<00:06, 30.02it/s, est. speed input: 32720.16 toks/s, output: 31.95 toks/s]
Processed prompts:  96%|| 3938/4096 [02:03<00:05, 30.13it/s, est. speed input: 32706.40 toks/s, output: 31.94 toks/s]
Processed prompts:  97%|| 3970/4096 [02:04<00:04, 29.96it/s, est. speed input: 32685.44 toks/s, output: 31.92 toks/s]
Processed prompts:  98%|| 4002/4096 [02:05<00:03, 29.85it/s, est. speed input: 32664.91 toks/s, output: 31.90 toks/s]
Processed prompts:  98%|| 4034/4096 [02:06<00:02, 30.60it/s, est. speed input: 32669.73 toks/s, output: 31.90 toks/s]
Processed prompts:  99%|| 4066/4096 [02:07<00:00, 30.44it/s, est. speed input: 32653.94 toks/s, output: 31.89 toks/s]
Processed prompts: 100%|| 4096/4096 [02:07<00:00, 30.44it/s, est. speed input: 32894.75 toks/s, output: 32.12 toks/s]
Processed prompts: 100%|| 4096/4096 [02:07<00:00, 32.12it/s, est. speed input: 32894.75 toks/s, output: 32.12 toks/s]
[rank0]:[W126 08:22:18.069092350 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-26 08:22:21
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-1B-FP8_M65536.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:22:47 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 08:22:47 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1069977) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1069977) WARNING 01-26 08:23:12 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 30.15 requests/s, 30907.73 total tokens/s, 30.15 output tokens/s
Total num prompt tokens:  8388608
Total num output tokens:  8192

STDERR:
[2026-01-26 08:22:47] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:22:47] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:22:47] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:22:47] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:22:47] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:22:47] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:22:47] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:22:47] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:22:47] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:22:47] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:22:47] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:22:47] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:22:47] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:22:47] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:22:51] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:22:51] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:22:51] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:22:51] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:22:51] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:22:51] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:22:51] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:22:51] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:22:51] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:22:51] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:22:51] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:22:51] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:22:51] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:22:51] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1069977) [2026-01-26 08:22:52] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1069977) [2026-01-26 08:22:52] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1069977) [2026-01-26 08:22:52] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1069977) [2026-01-26 08:22:52] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1069977) [2026-01-26 08:22:52] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1069977) [2026-01-26 08:22:52] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1069977) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1069977) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.25s/it]
(EngineCore_DP0 pid=1069977) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:09<00:00,  9.25s/it]
(EngineCore_DP0 pid=1069977) 
(EngineCore_DP0 pid=1069977) [2026-01-26 08:23:02] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=1069977) [2026-01-26 08:23:02] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5308416 bytes
(EngineCore_DP0 pid=1069977) [2026-01-26 08:23:02] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=1069977) [2026-01-26 08:23:02] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3538944 bytes
(EngineCore_DP0 pid=1069977) [2026-01-26 08:23:02] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=1069977) [2026-01-26 08:23:02] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 28311552 bytes
(EngineCore_DP0 pid=1069977) [2026-01-26 08:23:02] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=1069977) [2026-01-26 08:23:02] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14024704 bytes
(EngineCore_DP0 pid=1069977) 2026-01-26 08:23:09,320 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1069977) 2026-01-26 08:23:09,575 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/8192 [00:00<?, ?it/s]
Adding requests:   1%|          | 55/8192 [00:00<00:14, 544.78it/s]
Adding requests:   1%|         | 110/8192 [00:00<00:18, 447.18it/s]
Adding requests:   2%|         | 168/8192 [00:00<00:16, 497.28it/s]
Adding requests:   3%|         | 228/8192 [00:00<00:14, 532.76it/s]
Adding requests:   3%|         | 283/8192 [00:00<00:15, 522.23it/s]
Adding requests:   4%|         | 336/8192 [00:00<00:16, 481.03it/s]
Adding requests:   5%|         | 386/8192 [00:00<00:16, 485.05it/s]
Adding requests:   5%|         | 436/8192 [00:00<00:16, 478.43it/s]
Adding requests:   6%|         | 485/8192 [00:00<00:16, 475.57it/s]
Adding requests:   7%|         | 533/8192 [00:01<00:17, 449.97it/s]
Adding requests:   7%|         | 580/8192 [00:01<00:16, 451.76it/s]
Adding requests:   8%|         | 628/8192 [00:01<00:16, 457.90it/s]
Adding requests:   8%|         | 675/8192 [00:01<00:16, 456.77it/s]
Adding requests:   9%|         | 721/8192 [00:01<00:16, 451.74it/s]
Adding requests:   9%|         | 769/8192 [00:01<00:16, 458.73it/s]
Adding requests:  10%|         | 815/8192 [00:01<00:16, 449.30it/s]
Adding requests:  11%|         | 868/8192 [00:01<00:15, 471.18it/s]
Adding requests:  11%|         | 916/8192 [00:01<00:15, 454.90it/s]
Adding requests:  12%|        | 971/8192 [00:02<00:15, 480.29it/s]
Adding requests:  13%|        | 1030/8192 [00:02<00:13, 511.75it/s]
Adding requests:  13%|        | 1082/8192 [00:02<00:15, 459.00it/s]
Adding requests:  14%|        | 1133/8192 [00:02<00:14, 472.67it/s]
Adding requests:  14%|        | 1182/8192 [00:02<00:14, 467.43it/s]
Adding requests:  15%|        | 1230/8192 [00:02<00:15, 444.55it/s]
Adding requests:  16%|        | 1276/8192 [00:02<00:15, 448.64it/s]
Adding requests:  16%|        | 1322/8192 [00:02<00:15, 440.11it/s]
Adding requests:  17%|        | 1370/8192 [00:02<00:15, 448.96it/s]
Adding requests:  17%|        | 1416/8192 [00:03<00:15, 445.98it/s]
Adding requests:  18%|        | 1469/8192 [00:03<00:14, 469.35it/s]
Adding requests:  19%|        | 1517/8192 [00:03<00:14, 468.11it/s]
Adding requests:  19%|        | 1581/8192 [00:03<00:12, 517.60it/s]
Adding requests:  20%|        | 1651/8192 [00:03<00:11, 569.33it/s]
Adding requests:  21%|        | 1709/8192 [00:03<00:12, 526.30it/s]
Adding requests:  22%|       | 1763/8192 [00:03<00:12, 512.51it/s]
Adding requests:  22%|       | 1815/8192 [00:03<00:13, 486.50it/s]
Adding requests:  23%|       | 1865/8192 [00:03<00:13, 464.61it/s]
Adding requests:  23%|       | 1912/8192 [00:04<00:13, 463.57it/s]
Adding requests:  24%|       | 1959/8192 [00:04<00:14, 430.51it/s]
Adding requests:  24%|       | 2007/8192 [00:04<00:14, 440.79it/s]
Adding requests:  25%|       | 2056/8192 [00:04<00:13, 453.18it/s]
Adding requests:  26%|       | 2102/8192 [00:04<00:13, 453.39it/s]
Adding requests:  26%|       | 2148/8192 [00:04<00:13, 454.55it/s]
Adding requests:  27%|       | 2194/8192 [00:04<00:13, 444.70it/s]
Adding requests:  27%|       | 2243/8192 [00:04<00:13, 457.46it/s]
Adding requests:  28%|       | 2289/8192 [00:04<00:12, 454.29it/s]
Adding requests:  29%|       | 2335/8192 [00:04<00:12, 455.30it/s]
Adding requests:  29%|       | 2383/8192 [00:05<00:12, 461.42it/s]
Adding requests:  30%|       | 2431/8192 [00:05<00:12, 464.95it/s]
Adding requests:  30%|       | 2478/8192 [00:05<00:12, 464.63it/s]
Adding requests:  31%|       | 2527/8192 [00:05<00:12, 470.10it/s]
Adding requests:  31%|      | 2575/8192 [00:05<00:12, 458.32it/s]
Adding requests:  32%|      | 2622/8192 [00:05<00:12, 459.41it/s]
Adding requests:  33%|      | 2670/8192 [00:05<00:11, 465.18it/s]
Adding requests:  33%|      | 2717/8192 [00:05<00:11, 457.76it/s]
Adding requests:  34%|      | 2764/8192 [00:05<00:11, 459.37it/s]
Adding requests:  34%|      | 2810/8192 [00:06<00:11, 450.46it/s]
Adding requests:  35%|      | 2859/8192 [00:06<00:11, 461.01it/s]
Adding requests:  35%|      | 2906/8192 [00:06<00:11, 449.51it/s]
Adding requests:  36%|      | 2952/8192 [00:06<00:11, 445.34it/s]
Adding requests:  37%|      | 2997/8192 [00:06<00:11, 442.41it/s]
Adding requests:  37%|      | 3047/8192 [00:06<00:11, 455.17it/s]
Adding requests:  38%|      | 3095/8192 [00:06<00:11, 461.62it/s]
Adding requests:  38%|      | 3142/8192 [00:06<00:11, 451.44it/s]
Adding requests:  39%|      | 3188/8192 [00:06<00:11, 440.80it/s]
Adding requests:  39%|      | 3233/8192 [00:06<00:11, 431.99it/s]
Adding requests:  40%|      | 3281/8192 [00:07<00:11, 444.74it/s]
Adding requests:  41%|      | 3326/8192 [00:07<00:12, 401.49it/s]
Adding requests:  41%|      | 3371/8192 [00:07<00:11, 414.35it/s]
Adding requests:  42%|     | 3417/8192 [00:07<00:11, 425.86it/s]
Adding requests:  42%|     | 3461/8192 [00:07<00:11, 420.85it/s]
Adding requests:  43%|     | 3504/8192 [00:07<00:11, 420.41it/s]
Adding requests:  43%|     | 3553/8192 [00:07<00:10, 439.06it/s]
Adding requests:  44%|     | 3598/8192 [00:07<00:10, 436.19it/s]
Adding requests:  44%|     | 3642/8192 [00:07<00:10, 432.19it/s]
Adding requests:  45%|     | 3687/8192 [00:08<00:10, 436.52it/s]
Adding requests:  46%|     | 3731/8192 [00:08<00:10, 427.97it/s]
Adding requests:  46%|     | 3776/8192 [00:08<00:10, 433.83it/s]
Adding requests:  47%|     | 3820/8192 [00:08<00:10, 431.92it/s]
Adding requests:  47%|     | 3867/8192 [00:08<00:09, 440.67it/s]
Adding requests:  48%|     | 3917/8192 [00:08<00:09, 456.48it/s]
Adding requests:  48%|     | 3966/8192 [00:08<00:09, 465.64it/s]
Adding requests:  49%|     | 4013/8192 [00:08<00:08, 466.47it/s]
Adding requests:  50%|     | 4060/8192 [00:08<00:08, 460.18it/s]
Adding requests:  50%|     | 4109/8192 [00:08<00:08, 466.63it/s]
Adding requests:  51%|     | 4158/8192 [00:09<00:08, 472.62it/s]
Adding requests:  51%|    | 4207/8192 [00:09<00:08, 477.10it/s]
Adding requests:  52%|    | 4255/8192 [00:09<00:08, 470.57it/s]
Adding requests:  53%|    | 4303/8192 [00:09<00:08, 465.27it/s]
Adding requests:  53%|    | 4352/8192 [00:09<00:08, 472.06it/s]
Adding requests:  54%|    | 4400/8192 [00:09<00:08, 471.24it/s]
Adding requests:  54%|    | 4448/8192 [00:09<00:07, 473.28it/s]
Adding requests:  55%|    | 4496/8192 [00:09<00:07, 467.16it/s]
Adding requests:  55%|    | 4546/8192 [00:09<00:07, 474.51it/s]
Adding requests:  56%|    | 4594/8192 [00:09<00:07, 469.73it/s]
Adding requests:  57%|    | 4643/8192 [00:10<00:07, 475.45it/s]
Adding requests:  57%|    | 4691/8192 [00:10<00:07, 450.09it/s]
Adding requests:  58%|    | 4737/8192 [00:10<00:07, 433.48it/s]
Adding requests:  58%|    | 4784/8192 [00:10<00:07, 441.29it/s]
Adding requests:  59%|    | 4829/8192 [00:10<00:07, 443.02it/s]
Adding requests:  60%|    | 4877/8192 [00:10<00:07, 452.16it/s]
Adding requests:  60%|    | 4923/8192 [00:10<00:07, 449.44it/s]
Adding requests:  61%|    | 4973/8192 [00:10<00:06, 463.03it/s]
Adding requests:  61%|   | 5022/8192 [00:10<00:06, 470.23it/s]
Adding requests:  62%|   | 5070/8192 [00:11<00:06, 469.80it/s]
Adding requests:  63%|   | 5121/8192 [00:11<00:06, 480.08it/s]
Adding requests:  63%|   | 5170/8192 [00:11<00:06, 478.45it/s]
Adding requests:  64%|   | 5221/8192 [00:11<00:06, 486.40it/s]
Adding requests:  64%|   | 5270/8192 [00:11<00:06, 474.75it/s]
Adding requests:  65%|   | 5319/8192 [00:11<00:06, 478.22it/s]
Adding requests:  66%|   | 5367/8192 [00:11<00:05, 471.36it/s]
Adding requests:  66%|   | 5419/8192 [00:11<00:05, 483.42it/s]
Adding requests:  67%|   | 5468/8192 [00:11<00:05, 479.40it/s]
Adding requests:  67%|   | 5516/8192 [00:11<00:05, 463.33it/s]
Adding requests:  68%|   | 5563/8192 [00:12<00:05, 463.97it/s]
Adding requests:  68%|   | 5611/8192 [00:12<00:05, 465.57it/s]
Adding requests:  69%|   | 5661/8192 [00:12<00:05, 473.69it/s]
Adding requests:  70%|   | 5710/8192 [00:12<00:05, 477.03it/s]
Adding requests:  70%|   | 5758/8192 [00:12<00:05, 464.82it/s]
Adding requests:  71%|   | 5806/8192 [00:12<00:05, 467.11it/s]
Adding requests:  71%|  | 5855/8192 [00:12<00:04, 472.60it/s]
Adding requests:  72%|  | 5903/8192 [00:12<00:04, 466.47it/s]
Adding requests:  73%|  | 5950/8192 [00:12<00:04, 453.38it/s]
Adding requests:  73%|  | 5996/8192 [00:12<00:04, 446.35it/s]
Adding requests:  74%|  | 6045/8192 [00:13<00:04, 457.79it/s]
Adding requests:  74%|  | 6091/8192 [00:13<00:05, 418.36it/s]
Adding requests:  75%|  | 6143/8192 [00:13<00:04, 443.43it/s]
Adding requests:  76%|  | 6190/8192 [00:13<00:04, 449.47it/s]
Adding requests:  76%|  | 6241/8192 [00:13<00:04, 462.79it/s]
Adding requests:  77%|  | 6288/8192 [00:13<00:04, 456.10it/s]
Adding requests:  77%|  | 6336/8192 [00:13<00:04, 462.53it/s]
Adding requests:  78%|  | 6385/8192 [00:13<00:03, 469.65it/s]
Adding requests:  79%|  | 6433/8192 [00:13<00:03, 470.94it/s]
Adding requests:  79%|  | 6483/8192 [00:14<00:03, 478.01it/s]
Adding requests:  80%|  | 6535/8192 [00:14<00:03, 488.80it/s]
Adding requests:  80%|  | 6584/8192 [00:14<00:03, 487.07it/s]
Adding requests:  81%|  | 6633/8192 [00:14<00:03, 485.06it/s]
Adding requests:  82%| | 6682/8192 [00:14<00:03, 483.07it/s]
Adding requests:  82%| | 6731/8192 [00:14<00:03, 463.27it/s]
Adding requests:  83%| | 6780/8192 [00:14<00:03, 468.57it/s]
Adding requests:  83%| | 6829/8192 [00:14<00:02, 473.51it/s]
Adding requests:  84%| | 6878/8192 [00:14<00:02, 477.64it/s]
Adding requests:  85%| | 6928/8192 [00:14<00:02, 483.73it/s]
Adding requests:  85%| | 6978/8192 [00:15<00:02, 487.40it/s]
Adding requests:  86%| | 7027/8192 [00:15<00:02, 480.21it/s]
Adding requests:  86%| | 7076/8192 [00:15<00:02, 478.72it/s]
Adding requests:  87%| | 7126/8192 [00:15<00:02, 482.77it/s]
Adding requests:  88%| | 7178/8192 [00:15<00:02, 492.40it/s]
Adding requests:  88%| | 7228/8192 [00:15<00:01, 487.52it/s]
Adding requests:  89%| | 7278/8192 [00:15<00:01, 487.21it/s]
Adding requests:  89%| | 7327/8192 [00:15<00:01, 482.22it/s]
Adding requests:  90%| | 7376/8192 [00:15<00:01, 482.97it/s]
Adding requests:  91%| | 7425/8192 [00:16<00:01, 454.36it/s]
Adding requests:  91%| | 7474/8192 [00:16<00:01, 464.26it/s]
Adding requests:  92%|| 7526/8192 [00:16<00:01, 478.60it/s]
Adding requests:  92%|| 7575/8192 [00:16<00:01, 475.19it/s]
Adding requests:  93%|| 7624/8192 [00:16<00:01, 477.75it/s]
Adding requests:  94%|| 7674/8192 [00:16<00:01, 482.11it/s]
Adding requests:  94%|| 7723/8192 [00:16<00:00, 472.89it/s]
Adding requests:  95%|| 7771/8192 [00:16<00:00, 472.34it/s]
Adding requests:  95%|| 7819/8192 [00:16<00:00, 471.55it/s]
Adding requests:  96%|| 7868/8192 [00:16<00:00, 474.77it/s]
Adding requests:  97%|| 7917/8192 [00:17<00:00, 474.99it/s]
Adding requests:  97%|| 7967/8192 [00:17<00:00, 479.44it/s]
Adding requests:  98%|| 8015/8192 [00:17<00:00, 469.92it/s]
Adding requests:  98%|| 8063/8192 [00:17<00:00, 471.74it/s]
Adding requests:  99%|| 8111/8192 [00:17<00:00, 468.70it/s]
Adding requests: 100%|| 8162/8192 [00:17<00:00, 480.45it/s]
Adding requests: 100%|| 8192/8192 [00:17<00:00, 464.75it/s]

Processed prompts:   0%|          | 0/8192 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|         | 450/8192 [00:01<00:20, 379.09it/s, est. speed input: 388198.37 toks/s, output: 379.10 toks/s]
Processed prompts:   6%|         | 514/8192 [00:03<01:00, 127.57it/s, est. speed input: 158206.97 toks/s, output: 154.50 toks/s]
Processed prompts:   7%|         | 578/8192 [00:05<01:37, 78.06it/s, est. speed input: 108285.32 toks/s, output: 105.75 toks/s] 
Processed prompts:   8%|         | 642/8192 [00:07<02:10, 57.81it/s, est. speed input: 86422.19 toks/s, output: 84.40 toks/s]  
Processed prompts:   9%|         | 706/8192 [00:09<02:38, 47.30it/s, est. speed input: 74125.82 toks/s, output: 72.39 toks/s]
Processed prompts:   9%|         | 770/8192 [00:11<02:59, 41.30it/s, est. speed input: 66349.68 toks/s, output: 64.79 toks/s]
Processed prompts:  10%|         | 834/8192 [00:14<03:16, 37.46it/s, est. speed input: 60864.04 toks/s, output: 59.44 toks/s]
Processed prompts:  11%|         | 898/8192 [00:16<03:27, 35.14it/s, est. speed input: 56935.07 toks/s, output: 55.60 toks/s]
Processed prompts:  12%|        | 962/8192 [00:18<03:35, 33.61it/s, est. speed input: 53928.68 toks/s, output: 52.66 toks/s]
Processed prompts:  13%|        | 1026/8192 [00:20<03:40, 32.45it/s, est. speed input: 51484.05 toks/s, output: 50.28 toks/s]
Processed prompts:  13%|        | 1090/8192 [00:22<03:44, 31.67it/s, est. speed input: 49504.82 toks/s, output: 48.34 toks/s]
Processed prompts:  14%|        | 1154/8192 [00:24<03:45, 31.20it/s, est. speed input: 47898.29 toks/s, output: 46.78 toks/s]
Processed prompts:  15%|        | 1218/8192 [00:26<03:45, 30.90it/s, est. speed input: 46558.35 toks/s, output: 45.47 toks/s]
Processed prompts:  16%|        | 1282/8192 [00:28<03:45, 30.69it/s, est. speed input: 45413.15 toks/s, output: 44.35 toks/s]
Processed prompts:  16%|        | 1346/8192 [00:31<03:44, 30.45it/s, est. speed input: 44391.88 toks/s, output: 43.35 toks/s]
Processed prompts:  17%|        | 1410/8192 [00:33<03:44, 30.28it/s, est. speed input: 43501.11 toks/s, output: 42.48 toks/s]
Processed prompts:  18%|        | 1474/8192 [00:35<03:42, 30.17it/s, est. speed input: 42723.19 toks/s, output: 41.72 toks/s]
Processed prompts:  19%|        | 1538/8192 [00:37<03:40, 30.16it/s, est. speed input: 42051.13 toks/s, output: 41.07 toks/s]
Processed prompts:  20%|        | 1602/8192 [00:39<03:38, 30.18it/s, est. speed input: 41456.50 toks/s, output: 40.48 toks/s]
Processed prompts:  20%|        | 1666/8192 [00:41<03:36, 30.11it/s, est. speed input: 40904.58 toks/s, output: 39.95 toks/s]
Processed prompts:  21%|        | 1730/8192 [00:43<03:34, 30.06it/s, est. speed input: 40405.26 toks/s, output: 39.46 toks/s]
Processed prompts:  22%|       | 1794/8192 [00:45<03:33, 30.01it/s, est. speed input: 39949.87 toks/s, output: 39.01 toks/s]
Processed prompts:  23%|       | 1858/8192 [00:48<03:30, 30.08it/s, est. speed input: 39555.13 toks/s, output: 38.63 toks/s]
Processed prompts:  23%|       | 1922/8192 [00:50<03:28, 30.13it/s, est. speed input: 39192.66 toks/s, output: 38.27 toks/s]
Processed prompts:  24%|       | 1986/8192 [00:52<03:24, 30.39it/s, est. speed input: 38899.44 toks/s, output: 37.99 toks/s]
Processed prompts:  25%|       | 2050/8192 [00:54<03:20, 30.62it/s, est. speed input: 38635.37 toks/s, output: 37.73 toks/s]
Processed prompts:  26%|       | 2114/8192 [00:56<03:20, 30.38it/s, est. speed input: 38329.07 toks/s, output: 37.43 toks/s]
Processed prompts:  27%|       | 2178/8192 [00:58<03:15, 30.74it/s, est. speed input: 38122.03 toks/s, output: 37.23 toks/s]
Processed prompts:  27%|       | 2242/8192 [01:00<03:14, 30.56it/s, est. speed input: 37868.80 toks/s, output: 36.98 toks/s]
Processed prompts:  28%|       | 2306/8192 [01:02<03:12, 30.55it/s, est. speed input: 37648.04 toks/s, output: 36.77 toks/s]
Processed prompts:  29%|       | 2370/8192 [01:04<03:08, 30.88it/s, est. speed input: 37485.78 toks/s, output: 36.61 toks/s]
Processed prompts:  30%|       | 2434/8192 [01:06<03:06, 30.79it/s, est. speed input: 37292.83 toks/s, output: 36.42 toks/s]
Processed prompts:  30%|       | 2498/8192 [01:08<03:05, 30.62it/s, est. speed input: 37097.79 toks/s, output: 36.23 toks/s]
Processed prompts:  31%|      | 2562/8192 [01:11<03:03, 30.62it/s, est. speed input: 36928.55 toks/s, output: 36.06 toks/s]
Processed prompts:  32%|      | 2626/8192 [01:13<03:03, 30.38it/s, est. speed input: 36741.75 toks/s, output: 35.88 toks/s]
Processed prompts:  33%|      | 2690/8192 [01:15<03:00, 30.48it/s, est. speed input: 36595.17 toks/s, output: 35.74 toks/s]
Processed prompts:  34%|      | 2754/8192 [01:17<02:59, 30.38it/s, est. speed input: 36438.06 toks/s, output: 35.58 toks/s]
Processed prompts:  34%|      | 2818/8192 [01:19<02:55, 30.61it/s, est. speed input: 36321.27 toks/s, output: 35.47 toks/s]
Processed prompts:  35%|      | 2882/8192 [01:21<02:54, 30.35it/s, est. speed input: 36167.07 toks/s, output: 35.32 toks/s]
Processed prompts:  36%|      | 2946/8192 [01:23<02:53, 30.29it/s, est. speed input: 36033.27 toks/s, output: 35.19 toks/s]
Processed prompts:  37%|      | 3010/8192 [01:25<02:49, 30.53it/s, est. speed input: 35932.53 toks/s, output: 35.09 toks/s]
Processed prompts:  38%|      | 3074/8192 [01:27<02:46, 30.72it/s, est. speed input: 35839.05 toks/s, output: 35.00 toks/s]
Processed prompts:  38%|      | 3138/8192 [01:29<02:44, 30.74it/s, est. speed input: 35738.96 toks/s, output: 34.90 toks/s]
Processed prompts:  39%|      | 3202/8192 [01:31<02:41, 30.88it/s, est. speed input: 35654.89 toks/s, output: 34.82 toks/s]
Processed prompts:  40%|      | 3266/8192 [01:34<02:40, 30.68it/s, est. speed input: 35549.29 toks/s, output: 34.72 toks/s]
Processed prompts:  41%|      | 3330/8192 [01:36<02:38, 30.67it/s, est. speed input: 35458.32 toks/s, output: 34.63 toks/s]
Processed prompts:  41%|     | 3394/8192 [01:38<02:37, 30.49it/s, est. speed input: 35357.49 toks/s, output: 34.53 toks/s]
Processed prompts:  42%|     | 3458/8192 [01:40<02:34, 30.70it/s, est. speed input: 35288.18 toks/s, output: 34.46 toks/s]
Processed prompts:  43%|     | 3522/8192 [01:42<02:33, 30.44it/s, est. speed input: 35188.97 toks/s, output: 34.36 toks/s]
Processed prompts:  44%|     | 3586/8192 [01:44<02:32, 30.27it/s, est. speed input: 35094.79 toks/s, output: 34.27 toks/s]
Processed prompts:  45%|     | 3650/8192 [01:46<02:29, 30.37it/s, est. speed input: 35021.17 toks/s, output: 34.20 toks/s]
Processed prompts:  45%|     | 3714/8192 [01:48<02:27, 30.33it/s, est. speed input: 34942.09 toks/s, output: 34.12 toks/s]
Processed prompts:  46%|     | 3778/8192 [01:50<02:25, 30.27it/s, est. speed input: 34863.79 toks/s, output: 34.05 toks/s]
Processed prompts:  47%|     | 3842/8192 [01:53<02:23, 30.40it/s, est. speed input: 34801.14 toks/s, output: 33.99 toks/s]
Processed prompts:  48%|     | 3906/8192 [01:55<02:21, 30.33it/s, est. speed input: 34729.20 toks/s, output: 33.92 toks/s]
Processed prompts:  48%|     | 3970/8192 [01:57<02:19, 30.17it/s, est. speed input: 34652.13 toks/s, output: 33.84 toks/s]
Processed prompts:  49%|     | 4034/8192 [01:59<02:16, 30.46it/s, est. speed input: 34604.64 toks/s, output: 33.79 toks/s]
Processed prompts:  50%|     | 4098/8192 [02:01<02:15, 30.31it/s, est. speed input: 34535.95 toks/s, output: 33.73 toks/s]
Processed prompts:  51%|     | 4162/8192 [02:03<02:11, 30.71it/s, est. speed input: 34501.70 toks/s, output: 33.69 toks/s]
Processed prompts:  52%|    | 4226/8192 [02:05<02:09, 30.71it/s, est. speed input: 34450.74 toks/s, output: 33.64 toks/s]
Processed prompts:  52%|    | 4290/8192 [02:07<02:07, 30.54it/s, est. speed input: 34391.34 toks/s, output: 33.59 toks/s]
Processed prompts:  53%|    | 4354/8192 [02:09<02:06, 30.32it/s, est. speed input: 34327.76 toks/s, output: 33.52 toks/s]
Processed prompts:  54%|    | 4418/8192 [02:11<02:04, 30.34it/s, est. speed input: 34276.24 toks/s, output: 33.47 toks/s]
Processed prompts:  55%|    | 4482/8192 [02:14<02:03, 30.15it/s, est. speed input: 34214.72 toks/s, output: 33.41 toks/s]
Processed prompts:  55%|    | 4546/8192 [02:16<01:59, 30.44it/s, est. speed input: 34179.70 toks/s, output: 33.38 toks/s]
Processed prompts:  56%|    | 4610/8192 [02:18<01:57, 30.38it/s, est. speed input: 34130.22 toks/s, output: 33.33 toks/s]
Processed prompts:  57%|    | 4674/8192 [02:20<01:56, 30.20it/s, est. speed input: 34075.05 toks/s, output: 33.28 toks/s]
Processed prompts:  58%|    | 4738/8192 [02:22<01:53, 30.33it/s, est. speed input: 34035.24 toks/s, output: 33.24 toks/s]
Processed prompts:  59%|    | 4802/8192 [02:24<01:51, 30.28it/s, est. speed input: 33988.92 toks/s, output: 33.19 toks/s]
Processed prompts:  59%|    | 4866/8192 [02:26<01:49, 30.25it/s, est. speed input: 33944.31 toks/s, output: 33.15 toks/s]
Processed prompts:  60%|    | 4930/8192 [02:28<01:47, 30.24it/s, est. speed input: 33901.50 toks/s, output: 33.11 toks/s]
Processed prompts:  61%|    | 4994/8192 [02:31<01:45, 30.35it/s, est. speed input: 33866.36 toks/s, output: 33.07 toks/s]
Processed prompts:  62%|   | 5058/8192 [02:33<01:42, 30.56it/s, est. speed input: 33838.69 toks/s, output: 33.05 toks/s]
Processed prompts:  63%|   | 5122/8192 [02:35<01:41, 30.35it/s, est. speed input: 33793.89 toks/s, output: 33.00 toks/s]
Processed prompts:  63%|   | 5186/8192 [02:37<01:38, 30.58it/s, est. speed input: 33768.94 toks/s, output: 32.98 toks/s]
Processed prompts:  64%|   | 5250/8192 [02:39<01:35, 30.77it/s, est. speed input: 33745.66 toks/s, output: 32.95 toks/s]
Processed prompts:  65%|   | 5314/8192 [02:41<01:33, 30.88it/s, est. speed input: 33722.12 toks/s, output: 32.93 toks/s]
Processed prompts:  66%|   | 5378/8192 [02:43<01:31, 30.67it/s, est. speed input: 33685.80 toks/s, output: 32.90 toks/s]
Processed prompts:  66%|   | 5442/8192 [02:45<01:29, 30.66it/s, est. speed input: 33656.45 toks/s, output: 32.87 toks/s]
Processed prompts:  67%|   | 5506/8192 [02:47<01:28, 30.49it/s, est. speed input: 33620.52 toks/s, output: 32.83 toks/s]
Processed prompts:  68%|   | 5570/8192 [02:49<01:26, 30.28it/s, est. speed input: 33581.27 toks/s, output: 32.79 toks/s]
Processed prompts:  69%|   | 5634/8192 [02:51<01:24, 30.40it/s, est. speed input: 33555.09 toks/s, output: 32.77 toks/s]
Processed prompts:  70%|   | 5698/8192 [02:54<01:21, 30.48it/s, est. speed input: 33529.17 toks/s, output: 32.74 toks/s]
Processed prompts:  70%|   | 5762/8192 [02:56<01:19, 30.40it/s, est. speed input: 33498.32 toks/s, output: 32.71 toks/s]
Processed prompts:  71%|   | 5826/8192 [02:58<01:17, 30.33it/s, est. speed input: 33467.37 toks/s, output: 32.68 toks/s]
Processed prompts:  72%|  | 5890/8192 [03:00<01:15, 30.44it/s, est. speed input: 33443.95 toks/s, output: 32.66 toks/s]
Processed prompts:  73%|  | 5954/8192 [03:02<01:13, 30.30it/s, est. speed input: 33411.52 toks/s, output: 32.63 toks/s]
Processed prompts:  73%|  | 6018/8192 [03:04<01:11, 30.25it/s, est. speed input: 33382.26 toks/s, output: 32.60 toks/s]
Processed prompts:  74%|  | 6082/8192 [03:06<01:10, 30.14it/s, est. speed input: 33350.26 toks/s, output: 32.57 toks/s]
Processed prompts:  75%|  | 6146/8192 [03:08<01:07, 30.48it/s, est. speed input: 33336.13 toks/s, output: 32.55 toks/s]
Processed prompts:  76%|  | 6210/8192 [03:10<01:05, 30.38it/s, est. speed input: 33308.69 toks/s, output: 32.53 toks/s]
Processed prompts:  77%|  | 6274/8192 [03:13<01:03, 30.22it/s, est. speed input: 33278.30 toks/s, output: 32.50 toks/s]
Processed prompts:  77%|  | 6338/8192 [03:15<01:01, 30.34it/s, est. speed input: 33257.79 toks/s, output: 32.48 toks/s]
Processed prompts:  78%|  | 6402/8192 [03:17<00:59, 30.32it/s, est. speed input: 33233.58 toks/s, output: 32.45 toks/s]
Processed prompts:  79%|  | 6466/8192 [03:19<00:57, 30.18it/s, est. speed input: 33205.01 toks/s, output: 32.43 toks/s]
Processed prompts:  80%|  | 6530/8192 [03:21<00:54, 30.33it/s, est. speed input: 33186.71 toks/s, output: 32.41 toks/s]
Processed prompts:  80%|  | 6594/8192 [03:23<00:52, 30.32it/s, est. speed input: 33164.07 toks/s, output: 32.39 toks/s]
Processed prompts:  81%| | 6658/8192 [03:25<00:50, 30.42it/s, est. speed input: 33145.98 toks/s, output: 32.37 toks/s]
Processed prompts:  82%| | 6722/8192 [03:27<00:48, 30.24it/s, est. speed input: 33119.05 toks/s, output: 32.34 toks/s]
Processed prompts:  83%| | 6786/8192 [03:29<00:46, 30.21it/s, est. speed input: 33096.44 toks/s, output: 32.32 toks/s]
Processed prompts:  84%| | 6850/8192 [03:32<00:44, 30.19it/s, est. speed input: 33073.97 toks/s, output: 32.30 toks/s]
Processed prompts:  84%| | 6914/8192 [03:34<00:42, 30.16it/s, est. speed input: 33051.51 toks/s, output: 32.28 toks/s]
Processed prompts:  85%| | 6978/8192 [03:36<00:40, 30.30it/s, est. speed input: 33035.42 toks/s, output: 32.26 toks/s]
Processed prompts:  86%| | 7042/8192 [03:38<00:37, 30.29it/s, est. speed input: 33015.62 toks/s, output: 32.24 toks/s]
Processed prompts:  87%| | 7106/8192 [03:40<00:35, 30.71it/s, est. speed input: 33010.72 toks/s, output: 32.24 toks/s]
Processed prompts:  88%| | 7170/8192 [03:42<00:33, 30.54it/s, est. speed input: 32990.44 toks/s, output: 32.22 toks/s]
Processed prompts:  88%| | 7234/8192 [03:44<00:31, 30.57it/s, est. speed input: 32975.44 toks/s, output: 32.20 toks/s]
Processed prompts:  89%| | 7298/8192 [03:46<00:29, 30.46it/s, est. speed input: 32956.19 toks/s, output: 32.18 toks/s]
Processed prompts:  90%| | 7362/8192 [03:48<00:27, 30.51it/s, est. speed input: 32941.56 toks/s, output: 32.17 toks/s]
Processed prompts:  91%| | 7426/8192 [03:50<00:25, 30.40it/s, est. speed input: 32922.59 toks/s, output: 32.15 toks/s]
Processed prompts:  91%|| 7490/8192 [03:53<00:22, 30.63it/s, est. speed input: 32913.71 toks/s, output: 32.14 toks/s]
Processed prompts:  92%|| 7554/8192 [03:55<00:20, 30.78it/s, est. speed input: 32904.88 toks/s, output: 32.13 toks/s]
Processed prompts:  93%|| 7618/8192 [03:57<00:18, 31.03it/s, est. speed input: 32900.51 toks/s, output: 32.13 toks/s]
Processed prompts:  94%|| 7682/8192 [03:59<00:16, 30.77it/s, est. speed input: 32882.84 toks/s, output: 32.11 toks/s]
Processed prompts:  95%|| 7746/8192 [04:01<00:14, 30.63it/s, est. speed input: 32866.71 toks/s, output: 32.10 toks/s]
Processed prompts:  95%|| 7810/8192 [04:03<00:12, 30.40it/s, est. speed input: 32846.67 toks/s, output: 32.08 toks/s]
Processed prompts:  96%|| 7874/8192 [04:05<00:10, 30.22it/s, est. speed input: 32826.39 toks/s, output: 32.06 toks/s]
Processed prompts:  97%|| 7938/8192 [04:07<00:08, 30.21it/s, est. speed input: 32810.03 toks/s, output: 32.04 toks/s]
Processed prompts:  98%|| 8002/8192 [04:09<00:06, 30.20it/s, est. speed input: 32793.81 toks/s, output: 32.03 toks/s]
Processed prompts:  98%|| 8066/8192 [04:11<00:04, 30.34it/s, est. speed input: 32782.27 toks/s, output: 32.01 toks/s]
Processed prompts:  99%|| 8130/8192 [04:14<00:02, 30.42it/s, est. speed input: 32770.53 toks/s, output: 32.00 toks/s]
Processed prompts: 100%|| 8192/8192 [04:14<00:00, 30.42it/s, est. speed input: 33020.38 toks/s, output: 32.25 toks/s]
Processed prompts: 100%|| 8192/8192 [04:14<00:00, 32.25it/s, est. speed input: 33020.38 toks/s, output: 32.25 toks/s]
[rank0]:[W126 08:27:45.223321693 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-26 12:23:40
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-3B-FP8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 12:23:44 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 12:23:44 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1283215) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1283215) WARNING 01-26 12:24:17 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 23.66 requests/s, 12139.02 total tokens/s, 23.66 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-26 12:23:44] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 12:23:44] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 12:23:44] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 12:23:44] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:23:44] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:23:44] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:23:44] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:23:44] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:23:44] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 12:23:44] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:23:44] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:23:44] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:23:44] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:23:44] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 12:23:47] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 12:23:47] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 12:23:47] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 12:23:47] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:23:47] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:23:47] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:23:47] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:23:47] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:23:47] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 12:23:47] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:23:47] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:23:47] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:23:47] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:23:47] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1283215) [2026-01-26 12:23:48] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1283215) [2026-01-26 12:23:48] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1283215) [2026-01-26 12:23:48] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1283215) [2026-01-26 12:23:48] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1283215) [2026-01-26 12:23:48] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1283215) [2026-01-26 12:23:48] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1283215) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1283215) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:21<00:00, 21.36s/it]
(EngineCore_DP0 pid=1283215) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:21<00:00, 21.36s/it]
(EngineCore_DP0 pid=1283215) 
(EngineCore_DP0 pid=1283215) [2026-01-26 12:24:10] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4096] -> 1D uint8
(EngineCore_DP0 pid=1283215) [2026-01-26 12:24:10] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 13107200 bytes
(EngineCore_DP0 pid=1283215) [2026-01-26 12:24:10] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4096] -> 1D uint8
(EngineCore_DP0 pid=1283215) [2026-01-26 12:24:10] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 7864320 bytes
(EngineCore_DP0 pid=1283215) [2026-01-26 12:24:10] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4096] -> 1D uint8
(EngineCore_DP0 pid=1283215) [2026-01-26 12:24:10] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 41943040 bytes
(EngineCore_DP0 pid=1283215) [2026-01-26 12:24:10] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 10944] -> 1D uint8
(EngineCore_DP0 pid=1283215) [2026-01-26 12:24:11] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 21037056 bytes
(EngineCore_DP0 pid=1283215) 2026-01-26 12:24:16,760 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1283215) 2026-01-26 12:24:16,772 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  86%| | 110/128 [00:00<00:00, 1098.27it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 1089.19it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:16,  7.92it/s, est. speed input: 4054.01 toks/s, output: 7.92 toks/s]
Processed prompts:   3%|         | 4/128 [00:00<00:06, 17.84it/s, est. speed input: 8351.23 toks/s, output: 16.31 toks/s]
Processed prompts:   5%|         | 7/128 [00:00<00:05, 21.30it/s, est. speed input: 9885.47 toks/s, output: 19.31 toks/s]
Processed prompts:   8%|         | 10/128 [00:00<00:05, 22.44it/s, est. speed input: 10514.50 toks/s, output: 20.54 toks/s]
Processed prompts:  10%|         | 13/128 [00:00<00:05, 21.25it/s, est. speed input: 10396.34 toks/s, output: 20.31 toks/s]
Processed prompts:  12%|        | 16/128 [00:00<00:05, 20.80it/s, est. speed input: 10370.92 toks/s, output: 20.26 toks/s]
Processed prompts:  15%|        | 19/128 [00:00<00:05, 20.66it/s, est. speed input: 10380.96 toks/s, output: 20.28 toks/s]
Processed prompts:  17%|        | 22/128 [00:01<00:05, 20.54it/s, est. speed input: 10382.94 toks/s, output: 20.28 toks/s]
Processed prompts:  20%|        | 25/128 [00:01<00:04, 21.80it/s, est. speed input: 10628.51 toks/s, output: 20.76 toks/s]
Processed prompts:  22%|       | 28/128 [00:01<00:04, 22.82it/s, est. speed input: 10843.40 toks/s, output: 21.18 toks/s]
Processed prompts:  24%|       | 31/128 [00:01<00:04, 23.48it/s, est. speed input: 11010.14 toks/s, output: 21.50 toks/s]
Processed prompts:  27%|       | 34/128 [00:01<00:03, 23.94it/s, est. speed input: 11149.91 toks/s, output: 21.78 toks/s]
Processed prompts:  29%|       | 37/128 [00:01<00:03, 23.91it/s, est. speed input: 11228.50 toks/s, output: 21.93 toks/s]
Processed prompts:  31%|      | 40/128 [00:01<00:03, 24.28it/s, est. speed input: 11338.47 toks/s, output: 22.15 toks/s]
Processed prompts:  34%|      | 43/128 [00:01<00:03, 24.78it/s, est. speed input: 11457.48 toks/s, output: 22.38 toks/s]
Processed prompts:  36%|      | 46/128 [00:02<00:03, 24.81it/s, est. speed input: 11533.34 toks/s, output: 22.53 toks/s]
Processed prompts:  38%|      | 49/128 [00:02<00:03, 24.84it/s, est. speed input: 11600.91 toks/s, output: 22.66 toks/s]
Processed prompts:  41%|      | 52/128 [00:02<00:03, 25.04it/s, est. speed input: 11676.61 toks/s, output: 22.81 toks/s]
Processed prompts:  43%|     | 55/128 [00:02<00:02, 25.23it/s, est. speed input: 11748.11 toks/s, output: 22.95 toks/s]
Processed prompts:  45%|     | 58/128 [00:02<00:02, 25.10it/s, est. speed input: 11793.57 toks/s, output: 23.03 toks/s]
Processed prompts:  48%|     | 61/128 [00:02<00:02, 25.33it/s, est. speed input: 11857.92 toks/s, output: 23.16 toks/s]
Processed prompts:  50%|     | 64/128 [00:02<00:02, 25.17it/s, est. speed input: 11895.25 toks/s, output: 23.23 toks/s]
Processed prompts:  52%|    | 67/128 [00:02<00:02, 25.27it/s, est. speed input: 11942.64 toks/s, output: 23.33 toks/s]
Processed prompts:  55%|    | 70/128 [00:02<00:02, 25.38it/s, est. speed input: 11989.09 toks/s, output: 23.42 toks/s]
Processed prompts:  57%|    | 73/128 [00:03<00:02, 25.40it/s, est. speed input: 12028.35 toks/s, output: 23.49 toks/s]
Processed prompts:  59%|    | 76/128 [00:03<00:02, 25.29it/s, est. speed input: 12058.16 toks/s, output: 23.55 toks/s]
Processed prompts:  62%|   | 79/128 [00:03<00:01, 25.22it/s, est. speed input: 12085.63 toks/s, output: 23.60 toks/s]
Processed prompts:  64%|   | 82/128 [00:03<00:01, 25.37it/s, est. speed input: 12122.18 toks/s, output: 23.68 toks/s]
Processed prompts:  66%|   | 85/128 [00:03<00:01, 25.40it/s, est. speed input: 12152.10 toks/s, output: 23.73 toks/s]
Processed prompts:  69%|   | 88/128 [00:03<00:01, 25.36it/s, est. speed input: 12177.41 toks/s, output: 23.78 toks/s]
Processed prompts:  71%|   | 91/128 [00:03<00:01, 24.90it/s, est. speed input: 12179.30 toks/s, output: 23.79 toks/s]
Processed prompts:  73%|  | 94/128 [00:03<00:01, 24.93it/s, est. speed input: 12197.99 toks/s, output: 23.82 toks/s]
Processed prompts:  76%|  | 97/128 [00:04<00:01, 25.06it/s, est. speed input: 12221.00 toks/s, output: 23.87 toks/s]
Processed prompts:  78%|  | 100/128 [00:04<00:01, 25.21it/s, est. speed input: 12245.54 toks/s, output: 23.92 toks/s]
Processed prompts:  80%|  | 103/128 [00:04<00:00, 25.07it/s, est. speed input: 12257.61 toks/s, output: 23.94 toks/s]
Processed prompts:  83%| | 106/128 [00:04<00:00, 25.29it/s, est. speed input: 12283.00 toks/s, output: 23.99 toks/s]
Processed prompts:  85%| | 109/128 [00:04<00:00, 25.36it/s, est. speed input: 12303.09 toks/s, output: 24.03 toks/s]
Processed prompts:  88%| | 112/128 [00:04<00:00, 25.26it/s, est. speed input: 12316.48 toks/s, output: 24.06 toks/s]
Processed prompts:  90%| | 115/128 [00:04<00:00, 25.26it/s, est. speed input: 12331.73 toks/s, output: 24.09 toks/s]
Processed prompts:  92%|| 118/128 [00:04<00:00, 25.13it/s, est. speed input: 12341.10 toks/s, output: 24.10 toks/s]
Processed prompts:  95%|| 121/128 [00:05<00:00, 25.20it/s, est. speed input: 12356.28 toks/s, output: 24.13 toks/s]
Processed prompts:  97%|| 124/128 [00:05<00:00, 25.12it/s, est. speed input: 12366.06 toks/s, output: 24.15 toks/s]
Processed prompts:  99%|| 127/128 [00:05<00:00, 25.19it/s, est. speed input: 12379.78 toks/s, output: 24.18 toks/s]
Processed prompts: 100%|| 128/128 [00:05<00:00, 25.19it/s, est. speed input: 12386.75 toks/s, output: 24.19 toks/s]
Processed prompts: 100%|| 128/128 [00:05<00:00, 24.19it/s, est. speed input: 12386.75 toks/s, output: 24.19 toks/s]
[rank0]:[W126 12:24:23.307864582 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-26 12:24:25
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-3B-FP8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 12:24:29 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 12:24:29 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1284021) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1284021) WARNING 01-26 12:25:01 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 13.02 requests/s, 13345.22 total tokens/s, 13.02 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-26 12:24:29] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 12:24:29] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 12:24:29] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 12:24:29] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:24:29] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:24:29] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:24:29] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:24:29] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:24:29] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 12:24:29] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:24:29] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:24:29] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:24:29] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:24:29] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 12:24:32] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 12:24:32] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 12:24:32] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 12:24:32] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:24:32] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:24:32] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:24:32] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:24:32] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:24:32] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 12:24:32] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:24:32] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:24:32] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:24:32] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:24:32] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1284021) [2026-01-26 12:24:33] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1284021) [2026-01-26 12:24:33] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1284021) [2026-01-26 12:24:33] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1284021) [2026-01-26 12:24:33] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1284021) [2026-01-26 12:24:33] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1284021) [2026-01-26 12:24:33] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1284021) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1284021) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:20<00:00, 20.49s/it]
(EngineCore_DP0 pid=1284021) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:20<00:00, 20.49s/it]
(EngineCore_DP0 pid=1284021) 
(EngineCore_DP0 pid=1284021) [2026-01-26 12:24:55] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4096] -> 1D uint8
(EngineCore_DP0 pid=1284021) [2026-01-26 12:24:55] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 13107200 bytes
(EngineCore_DP0 pid=1284021) [2026-01-26 12:24:55] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4096] -> 1D uint8
(EngineCore_DP0 pid=1284021) [2026-01-26 12:24:55] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 7864320 bytes
(EngineCore_DP0 pid=1284021) [2026-01-26 12:24:55] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4096] -> 1D uint8
(EngineCore_DP0 pid=1284021) [2026-01-26 12:24:55] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 41943040 bytes
(EngineCore_DP0 pid=1284021) [2026-01-26 12:24:55] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 10944] -> 1D uint8
(EngineCore_DP0 pid=1284021) [2026-01-26 12:24:55] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 21037056 bytes
(EngineCore_DP0 pid=1284021) 2026-01-26 12:25:00,814 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1284021) 2026-01-26 12:25:00,826 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  23%|       | 29/128 [00:00<00:00, 285.70it/s]
Adding requests:  58%|    | 74/128 [00:00<00:00, 378.01it/s]
Adding requests:  98%|| 125/128 [00:00<00:00, 435.87it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 411.97it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   4%|         | 5/128 [00:00<00:04, 29.63it/s, est. speed input: 30343.18 toks/s, output: 29.63 toks/s]
Processed prompts:   6%|         | 8/128 [00:00<00:06, 18.68it/s, est. speed input: 20552.37 toks/s, output: 20.07 toks/s]
Processed prompts:   8%|         | 10/128 [00:00<00:07, 16.53it/s, est. speed input: 18575.02 toks/s, output: 18.14 toks/s]
Processed prompts:   9%|         | 12/128 [00:00<00:07, 15.30it/s, est. speed input: 17448.00 toks/s, output: 17.04 toks/s]
Processed prompts:  11%|         | 14/128 [00:00<00:07, 14.65it/s, est. speed input: 16782.18 toks/s, output: 16.39 toks/s]
Processed prompts:  12%|        | 16/128 [00:01<00:07, 14.06it/s, est. speed input: 16229.29 toks/s, output: 15.85 toks/s]
Processed prompts:  14%|        | 18/128 [00:01<00:07, 13.83it/s, est. speed input: 15891.44 toks/s, output: 15.52 toks/s]
Processed prompts:  16%|        | 20/128 [00:01<00:07, 13.65it/s, est. speed input: 15626.00 toks/s, output: 15.26 toks/s]
Processed prompts:  17%|        | 22/128 [00:01<00:07, 13.54it/s, est. speed input: 15419.48 toks/s, output: 15.06 toks/s]
Processed prompts:  19%|        | 24/128 [00:01<00:07, 13.41it/s, est. speed input: 15230.08 toks/s, output: 14.87 toks/s]
Processed prompts:  20%|        | 26/128 [00:01<00:07, 13.38it/s, est. speed input: 15092.73 toks/s, output: 14.74 toks/s]
Processed prompts:  22%|       | 28/128 [00:01<00:07, 13.34it/s, est. speed input: 14972.80 toks/s, output: 14.62 toks/s]
Processed prompts:  23%|       | 30/128 [00:02<00:07, 13.07it/s, est. speed input: 14805.28 toks/s, output: 14.46 toks/s]
Processed prompts:  25%|       | 32/128 [00:02<00:07, 13.18it/s, est. speed input: 14733.39 toks/s, output: 14.39 toks/s]
Processed prompts:  27%|       | 34/128 [00:02<00:07, 13.20it/s, est. speed input: 14659.88 toks/s, output: 14.32 toks/s]
Processed prompts:  28%|       | 36/128 [00:02<00:06, 13.25it/s, est. speed input: 14601.86 toks/s, output: 14.26 toks/s]
Processed prompts:  30%|       | 38/128 [00:02<00:06, 13.29it/s, est. speed input: 14552.91 toks/s, output: 14.21 toks/s]
Processed prompts:  31%|      | 40/128 [00:02<00:06, 13.26it/s, est. speed input: 14497.30 toks/s, output: 14.16 toks/s]
Processed prompts:  33%|      | 42/128 [00:02<00:06, 13.33it/s, est. speed input: 14463.25 toks/s, output: 14.12 toks/s]
Processed prompts:  34%|      | 44/128 [00:03<00:06, 13.16it/s, est. speed input: 14393.47 toks/s, output: 14.06 toks/s]
Processed prompts:  36%|      | 46/128 [00:03<00:06, 13.22it/s, est. speed input: 14360.75 toks/s, output: 14.02 toks/s]
Processed prompts:  38%|      | 48/128 [00:03<00:06, 13.16it/s, est. speed input: 14314.61 toks/s, output: 13.98 toks/s]
Processed prompts:  39%|      | 50/128 [00:03<00:05, 13.18it/s, est. speed input: 14282.15 toks/s, output: 13.95 toks/s]
Processed prompts:  41%|      | 52/128 [00:03<00:05, 13.20it/s, est. speed input: 14253.23 toks/s, output: 13.92 toks/s]
Processed prompts:  42%|     | 54/128 [00:03<00:05, 13.23it/s, est. speed input: 14228.17 toks/s, output: 13.89 toks/s]
Processed prompts:  44%|     | 56/128 [00:04<00:05, 13.25it/s, est. speed input: 14205.38 toks/s, output: 13.87 toks/s]
Processed prompts:  45%|     | 58/128 [00:04<00:05, 13.06it/s, est. speed input: 14158.64 toks/s, output: 13.83 toks/s]
Processed prompts:  47%|     | 60/128 [00:04<00:05, 13.15it/s, est. speed input: 14142.26 toks/s, output: 13.81 toks/s]
Processed prompts:  48%|     | 62/128 [00:04<00:05, 13.15it/s, est. speed input: 14119.21 toks/s, output: 13.79 toks/s]
Processed prompts:  50%|     | 64/128 [00:04<00:04, 13.13it/s, est. speed input: 14096.01 toks/s, output: 13.77 toks/s]
Processed prompts:  52%|    | 66/128 [00:04<00:04, 13.15it/s, est. speed input: 14077.37 toks/s, output: 13.75 toks/s]
Processed prompts:  53%|    | 68/128 [00:04<00:04, 13.15it/s, est. speed input: 14058.19 toks/s, output: 13.73 toks/s]
Processed prompts:  55%|    | 70/128 [00:05<00:04, 13.13it/s, est. speed input: 14038.68 toks/s, output: 13.71 toks/s]
Processed prompts:  56%|    | 72/128 [00:05<00:04, 13.08it/s, est. speed input: 14016.12 toks/s, output: 13.69 toks/s]
Processed prompts:  58%|    | 74/128 [00:05<00:04, 13.11it/s, est. speed input: 14001.88 toks/s, output: 13.67 toks/s]
Processed prompts:  59%|    | 76/128 [00:05<00:03, 13.12it/s, est. speed input: 13987.38 toks/s, output: 13.66 toks/s]
Processed prompts:  61%|    | 78/128 [00:05<00:03, 13.17it/s, est. speed input: 13977.06 toks/s, output: 13.65 toks/s]
Processed prompts:  62%|   | 80/128 [00:05<00:03, 13.24it/s, est. speed input: 13971.09 toks/s, output: 13.64 toks/s]
Processed prompts:  64%|   | 82/128 [00:06<00:03, 13.17it/s, est. speed input: 13954.50 toks/s, output: 13.63 toks/s]
Processed prompts:  66%|   | 84/128 [00:06<00:03, 13.04it/s, est. speed input: 13930.95 toks/s, output: 13.60 toks/s]
Processed prompts:  67%|   | 86/128 [00:06<00:03, 13.10it/s, est. speed input: 13922.28 toks/s, output: 13.60 toks/s]
Processed prompts:  69%|   | 88/128 [00:06<00:03, 13.14it/s, est. speed input: 13914.02 toks/s, output: 13.59 toks/s]
Processed prompts:  70%|   | 90/128 [00:06<00:02, 13.13it/s, est. speed input: 13902.26 toks/s, output: 13.58 toks/s]
Processed prompts:  72%|  | 92/128 [00:06<00:02, 13.18it/s, est. speed input: 13896.41 toks/s, output: 13.57 toks/s]
Processed prompts:  73%|  | 94/128 [00:06<00:02, 13.10it/s, est. speed input: 13881.43 toks/s, output: 13.56 toks/s]
Processed prompts:  75%|  | 96/128 [00:07<00:02, 13.17it/s, est. speed input: 13876.80 toks/s, output: 13.55 toks/s]
Processed prompts:  77%|  | 98/128 [00:07<00:02, 13.08it/s, est. speed input: 13861.45 toks/s, output: 13.54 toks/s]
Processed prompts:  78%|  | 100/128 [00:07<00:02, 13.18it/s, est. speed input: 13859.35 toks/s, output: 13.53 toks/s]
Processed prompts:  80%|  | 102/128 [00:07<00:01, 13.17it/s, est. speed input: 13850.98 toks/s, output: 13.53 toks/s]
Processed prompts:  81%| | 104/128 [00:07<00:01, 13.21it/s, est. speed input: 13846.64 toks/s, output: 13.52 toks/s]
Processed prompts:  83%| | 106/128 [00:07<00:01, 13.19it/s, est. speed input: 13839.03 toks/s, output: 13.51 toks/s]
Processed prompts:  84%| | 108/128 [00:07<00:01, 13.22it/s, est. speed input: 13834.61 toks/s, output: 13.51 toks/s]
Processed prompts:  86%| | 110/128 [00:08<00:01, 13.22it/s, est. speed input: 13828.93 toks/s, output: 13.50 toks/s]
Processed prompts:  88%| | 112/128 [00:08<00:01, 13.06it/s, est. speed input: 13813.45 toks/s, output: 13.49 toks/s]
Processed prompts:  89%| | 114/128 [00:08<00:01, 13.07it/s, est. speed input: 13805.91 toks/s, output: 13.48 toks/s]
Processed prompts:  91%| | 116/128 [00:08<00:00, 13.14it/s, est. speed input: 13802.81 toks/s, output: 13.48 toks/s]
Processed prompts:  92%|| 118/128 [00:08<00:00, 13.20it/s, est. speed input: 13800.37 toks/s, output: 13.48 toks/s]
Processed prompts:  94%|| 120/128 [00:08<00:00, 13.19it/s, est. speed input: 13795.22 toks/s, output: 13.47 toks/s]
Processed prompts:  95%|| 122/128 [00:09<00:00, 13.19it/s, est. speed input: 13790.48 toks/s, output: 13.47 toks/s]
Processed prompts:  97%|| 124/128 [00:09<00:00, 13.23it/s, est. speed input: 13788.05 toks/s, output: 13.46 toks/s]
Processed prompts:  98%|| 126/128 [00:09<00:00, 13.11it/s, est. speed input: 13777.34 toks/s, output: 13.45 toks/s]
Processed prompts: 100%|| 128/128 [00:09<00:00, 13.06it/s, est. speed input: 13768.88 toks/s, output: 13.45 toks/s]
Processed prompts: 100%|| 128/128 [00:09<00:00, 13.06it/s, est. speed input: 13768.88 toks/s, output: 13.45 toks/s]
Processed prompts: 100%|| 128/128 [00:09<00:00, 13.45it/s, est. speed input: 13768.88 toks/s, output: 13.45 toks/s]
[rank0]:[W126 12:25:11.716944251 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-26 12:25:13
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-3B-FP8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 12:25:18 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 12:25:18 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1284910) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1284910) WARNING 01-26 12:25:50 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 13.20 requests/s, 13525.55 total tokens/s, 13.20 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-26 12:25:18] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 12:25:18] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 12:25:18] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 12:25:18] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:25:18] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:25:18] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:25:18] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:25:18] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:25:18] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 12:25:18] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:25:18] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:25:18] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:25:18] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:25:18] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 12:25:21] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 12:25:21] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 12:25:21] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 12:25:21] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:25:21] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:25:21] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:25:21] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:25:21] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:25:21] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 12:25:21] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:25:21] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:25:21] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:25:21] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:25:21] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1284910) [2026-01-26 12:25:22] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1284910) [2026-01-26 12:25:22] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1284910) [2026-01-26 12:25:22] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1284910) [2026-01-26 12:25:22] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1284910) [2026-01-26 12:25:22] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1284910) [2026-01-26 12:25:22] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1284910) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1284910) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:20<00:00, 20.26s/it]
(EngineCore_DP0 pid=1284910) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:20<00:00, 20.26s/it]
(EngineCore_DP0 pid=1284910) 
(EngineCore_DP0 pid=1284910) [2026-01-26 12:25:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4096] -> 1D uint8
(EngineCore_DP0 pid=1284910) [2026-01-26 12:25:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 13107200 bytes
(EngineCore_DP0 pid=1284910) [2026-01-26 12:25:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4096] -> 1D uint8
(EngineCore_DP0 pid=1284910) [2026-01-26 12:25:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 7864320 bytes
(EngineCore_DP0 pid=1284910) [2026-01-26 12:25:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4096] -> 1D uint8
(EngineCore_DP0 pid=1284910) [2026-01-26 12:25:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 41943040 bytes
(EngineCore_DP0 pid=1284910) [2026-01-26 12:25:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 10944] -> 1D uint8
(EngineCore_DP0 pid=1284910) [2026-01-26 12:25:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 21037056 bytes
(EngineCore_DP0 pid=1284910) 2026-01-26 12:25:49,219 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1284910) 2026-01-26 12:25:49,229 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  21%|        | 53/256 [00:00<00:00, 526.36it/s]
Adding requests:  41%|     | 106/256 [00:00<00:00, 484.22it/s]
Adding requests:  62%|   | 159/256 [00:00<00:00, 502.01it/s]
Adding requests:  82%| | 210/256 [00:00<00:00, 469.33it/s]
Adding requests: 100%|| 256/256 [00:00<00:00, 487.07it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 6/256 [00:00<00:05, 46.89it/s, est. speed input: 48026.20 toks/s, output: 46.90 toks/s]
Processed prompts:   4%|         | 11/256 [00:00<00:10, 23.44it/s, est. speed input: 26146.84 toks/s, output: 25.53 toks/s]
Processed prompts:   5%|         | 14/256 [00:00<00:14, 16.43it/s, est. speed input: 19623.83 toks/s, output: 19.16 toks/s]
Processed prompts:   7%|         | 17/256 [00:00<00:13, 17.49it/s, est. speed input: 19828.40 toks/s, output: 19.36 toks/s]
Processed prompts:   8%|         | 20/256 [00:01<00:16, 14.22it/s, est. speed input: 17398.53 toks/s, output: 16.99 toks/s]
Processed prompts:   9%|         | 22/256 [00:01<00:16, 13.98it/s, est. speed input: 16956.85 toks/s, output: 16.56 toks/s]
Processed prompts:   9%|         | 24/256 [00:01<00:16, 13.77it/s, est. speed input: 16598.90 toks/s, output: 16.21 toks/s]
Processed prompts:  10%|         | 26/256 [00:01<00:16, 13.63it/s, est. speed input: 16319.39 toks/s, output: 15.94 toks/s]
Processed prompts:  11%|         | 28/256 [00:01<00:16, 13.55it/s, est. speed input: 16094.53 toks/s, output: 15.72 toks/s]
Processed prompts:  12%|        | 30/256 [00:01<00:16, 13.49it/s, est. speed input: 15905.88 toks/s, output: 15.53 toks/s]
Processed prompts:  12%|        | 32/256 [00:02<00:16, 13.53it/s, est. speed input: 15768.46 toks/s, output: 15.40 toks/s]
Processed prompts:  13%|        | 34/256 [00:02<00:16, 13.43it/s, est. speed input: 15615.23 toks/s, output: 15.25 toks/s]
Processed prompts:  14%|        | 36/256 [00:02<00:16, 13.42it/s, est. speed input: 15494.82 toks/s, output: 15.13 toks/s]
Processed prompts:  15%|        | 38/256 [00:02<00:16, 13.31it/s, est. speed input: 15365.96 toks/s, output: 15.01 toks/s]
Processed prompts:  16%|        | 40/256 [00:02<00:16, 13.20it/s, est. speed input: 15244.18 toks/s, output: 14.89 toks/s]
Processed prompts:  16%|        | 42/256 [00:02<00:16, 13.25it/s, est. speed input: 15162.67 toks/s, output: 14.81 toks/s]
Processed prompts:  17%|        | 44/256 [00:02<00:15, 13.26it/s, est. speed input: 15084.77 toks/s, output: 14.73 toks/s]
Processed prompts:  18%|        | 46/256 [00:03<00:15, 13.28it/s, est. speed input: 15016.56 toks/s, output: 14.66 toks/s]
Processed prompts:  19%|        | 48/256 [00:03<00:15, 13.32it/s, est. speed input: 14957.22 toks/s, output: 14.61 toks/s]
Processed prompts:  20%|        | 50/256 [00:03<00:15, 13.40it/s, est. speed input: 14913.21 toks/s, output: 14.56 toks/s]
Processed prompts:  20%|        | 52/256 [00:03<00:15, 13.31it/s, est. speed input: 14850.17 toks/s, output: 14.50 toks/s]
Processed prompts:  21%|        | 54/256 [00:03<00:15, 13.23it/s, est. speed input: 14788.35 toks/s, output: 14.44 toks/s]
Processed prompts:  22%|       | 56/256 [00:03<00:15, 13.26it/s, est. speed input: 14745.29 toks/s, output: 14.40 toks/s]
Processed prompts:  23%|       | 58/256 [00:04<00:14, 13.38it/s, est. speed input: 14717.46 toks/s, output: 14.37 toks/s]
Processed prompts:  23%|       | 60/256 [00:04<00:14, 13.40it/s, est. speed input: 14684.43 toks/s, output: 14.34 toks/s]
Processed prompts:  24%|       | 62/256 [00:04<00:14, 13.41it/s, est. speed input: 14652.08 toks/s, output: 14.31 toks/s]
Processed prompts:  25%|       | 64/256 [00:04<00:14, 13.40it/s, est. speed input: 14619.74 toks/s, output: 14.28 toks/s]
Processed prompts:  26%|       | 66/256 [00:04<00:14, 13.38it/s, est. speed input: 14589.08 toks/s, output: 14.25 toks/s]
Processed prompts:  27%|       | 68/256 [00:04<00:14, 13.33it/s, est. speed input: 14555.53 toks/s, output: 14.21 toks/s]
Processed prompts:  27%|       | 70/256 [00:04<00:13, 13.32it/s, est. speed input: 14527.19 toks/s, output: 14.19 toks/s]
Processed prompts:  28%|       | 72/256 [00:05<00:13, 13.30it/s, est. speed input: 14498.96 toks/s, output: 14.16 toks/s]
Processed prompts:  29%|       | 74/256 [00:05<00:13, 13.38it/s, est. speed input: 14481.22 toks/s, output: 14.14 toks/s]
Processed prompts:  30%|       | 76/256 [00:05<00:13, 13.38it/s, est. speed input: 14459.39 toks/s, output: 14.12 toks/s]
Processed prompts:  30%|       | 78/256 [00:05<00:13, 13.39it/s, est. speed input: 14440.64 toks/s, output: 14.10 toks/s]
Processed prompts:  31%|      | 80/256 [00:05<00:13, 13.33it/s, est. speed input: 14415.67 toks/s, output: 14.08 toks/s]
Processed prompts:  32%|      | 82/256 [00:05<00:13, 13.19it/s, est. speed input: 14382.49 toks/s, output: 14.05 toks/s]
Processed prompts:  33%|      | 84/256 [00:05<00:12, 13.25it/s, est. speed input: 14365.66 toks/s, output: 14.03 toks/s]
Processed prompts:  34%|      | 86/256 [00:06<00:12, 13.26it/s, est. speed input: 14347.56 toks/s, output: 14.01 toks/s]
Processed prompts:  34%|      | 88/256 [00:06<00:12, 13.21it/s, est. speed input: 14324.85 toks/s, output: 13.99 toks/s]
Processed prompts:  35%|      | 90/256 [00:06<00:12, 13.29it/s, est. speed input: 14312.32 toks/s, output: 13.98 toks/s]
Processed prompts:  36%|      | 92/256 [00:06<00:12, 13.30it/s, est. speed input: 14297.02 toks/s, output: 13.96 toks/s]
Processed prompts:  37%|      | 94/256 [00:06<00:12, 13.32it/s, est. speed input: 14284.05 toks/s, output: 13.95 toks/s]
Processed prompts:  38%|      | 96/256 [00:06<00:12, 13.13it/s, est. speed input: 14254.93 toks/s, output: 13.92 toks/s]
Processed prompts:  38%|      | 98/256 [00:07<00:12, 13.13it/s, est. speed input: 14237.70 toks/s, output: 13.90 toks/s]
Processed prompts:  39%|      | 100/256 [00:07<00:11, 13.24it/s, est. speed input: 14228.93 toks/s, output: 13.90 toks/s]
Processed prompts:  40%|      | 102/256 [00:07<00:11, 13.26it/s, est. speed input: 14216.69 toks/s, output: 13.88 toks/s]
Processed prompts:  41%|      | 104/256 [00:07<00:11, 13.33it/s, est. speed input: 14209.12 toks/s, output: 13.88 toks/s]
Processed prompts:  41%|     | 106/256 [00:07<00:11, 13.41it/s, est. speed input: 14203.42 toks/s, output: 13.87 toks/s]
Processed prompts:  42%|     | 108/256 [00:07<00:11, 13.43it/s, est. speed input: 14196.07 toks/s, output: 13.86 toks/s]
Processed prompts:  43%|     | 110/256 [00:07<00:11, 13.23it/s, est. speed input: 14174.18 toks/s, output: 13.84 toks/s]
Processed prompts:  44%|     | 112/256 [00:08<00:10, 13.25it/s, est. speed input: 14163.73 toks/s, output: 13.83 toks/s]
Processed prompts:  45%|     | 114/256 [00:08<00:10, 13.31it/s, est. speed input: 14156.91 toks/s, output: 13.83 toks/s]
Processed prompts:  45%|     | 116/256 [00:08<00:10, 13.27it/s, est. speed input: 14144.66 toks/s, output: 13.81 toks/s]
Processed prompts:  46%|     | 118/256 [00:08<00:10, 13.29it/s, est. speed input: 14136.13 toks/s, output: 13.80 toks/s]
Processed prompts:  47%|     | 120/256 [00:08<00:10, 13.30it/s, est. speed input: 14127.47 toks/s, output: 13.80 toks/s]
Processed prompts:  48%|     | 122/256 [00:08<00:10, 13.27it/s, est. speed input: 14117.18 toks/s, output: 13.79 toks/s]
Processed prompts:  48%|     | 124/256 [00:09<00:10, 13.14it/s, est. speed input: 14100.85 toks/s, output: 13.77 toks/s]
Processed prompts:  49%|     | 126/256 [00:09<00:09, 13.16it/s, est. speed input: 14090.87 toks/s, output: 13.76 toks/s]
Processed prompts:  50%|     | 128/256 [00:09<00:09, 13.19it/s, est. speed input: 14082.63 toks/s, output: 13.75 toks/s]
Processed prompts:  51%|     | 130/256 [00:09<00:09, 13.24it/s, est. speed input: 14076.21 toks/s, output: 13.75 toks/s]
Processed prompts:  52%|    | 132/256 [00:09<00:09, 13.27it/s, est. speed input: 14070.00 toks/s, output: 13.74 toks/s]
Processed prompts:  52%|    | 134/256 [00:09<00:09, 13.26it/s, est. speed input: 14062.10 toks/s, output: 13.73 toks/s]
Processed prompts:  53%|    | 136/256 [00:09<00:09, 13.30it/s, est. speed input: 14056.84 toks/s, output: 13.73 toks/s]
Processed prompts:  54%|    | 138/256 [00:10<00:08, 13.19it/s, est. speed input: 14044.39 toks/s, output: 13.72 toks/s]
Processed prompts:  55%|    | 140/256 [00:10<00:08, 13.25it/s, est. speed input: 14039.47 toks/s, output: 13.71 toks/s]
Processed prompts:  55%|    | 142/256 [00:10<00:08, 13.25it/s, est. speed input: 14032.53 toks/s, output: 13.70 toks/s]
Processed prompts:  56%|    | 144/256 [00:10<00:08, 13.31it/s, est. speed input: 14029.09 toks/s, output: 13.70 toks/s]
Processed prompts:  57%|    | 146/256 [00:10<00:08, 13.38it/s, est. speed input: 14026.76 toks/s, output: 13.70 toks/s]
Processed prompts:  58%|    | 148/256 [00:10<00:08, 13.43it/s, est. speed input: 14024.64 toks/s, output: 13.70 toks/s]
Processed prompts:  59%|    | 150/256 [00:10<00:07, 13.42it/s, est. speed input: 14020.29 toks/s, output: 13.69 toks/s]
Processed prompts:  59%|    | 152/256 [00:11<00:07, 13.22it/s, est. speed input: 14007.08 toks/s, output: 13.68 toks/s]
Processed prompts:  60%|    | 154/256 [00:11<00:07, 13.35it/s, est. speed input: 14006.94 toks/s, output: 13.68 toks/s]
Processed prompts:  61%|    | 156/256 [00:11<00:07, 13.27it/s, est. speed input: 13998.78 toks/s, output: 13.67 toks/s]
Processed prompts:  62%|   | 158/256 [00:11<00:07, 13.32it/s, est. speed input: 13995.72 toks/s, output: 13.67 toks/s]
Processed prompts:  62%|   | 160/256 [00:11<00:07, 13.31it/s, est. speed input: 13990.69 toks/s, output: 13.66 toks/s]
Processed prompts:  63%|   | 162/256 [00:11<00:07, 13.32it/s, est. speed input: 13986.56 toks/s, output: 13.66 toks/s]
Processed prompts:  64%|   | 164/256 [00:12<00:06, 13.33it/s, est. speed input: 13982.54 toks/s, output: 13.65 toks/s]
Processed prompts:  65%|   | 166/256 [00:12<00:06, 13.16it/s, est. speed input: 13971.09 toks/s, output: 13.64 toks/s]
Processed prompts:  66%|   | 168/256 [00:12<00:06, 13.18it/s, est. speed input: 13965.74 toks/s, output: 13.64 toks/s]
Processed prompts:  66%|   | 170/256 [00:12<00:06, 13.15it/s, est. speed input: 13958.71 toks/s, output: 13.63 toks/s]
Processed prompts:  67%|   | 172/256 [00:12<00:06, 13.25it/s, est. speed input: 13956.89 toks/s, output: 13.63 toks/s]
Processed prompts:  68%|   | 174/256 [00:12<00:06, 13.26it/s, est. speed input: 13952.71 toks/s, output: 13.63 toks/s]
Processed prompts:  69%|   | 176/256 [00:12<00:06, 13.28it/s, est. speed input: 13949.11 toks/s, output: 13.62 toks/s]
Processed prompts:  70%|   | 178/256 [00:13<00:05, 13.26it/s, est. speed input: 13944.27 toks/s, output: 13.62 toks/s]
Processed prompts:  70%|   | 180/256 [00:13<00:05, 13.12it/s, est. speed input: 13934.46 toks/s, output: 13.61 toks/s]
Processed prompts:  71%|   | 182/256 [00:13<00:05, 13.24it/s, est. speed input: 13933.53 toks/s, output: 13.61 toks/s]
Processed prompts:  72%|  | 184/256 [00:13<00:05, 13.27it/s, est. speed input: 13930.53 toks/s, output: 13.60 toks/s]
Processed prompts:  73%|  | 186/256 [00:13<00:05, 13.29it/s, est. speed input: 13927.56 toks/s, output: 13.60 toks/s]
Processed prompts:  73%|  | 188/256 [00:13<00:05, 13.33it/s, est. speed input: 13925.76 toks/s, output: 13.60 toks/s]
Processed prompts:  74%|  | 190/256 [00:13<00:04, 13.30it/s, est. speed input: 13921.67 toks/s, output: 13.60 toks/s]
Processed prompts:  75%|  | 192/256 [00:14<00:04, 13.33it/s, est. speed input: 13919.59 toks/s, output: 13.59 toks/s]
Processed prompts:  76%|  | 194/256 [00:14<00:04, 13.16it/s, est. speed input: 13910.24 toks/s, output: 13.58 toks/s]
Processed prompts:  77%|  | 196/256 [00:14<00:04, 13.13it/s, est. speed input: 13904.66 toks/s, output: 13.58 toks/s]
Processed prompts:  77%|  | 198/256 [00:14<00:04, 13.21it/s, est. speed input: 13902.72 toks/s, output: 13.58 toks/s]
Processed prompts:  78%|  | 200/256 [00:14<00:04, 13.29it/s, est. speed input: 13901.77 toks/s, output: 13.58 toks/s]
Processed prompts:  79%|  | 202/256 [00:14<00:04, 13.25it/s, est. speed input: 13897.34 toks/s, output: 13.57 toks/s]
Processed prompts:  80%|  | 204/256 [00:15<00:03, 13.25it/s, est. speed input: 13894.16 toks/s, output: 13.57 toks/s]
Processed prompts:  80%|  | 206/256 [00:15<00:03, 13.27it/s, est. speed input: 13891.59 toks/s, output: 13.57 toks/s]
Processed prompts:  81%| | 208/256 [00:15<00:03, 13.16it/s, est. speed input: 13884.89 toks/s, output: 13.56 toks/s]
Processed prompts:  82%| | 210/256 [00:15<00:03, 13.20it/s, est. speed input: 13882.11 toks/s, output: 13.56 toks/s]
Processed prompts:  83%| | 212/256 [00:15<00:03, 13.21it/s, est. speed input: 13879.07 toks/s, output: 13.55 toks/s]
Processed prompts:  84%| | 214/256 [00:15<00:03, 13.23it/s, est. speed input: 13876.31 toks/s, output: 13.55 toks/s]
Processed prompts:  84%| | 216/256 [00:15<00:03, 13.26it/s, est. speed input: 13874.05 toks/s, output: 13.55 toks/s]
Processed prompts:  85%| | 218/256 [00:16<00:02, 13.26it/s, est. speed input: 13871.42 toks/s, output: 13.55 toks/s]
Processed prompts:  86%| | 220/256 [00:16<00:02, 13.26it/s, est. speed input: 13868.51 toks/s, output: 13.54 toks/s]
Processed prompts:  87%| | 222/256 [00:16<00:02, 13.18it/s, est. speed input: 13863.30 toks/s, output: 13.54 toks/s]
Processed prompts:  88%| | 224/256 [00:16<00:02, 13.22it/s, est. speed input: 13861.13 toks/s, output: 13.54 toks/s]
Processed prompts:  88%| | 226/256 [00:16<00:02, 13.23it/s, est. speed input: 13858.53 toks/s, output: 13.53 toks/s]
Processed prompts:  89%| | 228/256 [00:16<00:02, 13.31it/s, est. speed input: 13858.40 toks/s, output: 13.53 toks/s]
Processed prompts:  90%| | 230/256 [00:16<00:01, 13.32it/s, est. speed input: 13856.51 toks/s, output: 13.53 toks/s]
Processed prompts:  91%| | 232/256 [00:17<00:01, 13.36it/s, est. speed input: 13855.75 toks/s, output: 13.53 toks/s]
Processed prompts:  91%|| 234/256 [00:17<00:01, 13.36it/s, est. speed input: 13854.23 toks/s, output: 13.53 toks/s]
Processed prompts:  92%|| 236/256 [00:17<00:01, 13.21it/s, est. speed input: 13848.31 toks/s, output: 13.52 toks/s]
Processed prompts:  93%|| 238/256 [00:17<00:01, 13.28it/s, est. speed input: 13847.62 toks/s, output: 13.52 toks/s]
Processed prompts:  94%|| 240/256 [00:17<00:01, 13.29it/s, est. speed input: 13845.80 toks/s, output: 13.52 toks/s]
Processed prompts:  95%|| 242/256 [00:17<00:01, 13.31it/s, est. speed input: 13844.31 toks/s, output: 13.52 toks/s]
Processed prompts:  95%|| 244/256 [00:18<00:00, 13.32it/s, est. speed input: 13843.00 toks/s, output: 13.52 toks/s]
Processed prompts:  96%|| 246/256 [00:18<00:00, 13.33it/s, est. speed input: 13841.64 toks/s, output: 13.52 toks/s]
Processed prompts:  97%|| 248/256 [00:18<00:00, 13.37it/s, est. speed input: 13841.07 toks/s, output: 13.52 toks/s]
Processed prompts:  98%|| 250/256 [00:18<00:00, 13.21it/s, est. speed input: 13835.27 toks/s, output: 13.51 toks/s]
Processed prompts:  98%|| 252/256 [00:18<00:00, 13.30it/s, est. speed input: 13835.30 toks/s, output: 13.51 toks/s]
Processed prompts:  99%|| 254/256 [00:18<00:00, 13.37it/s, est. speed input: 13835.62 toks/s, output: 13.51 toks/s]
Processed prompts: 100%|| 256/256 [00:18<00:00, 13.37it/s, est. speed input: 13889.46 toks/s, output: 13.56 toks/s]
Processed prompts: 100%|| 256/256 [00:18<00:00, 13.56it/s, est. speed input: 13889.46 toks/s, output: 13.56 toks/s]
[rank0]:[W126 12:26:09.818697283 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-26 12:26:11
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-3B-FP8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 12:26:16 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 12:26:16 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1285916) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1285916) WARNING 01-26 12:26:49 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 12.62 requests/s, 12933.57 total tokens/s, 12.62 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-26 12:26:16] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 12:26:16] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 12:26:16] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 12:26:16] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:26:16] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:26:16] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:26:16] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:26:16] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:26:16] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 12:26:16] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:26:16] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:26:16] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:26:16] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:26:16] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 12:26:20] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 12:26:20] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 12:26:20] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 12:26:20] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:26:20] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:26:20] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:26:20] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:26:20] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:26:20] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 12:26:20] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:26:20] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:26:20] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:26:20] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:26:20] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1285916) [2026-01-26 12:26:21] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1285916) [2026-01-26 12:26:21] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1285916) [2026-01-26 12:26:21] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1285916) [2026-01-26 12:26:21] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1285916) [2026-01-26 12:26:21] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1285916) [2026-01-26 12:26:21] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1285916) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1285916) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:20<00:00, 20.82s/it]
(EngineCore_DP0 pid=1285916) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:20<00:00, 20.82s/it]
(EngineCore_DP0 pid=1285916) 
(EngineCore_DP0 pid=1285916) [2026-01-26 12:26:42] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4096] -> 1D uint8
(EngineCore_DP0 pid=1285916) [2026-01-26 12:26:42] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 13107200 bytes
(EngineCore_DP0 pid=1285916) [2026-01-26 12:26:42] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4096] -> 1D uint8
(EngineCore_DP0 pid=1285916) [2026-01-26 12:26:42] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 7864320 bytes
(EngineCore_DP0 pid=1285916) [2026-01-26 12:26:42] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4096] -> 1D uint8
(EngineCore_DP0 pid=1285916) [2026-01-26 12:26:42] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 41943040 bytes
(EngineCore_DP0 pid=1285916) [2026-01-26 12:26:42] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 10944] -> 1D uint8
(EngineCore_DP0 pid=1285916) [2026-01-26 12:26:42] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 21037056 bytes
(EngineCore_DP0 pid=1285916) 2026-01-26 12:26:48,326 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1285916) 2026-01-26 12:26:48,336 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   7%|         | 34/512 [00:00<00:01, 334.13it/s]
Adding requests:  15%|        | 79/512 [00:00<00:01, 392.48it/s]
Adding requests:  24%|       | 125/512 [00:00<00:00, 419.44it/s]
Adding requests:  34%|      | 173/512 [00:00<00:00, 442.64it/s]
Adding requests:  43%|     | 222/512 [00:00<00:00, 456.04it/s]
Adding requests:  53%|    | 272/512 [00:00<00:00, 468.68it/s]
Adding requests:  62%|   | 319/512 [00:00<00:00, 463.42it/s]
Adding requests:  72%|  | 368/512 [00:00<00:00, 469.06it/s]
Adding requests:  81%|  | 415/512 [00:00<00:00, 462.85it/s]
Adding requests:  91%| | 464/512 [00:01<00:00, 470.40it/s]
Adding requests: 100%|| 512/512 [00:01<00:00, 466.15it/s]
Adding requests: 100%|| 512/512 [00:01<00:00, 454.22it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   3%|         | 14/512 [00:00<00:10, 46.46it/s, est. speed input: 47574.23 toks/s, output: 46.46 toks/s]
Processed prompts:   4%|         | 19/512 [00:00<00:17, 27.78it/s, est. speed input: 31220.40 toks/s, output: 30.49 toks/s]
Processed prompts:   4%|         | 22/512 [00:00<00:25, 19.46it/s, est. speed input: 24047.81 toks/s, output: 23.48 toks/s]
Processed prompts:   5%|         | 26/512 [00:01<00:28, 16.79it/s, est. speed input: 21275.51 toks/s, output: 20.78 toks/s]
Processed prompts:   6%|         | 30/512 [00:01<00:31, 15.31it/s, est. speed input: 19611.68 toks/s, output: 19.15 toks/s]
Processed prompts:   7%|         | 34/512 [00:01<00:33, 14.36it/s, est. speed input: 18464.04 toks/s, output: 18.03 toks/s]
Processed prompts:   7%|         | 38/512 [00:02<00:34, 13.78it/s, est. speed input: 17662.06 toks/s, output: 17.25 toks/s]
Processed prompts:   8%|         | 42/512 [00:02<00:34, 13.43it/s, est. speed input: 17075.50 toks/s, output: 16.68 toks/s]
Processed prompts:   9%|         | 46/512 [00:02<00:35, 13.18it/s, est. speed input: 16612.60 toks/s, output: 16.22 toks/s]
Processed prompts:  10%|         | 50/512 [00:03<00:35, 13.05it/s, est. speed input: 16261.15 toks/s, output: 15.88 toks/s]
Processed prompts:  11%|         | 54/512 [00:03<00:35, 12.97it/s, est. speed input: 15972.76 toks/s, output: 15.60 toks/s]
Processed prompts:  11%|        | 58/512 [00:03<00:35, 12.86it/s, est. speed input: 15717.07 toks/s, output: 15.35 toks/s]
Processed prompts:  12%|        | 62/512 [00:04<00:35, 12.80it/s, est. speed input: 15503.46 toks/s, output: 15.14 toks/s]
Processed prompts:  13%|        | 66/512 [00:04<00:34, 12.78it/s, est. speed input: 15328.56 toks/s, output: 14.97 toks/s]
Processed prompts:  14%|        | 70/512 [00:04<00:34, 12.78it/s, est. speed input: 15180.07 toks/s, output: 14.82 toks/s]
Processed prompts:  14%|        | 74/512 [00:05<00:34, 12.71it/s, est. speed input: 15032.08 toks/s, output: 14.68 toks/s]
Processed prompts:  15%|        | 78/512 [00:05<00:34, 12.68it/s, est. speed input: 14907.31 toks/s, output: 14.56 toks/s]
Processed prompts:  16%|        | 82/512 [00:05<00:33, 12.69it/s, est. speed input: 14802.27 toks/s, output: 14.46 toks/s]
Processed prompts:  17%|        | 86/512 [00:05<00:33, 12.61it/s, est. speed input: 14691.70 toks/s, output: 14.35 toks/s]
Processed prompts:  18%|        | 90/512 [00:06<00:33, 12.68it/s, est. speed input: 14615.52 toks/s, output: 14.27 toks/s]
Processed prompts:  18%|        | 94/512 [00:06<00:32, 12.70it/s, est. speed input: 14541.57 toks/s, output: 14.20 toks/s]
Processed prompts:  19%|        | 98/512 [00:06<00:32, 12.65it/s, est. speed input: 14463.12 toks/s, output: 14.12 toks/s]
Processed prompts:  20%|        | 102/512 [00:07<00:32, 12.66it/s, est. speed input: 14398.15 toks/s, output: 14.06 toks/s]
Processed prompts:  21%|        | 106/512 [00:07<00:32, 12.66it/s, est. speed input: 14339.28 toks/s, output: 14.00 toks/s]
Processed prompts:  21%|       | 110/512 [00:07<00:31, 12.68it/s, est. speed input: 14286.55 toks/s, output: 13.95 toks/s]
Processed prompts:  22%|       | 114/512 [00:08<00:31, 12.62it/s, est. speed input: 14228.06 toks/s, output: 13.89 toks/s]
Processed prompts:  23%|       | 118/512 [00:08<00:31, 12.60it/s, est. speed input: 14177.19 toks/s, output: 13.84 toks/s]
Processed prompts:  24%|       | 122/512 [00:08<00:30, 12.66it/s, est. speed input: 14139.67 toks/s, output: 13.81 toks/s]
Processed prompts:  25%|       | 126/512 [00:09<00:30, 12.58it/s, est. speed input: 14088.79 toks/s, output: 13.76 toks/s]
Processed prompts:  25%|       | 130/512 [00:09<00:30, 12.60it/s, est. speed input: 14051.02 toks/s, output: 13.72 toks/s]
Processed prompts:  26%|       | 134/512 [00:09<00:29, 12.62it/s, est. speed input: 14015.40 toks/s, output: 13.69 toks/s]
Processed prompts:  27%|       | 138/512 [00:10<00:29, 12.57it/s, est. speed input: 13975.38 toks/s, output: 13.65 toks/s]
Processed prompts:  28%|       | 142/512 [00:10<00:29, 12.60it/s, est. speed input: 13944.73 toks/s, output: 13.62 toks/s]
Processed prompts:  29%|       | 146/512 [00:10<00:29, 12.60it/s, est. speed input: 13914.11 toks/s, output: 13.59 toks/s]
Processed prompts:  29%|       | 150/512 [00:11<00:28, 12.63it/s, est. speed input: 13888.24 toks/s, output: 13.56 toks/s]
Processed prompts:  30%|       | 154/512 [00:11<00:28, 12.61it/s, est. speed input: 13859.36 toks/s, output: 13.53 toks/s]
Processed prompts:  31%|       | 158/512 [00:11<00:28, 12.59it/s, est. speed input: 13831.64 toks/s, output: 13.51 toks/s]
Processed prompts:  32%|      | 162/512 [00:12<00:27, 12.65it/s, est. speed input: 13812.58 toks/s, output: 13.49 toks/s]
Processed prompts:  32%|      | 166/512 [00:12<00:27, 12.61it/s, est. speed input: 13787.05 toks/s, output: 13.46 toks/s]
Processed prompts:  33%|      | 170/512 [00:12<00:27, 12.63it/s, est. speed input: 13767.25 toks/s, output: 13.44 toks/s]
Processed prompts:  34%|      | 174/512 [00:12<00:26, 12.64it/s, est. speed input: 13747.19 toks/s, output: 13.42 toks/s]
Processed prompts:  35%|      | 178/512 [00:13<00:26, 12.64it/s, est. speed input: 13727.98 toks/s, output: 13.41 toks/s]
Processed prompts:  36%|      | 182/512 [00:13<00:26, 12.56it/s, est. speed input: 13702.88 toks/s, output: 13.38 toks/s]
Processed prompts:  36%|      | 186/512 [00:13<00:25, 12.66it/s, est. speed input: 13692.07 toks/s, output: 13.37 toks/s]
Processed prompts:  37%|      | 190/512 [00:14<00:25, 12.65it/s, est. speed input: 13674.77 toks/s, output: 13.35 toks/s]
Processed prompts:  38%|      | 194/512 [00:14<00:25, 12.61it/s, est. speed input: 13655.84 toks/s, output: 13.34 toks/s]
Processed prompts:  39%|      | 198/512 [00:14<00:24, 12.62it/s, est. speed input: 13641.14 toks/s, output: 13.32 toks/s]
Processed prompts:  39%|      | 202/512 [00:15<00:24, 12.65it/s, est. speed input: 13628.15 toks/s, output: 13.31 toks/s]
Processed prompts:  40%|      | 206/512 [00:15<00:24, 12.60it/s, est. speed input: 13610.66 toks/s, output: 13.29 toks/s]
Processed prompts:  41%|      | 210/512 [00:15<00:23, 12.66it/s, est. speed input: 13601.09 toks/s, output: 13.28 toks/s]
Processed prompts:  42%|     | 214/512 [00:16<00:23, 12.67it/s, est. speed input: 13588.99 toks/s, output: 13.27 toks/s]
Processed prompts:  43%|     | 218/512 [00:16<00:23, 12.65it/s, est. speed input: 13576.08 toks/s, output: 13.26 toks/s]
Processed prompts:  43%|     | 222/512 [00:16<00:23, 12.59it/s, est. speed input: 13560.30 toks/s, output: 13.24 toks/s]
Processed prompts:  44%|     | 226/512 [00:17<00:22, 12.59it/s, est. speed input: 13547.69 toks/s, output: 13.23 toks/s]
Processed prompts:  45%|     | 230/512 [00:17<00:22, 12.61it/s, est. speed input: 13537.30 toks/s, output: 13.22 toks/s]
Processed prompts:  46%|     | 234/512 [00:17<00:22, 12.56it/s, est. speed input: 13522.78 toks/s, output: 13.21 toks/s]
Processed prompts:  46%|     | 238/512 [00:18<00:21, 12.63it/s, est. speed input: 13515.28 toks/s, output: 13.20 toks/s]
Processed prompts:  47%|     | 242/512 [00:18<00:21, 12.62it/s, est. speed input: 13504.48 toks/s, output: 13.19 toks/s]
Processed prompts:  48%|     | 246/512 [00:18<00:21, 12.56it/s, est. speed input: 13491.30 toks/s, output: 13.18 toks/s]
Processed prompts:  49%|     | 250/512 [00:18<00:20, 12.57it/s, est. speed input: 13481.48 toks/s, output: 13.17 toks/s]
Processed prompts:  50%|     | 254/512 [00:19<00:20, 12.63it/s, est. speed input: 13474.66 toks/s, output: 13.16 toks/s]
Processed prompts:  50%|     | 258/512 [00:19<00:20, 12.63it/s, est. speed input: 13466.01 toks/s, output: 13.15 toks/s]
Processed prompts:  51%|     | 262/512 [00:19<00:19, 12.55it/s, est. speed input: 13453.22 toks/s, output: 13.14 toks/s]
Processed prompts:  52%|    | 266/512 [00:20<00:19, 12.59it/s, est. speed input: 13445.57 toks/s, output: 13.13 toks/s]
Processed prompts:  53%|    | 270/512 [00:20<00:19, 12.63it/s, est. speed input: 13439.15 toks/s, output: 13.12 toks/s]
Processed prompts:  54%|    | 274/512 [00:20<00:18, 12.61it/s, est. speed input: 13430.66 toks/s, output: 13.12 toks/s]
Processed prompts:  54%|    | 278/512 [00:21<00:18, 12.63it/s, est. speed input: 13423.75 toks/s, output: 13.11 toks/s]
Processed prompts:  55%|    | 282/512 [00:21<00:18, 12.61it/s, est. speed input: 13415.75 toks/s, output: 13.10 toks/s]
Processed prompts:  56%|    | 286/512 [00:21<00:17, 12.60it/s, est. speed input: 13407.66 toks/s, output: 13.09 toks/s]
Processed prompts:  57%|    | 290/512 [00:22<00:17, 12.62it/s, est. speed input: 13401.63 toks/s, output: 13.09 toks/s]
Processed prompts:  57%|    | 294/512 [00:22<00:17, 12.66it/s, est. speed input: 13396.70 toks/s, output: 13.08 toks/s]
Processed prompts:  58%|    | 298/512 [00:22<00:16, 12.64it/s, est. speed input: 13389.99 toks/s, output: 13.08 toks/s]
Processed prompts:  59%|    | 302/512 [00:23<00:16, 12.59it/s, est. speed input: 13381.37 toks/s, output: 13.07 toks/s]
Processed prompts:  60%|    | 306/512 [00:23<00:16, 12.67it/s, est. speed input: 13378.33 toks/s, output: 13.06 toks/s]
Processed prompts:  61%|    | 310/512 [00:23<00:15, 12.71it/s, est. speed input: 13374.92 toks/s, output: 13.06 toks/s]
Processed prompts:  61%|   | 314/512 [00:24<00:15, 12.62it/s, est. speed input: 13366.23 toks/s, output: 13.05 toks/s]
Processed prompts:  62%|   | 318/512 [00:24<00:15, 12.65it/s, est. speed input: 13361.52 toks/s, output: 13.05 toks/s]
Processed prompts:  63%|   | 322/512 [00:24<00:14, 12.68it/s, est. speed input: 13357.74 toks/s, output: 13.04 toks/s]
Processed prompts:  64%|   | 326/512 [00:25<00:14, 12.61it/s, est. speed input: 13349.88 toks/s, output: 13.04 toks/s]
Processed prompts:  64%|   | 330/512 [00:25<00:14, 12.60it/s, est. speed input: 13344.00 toks/s, output: 13.03 toks/s]
Processed prompts:  65%|   | 334/512 [00:25<00:14, 12.63it/s, est. speed input: 13339.68 toks/s, output: 13.03 toks/s]
Processed prompts:  66%|   | 338/512 [00:25<00:13, 12.62it/s, est. speed input: 13334.54 toks/s, output: 13.02 toks/s]
Processed prompts:  67%|   | 342/512 [00:26<00:13, 13.07it/s, est. speed input: 13348.04 toks/s, output: 13.04 toks/s]
Processed prompts:  68%|   | 346/512 [00:26<00:12, 12.95it/s, est. speed input: 13343.59 toks/s, output: 13.03 toks/s]
Processed prompts:  68%|   | 350/512 [00:26<00:12, 12.87it/s, est. speed input: 13339.49 toks/s, output: 13.03 toks/s]
Processed prompts:  69%|   | 354/512 [00:27<00:12, 12.73it/s, est. speed input: 13332.05 toks/s, output: 13.02 toks/s]
Processed prompts:  70%|   | 358/512 [00:27<00:12, 12.72it/s, est. speed input: 13328.14 toks/s, output: 13.02 toks/s]
Processed prompts:  71%|   | 362/512 [00:27<00:11, 12.73it/s, est. speed input: 13325.05 toks/s, output: 13.01 toks/s]
Processed prompts:  71%|  | 366/512 [00:28<00:11, 12.69it/s, est. speed input: 13320.46 toks/s, output: 13.01 toks/s]
Processed prompts:  72%|  | 370/512 [00:28<00:11, 12.62it/s, est. speed input: 13314.12 toks/s, output: 13.00 toks/s]
Processed prompts:  73%|  | 374/512 [00:28<00:10, 12.62it/s, est. speed input: 13309.77 toks/s, output: 13.00 toks/s]
Processed prompts:  74%|  | 378/512 [00:29<00:10, 12.62it/s, est. speed input: 13305.72 toks/s, output: 12.99 toks/s]
Processed prompts:  75%|  | 382/512 [00:29<00:10, 12.57it/s, est. speed input: 13299.74 toks/s, output: 12.99 toks/s]
Processed prompts:  75%|  | 386/512 [00:29<00:10, 12.59it/s, est. speed input: 13295.96 toks/s, output: 12.98 toks/s]
Processed prompts:  76%|  | 390/512 [00:30<00:09, 12.62it/s, est. speed input: 13292.52 toks/s, output: 12.98 toks/s]
Processed prompts:  77%|  | 394/512 [00:30<00:09, 12.57it/s, est. speed input: 13286.77 toks/s, output: 12.98 toks/s]
Processed prompts:  78%|  | 398/512 [00:30<00:09, 12.60it/s, est. speed input: 13283.54 toks/s, output: 12.97 toks/s]
Processed prompts:  79%|  | 402/512 [00:30<00:08, 12.64it/s, est. speed input: 13281.21 toks/s, output: 12.97 toks/s]
Processed prompts:  79%|  | 406/512 [00:31<00:08, 12.69it/s, est. speed input: 13279.41 toks/s, output: 12.97 toks/s]
Processed prompts:  80%|  | 410/512 [00:31<00:08, 12.64it/s, est. speed input: 13274.95 toks/s, output: 12.96 toks/s]
Processed prompts:  81%|  | 414/512 [00:31<00:07, 12.68it/s, est. speed input: 13272.90 toks/s, output: 12.96 toks/s]
Processed prompts:  82%| | 418/512 [00:32<00:07, 12.65it/s, est. speed input: 13269.03 toks/s, output: 12.96 toks/s]
Processed prompts:  82%| | 422/512 [00:32<00:07, 12.58it/s, est. speed input: 13263.56 toks/s, output: 12.95 toks/s]
Processed prompts:  83%| | 426/512 [00:32<00:06, 12.63it/s, est. speed input: 13261.67 toks/s, output: 12.95 toks/s]
Processed prompts:  84%| | 430/512 [00:33<00:06, 12.67it/s, est. speed input: 13259.83 toks/s, output: 12.95 toks/s]
Processed prompts:  85%| | 434/512 [00:33<00:06, 12.58it/s, est. speed input: 13254.10 toks/s, output: 12.94 toks/s]
Processed prompts:  86%| | 438/512 [00:33<00:05, 12.58it/s, est. speed input: 13250.62 toks/s, output: 12.94 toks/s]
Processed prompts:  86%| | 442/512 [00:34<00:05, 12.59it/s, est. speed input: 13247.42 toks/s, output: 12.94 toks/s]
Processed prompts:  87%| | 446/512 [00:34<00:05, 12.65it/s, est. speed input: 13246.10 toks/s, output: 12.94 toks/s]
Processed prompts:  88%| | 450/512 [00:34<00:04, 13.24it/s, est. speed input: 13261.34 toks/s, output: 12.95 toks/s]
Processed prompts:  89%| | 454/512 [00:35<00:04, 13.03it/s, est. speed input: 13257.70 toks/s, output: 12.95 toks/s]
Processed prompts:  89%| | 458/512 [00:35<00:04, 12.96it/s, est. speed input: 13256.41 toks/s, output: 12.95 toks/s]
Processed prompts:  90%| | 462/512 [00:35<00:03, 12.78it/s, est. speed input: 13251.14 toks/s, output: 12.94 toks/s]
Processed prompts:  91%| | 466/512 [00:36<00:03, 12.74it/s, est. speed input: 13248.59 toks/s, output: 12.94 toks/s]
Processed prompts:  92%|| 470/512 [00:36<00:03, 12.69it/s, est. speed input: 13245.38 toks/s, output: 12.93 toks/s]
Processed prompts:  93%|| 474/512 [00:36<00:03, 12.66it/s, est. speed input: 13242.36 toks/s, output: 12.93 toks/s]
Processed prompts:  93%|| 478/512 [00:36<00:02, 12.61it/s, est. speed input: 13238.43 toks/s, output: 12.93 toks/s]
Processed prompts:  94%|| 482/512 [00:37<00:02, 12.64it/s, est. speed input: 13236.41 toks/s, output: 12.93 toks/s]
Processed prompts:  95%|| 486/512 [00:37<00:02, 12.65it/s, est. speed input: 13234.19 toks/s, output: 12.92 toks/s]
Processed prompts:  96%|| 490/512 [00:37<00:01, 12.59it/s, est. speed input: 13230.24 toks/s, output: 12.92 toks/s]
Processed prompts:  96%|| 494/512 [00:38<00:01, 12.60it/s, est. speed input: 13227.55 toks/s, output: 12.92 toks/s]
Processed prompts:  97%|| 498/512 [00:38<00:01, 12.64it/s, est. speed input: 13226.02 toks/s, output: 12.92 toks/s]
Processed prompts:  98%|| 502/512 [00:38<00:00, 12.61it/s, est. speed input: 13222.95 toks/s, output: 12.91 toks/s]
Processed prompts:  99%|| 506/512 [00:39<00:00, 12.62it/s, est. speed input: 13220.69 toks/s, output: 12.91 toks/s]
Processed prompts: 100%|| 510/512 [00:39<00:00, 13.39it/s, est. speed input: 13238.64 toks/s, output: 12.93 toks/s]
Processed prompts: 100%|| 512/512 [00:39<00:00, 13.39it/s, est. speed input: 13290.53 toks/s, output: 12.98 toks/s]
Processed prompts: 100%|| 512/512 [00:39<00:00, 12.98it/s, est. speed input: 13290.53 toks/s, output: 12.98 toks/s]
[rank0]:[W126 12:27:30.249846209 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-26 12:27:32
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-3B-FP8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 12:27:38 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 12:27:38 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1287231) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1287231) WARNING 01-26 12:28:12 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 12.58 requests/s, 12892.44 total tokens/s, 12.58 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-26 12:27:38] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 12:27:38] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 12:27:38] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 12:27:38] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:27:38] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:27:38] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:27:38] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:27:38] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:27:38] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 12:27:38] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:27:38] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:27:38] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:27:38] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:27:38] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 12:27:42] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 12:27:42] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 12:27:42] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 12:27:42] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:27:42] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:27:42] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:27:42] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:27:42] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:27:42] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 12:27:42] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:27:42] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:27:42] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:27:42] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:27:42] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1287231) [2026-01-26 12:27:43] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1287231) [2026-01-26 12:27:43] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1287231) [2026-01-26 12:27:43] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1287231) [2026-01-26 12:27:43] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1287231) [2026-01-26 12:27:43] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1287231) [2026-01-26 12:27:43] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1287231) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1287231) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:20<00:00, 20.95s/it]
(EngineCore_DP0 pid=1287231) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:20<00:00, 20.95s/it]
(EngineCore_DP0 pid=1287231) 
(EngineCore_DP0 pid=1287231) [2026-01-26 12:28:05] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4096] -> 1D uint8
(EngineCore_DP0 pid=1287231) [2026-01-26 12:28:05] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 13107200 bytes
(EngineCore_DP0 pid=1287231) [2026-01-26 12:28:05] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4096] -> 1D uint8
(EngineCore_DP0 pid=1287231) [2026-01-26 12:28:05] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 7864320 bytes
(EngineCore_DP0 pid=1287231) [2026-01-26 12:28:05] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4096] -> 1D uint8
(EngineCore_DP0 pid=1287231) [2026-01-26 12:28:05] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 41943040 bytes
(EngineCore_DP0 pid=1287231) [2026-01-26 12:28:05] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 10944] -> 1D uint8
(EngineCore_DP0 pid=1287231) [2026-01-26 12:28:05] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 21037056 bytes
(EngineCore_DP0 pid=1287231) 2026-01-26 12:28:10,809 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1287231) 2026-01-26 12:28:10,869 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   5%|         | 53/1024 [00:00<00:01, 518.20it/s]
Adding requests:  10%|         | 105/1024 [00:00<00:01, 467.16it/s]
Adding requests:  15%|        | 153/1024 [00:00<00:01, 454.73it/s]
Adding requests:  20%|        | 201/1024 [00:00<00:01, 462.08it/s]
Adding requests:  24%|       | 249/1024 [00:00<00:01, 467.32it/s]
Adding requests:  29%|       | 296/1024 [00:00<00:01, 466.58it/s]
Adding requests:  34%|      | 345/1024 [00:00<00:01, 473.80it/s]
Adding requests:  39%|      | 395/1024 [00:00<00:01, 481.68it/s]
Adding requests:  43%|     | 444/1024 [00:00<00:01, 477.45it/s]
Adding requests:  48%|     | 492/1024 [00:01<00:01, 477.13it/s]
Adding requests:  53%|    | 540/1024 [00:01<00:01, 470.95it/s]
Adding requests:  58%|    | 591/1024 [00:01<00:00, 481.30it/s]
Adding requests:  62%|   | 640/1024 [00:01<00:00, 467.37it/s]
Adding requests:  67%|   | 688/1024 [00:01<00:00, 470.01it/s]
Adding requests:  72%|  | 736/1024 [00:01<00:00, 462.92it/s]
Adding requests:  76%|  | 783/1024 [00:01<00:00, 459.72it/s]
Adding requests:  81%|  | 830/1024 [00:01<00:00, 458.19it/s]
Adding requests:  86%| | 879/1024 [00:01<00:00, 464.77it/s]
Adding requests:  91%| | 930/1024 [00:01<00:00, 475.76it/s]
Adding requests:  96%|| 978/1024 [00:02<00:00, 476.28it/s]
Adding requests: 100%|| 1024/1024 [00:02<00:00, 470.22it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   3%|         | 26/1024 [00:00<00:20, 49.07it/s, est. speed input: 50245.97 toks/s, output: 49.07 toks/s]
Processed prompts:   3%|         | 34/1024 [00:01<00:37, 26.10it/s, est. speed input: 29942.14 toks/s, output: 29.24 toks/s]
Processed prompts:   4%|         | 42/1024 [00:01<00:49, 19.70it/s, est. speed input: 23930.29 toks/s, output: 23.37 toks/s]
Processed prompts:   5%|         | 50/1024 [00:02<00:57, 16.82it/s, est. speed input: 21043.86 toks/s, output: 20.55 toks/s]
Processed prompts:   6%|         | 58/1024 [00:03<01:03, 15.30it/s, est. speed input: 19372.76 toks/s, output: 18.92 toks/s]
Processed prompts:   6%|         | 66/1024 [00:03<01:06, 14.37it/s, est. speed input: 18262.82 toks/s, output: 17.83 toks/s]
Processed prompts:   7%|         | 74/1024 [00:04<01:08, 13.80it/s, est. speed input: 17487.97 toks/s, output: 17.08 toks/s]
Processed prompts:   8%|         | 82/1024 [00:04<01:10, 13.44it/s, est. speed input: 16910.86 toks/s, output: 16.51 toks/s]
Processed prompts:   9%|         | 90/1024 [00:05<01:10, 13.17it/s, est. speed input: 16454.61 toks/s, output: 16.07 toks/s]
Processed prompts:  10%|         | 98/1024 [00:06<01:11, 13.02it/s, est. speed input: 16103.51 toks/s, output: 15.73 toks/s]
Processed prompts:  10%|         | 106/1024 [00:06<01:11, 12.86it/s, est. speed input: 15797.74 toks/s, output: 15.43 toks/s]
Processed prompts:  11%|         | 114/1024 [00:07<01:11, 12.78it/s, est. speed input: 15551.09 toks/s, output: 15.19 toks/s]
Processed prompts:  12%|        | 122/1024 [00:08<01:10, 12.74it/s, est. speed input: 15349.87 toks/s, output: 14.99 toks/s]
Processed prompts:  13%|        | 130/1024 [00:08<01:10, 12.68it/s, est. speed input: 15168.25 toks/s, output: 14.81 toks/s]
Processed prompts:  13%|        | 138/1024 [00:09<01:09, 12.68it/s, est. speed input: 15021.34 toks/s, output: 14.67 toks/s]
Processed prompts:  14%|        | 146/1024 [00:10<01:09, 12.65it/s, est. speed input: 14886.81 toks/s, output: 14.54 toks/s]
Processed prompts:  15%|        | 154/1024 [00:10<01:08, 12.63it/s, est. speed input: 14766.36 toks/s, output: 14.42 toks/s]
Processed prompts:  16%|        | 162/1024 [00:11<01:08, 12.62it/s, est. speed input: 14661.89 toks/s, output: 14.32 toks/s]
Processed prompts:  17%|        | 170/1024 [00:11<01:07, 12.60it/s, est. speed input: 14566.44 toks/s, output: 14.23 toks/s]
Processed prompts:  17%|        | 178/1024 [00:12<01:06, 12.64it/s, est. speed input: 14489.45 toks/s, output: 14.15 toks/s]
Processed prompts:  18%|        | 186/1024 [00:13<01:06, 12.62it/s, est. speed input: 14411.75 toks/s, output: 14.07 toks/s]
Processed prompts:  19%|        | 194/1024 [00:13<01:05, 12.63it/s, est. speed input: 14344.63 toks/s, output: 14.01 toks/s]
Processed prompts:  20%|        | 202/1024 [00:14<01:05, 12.60it/s, est. speed input: 14278.52 toks/s, output: 13.94 toks/s]
Processed prompts:  21%|        | 210/1024 [00:15<01:04, 12.57it/s, est. speed input: 14215.26 toks/s, output: 13.88 toks/s]
Processed prompts:  21%|       | 218/1024 [00:15<01:03, 12.60it/s, est. speed input: 14165.91 toks/s, output: 13.83 toks/s]
Processed prompts:  22%|       | 226/1024 [00:16<01:03, 12.59it/s, est. speed input: 14115.66 toks/s, output: 13.78 toks/s]
Processed prompts:  23%|       | 234/1024 [00:17<01:02, 12.61it/s, est. speed input: 14072.62 toks/s, output: 13.74 toks/s]
Processed prompts:  24%|       | 242/1024 [00:17<01:01, 12.63it/s, est. speed input: 14033.56 toks/s, output: 13.70 toks/s]
Processed prompts:  24%|       | 250/1024 [00:18<01:01, 12.59it/s, est. speed input: 13990.03 toks/s, output: 13.66 toks/s]
Processed prompts:  25%|       | 258/1024 [00:18<01:00, 12.61it/s, est. speed input: 13955.91 toks/s, output: 13.63 toks/s]
Processed prompts:  26%|       | 266/1024 [00:19<01:00, 12.58it/s, est. speed input: 13918.06 toks/s, output: 13.59 toks/s]
Processed prompts:  27%|       | 274/1024 [00:20<00:59, 12.58it/s, est. speed input: 13885.72 toks/s, output: 13.56 toks/s]
Processed prompts:  28%|       | 282/1024 [00:20<00:58, 12.58it/s, est. speed input: 13855.33 toks/s, output: 13.53 toks/s]
Processed prompts:  28%|       | 290/1024 [00:21<00:58, 12.57it/s, est. speed input: 13825.67 toks/s, output: 13.50 toks/s]
Processed prompts:  29%|       | 298/1024 [00:22<00:57, 12.60it/s, est. speed input: 13801.34 toks/s, output: 13.48 toks/s]
Processed prompts:  30%|       | 306/1024 [00:22<00:57, 12.58it/s, est. speed input: 13774.17 toks/s, output: 13.45 toks/s]
Processed prompts:  31%|       | 314/1024 [00:23<00:56, 12.60it/s, est. speed input: 13752.14 toks/s, output: 13.43 toks/s]
Processed prompts:  31%|      | 322/1024 [00:24<00:55, 12.58it/s, est. speed input: 13727.38 toks/s, output: 13.41 toks/s]
Processed prompts:  32%|      | 330/1024 [00:24<00:55, 12.57it/s, est. speed input: 13705.13 toks/s, output: 13.38 toks/s]
Processed prompts:  33%|      | 338/1024 [00:25<00:53, 12.87it/s, est. speed input: 13710.32 toks/s, output: 13.39 toks/s]
Processed prompts:  34%|      | 346/1024 [00:25<00:53, 12.77it/s, est. speed input: 13689.27 toks/s, output: 13.37 toks/s]
Processed prompts:  35%|      | 354/1024 [00:26<00:52, 12.72it/s, est. speed input: 13670.80 toks/s, output: 13.35 toks/s]
Processed prompts:  35%|      | 362/1024 [00:27<00:52, 12.67it/s, est. speed input: 13651.58 toks/s, output: 13.33 toks/s]
Processed prompts:  36%|      | 370/1024 [00:27<00:51, 12.64it/s, est. speed input: 13633.70 toks/s, output: 13.31 toks/s]
Processed prompts:  37%|      | 378/1024 [00:28<00:51, 12.65it/s, est. speed input: 13618.84 toks/s, output: 13.30 toks/s]
Processed prompts:  38%|      | 386/1024 [00:29<00:50, 12.59it/s, est. speed input: 13600.16 toks/s, output: 13.28 toks/s]
Processed prompts:  38%|      | 394/1024 [00:29<00:50, 12.60it/s, est. speed input: 13585.53 toks/s, output: 13.27 toks/s]
Processed prompts:  39%|      | 402/1024 [00:30<00:50, 12.21it/s, est. speed input: 13541.12 toks/s, output: 13.22 toks/s]
Processed prompts:  40%|      | 410/1024 [00:31<00:49, 12.30it/s, est. speed input: 13526.37 toks/s, output: 13.21 toks/s]
Processed prompts:  41%|      | 418/1024 [00:31<00:48, 12.39it/s, est. speed input: 13513.60 toks/s, output: 13.20 toks/s]
Processed prompts:  42%|     | 426/1024 [00:32<00:48, 12.42it/s, est. speed input: 13499.43 toks/s, output: 13.18 toks/s]
Processed prompts:  42%|     | 434/1024 [00:32<00:47, 12.48it/s, est. speed input: 13488.43 toks/s, output: 13.17 toks/s]
Processed prompts:  43%|     | 442/1024 [00:33<00:46, 12.49it/s, est. speed input: 13475.24 toks/s, output: 13.16 toks/s]
Processed prompts:  44%|     | 450/1024 [00:34<00:44, 12.87it/s, est. speed input: 13487.27 toks/s, output: 13.17 toks/s]
Processed prompts:  45%|     | 458/1024 [00:34<00:44, 12.77it/s, est. speed input: 13475.37 toks/s, output: 13.16 toks/s]
Processed prompts:  46%|     | 466/1024 [00:35<00:44, 12.67it/s, est. speed input: 13462.44 toks/s, output: 13.15 toks/s]
Processed prompts:  46%|     | 474/1024 [00:36<00:43, 12.66it/s, est. speed input: 13453.35 toks/s, output: 13.14 toks/s]
Processed prompts:  47%|     | 482/1024 [00:36<00:42, 12.63it/s, est. speed input: 13443.09 toks/s, output: 13.13 toks/s]
Processed prompts:  48%|     | 490/1024 [00:37<00:42, 12.64it/s, est. speed input: 13434.71 toks/s, output: 13.12 toks/s]
Processed prompts:  49%|     | 498/1024 [00:37<00:41, 12.63it/s, est. speed input: 13426.25 toks/s, output: 13.11 toks/s]
Processed prompts:  49%|     | 506/1024 [00:38<00:41, 12.59it/s, est. speed input: 13415.60 toks/s, output: 13.10 toks/s]
Processed prompts:  50%|     | 514/1024 [00:39<00:40, 12.59it/s, est. speed input: 13407.32 toks/s, output: 13.09 toks/s]
Processed prompts:  51%|     | 522/1024 [00:39<00:39, 12.56it/s, est. speed input: 13397.60 toks/s, output: 13.08 toks/s]
Processed prompts:  52%|    | 530/1024 [00:40<00:39, 12.59it/s, est. speed input: 13390.83 toks/s, output: 13.08 toks/s]
Processed prompts:  53%|    | 538/1024 [00:41<00:38, 12.58it/s, est. speed input: 13382.60 toks/s, output: 13.07 toks/s]
Processed prompts:  53%|    | 546/1024 [00:41<00:37, 12.58it/s, est. speed input: 13374.86 toks/s, output: 13.06 toks/s]
Processed prompts:  54%|    | 554/1024 [00:42<00:37, 12.58it/s, est. speed input: 13367.30 toks/s, output: 13.05 toks/s]
Processed prompts:  55%|    | 562/1024 [00:43<00:36, 12.57it/s, est. speed input: 13359.85 toks/s, output: 13.05 toks/s]
Processed prompts:  56%|    | 570/1024 [00:43<00:36, 12.57it/s, est. speed input: 13352.92 toks/s, output: 13.04 toks/s]
Processed prompts:  56%|    | 578/1024 [00:44<00:35, 12.56it/s, est. speed input: 13345.55 toks/s, output: 13.03 toks/s]
Processed prompts:  57%|    | 586/1024 [00:44<00:34, 12.55it/s, est. speed input: 13338.21 toks/s, output: 13.03 toks/s]
Processed prompts:  58%|    | 594/1024 [00:45<00:34, 12.55it/s, est. speed input: 13331.38 toks/s, output: 13.02 toks/s]
Processed prompts:  59%|    | 602/1024 [00:46<00:33, 12.51it/s, est. speed input: 13322.87 toks/s, output: 13.01 toks/s]
Processed prompts:  60%|    | 610/1024 [00:46<00:32, 12.55it/s, est. speed input: 13317.88 toks/s, output: 13.01 toks/s]
Processed prompts:  60%|    | 618/1024 [00:47<00:32, 12.55it/s, est. speed input: 13311.35 toks/s, output: 13.00 toks/s]
Processed prompts:  61%|    | 626/1024 [00:48<00:31, 12.57it/s, est. speed input: 13306.08 toks/s, output: 12.99 toks/s]
Processed prompts:  62%|   | 634/1024 [00:48<00:30, 12.58it/s, est. speed input: 13301.24 toks/s, output: 12.99 toks/s]
Processed prompts:  63%|   | 642/1024 [00:49<00:30, 12.57it/s, est. speed input: 13295.33 toks/s, output: 12.98 toks/s]
Processed prompts:  63%|   | 650/1024 [00:50<00:29, 12.58it/s, est. speed input: 13290.35 toks/s, output: 12.98 toks/s]
Processed prompts:  64%|   | 658/1024 [00:50<00:29, 12.56it/s, est. speed input: 13284.45 toks/s, output: 12.97 toks/s]
Processed prompts:  65%|   | 666/1024 [00:51<00:28, 12.56it/s, est. speed input: 13279.30 toks/s, output: 12.97 toks/s]
Processed prompts:  66%|   | 674/1024 [00:51<00:27, 12.56it/s, est. speed input: 13274.17 toks/s, output: 12.96 toks/s]
Processed prompts:  67%|   | 682/1024 [00:52<00:27, 12.55it/s, est. speed input: 13268.64 toks/s, output: 12.96 toks/s]
Processed prompts:  67%|   | 690/1024 [00:53<00:26, 12.54it/s, est. speed input: 13263.45 toks/s, output: 12.95 toks/s]
Processed prompts:  68%|   | 698/1024 [00:53<00:25, 12.54it/s, est. speed input: 13258.29 toks/s, output: 12.95 toks/s]
Processed prompts:  69%|   | 706/1024 [00:54<00:25, 12.51it/s, est. speed input: 13252.19 toks/s, output: 12.94 toks/s]
Processed prompts:  70%|   | 714/1024 [00:55<00:24, 12.53it/s, est. speed input: 13248.03 toks/s, output: 12.94 toks/s]
Processed prompts:  71%|   | 722/1024 [00:55<00:24, 12.52it/s, est. speed input: 13242.80 toks/s, output: 12.93 toks/s]
Processed prompts:  71%|  | 730/1024 [00:56<00:23, 12.55it/s, est. speed input: 13239.02 toks/s, output: 12.93 toks/s]
Processed prompts:  72%|  | 738/1024 [00:57<00:22, 12.53it/s, est. speed input: 13234.03 toks/s, output: 12.92 toks/s]
Processed prompts:  73%|  | 746/1024 [00:57<00:22, 12.52it/s, est. speed input: 13228.98 toks/s, output: 12.92 toks/s]
Processed prompts:  74%|  | 754/1024 [00:58<00:21, 12.56it/s, est. speed input: 13226.26 toks/s, output: 12.92 toks/s]
Processed prompts:  74%|  | 762/1024 [00:59<00:20, 12.53it/s, est. speed input: 13221.14 toks/s, output: 12.91 toks/s]
Processed prompts:  75%|  | 770/1024 [00:59<00:20, 12.52it/s, est. speed input: 13216.75 toks/s, output: 12.91 toks/s]
Processed prompts:  76%|  | 778/1024 [01:00<00:19, 12.54it/s, est. speed input: 13213.05 toks/s, output: 12.90 toks/s]
Processed prompts:  77%|  | 786/1024 [01:00<00:19, 12.52it/s, est. speed input: 13208.48 toks/s, output: 12.90 toks/s]
Processed prompts:  78%|  | 794/1024 [01:01<00:18, 12.54it/s, est. speed input: 13205.06 toks/s, output: 12.90 toks/s]
Processed prompts:  78%|  | 802/1024 [01:02<00:17, 12.54it/s, est. speed input: 13201.33 toks/s, output: 12.89 toks/s]
Processed prompts:  79%|  | 810/1024 [01:02<00:17, 12.55it/s, est. speed input: 13198.25 toks/s, output: 12.89 toks/s]
Processed prompts:  80%|  | 818/1024 [01:03<00:16, 12.54it/s, est. speed input: 13194.35 toks/s, output: 12.89 toks/s]
Processed prompts:  81%|  | 826/1024 [01:04<00:15, 12.51it/s, est. speed input: 13189.84 toks/s, output: 12.88 toks/s]
Processed prompts:  81%| | 834/1024 [01:04<00:15, 12.56it/s, est. speed input: 13187.77 toks/s, output: 12.88 toks/s]
Processed prompts:  82%| | 842/1024 [01:05<00:14, 12.53it/s, est. speed input: 13183.71 toks/s, output: 12.87 toks/s]
Processed prompts:  83%| | 850/1024 [01:06<00:13, 12.55it/s, est. speed input: 13180.76 toks/s, output: 12.87 toks/s]
Processed prompts:  84%| | 858/1024 [01:06<00:13, 12.52it/s, est. speed input: 13176.66 toks/s, output: 12.87 toks/s]
Processed prompts:  85%| | 866/1024 [01:07<00:12, 12.52it/s, est. speed input: 13173.28 toks/s, output: 12.86 toks/s]
Processed prompts:  85%| | 874/1024 [01:07<00:11, 12.52it/s, est. speed input: 13170.07 toks/s, output: 12.86 toks/s]
Processed prompts:  86%| | 882/1024 [01:08<00:11, 12.51it/s, est. speed input: 13166.55 toks/s, output: 12.86 toks/s]
Processed prompts:  87%| | 890/1024 [01:09<00:10, 12.53it/s, est. speed input: 13163.79 toks/s, output: 12.86 toks/s]
Processed prompts:  88%| | 898/1024 [01:09<00:10, 12.53it/s, est. speed input: 13160.61 toks/s, output: 12.85 toks/s]
Processed prompts:  88%| | 906/1024 [01:10<00:09, 12.51it/s, est. speed input: 13157.24 toks/s, output: 12.85 toks/s]
Processed prompts:  89%| | 914/1024 [01:11<00:08, 12.56it/s, est. speed input: 13155.68 toks/s, output: 12.85 toks/s]
Processed prompts:  90%| | 922/1024 [01:11<00:08, 12.55it/s, est. speed input: 13152.83 toks/s, output: 12.84 toks/s]
Processed prompts:  91%| | 930/1024 [01:12<00:07, 12.56it/s, est. speed input: 13150.27 toks/s, output: 12.84 toks/s]
Processed prompts:  92%|| 938/1024 [01:12<00:06, 12.98it/s, est. speed input: 13160.31 toks/s, output: 12.85 toks/s]
Processed prompts:  92%|| 946/1024 [01:13<00:06, 12.83it/s, est. speed input: 13156.98 toks/s, output: 12.85 toks/s]
Processed prompts:  93%|| 954/1024 [01:14<00:05, 12.74it/s, est. speed input: 13154.40 toks/s, output: 12.85 toks/s]
Processed prompts:  94%|| 962/1024 [01:14<00:04, 12.65it/s, est. speed input: 13150.76 toks/s, output: 12.84 toks/s]
Processed prompts:  95%|| 970/1024 [01:15<00:04, 12.65it/s, est. speed input: 13149.14 toks/s, output: 12.84 toks/s]
Processed prompts:  96%|| 978/1024 [01:16<00:03, 12.59it/s, est. speed input: 13145.67 toks/s, output: 12.84 toks/s]
Processed prompts:  96%|| 986/1024 [01:16<00:02, 13.04it/s, est. speed input: 13156.12 toks/s, output: 12.85 toks/s]
Processed prompts:  97%|| 994/1024 [01:17<00:02, 12.88it/s, est. speed input: 13153.46 toks/s, output: 12.85 toks/s]
Processed prompts:  98%|| 1002/1024 [01:18<00:01, 12.76it/s, est. speed input: 13150.49 toks/s, output: 12.84 toks/s]
Processed prompts:  99%|| 1010/1024 [01:18<00:01, 12.73it/s, est. speed input: 13148.80 toks/s, output: 12.84 toks/s]
Processed prompts:  99%|| 1018/1024 [01:19<00:00, 13.05it/s, est. speed input: 13156.64 toks/s, output: 12.85 toks/s]
Processed prompts: 100%|| 1024/1024 [01:19<00:00, 13.05it/s, est. speed input: 13234.16 toks/s, output: 12.92 toks/s]
Processed prompts: 100%|| 1024/1024 [01:19<00:00, 12.92it/s, est. speed input: 13234.16 toks/s, output: 12.92 toks/s]
[rank0]:[W126 12:29:33.880299761 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-26 12:29:36
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-3B-FP8_M16384.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 12:29:45 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 12:29:45 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1289180) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1289180) WARNING 01-26 12:30:19 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 12.72 requests/s, 13041.45 total tokens/s, 12.72 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-26 12:29:45] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 12:29:45] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 12:29:45] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 12:29:45] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:29:45] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:29:45] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:29:45] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:29:45] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:29:45] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 12:29:45] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:29:45] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:29:45] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:29:45] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:29:45] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 12:29:48] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 12:29:48] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 12:29:48] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 12:29:48] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:29:48] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:29:48] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:29:48] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:29:48] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:29:48] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 12:29:48] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:29:48] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:29:48] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:29:48] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:29:48] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1289180) [2026-01-26 12:29:49] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1289180) [2026-01-26 12:29:49] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1289180) [2026-01-26 12:29:49] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1289180) [2026-01-26 12:29:49] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1289180) [2026-01-26 12:29:49] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1289180) [2026-01-26 12:29:49] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1289180) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1289180) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:20<00:00, 20.89s/it]
(EngineCore_DP0 pid=1289180) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:20<00:00, 20.89s/it]
(EngineCore_DP0 pid=1289180) 
(EngineCore_DP0 pid=1289180) [2026-01-26 12:30:11] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4096] -> 1D uint8
(EngineCore_DP0 pid=1289180) [2026-01-26 12:30:11] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 13107200 bytes
(EngineCore_DP0 pid=1289180) [2026-01-26 12:30:11] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4096] -> 1D uint8
(EngineCore_DP0 pid=1289180) [2026-01-26 12:30:11] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 7864320 bytes
(EngineCore_DP0 pid=1289180) [2026-01-26 12:30:11] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4096] -> 1D uint8
(EngineCore_DP0 pid=1289180) [2026-01-26 12:30:11] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 41943040 bytes
(EngineCore_DP0 pid=1289180) [2026-01-26 12:30:11] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 10944] -> 1D uint8
(EngineCore_DP0 pid=1289180) [2026-01-26 12:30:11] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 21037056 bytes
(EngineCore_DP0 pid=1289180) 2026-01-26 12:30:17,788 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1289180) 2026-01-26 12:30:17,904 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   3%|         | 56/2048 [00:00<00:03, 546.76it/s]
Adding requests:   5%|         | 111/2048 [00:00<00:03, 493.49it/s]
Adding requests:   8%|         | 163/2048 [00:00<00:03, 503.53it/s]
Adding requests:  10%|         | 214/2048 [00:00<00:03, 502.69it/s]
Adding requests:  13%|        | 269/2048 [00:00<00:03, 516.60it/s]
Adding requests:  16%|        | 321/2048 [00:00<00:03, 507.36it/s]
Adding requests:  18%|        | 376/2048 [00:00<00:03, 517.20it/s]
Adding requests:  21%|        | 428/2048 [00:00<00:03, 517.15it/s]
Adding requests:  23%|       | 480/2048 [00:00<00:03, 514.25it/s]
Adding requests:  26%|       | 532/2048 [00:01<00:03, 501.07it/s]
Adding requests:  29%|       | 584/2048 [00:01<00:02, 505.17it/s]
Adding requests:  31%|       | 637/2048 [00:01<00:02, 512.01it/s]
Adding requests:  34%|      | 691/2048 [00:01<00:02, 518.47it/s]
Adding requests:  36%|      | 743/2048 [00:01<00:02, 510.45it/s]
Adding requests:  39%|      | 795/2048 [00:01<00:02, 481.33it/s]
Adding requests:  41%|      | 844/2048 [00:01<00:02, 482.73it/s]
Adding requests:  44%|     | 893/2048 [00:02<00:06, 187.33it/s]
Adding requests:  46%|     | 945/2048 [00:02<00:04, 232.21it/s]
Adding requests:  49%|     | 994/2048 [00:02<00:03, 274.10it/s]
Adding requests:  51%|     | 1045/2048 [00:02<00:03, 318.00it/s]
Adding requests:  53%|    | 1093/2048 [00:02<00:02, 352.33it/s]
Adding requests:  56%|    | 1142/2048 [00:02<00:02, 383.78it/s]
Adding requests:  58%|    | 1196/2048 [00:02<00:02, 421.43it/s]
Adding requests:  61%|    | 1247/2048 [00:03<00:01, 443.10it/s]
Adding requests:  63%|   | 1298/2048 [00:03<00:01, 459.61it/s]
Adding requests:  66%|   | 1350/2048 [00:03<00:01, 475.94it/s]
Adding requests:  69%|   | 1403/2048 [00:03<00:01, 489.25it/s]
Adding requests:  71%|   | 1454/2048 [00:03<00:01, 494.42it/s]
Adding requests:  73%|  | 1505/2048 [00:03<00:01, 496.92it/s]
Adding requests:  76%|  | 1556/2048 [00:03<00:00, 497.46it/s]
Adding requests:  79%|  | 1611/2048 [00:03<00:00, 509.98it/s]
Adding requests:  81%| | 1664/2048 [00:03<00:00, 512.17it/s]
Adding requests:  84%| | 1717/2048 [00:03<00:00, 517.16it/s]
Adding requests:  86%| | 1769/2048 [00:04<00:00, 493.79it/s]
Adding requests:  89%| | 1821/2048 [00:04<00:00, 499.61it/s]
Adding requests:  91%|| 1872/2048 [00:04<00:00, 492.50it/s]
Adding requests:  94%|| 1923/2048 [00:04<00:00, 495.69it/s]
Adding requests:  96%|| 1973/2048 [00:04<00:00, 491.35it/s]
Adding requests:  99%|| 2023/2048 [00:04<00:00, 471.26it/s]
Adding requests: 100%|| 2048/2048 [00:04<00:00, 440.48it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 50/2048 [00:00<00:21, 91.18it/s, est. speed input: 93375.11 toks/s, output: 91.18 toks/s]
Processed prompts:   3%|         | 66/2048 [00:01<01:03, 31.06it/s, est. speed input: 37412.02 toks/s, output: 36.53 toks/s]
Processed prompts:   4%|         | 82/2048 [00:03<01:31, 21.53it/s, est. speed input: 27459.70 toks/s, output: 26.82 toks/s]
Processed prompts:   5%|         | 98/2048 [00:04<01:49, 17.76it/s, est. speed input: 23255.61 toks/s, output: 22.71 toks/s]
Processed prompts:   6%|         | 114/2048 [00:05<02:01, 15.85it/s, est. speed input: 20949.49 toks/s, output: 20.46 toks/s]
Processed prompts:   6%|         | 130/2048 [00:06<02:10, 14.75it/s, est. speed input: 19488.73 toks/s, output: 19.03 toks/s]
Processed prompts:   7%|         | 146/2048 [00:08<02:15, 14.08it/s, est. speed input: 18490.81 toks/s, output: 18.06 toks/s]
Processed prompts:   8%|         | 162/2048 [00:09<02:18, 13.66it/s, est. speed input: 17766.13 toks/s, output: 17.35 toks/s]
Processed prompts:   9%|         | 178/2048 [00:10<02:19, 13.37it/s, est. speed input: 17204.39 toks/s, output: 16.80 toks/s]
Processed prompts:   9%|         | 194/2048 [00:11<02:20, 13.17it/s, est. speed input: 16761.26 toks/s, output: 16.37 toks/s]
Processed prompts:  10%|         | 210/2048 [00:13<02:21, 13.02it/s, est. speed input: 16398.05 toks/s, output: 16.01 toks/s]
Processed prompts:  11%|         | 226/2048 [00:14<02:20, 12.92it/s, est. speed input: 16101.63 toks/s, output: 15.72 toks/s]
Processed prompts:  12%|        | 242/2048 [00:15<02:20, 12.87it/s, est. speed input: 15855.63 toks/s, output: 15.48 toks/s]
Processed prompts:  13%|        | 258/2048 [00:16<02:19, 12.83it/s, est. speed input: 15646.28 toks/s, output: 15.28 toks/s]
Processed prompts:  13%|        | 274/2048 [00:18<02:18, 12.80it/s, est. speed input: 15466.55 toks/s, output: 15.10 toks/s]
Processed prompts:  14%|        | 290/2048 [00:19<02:17, 12.77it/s, est. speed input: 15307.66 toks/s, output: 14.95 toks/s]
Processed prompts:  15%|        | 306/2048 [00:20<02:16, 12.76it/s, est. speed input: 15168.57 toks/s, output: 14.81 toks/s]
Processed prompts:  16%|        | 322/2048 [00:21<02:15, 12.74it/s, est. speed input: 15043.70 toks/s, output: 14.69 toks/s]
Processed prompts:  17%|        | 338/2048 [00:23<02:12, 12.88it/s, est. speed input: 14965.24 toks/s, output: 14.61 toks/s]
Processed prompts:  17%|        | 354/2048 [00:24<02:12, 12.83it/s, est. speed input: 14864.42 toks/s, output: 14.52 toks/s]
Processed prompts:  18%|        | 370/2048 [00:25<02:11, 12.79it/s, est. speed input: 14773.17 toks/s, output: 14.43 toks/s]
Processed prompts:  19%|        | 386/2048 [00:26<02:10, 12.77it/s, est. speed input: 14692.28 toks/s, output: 14.35 toks/s]
Processed prompts:  20%|        | 402/2048 [00:28<02:09, 12.75it/s, est. speed input: 14616.61 toks/s, output: 14.27 toks/s]
Processed prompts:  20%|        | 418/2048 [00:29<02:07, 12.74it/s, est. speed input: 14548.04 toks/s, output: 14.21 toks/s]
Processed prompts:  21%|        | 434/2048 [00:30<02:06, 12.72it/s, est. speed input: 14483.88 toks/s, output: 14.14 toks/s]
Processed prompts:  22%|       | 450/2048 [00:31<02:03, 12.92it/s, est. speed input: 14455.09 toks/s, output: 14.12 toks/s]
Processed prompts:  23%|       | 466/2048 [00:33<02:03, 12.86it/s, est. speed input: 14400.69 toks/s, output: 14.06 toks/s]
Processed prompts:  24%|       | 482/2048 [00:34<02:02, 12.79it/s, est. speed input: 14346.76 toks/s, output: 14.01 toks/s]
Processed prompts:  24%|       | 498/2048 [00:35<02:01, 12.75it/s, est. speed input: 14297.86 toks/s, output: 13.96 toks/s]
Processed prompts:  25%|       | 514/2048 [00:36<02:00, 12.74it/s, est. speed input: 14254.27 toks/s, output: 13.92 toks/s]
Processed prompts:  26%|       | 530/2048 [00:38<01:59, 12.71it/s, est. speed input: 14211.47 toks/s, output: 13.88 toks/s]
Processed prompts:  27%|       | 546/2048 [00:39<01:58, 12.71it/s, est. speed input: 14172.39 toks/s, output: 13.84 toks/s]
Processed prompts:  27%|       | 562/2048 [00:40<01:57, 12.69it/s, est. speed input: 14134.12 toks/s, output: 13.80 toks/s]
Processed prompts:  28%|       | 578/2048 [00:41<01:55, 12.69it/s, est. speed input: 14099.96 toks/s, output: 13.77 toks/s]
Processed prompts:  29%|       | 594/2048 [00:43<01:54, 12.69it/s, est. speed input: 14068.41 toks/s, output: 13.74 toks/s]
Processed prompts:  30%|       | 610/2048 [00:44<01:53, 12.69it/s, est. speed input: 14038.03 toks/s, output: 13.71 toks/s]
Processed prompts:  31%|       | 626/2048 [00:45<01:52, 12.68it/s, est. speed input: 14007.75 toks/s, output: 13.68 toks/s]
Processed prompts:  31%|      | 642/2048 [00:47<01:50, 12.67it/s, est. speed input: 13979.34 toks/s, output: 13.65 toks/s]
Processed prompts:  32%|      | 658/2048 [00:48<01:49, 12.66it/s, est. speed input: 13952.17 toks/s, output: 13.63 toks/s]
Processed prompts:  33%|      | 674/2048 [00:49<01:48, 12.67it/s, est. speed input: 13927.58 toks/s, output: 13.60 toks/s]
Processed prompts:  34%|      | 690/2048 [00:50<01:47, 12.66it/s, est. speed input: 13903.32 toks/s, output: 13.58 toks/s]
Processed prompts:  34%|      | 706/2048 [00:52<01:45, 12.67it/s, est. speed input: 13881.59 toks/s, output: 13.56 toks/s]
Processed prompts:  35%|      | 722/2048 [00:53<01:44, 12.69it/s, est. speed input: 13861.25 toks/s, output: 13.54 toks/s]
Processed prompts:  36%|      | 738/2048 [00:54<01:43, 12.67it/s, est. speed input: 13839.44 toks/s, output: 13.52 toks/s]
Processed prompts:  37%|      | 754/2048 [00:55<01:42, 12.67it/s, est. speed input: 13819.95 toks/s, output: 13.50 toks/s]
Processed prompts:  38%|      | 770/2048 [00:57<01:40, 12.67it/s, est. speed input: 13801.09 toks/s, output: 13.48 toks/s]
Processed prompts:  38%|      | 786/2048 [00:58<01:39, 12.68it/s, est. speed input: 13783.85 toks/s, output: 13.46 toks/s]
Processed prompts:  39%|      | 802/2048 [00:59<01:38, 12.67it/s, est. speed input: 13766.09 toks/s, output: 13.44 toks/s]
Processed prompts:  40%|      | 818/2048 [01:00<01:37, 12.66it/s, est. speed input: 13749.07 toks/s, output: 13.43 toks/s]
Processed prompts:  41%|      | 834/2048 [01:02<01:35, 12.67it/s, est. speed input: 13733.72 toks/s, output: 13.41 toks/s]
Processed prompts:  42%|     | 850/2048 [01:03<01:34, 12.66it/s, est. speed input: 13718.19 toks/s, output: 13.40 toks/s]
Processed prompts:  42%|     | 866/2048 [01:04<01:33, 12.67it/s, est. speed input: 13703.71 toks/s, output: 13.38 toks/s]
Processed prompts:  43%|     | 882/2048 [01:05<01:32, 12.66it/s, est. speed input: 13689.24 toks/s, output: 13.37 toks/s]
Processed prompts:  44%|     | 898/2048 [01:07<01:30, 12.65it/s, est. speed input: 13674.69 toks/s, output: 13.35 toks/s]
Processed prompts:  45%|     | 914/2048 [01:08<01:29, 12.65it/s, est. speed input: 13661.43 toks/s, output: 13.34 toks/s]
Processed prompts:  45%|     | 930/2048 [01:09<01:26, 12.91it/s, est. speed input: 13665.28 toks/s, output: 13.34 toks/s]
Processed prompts:  46%|     | 946/2048 [01:10<01:25, 12.84it/s, est. speed input: 13653.38 toks/s, output: 13.33 toks/s]
Processed prompts:  47%|     | 962/2048 [01:12<01:24, 12.80it/s, est. speed input: 13642.07 toks/s, output: 13.32 toks/s]
Processed prompts:  48%|     | 978/2048 [01:13<01:22, 12.99it/s, est. speed input: 13644.35 toks/s, output: 13.32 toks/s]
Processed prompts:  49%|     | 994/2048 [01:14<01:21, 12.90it/s, est. speed input: 13633.13 toks/s, output: 13.31 toks/s]
Processed prompts:  49%|     | 1010/2048 [01:15<01:20, 12.82it/s, est. speed input: 13621.91 toks/s, output: 13.30 toks/s]
Processed prompts:  50%|     | 1026/2048 [01:17<01:20, 12.77it/s, est. speed input: 13611.17 toks/s, output: 13.29 toks/s]
Processed prompts:  51%|     | 1042/2048 [01:18<01:18, 12.75it/s, est. speed input: 13601.37 toks/s, output: 13.28 toks/s]
Processed prompts:  52%|    | 1058/2048 [01:19<01:17, 12.72it/s, est. speed input: 13590.92 toks/s, output: 13.27 toks/s]
Processed prompts:  52%|    | 1074/2048 [01:20<01:16, 12.71it/s, est. speed input: 13581.92 toks/s, output: 13.26 toks/s]
Processed prompts:  53%|    | 1090/2048 [01:22<01:15, 12.69it/s, est. speed input: 13572.16 toks/s, output: 13.25 toks/s]
Processed prompts:  54%|    | 1106/2048 [01:23<01:14, 12.69it/s, est. speed input: 13563.38 toks/s, output: 13.25 toks/s]
Processed prompts:  55%|    | 1122/2048 [01:24<01:13, 12.67it/s, est. speed input: 13553.97 toks/s, output: 13.24 toks/s]
Processed prompts:  56%|    | 1138/2048 [01:26<01:11, 12.67it/s, est. speed input: 13545.47 toks/s, output: 13.23 toks/s]
Processed prompts:  56%|    | 1154/2048 [01:27<01:09, 12.92it/s, est. speed input: 13549.88 toks/s, output: 13.23 toks/s]
Processed prompts:  57%|    | 1170/2048 [01:28<01:08, 12.84it/s, est. speed input: 13541.43 toks/s, output: 13.22 toks/s]
Processed prompts:  58%|    | 1186/2048 [01:29<01:07, 12.79it/s, est. speed input: 13533.66 toks/s, output: 13.22 toks/s]
Processed prompts:  59%|    | 1202/2048 [01:31<01:06, 12.75it/s, est. speed input: 13525.55 toks/s, output: 13.21 toks/s]
Processed prompts:  59%|    | 1218/2048 [01:32<01:05, 12.72it/s, est. speed input: 13517.93 toks/s, output: 13.20 toks/s]
Processed prompts:  60%|    | 1234/2048 [01:33<01:04, 12.71it/s, est. speed input: 13510.75 toks/s, output: 13.19 toks/s]
Processed prompts:  61%|    | 1250/2048 [01:34<01:02, 12.69it/s, est. speed input: 13503.40 toks/s, output: 13.19 toks/s]
Processed prompts:  62%|   | 1266/2048 [01:35<01:00, 12.91it/s, est. speed input: 13506.46 toks/s, output: 13.19 toks/s]
Processed prompts:  63%|   | 1282/2048 [01:37<00:59, 12.84it/s, est. speed input: 13499.67 toks/s, output: 13.18 toks/s]
Processed prompts:  63%|   | 1298/2048 [01:38<00:58, 12.79it/s, est. speed input: 13492.97 toks/s, output: 13.18 toks/s]
Processed prompts:  64%|   | 1314/2048 [01:39<00:57, 12.75it/s, est. speed input: 13486.28 toks/s, output: 13.17 toks/s]
Processed prompts:  65%|   | 1330/2048 [01:41<00:56, 12.73it/s, est. speed input: 13480.14 toks/s, output: 13.16 toks/s]
Processed prompts:  66%|   | 1346/2048 [01:42<00:55, 12.69it/s, est. speed input: 13473.03 toks/s, output: 13.16 toks/s]
Processed prompts:  67%|   | 1362/2048 [01:43<00:54, 12.70it/s, est. speed input: 13467.62 toks/s, output: 13.15 toks/s]
Processed prompts:  67%|   | 1378/2048 [01:44<00:52, 12.68it/s, est. speed input: 13461.29 toks/s, output: 13.15 toks/s]
Processed prompts:  68%|   | 1394/2048 [01:46<00:51, 12.67it/s, est. speed input: 13455.26 toks/s, output: 13.14 toks/s]
Processed prompts:  69%|   | 1410/2048 [01:47<00:50, 12.67it/s, est. speed input: 13449.31 toks/s, output: 13.13 toks/s]
Processed prompts:  70%|   | 1426/2048 [01:48<00:49, 12.67it/s, est. speed input: 13444.05 toks/s, output: 13.13 toks/s]
Processed prompts:  70%|   | 1442/2048 [01:49<00:47, 12.66it/s, est. speed input: 13438.07 toks/s, output: 13.12 toks/s]
Processed prompts:  71%|   | 1458/2048 [01:51<00:46, 12.67it/s, est. speed input: 13433.06 toks/s, output: 13.12 toks/s]
Processed prompts:  72%|  | 1474/2048 [01:52<00:45, 12.66it/s, est. speed input: 13427.71 toks/s, output: 13.11 toks/s]
Processed prompts:  73%|  | 1490/2048 [01:53<00:44, 12.66it/s, est. speed input: 13422.45 toks/s, output: 13.11 toks/s]
Processed prompts:  74%|  | 1506/2048 [01:54<00:42, 12.65it/s, est. speed input: 13416.90 toks/s, output: 13.10 toks/s]
Processed prompts:  74%|  | 1522/2048 [01:56<00:41, 12.64it/s, est. speed input: 13411.73 toks/s, output: 13.10 toks/s]
Processed prompts:  75%|  | 1538/2048 [01:57<00:40, 12.66it/s, est. speed input: 13407.35 toks/s, output: 13.09 toks/s]
Processed prompts:  76%|  | 1554/2048 [01:58<00:39, 12.66it/s, est. speed input: 13402.69 toks/s, output: 13.09 toks/s]
Processed prompts:  77%|  | 1570/2048 [01:59<00:37, 12.66it/s, est. speed input: 13397.89 toks/s, output: 13.08 toks/s]
Processed prompts:  77%|  | 1586/2048 [02:01<00:35, 12.90it/s, est. speed input: 13402.22 toks/s, output: 13.09 toks/s]
Processed prompts:  78%|  | 1602/2048 [02:02<00:34, 12.84it/s, est. speed input: 13397.95 toks/s, output: 13.08 toks/s]
Processed prompts:  79%|  | 1618/2048 [02:03<00:33, 12.77it/s, est. speed input: 13393.11 toks/s, output: 13.08 toks/s]
Processed prompts:  80%|  | 1634/2048 [02:04<00:32, 12.74it/s, est. speed input: 13388.67 toks/s, output: 13.07 toks/s]
Processed prompts:  81%|  | 1650/2048 [02:06<00:31, 12.72it/s, est. speed input: 13384.70 toks/s, output: 13.07 toks/s]
Processed prompts:  81%| | 1666/2048 [02:07<00:30, 12.71it/s, est. speed input: 13380.78 toks/s, output: 13.07 toks/s]
Processed prompts:  82%| | 1682/2048 [02:08<00:28, 12.70it/s, est. speed input: 13376.97 toks/s, output: 13.06 toks/s]
Processed prompts:  83%| | 1698/2048 [02:10<00:27, 12.69it/s, est. speed input: 13372.79 toks/s, output: 13.06 toks/s]
Processed prompts:  84%| | 1714/2048 [02:11<00:26, 12.68it/s, est. speed input: 13368.83 toks/s, output: 13.06 toks/s]
Processed prompts:  84%| | 1730/2048 [02:12<00:25, 12.68it/s, est. speed input: 13365.21 toks/s, output: 13.05 toks/s]
Processed prompts:  85%| | 1746/2048 [02:13<00:23, 12.68it/s, est. speed input: 13361.68 toks/s, output: 13.05 toks/s]
Processed prompts:  86%| | 1762/2048 [02:15<00:22, 12.68it/s, est. speed input: 13358.13 toks/s, output: 13.05 toks/s]
Processed prompts:  87%| | 1778/2048 [02:16<00:21, 12.67it/s, est. speed input: 13354.20 toks/s, output: 13.04 toks/s]
Processed prompts:  88%| | 1794/2048 [02:17<00:20, 12.67it/s, est. speed input: 13350.81 toks/s, output: 13.04 toks/s]
Processed prompts:  88%| | 1810/2048 [02:18<00:18, 12.67it/s, est. speed input: 13347.33 toks/s, output: 13.03 toks/s]
Processed prompts:  89%| | 1826/2048 [02:20<00:17, 12.66it/s, est. speed input: 13343.61 toks/s, output: 13.03 toks/s]
Processed prompts:  90%| | 1842/2048 [02:21<00:16, 12.67it/s, est. speed input: 13340.57 toks/s, output: 13.03 toks/s]
Processed prompts:  91%| | 1858/2048 [02:22<00:15, 12.66it/s, est. speed input: 13337.03 toks/s, output: 13.02 toks/s]
Processed prompts:  92%|| 1874/2048 [02:23<00:13, 12.91it/s, est. speed input: 13341.26 toks/s, output: 13.03 toks/s]
Processed prompts:  92%|| 1890/2048 [02:25<00:12, 12.84it/s, est. speed input: 13338.28 toks/s, output: 13.03 toks/s]
Processed prompts:  93%|| 1906/2048 [02:26<00:11, 12.80it/s, est. speed input: 13335.30 toks/s, output: 13.02 toks/s]
Processed prompts:  94%|| 1922/2048 [02:27<00:09, 12.76it/s, est. speed input: 13332.15 toks/s, output: 13.02 toks/s]
Processed prompts:  95%|| 1938/2048 [02:28<00:08, 12.73it/s, est. speed input: 13329.21 toks/s, output: 13.02 toks/s]
Processed prompts:  95%|| 1954/2048 [02:30<00:07, 12.98it/s, est. speed input: 13333.81 toks/s, output: 13.02 toks/s]
Processed prompts:  96%|| 1970/2048 [02:31<00:06, 12.87it/s, est. speed input: 13330.38 toks/s, output: 13.02 toks/s]
Processed prompts:  97%|| 1986/2048 [02:32<00:04, 12.80it/s, est. speed input: 13327.31 toks/s, output: 13.01 toks/s]
Processed prompts:  98%|| 2002/2048 [02:33<00:03, 12.76it/s, est. speed input: 13324.28 toks/s, output: 13.01 toks/s]
Processed prompts:  99%|| 2018/2048 [02:35<00:02, 12.73it/s, est. speed input: 13321.45 toks/s, output: 13.01 toks/s]
Processed prompts:  99%|| 2034/2048 [02:36<00:01, 12.93it/s, est. speed input: 13324.66 toks/s, output: 13.01 toks/s]
Processed prompts: 100%|| 2048/2048 [02:36<00:00, 12.93it/s, est. speed input: 13416.36 toks/s, output: 13.10 toks/s]
Processed prompts: 100%|| 2048/2048 [02:36<00:00, 13.10it/s, est. speed input: 13416.36 toks/s, output: 13.10 toks/s]
[rank0]:[W126 12:33:00.023155148 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-26 12:33:03
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-3B-FP8_M32768.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 12:33:18 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 12:33:18 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1292292) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1292292) WARNING 01-26 12:33:54 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 12.68 requests/s, 12999.36 total tokens/s, 12.68 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-26 12:33:17] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 12:33:18] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 12:33:18] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 12:33:18] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:33:18] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:33:18] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:33:18] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:33:18] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:33:18] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 12:33:18] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:33:18] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:33:18] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:33:18] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:33:18] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 12:33:21] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 12:33:21] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 12:33:21] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 12:33:21] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:33:21] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:33:21] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:33:21] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:33:21] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:33:21] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 12:33:21] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:33:21] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:33:21] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:33:21] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:33:21] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1292292) [2026-01-26 12:33:22] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1292292) [2026-01-26 12:33:22] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1292292) [2026-01-26 12:33:22] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1292292) [2026-01-26 12:33:22] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1292292) [2026-01-26 12:33:22] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1292292) [2026-01-26 12:33:22] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1292292) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1292292) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:20<00:00, 20.37s/it]
(EngineCore_DP0 pid=1292292) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:20<00:00, 20.37s/it]
(EngineCore_DP0 pid=1292292) 
(EngineCore_DP0 pid=1292292) [2026-01-26 12:33:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4096] -> 1D uint8
(EngineCore_DP0 pid=1292292) [2026-01-26 12:33:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 13107200 bytes
(EngineCore_DP0 pid=1292292) [2026-01-26 12:33:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4096] -> 1D uint8
(EngineCore_DP0 pid=1292292) [2026-01-26 12:33:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 7864320 bytes
(EngineCore_DP0 pid=1292292) [2026-01-26 12:33:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4096] -> 1D uint8
(EngineCore_DP0 pid=1292292) [2026-01-26 12:33:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 41943040 bytes
(EngineCore_DP0 pid=1292292) [2026-01-26 12:33:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 10944] -> 1D uint8
(EngineCore_DP0 pid=1292292) [2026-01-26 12:33:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 21037056 bytes
(EngineCore_DP0 pid=1292292) 2026-01-26 12:33:51,179 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1292292) 2026-01-26 12:33:51,330 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|         | 58/4096 [00:00<00:07, 575.17it/s]
Adding requests:   3%|         | 116/4096 [00:00<00:09, 441.97it/s]
Adding requests:   4%|         | 163/4096 [00:00<00:09, 400.23it/s]
Adding requests:   5%|         | 214/4096 [00:00<00:08, 435.14it/s]
Adding requests:   7%|         | 267/4096 [00:00<00:08, 464.04it/s]
Adding requests:   8%|         | 315/4096 [00:00<00:08, 441.55it/s]
Adding requests:   9%|         | 368/4096 [00:00<00:08, 464.74it/s]
Adding requests:  10%|         | 421/4096 [00:00<00:07, 482.04it/s]
Adding requests:  12%|        | 472/4096 [00:01<00:07, 487.66it/s]
Adding requests:  13%|        | 522/4096 [00:01<00:07, 477.83it/s]
Adding requests:  14%|        | 583/4096 [00:01<00:06, 515.19it/s]
Adding requests:  16%|        | 645/4096 [00:01<00:06, 544.10it/s]
Adding requests:  17%|        | 700/4096 [00:01<00:06, 528.97it/s]
Adding requests:  18%|        | 754/4096 [00:01<00:06, 520.85it/s]
Adding requests:  20%|        | 807/4096 [00:01<00:06, 507.71it/s]
Adding requests:  21%|        | 858/4096 [00:01<00:06, 501.59it/s]
Adding requests:  22%|       | 911/4096 [00:01<00:06, 508.46it/s]
Adding requests:  23%|       | 962/4096 [00:01<00:06, 503.71it/s]
Adding requests:  25%|       | 1013/4096 [00:02<00:06, 503.74it/s]
Adding requests:  26%|       | 1067/4096 [00:02<00:05, 512.44it/s]
Adding requests:  27%|       | 1119/4096 [00:02<00:05, 501.62it/s]
Adding requests:  29%|       | 1173/4096 [00:02<00:05, 510.49it/s]
Adding requests:  30%|       | 1225/4096 [00:02<00:06, 476.28it/s]
Adding requests:  31%|       | 1276/4096 [00:02<00:05, 481.70it/s]
Adding requests:  32%|      | 1327/4096 [00:02<00:05, 489.65it/s]
Adding requests:  34%|      | 1379/4096 [00:02<00:05, 496.12it/s]
Adding requests:  35%|      | 1430/4096 [00:02<00:05, 498.49it/s]
Adding requests:  36%|      | 1482/4096 [00:03<00:05, 501.98it/s]
Adding requests:  37%|      | 1533/4096 [00:03<00:05, 496.41it/s]
Adding requests:  39%|      | 1585/4096 [00:03<00:04, 502.44it/s]
Adding requests:  40%|      | 1638/4096 [00:03<00:04, 509.43it/s]
Adding requests:  41%|     | 1690/4096 [00:03<00:04, 503.51it/s]
Adding requests:  43%|     | 1744/4096 [00:03<00:04, 512.30it/s]
Adding requests:  44%|     | 1796/4096 [00:03<00:04, 511.42it/s]
Adding requests:  45%|     | 1849/4096 [00:03<00:04, 515.16it/s]
Adding requests:  46%|     | 1901/4096 [00:03<00:04, 509.33it/s]
Adding requests:  48%|     | 1955/4096 [00:03<00:04, 516.13it/s]
Adding requests:  49%|     | 2007/4096 [00:04<00:04, 514.78it/s]
Adding requests:  50%|     | 2059/4096 [00:04<00:03, 515.16it/s]
Adding requests:  52%|    | 2111/4096 [00:04<00:03, 514.91it/s]
Adding requests:  53%|    | 2163/4096 [00:04<00:03, 507.09it/s]
Adding requests:  54%|    | 2214/4096 [00:04<00:03, 505.55it/s]
Adding requests:  55%|    | 2267/4096 [00:04<00:03, 509.91it/s]
Adding requests:  57%|    | 2321/4096 [00:04<00:03, 517.41it/s]
Adding requests:  58%|    | 2373/4096 [00:04<00:03, 514.59it/s]
Adding requests:  59%|    | 2425/4096 [00:04<00:03, 482.39it/s]
Adding requests:  60%|    | 2475/4096 [00:04<00:03, 484.62it/s]
Adding requests:  62%|   | 2528/4096 [00:05<00:03, 496.58it/s]
Adding requests:  63%|   | 2578/4096 [00:05<00:03, 491.31it/s]
Adding requests:  64%|   | 2628/4096 [00:05<00:03, 488.64it/s]
Adding requests:  65%|   | 2679/4096 [00:05<00:02, 493.11it/s]
Adding requests:  67%|   | 2730/4096 [00:05<00:02, 497.27it/s]
Adding requests:  68%|   | 2780/4096 [00:05<00:02, 491.96it/s]
Adding requests:  69%|   | 2832/4096 [00:05<00:02, 500.09it/s]
Adding requests:  70%|   | 2883/4096 [00:05<00:02, 502.93it/s]
Adding requests:  72%|  | 2934/4096 [00:05<00:02, 498.60it/s]
Adding requests:  73%|  | 2987/4096 [00:05<00:02, 506.00it/s]
Adding requests:  74%|  | 3038/4096 [00:06<00:02, 506.21it/s]
Adding requests:  75%|  | 3091/4096 [00:06<00:01, 512.09it/s]
Adding requests:  77%|  | 3143/4096 [00:06<00:01, 501.63it/s]
Adding requests:  78%|  | 3198/4096 [00:06<00:01, 514.28it/s]
Adding requests:  79%|  | 3250/4096 [00:06<00:01, 514.31it/s]
Adding requests:  81%|  | 3303/4096 [00:06<00:01, 517.37it/s]
Adding requests:  82%| | 3355/4096 [00:06<00:01, 516.04it/s]
Adding requests:  83%| | 3407/4096 [00:06<00:01, 517.09it/s]
Adding requests:  84%| | 3459/4096 [00:06<00:01, 513.16it/s]
Adding requests:  86%| | 3511/4096 [00:07<00:01, 507.97it/s]
Adding requests:  87%| | 3564/4096 [00:07<00:01, 514.43it/s]
Adding requests:  88%| | 3616/4096 [00:07<00:00, 508.74it/s]
Adding requests:  90%| | 3668/4096 [00:07<00:00, 511.82it/s]
Adding requests:  91%| | 3720/4096 [00:07<00:00, 512.52it/s]
Adding requests:  92%|| 3775/4096 [00:07<00:00, 522.05it/s]
Adding requests:  93%|| 3828/4096 [00:07<00:00, 494.06it/s]
Adding requests:  95%|| 3881/4096 [00:07<00:00, 503.65it/s]
Adding requests:  96%|| 3933/4096 [00:07<00:00, 505.84it/s]
Adding requests:  97%|| 3986/4096 [00:07<00:00, 509.92it/s]
Adding requests:  99%|| 4039/4096 [00:08<00:00, 511.13it/s]
Adding requests: 100%|| 4091/4096 [00:08<00:00, 503.36it/s]
Adding requests: 100%|| 4096/4096 [00:08<00:00, 501.17it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 98/4096 [00:02<01:37, 41.01it/s, est. speed input: 41995.95 toks/s, output: 41.01 toks/s]
Processed prompts:   3%|         | 130/4096 [00:04<02:45, 23.96it/s, est. speed input: 27079.60 toks/s, output: 26.44 toks/s]
Processed prompts:   4%|         | 162/4096 [00:07<03:29, 18.75it/s, est. speed input: 22295.47 toks/s, output: 21.77 toks/s]
Processed prompts:   5%|         | 194/4096 [00:09<03:59, 16.32it/s, est. speed input: 19927.37 toks/s, output: 19.46 toks/s]
Processed prompts:   6%|         | 226/4096 [00:12<04:17, 15.01it/s, est. speed input: 18528.36 toks/s, output: 18.09 toks/s]
Processed prompts:   6%|         | 258/4096 [00:15<04:30, 14.21it/s, est. speed input: 17593.41 toks/s, output: 17.18 toks/s]
Processed prompts:   7%|         | 290/4096 [00:17<04:37, 13.70it/s, est. speed input: 16925.40 toks/s, output: 16.53 toks/s]
Processed prompts:   8%|         | 322/4096 [00:20<04:40, 13.45it/s, est. speed input: 16465.58 toks/s, output: 16.08 toks/s]
Processed prompts:   9%|         | 354/4096 [00:22<04:43, 13.21it/s, est. speed input: 16075.25 toks/s, output: 15.70 toks/s]
Processed prompts:   9%|         | 386/4096 [00:25<04:44, 13.02it/s, est. speed input: 15756.76 toks/s, output: 15.39 toks/s]
Processed prompts:  10%|         | 418/4096 [00:27<04:44, 12.92it/s, est. speed input: 15502.48 toks/s, output: 15.14 toks/s]
Processed prompts:  11%|         | 450/4096 [00:30<04:41, 12.94it/s, est. speed input: 15321.12 toks/s, output: 14.96 toks/s]
Processed prompts:  12%|        | 482/4096 [00:32<04:41, 12.84it/s, est. speed input: 15134.90 toks/s, output: 14.78 toks/s]
Processed prompts:  13%|        | 514/4096 [00:35<04:40, 12.79it/s, est. speed input: 14979.42 toks/s, output: 14.63 toks/s]
Processed prompts:  13%|        | 546/4096 [00:37<04:38, 12.74it/s, est. speed input: 14842.83 toks/s, output: 14.49 toks/s]
Processed prompts:  14%|        | 578/4096 [00:40<04:36, 12.71it/s, est. speed input: 14723.14 toks/s, output: 14.38 toks/s]
Processed prompts:  15%|        | 610/4096 [00:42<04:34, 12.70it/s, est. speed input: 14618.90 toks/s, output: 14.28 toks/s]
Processed prompts:  16%|        | 642/4096 [00:45<04:32, 12.67it/s, est. speed input: 14523.78 toks/s, output: 14.18 toks/s]
Processed prompts:  16%|        | 674/4096 [00:47<04:30, 12.67it/s, est. speed input: 14441.28 toks/s, output: 14.10 toks/s]
Processed prompts:  17%|        | 706/4096 [00:50<04:27, 12.66it/s, est. speed input: 14366.67 toks/s, output: 14.03 toks/s]
Processed prompts:  18%|        | 738/4096 [00:52<04:25, 12.65it/s, est. speed input: 14297.14 toks/s, output: 13.96 toks/s]
Processed prompts:  19%|        | 770/4096 [00:55<04:23, 12.65it/s, est. speed input: 14235.01 toks/s, output: 13.90 toks/s]
Processed prompts:  20%|        | 802/4096 [00:57<04:20, 12.63it/s, est. speed input: 14176.88 toks/s, output: 13.84 toks/s]
Processed prompts:  20%|        | 834/4096 [01:00<04:18, 12.63it/s, est. speed input: 14125.12 toks/s, output: 13.79 toks/s]
Processed prompts:  21%|        | 866/4096 [01:02<04:15, 12.64it/s, est. speed input: 14077.77 toks/s, output: 13.75 toks/s]
Processed prompts:  22%|       | 898/4096 [01:05<04:13, 12.63it/s, est. speed input: 14032.75 toks/s, output: 13.70 toks/s]
Processed prompts:  23%|       | 930/4096 [01:07<04:08, 12.74it/s, est. speed input: 14006.42 toks/s, output: 13.68 toks/s]
Processed prompts:  23%|       | 962/4096 [01:10<04:04, 12.81it/s, est. speed input: 13981.78 toks/s, output: 13.65 toks/s]
Processed prompts:  24%|       | 994/4096 [01:12<04:03, 12.75it/s, est. speed input: 13944.89 toks/s, output: 13.62 toks/s]
Processed prompts:  25%|       | 1026/4096 [01:15<04:01, 12.72it/s, est. speed input: 13911.40 toks/s, output: 13.59 toks/s]
Processed prompts:  26%|       | 1058/4096 [01:18<03:59, 12.69it/s, est. speed input: 13879.10 toks/s, output: 13.55 toks/s]
Processed prompts:  27%|       | 1090/4096 [01:20<03:57, 12.67it/s, est. speed input: 13849.55 toks/s, output: 13.52 toks/s]
Processed prompts:  27%|       | 1122/4096 [01:23<03:54, 12.67it/s, est. speed input: 13822.43 toks/s, output: 13.50 toks/s]
Processed prompts:  28%|       | 1154/4096 [01:25<03:50, 12.75it/s, est. speed input: 13806.65 toks/s, output: 13.48 toks/s]
Processed prompts:  29%|       | 1186/4096 [01:28<03:48, 12.72it/s, est. speed input: 13781.91 toks/s, output: 13.46 toks/s]
Processed prompts:  30%|       | 1218/4096 [01:30<03:46, 12.70it/s, est. speed input: 13758.52 toks/s, output: 13.44 toks/s]
Processed prompts:  31%|       | 1250/4096 [01:33<03:42, 12.78it/s, est. speed input: 13746.27 toks/s, output: 13.42 toks/s]
Processed prompts:  31%|      | 1282/4096 [01:35<03:40, 12.73it/s, est. speed input: 13724.54 toks/s, output: 13.40 toks/s]
Processed prompts:  32%|      | 1314/4096 [01:38<03:38, 12.71it/s, est. speed input: 13704.53 toks/s, output: 13.38 toks/s]
Processed prompts:  33%|      | 1346/4096 [01:40<03:36, 12.68it/s, est. speed input: 13684.60 toks/s, output: 13.36 toks/s]
Processed prompts:  34%|      | 1378/4096 [01:43<03:34, 12.67it/s, est. speed input: 13666.49 toks/s, output: 13.35 toks/s]
Processed prompts:  34%|      | 1410/4096 [01:45<03:32, 12.65it/s, est. speed input: 13648.74 toks/s, output: 13.33 toks/s]
Processed prompts:  35%|      | 1442/4096 [01:48<03:29, 12.64it/s, est. speed input: 13631.80 toks/s, output: 13.31 toks/s]
Processed prompts:  36%|      | 1474/4096 [01:50<03:27, 12.65it/s, est. speed input: 13616.83 toks/s, output: 13.30 toks/s]
Processed prompts:  37%|      | 1506/4096 [01:53<03:24, 12.64it/s, est. speed input: 13600.78 toks/s, output: 13.28 toks/s]
Processed prompts:  38%|      | 1538/4096 [01:55<03:22, 12.64it/s, est. speed input: 13586.60 toks/s, output: 13.27 toks/s]
Processed prompts:  38%|      | 1570/4096 [01:58<03:18, 12.75it/s, est. speed input: 13581.15 toks/s, output: 13.26 toks/s]
Processed prompts:  39%|      | 1602/4096 [02:00<03:16, 12.71it/s, est. speed input: 13567.37 toks/s, output: 13.25 toks/s]
Processed prompts:  40%|      | 1634/4096 [02:03<03:14, 12.68it/s, est. speed input: 13554.25 toks/s, output: 13.24 toks/s]
Processed prompts:  41%|      | 1666/4096 [02:05<03:11, 12.68it/s, est. speed input: 13542.28 toks/s, output: 13.22 toks/s]
Processed prompts:  41%|     | 1698/4096 [02:08<03:09, 12.66it/s, est. speed input: 13530.19 toks/s, output: 13.21 toks/s]
Processed prompts:  42%|     | 1730/4096 [02:11<03:06, 12.65it/s, est. speed input: 13518.85 toks/s, output: 13.20 toks/s]
Processed prompts:  43%|     | 1762/4096 [02:13<03:04, 12.64it/s, est. speed input: 13507.21 toks/s, output: 13.19 toks/s]
Processed prompts:  44%|     | 1794/4096 [02:16<03:02, 12.64it/s, est. speed input: 13496.50 toks/s, output: 13.18 toks/s]
Processed prompts:  45%|     | 1826/4096 [02:18<02:59, 12.64it/s, est. speed input: 13486.55 toks/s, output: 13.17 toks/s]
Processed prompts:  45%|     | 1858/4096 [02:21<02:55, 12.74it/s, est. speed input: 13483.26 toks/s, output: 13.17 toks/s]
Processed prompts:  46%|     | 1890/4096 [02:23<02:53, 12.71it/s, est. speed input: 13473.71 toks/s, output: 13.16 toks/s]
Processed prompts:  47%|     | 1922/4096 [02:26<02:51, 12.69it/s, est. speed input: 13464.81 toks/s, output: 13.15 toks/s]
Processed prompts:  48%|     | 1954/4096 [02:28<02:47, 12.78it/s, est. speed input: 13462.17 toks/s, output: 13.15 toks/s]
Processed prompts:  48%|     | 1986/4096 [02:31<02:45, 12.74it/s, est. speed input: 13453.43 toks/s, output: 13.14 toks/s]
Processed prompts:  49%|     | 2018/4096 [02:33<02:43, 12.70it/s, est. speed input: 13444.46 toks/s, output: 13.13 toks/s]
Processed prompts:  50%|     | 2050/4096 [02:36<02:41, 12.69it/s, est. speed input: 13436.63 toks/s, output: 13.12 toks/s]
Processed prompts:  51%|     | 2082/4096 [02:38<02:38, 12.67it/s, est. speed input: 13428.50 toks/s, output: 13.11 toks/s]
Processed prompts:  52%|    | 2114/4096 [02:41<02:36, 12.65it/s, est. speed input: 13420.40 toks/s, output: 13.11 toks/s]
Processed prompts:  52%|    | 2146/4096 [02:43<02:34, 12.65it/s, est. speed input: 13413.08 toks/s, output: 13.10 toks/s]
Processed prompts:  53%|    | 2178/4096 [02:46<02:31, 12.65it/s, est. speed input: 13406.28 toks/s, output: 13.09 toks/s]
Processed prompts:  54%|    | 2210/4096 [02:48<02:26, 12.85it/s, est. speed input: 13409.87 toks/s, output: 13.10 toks/s]
Processed prompts:  55%|    | 2242/4096 [02:51<02:25, 12.78it/s, est. speed input: 13402.71 toks/s, output: 13.09 toks/s]
Processed prompts:  56%|    | 2274/4096 [02:53<02:21, 12.85it/s, est. speed input: 13401.56 toks/s, output: 13.09 toks/s]
Processed prompts:  56%|    | 2306/4096 [02:56<02:20, 12.78it/s, est. speed input: 13394.49 toks/s, output: 13.08 toks/s]
Processed prompts:  57%|    | 2338/4096 [02:58<02:16, 12.84it/s, est. speed input: 13393.35 toks/s, output: 13.08 toks/s]
Processed prompts:  58%|    | 2370/4096 [03:01<02:12, 13.01it/s, est. speed input: 13397.86 toks/s, output: 13.08 toks/s]
Processed prompts:  59%|    | 2402/4096 [03:03<02:11, 12.89it/s, est. speed input: 13391.53 toks/s, output: 13.08 toks/s]
Processed prompts:  59%|    | 2434/4096 [03:06<02:09, 12.82it/s, est. speed input: 13385.36 toks/s, output: 13.07 toks/s]
Processed prompts:  60%|    | 2466/4096 [03:08<02:07, 12.76it/s, est. speed input: 13379.46 toks/s, output: 13.07 toks/s]
Processed prompts:  61%|    | 2498/4096 [03:11<02:04, 12.82it/s, est. speed input: 13378.10 toks/s, output: 13.06 toks/s]
Processed prompts:  62%|   | 2530/4096 [03:13<02:02, 12.77it/s, est. speed input: 13372.59 toks/s, output: 13.06 toks/s]
Processed prompts:  63%|   | 2562/4096 [03:16<01:59, 12.84it/s, est. speed input: 13371.88 toks/s, output: 13.06 toks/s]
Processed prompts:  63%|   | 2594/4096 [03:18<01:57, 12.77it/s, est. speed input: 13366.04 toks/s, output: 13.05 toks/s]
Processed prompts:  64%|   | 2626/4096 [03:21<01:55, 12.74it/s, est. speed input: 13360.93 toks/s, output: 13.05 toks/s]
Processed prompts:  65%|   | 2658/4096 [03:23<01:53, 12.70it/s, est. speed input: 13355.63 toks/s, output: 13.04 toks/s]
Processed prompts:  66%|   | 2690/4096 [03:26<01:50, 12.68it/s, est. speed input: 13350.26 toks/s, output: 13.04 toks/s]
Processed prompts:  66%|   | 2722/4096 [03:28<01:48, 12.67it/s, est. speed input: 13345.47 toks/s, output: 13.03 toks/s]
Processed prompts:  67%|   | 2754/4096 [03:31<01:46, 12.65it/s, est. speed input: 13340.08 toks/s, output: 13.03 toks/s]
Processed prompts:  68%|   | 2786/4096 [03:33<01:43, 12.64it/s, est. speed input: 13335.33 toks/s, output: 13.02 toks/s]
Processed prompts:  69%|   | 2818/4096 [03:36<01:41, 12.64it/s, est. speed input: 13330.84 toks/s, output: 13.02 toks/s]
Processed prompts:  70%|   | 2850/4096 [03:39<01:38, 12.63it/s, est. speed input: 13325.94 toks/s, output: 13.01 toks/s]
Processed prompts:  70%|   | 2882/4096 [03:41<01:36, 12.64it/s, est. speed input: 13321.66 toks/s, output: 13.01 toks/s]
Processed prompts:  71%|   | 2914/4096 [03:44<01:33, 12.63it/s, est. speed input: 13317.02 toks/s, output: 13.00 toks/s]
Processed prompts:  72%|  | 2946/4096 [03:46<01:31, 12.63it/s, est. speed input: 13312.84 toks/s, output: 13.00 toks/s]
Processed prompts:  73%|  | 2978/4096 [03:49<01:28, 12.64it/s, est. speed input: 13308.85 toks/s, output: 13.00 toks/s]
Processed prompts:  73%|  | 3010/4096 [03:51<01:25, 12.63it/s, est. speed input: 13304.49 toks/s, output: 12.99 toks/s]
Processed prompts:  74%|  | 3042/4096 [03:54<01:23, 12.63it/s, est. speed input: 13300.53 toks/s, output: 12.99 toks/s]
Processed prompts:  75%|  | 3074/4096 [03:56<01:20, 12.63it/s, est. speed input: 13296.71 toks/s, output: 12.99 toks/s]
Processed prompts:  76%|  | 3106/4096 [03:59<01:18, 12.63it/s, est. speed input: 13292.89 toks/s, output: 12.98 toks/s]
Processed prompts:  77%|  | 3138/4096 [04:01<01:15, 12.74it/s, est. speed input: 13293.00 toks/s, output: 12.98 toks/s]
Processed prompts:  77%|  | 3170/4096 [04:04<01:12, 12.70it/s, est. speed input: 13289.11 toks/s, output: 12.98 toks/s]
Processed prompts:  78%|  | 3202/4096 [04:06<01:10, 12.68it/s, est. speed input: 13285.31 toks/s, output: 12.97 toks/s]
Processed prompts:  79%|  | 3234/4096 [04:09<01:08, 12.67it/s, est. speed input: 13282.01 toks/s, output: 12.97 toks/s]
Processed prompts:  80%|  | 3266/4096 [04:11<01:05, 12.65it/s, est. speed input: 13278.33 toks/s, output: 12.97 toks/s]
Processed prompts:  81%|  | 3298/4096 [04:14<01:03, 12.65it/s, est. speed input: 13275.06 toks/s, output: 12.96 toks/s]
Processed prompts:  81%| | 3330/4096 [04:16<01:00, 12.64it/s, est. speed input: 13271.55 toks/s, output: 12.96 toks/s]
Processed prompts:  82%| | 3362/4096 [04:19<00:58, 12.64it/s, est. speed input: 13268.30 toks/s, output: 12.96 toks/s]
Processed prompts:  83%| | 3394/4096 [04:22<00:55, 12.64it/s, est. speed input: 13265.09 toks/s, output: 12.95 toks/s]
Processed prompts:  84%| | 3426/4096 [04:24<00:53, 12.62it/s, est. speed input: 13261.56 toks/s, output: 12.95 toks/s]
Processed prompts:  84%| | 3458/4096 [04:27<00:50, 12.63it/s, est. speed input: 13258.73 toks/s, output: 12.95 toks/s]
Processed prompts:  85%| | 3490/4096 [04:29<00:47, 12.86it/s, est. speed input: 13262.84 toks/s, output: 12.95 toks/s]
Processed prompts:  86%| | 3522/4096 [04:31<00:44, 12.78it/s, est. speed input: 13259.44 toks/s, output: 12.95 toks/s]
Processed prompts:  87%| | 3554/4096 [04:34<00:42, 12.74it/s, est. speed input: 13256.64 toks/s, output: 12.95 toks/s]
Processed prompts:  88%| | 3586/4096 [04:37<00:40, 12.71it/s, est. speed input: 13253.76 toks/s, output: 12.94 toks/s]
Processed prompts:  88%| | 3618/4096 [04:39<00:37, 12.68it/s, est. speed input: 13250.58 toks/s, output: 12.94 toks/s]
Processed prompts:  89%| | 3650/4096 [04:42<00:35, 12.68it/s, est. speed input: 13248.20 toks/s, output: 12.94 toks/s]
Processed prompts:  90%| | 3682/4096 [04:44<00:32, 12.66it/s, est. speed input: 13245.34 toks/s, output: 12.93 toks/s]
Processed prompts:  91%| | 3714/4096 [04:47<00:29, 12.76it/s, est. speed input: 13245.78 toks/s, output: 12.94 toks/s]
Processed prompts:  91%|| 3746/4096 [04:49<00:27, 12.72it/s, est. speed input: 13243.09 toks/s, output: 12.93 toks/s]
Processed prompts:  92%|| 3778/4096 [04:52<00:25, 12.69it/s, est. speed input: 13240.24 toks/s, output: 12.93 toks/s]
Processed prompts:  93%|| 3810/4096 [04:54<00:22, 12.67it/s, est. speed input: 13237.51 toks/s, output: 12.93 toks/s]
Processed prompts:  94%|| 3842/4096 [04:57<00:19, 12.77it/s, est. speed input: 13238.14 toks/s, output: 12.93 toks/s]
Processed prompts:  95%|| 3874/4096 [04:59<00:17, 12.72it/s, est. speed input: 13235.31 toks/s, output: 12.93 toks/s]
Processed prompts:  95%|| 3906/4096 [05:02<00:14, 12.70it/s, est. speed input: 13232.98 toks/s, output: 12.92 toks/s]
Processed prompts:  96%|| 3938/4096 [05:04<00:12, 12.67it/s, est. speed input: 13230.32 toks/s, output: 12.92 toks/s]
Processed prompts:  97%|| 3970/4096 [05:07<00:09, 12.66it/s, est. speed input: 13227.88 toks/s, output: 12.92 toks/s]
Processed prompts:  98%|| 4002/4096 [05:09<00:07, 12.65it/s, est. speed input: 13225.52 toks/s, output: 12.92 toks/s]
Processed prompts:  98%|| 4034/4096 [05:12<00:04, 12.75it/s, est. speed input: 13226.04 toks/s, output: 12.92 toks/s]
Processed prompts:  99%|| 4066/4096 [05:14<00:02, 12.81it/s, est. speed input: 13226.34 toks/s, output: 12.92 toks/s]
Processed prompts: 100%|| 4096/4096 [05:14<00:00, 12.81it/s, est. speed input: 13323.91 toks/s, output: 13.01 toks/s]
Processed prompts: 100%|| 4096/4096 [05:14<00:00, 13.01it/s, est. speed input: 13323.91 toks/s, output: 13.01 toks/s]
[rank0]:[W126 12:39:17.818316960 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-26 12:39:19
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Llama3.2-3B-FP8_M65536.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 12:39:46 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 12:39:46 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1297838) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1297838) WARNING 01-26 12:40:28 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 11.37 requests/s, 11649.82 total tokens/s, 11.37 output tokens/s
Total num prompt tokens:  8388608
Total num output tokens:  8192

STDERR:
[2026-01-26 12:39:46] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 12:39:46] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 12:39:46] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 12:39:46] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:39:46] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:39:46] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:39:46] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:39:46] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:39:46] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 12:39:46] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:39:46] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:39:46] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:39:46] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:39:46] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 12:39:50] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 12:39:50] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 12:39:50] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 12:39:50] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:39:50] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:39:50] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:39:50] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:39:50] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:39:50] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 12:39:50] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:39:50] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:39:50] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:39:50] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:39:50] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1297838) [2026-01-26 12:39:51] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1297838) [2026-01-26 12:39:51] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1297838) [2026-01-26 12:39:51] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1297838) [2026-01-26 12:39:51] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1297838) [2026-01-26 12:39:51] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1297838) [2026-01-26 12:39:51] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1297838) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1297838) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:20<00:00, 20.89s/it]
(EngineCore_DP0 pid=1297838) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:20<00:00, 20.89s/it]
(EngineCore_DP0 pid=1297838) 
(EngineCore_DP0 pid=1297838) [2026-01-26 12:40:12] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4096] -> 1D uint8
(EngineCore_DP0 pid=1297838) [2026-01-26 12:40:12] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 13107200 bytes
(EngineCore_DP0 pid=1297838) [2026-01-26 12:40:12] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4096] -> 1D uint8
(EngineCore_DP0 pid=1297838) [2026-01-26 12:40:12] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 7864320 bytes
(EngineCore_DP0 pid=1297838) [2026-01-26 12:40:12] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4096] -> 1D uint8
(EngineCore_DP0 pid=1297838) [2026-01-26 12:40:12] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 41943040 bytes
(EngineCore_DP0 pid=1297838) [2026-01-26 12:40:12] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 10944] -> 1D uint8
(EngineCore_DP0 pid=1297838) [2026-01-26 12:40:12] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 21037056 bytes
(EngineCore_DP0 pid=1297838) 2026-01-26 12:40:22,685 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1297838) 2026-01-26 12:40:23,020 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/8192 [00:00<?, ?it/s]
Adding requests:   1%|          | 60/8192 [00:00<00:13, 591.22it/s]
Adding requests:   1%|         | 120/8192 [00:00<00:15, 512.18it/s]
Adding requests:   2%|         | 172/8192 [00:00<00:16, 488.64it/s]
Adding requests:   3%|         | 222/8192 [00:00<00:16, 475.85it/s]
Adding requests:   3%|         | 270/8192 [00:00<00:16, 474.25it/s]
Adding requests:   4%|         | 318/8192 [00:00<00:16, 469.46it/s]
Adding requests:   4%|         | 365/8192 [00:00<00:16, 465.56it/s]
Adding requests:   5%|         | 413/8192 [00:00<00:16, 468.91it/s]
Adding requests:   6%|         | 462/8192 [00:00<00:16, 474.12it/s]
Adding requests:   6%|         | 511/8192 [00:01<00:16, 476.60it/s]
Adding requests:   7%|         | 559/8192 [00:01<00:16, 476.53it/s]
Adding requests:   7%|         | 607/8192 [00:01<00:16, 468.17it/s]
Adding requests:   8%|         | 658/8192 [00:01<00:15, 479.89it/s]
Adding requests:   9%|         | 707/8192 [00:01<00:15, 469.80it/s]
Adding requests:   9%|         | 755/8192 [00:01<00:15, 465.45it/s]
Adding requests:  10%|         | 802/8192 [00:01<00:15, 465.58it/s]
Adding requests:  10%|         | 849/8192 [00:01<00:16, 454.19it/s]
Adding requests:  11%|         | 902/8192 [00:01<00:15, 472.43it/s]
Adding requests:  12%|        | 950/8192 [00:02<00:15, 470.88it/s]
Adding requests:  12%|        | 998/8192 [00:02<00:15, 471.49it/s]
Adding requests:  13%|        | 1049/8192 [00:02<00:14, 479.59it/s]
Adding requests:  13%|        | 1097/8192 [00:02<00:14, 475.07it/s]
Adding requests:  14%|        | 1145/8192 [00:02<00:14, 471.35it/s]
Adding requests:  15%|        | 1193/8192 [00:02<00:15, 465.99it/s]
Adding requests:  15%|        | 1242/8192 [00:02<00:14, 470.21it/s]
Adding requests:  16%|        | 1290/8192 [00:02<00:14, 464.45it/s]
Adding requests:  16%|        | 1339/8192 [00:02<00:14, 469.85it/s]
Adding requests:  17%|        | 1387/8192 [00:02<00:14, 472.66it/s]
Adding requests:  18%|        | 1438/8192 [00:03<00:14, 480.45it/s]
Adding requests:  18%|        | 1490/8192 [00:03<00:13, 489.90it/s]
Adding requests:  19%|        | 1540/8192 [00:03<00:13, 484.73it/s]
Adding requests:  19%|        | 1589/8192 [00:03<00:13, 483.01it/s]
Adding requests:  20%|        | 1638/8192 [00:03<00:13, 481.93it/s]
Adding requests:  21%|        | 1687/8192 [00:03<00:13, 472.78it/s]
Adding requests:  21%|        | 1738/8192 [00:03<00:13, 482.58it/s]
Adding requests:  22%|       | 1787/8192 [00:03<00:13, 478.45it/s]
Adding requests:  22%|       | 1839/8192 [00:03<00:12, 490.30it/s]
Adding requests:  23%|       | 1889/8192 [00:03<00:13, 454.54it/s]
Adding requests:  24%|       | 1938/8192 [00:04<00:13, 462.79it/s]
Adding requests:  24%|       | 1985/8192 [00:04<00:13, 461.19it/s]
Adding requests:  25%|       | 2036/8192 [00:04<00:13, 472.41it/s]
Adding requests:  26%|       | 2092/8192 [00:04<00:12, 497.35it/s]
Adding requests:  26%|       | 2142/8192 [00:04<00:12, 487.23it/s]
Adding requests:  27%|       | 2193/8192 [00:04<00:12, 493.83it/s]
Adding requests:  27%|       | 2244/8192 [00:04<00:11, 495.71it/s]
Adding requests:  28%|       | 2295/8192 [00:04<00:11, 498.76it/s]
Adding requests:  29%|       | 2345/8192 [00:04<00:11, 498.07it/s]
Adding requests:  29%|       | 2397/8192 [00:05<00:11, 503.23it/s]
Adding requests:  30%|       | 2450/8192 [00:05<00:11, 509.19it/s]
Adding requests:  31%|       | 2501/8192 [00:05<00:11, 497.32it/s]
Adding requests:  31%|       | 2551/8192 [00:05<00:11, 485.70it/s]
Adding requests:  32%|      | 2601/8192 [00:05<00:11, 489.49it/s]
Adding requests:  32%|      | 2653/8192 [00:05<00:11, 495.20it/s]
Adding requests:  33%|      | 2704/8192 [00:05<00:11, 497.42it/s]
Adding requests:  34%|      | 2757/8192 [00:05<00:10, 506.00it/s]
Adding requests:  34%|      | 2808/8192 [00:05<00:10, 506.44it/s]
Adding requests:  35%|      | 2859/8192 [00:05<00:10, 500.70it/s]
Adding requests:  36%|      | 2911/8192 [00:06<00:10, 503.81it/s]
Adding requests:  36%|      | 2962/8192 [00:06<00:10, 495.12it/s]
Adding requests:  37%|      | 3012/8192 [00:06<00:10, 494.54it/s]
Adding requests:  37%|      | 3062/8192 [00:06<00:10, 496.01it/s]
Adding requests:  38%|      | 3116/8192 [00:06<00:10, 507.56it/s]
Adding requests:  39%|      | 3167/8192 [00:06<00:09, 504.42it/s]
Adding requests:  39%|      | 3218/8192 [00:06<00:10, 490.41it/s]
Adding requests:  40%|      | 3268/8192 [00:06<00:10, 489.19it/s]
Adding requests:  41%|      | 3318/8192 [00:06<00:09, 491.00it/s]
Adding requests:  41%|      | 3369/8192 [00:06<00:09, 494.58it/s]
Adding requests:  42%|     | 3421/8192 [00:07<00:09, 501.91it/s]
Adding requests:  42%|     | 3472/8192 [00:07<00:09, 490.92it/s]
Adding requests:  43%|     | 3527/8192 [00:07<00:09, 507.01it/s]
Adding requests:  44%|     | 3578/8192 [00:07<00:09, 496.10it/s]
Adding requests:  44%|     | 3629/8192 [00:07<00:09, 496.89it/s]
Adding requests:  45%|     | 3679/8192 [00:07<00:09, 496.47it/s]
Adding requests:  46%|     | 3729/8192 [00:07<00:09, 491.09it/s]
Adding requests:  46%|     | 3785/8192 [00:07<00:08, 509.75it/s]
Adding requests:  47%|     | 3837/8192 [00:07<00:08, 508.98it/s]
Adding requests:  48%|     | 3892/8192 [00:07<00:08, 520.46it/s]
Adding requests:  48%|     | 3945/8192 [00:08<00:08, 504.75it/s]
Adding requests:  49%|     | 3998/8192 [00:08<00:08, 508.46it/s]
Adding requests:  49%|     | 4049/8192 [00:08<00:08, 503.65it/s]
Adding requests:  50%|     | 4103/8192 [00:08<00:07, 513.01it/s]
Adding requests:  51%|     | 4155/8192 [00:08<00:07, 511.95it/s]
Adding requests:  51%|    | 4207/8192 [00:08<00:07, 509.35it/s]
Adding requests:  52%|    | 4263/8192 [00:08<00:07, 521.49it/s]
Adding requests:  53%|    | 4316/8192 [00:08<00:07, 513.36it/s]
Adding requests:  53%|    | 4369/8192 [00:08<00:07, 517.88it/s]
Adding requests:  54%|    | 4421/8192 [00:09<00:07, 509.05it/s]
Adding requests:  55%|    | 4478/8192 [00:09<00:07, 524.97it/s]
Adding requests:  55%|    | 4531/8192 [00:09<00:07, 514.97it/s]
Adding requests:  56%|    | 4583/8192 [00:09<00:07, 510.65it/s]
Adding requests:  57%|    | 4635/8192 [00:09<00:07, 473.20it/s]
Adding requests:  57%|    | 4686/8192 [00:09<00:07, 482.95it/s]
Adding requests:  58%|    | 4740/8192 [00:09<00:06, 497.62it/s]
Adding requests:  59%|    | 4794/8192 [00:09<00:06, 507.71it/s]
Adding requests:  59%|    | 4846/8192 [00:09<00:06, 506.79it/s]
Adding requests:  60%|    | 4898/8192 [00:09<00:06, 507.71it/s]
Adding requests:  60%|    | 4949/8192 [00:10<00:06, 498.15it/s]
Adding requests:  61%|    | 5000/8192 [00:10<00:06, 501.49it/s]
Adding requests:  62%|   | 5051/8192 [00:10<00:06, 486.70it/s]
Adding requests:  62%|   | 5104/8192 [00:10<00:06, 498.05it/s]
Adding requests:  63%|   | 5158/8192 [00:10<00:05, 508.45it/s]
Adding requests:  64%|   | 5209/8192 [00:10<00:06, 496.22it/s]
Adding requests:  64%|   | 5261/8192 [00:10<00:05, 500.87it/s]
Adding requests:  65%|   | 5312/8192 [00:10<00:05, 497.34it/s]
Adding requests:  66%|   | 5366/8192 [00:10<00:05, 507.06it/s]
Adding requests:  66%|   | 5417/8192 [00:11<00:05, 506.61it/s]
Adding requests:  67%|   | 5468/8192 [00:11<00:05, 502.68it/s]
Adding requests:  67%|   | 5519/8192 [00:11<00:05, 499.16it/s]
Adding requests:  68%|   | 5569/8192 [00:11<00:05, 497.26it/s]
Adding requests:  69%|   | 5624/8192 [00:11<00:05, 510.40it/s]
Adding requests:  69%|   | 5676/8192 [00:11<00:05, 497.51it/s]
Adding requests:  70%|   | 5729/8192 [00:11<00:04, 505.15it/s]
Adding requests:  71%|   | 5781/8192 [00:11<00:04, 505.81it/s]
Adding requests:  71%|   | 5833/8192 [00:11<00:04, 509.79it/s]
Adding requests:  72%|  | 5885/8192 [00:11<00:04, 511.75it/s]
Adding requests:  72%|  | 5937/8192 [00:12<00:04, 509.41it/s]
Adding requests:  73%|  | 5988/8192 [00:12<00:04, 484.15it/s]
Adding requests:  74%|  | 6038/8192 [00:12<00:04, 488.34it/s]
Adding requests:  74%|  | 6088/8192 [00:12<00:04, 491.36it/s]
Adding requests:  75%|  | 6140/8192 [00:12<00:04, 499.64it/s]
Adding requests:  76%|  | 6194/8192 [00:12<00:03, 507.57it/s]
Adding requests:  76%|  | 6247/8192 [00:12<00:03, 513.95it/s]
Adding requests:  77%|  | 6300/8192 [00:12<00:03, 517.62it/s]
Adding requests:  78%|  | 6355/8192 [00:12<00:03, 526.84it/s]
Adding requests:  78%|  | 6408/8192 [00:12<00:03, 525.12it/s]
Adding requests:  79%|  | 6462/8192 [00:13<00:03, 529.37it/s]
Adding requests:  80%|  | 6516/8192 [00:13<00:03, 530.58it/s]
Adding requests:  80%|  | 6570/8192 [00:13<00:03, 525.80it/s]
Adding requests:  81%|  | 6623/8192 [00:13<00:02, 526.18it/s]
Adding requests:  81%| | 6676/8192 [00:13<00:02, 520.46it/s]
Adding requests:  82%| | 6733/8192 [00:13<00:02, 532.94it/s]
Adding requests:  83%| | 6787/8192 [00:13<00:02, 516.57it/s]
Adding requests:  83%| | 6840/8192 [00:13<00:02, 517.90it/s]
Adding requests:  84%| | 6895/8192 [00:13<00:02, 525.60it/s]
Adding requests:  85%| | 6952/8192 [00:14<00:02, 538.51it/s]
Adding requests:  86%| | 7006/8192 [00:14<00:02, 527.57it/s]
Adding requests:  86%| | 7059/8192 [00:14<00:02, 518.02it/s]
Adding requests:  87%| | 7114/8192 [00:14<00:02, 523.49it/s]
Adding requests:  87%| | 7167/8192 [00:14<00:02, 499.77it/s]
Adding requests:  88%| | 7220/8192 [00:14<00:01, 506.86it/s]
Adding requests:  89%| | 7271/8192 [00:14<00:01, 506.75it/s]
Adding requests:  89%| | 7323/8192 [00:14<00:01, 509.67it/s]
Adding requests:  90%| | 7375/8192 [00:14<00:01, 480.22it/s]
Adding requests:  91%| | 7431/8192 [00:14<00:01, 501.26it/s]
Adding requests:  91%|| 7484/8192 [00:15<00:01, 506.64it/s]
Adding requests:  92%|| 7537/8192 [00:15<00:01, 512.45it/s]
Adding requests:  93%|| 7591/8192 [00:15<00:01, 518.73it/s]
Adding requests:  93%|| 7644/8192 [00:15<00:01, 504.81it/s]
Adding requests:  94%|| 7696/8192 [00:15<00:00, 507.78it/s]
Adding requests:  95%|| 7755/8192 [00:15<00:00, 529.53it/s]
Adding requests:  95%|| 7809/8192 [00:15<00:00, 514.66it/s]
Adding requests:  96%|| 7864/8192 [00:15<00:00, 523.70it/s]
Adding requests:  97%|| 7917/8192 [00:15<00:00, 520.15it/s]
Adding requests:  97%|| 7972/8192 [00:15<00:00, 528.12it/s]
Adding requests:  98%|| 8025/8192 [00:16<00:00, 522.08it/s]
Adding requests:  99%|| 8078/8192 [00:16<00:00, 515.82it/s]
Adding requests:  99%|| 8133/8192 [00:16<00:00, 522.60it/s]
Adding requests: 100%|| 8186/8192 [00:16<00:00, 514.60it/s]
Adding requests: 100%|| 8192/8192 [00:16<00:00, 498.74it/s]

Processed prompts:   0%|          | 0/8192 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 194/8192 [00:03<02:40, 49.90it/s, est. speed input: 51094.46 toks/s, output: 49.90 toks/s]
Processed prompts:   3%|         | 258/8192 [00:08<05:07, 25.78it/s, est. speed input: 29626.60 toks/s, output: 28.93 toks/s]
Processed prompts:   4%|         | 322/8192 [00:13<06:41, 19.61it/s, est. speed input: 23741.79 toks/s, output: 23.19 toks/s]
Processed prompts:   5%|         | 386/8192 [00:18<07:44, 16.79it/s, est. speed input: 20891.09 toks/s, output: 20.40 toks/s]
Processed prompts:   5%|         | 450/8192 [00:23<08:24, 15.35it/s, est. speed input: 19283.87 toks/s, output: 18.83 toks/s]
Processed prompts:   6%|         | 514/8192 [00:28<08:52, 14.42it/s, est. speed input: 18183.61 toks/s, output: 17.76 toks/s]
Processed prompts:   7%|         | 578/8192 [00:33<09:09, 13.85it/s, est. speed input: 17412.58 toks/s, output: 17.00 toks/s]
Processed prompts:   8%|         | 642/8192 [00:39<09:20, 13.48it/s, est. speed input: 16843.53 toks/s, output: 16.45 toks/s]
Processed prompts:   9%|         | 706/8192 [00:44<09:25, 13.23it/s, est. speed input: 16401.68 toks/s, output: 16.02 toks/s]
Processed prompts:   9%|         | 770/8192 [00:49<09:28, 13.06it/s, est. speed input: 16049.54 toks/s, output: 15.67 toks/s]
Processed prompts:  10%|         | 834/8192 [00:54<09:28, 12.94it/s, est. speed input: 15763.90 toks/s, output: 15.39 toks/s]
Processed prompts:  11%|         | 898/8192 [00:59<09:24, 12.92it/s, est. speed input: 15546.85 toks/s, output: 15.18 toks/s]
Processed prompts:  12%|        | 962/8192 [01:04<09:20, 12.91it/s, est. speed input: 15364.49 toks/s, output: 15.00 toks/s]
Processed prompts:  13%|        | 1026/8192 [01:09<09:17, 12.85it/s, est. speed input: 15192.48 toks/s, output: 14.84 toks/s]
Processed prompts:  13%|        | 1090/8192 [01:14<09:14, 12.80it/s, est. speed input: 15042.81 toks/s, output: 14.69 toks/s]
Processed prompts:  14%|        | 1154/8192 [01:19<09:09, 12.82it/s, est. speed input: 14925.86 toks/s, output: 14.58 toks/s]
Processed prompts:  15%|        | 1218/8192 [01:24<09:03, 12.84it/s, est. speed input: 14822.96 toks/s, output: 14.48 toks/s]
Processed prompts:  16%|        | 1282/8192 [01:29<09:00, 12.79it/s, est. speed input: 14718.85 toks/s, output: 14.37 toks/s]
Processed prompts:  16%|        | 1346/8192 [01:34<08:56, 12.75it/s, est. speed input: 14625.19 toks/s, output: 14.28 toks/s]
Processed prompts:  17%|        | 1410/8192 [01:39<08:52, 12.73it/s, est. speed input: 14540.91 toks/s, output: 14.20 toks/s]
Processed prompts:  18%|        | 1474/8192 [01:44<08:48, 12.72it/s, est. speed input: 14466.52 toks/s, output: 14.13 toks/s]
Processed prompts:  19%|        | 1538/8192 [01:49<08:41, 12.77it/s, est. speed input: 14408.40 toks/s, output: 14.07 toks/s]
Processed prompts:  20%|        | 1602/8192 [01:54<08:37, 12.74it/s, est. speed input: 14345.06 toks/s, output: 14.01 toks/s]
Processed prompts:  20%|        | 1666/8192 [01:59<08:33, 12.72it/s, est. speed input: 14287.02 toks/s, output: 13.95 toks/s]
Processed prompts:  21%|        | 1730/8192 [02:04<08:28, 12.71it/s, est. speed input: 14234.14 toks/s, output: 13.90 toks/s]
Processed prompts:  22%|       | 1794/8192 [02:09<08:23, 12.70it/s, est. speed input: 14185.88 toks/s, output: 13.85 toks/s]
Processed prompts:  23%|       | 1858/8192 [02:14<08:16, 12.75it/s, est. speed input: 14148.78 toks/s, output: 13.82 toks/s]
Processed prompts:  23%|       | 1922/8192 [02:19<08:10, 12.79it/s, est. speed input: 14115.05 toks/s, output: 13.78 toks/s]
Processed prompts:  24%|       | 1986/8192 [02:24<08:06, 12.76it/s, est. speed input: 14075.91 toks/s, output: 13.75 toks/s]
Processed prompts:  25%|       | 2050/8192 [02:29<08:02, 12.74it/s, est. speed input: 14039.45 toks/s, output: 13.71 toks/s]
Processed prompts:  26%|       | 2114/8192 [02:34<07:57, 12.72it/s, est. speed input: 14005.03 toks/s, output: 13.68 toks/s]
Processed prompts:  27%|       | 2178/8192 [02:49<12:28,  8.04it/s, est. speed input: 13167.67 toks/s, output: 12.86 toks/s]
Processed prompts:  27%|       | 2242/8192 [02:54<10:59,  9.02it/s, est. speed input: 13160.33 toks/s, output: 12.85 toks/s]
Processed prompts:  28%|       | 2306/8192 [02:59<09:57,  9.86it/s, est. speed input: 13152.42 toks/s, output: 12.84 toks/s]
Processed prompts:  29%|       | 2369/8192 [03:13<09:50,  9.86it/s, est. speed input: 13511.69 toks/s, output: 13.20 toks/s]
Processed prompts:  29%|       | 2370/8192 [03:13<13:27,  7.21it/s, est. speed input: 12510.92 toks/s, output: 12.22 toks/s]
Processed prompts:  30%|       | 2434/8192 [03:19<11:38,  8.24it/s, est. speed input: 12515.53 toks/s, output: 12.22 toks/s]
Processed prompts:  30%|       | 2498/8192 [03:24<10:19,  9.20it/s, est. speed input: 12525.17 toks/s, output: 12.23 toks/s]
Processed prompts:  31%|      | 2562/8192 [03:29<09:22, 10.00it/s, est. speed input: 12533.86 toks/s, output: 12.24 toks/s]
Processed prompts:  32%|      | 2626/8192 [03:34<08:44, 10.62it/s, est. speed input: 12537.31 toks/s, output: 12.24 toks/s]
Processed prompts:  33%|      | 2690/8192 [03:39<08:16, 11.09it/s, est. speed input: 12540.66 toks/s, output: 12.25 toks/s]
Processed prompts:  34%|      | 2754/8192 [03:44<07:55, 11.44it/s, est. speed input: 12543.30 toks/s, output: 12.25 toks/s]
Processed prompts:  34%|      | 2818/8192 [03:50<07:39, 11.71it/s, est. speed input: 12546.20 toks/s, output: 12.25 toks/s]
Processed prompts:  35%|      | 2882/8192 [03:55<07:26, 11.90it/s, est. speed input: 12548.74 toks/s, output: 12.25 toks/s]
Processed prompts:  36%|      | 2946/8192 [04:00<07:15, 12.04it/s, est. speed input: 12551.31 toks/s, output: 12.26 toks/s]
Processed prompts:  37%|      | 3010/8192 [04:05<07:07, 12.13it/s, est. speed input: 12553.56 toks/s, output: 12.26 toks/s]
Processed prompts:  38%|      | 3074/8192 [04:10<06:59, 12.20it/s, est. speed input: 12555.57 toks/s, output: 12.26 toks/s]
Processed prompts:  38%|      | 3138/8192 [04:15<06:50, 12.31it/s, est. speed input: 12562.24 toks/s, output: 12.27 toks/s]
Processed prompts:  39%|      | 3202/8192 [04:20<06:44, 12.32it/s, est. speed input: 12563.81 toks/s, output: 12.27 toks/s]
Processed prompts:  40%|      | 3266/8192 [04:26<06:39, 12.33it/s, est. speed input: 12565.31 toks/s, output: 12.27 toks/s]
Processed prompts:  41%|      | 3330/8192 [04:31<06:34, 12.34it/s, est. speed input: 12567.07 toks/s, output: 12.27 toks/s]
Processed prompts:  41%|     | 3394/8192 [04:36<06:28, 12.34it/s, est. speed input: 12568.56 toks/s, output: 12.27 toks/s]
Processed prompts:  42%|     | 3458/8192 [04:50<09:49,  8.03it/s, est. speed input: 12169.16 toks/s, output: 11.88 toks/s]
Processed prompts:  43%|     | 3522/8192 [04:56<08:40,  8.98it/s, est. speed input: 12177.97 toks/s, output: 11.89 toks/s]
Processed prompts:  44%|     | 3586/8192 [05:01<07:50,  9.78it/s, est. speed input: 12186.47 toks/s, output: 11.90 toks/s]
Processed prompts:  45%|     | 3650/8192 [05:06<07:14, 10.44it/s, est. speed input: 12195.08 toks/s, output: 11.91 toks/s]
Processed prompts:  45%|     | 3714/8192 [05:11<06:46, 11.00it/s, est. speed input: 12206.29 toks/s, output: 11.92 toks/s]
Processed prompts:  46%|     | 3778/8192 [05:16<06:27, 11.38it/s, est. speed input: 12213.64 toks/s, output: 11.93 toks/s]
Processed prompts:  47%|     | 3842/8192 [05:21<06:13, 11.66it/s, est. speed input: 12221.00 toks/s, output: 11.93 toks/s]
Processed prompts:  48%|     | 3906/8192 [05:27<06:01, 11.87it/s, est. speed input: 12228.12 toks/s, output: 11.94 toks/s]
Processed prompts:  48%|     | 3970/8192 [05:32<05:51, 12.02it/s, est. speed input: 12235.47 toks/s, output: 11.95 toks/s]
Processed prompts:  49%|     | 4034/8192 [05:37<05:41, 12.19it/s, est. speed input: 12245.52 toks/s, output: 11.96 toks/s]
Processed prompts:  50%|     | 4098/8192 [05:42<05:34, 12.24it/s, est. speed input: 12251.77 toks/s, output: 11.96 toks/s]
Processed prompts:  51%|     | 4162/8192 [05:47<05:28, 12.28it/s, est. speed input: 12257.86 toks/s, output: 11.97 toks/s]
Processed prompts:  52%|    | 4226/8192 [06:02<08:15,  8.01it/s, est. speed input: 11949.06 toks/s, output: 11.67 toks/s]
Processed prompts:  52%|    | 4290/8192 [06:07<07:13,  8.99it/s, est. speed input: 11962.12 toks/s, output: 11.68 toks/s]
Processed prompts:  53%|    | 4354/8192 [06:12<06:31,  9.80it/s, est. speed input: 11972.25 toks/s, output: 11.69 toks/s]
Processed prompts:  54%|    | 4418/8192 [06:17<06:01, 10.45it/s, est. speed input: 11981.96 toks/s, output: 11.70 toks/s]
Processed prompts:  55%|    | 4482/8192 [06:22<05:38, 10.96it/s, est. speed input: 11991.22 toks/s, output: 11.71 toks/s]
Processed prompts:  55%|    | 4546/8192 [06:27<05:21, 11.35it/s, est. speed input: 12000.44 toks/s, output: 11.72 toks/s]
Processed prompts:  56%|    | 4610/8192 [06:33<05:07, 11.65it/s, est. speed input: 12009.40 toks/s, output: 11.73 toks/s]
Processed prompts:  57%|    | 4674/8192 [06:38<04:56, 11.85it/s, est. speed input: 12017.93 toks/s, output: 11.74 toks/s]
Processed prompts:  58%|    | 4738/8192 [06:43<04:46, 12.06it/s, est. speed input: 12028.72 toks/s, output: 11.75 toks/s]
Processed prompts:  59%|    | 4802/8192 [06:48<04:37, 12.21it/s, est. speed input: 12039.44 toks/s, output: 11.76 toks/s]
Processed prompts:  59%|    | 4866/8192 [06:53<04:31, 12.26it/s, est. speed input: 12047.09 toks/s, output: 11.76 toks/s]
Processed prompts:  60%|    | 4930/8192 [06:58<04:25, 12.29it/s, est. speed input: 12054.78 toks/s, output: 11.77 toks/s]
Processed prompts:  61%|    | 4994/8192 [07:13<06:38,  8.02it/s, est. speed input: 11803.85 toks/s, output: 11.53 toks/s]
Processed prompts:  62%|   | 5058/8192 [07:18<05:49,  8.97it/s, est. speed input: 11814.33 toks/s, output: 11.54 toks/s]
Processed prompts:  63%|   | 5122/8192 [07:23<05:13,  9.78it/s, est. speed input: 11824.51 toks/s, output: 11.55 toks/s]
Processed prompts:  63%|   | 5186/8192 [07:28<04:46, 10.48it/s, est. speed input: 11836.62 toks/s, output: 11.56 toks/s]
Processed prompts:  64%|   | 5250/8192 [07:33<04:27, 10.98it/s, est. speed input: 11846.05 toks/s, output: 11.57 toks/s]
Processed prompts:  65%|   | 5314/8192 [07:38<04:11, 11.42it/s, est. speed input: 11857.68 toks/s, output: 11.58 toks/s]
Processed prompts:  66%|   | 5378/8192 [07:43<03:59, 11.75it/s, est. speed input: 11869.00 toks/s, output: 11.59 toks/s]
Processed prompts:  66%|   | 5442/8192 [07:49<03:50, 11.93it/s, est. speed input: 11877.70 toks/s, output: 11.60 toks/s]
Processed prompts:  67%|   | 5506/8192 [07:54<03:41, 12.11it/s, est. speed input: 11888.35 toks/s, output: 11.61 toks/s]
Processed prompts:  68%|   | 5570/8192 [07:59<03:35, 12.19it/s, est. speed input: 11896.71 toks/s, output: 11.62 toks/s]
Processed prompts:  69%|   | 5634/8192 [08:04<03:27, 12.30it/s, est. speed input: 11907.08 toks/s, output: 11.63 toks/s]
Processed prompts:  70%|   | 5698/8192 [08:09<03:22, 12.33it/s, est. speed input: 11915.20 toks/s, output: 11.64 toks/s]
Processed prompts:  70%|   | 5762/8192 [08:14<03:16, 12.34it/s, est. speed input: 11923.18 toks/s, output: 11.64 toks/s]
Processed prompts:  71%|   | 5826/8192 [08:20<03:11, 12.35it/s, est. speed input: 11930.73 toks/s, output: 11.65 toks/s]
Processed prompts:  72%|  | 5890/8192 [08:25<03:06, 12.35it/s, est. speed input: 11938.12 toks/s, output: 11.66 toks/s]
Processed prompts:  73%|  | 5954/8192 [08:30<03:01, 12.35it/s, est. speed input: 11945.40 toks/s, output: 11.67 toks/s]
Processed prompts:  73%|  | 6018/8192 [08:35<02:55, 12.35it/s, est. speed input: 11952.49 toks/s, output: 11.67 toks/s]
Processed prompts:  74%|  | 6082/8192 [08:40<02:50, 12.36it/s, est. speed input: 11959.58 toks/s, output: 11.68 toks/s]
Processed prompts:  75%|  | 6146/8192 [08:45<02:45, 12.35it/s, est. speed input: 11966.26 toks/s, output: 11.69 toks/s]
Processed prompts:  76%|  | 6210/8192 [08:51<02:40, 12.36it/s, est. speed input: 11973.09 toks/s, output: 11.69 toks/s]
Processed prompts:  77%|  | 6274/8192 [08:56<02:35, 12.36it/s, est. speed input: 11979.68 toks/s, output: 11.70 toks/s]
Processed prompts:  77%|  | 6338/8192 [09:01<02:30, 12.36it/s, est. speed input: 11986.13 toks/s, output: 11.71 toks/s]
Processed prompts:  78%|  | 6402/8192 [09:06<02:24, 12.35it/s, est. speed input: 11992.36 toks/s, output: 11.71 toks/s]
Processed prompts:  79%|  | 6466/8192 [09:11<02:19, 12.36it/s, est. speed input: 11998.57 toks/s, output: 11.72 toks/s]
Processed prompts:  80%|  | 6530/8192 [09:17<02:14, 12.36it/s, est. speed input: 12004.64 toks/s, output: 11.72 toks/s]
Processed prompts:  80%|  | 6594/8192 [09:22<02:08, 12.42it/s, est. speed input: 12012.52 toks/s, output: 11.73 toks/s]
Processed prompts:  81%| | 6658/8192 [09:27<02:03, 12.47it/s, est. speed input: 12020.26 toks/s, output: 11.74 toks/s]
Processed prompts:  82%| | 6722/8192 [09:32<01:58, 12.43it/s, est. speed input: 12026.03 toks/s, output: 11.74 toks/s]
Processed prompts:  83%| | 6786/8192 [09:37<01:53, 12.41it/s, est. speed input: 12031.58 toks/s, output: 11.75 toks/s]
Processed prompts:  84%| | 6850/8192 [09:42<01:48, 12.39it/s, est. speed input: 12037.11 toks/s, output: 11.75 toks/s]
Processed prompts:  84%| | 6914/8192 [09:47<01:43, 12.38it/s, est. speed input: 12042.42 toks/s, output: 11.76 toks/s]
Processed prompts:  85%| | 6978/8192 [09:53<01:38, 12.37it/s, est. speed input: 12047.79 toks/s, output: 11.77 toks/s]
Processed prompts:  86%| | 7042/8192 [09:58<01:32, 12.37it/s, est. speed input: 12053.00 toks/s, output: 11.77 toks/s]
Processed prompts:  87%| | 7106/8192 [10:03<01:27, 12.43it/s, est. speed input: 12059.90 toks/s, output: 11.78 toks/s]
Processed prompts:  88%| | 7170/8192 [10:08<01:22, 12.41it/s, est. speed input: 12064.98 toks/s, output: 11.78 toks/s]
Processed prompts:  88%| | 7234/8192 [10:13<01:16, 12.45it/s, est. speed input: 12071.57 toks/s, output: 11.79 toks/s]
Processed prompts:  89%| | 7298/8192 [10:18<01:11, 12.42it/s, est. speed input: 12076.39 toks/s, output: 11.79 toks/s]
Processed prompts:  90%| | 7362/8192 [10:24<01:06, 12.40it/s, est. speed input: 12081.01 toks/s, output: 11.80 toks/s]
Processed prompts:  91%| | 7426/8192 [10:29<01:01, 12.45it/s, est. speed input: 12087.36 toks/s, output: 11.80 toks/s]
Processed prompts:  91%|| 7490/8192 [10:34<00:56, 12.42it/s, est. speed input: 12091.97 toks/s, output: 11.81 toks/s]
Processed prompts:  92%|| 7554/8192 [10:48<01:19,  8.06it/s, est. speed input: 11923.59 toks/s, output: 11.64 toks/s]
Processed prompts:  93%|| 7618/8192 [10:53<01:03,  9.00it/s, est. speed input: 11929.52 toks/s, output: 11.65 toks/s]
Processed prompts:  94%|| 7682/8192 [10:58<00:51,  9.84it/s, est. speed input: 11936.89 toks/s, output: 11.66 toks/s]
Processed prompts:  95%|| 7746/8192 [11:04<00:42, 10.48it/s, est. speed input: 11942.55 toks/s, output: 11.66 toks/s]
Processed prompts:  95%|| 7810/8192 [11:09<00:34, 10.98it/s, est. speed input: 11948.13 toks/s, output: 11.67 toks/s]
Processed prompts:  96%|| 7874/8192 [11:14<00:27, 11.36it/s, est. speed input: 11953.55 toks/s, output: 11.67 toks/s]
Processed prompts:  97%|| 7938/8192 [11:19<00:21, 11.71it/s, est. speed input: 11960.56 toks/s, output: 11.68 toks/s]
Processed prompts:  98%|| 8002/8192 [11:24<00:15, 11.89it/s, est. speed input: 11965.70 toks/s, output: 11.69 toks/s]
Processed prompts:  98%|| 8066/8192 [11:29<00:10, 12.09it/s, est. speed input: 11972.42 toks/s, output: 11.69 toks/s]
Processed prompts:  99%|| 8129/8192 [11:43<00:05, 12.09it/s, est. speed input: 12065.92 toks/s, output: 11.78 toks/s]
Processed prompts:  99%|| 8130/8192 [11:44<00:07,  7.96it/s, est. speed input: 11819.78 toks/s, output: 11.54 toks/s]
Processed prompts: 100%|| 8192/8192 [11:44<00:00,  7.96it/s, est. speed input: 11909.91 toks/s, output: 11.63 toks/s]
Processed prompts: 100%|| 8192/8192 [11:44<00:00, 11.63it/s, est. speed input: 11909.91 toks/s, output: 11.63 toks/s]
[rank0]:[W126 12:52:29.745955758 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-26 18:42:21
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Qwen2.5-7B-FP8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 18:42:25 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 18:42:25 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1611492) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1611492) WARNING 01-26 18:43:35 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 11.60 requests/s, 5948.67 total tokens/s, 11.60 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-26 18:42:25] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 18:42:25] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 18:42:25] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 18:42:25] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:42:25] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:42:25] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:42:25] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:42:25] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:42:25] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 18:42:25] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 18:42:25] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 18:42:25] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 18:42:25] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 18:42:25] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 18:42:28] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 18:42:28] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 18:42:28] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 18:42:28] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:42:28] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:42:28] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:42:28] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:42:28] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:42:28] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 18:42:28] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 18:42:28] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 18:42:28] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 18:42:28] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 18:42:28] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1611492) [2026-01-26 18:42:29] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1611492) [2026-01-26 18:42:29] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1611492) [2026-01-26 18:42:29] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1611492) [2026-01-26 18:42:29] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1611492) [2026-01-26 18:42:29] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1611492) [2026-01-26 18:42:29] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1611492) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1611492) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:23<00:23, 23.81s/it]
(EngineCore_DP0 pid=1611492) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:57<00:00, 29.44s/it]
(EngineCore_DP0 pid=1611492) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:57<00:00, 28.60s/it]
(EngineCore_DP0 pid=1611492) 
(EngineCore_DP0 pid=1611492) [2026-01-26 18:43:28] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=1611492) [2026-01-26 18:43:28] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 13860864 bytes
(EngineCore_DP0 pid=1611492) [2026-01-26 18:43:28] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=1611492) [2026-01-26 18:43:28] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10780672 bytes
(EngineCore_DP0 pid=1611492) [2026-01-26 18:43:28] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=1611492) [2026-01-26 18:43:28] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 113967104 bytes
(EngineCore_DP0 pid=1611492) [2026-01-26 18:43:28] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=1611492) [2026-01-26 18:43:28] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 56655872 bytes
(EngineCore_DP0 pid=1611492) 2026-01-26 18:43:34,937 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1611492) 2026-01-26 18:43:34,963 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  12%|        | 16/128 [00:00<00:00, 157.39it/s]
Adding requests:  74%|  | 95/128 [00:00<00:00, 524.74it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 525.27it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 2/128 [00:00<00:09, 13.63it/s, est. speed input: 6979.78 toks/s, output: 13.63 toks/s]
Processed prompts:   3%|         | 4/128 [00:00<00:09, 12.55it/s, est. speed input: 6501.63 toks/s, output: 12.70 toks/s]
Processed prompts:   5%|         | 6/128 [00:00<00:09, 12.27it/s, est. speed input: 6370.07 toks/s, output: 12.44 toks/s]
Processed prompts:   6%|         | 8/128 [00:00<00:09, 12.14it/s, est. speed input: 6303.08 toks/s, output: 12.31 toks/s]
Processed prompts:   8%|         | 10/128 [00:00<00:09, 12.05it/s, est. speed input: 6259.79 toks/s, output: 12.23 toks/s]
Processed prompts:   9%|         | 12/128 [00:00<00:09, 12.04it/s, est. speed input: 6241.00 toks/s, output: 12.19 toks/s]
Processed prompts:  11%|         | 14/128 [00:01<00:09, 12.02it/s, est. speed input: 6226.87 toks/s, output: 12.16 toks/s]
Processed prompts:  12%|        | 16/128 [00:01<00:09, 12.06it/s, est. speed input: 6224.42 toks/s, output: 12.16 toks/s]
Processed prompts:  14%|        | 18/128 [00:01<00:09, 11.96it/s, est. speed input: 6201.82 toks/s, output: 12.11 toks/s]
Processed prompts:  16%|        | 20/128 [00:01<00:09, 11.99it/s, est. speed input: 6198.66 toks/s, output: 12.11 toks/s]
Processed prompts:  17%|        | 22/128 [00:01<00:08, 11.92it/s, est. speed input: 6182.55 toks/s, output: 12.08 toks/s]
Processed prompts:  19%|        | 24/128 [00:01<00:08, 11.84it/s, est. speed input: 6164.50 toks/s, output: 12.04 toks/s]
Processed prompts:  20%|        | 26/128 [00:02<00:08, 11.88it/s, est. speed input: 6161.12 toks/s, output: 12.03 toks/s]
Processed prompts:  22%|       | 28/128 [00:02<00:08, 11.91it/s, est. speed input: 6159.19 toks/s, output: 12.03 toks/s]
Processed prompts:  23%|       | 30/128 [00:02<00:08, 12.01it/s, est. speed input: 6166.91 toks/s, output: 12.04 toks/s]
Processed prompts:  25%|       | 32/128 [00:02<00:08, 12.00it/s, est. speed input: 6164.32 toks/s, output: 12.04 toks/s]
Processed prompts:  27%|       | 34/128 [00:02<00:07, 12.03it/s, est. speed input: 6166.12 toks/s, output: 12.04 toks/s]
Processed prompts:  28%|       | 36/128 [00:02<00:07, 11.88it/s, est. speed input: 6151.36 toks/s, output: 12.01 toks/s]
Processed prompts:  30%|       | 38/128 [00:03<00:07, 11.94it/s, est. speed input: 6153.69 toks/s, output: 12.02 toks/s]
Processed prompts:  31%|      | 40/128 [00:03<00:07, 11.93it/s, est. speed input: 6150.85 toks/s, output: 12.01 toks/s]
Processed prompts:  33%|      | 42/128 [00:03<00:07, 11.94it/s, est. speed input: 6149.80 toks/s, output: 12.01 toks/s]
Processed prompts:  34%|      | 44/128 [00:03<00:07, 11.92it/s, est. speed input: 6146.27 toks/s, output: 12.00 toks/s]
Processed prompts:  36%|      | 46/128 [00:03<00:06, 11.91it/s, est. speed input: 6143.73 toks/s, output: 12.00 toks/s]
Processed prompts:  38%|      | 48/128 [00:04<00:06, 11.79it/s, est. speed input: 6133.11 toks/s, output: 11.98 toks/s]
Processed prompts:  39%|      | 50/128 [00:04<00:06, 11.84it/s, est. speed input: 6132.38 toks/s, output: 11.98 toks/s]
Processed prompts:  41%|      | 52/128 [00:04<00:06, 11.87it/s, est. speed input: 6131.61 toks/s, output: 11.98 toks/s]
Processed prompts:  42%|     | 54/128 [00:04<00:06, 11.89it/s, est. speed input: 6131.30 toks/s, output: 11.98 toks/s]
Processed prompts:  44%|     | 56/128 [00:04<00:06, 12.00it/s, est. speed input: 6136.02 toks/s, output: 11.98 toks/s]
Processed prompts:  45%|     | 58/128 [00:04<00:05, 11.97it/s, est. speed input: 6134.53 toks/s, output: 11.98 toks/s]
Processed prompts:  47%|     | 60/128 [00:05<00:05, 11.95it/s, est. speed input: 6133.08 toks/s, output: 11.98 toks/s]
Processed prompts:  48%|     | 62/128 [00:05<00:05, 11.89it/s, est. speed input: 6129.31 toks/s, output: 11.97 toks/s]
Processed prompts:  50%|     | 64/128 [00:05<00:05, 11.89it/s, est. speed input: 6128.34 toks/s, output: 11.97 toks/s]
Processed prompts:  52%|    | 66/128 [00:05<00:05, 11.91it/s, est. speed input: 6128.14 toks/s, output: 11.97 toks/s]
Processed prompts:  53%|    | 68/128 [00:05<00:05, 11.92it/s, est. speed input: 6127.67 toks/s, output: 11.97 toks/s]
Processed prompts:  55%|    | 70/128 [00:05<00:04, 11.90it/s, est. speed input: 6126.08 toks/s, output: 11.96 toks/s]
Processed prompts:  56%|    | 72/128 [00:06<00:04, 11.85it/s, est. speed input: 6122.54 toks/s, output: 11.96 toks/s]
Processed prompts:  58%|    | 74/128 [00:06<00:04, 11.80it/s, est. speed input: 6118.96 toks/s, output: 11.95 toks/s]
Processed prompts:  59%|    | 76/128 [00:06<00:04, 11.86it/s, est. speed input: 6119.36 toks/s, output: 11.95 toks/s]
Processed prompts:  61%|    | 78/128 [00:06<00:04, 11.85it/s, est. speed input: 6117.80 toks/s, output: 11.95 toks/s]
Processed prompts:  62%|   | 80/128 [00:06<00:04, 11.84it/s, est. speed input: 6116.01 toks/s, output: 11.95 toks/s]
Processed prompts:  64%|   | 82/128 [00:06<00:03, 11.83it/s, est. speed input: 6114.21 toks/s, output: 11.94 toks/s]
Processed prompts:  66%|   | 84/128 [00:07<00:03, 11.83it/s, est. speed input: 6113.06 toks/s, output: 11.94 toks/s]
Processed prompts:  67%|   | 86/128 [00:07<00:03, 11.72it/s, est. speed input: 6106.93 toks/s, output: 11.93 toks/s]
Processed prompts:  69%|   | 88/128 [00:07<00:03, 11.75it/s, est. speed input: 6105.70 toks/s, output: 11.93 toks/s]
Processed prompts:  70%|   | 90/128 [00:07<00:03, 11.79it/s, est. speed input: 6105.45 toks/s, output: 11.92 toks/s]
Processed prompts:  72%|  | 92/128 [00:07<00:03, 11.83it/s, est. speed input: 6105.34 toks/s, output: 11.92 toks/s]
Processed prompts:  73%|  | 94/128 [00:07<00:02, 11.84it/s, est. speed input: 6104.78 toks/s, output: 11.92 toks/s]
Processed prompts:  75%|  | 96/128 [00:08<00:02, 11.90it/s, est. speed input: 6105.92 toks/s, output: 11.93 toks/s]
Processed prompts:  77%|  | 98/128 [00:08<00:02, 11.76it/s, est. speed input: 6100.59 toks/s, output: 11.92 toks/s]
Processed prompts:  78%|  | 100/128 [00:08<00:02, 11.82it/s, est. speed input: 6101.03 toks/s, output: 11.92 toks/s]
Processed prompts:  80%|  | 102/128 [00:08<00:02, 11.90it/s, est. speed input: 6102.71 toks/s, output: 11.92 toks/s]
Processed prompts:  81%| | 104/128 [00:08<00:02, 11.86it/s, est. speed input: 6101.29 toks/s, output: 11.92 toks/s]
Processed prompts:  83%| | 106/128 [00:08<00:01, 11.93it/s, est. speed input: 6103.15 toks/s, output: 11.92 toks/s]
Processed prompts:  84%| | 108/128 [00:09<00:01, 11.95it/s, est. speed input: 6103.86 toks/s, output: 11.92 toks/s]
Processed prompts:  86%| | 110/128 [00:09<00:01, 11.98it/s, est. speed input: 6104.85 toks/s, output: 11.92 toks/s]
Processed prompts:  88%| | 112/128 [00:09<00:01, 11.77it/s, est. speed input: 6099.12 toks/s, output: 11.91 toks/s]
Processed prompts:  89%| | 114/128 [00:09<00:01, 11.81it/s, est. speed input: 6098.91 toks/s, output: 11.91 toks/s]
Processed prompts:  91%| | 116/128 [00:09<00:01, 11.81it/s, est. speed input: 6098.16 toks/s, output: 11.91 toks/s]
Processed prompts:  92%|| 118/128 [00:09<00:00, 11.76it/s, est. speed input: 6095.66 toks/s, output: 11.91 toks/s]
Processed prompts:  94%|| 120/128 [00:10<00:00, 11.85it/s, est. speed input: 6096.95 toks/s, output: 11.91 toks/s]
Processed prompts:  95%|| 122/128 [00:10<00:00, 11.85it/s, est. speed input: 6096.41 toks/s, output: 11.91 toks/s]
Processed prompts:  97%|| 124/128 [00:10<00:00, 11.67it/s, est. speed input: 6091.02 toks/s, output: 11.90 toks/s]
Processed prompts:  98%|| 126/128 [00:10<00:00, 11.73it/s, est. speed input: 6090.67 toks/s, output: 11.90 toks/s]
Processed prompts: 100%|| 128/128 [00:10<00:00, 11.62it/s, est. speed input: 6086.30 toks/s, output: 11.89 toks/s]
Processed prompts: 100%|| 128/128 [00:10<00:00, 11.62it/s, est. speed input: 6086.30 toks/s, output: 11.89 toks/s]
Processed prompts: 100%|| 128/128 [00:10<00:00, 11.89it/s, est. speed input: 6086.30 toks/s, output: 11.89 toks/s]
[rank0]:[W126 18:43:47.202657167 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-26 18:43:52
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Qwen2.5-7B-FP8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 18:43:59 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 18:43:59 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1612994) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1612994) WARNING 01-26 18:45:10 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 6.05 requests/s, 6201.39 total tokens/s, 6.05 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-26 18:43:59] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 18:43:59] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 18:43:59] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 18:43:59] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:43:59] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:43:59] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:43:59] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:43:59] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:43:59] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 18:43:59] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 18:43:59] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 18:43:59] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 18:43:59] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 18:43:59] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 18:44:03] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 18:44:03] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 18:44:03] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 18:44:03] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:44:03] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:44:03] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:44:03] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:44:03] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:44:03] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 18:44:03] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 18:44:03] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 18:44:03] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 18:44:03] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 18:44:03] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1612994) [2026-01-26 18:44:04] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1612994) [2026-01-26 18:44:04] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1612994) [2026-01-26 18:44:04] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1612994) [2026-01-26 18:44:04] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1612994) [2026-01-26 18:44:04] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1612994) [2026-01-26 18:44:04] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1612994) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1612994) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:24<00:24, 24.61s/it]
(EngineCore_DP0 pid=1612994) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:58<00:00, 30.04s/it]
(EngineCore_DP0 pid=1612994) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:58<00:00, 29.22s/it]
(EngineCore_DP0 pid=1612994) 
(EngineCore_DP0 pid=1612994) [2026-01-26 18:45:03] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=1612994) [2026-01-26 18:45:03] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 13860864 bytes
(EngineCore_DP0 pid=1612994) [2026-01-26 18:45:03] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=1612994) [2026-01-26 18:45:03] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10780672 bytes
(EngineCore_DP0 pid=1612994) [2026-01-26 18:45:03] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=1612994) [2026-01-26 18:45:03] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 113967104 bytes
(EngineCore_DP0 pid=1612994) [2026-01-26 18:45:03] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=1612994) [2026-01-26 18:45:03] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 56655872 bytes
(EngineCore_DP0 pid=1612994) 2026-01-26 18:45:10,049 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1612994) 2026-01-26 18:45:10,113 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  36%|      | 46/128 [00:00<00:00, 459.52it/s]
Adding requests:  72%|  | 92/128 [00:00<00:00, 395.24it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 390.78it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 3/128 [00:00<00:10, 11.38it/s, est. speed input: 11649.06 toks/s, output: 11.38 toks/s]
Processed prompts:   4%|         | 5/128 [00:00<00:15,  8.04it/s, est. speed input: 8692.68 toks/s, output: 8.49 toks/s]  
Processed prompts:   5%|         | 6/128 [00:00<00:16,  7.50it/s, est. speed input: 8210.35 toks/s, output: 8.02 toks/s]
Processed prompts:   5%|         | 7/128 [00:00<00:17,  7.01it/s, est. speed input: 7825.97 toks/s, output: 7.64 toks/s]
Processed prompts:   6%|         | 8/128 [00:01<00:17,  6.73it/s, est. speed input: 7584.19 toks/s, output: 7.41 toks/s]
Processed prompts:   7%|         | 9/128 [00:01<00:18,  6.54it/s, est. speed input: 7411.70 toks/s, output: 7.24 toks/s]
Processed prompts:   8%|         | 10/128 [00:01<00:18,  6.43it/s, est. speed input: 7282.63 toks/s, output: 7.11 toks/s]
Processed prompts:   9%|         | 11/128 [00:01<00:18,  6.35it/s, est. speed input: 7182.22 toks/s, output: 7.01 toks/s]
Processed prompts:   9%|         | 12/128 [00:01<00:18,  6.29it/s, est. speed input: 7100.45 toks/s, output: 6.93 toks/s]
Processed prompts:  10%|         | 13/128 [00:01<00:18,  6.26it/s, est. speed input: 7035.38 toks/s, output: 6.87 toks/s]
Processed prompts:  11%|         | 14/128 [00:02<00:18,  6.16it/s, est. speed input: 6958.49 toks/s, output: 6.80 toks/s]
Processed prompts:  12%|        | 15/128 [00:02<00:18,  6.16it/s, est. speed input: 6908.73 toks/s, output: 6.75 toks/s]
Processed prompts:  12%|        | 16/128 [00:02<00:18,  6.12it/s, est. speed input: 6858.44 toks/s, output: 6.70 toks/s]
Processed prompts:  13%|        | 17/128 [00:02<00:18,  6.13it/s, est. speed input: 6821.77 toks/s, output: 6.66 toks/s]
Processed prompts:  14%|        | 18/128 [00:02<00:17,  6.11it/s, est. speed input: 6786.12 toks/s, output: 6.63 toks/s]
Processed prompts:  15%|        | 19/128 [00:02<00:17,  6.11it/s, est. speed input: 6755.98 toks/s, output: 6.60 toks/s]
Processed prompts:  16%|        | 20/128 [00:03<00:17,  6.04it/s, est. speed input: 6715.55 toks/s, output: 6.56 toks/s]
Processed prompts:  16%|        | 21/128 [00:03<00:17,  6.09it/s, est. speed input: 6697.96 toks/s, output: 6.54 toks/s]
Processed prompts:  17%|        | 22/128 [00:03<00:17,  6.13it/s, est. speed input: 6681.80 toks/s, output: 6.53 toks/s]
Processed prompts:  18%|        | 23/128 [00:03<00:17,  6.17it/s, est. speed input: 6669.70 toks/s, output: 6.51 toks/s]
Processed prompts:  19%|        | 24/128 [00:03<00:16,  6.16it/s, est. speed input: 6653.12 toks/s, output: 6.50 toks/s]
Processed prompts:  20%|        | 25/128 [00:03<00:16,  6.17it/s, est. speed input: 6639.40 toks/s, output: 6.48 toks/s]
Processed prompts:  20%|        | 26/128 [00:04<00:16,  6.16it/s, est. speed input: 6624.85 toks/s, output: 6.47 toks/s]
Processed prompts:  21%|        | 27/128 [00:04<00:16,  6.09it/s, est. speed input: 6603.18 toks/s, output: 6.45 toks/s]
Processed prompts:  22%|       | 28/128 [00:04<00:16,  6.10it/s, est. speed input: 6590.33 toks/s, output: 6.44 toks/s]
Processed prompts:  23%|       | 29/128 [00:04<00:16,  6.08it/s, est. speed input: 6574.94 toks/s, output: 6.42 toks/s]
Processed prompts:  23%|       | 30/128 [00:04<00:16,  6.09it/s, est. speed input: 6563.66 toks/s, output: 6.41 toks/s]
Processed prompts:  24%|       | 31/128 [00:04<00:15,  6.07it/s, est. speed input: 6550.43 toks/s, output: 6.40 toks/s]
Processed prompts:  25%|       | 32/128 [00:05<00:15,  6.10it/s, est. speed input: 6542.57 toks/s, output: 6.39 toks/s]
Processed prompts:  26%|       | 33/128 [00:05<00:15,  6.05it/s, est. speed input: 6527.70 toks/s, output: 6.37 toks/s]
Processed prompts:  27%|       | 34/128 [00:05<00:15,  6.07it/s, est. speed input: 6519.61 toks/s, output: 6.37 toks/s]
Processed prompts:  27%|       | 35/128 [00:05<00:15,  6.10it/s, est. speed input: 6513.75 toks/s, output: 6.36 toks/s]
Processed prompts:  28%|       | 36/128 [00:05<00:15,  6.11it/s, est. speed input: 6506.75 toks/s, output: 6.35 toks/s]
Processed prompts:  29%|       | 37/128 [00:05<00:14,  6.11it/s, est. speed input: 6499.77 toks/s, output: 6.35 toks/s]
Processed prompts:  30%|       | 38/128 [00:05<00:14,  6.10it/s, est. speed input: 6492.19 toks/s, output: 6.34 toks/s]
Processed prompts:  30%|       | 39/128 [00:06<00:14,  6.07it/s, est. speed input: 6482.51 toks/s, output: 6.33 toks/s]
Processed prompts:  31%|      | 40/128 [00:06<00:14,  6.06it/s, est. speed input: 6474.78 toks/s, output: 6.32 toks/s]
Processed prompts:  32%|      | 41/128 [00:06<00:14,  6.06it/s, est. speed input: 6468.34 toks/s, output: 6.32 toks/s]
Processed prompts:  33%|      | 42/128 [00:06<00:14,  6.08it/s, est. speed input: 6463.74 toks/s, output: 6.31 toks/s]
Processed prompts:  34%|      | 43/128 [00:06<00:13,  6.07it/s, est. speed input: 6457.21 toks/s, output: 6.31 toks/s]
Processed prompts:  34%|      | 44/128 [00:06<00:13,  6.11it/s, est. speed input: 6454.36 toks/s, output: 6.30 toks/s]
Processed prompts:  35%|      | 45/128 [00:07<00:13,  6.13it/s, est. speed input: 6451.73 toks/s, output: 6.30 toks/s]
Processed prompts:  36%|      | 46/128 [00:07<00:13,  6.06it/s, est. speed input: 6442.35 toks/s, output: 6.29 toks/s]
Processed prompts:  37%|      | 47/128 [00:07<00:13,  6.05it/s, est. speed input: 6436.16 toks/s, output: 6.29 toks/s]
Processed prompts:  38%|      | 48/128 [00:07<00:13,  6.08it/s, est. speed input: 6433.18 toks/s, output: 6.28 toks/s]
Processed prompts:  38%|      | 49/128 [00:07<00:12,  6.08it/s, est. speed input: 6428.97 toks/s, output: 6.28 toks/s]
Processed prompts:  39%|      | 50/128 [00:07<00:12,  6.09it/s, est. speed input: 6425.56 toks/s, output: 6.27 toks/s]
Processed prompts:  40%|      | 51/128 [00:08<00:12,  6.08it/s, est. speed input: 6420.92 toks/s, output: 6.27 toks/s]
Processed prompts:  41%|      | 52/128 [00:08<00:12,  6.08it/s, est. speed input: 6416.78 toks/s, output: 6.27 toks/s]
Processed prompts:  41%|     | 53/128 [00:08<00:12,  6.08it/s, est. speed input: 6413.03 toks/s, output: 6.26 toks/s]
Processed prompts:  42%|     | 54/128 [00:08<00:12,  6.09it/s, est. speed input: 6410.09 toks/s, output: 6.26 toks/s]
Processed prompts:  43%|     | 55/128 [00:08<00:11,  6.09it/s, est. speed input: 6406.71 toks/s, output: 6.26 toks/s]
Processed prompts:  44%|     | 56/128 [00:08<00:11,  6.06it/s, est. speed input: 6402.11 toks/s, output: 6.25 toks/s]
Processed prompts:  45%|     | 57/128 [00:09<00:11,  6.06it/s, est. speed input: 6398.35 toks/s, output: 6.25 toks/s]
Processed prompts:  45%|     | 58/128 [00:09<00:11,  6.07it/s, est. speed input: 6395.49 toks/s, output: 6.25 toks/s]
Processed prompts:  46%|     | 59/128 [00:09<00:11,  6.03it/s, est. speed input: 6389.89 toks/s, output: 6.24 toks/s]
Processed prompts:  47%|     | 60/128 [00:09<00:11,  6.05it/s, est. speed input: 6387.51 toks/s, output: 6.24 toks/s]
Processed prompts:  48%|     | 61/128 [00:09<00:11,  6.05it/s, est. speed input: 6384.41 toks/s, output: 6.23 toks/s]
Processed prompts:  48%|     | 62/128 [00:09<00:10,  6.07it/s, est. speed input: 6382.06 toks/s, output: 6.23 toks/s]
Processed prompts:  49%|     | 63/128 [00:10<00:10,  6.06it/s, est. speed input: 6378.83 toks/s, output: 6.23 toks/s]
Processed prompts:  50%|     | 64/128 [00:10<00:10,  6.06it/s, est. speed input: 6376.07 toks/s, output: 6.23 toks/s]
Processed prompts:  51%|     | 65/128 [00:10<00:10,  6.02it/s, est. speed input: 6371.18 toks/s, output: 6.22 toks/s]
Processed prompts:  52%|    | 66/128 [00:10<00:10,  6.03it/s, est. speed input: 6368.67 toks/s, output: 6.22 toks/s]
Processed prompts:  52%|    | 67/128 [00:10<00:10,  6.04it/s, est. speed input: 6365.91 toks/s, output: 6.22 toks/s]
Processed prompts:  53%|    | 68/128 [00:10<00:09,  6.04it/s, est. speed input: 6363.53 toks/s, output: 6.21 toks/s]
Processed prompts:  54%|    | 69/128 [00:11<00:09,  6.05it/s, est. speed input: 6361.44 toks/s, output: 6.21 toks/s]
Processed prompts:  55%|    | 70/128 [00:11<00:09,  6.07it/s, est. speed input: 6359.83 toks/s, output: 6.21 toks/s]
Processed prompts:  55%|    | 71/128 [00:11<00:09,  6.07it/s, est. speed input: 6357.58 toks/s, output: 6.21 toks/s]
Processed prompts:  56%|    | 72/128 [00:11<00:09,  6.02it/s, est. speed input: 6353.07 toks/s, output: 6.20 toks/s]
Processed prompts:  57%|    | 73/128 [00:11<00:09,  6.02it/s, est. speed input: 6350.57 toks/s, output: 6.20 toks/s]
Processed prompts:  58%|    | 74/128 [00:11<00:08,  6.04it/s, est. speed input: 6349.11 toks/s, output: 6.20 toks/s]
Processed prompts:  59%|    | 75/128 [00:12<00:08,  6.09it/s, est. speed input: 6349.28 toks/s, output: 6.20 toks/s]
Processed prompts:  59%|    | 76/128 [00:12<00:08,  6.09it/s, est. speed input: 6347.77 toks/s, output: 6.20 toks/s]
Processed prompts:  60%|    | 77/128 [00:12<00:08,  6.10it/s, est. speed input: 6346.47 toks/s, output: 6.20 toks/s]
Processed prompts:  61%|    | 78/128 [00:12<00:08,  6.02it/s, est. speed input: 6341.61 toks/s, output: 6.19 toks/s]
Processed prompts:  62%|   | 79/128 [00:12<00:08,  6.05it/s, est. speed input: 6340.82 toks/s, output: 6.19 toks/s]
Processed prompts:  62%|   | 80/128 [00:12<00:07,  6.09it/s, est. speed input: 6340.60 toks/s, output: 6.19 toks/s]
Processed prompts:  63%|   | 81/128 [00:13<00:07,  6.11it/s, est. speed input: 6340.34 toks/s, output: 6.19 toks/s]
Processed prompts:  64%|   | 82/128 [00:13<00:07,  6.10it/s, est. speed input: 6338.92 toks/s, output: 6.19 toks/s]
Processed prompts:  65%|   | 83/128 [00:13<00:07,  6.08it/s, est. speed input: 6337.00 toks/s, output: 6.19 toks/s]
Processed prompts:  66%|   | 84/128 [00:13<00:07,  6.10it/s, est. speed input: 6336.55 toks/s, output: 6.19 toks/s]
Processed prompts:  66%|   | 85/128 [00:13<00:07,  6.03it/s, est. speed input: 6332.48 toks/s, output: 6.18 toks/s]
Processed prompts:  67%|   | 86/128 [00:13<00:06,  6.06it/s, est. speed input: 6331.91 toks/s, output: 6.18 toks/s]
Processed prompts:  68%|   | 87/128 [00:14<00:06,  6.06it/s, est. speed input: 6330.24 toks/s, output: 6.18 toks/s]
Processed prompts:  69%|   | 88/128 [00:14<00:06,  6.09it/s, est. speed input: 6329.93 toks/s, output: 6.18 toks/s]
Processed prompts:  70%|   | 89/128 [00:14<00:06,  6.10it/s, est. speed input: 6329.32 toks/s, output: 6.18 toks/s]
Processed prompts:  70%|   | 90/128 [00:14<00:06,  6.11it/s, est. speed input: 6328.70 toks/s, output: 6.18 toks/s]
Processed prompts:  71%|   | 91/128 [00:14<00:06,  6.06it/s, est. speed input: 6326.11 toks/s, output: 6.18 toks/s]
Processed prompts:  72%|  | 92/128 [00:14<00:05,  6.08it/s, est. speed input: 6325.64 toks/s, output: 6.18 toks/s]
Processed prompts:  73%|  | 93/128 [00:15<00:05,  6.09it/s, est. speed input: 6324.78 toks/s, output: 6.18 toks/s]
Processed prompts:  73%|  | 94/128 [00:15<00:05,  6.07it/s, est. speed input: 6323.28 toks/s, output: 6.18 toks/s]
Processed prompts:  74%|  | 95/128 [00:15<00:05,  6.10it/s, est. speed input: 6322.99 toks/s, output: 6.17 toks/s]
Processed prompts:  75%|  | 96/128 [00:15<00:05,  6.10it/s, est. speed input: 6322.37 toks/s, output: 6.17 toks/s]
Processed prompts:  76%|  | 97/128 [00:15<00:05,  6.10it/s, est. speed input: 6321.64 toks/s, output: 6.17 toks/s]
Processed prompts:  77%|  | 98/128 [00:15<00:04,  6.03it/s, est. speed input: 6318.13 toks/s, output: 6.17 toks/s]
Processed prompts:  77%|  | 99/128 [00:16<00:04,  6.03it/s, est. speed input: 6316.75 toks/s, output: 6.17 toks/s]
Processed prompts:  78%|  | 100/128 [00:16<00:04,  6.05it/s, est. speed input: 6316.15 toks/s, output: 6.17 toks/s]
Processed prompts:  79%|  | 101/128 [00:16<00:04,  6.05it/s, est. speed input: 6314.70 toks/s, output: 6.17 toks/s]
Processed prompts:  80%|  | 102/128 [00:16<00:04,  6.06it/s, est. speed input: 6313.94 toks/s, output: 6.17 toks/s]
Processed prompts:  80%|  | 103/128 [00:16<00:04,  6.06it/s, est. speed input: 6312.98 toks/s, output: 6.17 toks/s]
Processed prompts:  81%| | 104/128 [00:16<00:03,  6.03it/s, est. speed input: 6310.77 toks/s, output: 6.16 toks/s]
Processed prompts:  82%| | 105/128 [00:17<00:03,  6.02it/s, est. speed input: 6309.28 toks/s, output: 6.16 toks/s]
Processed prompts:  83%| | 106/128 [00:17<00:03,  6.04it/s, est. speed input: 6308.36 toks/s, output: 6.16 toks/s]
Processed prompts:  84%| | 107/128 [00:17<00:03,  6.07it/s, est. speed input: 6308.32 toks/s, output: 6.16 toks/s]
Processed prompts:  84%| | 108/128 [00:17<00:03,  6.08it/s, est. speed input: 6307.77 toks/s, output: 6.16 toks/s]
Processed prompts:  85%| | 109/128 [00:17<00:03,  6.10it/s, est. speed input: 6307.58 toks/s, output: 6.16 toks/s]
Processed prompts:  86%| | 110/128 [00:17<00:02,  6.06it/s, est. speed input: 6305.62 toks/s, output: 6.16 toks/s]
Processed prompts:  87%| | 111/128 [00:18<00:02,  6.03it/s, est. speed input: 6303.91 toks/s, output: 6.16 toks/s]
Processed prompts:  88%| | 112/128 [00:18<00:02,  6.07it/s, est. speed input: 6303.91 toks/s, output: 6.16 toks/s]
Processed prompts:  88%| | 113/128 [00:18<00:02,  6.07it/s, est. speed input: 6303.21 toks/s, output: 6.16 toks/s]
Processed prompts:  89%| | 114/128 [00:18<00:02,  6.06it/s, est. speed input: 6302.22 toks/s, output: 6.15 toks/s]
Processed prompts:  90%| | 115/128 [00:18<00:02,  6.08it/s, est. speed input: 6302.01 toks/s, output: 6.15 toks/s]
Processed prompts:  91%| | 116/128 [00:18<00:01,  6.06it/s, est. speed input: 6300.78 toks/s, output: 6.15 toks/s]
Processed prompts:  91%|| 117/128 [00:19<00:01,  6.03it/s, est. speed input: 6298.92 toks/s, output: 6.15 toks/s]
Processed prompts:  92%|| 118/128 [00:19<00:01,  6.03it/s, est. speed input: 6297.86 toks/s, output: 6.15 toks/s]
Processed prompts:  93%|| 119/128 [00:19<00:01,  6.06it/s, est. speed input: 6297.68 toks/s, output: 6.15 toks/s]
Processed prompts:  94%|| 120/128 [00:19<00:01,  6.12it/s, est. speed input: 6298.66 toks/s, output: 6.15 toks/s]
Processed prompts:  95%|| 121/128 [00:19<00:01,  6.11it/s, est. speed input: 6298.12 toks/s, output: 6.15 toks/s]
Processed prompts:  95%|| 122/128 [00:19<00:00,  6.09it/s, est. speed input: 6297.29 toks/s, output: 6.15 toks/s]
Processed prompts:  96%|| 123/128 [00:20<00:00,  6.03it/s, est. speed input: 6295.09 toks/s, output: 6.15 toks/s]
Processed prompts:  97%|| 124/128 [00:20<00:00,  6.07it/s, est. speed input: 6295.27 toks/s, output: 6.15 toks/s]
Processed prompts:  98%|| 125/128 [00:20<00:00,  6.08it/s, est. speed input: 6294.90 toks/s, output: 6.15 toks/s]
Processed prompts:  98%|| 126/128 [00:20<00:00,  6.08it/s, est. speed input: 6294.26 toks/s, output: 6.15 toks/s]
Processed prompts:  99%|| 127/128 [00:20<00:00,  6.09it/s, est. speed input: 6293.99 toks/s, output: 6.15 toks/s]
Processed prompts: 100%|| 128/128 [00:20<00:00,  6.07it/s, est. speed input: 6293.13 toks/s, output: 6.15 toks/s]
Processed prompts: 100%|| 128/128 [00:20<00:00,  6.07it/s, est. speed input: 6293.13 toks/s, output: 6.15 toks/s]
Processed prompts: 100%|| 128/128 [00:20<00:00,  6.15it/s, est. speed input: 6293.13 toks/s, output: 6.15 toks/s]
[rank0]:[W126 18:45:32.344108994 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-26 18:45:34
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Qwen2.5-7B-FP8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 18:45:40 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 18:45:40 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1614564) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1614564) WARNING 01-26 18:46:51 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 6.03 requests/s, 6185.84 total tokens/s, 6.03 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-26 18:45:40] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 18:45:40] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 18:45:40] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 18:45:40] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:45:40] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:45:40] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:45:40] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:45:40] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:45:40] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 18:45:40] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 18:45:40] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 18:45:40] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 18:45:40] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 18:45:40] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 18:45:43] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 18:45:43] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 18:45:43] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 18:45:43] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:45:43] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:45:43] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:45:43] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:45:43] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:45:43] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 18:45:43] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 18:45:43] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 18:45:43] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 18:45:43] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 18:45:43] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1614564) [2026-01-26 18:45:44] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1614564) [2026-01-26 18:45:44] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1614564) [2026-01-26 18:45:44] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1614564) [2026-01-26 18:45:44] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1614564) [2026-01-26 18:45:44] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1614564) [2026-01-26 18:45:44] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1614564) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1614564) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:23<00:23, 23.92s/it]
(EngineCore_DP0 pid=1614564) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:57<00:00, 29.80s/it]
(EngineCore_DP0 pid=1614564) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:57<00:00, 28.92s/it]
(EngineCore_DP0 pid=1614564) 
(EngineCore_DP0 pid=1614564) [2026-01-26 18:46:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=1614564) [2026-01-26 18:46:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 13860864 bytes
(EngineCore_DP0 pid=1614564) [2026-01-26 18:46:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=1614564) [2026-01-26 18:46:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10780672 bytes
(EngineCore_DP0 pid=1614564) [2026-01-26 18:46:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=1614564) [2026-01-26 18:46:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 113967104 bytes
(EngineCore_DP0 pid=1614564) [2026-01-26 18:46:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=1614564) [2026-01-26 18:46:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 56655872 bytes
(EngineCore_DP0 pid=1614564) 2026-01-26 18:46:50,214 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1614564) 2026-01-26 18:46:50,305 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  11%|         | 28/256 [00:00<00:00, 276.11it/s]
Adding requests:  28%|       | 71/256 [00:00<00:00, 364.82it/s]
Adding requests:  45%|     | 115/256 [00:00<00:00, 396.72it/s]
Adding requests:  63%|   | 161/256 [00:00<00:00, 415.91it/s]
Adding requests:  79%|  | 203/256 [00:00<00:00, 398.56it/s]
Adding requests:  95%|| 243/256 [00:00<00:00, 370.65it/s]
Adding requests: 100%|| 256/256 [00:00<00:00, 376.97it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 4/256 [00:00<00:26,  9.64it/s, est. speed input: 9873.64 toks/s, output: 9.64 toks/s]
Processed prompts:   2%|         | 6/256 [00:01<00:45,  5.47it/s, est. speed input: 6136.80 toks/s, output: 5.99 toks/s]
Processed prompts:   3%|         | 8/256 [00:01<00:43,  5.69it/s, est. speed input: 6162.95 toks/s, output: 6.02 toks/s]
Processed prompts:   4%|         | 10/256 [00:01<00:41,  5.88it/s, est. speed input: 6210.49 toks/s, output: 6.06 toks/s]
Processed prompts:   5%|         | 12/256 [00:01<00:40,  5.97it/s, est. speed input: 6228.29 toks/s, output: 6.08 toks/s]
Processed prompts:   5%|         | 14/256 [00:02<00:40,  6.03it/s, est. speed input: 6239.46 toks/s, output: 6.09 toks/s]
Processed prompts:   6%|         | 16/256 [00:02<00:39,  6.08it/s, est. speed input: 6251.37 toks/s, output: 6.10 toks/s]
Processed prompts:   7%|         | 18/256 [00:02<00:38,  6.12it/s, est. speed input: 6263.07 toks/s, output: 6.12 toks/s]
Processed prompts:   8%|         | 20/256 [00:03<00:38,  6.11it/s, est. speed input: 6261.11 toks/s, output: 6.11 toks/s]
Processed prompts:   9%|         | 22/256 [00:03<00:38,  6.14it/s, est. speed input: 6268.30 toks/s, output: 6.12 toks/s]
Processed prompts:   9%|         | 24/256 [00:03<00:37,  6.14it/s, est. speed input: 6271.38 toks/s, output: 6.12 toks/s]
Processed prompts:  10%|         | 26/256 [00:04<00:37,  6.13it/s, est. speed input: 6269.38 toks/s, output: 6.12 toks/s]
Processed prompts:  11%|         | 28/256 [00:04<00:37,  6.15it/s, est. speed input: 6274.71 toks/s, output: 6.13 toks/s]
Processed prompts:  12%|        | 30/256 [00:04<00:36,  6.17it/s, est. speed input: 6281.34 toks/s, output: 6.13 toks/s]
Processed prompts:  12%|        | 32/256 [00:05<00:36,  6.18it/s, est. speed input: 6286.37 toks/s, output: 6.14 toks/s]
Processed prompts:  13%|        | 34/256 [00:05<00:36,  6.15it/s, est. speed input: 6281.80 toks/s, output: 6.13 toks/s]
Processed prompts:  14%|        | 36/256 [00:05<00:35,  6.17it/s, est. speed input: 6286.40 toks/s, output: 6.14 toks/s]
Processed prompts:  15%|        | 38/256 [00:06<00:35,  6.17it/s, est. speed input: 6287.92 toks/s, output: 6.14 toks/s]
Processed prompts:  16%|        | 40/256 [00:06<00:35,  6.14it/s, est. speed input: 6284.61 toks/s, output: 6.14 toks/s]
Processed prompts:  16%|        | 42/256 [00:06<00:34,  6.16it/s, est. speed input: 6287.20 toks/s, output: 6.14 toks/s]
Processed prompts:  17%|        | 44/256 [00:07<00:34,  6.16it/s, est. speed input: 6287.89 toks/s, output: 6.14 toks/s]
Processed prompts:  18%|        | 46/256 [00:07<00:34,  6.13it/s, est. speed input: 6284.68 toks/s, output: 6.14 toks/s]
Processed prompts:  19%|        | 48/256 [00:07<00:33,  6.14it/s, est. speed input: 6285.40 toks/s, output: 6.14 toks/s]
Processed prompts:  20%|        | 50/256 [00:08<00:33,  6.16it/s, est. speed input: 6288.45 toks/s, output: 6.14 toks/s]
Processed prompts:  20%|        | 52/256 [00:08<00:33,  6.17it/s, est. speed input: 6290.04 toks/s, output: 6.14 toks/s]
Processed prompts:  21%|        | 54/256 [00:08<00:32,  6.16it/s, est. speed input: 6289.83 toks/s, output: 6.14 toks/s]
Processed prompts:  22%|       | 56/256 [00:09<00:32,  6.17it/s, est. speed input: 6292.15 toks/s, output: 6.14 toks/s]
Processed prompts:  23%|       | 58/256 [00:09<00:32,  6.17it/s, est. speed input: 6293.12 toks/s, output: 6.15 toks/s]
Processed prompts:  23%|       | 60/256 [00:09<00:31,  6.14it/s, est. speed input: 6290.88 toks/s, output: 6.14 toks/s]
Processed prompts:  24%|       | 62/256 [00:10<00:31,  6.16it/s, est. speed input: 6292.13 toks/s, output: 6.14 toks/s]
Processed prompts:  25%|       | 64/256 [00:10<00:31,  6.15it/s, est. speed input: 6291.68 toks/s, output: 6.14 toks/s]
Processed prompts:  26%|       | 66/256 [00:10<00:31,  6.12it/s, est. speed input: 6288.86 toks/s, output: 6.14 toks/s]
Processed prompts:  27%|       | 68/256 [00:11<00:30,  6.14it/s, est. speed input: 6290.14 toks/s, output: 6.14 toks/s]
Processed prompts:  27%|       | 70/256 [00:11<00:30,  6.16it/s, est. speed input: 6292.19 toks/s, output: 6.14 toks/s]
Processed prompts:  28%|       | 72/256 [00:11<00:29,  6.16it/s, est. speed input: 6292.36 toks/s, output: 6.14 toks/s]
Processed prompts:  29%|       | 74/256 [00:12<00:29,  6.16it/s, est. speed input: 6293.04 toks/s, output: 6.15 toks/s]
Processed prompts:  30%|       | 76/256 [00:12<00:29,  6.16it/s, est. speed input: 6292.92 toks/s, output: 6.15 toks/s]
Processed prompts:  30%|       | 78/256 [00:12<00:28,  6.17it/s, est. speed input: 6294.22 toks/s, output: 6.15 toks/s]
Processed prompts:  31%|      | 80/256 [00:13<00:28,  6.12it/s, est. speed input: 6290.93 toks/s, output: 6.14 toks/s]
Processed prompts:  32%|      | 82/256 [00:13<00:28,  6.15it/s, est. speed input: 6292.47 toks/s, output: 6.14 toks/s]
Processed prompts:  33%|      | 84/256 [00:13<00:27,  6.17it/s, est. speed input: 6294.10 toks/s, output: 6.15 toks/s]
Processed prompts:  34%|      | 86/256 [00:13<00:27,  6.14it/s, est. speed input: 6292.49 toks/s, output: 6.14 toks/s]
Processed prompts:  34%|      | 88/256 [00:14<00:27,  6.15it/s, est. speed input: 6292.77 toks/s, output: 6.15 toks/s]
Processed prompts:  35%|      | 90/256 [00:14<00:26,  6.16it/s, est. speed input: 6293.52 toks/s, output: 6.15 toks/s]
Processed prompts:  36%|      | 92/256 [00:14<00:26,  6.13it/s, est. speed input: 6292.15 toks/s, output: 6.14 toks/s]
Processed prompts:  37%|      | 94/256 [00:15<00:26,  6.14it/s, est. speed input: 6292.15 toks/s, output: 6.14 toks/s]
Processed prompts:  38%|      | 96/256 [00:15<00:26,  6.15it/s, est. speed input: 6292.70 toks/s, output: 6.15 toks/s]
Processed prompts:  38%|      | 98/256 [00:15<00:25,  6.12it/s, est. speed input: 6291.09 toks/s, output: 6.14 toks/s]
Processed prompts:  39%|      | 100/256 [00:16<00:25,  6.13it/s, est. speed input: 6290.89 toks/s, output: 6.14 toks/s]
Processed prompts:  40%|      | 102/256 [00:16<00:25,  6.13it/s, est. speed input: 6290.72 toks/s, output: 6.14 toks/s]
Processed prompts:  41%|      | 104/256 [00:16<00:24,  6.14it/s, est. speed input: 6291.23 toks/s, output: 6.14 toks/s]
Processed prompts:  41%|     | 106/256 [00:17<00:24,  6.14it/s, est. speed input: 6290.83 toks/s, output: 6.14 toks/s]
Processed prompts:  42%|     | 108/256 [00:17<00:24,  6.12it/s, est. speed input: 6289.86 toks/s, output: 6.14 toks/s]
Processed prompts:  43%|     | 110/256 [00:17<00:23,  6.15it/s, est. speed input: 6291.10 toks/s, output: 6.14 toks/s]
Processed prompts:  44%|     | 112/256 [00:18<00:23,  6.12it/s, est. speed input: 6289.68 toks/s, output: 6.14 toks/s]
Processed prompts:  45%|     | 114/256 [00:18<00:23,  6.12it/s, est. speed input: 6288.94 toks/s, output: 6.14 toks/s]
Processed prompts:  45%|     | 116/256 [00:18<00:22,  6.12it/s, est. speed input: 6288.59 toks/s, output: 6.14 toks/s]
Processed prompts:  46%|     | 118/256 [00:19<00:22,  6.12it/s, est. speed input: 6288.04 toks/s, output: 6.14 toks/s]
Processed prompts:  47%|     | 120/256 [00:19<00:22,  6.11it/s, est. speed input: 6287.54 toks/s, output: 6.14 toks/s]
Processed prompts:  48%|     | 122/256 [00:19<00:21,  6.14it/s, est. speed input: 6288.53 toks/s, output: 6.14 toks/s]
Processed prompts:  48%|     | 124/256 [00:20<00:21,  6.15it/s, est. speed input: 6289.18 toks/s, output: 6.14 toks/s]
Processed prompts:  49%|     | 126/256 [00:20<00:21,  6.13it/s, est. speed input: 6287.92 toks/s, output: 6.14 toks/s]
Processed prompts:  50%|     | 128/256 [00:20<00:20,  6.12it/s, est. speed input: 6287.19 toks/s, output: 6.14 toks/s]
Processed prompts:  51%|     | 130/256 [00:21<00:20,  6.13it/s, est. speed input: 6287.77 toks/s, output: 6.14 toks/s]
Processed prompts:  52%|    | 132/256 [00:21<00:20,  6.11it/s, est. speed input: 6286.42 toks/s, output: 6.14 toks/s]
Processed prompts:  52%|    | 134/256 [00:21<00:19,  6.12it/s, est. speed input: 6286.72 toks/s, output: 6.14 toks/s]
Processed prompts:  53%|    | 136/256 [00:22<00:19,  6.13it/s, est. speed input: 6286.74 toks/s, output: 6.14 toks/s]
Processed prompts:  54%|    | 138/256 [00:22<00:19,  6.11it/s, est. speed input: 6285.56 toks/s, output: 6.14 toks/s]
Processed prompts:  55%|    | 140/256 [00:22<00:18,  6.13it/s, est. speed input: 6286.14 toks/s, output: 6.14 toks/s]
Processed prompts:  55%|    | 142/256 [00:23<00:18,  6.15it/s, est. speed input: 6287.09 toks/s, output: 6.14 toks/s]
Processed prompts:  56%|    | 144/256 [00:23<00:18,  6.13it/s, est. speed input: 6286.10 toks/s, output: 6.14 toks/s]
Processed prompts:  57%|    | 146/256 [00:23<00:17,  6.14it/s, est. speed input: 6286.58 toks/s, output: 6.14 toks/s]
Processed prompts:  58%|    | 148/256 [00:24<00:17,  6.17it/s, est. speed input: 6287.79 toks/s, output: 6.14 toks/s]
Processed prompts:  59%|    | 150/256 [00:24<00:17,  6.15it/s, est. speed input: 6287.60 toks/s, output: 6.14 toks/s]
Processed prompts:  59%|    | 152/256 [00:24<00:16,  6.13it/s, est. speed input: 6286.86 toks/s, output: 6.14 toks/s]
Processed prompts:  60%|    | 154/256 [00:25<00:16,  6.13it/s, est. speed input: 6286.57 toks/s, output: 6.14 toks/s]
Processed prompts:  61%|    | 156/256 [00:25<00:16,  6.12it/s, est. speed input: 6286.21 toks/s, output: 6.14 toks/s]
Processed prompts:  62%|   | 158/256 [00:25<00:16,  6.11it/s, est. speed input: 6285.21 toks/s, output: 6.14 toks/s]
Processed prompts:  62%|   | 160/256 [00:26<00:15,  6.12it/s, est. speed input: 6285.34 toks/s, output: 6.14 toks/s]
Processed prompts:  63%|   | 162/256 [00:26<00:15,  6.15it/s, est. speed input: 6286.63 toks/s, output: 6.14 toks/s]
Processed prompts:  64%|   | 164/256 [00:26<00:15,  6.12it/s, est. speed input: 6285.45 toks/s, output: 6.14 toks/s]
Processed prompts:  65%|   | 166/256 [00:27<00:14,  6.12it/s, est. speed input: 6285.31 toks/s, output: 6.14 toks/s]
Processed prompts:  66%|   | 168/256 [00:27<00:14,  6.13it/s, est. speed input: 6285.30 toks/s, output: 6.14 toks/s]
Processed prompts:  66%|   | 170/256 [00:27<00:14,  6.11it/s, est. speed input: 6284.27 toks/s, output: 6.14 toks/s]
Processed prompts:  67%|   | 172/256 [00:28<00:13,  6.11it/s, est. speed input: 6284.21 toks/s, output: 6.14 toks/s]
Processed prompts:  68%|   | 174/256 [00:28<00:13,  6.13it/s, est. speed input: 6284.43 toks/s, output: 6.14 toks/s]
Processed prompts:  69%|   | 176/256 [00:28<00:13,  6.14it/s, est. speed input: 6284.83 toks/s, output: 6.14 toks/s]
Processed prompts:  70%|   | 178/256 [00:29<00:12,  6.11it/s, est. speed input: 6283.78 toks/s, output: 6.14 toks/s]
Processed prompts:  70%|   | 180/256 [00:29<00:12,  6.11it/s, est. speed input: 6283.60 toks/s, output: 6.14 toks/s]
Processed prompts:  71%|   | 182/256 [00:29<00:12,  6.12it/s, est. speed input: 6283.75 toks/s, output: 6.14 toks/s]
Processed prompts:  72%|  | 184/256 [00:29<00:11,  6.10it/s, est. speed input: 6282.62 toks/s, output: 6.14 toks/s]
Processed prompts:  73%|  | 186/256 [00:30<00:11,  6.10it/s, est. speed input: 6282.38 toks/s, output: 6.14 toks/s]
Processed prompts:  73%|  | 188/256 [00:30<00:11,  6.13it/s, est. speed input: 6282.87 toks/s, output: 6.14 toks/s]
Processed prompts:  74%|  | 190/256 [00:30<00:10,  6.09it/s, est. speed input: 6281.53 toks/s, output: 6.13 toks/s]
Processed prompts:  75%|  | 192/256 [00:31<00:10,  6.09it/s, est. speed input: 6281.12 toks/s, output: 6.13 toks/s]
Processed prompts:  76%|  | 194/256 [00:31<00:10,  6.12it/s, est. speed input: 6281.73 toks/s, output: 6.13 toks/s]
Processed prompts:  77%|  | 196/256 [00:31<00:09,  6.10it/s, est. speed input: 6280.94 toks/s, output: 6.13 toks/s]
Processed prompts:  77%|  | 198/256 [00:32<00:09,  6.14it/s, est. speed input: 6282.06 toks/s, output: 6.13 toks/s]
Processed prompts:  78%|  | 200/256 [00:32<00:09,  6.14it/s, est. speed input: 6282.08 toks/s, output: 6.13 toks/s]
Processed prompts:  79%|  | 202/256 [00:32<00:07,  6.89it/s, est. speed input: 6304.67 toks/s, output: 6.16 toks/s]
Processed prompts:  80%|  | 204/256 [00:33<00:07,  6.62it/s, est. speed input: 6303.68 toks/s, output: 6.16 toks/s]
Processed prompts:  80%|  | 206/256 [00:33<00:08,  5.63it/s, est. speed input: 6274.92 toks/s, output: 6.13 toks/s]
Processed prompts:  81%| | 208/256 [00:34<00:08,  5.35it/s, est. speed input: 6257.89 toks/s, output: 6.11 toks/s]
Processed prompts:  82%| | 210/256 [00:34<00:08,  5.55it/s, est. speed input: 6257.90 toks/s, output: 6.11 toks/s]
Processed prompts:  83%| | 212/256 [00:34<00:07,  5.72it/s, est. speed input: 6258.36 toks/s, output: 6.11 toks/s]
Processed prompts:  84%| | 214/256 [00:35<00:07,  5.86it/s, est. speed input: 6259.11 toks/s, output: 6.11 toks/s]
Processed prompts:  84%| | 216/256 [00:35<00:06,  5.91it/s, est. speed input: 6258.26 toks/s, output: 6.11 toks/s]
Processed prompts:  85%| | 218/256 [00:35<00:06,  5.97it/s, est. speed input: 6258.31 toks/s, output: 6.11 toks/s]
Processed prompts:  86%| | 220/256 [00:35<00:05,  6.02it/s, est. speed input: 6258.49 toks/s, output: 6.11 toks/s]
Processed prompts:  87%| | 222/256 [00:36<00:05,  6.03it/s, est. speed input: 6257.93 toks/s, output: 6.11 toks/s]
Processed prompts:  88%| | 224/256 [00:36<00:05,  6.07it/s, est. speed input: 6258.46 toks/s, output: 6.11 toks/s]
Processed prompts:  88%| | 226/256 [00:36<00:04,  6.08it/s, est. speed input: 6258.43 toks/s, output: 6.11 toks/s]
Processed prompts:  89%| | 228/256 [00:37<00:04,  6.07it/s, est. speed input: 6257.80 toks/s, output: 6.11 toks/s]
Processed prompts:  90%| | 230/256 [00:37<00:04,  6.10it/s, est. speed input: 6258.30 toks/s, output: 6.11 toks/s]
Processed prompts:  91%| | 232/256 [00:37<00:03,  6.11it/s, est. speed input: 6258.46 toks/s, output: 6.11 toks/s]
Processed prompts:  91%|| 234/256 [00:38<00:03,  6.10it/s, est. speed input: 6258.05 toks/s, output: 6.11 toks/s]
Processed prompts:  92%|| 236/256 [00:38<00:03,  6.09it/s, est. speed input: 6257.86 toks/s, output: 6.11 toks/s]
Processed prompts:  93%|| 238/256 [00:38<00:02,  6.11it/s, est. speed input: 6258.18 toks/s, output: 6.11 toks/s]
Processed prompts:  94%|| 240/256 [00:39<00:02,  6.13it/s, est. speed input: 6258.77 toks/s, output: 6.11 toks/s]
Processed prompts:  95%|| 242/256 [00:39<00:02,  6.12it/s, est. speed input: 6258.53 toks/s, output: 6.11 toks/s]
Processed prompts:  95%|| 244/256 [00:39<00:01,  6.13it/s, est. speed input: 6258.96 toks/s, output: 6.11 toks/s]
Processed prompts:  96%|| 246/256 [00:40<00:01,  6.16it/s, est. speed input: 6259.84 toks/s, output: 6.11 toks/s]
Processed prompts:  97%|| 248/256 [00:40<00:01,  6.12it/s, est. speed input: 6259.22 toks/s, output: 6.11 toks/s]
Processed prompts:  98%|| 250/256 [00:40<00:00,  6.13it/s, est. speed input: 6259.62 toks/s, output: 6.11 toks/s]
Processed prompts:  98%|| 252/256 [00:41<00:00,  6.16it/s, est. speed input: 6260.48 toks/s, output: 6.11 toks/s]
Processed prompts:  99%|| 254/256 [00:41<00:00,  6.13it/s, est. speed input: 6259.95 toks/s, output: 6.11 toks/s]
Processed prompts: 100%|| 256/256 [00:41<00:00,  7.19it/s, est. speed input: 6284.24 toks/s, output: 6.14 toks/s]
Processed prompts: 100%|| 256/256 [00:41<00:00,  7.19it/s, est. speed input: 6284.24 toks/s, output: 6.14 toks/s]
Processed prompts: 100%|| 256/256 [00:41<00:00,  6.14it/s, est. speed input: 6284.24 toks/s, output: 6.14 toks/s]
[rank0]:[W126 18:47:34.241353409 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-26 18:47:36
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Qwen2.5-7B-FP8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 18:47:41 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 18:47:41 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1616453) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1616453) WARNING 01-26 18:48:52 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 5.91 requests/s, 6052.66 total tokens/s, 5.91 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-26 18:47:41] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 18:47:41] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 18:47:41] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 18:47:41] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:47:41] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:47:41] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:47:41] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:47:41] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:47:41] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 18:47:41] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 18:47:41] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 18:47:41] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 18:47:41] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 18:47:41] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 18:47:45] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 18:47:45] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 18:47:45] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 18:47:45] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:47:45] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:47:45] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:47:45] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:47:45] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:47:45] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 18:47:45] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 18:47:45] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 18:47:45] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 18:47:45] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 18:47:45] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1616453) [2026-01-26 18:47:46] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1616453) [2026-01-26 18:47:46] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1616453) [2026-01-26 18:47:46] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1616453) [2026-01-26 18:47:46] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1616453) [2026-01-26 18:47:46] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1616453) [2026-01-26 18:47:46] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1616453) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1616453) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:24<00:24, 24.38s/it]
(EngineCore_DP0 pid=1616453) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:58<00:00, 29.84s/it]
(EngineCore_DP0 pid=1616453) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:58<00:00, 29.02s/it]
(EngineCore_DP0 pid=1616453) 
(EngineCore_DP0 pid=1616453) [2026-01-26 18:48:45] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=1616453) [2026-01-26 18:48:45] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 13860864 bytes
(EngineCore_DP0 pid=1616453) [2026-01-26 18:48:45] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=1616453) [2026-01-26 18:48:45] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10780672 bytes
(EngineCore_DP0 pid=1616453) [2026-01-26 18:48:45] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=1616453) [2026-01-26 18:48:45] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 113967104 bytes
(EngineCore_DP0 pid=1616453) [2026-01-26 18:48:45] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=1616453) [2026-01-26 18:48:45] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 56655872 bytes
(EngineCore_DP0 pid=1616453) 2026-01-26 18:48:51,491 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1616453) 2026-01-26 18:48:51,590 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   8%|         | 41/512 [00:00<00:01, 396.25it/s]
Adding requests:  16%|        | 81/512 [00:00<00:01, 367.09it/s]
Adding requests:  24%|       | 122/512 [00:00<00:01, 381.49it/s]
Adding requests:  32%|      | 163/512 [00:00<00:00, 390.78it/s]
Adding requests:  40%|      | 207/512 [00:00<00:00, 404.37it/s]
Adding requests:  49%|     | 251/512 [00:00<00:00, 414.37it/s]
Adding requests:  58%|    | 295/512 [00:00<00:00, 421.22it/s]
Adding requests:  67%|   | 342/512 [00:00<00:00, 435.41it/s]
Adding requests:  76%|  | 387/512 [00:00<00:00, 438.17it/s]
Adding requests:  84%| | 431/512 [00:01<00:00, 437.05it/s]
Adding requests:  93%|| 475/512 [00:01<00:00, 431.16it/s]
Adding requests: 100%|| 512/512 [00:01<00:00, 421.52it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 6/512 [00:00<00:34, 14.87it/s, est. speed input: 15226.77 toks/s, output: 14.87 toks/s]
Processed prompts:   2%|         | 10/512 [00:01<00:58,  8.56it/s, est. speed input: 9493.77 toks/s, output: 9.27 toks/s] 
Processed prompts:   3%|         | 14/512 [00:01<01:08,  7.25it/s, est. speed input: 8181.06 toks/s, output: 7.99 toks/s]
Processed prompts:   4%|         | 18/512 [00:02<01:13,  6.68it/s, est. speed input: 7581.67 toks/s, output: 7.40 toks/s]
Processed prompts:   4%|         | 22/512 [00:03<01:16,  6.41it/s, est. speed input: 7258.51 toks/s, output: 7.09 toks/s]
Processed prompts:   5%|         | 26/512 [00:03<01:17,  6.23it/s, est. speed input: 7042.54 toks/s, output: 6.88 toks/s]
Processed prompts:   6%|         | 30/512 [00:04<01:18,  6.12it/s, est. speed input: 6886.84 toks/s, output: 6.73 toks/s]
Processed prompts:   7%|         | 34/512 [00:05<01:18,  6.07it/s, est. speed input: 6784.80 toks/s, output: 6.63 toks/s]
Processed prompts:   7%|         | 38/512 [00:05<01:18,  6.01it/s, est. speed input: 6697.41 toks/s, output: 6.54 toks/s]
Processed prompts:   8%|         | 42/512 [00:06<01:18,  5.97it/s, est. speed input: 6626.41 toks/s, output: 6.47 toks/s]
Processed prompts:   9%|         | 46/512 [00:07<01:18,  5.96it/s, est. speed input: 6575.01 toks/s, output: 6.42 toks/s]
Processed prompts:  10%|         | 50/512 [00:07<01:17,  5.93it/s, est. speed input: 6525.63 toks/s, output: 6.37 toks/s]
Processed prompts:  11%|         | 54/512 [00:08<01:17,  5.93it/s, est. speed input: 6489.79 toks/s, output: 6.34 toks/s]
Processed prompts:  11%|        | 58/512 [00:09<01:16,  5.93it/s, est. speed input: 6458.36 toks/s, output: 6.31 toks/s]
Processed prompts:  12%|        | 62/512 [00:09<01:16,  5.91it/s, est. speed input: 6427.52 toks/s, output: 6.28 toks/s]
Processed prompts:  13%|        | 66/512 [00:10<01:15,  5.92it/s, est. speed input: 6404.64 toks/s, output: 6.25 toks/s]
Processed prompts:  14%|        | 70/512 [00:11<01:14,  5.90it/s, est. speed input: 6381.35 toks/s, output: 6.23 toks/s]
Processed prompts:  14%|        | 74/512 [00:11<01:14,  5.90it/s, est. speed input: 6361.62 toks/s, output: 6.21 toks/s]
Processed prompts:  15%|        | 78/512 [00:12<01:13,  5.90it/s, est. speed input: 6344.91 toks/s, output: 6.20 toks/s]
Processed prompts:  16%|        | 82/512 [00:13<01:12,  5.90it/s, est. speed input: 6328.34 toks/s, output: 6.18 toks/s]
Processed prompts:  17%|        | 86/512 [00:13<01:12,  5.90it/s, est. speed input: 6314.78 toks/s, output: 6.17 toks/s]
Processed prompts:  18%|        | 90/512 [00:14<01:11,  5.91it/s, est. speed input: 6304.25 toks/s, output: 6.16 toks/s]
Processed prompts:  18%|        | 94/512 [00:15<01:10,  5.90it/s, est. speed input: 6291.62 toks/s, output: 6.14 toks/s]
Processed prompts:  19%|        | 98/512 [00:15<01:10,  5.90it/s, est. speed input: 6280.35 toks/s, output: 6.13 toks/s]
Processed prompts:  20%|        | 102/512 [00:16<01:09,  5.91it/s, est. speed input: 6271.84 toks/s, output: 6.12 toks/s]
Processed prompts:  21%|        | 106/512 [00:17<01:08,  5.90it/s, est. speed input: 6262.20 toks/s, output: 6.12 toks/s]
Processed prompts:  21%|       | 110/512 [00:18<01:08,  5.91it/s, est. speed input: 6255.41 toks/s, output: 6.11 toks/s]
Processed prompts:  22%|       | 114/512 [00:18<01:07,  5.90it/s, est. speed input: 6246.56 toks/s, output: 6.10 toks/s]
Processed prompts:  23%|       | 118/512 [00:19<01:06,  5.90it/s, est. speed input: 6238.90 toks/s, output: 6.09 toks/s]
Processed prompts:  24%|       | 122/512 [00:20<01:06,  5.91it/s, est. speed input: 6233.22 toks/s, output: 6.09 toks/s]
Processed prompts:  25%|       | 126/512 [00:20<01:05,  5.89it/s, est. speed input: 6225.55 toks/s, output: 6.08 toks/s]
Processed prompts:  25%|       | 130/512 [00:21<01:04,  5.89it/s, est. speed input: 6219.44 toks/s, output: 6.07 toks/s]
Processed prompts:  26%|       | 134/512 [00:22<01:04,  5.90it/s, est. speed input: 6214.38 toks/s, output: 6.07 toks/s]
Processed prompts:  27%|       | 138/512 [00:22<01:03,  5.89it/s, est. speed input: 6208.60 toks/s, output: 6.06 toks/s]
Processed prompts:  28%|       | 142/512 [00:23<01:02,  5.89it/s, est. speed input: 6203.76 toks/s, output: 6.06 toks/s]
Processed prompts:  29%|       | 146/512 [00:24<01:02,  5.89it/s, est. speed input: 6198.51 toks/s, output: 6.05 toks/s]
Processed prompts:  29%|       | 150/512 [00:24<01:01,  5.89it/s, est. speed input: 6193.81 toks/s, output: 6.05 toks/s]
Processed prompts:  30%|       | 154/512 [00:25<01:00,  5.89it/s, est. speed input: 6189.89 toks/s, output: 6.04 toks/s]
Processed prompts:  31%|       | 158/512 [00:26<01:00,  5.89it/s, est. speed input: 6185.24 toks/s, output: 6.04 toks/s]
Processed prompts:  32%|      | 162/512 [00:26<00:59,  5.89it/s, est. speed input: 6181.20 toks/s, output: 6.04 toks/s]
Processed prompts:  32%|      | 166/512 [00:27<00:58,  5.89it/s, est. speed input: 6177.73 toks/s, output: 6.03 toks/s]
Processed prompts:  33%|      | 170/512 [00:28<00:58,  5.89it/s, est. speed input: 6174.62 toks/s, output: 6.03 toks/s]
Processed prompts:  34%|      | 174/512 [00:28<00:57,  5.89it/s, est. speed input: 6171.01 toks/s, output: 6.03 toks/s]
Processed prompts:  35%|      | 178/512 [00:29<00:56,  5.89it/s, est. speed input: 6168.08 toks/s, output: 6.02 toks/s]
Processed prompts:  36%|      | 182/512 [00:30<00:56,  5.88it/s, est. speed input: 6164.28 toks/s, output: 6.02 toks/s]
Processed prompts:  36%|      | 186/512 [00:30<00:55,  5.89it/s, est. speed input: 6161.60 toks/s, output: 6.02 toks/s]
Processed prompts:  37%|      | 190/512 [00:31<00:56,  5.72it/s, est. speed input: 6145.67 toks/s, output: 6.00 toks/s]
Processed prompts:  38%|      | 194/512 [00:32<00:55,  5.76it/s, est. speed input: 6142.74 toks/s, output: 6.00 toks/s]
Processed prompts:  39%|      | 198/512 [00:33<00:54,  5.80it/s, est. speed input: 6140.72 toks/s, output: 6.00 toks/s]
Processed prompts:  39%|      | 202/512 [00:33<00:50,  6.18it/s, est. speed input: 6162.13 toks/s, output: 6.02 toks/s]
Processed prompts:  40%|      | 206/512 [00:34<00:50,  6.09it/s, est. speed input: 6159.32 toks/s, output: 6.01 toks/s]
Processed prompts:  41%|      | 210/512 [00:34<00:50,  6.03it/s, est. speed input: 6156.84 toks/s, output: 6.01 toks/s]
Processed prompts:  42%|     | 214/512 [00:35<00:49,  5.97it/s, est. speed input: 6153.80 toks/s, output: 6.01 toks/s]
Processed prompts:  43%|     | 218/512 [00:36<00:49,  5.95it/s, est. speed input: 6151.64 toks/s, output: 6.01 toks/s]
Processed prompts:  43%|     | 222/512 [00:36<00:48,  5.93it/s, est. speed input: 6149.18 toks/s, output: 6.01 toks/s]
Processed prompts:  44%|     | 226/512 [00:37<00:48,  5.92it/s, est. speed input: 6147.05 toks/s, output: 6.00 toks/s]
Processed prompts:  45%|     | 230/512 [00:38<00:47,  5.91it/s, est. speed input: 6145.08 toks/s, output: 6.00 toks/s]
Processed prompts:  46%|     | 234/512 [00:39<00:47,  5.90it/s, est. speed input: 6142.87 toks/s, output: 6.00 toks/s]
Processed prompts:  46%|     | 238/512 [00:39<00:46,  5.89it/s, est. speed input: 6140.36 toks/s, output: 6.00 toks/s]
Processed prompts:  47%|     | 242/512 [00:40<00:45,  5.89it/s, est. speed input: 6138.77 toks/s, output: 5.99 toks/s]
Processed prompts:  48%|     | 246/512 [00:41<00:45,  5.88it/s, est. speed input: 6136.52 toks/s, output: 5.99 toks/s]
Processed prompts:  49%|     | 250/512 [00:41<00:44,  5.88it/s, est. speed input: 6134.62 toks/s, output: 5.99 toks/s]
Processed prompts:  50%|     | 254/512 [00:42<00:43,  5.89it/s, est. speed input: 6133.34 toks/s, output: 5.99 toks/s]
Processed prompts:  50%|     | 258/512 [00:43<00:43,  5.88it/s, est. speed input: 6131.27 toks/s, output: 5.99 toks/s]
Processed prompts:  51%|     | 262/512 [00:43<00:42,  5.88it/s, est. speed input: 6129.34 toks/s, output: 5.99 toks/s]
Processed prompts:  52%|    | 266/512 [00:44<00:41,  5.88it/s, est. speed input: 6127.72 toks/s, output: 5.98 toks/s]
Processed prompts:  53%|    | 270/512 [00:45<00:41,  5.88it/s, est. speed input: 6125.96 toks/s, output: 5.98 toks/s]
Processed prompts:  54%|    | 274/512 [00:45<00:40,  5.89it/s, est. speed input: 6124.99 toks/s, output: 5.98 toks/s]
Processed prompts:  54%|    | 278/512 [00:46<00:39,  5.88it/s, est. speed input: 6123.00 toks/s, output: 5.98 toks/s]
Processed prompts:  55%|    | 282/512 [00:47<00:39,  5.88it/s, est. speed input: 6121.65 toks/s, output: 5.98 toks/s]
Processed prompts:  56%|    | 286/512 [00:47<00:38,  5.88it/s, est. speed input: 6120.41 toks/s, output: 5.98 toks/s]
Processed prompts:  57%|    | 290/512 [00:48<00:37,  5.88it/s, est. speed input: 6118.83 toks/s, output: 5.98 toks/s]
Processed prompts:  57%|    | 294/512 [00:49<00:37,  5.87it/s, est. speed input: 6117.04 toks/s, output: 5.97 toks/s]
Processed prompts:  58%|    | 298/512 [00:49<00:36,  5.88it/s, est. speed input: 6115.96 toks/s, output: 5.97 toks/s]
Processed prompts:  59%|    | 302/512 [00:50<00:35,  5.87it/s, est. speed input: 6114.32 toks/s, output: 5.97 toks/s]
Processed prompts:  60%|    | 306/512 [00:51<00:32,  6.37it/s, est. speed input: 6134.29 toks/s, output: 5.99 toks/s]
Processed prompts:  61%|    | 310/512 [00:51<00:32,  6.22it/s, est. speed input: 6132.91 toks/s, output: 5.99 toks/s]
Processed prompts:  61%|   | 314/512 [00:52<00:32,  6.10it/s, est. speed input: 6131.10 toks/s, output: 5.99 toks/s]
Processed prompts:  62%|   | 318/512 [00:53<00:32,  6.04it/s, est. speed input: 6129.86 toks/s, output: 5.99 toks/s]
Processed prompts:  63%|   | 322/512 [00:53<00:31,  5.98it/s, est. speed input: 6128.19 toks/s, output: 5.98 toks/s]
Processed prompts:  64%|   | 326/512 [00:54<00:31,  5.95it/s, est. speed input: 6126.91 toks/s, output: 5.98 toks/s]
Processed prompts:  64%|   | 330/512 [00:55<00:30,  5.94it/s, est. speed input: 6126.00 toks/s, output: 5.98 toks/s]
Processed prompts:  65%|   | 334/512 [00:55<00:30,  5.92it/s, est. speed input: 6124.52 toks/s, output: 5.98 toks/s]
Processed prompts:  66%|   | 338/512 [00:56<00:29,  5.91it/s, est. speed input: 6123.42 toks/s, output: 5.98 toks/s]
Processed prompts:  67%|   | 342/512 [00:57<00:28,  5.90it/s, est. speed input: 6122.07 toks/s, output: 5.98 toks/s]
Processed prompts:  68%|   | 346/512 [00:57<00:28,  5.88it/s, est. speed input: 6120.41 toks/s, output: 5.98 toks/s]
Processed prompts:  68%|   | 350/512 [00:58<00:27,  5.88it/s, est. speed input: 6119.43 toks/s, output: 5.98 toks/s]
Processed prompts:  69%|   | 354/512 [00:59<00:26,  5.88it/s, est. speed input: 6118.33 toks/s, output: 5.97 toks/s]
Processed prompts:  70%|   | 358/512 [00:59<00:26,  5.88it/s, est. speed input: 6117.04 toks/s, output: 5.97 toks/s]
Processed prompts:  71%|   | 362/512 [01:00<00:25,  5.88it/s, est. speed input: 6116.12 toks/s, output: 5.97 toks/s]
Processed prompts:  71%|  | 366/512 [01:01<00:24,  5.88it/s, est. speed input: 6114.90 toks/s, output: 5.97 toks/s]
Processed prompts:  72%|  | 370/512 [01:01<00:24,  5.87it/s, est. speed input: 6113.65 toks/s, output: 5.97 toks/s]
Processed prompts:  73%|  | 374/512 [01:02<00:23,  5.87it/s, est. speed input: 6112.57 toks/s, output: 5.97 toks/s]
Processed prompts:  74%|  | 378/512 [01:03<00:22,  5.87it/s, est. speed input: 6111.36 toks/s, output: 5.97 toks/s]
Processed prompts:  75%|  | 382/512 [01:04<00:22,  5.85it/s, est. speed input: 6109.58 toks/s, output: 5.97 toks/s]
Processed prompts:  75%|  | 386/512 [01:04<00:21,  5.86it/s, est. speed input: 6108.52 toks/s, output: 5.97 toks/s]
Processed prompts:  76%|  | 390/512 [01:05<00:20,  5.85it/s, est. speed input: 6107.31 toks/s, output: 5.96 toks/s]
Processed prompts:  77%|  | 394/512 [01:06<00:20,  5.87it/s, est. speed input: 6106.59 toks/s, output: 5.96 toks/s]
Processed prompts:  78%|  | 398/512 [01:06<00:19,  5.87it/s, est. speed input: 6105.54 toks/s, output: 5.96 toks/s]
Processed prompts:  79%|  | 402/512 [01:07<00:18,  5.86it/s, est. speed input: 6104.41 toks/s, output: 5.96 toks/s]
Processed prompts:  79%|  | 406/512 [01:08<00:18,  5.87it/s, est. speed input: 6103.75 toks/s, output: 5.96 toks/s]
Processed prompts:  80%|  | 410/512 [01:08<00:17,  5.87it/s, est. speed input: 6102.66 toks/s, output: 5.96 toks/s]
Processed prompts:  81%|  | 414/512 [01:09<00:16,  5.86it/s, est. speed input: 6101.61 toks/s, output: 5.96 toks/s]
Processed prompts:  82%| | 418/512 [01:10<00:16,  5.87it/s, est. speed input: 6100.92 toks/s, output: 5.96 toks/s]
Processed prompts:  82%| | 422/512 [01:10<00:15,  5.87it/s, est. speed input: 6099.97 toks/s, output: 5.96 toks/s]
Processed prompts:  83%| | 426/512 [01:11<00:14,  5.88it/s, est. speed input: 6099.60 toks/s, output: 5.96 toks/s]
Processed prompts:  84%| | 430/512 [01:12<00:13,  5.87it/s, est. speed input: 6098.61 toks/s, output: 5.96 toks/s]
Processed prompts:  85%| | 434/512 [01:12<00:12,  6.35it/s, est. speed input: 6112.12 toks/s, output: 5.97 toks/s]
Processed prompts:  86%| | 438/512 [01:13<00:11,  6.21it/s, est. speed input: 6111.60 toks/s, output: 5.97 toks/s]
Processed prompts:  86%| | 442/512 [01:14<00:11,  6.11it/s, est. speed input: 6110.69 toks/s, output: 5.97 toks/s]
Processed prompts:  87%| | 446/512 [01:14<00:10,  6.04it/s, est. speed input: 6109.96 toks/s, output: 5.97 toks/s]
Processed prompts:  88%| | 450/512 [01:15<00:10,  5.98it/s, est. speed input: 6108.93 toks/s, output: 5.97 toks/s]
Processed prompts:  89%| | 454/512 [01:16<00:09,  5.95it/s, est. speed input: 6108.03 toks/s, output: 5.96 toks/s]
Processed prompts:  89%| | 458/512 [01:16<00:09,  5.94it/s, est. speed input: 6107.72 toks/s, output: 5.96 toks/s]
Processed prompts:  90%| | 462/512 [01:17<00:08,  5.91it/s, est. speed input: 6106.56 toks/s, output: 5.96 toks/s]
Processed prompts:  91%| | 466/512 [01:18<00:07,  5.89it/s, est. speed input: 6105.46 toks/s, output: 5.96 toks/s]
Processed prompts:  92%|| 470/512 [01:18<00:07,  5.89it/s, est. speed input: 6104.92 toks/s, output: 5.96 toks/s]
Processed prompts:  93%|| 474/512 [01:19<00:06,  5.88it/s, est. speed input: 6103.97 toks/s, output: 5.96 toks/s]
Processed prompts:  93%|| 478/512 [01:20<00:05,  5.88it/s, est. speed input: 6103.10 toks/s, output: 5.96 toks/s]
Processed prompts:  94%|| 482/512 [01:20<00:05,  5.89it/s, est. speed input: 6102.88 toks/s, output: 5.96 toks/s]
Processed prompts:  95%|| 486/512 [01:21<00:04,  5.88it/s, est. speed input: 6101.96 toks/s, output: 5.96 toks/s]
Processed prompts:  96%|| 490/512 [01:22<00:03,  5.88it/s, est. speed input: 6101.30 toks/s, output: 5.96 toks/s]
Processed prompts:  96%|| 494/512 [01:22<00:03,  5.88it/s, est. speed input: 6100.52 toks/s, output: 5.96 toks/s]
Processed prompts:  97%|| 498/512 [01:23<00:02,  5.87it/s, est. speed input: 6099.61 toks/s, output: 5.96 toks/s]
Processed prompts:  98%|| 502/512 [01:24<00:01,  5.88it/s, est. speed input: 6099.08 toks/s, output: 5.96 toks/s]
Processed prompts:  99%|| 506/512 [01:24<00:01,  5.86it/s, est. speed input: 6098.10 toks/s, output: 5.96 toks/s]
Processed prompts: 100%|| 510/512 [01:25<00:00,  6.31it/s, est. speed input: 6108.80 toks/s, output: 5.97 toks/s]
Processed prompts: 100%|| 512/512 [01:25<00:00,  6.31it/s, est. speed input: 6132.75 toks/s, output: 5.99 toks/s]
Processed prompts: 100%|| 512/512 [01:25<00:00,  5.99it/s, est. speed input: 6132.75 toks/s, output: 5.99 toks/s]
[rank0]:[W126 18:50:19.915371482 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-26 18:50:22
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Qwen2.5-7B-FP8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 18:50:29 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 18:50:29 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1618934) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1618934) WARNING 01-26 18:51:43 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 6.04 requests/s, 6191.22 total tokens/s, 6.04 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-26 18:50:29] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 18:50:29] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 18:50:29] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 18:50:29] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:50:29] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:50:29] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:50:29] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:50:29] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:50:29] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 18:50:29] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 18:50:29] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 18:50:29] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 18:50:29] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 18:50:29] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 18:50:32] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 18:50:32] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 18:50:32] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 18:50:32] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:50:32] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:50:32] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:50:32] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:50:32] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:50:32] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 18:50:32] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 18:50:32] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 18:50:32] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 18:50:32] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 18:50:32] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1618934) [2026-01-26 18:50:33] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1618934) [2026-01-26 18:50:33] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1618934) [2026-01-26 18:50:33] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1618934) [2026-01-26 18:50:33] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1618934) [2026-01-26 18:50:33] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1618934) [2026-01-26 18:50:33] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1618934) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1618934) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:24<00:24, 24.72s/it]
(EngineCore_DP0 pid=1618934) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:58<00:00, 30.07s/it]
(EngineCore_DP0 pid=1618934) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:58<00:00, 29.27s/it]
(EngineCore_DP0 pid=1618934) 
(EngineCore_DP0 pid=1618934) [2026-01-26 18:51:33] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=1618934) [2026-01-26 18:51:33] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 13860864 bytes
(EngineCore_DP0 pid=1618934) [2026-01-26 18:51:33] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=1618934) [2026-01-26 18:51:33] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10780672 bytes
(EngineCore_DP0 pid=1618934) [2026-01-26 18:51:33] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=1618934) [2026-01-26 18:51:33] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 113967104 bytes
(EngineCore_DP0 pid=1618934) [2026-01-26 18:51:33] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=1618934) [2026-01-26 18:51:33] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 56655872 bytes
(EngineCore_DP0 pid=1618934) 2026-01-26 18:51:40,618 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1618934) 2026-01-26 18:51:40,933 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   4%|         | 45/1024 [00:00<00:02, 448.12it/s]
Adding requests:   9%|         | 90/1024 [00:00<00:02, 353.00it/s]
Adding requests:  13%|        | 131/1024 [00:00<00:02, 373.04it/s]
Adding requests:  17%|        | 170/1024 [00:00<00:02, 375.74it/s]
Adding requests:  21%|        | 214/1024 [00:00<00:02, 396.38it/s]
Adding requests:  25%|       | 256/1024 [00:00<00:01, 402.17it/s]
Adding requests:  29%|       | 301/1024 [00:00<00:01, 414.00it/s]
Adding requests:  34%|      | 344/1024 [00:00<00:01, 418.77it/s]
Adding requests:  38%|      | 387/1024 [00:00<00:01, 422.09it/s]
Adding requests:  42%|     | 431/1024 [00:01<00:01, 427.18it/s]
Adding requests:  46%|     | 474/1024 [00:01<00:01, 418.93it/s]
Adding requests:  51%|     | 519/1024 [00:01<00:01, 427.09it/s]
Adding requests:  55%|    | 562/1024 [00:01<00:01, 416.17it/s]
Adding requests:  59%|    | 604/1024 [00:01<00:01, 411.38it/s]
Adding requests:  63%|   | 646/1024 [00:01<00:00, 409.44it/s]
Adding requests:  67%|   | 687/1024 [00:01<00:00, 408.90it/s]
Adding requests:  71%|   | 728/1024 [00:01<00:00, 403.95it/s]
Adding requests:  75%|  | 769/1024 [00:01<00:00, 402.80it/s]
Adding requests:  79%|  | 813/1024 [00:01<00:00, 412.27it/s]
Adding requests:  83%| | 855/1024 [00:02<00:00, 411.23it/s]
Adding requests:  88%| | 897/1024 [00:02<00:00, 411.41it/s]
Adding requests:  92%|| 939/1024 [00:02<00:00, 409.77it/s]
Adding requests:  96%|| 981/1024 [00:02<00:00, 412.09it/s]
Adding requests: 100%|| 1024/1024 [00:02<00:00, 413.08it/s]
Adding requests: 100%|| 1024/1024 [00:02<00:00, 408.94it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 10/1024 [00:00<00:45, 22.19it/s, est. speed input: 22727.22 toks/s, output: 22.19 toks/s]
Processed prompts:   2%|         | 18/1024 [00:01<01:49,  9.17it/s, est. speed input: 10406.94 toks/s, output: 10.16 toks/s]
Processed prompts:   3%|         | 26/1024 [00:03<02:13,  7.50it/s, est. speed input: 8608.34 toks/s, output: 8.41 toks/s]  
Processed prompts:   3%|         | 34/1024 [00:04<02:23,  6.88it/s, est. speed input: 7890.04 toks/s, output: 7.71 toks/s]
Processed prompts:   4%|         | 42/1024 [00:05<02:29,  6.56it/s, est. speed input: 7498.42 toks/s, output: 7.32 toks/s]
Processed prompts:   5%|         | 50/1024 [00:07<02:32,  6.38it/s, est. speed input: 7252.60 toks/s, output: 7.08 toks/s]
Processed prompts:   6%|         | 58/1024 [00:08<02:34,  6.27it/s, est. speed input: 7085.10 toks/s, output: 6.92 toks/s]
Processed prompts:   6%|         | 66/1024 [00:09<02:34,  6.20it/s, est. speed input: 6964.13 toks/s, output: 6.80 toks/s]
Processed prompts:   7%|         | 74/1024 [00:11<02:34,  6.15it/s, est. speed input: 6870.73 toks/s, output: 6.71 toks/s]
Processed prompts:   8%|         | 82/1024 [00:12<02:34,  6.11it/s, est. speed input: 6794.21 toks/s, output: 6.63 toks/s]
Processed prompts:   9%|         | 90/1024 [00:13<02:33,  6.08it/s, est. speed input: 6733.91 toks/s, output: 6.58 toks/s]
Processed prompts:  10%|         | 98/1024 [00:15<02:32,  6.07it/s, est. speed input: 6687.21 toks/s, output: 6.53 toks/s]
Processed prompts:  10%|         | 106/1024 [00:16<02:31,  6.06it/s, est. speed input: 6646.72 toks/s, output: 6.49 toks/s]
Processed prompts:  11%|         | 114/1024 [00:17<02:30,  6.05it/s, est. speed input: 6610.80 toks/s, output: 6.46 toks/s]
Processed prompts:  12%|        | 122/1024 [00:18<02:29,  6.05it/s, est. speed input: 6581.21 toks/s, output: 6.43 toks/s]
Processed prompts:  13%|        | 130/1024 [00:20<02:27,  6.04it/s, est. speed input: 6554.84 toks/s, output: 6.40 toks/s]
Processed prompts:  13%|        | 138/1024 [00:21<02:26,  6.05it/s, est. speed input: 6532.72 toks/s, output: 6.38 toks/s]
Processed prompts:  14%|        | 146/1024 [00:22<02:25,  6.03it/s, est. speed input: 6510.75 toks/s, output: 6.36 toks/s]
Processed prompts:  15%|        | 154/1024 [00:24<02:24,  6.04it/s, est. speed input: 6493.34 toks/s, output: 6.34 toks/s]
Processed prompts:  16%|        | 162/1024 [00:25<02:22,  6.04it/s, est. speed input: 6477.68 toks/s, output: 6.33 toks/s]
Processed prompts:  17%|        | 170/1024 [00:26<02:21,  6.04it/s, est. speed input: 6463.46 toks/s, output: 6.31 toks/s]
Processed prompts:  17%|        | 178/1024 [00:28<02:20,  6.03it/s, est. speed input: 6449.28 toks/s, output: 6.30 toks/s]
Processed prompts:  18%|        | 186/1024 [00:29<02:19,  5.99it/s, est. speed input: 6430.19 toks/s, output: 6.28 toks/s]
Processed prompts:  19%|        | 194/1024 [00:31<02:21,  5.87it/s, est. speed input: 6397.82 toks/s, output: 6.25 toks/s]
Processed prompts:  20%|        | 202/1024 [00:32<02:14,  6.10it/s, est. speed input: 6416.26 toks/s, output: 6.27 toks/s]
Processed prompts:  21%|        | 210/1024 [00:33<02:13,  6.08it/s, est. speed input: 6407.01 toks/s, output: 6.26 toks/s]
Processed prompts:  21%|       | 218/1024 [00:34<02:12,  6.07it/s, est. speed input: 6398.06 toks/s, output: 6.25 toks/s]
Processed prompts:  22%|       | 226/1024 [00:36<02:11,  6.06it/s, est. speed input: 6390.66 toks/s, output: 6.24 toks/s]
Processed prompts:  23%|       | 234/1024 [00:37<02:10,  6.05it/s, est. speed input: 6383.34 toks/s, output: 6.23 toks/s]
Processed prompts:  24%|       | 242/1024 [00:38<02:09,  6.05it/s, est. speed input: 6376.68 toks/s, output: 6.23 toks/s]
Processed prompts:  24%|       | 250/1024 [00:40<02:08,  6.04it/s, est. speed input: 6369.65 toks/s, output: 6.22 toks/s]
Processed prompts:  25%|       | 258/1024 [00:41<02:06,  6.04it/s, est. speed input: 6364.00 toks/s, output: 6.21 toks/s]
Processed prompts:  26%|       | 266/1024 [00:42<02:05,  6.04it/s, est. speed input: 6358.31 toks/s, output: 6.21 toks/s]
Processed prompts:  27%|       | 274/1024 [00:44<02:04,  6.04it/s, est. speed input: 6353.01 toks/s, output: 6.20 toks/s]
Processed prompts:  28%|       | 282/1024 [00:45<02:03,  6.03it/s, est. speed input: 6347.24 toks/s, output: 6.20 toks/s]
Processed prompts:  28%|       | 290/1024 [00:46<02:01,  6.03it/s, est. speed input: 6342.47 toks/s, output: 6.19 toks/s]
Processed prompts:  29%|       | 298/1024 [00:48<02:00,  6.03it/s, est. speed input: 6338.14 toks/s, output: 6.19 toks/s]
Processed prompts:  30%|       | 306/1024 [00:49<01:54,  6.26it/s, est. speed input: 6354.13 toks/s, output: 6.21 toks/s]
Processed prompts:  31%|       | 314/1024 [00:50<01:54,  6.19it/s, est. speed input: 6349.59 toks/s, output: 6.20 toks/s]
Processed prompts:  31%|      | 322/1024 [00:51<01:54,  6.14it/s, est. speed input: 6344.81 toks/s, output: 6.20 toks/s]
Processed prompts:  32%|      | 330/1024 [00:53<01:53,  6.11it/s, est. speed input: 6340.94 toks/s, output: 6.19 toks/s]
Processed prompts:  33%|      | 338/1024 [00:54<01:52,  6.09it/s, est. speed input: 6337.26 toks/s, output: 6.19 toks/s]
Processed prompts:  34%|      | 346/1024 [00:55<01:51,  6.07it/s, est. speed input: 6333.63 toks/s, output: 6.19 toks/s]
Processed prompts:  35%|      | 354/1024 [00:57<01:50,  6.06it/s, est. speed input: 6329.88 toks/s, output: 6.18 toks/s]
Processed prompts:  35%|      | 362/1024 [00:58<01:49,  6.06it/s, est. speed input: 6327.01 toks/s, output: 6.18 toks/s]
Processed prompts:  36%|      | 370/1024 [00:59<01:48,  6.05it/s, est. speed input: 6323.53 toks/s, output: 6.18 toks/s]
Processed prompts:  37%|      | 378/1024 [01:01<01:46,  6.04it/s, est. speed input: 6320.39 toks/s, output: 6.17 toks/s]
Processed prompts:  38%|      | 386/1024 [01:02<01:46,  5.97it/s, est. speed input: 6311.84 toks/s, output: 6.16 toks/s]
Processed prompts:  38%|      | 394/1024 [01:03<01:45,  5.99it/s, est. speed input: 6309.22 toks/s, output: 6.16 toks/s]
Processed prompts:  39%|      | 402/1024 [01:05<01:43,  6.00it/s, est. speed input: 6306.71 toks/s, output: 6.16 toks/s]
Processed prompts:  40%|      | 410/1024 [01:06<01:42,  6.02it/s, est. speed input: 6304.40 toks/s, output: 6.16 toks/s]
Processed prompts:  41%|      | 418/1024 [01:07<01:40,  6.02it/s, est. speed input: 6301.51 toks/s, output: 6.15 toks/s]
Processed prompts:  42%|     | 426/1024 [01:09<01:39,  6.02it/s, est. speed input: 6299.19 toks/s, output: 6.15 toks/s]
Processed prompts:  42%|     | 434/1024 [01:10<01:34,  6.25it/s, est. speed input: 6311.00 toks/s, output: 6.16 toks/s]
Processed prompts:  43%|     | 442/1024 [01:11<01:34,  6.19it/s, est. speed input: 6308.78 toks/s, output: 6.16 toks/s]
Processed prompts:  44%|     | 450/1024 [01:13<01:33,  6.14it/s, est. speed input: 6306.63 toks/s, output: 6.16 toks/s]
Processed prompts:  45%|     | 458/1024 [01:14<01:32,  6.10it/s, est. speed input: 6303.79 toks/s, output: 6.16 toks/s]
Processed prompts:  46%|     | 466/1024 [01:15<01:31,  6.09it/s, est. speed input: 6302.05 toks/s, output: 6.15 toks/s]
Processed prompts:  46%|     | 474/1024 [01:17<01:30,  6.07it/s, est. speed input: 6299.92 toks/s, output: 6.15 toks/s]
Processed prompts:  47%|     | 482/1024 [01:18<01:29,  6.06it/s, est. speed input: 6297.94 toks/s, output: 6.15 toks/s]
Processed prompts:  48%|     | 490/1024 [01:19<01:28,  6.05it/s, est. speed input: 6295.64 toks/s, output: 6.15 toks/s]
Processed prompts:  49%|     | 498/1024 [01:21<01:27,  6.05it/s, est. speed input: 6293.85 toks/s, output: 6.15 toks/s]
Processed prompts:  49%|     | 506/1024 [01:22<01:25,  6.04it/s, est. speed input: 6292.01 toks/s, output: 6.14 toks/s]
Processed prompts:  50%|     | 514/1024 [01:23<01:24,  6.04it/s, est. speed input: 6290.08 toks/s, output: 6.14 toks/s]
Processed prompts:  51%|     | 522/1024 [01:25<01:23,  6.03it/s, est. speed input: 6288.09 toks/s, output: 6.14 toks/s]
Processed prompts:  52%|    | 530/1024 [01:26<01:21,  6.03it/s, est. speed input: 6286.31 toks/s, output: 6.14 toks/s]
Processed prompts:  53%|    | 538/1024 [01:27<01:20,  6.04it/s, est. speed input: 6284.96 toks/s, output: 6.14 toks/s]
Processed prompts:  53%|    | 546/1024 [01:28<01:19,  6.04it/s, est. speed input: 6283.51 toks/s, output: 6.14 toks/s]
Processed prompts:  54%|    | 554/1024 [01:30<01:17,  6.03it/s, est. speed input: 6281.65 toks/s, output: 6.13 toks/s]
Processed prompts:  55%|    | 562/1024 [01:31<01:16,  6.03it/s, est. speed input: 6280.06 toks/s, output: 6.13 toks/s]
Processed prompts:  56%|    | 570/1024 [01:32<01:15,  6.04it/s, est. speed input: 6278.90 toks/s, output: 6.13 toks/s]
Processed prompts:  56%|    | 578/1024 [01:34<01:13,  6.04it/s, est. speed input: 6277.54 toks/s, output: 6.13 toks/s]
Processed prompts:  57%|    | 586/1024 [01:35<01:13,  5.99it/s, est. speed input: 6274.02 toks/s, output: 6.13 toks/s]
Processed prompts:  58%|    | 594/1024 [01:36<01:11,  6.00it/s, est. speed input: 6272.50 toks/s, output: 6.13 toks/s]
Processed prompts:  59%|    | 602/1024 [01:38<01:10,  6.01it/s, est. speed input: 6271.12 toks/s, output: 6.12 toks/s]
Processed prompts:  60%|    | 610/1024 [01:39<01:08,  6.02it/s, est. speed input: 6269.93 toks/s, output: 6.12 toks/s]
Processed prompts:  60%|    | 618/1024 [01:40<01:07,  6.02it/s, est. speed input: 6268.81 toks/s, output: 6.12 toks/s]
Processed prompts:  61%|    | 626/1024 [01:42<01:06,  6.02it/s, est. speed input: 6267.37 toks/s, output: 6.12 toks/s]
Processed prompts:  62%|   | 634/1024 [01:43<01:04,  6.03it/s, est. speed input: 6266.36 toks/s, output: 6.12 toks/s]
Processed prompts:  63%|   | 642/1024 [01:44<01:03,  6.03it/s, est. speed input: 6265.26 toks/s, output: 6.12 toks/s]
Processed prompts:  63%|   | 650/1024 [01:46<01:02,  6.03it/s, est. speed input: 6264.17 toks/s, output: 6.12 toks/s]
Processed prompts:  64%|   | 658/1024 [01:47<01:00,  6.03it/s, est. speed input: 6262.90 toks/s, output: 6.12 toks/s]
Processed prompts:  65%|   | 666/1024 [01:48<00:59,  6.03it/s, est. speed input: 6261.86 toks/s, output: 6.12 toks/s]
Processed prompts:  66%|   | 674/1024 [01:50<00:58,  6.03it/s, est. speed input: 6260.82 toks/s, output: 6.11 toks/s]
Processed prompts:  67%|   | 682/1024 [01:51<00:56,  6.03it/s, est. speed input: 6259.71 toks/s, output: 6.11 toks/s]
Processed prompts:  67%|   | 690/1024 [01:52<00:55,  6.02it/s, est. speed input: 6258.41 toks/s, output: 6.11 toks/s]
Processed prompts:  68%|   | 698/1024 [01:54<00:54,  6.03it/s, est. speed input: 6257.55 toks/s, output: 6.11 toks/s]
Processed prompts:  69%|   | 706/1024 [01:55<00:52,  6.03it/s, est. speed input: 6256.78 toks/s, output: 6.11 toks/s]
Processed prompts:  70%|   | 714/1024 [01:56<00:51,  6.03it/s, est. speed input: 6255.96 toks/s, output: 6.11 toks/s]
Processed prompts:  71%|   | 722/1024 [01:58<00:50,  6.03it/s, est. speed input: 6254.75 toks/s, output: 6.11 toks/s]
Processed prompts:  71%|  | 730/1024 [01:59<00:48,  6.03it/s, est. speed input: 6253.90 toks/s, output: 6.11 toks/s]
Processed prompts:  72%|  | 738/1024 [02:00<00:47,  6.03it/s, est. speed input: 6253.09 toks/s, output: 6.11 toks/s]
Processed prompts:  73%|  | 746/1024 [02:02<00:46,  6.03it/s, est. speed input: 6252.18 toks/s, output: 6.11 toks/s]
Processed prompts:  74%|  | 754/1024 [02:03<00:44,  6.02it/s, est. speed input: 6251.18 toks/s, output: 6.10 toks/s]
Processed prompts:  74%|  | 762/1024 [02:04<00:43,  6.03it/s, est. speed input: 6250.37 toks/s, output: 6.10 toks/s]
Processed prompts:  75%|  | 770/1024 [02:06<00:42,  6.03it/s, est. speed input: 6249.60 toks/s, output: 6.10 toks/s]
Processed prompts:  76%|  | 778/1024 [02:07<00:41,  5.99it/s, est. speed input: 6247.42 toks/s, output: 6.10 toks/s]
Processed prompts:  77%|  | 786/1024 [02:08<00:38,  6.23it/s, est. speed input: 6254.46 toks/s, output: 6.11 toks/s]
Processed prompts:  78%|  | 794/1024 [02:10<00:37,  6.16it/s, est. speed input: 6253.46 toks/s, output: 6.11 toks/s]
Processed prompts:  78%|  | 802/1024 [02:11<00:36,  6.12it/s, est. speed input: 6252.64 toks/s, output: 6.11 toks/s]
Processed prompts:  79%|  | 810/1024 [02:12<00:35,  6.09it/s, est. speed input: 6251.79 toks/s, output: 6.11 toks/s]
Processed prompts:  80%|  | 818/1024 [02:13<00:33,  6.08it/s, est. speed input: 6251.19 toks/s, output: 6.10 toks/s]
Processed prompts:  81%|  | 826/1024 [02:15<00:32,  6.05it/s, est. speed input: 6250.14 toks/s, output: 6.10 toks/s]
Processed prompts:  81%| | 834/1024 [02:16<00:31,  6.05it/s, est. speed input: 6249.53 toks/s, output: 6.10 toks/s]
Processed prompts:  82%| | 842/1024 [02:17<00:30,  6.05it/s, est. speed input: 6248.92 toks/s, output: 6.10 toks/s]
Processed prompts:  83%| | 850/1024 [02:19<00:28,  6.04it/s, est. speed input: 6248.30 toks/s, output: 6.10 toks/s]
Processed prompts:  84%| | 858/1024 [02:20<00:27,  6.04it/s, est. speed input: 6247.43 toks/s, output: 6.10 toks/s]
Processed prompts:  85%| | 866/1024 [02:21<00:26,  6.04it/s, est. speed input: 6246.85 toks/s, output: 6.10 toks/s]
Processed prompts:  85%| | 874/1024 [02:23<00:24,  6.04it/s, est. speed input: 6246.33 toks/s, output: 6.10 toks/s]
Processed prompts:  86%| | 882/1024 [02:24<00:23,  6.04it/s, est. speed input: 6245.64 toks/s, output: 6.10 toks/s]
Processed prompts:  87%| | 890/1024 [02:25<00:22,  6.02it/s, est. speed input: 6244.63 toks/s, output: 6.10 toks/s]
Processed prompts:  88%| | 898/1024 [02:27<00:20,  6.03it/s, est. speed input: 6244.10 toks/s, output: 6.10 toks/s]
Processed prompts:  88%| | 906/1024 [02:28<00:19,  6.03it/s, est. speed input: 6243.60 toks/s, output: 6.10 toks/s]
Processed prompts:  89%| | 914/1024 [02:29<00:18,  6.03it/s, est. speed input: 6243.06 toks/s, output: 6.10 toks/s]
Processed prompts:  90%| | 922/1024 [02:31<00:16,  6.03it/s, est. speed input: 6242.47 toks/s, output: 6.10 toks/s]
Processed prompts:  91%| | 930/1024 [02:32<00:15,  6.02it/s, est. speed input: 6241.65 toks/s, output: 6.10 toks/s]
Processed prompts:  92%|| 938/1024 [02:33<00:14,  6.03it/s, est. speed input: 6241.24 toks/s, output: 6.09 toks/s]
Processed prompts:  92%|| 946/1024 [02:35<00:12,  6.03it/s, est. speed input: 6240.70 toks/s, output: 6.09 toks/s]
Processed prompts:  93%|| 954/1024 [02:36<00:11,  6.03it/s, est. speed input: 6240.15 toks/s, output: 6.09 toks/s]
Processed prompts:  94%|| 962/1024 [02:37<00:10,  6.02it/s, est. speed input: 6239.37 toks/s, output: 6.09 toks/s]
Processed prompts:  95%|| 970/1024 [02:39<00:08,  6.00it/s, est. speed input: 6238.22 toks/s, output: 6.09 toks/s]
Processed prompts:  96%|| 978/1024 [02:40<00:07,  6.01it/s, est. speed input: 6237.73 toks/s, output: 6.09 toks/s]
Processed prompts:  96%|| 986/1024 [02:41<00:06,  6.02it/s, est. speed input: 6237.16 toks/s, output: 6.09 toks/s]
Processed prompts:  97%|| 994/1024 [02:43<00:04,  6.01it/s, est. speed input: 6236.44 toks/s, output: 6.09 toks/s]
Processed prompts:  98%|| 1002/1024 [02:44<00:03,  6.02it/s, est. speed input: 6236.01 toks/s, output: 6.09 toks/s]
Processed prompts:  99%|| 1010/1024 [02:45<00:02,  6.03it/s, est. speed input: 6235.59 toks/s, output: 6.09 toks/s]
Processed prompts:  99%|| 1018/1024 [02:47<00:00,  6.26it/s, est. speed input: 6241.17 toks/s, output: 6.09 toks/s]
Processed prompts: 100%|| 1024/1024 [02:47<00:00,  6.26it/s, est. speed input: 6277.95 toks/s, output: 6.13 toks/s]
Processed prompts: 100%|| 1024/1024 [02:47<00:00,  6.13it/s, est. speed input: 6277.95 toks/s, output: 6.13 toks/s]
[rank0]:[W126 18:54:33.226662190 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-26 18:54:35
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Qwen2.5-7B-FP8_M16384.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 18:54:48 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 18:54:48 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1622680) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1622680) WARNING 01-26 18:56:04 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 6.11 requests/s, 6264.85 total tokens/s, 6.11 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-26 18:54:48] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 18:54:48] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 18:54:48] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 18:54:48] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:54:48] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:54:48] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:54:48] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:54:48] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:54:48] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 18:54:48] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 18:54:48] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 18:54:48] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 18:54:48] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 18:54:48] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 18:54:52] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 18:54:52] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 18:54:52] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 18:54:52] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:54:52] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:54:52] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:54:52] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:54:52] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 18:54:52] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 18:54:52] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 18:54:52] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 18:54:52] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 18:54:52] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 18:54:52] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1622680) [2026-01-26 18:54:53] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1622680) [2026-01-26 18:54:53] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1622680) [2026-01-26 18:54:53] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1622680) [2026-01-26 18:54:53] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1622680) [2026-01-26 18:54:53] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1622680) [2026-01-26 18:54:53] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1622680) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1622680) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:24<00:24, 24.39s/it]
(EngineCore_DP0 pid=1622680) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:58<00:00, 30.14s/it]
(EngineCore_DP0 pid=1622680) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:58<00:00, 29.27s/it]
(EngineCore_DP0 pid=1622680) 
(EngineCore_DP0 pid=1622680) [2026-01-26 18:55:52] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=1622680) [2026-01-26 18:55:53] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 13860864 bytes
(EngineCore_DP0 pid=1622680) [2026-01-26 18:55:53] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=1622680) [2026-01-26 18:55:53] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10780672 bytes
(EngineCore_DP0 pid=1622680) [2026-01-26 18:55:53] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=1622680) [2026-01-26 18:55:53] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 113967104 bytes
(EngineCore_DP0 pid=1622680) [2026-01-26 18:55:53] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=1622680) [2026-01-26 18:55:53] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 56655872 bytes
(EngineCore_DP0 pid=1622680) 2026-01-26 18:56:01,149 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1622680) 2026-01-26 18:56:01,455 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   2%|         | 31/2048 [00:00<00:06, 301.42it/s]
Adding requests:   3%|         | 65/2048 [00:00<00:06, 321.21it/s]
Adding requests:   5%|         | 103/2048 [00:00<00:05, 347.64it/s]
Adding requests:   7%|         | 144/2048 [00:00<00:05, 371.01it/s]
Adding requests:   9%|         | 187/2048 [00:00<00:04, 390.10it/s]
Adding requests:  11%|        | 232/2048 [00:00<00:04, 406.79it/s]
Adding requests:  13%|        | 273/2048 [00:00<00:04, 405.34it/s]
Adding requests:  16%|        | 319/2048 [00:00<00:04, 421.94it/s]
Adding requests:  18%|        | 365/2048 [00:00<00:03, 432.51it/s]
Adding requests:  20%|        | 409/2048 [00:01<00:03, 432.41it/s]
Adding requests:  22%|       | 453/2048 [00:01<00:03, 432.90it/s]
Adding requests:  24%|       | 498/2048 [00:01<00:03, 437.55it/s]
Adding requests:  27%|       | 543/2048 [00:01<00:03, 439.09it/s]
Adding requests:  29%|       | 587/2048 [00:01<00:03, 434.38it/s]
Adding requests:  31%|       | 631/2048 [00:01<00:03, 433.62it/s]
Adding requests:  33%|      | 675/2048 [00:01<00:03, 427.87it/s]
Adding requests:  35%|      | 720/2048 [00:01<00:03, 429.78it/s]
Adding requests:  37%|      | 763/2048 [00:01<00:03, 421.26it/s]
Adding requests:  39%|      | 807/2048 [00:01<00:02, 423.73it/s]
Adding requests:  42%|     | 853/2048 [00:02<00:02, 432.86it/s]
Adding requests:  44%|     | 897/2048 [00:02<00:02, 415.44it/s]
Adding requests:  46%|     | 940/2048 [00:02<00:02, 418.88it/s]
Adding requests:  48%|     | 983/2048 [00:03<00:07, 144.49it/s]
Adding requests:  50%|     | 1024/2048 [00:03<00:05, 176.92it/s]
Adding requests:  52%|    | 1066/2048 [00:03<00:04, 212.76it/s]
Adding requests:  54%|    | 1107/2048 [00:03<00:03, 247.40it/s]
Adding requests:  56%|    | 1148/2048 [00:03<00:03, 279.33it/s]
Adding requests:  58%|    | 1190/2048 [00:03<00:02, 310.61it/s]
Adding requests:  60%|    | 1233/2048 [00:03<00:02, 337.98it/s]
Adding requests:  62%|   | 1274/2048 [00:03<00:02, 353.02it/s]
Adding requests:  64%|   | 1317/2048 [00:03<00:01, 371.73it/s]
Adding requests:  66%|   | 1358/2048 [00:03<00:01, 379.67it/s]
Adding requests:  68%|   | 1401/2048 [00:04<00:01, 392.41it/s]
Adding requests:  71%|   | 1444/2048 [00:04<00:01, 402.39it/s]
Adding requests:  73%|  | 1489/2048 [00:04<00:01, 414.36it/s]
Adding requests:  75%|  | 1532/2048 [00:04<00:01, 416.66it/s]
Adding requests:  77%|  | 1575/2048 [00:04<00:01, 411.47it/s]
Adding requests:  79%|  | 1617/2048 [00:04<00:01, 413.16it/s]
Adding requests:  81%|  | 1659/2048 [00:04<00:00, 401.45it/s]
Adding requests:  83%| | 1702/2048 [00:04<00:00, 408.04it/s]
Adding requests:  85%| | 1745/2048 [00:04<00:00, 413.02it/s]
Adding requests:  87%| | 1789/2048 [00:04<00:00, 419.99it/s]
Adding requests:  89%| | 1832/2048 [00:05<00:00, 420.81it/s]
Adding requests:  92%|| 1875/2048 [00:05<00:00, 422.32it/s]
Adding requests:  94%|| 1921/2048 [00:05<00:00, 432.46it/s]
Adding requests:  96%|| 1965/2048 [00:05<00:00, 427.68it/s]
Adding requests:  98%|| 2008/2048 [00:05<00:00, 422.72it/s]
Adding requests: 100%|| 2048/2048 [00:05<00:00, 366.63it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 34/2048 [00:02<02:31, 13.28it/s, est. speed input: 13600.78 toks/s, output: 13.28 toks/s]
Processed prompts:   2%|         | 50/2048 [00:05<03:41,  9.01it/s, est. speed input: 9877.50 toks/s, output: 9.65 toks/s]  
Processed prompts:   3%|         | 66/2048 [00:07<04:18,  7.67it/s, est. speed input: 8649.24 toks/s, output: 8.45 toks/s]
Processed prompts:   4%|         | 82/2048 [00:10<04:39,  7.04it/s, est. speed input: 8043.13 toks/s, output: 7.85 toks/s]
Processed prompts:   5%|         | 98/2048 [00:13<04:51,  6.70it/s, est. speed input: 7678.30 toks/s, output: 7.50 toks/s]
Processed prompts:   6%|         | 114/2048 [00:15<04:57,  6.49it/s, est. speed input: 7437.89 toks/s, output: 7.26 toks/s]
Processed prompts:   6%|         | 130/2048 [00:18<05:01,  6.36it/s, est. speed input: 7264.20 toks/s, output: 7.09 toks/s]
Processed prompts:   7%|         | 146/2048 [00:20<05:03,  6.27it/s, est. speed input: 7135.38 toks/s, output: 6.97 toks/s]
Processed prompts:   8%|         | 162/2048 [00:23<05:03,  6.21it/s, est. speed input: 7034.69 toks/s, output: 6.87 toks/s]
Processed prompts:   9%|         | 178/2048 [00:26<05:02,  6.18it/s, est. speed input: 6955.34 toks/s, output: 6.79 toks/s]
Processed prompts:   9%|         | 194/2048 [00:28<04:55,  6.26it/s, est. speed input: 6927.36 toks/s, output: 6.76 toks/s]
Processed prompts:  10%|         | 210/2048 [00:31<04:56,  6.21it/s, est. speed input: 6868.29 toks/s, output: 6.71 toks/s]
Processed prompts:  11%|         | 226/2048 [00:33<04:55,  6.17it/s, est. speed input: 6818.57 toks/s, output: 6.66 toks/s]
Processed prompts:  12%|        | 242/2048 [00:36<04:54,  6.13it/s, est. speed input: 6774.10 toks/s, output: 6.62 toks/s]
Processed prompts:  13%|        | 258/2048 [00:39<04:52,  6.12it/s, est. speed input: 6737.53 toks/s, output: 6.58 toks/s]
Processed prompts:  13%|        | 274/2048 [00:41<04:50,  6.10it/s, est. speed input: 6704.02 toks/s, output: 6.55 toks/s]
Processed prompts:  14%|        | 290/2048 [00:44<04:48,  6.10it/s, est. speed input: 6675.83 toks/s, output: 6.52 toks/s]
Processed prompts:  15%|        | 306/2048 [00:46<04:40,  6.22it/s, est. speed input: 6675.79 toks/s, output: 6.52 toks/s]
Processed prompts:  16%|        | 322/2048 [00:49<04:39,  6.17it/s, est. speed input: 6650.49 toks/s, output: 6.49 toks/s]
Processed prompts:  17%|        | 338/2048 [00:52<04:38,  6.14it/s, est. speed input: 6628.20 toks/s, output: 6.47 toks/s]
Processed prompts:  17%|        | 354/2048 [00:54<04:36,  6.12it/s, est. speed input: 6608.59 toks/s, output: 6.45 toks/s]
Processed prompts:  18%|        | 370/2048 [00:57<04:34,  6.10it/s, est. speed input: 6590.47 toks/s, output: 6.44 toks/s]
Processed prompts:  19%|        | 386/2048 [01:00<04:32,  6.09it/s, est. speed input: 6574.07 toks/s, output: 6.42 toks/s]
Processed prompts:  20%|        | 402/2048 [01:02<04:30,  6.08it/s, est. speed input: 6558.72 toks/s, output: 6.40 toks/s]
Processed prompts:  20%|        | 418/2048 [01:05<04:28,  6.08it/s, est. speed input: 6544.92 toks/s, output: 6.39 toks/s]
Processed prompts:  21%|        | 434/2048 [01:07<04:20,  6.20it/s, est. speed input: 6549.43 toks/s, output: 6.40 toks/s]
Processed prompts:  22%|       | 450/2048 [01:10<04:19,  6.16it/s, est. speed input: 6536.57 toks/s, output: 6.38 toks/s]
Processed prompts:  23%|       | 466/2048 [01:13<04:17,  6.13it/s, est. speed input: 6525.00 toks/s, output: 6.37 toks/s]
Processed prompts:  24%|       | 482/2048 [01:15<04:16,  6.11it/s, est. speed input: 6513.91 toks/s, output: 6.36 toks/s]
Processed prompts:  24%|       | 498/2048 [01:18<04:14,  6.10it/s, est. speed input: 6503.87 toks/s, output: 6.35 toks/s]
Processed prompts:  25%|       | 514/2048 [01:21<04:11,  6.09it/s, est. speed input: 6494.30 toks/s, output: 6.34 toks/s]
Processed prompts:  26%|       | 530/2048 [01:23<04:09,  6.08it/s, est. speed input: 6485.75 toks/s, output: 6.33 toks/s]
Processed prompts:  27%|       | 546/2048 [01:26<04:07,  6.08it/s, est. speed input: 6477.33 toks/s, output: 6.33 toks/s]
Processed prompts:  27%|       | 562/2048 [01:28<04:04,  6.07it/s, est. speed input: 6468.79 toks/s, output: 6.32 toks/s]
Processed prompts:  28%|       | 578/2048 [01:31<04:02,  6.07it/s, est. speed input: 6461.29 toks/s, output: 6.31 toks/s]
Processed prompts:  29%|       | 594/2048 [01:34<03:59,  6.06it/s, est. speed input: 6453.83 toks/s, output: 6.30 toks/s]
Processed prompts:  30%|       | 610/2048 [01:36<03:57,  6.06it/s, est. speed input: 6447.12 toks/s, output: 6.30 toks/s]
Processed prompts:  31%|       | 626/2048 [01:39<03:54,  6.06it/s, est. speed input: 6440.66 toks/s, output: 6.29 toks/s]
Processed prompts:  31%|      | 642/2048 [01:42<03:51,  6.06it/s, est. speed input: 6434.74 toks/s, output: 6.28 toks/s]
Processed prompts:  32%|      | 658/2048 [01:44<03:49,  6.07it/s, est. speed input: 6429.44 toks/s, output: 6.28 toks/s]
Processed prompts:  33%|      | 674/2048 [01:47<03:46,  6.07it/s, est. speed input: 6424.23 toks/s, output: 6.27 toks/s]
Processed prompts:  34%|      | 690/2048 [01:50<03:44,  6.06it/s, est. speed input: 6418.66 toks/s, output: 6.27 toks/s]
Processed prompts:  34%|      | 706/2048 [01:52<03:41,  6.06it/s, est. speed input: 6413.79 toks/s, output: 6.26 toks/s]
Processed prompts:  35%|      | 722/2048 [01:55<03:38,  6.06it/s, est. speed input: 6409.00 toks/s, output: 6.26 toks/s]
Processed prompts:  36%|      | 738/2048 [01:57<03:36,  6.06it/s, est. speed input: 6404.50 toks/s, output: 6.25 toks/s]
Processed prompts:  37%|      | 754/2048 [02:00<03:33,  6.06it/s, est. speed input: 6399.76 toks/s, output: 6.25 toks/s]
Processed prompts:  38%|      | 770/2048 [02:03<03:30,  6.06it/s, est. speed input: 6395.78 toks/s, output: 6.25 toks/s]
Processed prompts:  38%|      | 786/2048 [02:05<03:23,  6.19it/s, est. speed input: 6401.04 toks/s, output: 6.25 toks/s]
Processed prompts:  39%|      | 802/2048 [02:08<03:23,  6.12it/s, est. speed input: 6395.15 toks/s, output: 6.25 toks/s]
Processed prompts:  40%|      | 818/2048 [02:11<03:21,  6.10it/s, est. speed input: 6391.18 toks/s, output: 6.24 toks/s]
Processed prompts:  41%|      | 834/2048 [02:13<03:19,  6.08it/s, est. speed input: 6386.94 toks/s, output: 6.24 toks/s]
Processed prompts:  42%|     | 850/2048 [02:16<03:17,  6.07it/s, est. speed input: 6383.33 toks/s, output: 6.23 toks/s]
Processed prompts:  42%|     | 866/2048 [02:18<03:14,  6.07it/s, est. speed input: 6379.93 toks/s, output: 6.23 toks/s]
Processed prompts:  43%|     | 882/2048 [02:21<03:12,  6.07it/s, est. speed input: 6376.67 toks/s, output: 6.23 toks/s]
Processed prompts:  44%|     | 898/2048 [02:24<03:09,  6.06it/s, est. speed input: 6373.06 toks/s, output: 6.22 toks/s]
Processed prompts:  45%|     | 914/2048 [02:26<03:07,  6.06it/s, est. speed input: 6370.16 toks/s, output: 6.22 toks/s]
Processed prompts:  45%|     | 930/2048 [02:29<03:04,  6.06it/s, est. speed input: 6367.00 toks/s, output: 6.22 toks/s]
Processed prompts:  46%|     | 946/2048 [02:32<03:02,  6.05it/s, est. speed input: 6363.97 toks/s, output: 6.21 toks/s]
Processed prompts:  47%|     | 962/2048 [02:34<02:59,  6.05it/s, est. speed input: 6361.00 toks/s, output: 6.21 toks/s]
Processed prompts:  48%|     | 978/2048 [02:37<02:56,  6.06it/s, est. speed input: 6358.57 toks/s, output: 6.21 toks/s]
Processed prompts:  49%|     | 994/2048 [02:40<02:54,  6.05it/s, est. speed input: 6355.87 toks/s, output: 6.21 toks/s]
Processed prompts:  49%|     | 1010/2048 [02:42<02:51,  6.06it/s, est. speed input: 6353.40 toks/s, output: 6.20 toks/s]
Processed prompts:  50%|     | 1026/2048 [02:45<02:48,  6.05it/s, est. speed input: 6350.85 toks/s, output: 6.20 toks/s]
Processed prompts:  51%|     | 1042/2048 [02:48<02:46,  6.06it/s, est. speed input: 6348.59 toks/s, output: 6.20 toks/s]
Processed prompts:  52%|    | 1058/2048 [02:50<02:43,  6.05it/s, est. speed input: 6346.13 toks/s, output: 6.20 toks/s]
Processed prompts:  52%|    | 1074/2048 [02:53<02:40,  6.05it/s, est. speed input: 6343.92 toks/s, output: 6.20 toks/s]
Processed prompts:  53%|    | 1090/2048 [02:56<02:38,  6.05it/s, est. speed input: 6341.70 toks/s, output: 6.19 toks/s]
Processed prompts:  54%|    | 1106/2048 [02:58<02:35,  6.06it/s, est. speed input: 6339.74 toks/s, output: 6.19 toks/s]
Processed prompts:  55%|    | 1122/2048 [03:01<02:32,  6.05it/s, est. speed input: 6337.66 toks/s, output: 6.19 toks/s]
Processed prompts:  56%|    | 1138/2048 [03:03<02:30,  6.06it/s, est. speed input: 6335.75 toks/s, output: 6.19 toks/s]
Processed prompts:  56%|    | 1154/2048 [03:06<02:27,  6.06it/s, est. speed input: 6333.81 toks/s, output: 6.19 toks/s]
Processed prompts:  57%|    | 1170/2048 [03:09<02:24,  6.06it/s, est. speed input: 6332.00 toks/s, output: 6.18 toks/s]
Processed prompts:  58%|    | 1186/2048 [03:11<02:22,  6.05it/s, est. speed input: 6330.14 toks/s, output: 6.18 toks/s]
Processed prompts:  59%|    | 1202/2048 [03:14<02:16,  6.19it/s, est. speed input: 6334.44 toks/s, output: 6.19 toks/s]
Processed prompts:  59%|    | 1218/2048 [03:16<02:14,  6.15it/s, est. speed input: 6332.76 toks/s, output: 6.18 toks/s]
Processed prompts:  60%|    | 1234/2048 [03:19<02:10,  6.25it/s, est. speed input: 6336.65 toks/s, output: 6.19 toks/s]
Processed prompts:  61%|    | 1250/2048 [03:22<02:08,  6.19it/s, est. speed input: 6334.90 toks/s, output: 6.19 toks/s]
Processed prompts:  62%|   | 1266/2048 [03:24<02:07,  6.15it/s, est. speed input: 6333.08 toks/s, output: 6.18 toks/s]
Processed prompts:  63%|   | 1282/2048 [03:27<02:05,  6.12it/s, est. speed input: 6331.36 toks/s, output: 6.18 toks/s]
Processed prompts:  63%|   | 1298/2048 [03:29<02:03,  6.10it/s, est. speed input: 6329.56 toks/s, output: 6.18 toks/s]
Processed prompts:  64%|   | 1314/2048 [03:32<02:00,  6.08it/s, est. speed input: 6327.88 toks/s, output: 6.18 toks/s]
Processed prompts:  65%|   | 1330/2048 [03:35<01:55,  6.21it/s, est. speed input: 6331.83 toks/s, output: 6.18 toks/s]
Processed prompts:  66%|   | 1346/2048 [03:37<01:54,  6.16it/s, est. speed input: 6330.12 toks/s, output: 6.18 toks/s]
Processed prompts:  67%|   | 1362/2048 [03:40<01:52,  6.12it/s, est. speed input: 6328.45 toks/s, output: 6.18 toks/s]
Processed prompts:  67%|   | 1378/2048 [03:43<01:49,  6.10it/s, est. speed input: 6326.77 toks/s, output: 6.18 toks/s]
Processed prompts:  68%|   | 1394/2048 [03:45<01:47,  6.09it/s, est. speed input: 6325.37 toks/s, output: 6.18 toks/s]
Processed prompts:  69%|   | 1410/2048 [03:48<01:45,  6.07it/s, est. speed input: 6323.81 toks/s, output: 6.18 toks/s]
Processed prompts:  70%|   | 1426/2048 [03:50<01:42,  6.07it/s, est. speed input: 6322.39 toks/s, output: 6.17 toks/s]
Processed prompts:  70%|   | 1442/2048 [03:53<01:37,  6.19it/s, est. speed input: 6325.96 toks/s, output: 6.18 toks/s]
Processed prompts:  71%|   | 1458/2048 [03:55<01:33,  6.29it/s, est. speed input: 6329.70 toks/s, output: 6.18 toks/s]
Processed prompts:  72%|  | 1474/2048 [03:58<01:32,  6.22it/s, est. speed input: 6328.32 toks/s, output: 6.18 toks/s]
Processed prompts:  73%|  | 1490/2048 [04:01<01:30,  6.17it/s, est. speed input: 6326.98 toks/s, output: 6.18 toks/s]
Processed prompts:  74%|  | 1506/2048 [04:03<01:28,  6.14it/s, est. speed input: 6325.62 toks/s, output: 6.18 toks/s]
Processed prompts:  74%|  | 1522/2048 [04:06<01:24,  6.24it/s, est. speed input: 6328.92 toks/s, output: 6.18 toks/s]
Processed prompts:  75%|  | 1538/2048 [04:08<01:22,  6.19it/s, est. speed input: 6327.68 toks/s, output: 6.18 toks/s]
Processed prompts:  76%|  | 1554/2048 [04:11<01:18,  6.28it/s, est. speed input: 6330.97 toks/s, output: 6.18 toks/s]
Processed prompts:  77%|  | 1570/2048 [04:13<01:17,  6.21it/s, est. speed input: 6329.49 toks/s, output: 6.18 toks/s]
Processed prompts:  77%|  | 1586/2048 [04:16<01:14,  6.16it/s, est. speed input: 6328.24 toks/s, output: 6.18 toks/s]
Processed prompts:  78%|  | 1602/2048 [04:19<01:12,  6.13it/s, est. speed input: 6326.77 toks/s, output: 6.18 toks/s]
Processed prompts:  79%|  | 1618/2048 [04:21<01:08,  6.23it/s, est. speed input: 6329.86 toks/s, output: 6.18 toks/s]
Processed prompts:  80%|  | 1634/2048 [04:24<01:07,  6.18it/s, est. speed input: 6328.50 toks/s, output: 6.18 toks/s]
Processed prompts:  81%|  | 1650/2048 [04:27<01:04,  6.14it/s, est. speed input: 6327.13 toks/s, output: 6.18 toks/s]
Processed prompts:  81%| | 1666/2048 [04:29<01:02,  6.11it/s, est. speed input: 6325.89 toks/s, output: 6.18 toks/s]
Processed prompts:  82%| | 1682/2048 [04:32<01:00,  6.09it/s, est. speed input: 6324.66 toks/s, output: 6.18 toks/s]
Processed prompts:  83%| | 1698/2048 [04:34<00:57,  6.08it/s, est. speed input: 6323.38 toks/s, output: 6.18 toks/s]
Processed prompts:  84%| | 1714/2048 [04:37<00:55,  6.07it/s, est. speed input: 6322.17 toks/s, output: 6.17 toks/s]
Processed prompts:  84%| | 1730/2048 [04:40<00:51,  6.19it/s, est. speed input: 6325.07 toks/s, output: 6.18 toks/s]
Processed prompts:  85%| | 1746/2048 [04:42<00:47,  6.38it/s, est. speed input: 6330.76 toks/s, output: 6.18 toks/s]
Processed prompts:  86%| | 1762/2048 [04:45<00:45,  6.28it/s, est. speed input: 6329.59 toks/s, output: 6.18 toks/s]
Processed prompts:  87%| | 1778/2048 [04:47<00:43,  6.21it/s, est. speed input: 6328.31 toks/s, output: 6.18 toks/s]
Processed prompts:  88%| | 1794/2048 [04:50<00:41,  6.16it/s, est. speed input: 6327.12 toks/s, output: 6.18 toks/s]
Processed prompts:  88%| | 1810/2048 [04:53<00:38,  6.12it/s, est. speed input: 6325.73 toks/s, output: 6.18 toks/s]
Processed prompts:  89%| | 1826/2048 [04:55<00:36,  6.10it/s, est. speed input: 6324.70 toks/s, output: 6.18 toks/s]
Processed prompts:  90%| | 1842/2048 [04:58<00:33,  6.09it/s, est. speed input: 6323.51 toks/s, output: 6.18 toks/s]
Processed prompts:  91%| | 1858/2048 [05:00<00:31,  6.07it/s, est. speed input: 6322.36 toks/s, output: 6.17 toks/s]
Processed prompts:  92%|| 1874/2048 [05:03<00:28,  6.07it/s, est. speed input: 6321.24 toks/s, output: 6.17 toks/s]
Processed prompts:  92%|| 1890/2048 [05:06<00:25,  6.19it/s, est. speed input: 6323.95 toks/s, output: 6.18 toks/s]
Processed prompts:  93%|| 1906/2048 [05:08<00:23,  6.14it/s, est. speed input: 6322.75 toks/s, output: 6.17 toks/s]
Processed prompts:  94%|| 1922/2048 [05:11<00:20,  6.11it/s, est. speed input: 6321.59 toks/s, output: 6.17 toks/s]
Processed prompts:  95%|| 1938/2048 [05:13<00:18,  6.10it/s, est. speed input: 6320.66 toks/s, output: 6.17 toks/s]
Processed prompts:  95%|| 1954/2048 [05:16<00:15,  6.08it/s, est. speed input: 6319.42 toks/s, output: 6.17 toks/s]
Processed prompts:  96%|| 1970/2048 [05:19<00:12,  6.07it/s, est. speed input: 6318.33 toks/s, output: 6.17 toks/s]
Processed prompts:  97%|| 1986/2048 [05:21<00:10,  6.19it/s, est. speed input: 6320.78 toks/s, output: 6.17 toks/s]
Processed prompts:  98%|| 2002/2048 [05:24<00:07,  6.14it/s, est. speed input: 6319.77 toks/s, output: 6.17 toks/s]
Processed prompts:  99%|| 2018/2048 [05:27<00:04,  6.11it/s, est. speed input: 6318.67 toks/s, output: 6.17 toks/s]
Processed prompts:  99%|| 2034/2048 [05:29<00:02,  6.23it/s, est. speed input: 6321.39 toks/s, output: 6.17 toks/s]
Processed prompts: 100%|| 2048/2048 [05:29<00:00,  6.23it/s, est. speed input: 6364.90 toks/s, output: 6.22 toks/s]
Processed prompts: 100%|| 2048/2048 [05:29<00:00,  6.22it/s, est. speed input: 6364.90 toks/s, output: 6.22 toks/s]
[rank0]:[W126 19:01:40.404375557 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-26 19:01:42
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Qwen2.5-7B-FP8_M32768.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 19:02:00 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 19:02:00 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1628796) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1628796) WARNING 01-26 19:03:23 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 6.20 requests/s, 6350.94 total tokens/s, 6.20 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-26 19:02:00] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 19:02:00] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 19:02:00] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 19:02:00] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:02:00] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:02:00] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:02:00] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:02:00] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:02:00] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 19:02:00] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 19:02:00] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 19:02:00] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 19:02:00] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 19:02:00] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 19:02:03] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 19:02:03] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 19:02:03] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 19:02:03] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:02:03] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:02:03] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:02:03] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:02:03] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:02:03] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 19:02:03] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 19:02:03] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 19:02:03] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 19:02:03] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 19:02:03] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1628796) [2026-01-26 19:02:04] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1628796) [2026-01-26 19:02:04] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1628796) [2026-01-26 19:02:04] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1628796) [2026-01-26 19:02:04] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1628796) [2026-01-26 19:02:04] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1628796) [2026-01-26 19:02:04] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1628796) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1628796) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:25<00:25, 25.14s/it]
(EngineCore_DP0 pid=1628796) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:59<00:00, 30.46s/it]
(EngineCore_DP0 pid=1628796) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:59<00:00, 29.66s/it]
(EngineCore_DP0 pid=1628796) 
(EngineCore_DP0 pid=1628796) [2026-01-26 19:03:05] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=1628796) [2026-01-26 19:03:05] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 13860864 bytes
(EngineCore_DP0 pid=1628796) [2026-01-26 19:03:05] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=1628796) [2026-01-26 19:03:05] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10780672 bytes
(EngineCore_DP0 pid=1628796) [2026-01-26 19:03:05] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=1628796) [2026-01-26 19:03:05] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 113967104 bytes
(EngineCore_DP0 pid=1628796) [2026-01-26 19:03:05] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=1628796) [2026-01-26 19:03:05] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 56655872 bytes
(EngineCore_DP0 pid=1628796) 2026-01-26 19:03:15,564 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1628796) 2026-01-26 19:03:16,506 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|          | 49/4096 [00:00<00:08, 489.81it/s]
Adding requests:   2%|         | 98/4096 [00:00<00:09, 404.83it/s]
Adding requests:   3%|         | 140/4096 [00:00<00:09, 406.19it/s]
Adding requests:   4%|         | 182/4096 [00:00<00:09, 404.04it/s]
Adding requests:   5%|         | 223/4096 [00:00<00:09, 404.10it/s]
Adding requests:   6%|         | 264/4096 [00:00<00:09, 402.30it/s]
Adding requests:   8%|         | 308/4096 [00:00<00:09, 413.30it/s]
Adding requests:   9%|         | 350/4096 [00:00<00:09, 413.27it/s]
Adding requests:  10%|         | 396/4096 [00:00<00:08, 427.36it/s]
Adding requests:  11%|         | 439/4096 [00:01<00:08, 413.17it/s]
Adding requests:  12%|        | 487/4096 [00:01<00:08, 432.37it/s]
Adding requests:  13%|        | 531/4096 [00:01<00:08, 431.42it/s]
Adding requests:  14%|        | 576/4096 [00:01<00:08, 434.50it/s]
Adding requests:  15%|        | 620/4096 [00:01<00:08, 419.88it/s]
Adding requests:  16%|        | 663/4096 [00:01<00:08, 420.48it/s]
Adding requests:  17%|        | 706/4096 [00:01<00:08, 422.29it/s]
Adding requests:  18%|        | 749/4096 [00:01<00:08, 409.92it/s]
Adding requests:  19%|        | 794/4096 [00:01<00:07, 421.34it/s]
Adding requests:  20%|        | 837/4096 [00:02<00:07, 408.11it/s]
Adding requests:  22%|       | 882/4096 [00:02<00:07, 419.09it/s]
Adding requests:  23%|       | 925/4096 [00:02<00:07, 413.30it/s]
Adding requests:  24%|       | 968/4096 [00:02<00:07, 415.61it/s]
Adding requests:  25%|       | 1010/4096 [00:02<00:07, 413.14it/s]
Adding requests:  26%|       | 1052/4096 [00:02<00:07, 403.25it/s]
Adding requests:  27%|       | 1096/4096 [00:02<00:07, 411.32it/s]
Adding requests:  28%|       | 1138/4096 [00:02<00:07, 405.50it/s]
Adding requests:  29%|       | 1180/4096 [00:02<00:07, 409.17it/s]
Adding requests:  30%|       | 1221/4096 [00:02<00:07, 383.30it/s]
Adding requests:  31%|       | 1261/4096 [00:03<00:07, 386.09it/s]
Adding requests:  32%|      | 1305/4096 [00:03<00:06, 400.54it/s]
Adding requests:  33%|      | 1346/4096 [00:03<00:06, 400.13it/s]
Adding requests:  34%|      | 1392/4096 [00:03<00:06, 414.60it/s]
Adding requests:  35%|      | 1434/4096 [00:03<00:06, 398.56it/s]
Adding requests:  36%|      | 1478/4096 [00:03<00:06, 406.77it/s]
Adding requests:  37%|      | 1519/4096 [00:03<00:06, 404.74it/s]
Adding requests:  38%|      | 1560/4096 [00:03<00:06, 405.47it/s]
Adding requests:  39%|      | 1601/4096 [00:03<00:06, 404.43it/s]
Adding requests:  40%|      | 1642/4096 [00:04<00:06, 399.33it/s]
Adding requests:  41%|      | 1687/4096 [00:04<00:05, 412.62it/s]
Adding requests:  42%|     | 1729/4096 [00:04<00:05, 404.20it/s]
Adding requests:  43%|     | 1776/4096 [00:04<00:05, 421.16it/s]
Adding requests:  44%|     | 1819/4096 [00:04<00:05, 403.61it/s]
Adding requests:  45%|     | 1861/4096 [00:04<00:05, 406.09it/s]
Adding requests:  46%|     | 1903/4096 [00:04<00:05, 409.74it/s]
Adding requests:  47%|     | 1945/4096 [00:04<00:05, 412.57it/s]
Adding requests:  49%|     | 1989/4096 [00:04<00:05, 419.28it/s]
Adding requests:  50%|     | 2032/4096 [00:04<00:05, 397.29it/s]
Adding requests:  51%|     | 2075/4096 [00:05<00:04, 404.32it/s]
Adding requests:  52%|    | 2116/4096 [00:05<00:04, 400.13it/s]
Adding requests:  53%|    | 2158/4096 [00:05<00:04, 402.73it/s]
Adding requests:  54%|    | 2199/4096 [00:05<00:04, 402.95it/s]
Adding requests:  55%|    | 2240/4096 [00:05<00:04, 404.48it/s]
Adding requests:  56%|    | 2283/4096 [00:05<00:04, 410.66it/s]
Adding requests:  57%|    | 2325/4096 [00:05<00:04, 405.54it/s]
Adding requests:  58%|    | 2370/4096 [00:05<00:04, 418.26it/s]
Adding requests:  59%|    | 2412/4096 [00:05<00:04, 412.26it/s]
Adding requests:  60%|    | 2454/4096 [00:05<00:04, 395.39it/s]
Adding requests:  61%|    | 2495/4096 [00:06<00:04, 396.79it/s]
Adding requests:  62%|   | 2541/4096 [00:06<00:03, 414.70it/s]
Adding requests:  63%|   | 2585/4096 [00:06<00:03, 420.46it/s]
Adding requests:  64%|   | 2628/4096 [00:06<00:03, 418.52it/s]
Adding requests:  65%|   | 2671/4096 [00:06<00:03, 421.45it/s]
Adding requests:  66%|   | 2714/4096 [00:06<00:03, 414.40it/s]
Adding requests:  67%|   | 2763/4096 [00:06<00:03, 435.83it/s]
Adding requests:  69%|   | 2807/4096 [00:06<00:03, 420.95it/s]
Adding requests:  70%|   | 2851/4096 [00:06<00:02, 425.37it/s]
Adding requests:  71%|   | 2894/4096 [00:07<00:02, 410.44it/s]
Adding requests:  72%|  | 2936/4096 [00:07<00:02, 412.53it/s]
Adding requests:  73%|  | 2978/4096 [00:07<00:02, 412.39it/s]
Adding requests:  74%|  | 3020/4096 [00:07<00:02, 408.69it/s]
Adding requests:  75%|  | 3067/4096 [00:07<00:02, 425.93it/s]
Adding requests:  76%|  | 3110/4096 [00:07<00:02, 419.17it/s]
Adding requests:  77%|  | 3156/4096 [00:07<00:02, 427.88it/s]
Adding requests:  78%|  | 3199/4096 [00:07<00:02, 420.30it/s]
Adding requests:  79%|  | 3244/4096 [00:07<00:01, 426.20it/s]
Adding requests:  80%|  | 3287/4096 [00:07<00:01, 417.31it/s]
Adding requests:  81%| | 3329/4096 [00:08<00:01, 413.73it/s]
Adding requests:  82%| | 3376/4096 [00:08<00:01, 428.60it/s]
Adding requests:  83%| | 3419/4096 [00:08<00:01, 424.16it/s]
Adding requests:  85%| | 3469/4096 [00:08<00:01, 443.03it/s]
Adding requests:  86%| | 3514/4096 [00:08<00:01, 425.90it/s]
Adding requests:  87%| | 3563/4096 [00:08<00:01, 443.86it/s]
Adding requests:  88%| | 3608/4096 [00:08<00:01, 435.35it/s]
Adding requests:  89%| | 3654/4096 [00:08<00:01, 440.42it/s]
Adding requests:  90%| | 3699/4096 [00:08<00:00, 438.08it/s]
Adding requests:  91%|| 3743/4096 [00:09<00:00, 434.29it/s]
Adding requests:  92%|| 3788/4096 [00:09<00:00, 437.02it/s]
Adding requests:  94%|| 3832/4096 [00:09<00:00, 383.81it/s]
Adding requests:  95%|| 3873/4096 [00:09<00:00, 388.41it/s]
Adding requests:  96%|| 3917/4096 [00:09<00:00, 401.26it/s]
Adding requests:  97%|| 3959/4096 [00:09<00:00, 405.63it/s]
Adding requests:  98%|| 4005/4096 [00:09<00:00, 420.78it/s]
Adding requests:  99%|| 4048/4096 [00:09<00:00, 411.98it/s]
Adding requests: 100%|| 4093/4096 [00:09<00:00, 422.69it/s]
Adding requests: 100%|| 4096/4096 [00:09<00:00, 414.03it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 34/4096 [00:00<01:37, 41.71it/s, est. speed input: 42715.57 toks/s, output: 41.71 toks/s]
Processed prompts:   2%|         | 66/4096 [00:05<06:53,  9.74it/s, est. speed input: 11312.48 toks/s, output: 11.05 toks/s]
Processed prompts:   2%|         | 98/4096 [00:11<08:36,  7.74it/s, est. speed input: 9003.98 toks/s, output: 8.79 toks/s]  
Processed prompts:   3%|         | 130/4096 [00:16<09:22,  7.04it/s, est. speed input: 8156.05 toks/s, output: 7.96 toks/s]
Processed prompts:   4%|         | 162/4096 [00:22<10:15,  6.39it/s, est. speed input: 7484.83 toks/s, output: 7.31 toks/s]
Processed prompts:   5%|         | 194/4096 [00:27<10:12,  6.37it/s, est. speed input: 7300.20 toks/s, output: 7.13 toks/s]
Processed prompts:   6%|         | 226/4096 [00:32<10:13,  6.30it/s, est. speed input: 7142.97 toks/s, output: 6.98 toks/s]
Processed prompts:   6%|         | 258/4096 [00:37<10:13,  6.26it/s, est. speed input: 7027.65 toks/s, output: 6.86 toks/s]
Processed prompts:   7%|         | 290/4096 [00:42<10:05,  6.29it/s, est. speed input: 6965.93 toks/s, output: 6.80 toks/s]
Processed prompts:   8%|         | 322/4096 [00:47<10:03,  6.25it/s, est. speed input: 6895.60 toks/s, output: 6.73 toks/s]
Processed prompts:   9%|         | 354/4096 [00:53<10:05,  6.18it/s, est. speed input: 6823.16 toks/s, output: 6.66 toks/s]
Processed prompts:   9%|         | 386/4096 [00:58<10:00,  6.17it/s, est. speed input: 6777.29 toks/s, output: 6.62 toks/s]
Processed prompts:  10%|         | 418/4096 [01:03<09:50,  6.23it/s, est. speed input: 6755.57 toks/s, output: 6.60 toks/s]
Processed prompts:  11%|         | 450/4096 [01:08<09:47,  6.21it/s, est. speed input: 6721.33 toks/s, output: 6.56 toks/s]
Processed prompts:  12%|        | 482/4096 [01:13<09:43,  6.19it/s, est. speed input: 6691.90 toks/s, output: 6.54 toks/s]
Processed prompts:  13%|        | 514/4096 [01:18<09:39,  6.18it/s, est. speed input: 6667.05 toks/s, output: 6.51 toks/s]
Processed prompts:  13%|        | 546/4096 [01:24<09:35,  6.17it/s, est. speed input: 6642.52 toks/s, output: 6.49 toks/s]
Processed prompts:  14%|        | 578/4096 [01:29<09:30,  6.16it/s, est. speed input: 6622.64 toks/s, output: 6.47 toks/s]
Processed prompts:  15%|        | 610/4096 [01:34<09:25,  6.16it/s, est. speed input: 6605.16 toks/s, output: 6.45 toks/s]
Processed prompts:  16%|        | 642/4096 [01:39<09:20,  6.16it/s, est. speed input: 6590.10 toks/s, output: 6.44 toks/s]
Processed prompts:  16%|        | 674/4096 [01:44<09:15,  6.16it/s, est. speed input: 6576.01 toks/s, output: 6.42 toks/s]
Processed prompts:  17%|        | 706/4096 [01:50<09:10,  6.16it/s, est. speed input: 6563.41 toks/s, output: 6.41 toks/s]
Processed prompts:  18%|        | 738/4096 [01:55<09:05,  6.16it/s, est. speed input: 6551.25 toks/s, output: 6.40 toks/s]
Processed prompts:  19%|        | 770/4096 [02:00<08:56,  6.21it/s, est. speed input: 6547.97 toks/s, output: 6.39 toks/s]
Processed prompts:  20%|        | 802/4096 [02:05<08:52,  6.19it/s, est. speed input: 6537.43 toks/s, output: 6.38 toks/s]
Processed prompts:  20%|        | 834/4096 [02:10<08:47,  6.18it/s, est. speed input: 6528.60 toks/s, output: 6.38 toks/s]
Processed prompts:  21%|        | 866/4096 [02:16<08:43,  6.18it/s, est. speed input: 6520.31 toks/s, output: 6.37 toks/s]
Processed prompts:  22%|       | 898/4096 [02:21<08:38,  6.17it/s, est. speed input: 6512.49 toks/s, output: 6.36 toks/s]
Processed prompts:  23%|       | 930/4096 [02:26<08:33,  6.17it/s, est. speed input: 6505.22 toks/s, output: 6.35 toks/s]
Processed prompts:  23%|       | 962/4096 [02:31<08:28,  6.16it/s, est. speed input: 6497.99 toks/s, output: 6.35 toks/s]
Processed prompts:  24%|       | 994/4096 [02:36<08:23,  6.16it/s, est. speed input: 6491.57 toks/s, output: 6.34 toks/s]
Processed prompts:  25%|       | 1026/4096 [02:41<08:18,  6.16it/s, est. speed input: 6485.75 toks/s, output: 6.33 toks/s]
Processed prompts:  26%|       | 1058/4096 [02:47<08:13,  6.16it/s, est. speed input: 6480.08 toks/s, output: 6.33 toks/s]
Processed prompts:  27%|       | 1090/4096 [02:52<08:08,  6.16it/s, est. speed input: 6474.65 toks/s, output: 6.32 toks/s]
Processed prompts:  27%|       | 1122/4096 [02:57<08:02,  6.16it/s, est. speed input: 6469.75 toks/s, output: 6.32 toks/s]
Processed prompts:  28%|       | 1154/4096 [03:02<07:57,  6.15it/s, est. speed input: 6464.80 toks/s, output: 6.31 toks/s]
Processed prompts:  29%|       | 1186/4096 [03:07<07:48,  6.21it/s, est. speed input: 6465.85 toks/s, output: 6.31 toks/s]
Processed prompts:  30%|       | 1218/4096 [03:12<07:40,  6.25it/s, est. speed input: 6466.96 toks/s, output: 6.32 toks/s]
Processed prompts:  31%|       | 1250/4096 [03:18<07:37,  6.22it/s, est. speed input: 6462.57 toks/s, output: 6.31 toks/s]
Processed prompts:  31%|      | 1282/4096 [03:23<07:33,  6.20it/s, est. speed input: 6458.42 toks/s, output: 6.31 toks/s]
Processed prompts:  32%|      | 1314/4096 [03:28<07:25,  6.25it/s, est. speed input: 6459.67 toks/s, output: 6.31 toks/s]
Processed prompts:  33%|      | 1346/4096 [03:33<07:22,  6.21it/s, est. speed input: 6455.21 toks/s, output: 6.30 toks/s]
Processed prompts:  34%|      | 1378/4096 [03:38<07:18,  6.19it/s, est. speed input: 6451.57 toks/s, output: 6.30 toks/s]
Processed prompts:  34%|      | 1410/4096 [03:43<07:14,  6.18it/s, est. speed input: 6448.24 toks/s, output: 6.30 toks/s]
Processed prompts:  35%|      | 1442/4096 [03:48<07:03,  6.26it/s, est. speed input: 6451.81 toks/s, output: 6.30 toks/s]
Processed prompts:  36%|      | 1474/4096 [03:54<07:00,  6.23it/s, est. speed input: 6448.43 toks/s, output: 6.30 toks/s]
Processed prompts:  37%|      | 1506/4096 [03:59<06:53,  6.26it/s, est. speed input: 6449.50 toks/s, output: 6.30 toks/s]
Processed prompts:  38%|      | 1538/4096 [04:04<06:46,  6.29it/s, est. speed input: 6450.40 toks/s, output: 6.30 toks/s]
Processed prompts:  38%|      | 1570/4096 [04:09<06:44,  6.24it/s, est. speed input: 6446.71 toks/s, output: 6.30 toks/s]
Processed prompts:  39%|      | 1602/4096 [04:14<06:37,  6.27it/s, est. speed input: 6447.74 toks/s, output: 6.30 toks/s]
Processed prompts:  40%|      | 1634/4096 [04:19<06:34,  6.23it/s, est. speed input: 6444.68 toks/s, output: 6.29 toks/s]
Processed prompts:  41%|      | 1666/4096 [04:24<06:31,  6.21it/s, est. speed input: 6441.67 toks/s, output: 6.29 toks/s]
Processed prompts:  41%|     | 1698/4096 [04:30<06:27,  6.19it/s, est. speed input: 6438.84 toks/s, output: 6.29 toks/s]
Processed prompts:  42%|     | 1730/4096 [04:34<06:12,  6.35it/s, est. speed input: 6447.47 toks/s, output: 6.30 toks/s]
Processed prompts:  43%|     | 1762/4096 [04:39<06:11,  6.29it/s, est. speed input: 6444.49 toks/s, output: 6.29 toks/s]
Processed prompts:  44%|     | 1794/4096 [04:45<06:08,  6.25it/s, est. speed input: 6441.78 toks/s, output: 6.29 toks/s]
Processed prompts:  45%|     | 1826/4096 [04:50<06:05,  6.22it/s, est. speed input: 6439.24 toks/s, output: 6.29 toks/s]
Processed prompts:  45%|     | 1858/4096 [04:55<06:01,  6.19it/s, est. speed input: 6436.62 toks/s, output: 6.29 toks/s]
Processed prompts:  46%|     | 1890/4096 [05:00<05:53,  6.24it/s, est. speed input: 6437.43 toks/s, output: 6.29 toks/s]
Processed prompts:  47%|     | 1922/4096 [05:05<05:50,  6.21it/s, est. speed input: 6434.86 toks/s, output: 6.28 toks/s]
Processed prompts:  48%|     | 1954/4096 [05:11<05:46,  6.18it/s, est. speed input: 6432.18 toks/s, output: 6.28 toks/s]
Processed prompts:  48%|     | 1986/4096 [05:16<05:38,  6.23it/s, est. speed input: 6433.18 toks/s, output: 6.28 toks/s]
Processed prompts:  49%|     | 2018/4096 [05:21<05:34,  6.20it/s, est. speed input: 6430.86 toks/s, output: 6.28 toks/s]
Processed prompts:  50%|     | 2050/4096 [05:26<05:25,  6.28it/s, est. speed input: 6433.58 toks/s, output: 6.28 toks/s]
Processed prompts:  51%|     | 2082/4096 [05:31<05:22,  6.24it/s, est. speed input: 6431.34 toks/s, output: 6.28 toks/s]
Processed prompts:  52%|    | 2114/4096 [05:36<05:19,  6.21it/s, est. speed input: 6429.25 toks/s, output: 6.28 toks/s]
Processed prompts:  52%|    | 2146/4096 [05:41<05:15,  6.19it/s, est. speed input: 6427.04 toks/s, output: 6.28 toks/s]
Processed prompts:  53%|    | 2178/4096 [05:46<05:07,  6.23it/s, est. speed input: 6427.85 toks/s, output: 6.28 toks/s]
Processed prompts:  54%|    | 2210/4096 [05:52<05:03,  6.21it/s, est. speed input: 6425.91 toks/s, output: 6.28 toks/s]
Processed prompts:  55%|    | 2242/4096 [05:57<04:59,  6.19it/s, est. speed input: 6423.90 toks/s, output: 6.27 toks/s]
Processed prompts:  56%|    | 2274/4096 [06:02<04:55,  6.17it/s, est. speed input: 6421.95 toks/s, output: 6.27 toks/s]
Processed prompts:  56%|    | 2306/4096 [06:07<04:50,  6.16it/s, est. speed input: 6420.06 toks/s, output: 6.27 toks/s]
Processed prompts:  57%|    | 2338/4096 [06:12<04:42,  6.22it/s, est. speed input: 6421.07 toks/s, output: 6.27 toks/s]
Processed prompts:  58%|    | 2370/4096 [06:18<04:38,  6.19it/s, est. speed input: 6419.24 toks/s, output: 6.27 toks/s]
Processed prompts:  59%|    | 2402/4096 [06:23<04:34,  6.18it/s, est. speed input: 6417.49 toks/s, output: 6.27 toks/s]
Processed prompts:  59%|    | 2434/4096 [06:28<04:29,  6.17it/s, est. speed input: 6415.69 toks/s, output: 6.27 toks/s]
Processed prompts:  60%|    | 2466/4096 [06:33<04:24,  6.16it/s, est. speed input: 6414.15 toks/s, output: 6.26 toks/s]
Processed prompts:  61%|    | 2498/4096 [06:38<04:19,  6.15it/s, est. speed input: 6412.47 toks/s, output: 6.26 toks/s]
Processed prompts:  62%|   | 2530/4096 [06:43<04:12,  6.21it/s, est. speed input: 6413.41 toks/s, output: 6.26 toks/s]
Processed prompts:  63%|   | 2562/4096 [06:49<04:08,  6.19it/s, est. speed input: 6411.72 toks/s, output: 6.26 toks/s]
Processed prompts:  63%|   | 2594/4096 [06:54<04:01,  6.23it/s, est. speed input: 6412.60 toks/s, output: 6.26 toks/s]
Processed prompts:  64%|   | 2626/4096 [06:59<03:57,  6.20it/s, est. speed input: 6411.05 toks/s, output: 6.26 toks/s]
Processed prompts:  65%|   | 2658/4096 [07:04<03:50,  6.24it/s, est. speed input: 6411.88 toks/s, output: 6.26 toks/s]
Processed prompts:  66%|   | 2690/4096 [07:09<03:46,  6.21it/s, est. speed input: 6410.41 toks/s, output: 6.26 toks/s]
Processed prompts:  66%|   | 2722/4096 [07:14<03:39,  6.25it/s, est. speed input: 6411.30 toks/s, output: 6.26 toks/s]
Processed prompts:  67%|   | 2754/4096 [07:19<03:35,  6.22it/s, est. speed input: 6409.85 toks/s, output: 6.26 toks/s]
Processed prompts:  68%|   | 2786/4096 [07:25<03:31,  6.19it/s, est. speed input: 6408.41 toks/s, output: 6.26 toks/s]
Processed prompts:  69%|   | 2818/4096 [07:30<03:26,  6.18it/s, est. speed input: 6407.07 toks/s, output: 6.26 toks/s]
Processed prompts:  70%|   | 2850/4096 [07:35<03:22,  6.17it/s, est. speed input: 6405.75 toks/s, output: 6.26 toks/s]
Processed prompts:  70%|   | 2882/4096 [07:40<03:11,  6.34it/s, est. speed input: 6411.27 toks/s, output: 6.26 toks/s]
Processed prompts:  71%|   | 2914/4096 [07:45<03:06,  6.34it/s, est. speed input: 6412.17 toks/s, output: 6.26 toks/s]
Processed prompts:  72%|  | 2946/4096 [07:50<03:03,  6.28it/s, est. speed input: 6410.66 toks/s, output: 6.26 toks/s]
Processed prompts:  73%|  | 2978/4096 [07:55<02:57,  6.29it/s, est. speed input: 6411.46 toks/s, output: 6.26 toks/s]
Processed prompts:  73%|  | 3010/4096 [08:00<02:53,  6.25it/s, est. speed input: 6410.19 toks/s, output: 6.26 toks/s]
Processed prompts:  74%|  | 3042/4096 [08:06<02:49,  6.21it/s, est. speed input: 6408.85 toks/s, output: 6.26 toks/s]
Processed prompts:  75%|  | 3074/4096 [08:11<02:45,  6.19it/s, est. speed input: 6407.54 toks/s, output: 6.26 toks/s]
Processed prompts:  76%|  | 3106/4096 [08:16<02:40,  6.18it/s, est. speed input: 6406.33 toks/s, output: 6.26 toks/s]
Processed prompts:  77%|  | 3138/4096 [08:21<02:35,  6.16it/s, est. speed input: 6405.03 toks/s, output: 6.25 toks/s]
Processed prompts:  77%|  | 3170/4096 [08:26<02:29,  6.21it/s, est. speed input: 6405.66 toks/s, output: 6.26 toks/s]
Processed prompts:  78%|  | 3202/4096 [08:31<02:24,  6.19it/s, est. speed input: 6404.42 toks/s, output: 6.25 toks/s]
Processed prompts:  79%|  | 3234/4096 [08:37<02:19,  6.17it/s, est. speed input: 6403.28 toks/s, output: 6.25 toks/s]
Processed prompts:  80%|  | 3266/4096 [08:42<02:14,  6.16it/s, est. speed input: 6402.11 toks/s, output: 6.25 toks/s]
Processed prompts:  81%|  | 3298/4096 [08:47<02:09,  6.15it/s, est. speed input: 6400.91 toks/s, output: 6.25 toks/s]
Processed prompts:  81%| | 3330/4096 [08:52<02:04,  6.15it/s, est. speed input: 6399.79 toks/s, output: 6.25 toks/s]
Processed prompts:  82%| | 3362/4096 [08:58<01:59,  6.14it/s, est. speed input: 6398.61 toks/s, output: 6.25 toks/s]
Processed prompts:  83%| | 3394/4096 [09:03<01:53,  6.20it/s, est. speed input: 6399.38 toks/s, output: 6.25 toks/s]
Processed prompts:  84%| | 3426/4096 [09:08<01:48,  6.18it/s, est. speed input: 6398.33 toks/s, output: 6.25 toks/s]
Processed prompts:  84%| | 3458/4096 [09:13<01:43,  6.17it/s, est. speed input: 6397.21 toks/s, output: 6.25 toks/s]
Processed prompts:  85%| | 3490/4096 [09:18<01:38,  6.16it/s, est. speed input: 6396.16 toks/s, output: 6.25 toks/s]
Processed prompts:  86%| | 3522/4096 [09:23<01:33,  6.15it/s, est. speed input: 6395.21 toks/s, output: 6.25 toks/s]
Processed prompts:  87%| | 3554/4096 [09:29<01:27,  6.20it/s, est. speed input: 6395.83 toks/s, output: 6.25 toks/s]
Processed prompts:  88%| | 3586/4096 [09:34<01:22,  6.18it/s, est. speed input: 6394.91 toks/s, output: 6.25 toks/s]
Processed prompts:  88%| | 3618/4096 [09:39<01:16,  6.23it/s, est. speed input: 6395.70 toks/s, output: 6.25 toks/s]
Processed prompts:  89%| | 3650/4096 [09:44<01:11,  6.20it/s, est. speed input: 6394.79 toks/s, output: 6.24 toks/s]
Processed prompts:  90%| | 3682/4096 [09:49<01:05,  6.27it/s, est. speed input: 6396.49 toks/s, output: 6.25 toks/s]
Processed prompts:  91%| | 3714/4096 [09:54<01:01,  6.23it/s, est. speed input: 6395.53 toks/s, output: 6.25 toks/s]
Processed prompts:  91%|| 3746/4096 [09:59<00:56,  6.20it/s, est. speed input: 6394.36 toks/s, output: 6.24 toks/s]
Processed prompts:  92%|| 3778/4096 [10:05<00:51,  6.18it/s, est. speed input: 6393.43 toks/s, output: 6.24 toks/s]
Processed prompts:  93%|| 3810/4096 [10:10<00:46,  6.17it/s, est. speed input: 6392.48 toks/s, output: 6.24 toks/s]
Processed prompts:  94%|| 3842/4096 [10:15<00:41,  6.16it/s, est. speed input: 6391.59 toks/s, output: 6.24 toks/s]
Processed prompts:  95%|| 3874/4096 [10:20<00:36,  6.15it/s, est. speed input: 6390.63 toks/s, output: 6.24 toks/s]
Processed prompts:  95%|| 3906/4096 [10:25<00:30,  6.21it/s, est. speed input: 6391.45 toks/s, output: 6.24 toks/s]
Processed prompts:  96%|| 3938/4096 [10:30<00:25,  6.24it/s, est. speed input: 6392.16 toks/s, output: 6.24 toks/s]
Processed prompts:  97%|| 3970/4096 [10:36<00:20,  6.20it/s, est. speed input: 6391.09 toks/s, output: 6.24 toks/s]
Processed prompts:  98%|| 4002/4096 [10:41<00:15,  6.24it/s, est. speed input: 6391.68 toks/s, output: 6.24 toks/s]
Processed prompts:  98%|| 4034/4096 [10:46<00:09,  6.26it/s, est. speed input: 6392.40 toks/s, output: 6.24 toks/s]
Processed prompts:  99%|| 4066/4096 [10:51<00:04,  6.32it/s, est. speed input: 6393.99 toks/s, output: 6.24 toks/s]
Processed prompts: 100%|| 4096/4096 [10:51<00:00,  6.32it/s, est. speed input: 6441.16 toks/s, output: 6.29 toks/s]
Processed prompts: 100%|| 4096/4096 [10:51<00:00,  6.29it/s, est. speed input: 6441.16 toks/s, output: 6.29 toks/s]
[rank0]:[W126 19:14:25.462708659 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-26 19:14:27
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Qwen2.5-7B-FP8_M65536.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 19:15:02 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 19:15:02 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1639717) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 303, in forward
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]     hidden_states = self.mlp(hidden_states)
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 108, in forward
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]     x, _ = self.down_proj(x)
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]            ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 1405, in forward
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]     output_parallel = self.quant_method.apply(self, input_parallel, bias_)
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 243, in quant_slide_fp8_triton
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]     out = torch.zeros(M_padded, K_out_padded, dtype=torch.float8_e4m3fn, device=x.device)
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866]           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866] torch.AcceleratorError: CUDA error: an illegal memory access was encountered
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866] Search for `cudaErrorIllegalAddress' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866] CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866] For debugging consider passing CUDA_LAUNCH_BLOCKING=1
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866] Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
(EngineCore_DP0 pid=1639717) ERROR 01-26 19:16:09 [core.py:866] 

STDERR:
[2026-01-26 19:15:02] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 19:15:02] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 19:15:02] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 19:15:02] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:15:02] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:15:02] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:15:02] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:15:02] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:15:02] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 19:15:02] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 19:15:02] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 19:15:02] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 19:15:02] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 19:15:02] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 19:15:05] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 19:15:05] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 19:15:05] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 19:15:05] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:15:05] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:15:05] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:15:05] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:15:05] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:15:05] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 19:15:05] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 19:15:05] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 19:15:05] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 19:15:05] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 19:15:05] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1639717) [2026-01-26 19:15:07] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1639717) [2026-01-26 19:15:07] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1639717) [2026-01-26 19:15:07] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1639717) [2026-01-26 19:15:07] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=1639717) [2026-01-26 19:15:07] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1639717) [2026-01-26 19:15:07] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1639717) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1639717) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:24<00:24, 24.54s/it]
(EngineCore_DP0 pid=1639717) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:59<00:00, 30.66s/it]
(EngineCore_DP0 pid=1639717) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:59<00:00, 29.74s/it]
(EngineCore_DP0 pid=1639717) 
(EngineCore_DP0 pid=1639717) [2026-01-26 19:16:07] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=1639717) [2026-01-26 19:16:07] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 13860864 bytes
(EngineCore_DP0 pid=1639717) [2026-01-26 19:16:07] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=1639717) [2026-01-26 19:16:07] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 10780672 bytes
(EngineCore_DP0 pid=1639717) [2026-01-26 19:16:07] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=1639717) [2026-01-26 19:16:07] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 113967104 bytes
(EngineCore_DP0 pid=1639717) [2026-01-26 19:16:07] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=1639717) [2026-01-26 19:16:07] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 56655872 bytes
(EngineCore_DP0 pid=1639717) Process EngineCore_DP0:
(EngineCore_DP0 pid=1639717) Traceback (most recent call last):
(EngineCore_DP0 pid=1639717)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=1639717)     self.run()
(EngineCore_DP0 pid=1639717)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=1639717)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=1639717)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=1639717)     raise e
(EngineCore_DP0 pid=1639717)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1639717)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1639717)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1639717)     super().__init__(
(EngineCore_DP0 pid=1639717)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=1639717)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=1639717)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=1639717)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=1639717)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=1639717)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=1639717)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=1639717)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=1639717)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=1639717)     return func(*args, **kwargs)
(EngineCore_DP0 pid=1639717)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=1639717)     return func(*args, **kwargs)
(EngineCore_DP0 pid=1639717)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=1639717)     self.model_runner.profile_run()
(EngineCore_DP0 pid=1639717)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=1639717)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=1639717)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=1639717)     return func(*args, **kwargs)
(EngineCore_DP0 pid=1639717)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=1639717)     outputs = self.model(
(EngineCore_DP0 pid=1639717)               ^^^^^^^^^^^
(EngineCore_DP0 pid=1639717)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1639717)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1639717)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1639717)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1639717)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=1639717)     hidden_states = self.model(
(EngineCore_DP0 pid=1639717)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=1639717)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=1639717)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=1639717)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=1639717)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=1639717)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1639717)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1639717)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1639717)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1639717)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 303, in forward
(EngineCore_DP0 pid=1639717)     hidden_states = self.mlp(hidden_states)
(EngineCore_DP0 pid=1639717)                     ^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1639717)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1639717)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1639717)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1639717)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 108, in forward
(EngineCore_DP0 pid=1639717)     x, _ = self.down_proj(x)
(EngineCore_DP0 pid=1639717)            ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1639717)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1639717)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1639717)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1639717)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 1405, in forward
(EngineCore_DP0 pid=1639717)     output_parallel = self.quant_method.apply(self, input_parallel, bias_)
(EngineCore_DP0 pid=1639717)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=1639717)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=1639717)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=1639717)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=1639717)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=1639717)     return self._linear_fn(
(EngineCore_DP0 pid=1639717)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=1639717)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=1639717)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=1639717)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=1639717)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=1639717)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=1639717)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=1639717)     return fn(input, L)
(EngineCore_DP0 pid=1639717)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 243, in quant_slide_fp8_triton
(EngineCore_DP0 pid=1639717)     out = torch.zeros(M_padded, K_out_padded, dtype=torch.float8_e4m3fn, device=x.device)
(EngineCore_DP0 pid=1639717)           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1639717) torch.AcceleratorError: CUDA error: an illegal memory access was encountered
(EngineCore_DP0 pid=1639717) Search for `cudaErrorIllegalAddress' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
(EngineCore_DP0 pid=1639717) CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
(EngineCore_DP0 pid=1639717) For debugging consider passing CUDA_LAUNCH_BLOCKING=1
(EngineCore_DP0 pid=1639717) Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
(EngineCore_DP0 pid=1639717) 
[rank0]:[W126 19:16:09.095472418 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=65536

========== M=512 ==========
Time: 2026-01-27 09:50:30
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Qwen2.5-14B-FP8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-27 09:50:37 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-27 09:50:37 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=2450483) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2450483) WARNING 01-27 09:52:49 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 6.60 requests/s, 3385.67 total tokens/s, 6.60 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-27 09:50:36] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 09:50:37] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 09:50:37] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 09:50:37] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 09:50:37] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 09:50:37] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 09:50:37] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 09:50:37] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 09:50:37] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 09:50:37] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 09:50:37] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 09:50:37] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 09:50:37] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 09:50:37] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-27 09:50:40] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 09:50:40] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 09:50:40] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 09:50:40] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 09:50:40] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 09:50:40] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 09:50:40] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 09:50:40] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 09:50:40] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 09:50:40] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 09:50:40] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 09:50:40] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 09:50:40] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 09:50:40] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=2450483) [2026-01-27 09:50:41] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=2450483) [2026-01-27 09:50:41] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2450483) [2026-01-27 09:50:41] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=2450483) [2026-01-27 09:50:41] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=2450483) [2026-01-27 09:50:41] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=2450483) [2026-01-27 09:50:41] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=2450483) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=2450483) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:25,  8.57s/it]
(EngineCore_DP0 pid=2450483) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:42<00:46, 23.47s/it]
(EngineCore_DP0 pid=2450483) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [01:14<00:27, 27.32s/it]
(EngineCore_DP0 pid=2450483) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:47<00:00, 29.73s/it]
(EngineCore_DP0 pid=2450483) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:47<00:00, 26.95s/it]
(EngineCore_DP0 pid=2450483) 
(EngineCore_DP0 pid=2450483) [2026-01-27 09:52:31] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 6848] -> 1D uint8
(EngineCore_DP0 pid=2450483) [2026-01-27 09:52:31] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 30736384 bytes
(EngineCore_DP0 pid=2450483) [2026-01-27 09:52:31] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 6848] -> 1D uint8
(EngineCore_DP0 pid=2450483) [2026-01-27 09:52:31] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 21954560 bytes
(EngineCore_DP0 pid=2450483) [2026-01-27 09:52:31] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 6848] -> 1D uint8
(EngineCore_DP0 pid=2450483) [2026-01-27 09:52:31] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 118554624 bytes
(EngineCore_DP0 pid=2450483) [2026-01-27 09:52:31] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 18432] -> 1D uint8
(EngineCore_DP0 pid=2450483) [2026-01-27 09:52:31] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 58982400 bytes
(EngineCore_DP0 pid=2450483) 2026-01-27 09:52:40,786 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=2450483) 2026-01-27 09:52:41,127 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:   1%|          | 1/128 [00:00<01:42,  1.24it/s]
Adding requests:   2%|         | 2/128 [00:01<01:02,  2.01it/s]
Adding requests:   2%|         | 3/128 [00:01<00:42,  2.93it/s]
Adding requests:   3%|         | 4/128 [00:01<00:30,  4.02it/s]
Adding requests:   5%|         | 6/128 [00:01<00:19,  6.32it/s]
Adding requests:   6%|         | 8/128 [00:01<00:13,  8.76it/s]
Adding requests:   9%|         | 11/128 [00:01<00:09, 12.76it/s]
Adding requests:  11%|         | 14/128 [00:01<00:07, 15.29it/s]
Adding requests:  15%|        | 19/128 [00:02<00:05, 21.71it/s]
Adding requests:  20%|        | 25/128 [00:02<00:03, 29.07it/s]
Adding requests:  24%|       | 31/128 [00:02<00:02, 36.33it/s]
Adding requests:  32%|      | 41/128 [00:02<00:01, 52.37it/s]
Adding requests:  56%|    | 72/128 [00:02<00:00, 120.64it/s]
Adding requests:  95%|| 121/128 [00:02<00:00, 221.14it/s]
Adding requests: 100%|| 128/128 [00:02<00:00, 50.14it/s] 

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   9%|         | 12/128 [00:00<00:01, 58.23it/s, est. speed input: 29819.12 toks/s, output: 58.24 toks/s]
Processed prompts:  14%|        | 18/128 [00:01<00:07, 14.42it/s, est. speed input: 8692.13 toks/s, output: 16.98 toks/s] 
Processed prompts:  16%|        | 21/128 [00:01<00:09, 11.57it/s, est. speed input: 7206.12 toks/s, output: 14.07 toks/s]
Processed prompts:  18%|        | 23/128 [00:01<00:10, 10.40it/s, est. speed input: 6641.86 toks/s, output: 12.97 toks/s]
Processed prompts:  20%|        | 25/128 [00:02<00:10,  9.50it/s, est. speed input: 6230.42 toks/s, output: 12.17 toks/s]
Processed prompts:  21%|        | 27/128 [00:02<00:11,  8.85it/s, est. speed input: 5923.89 toks/s, output: 11.57 toks/s]
Processed prompts:  23%|       | 29/128 [00:02<00:12,  8.23it/s, est. speed input: 5646.14 toks/s, output: 11.03 toks/s]
Processed prompts:  23%|       | 30/128 [00:02<00:12,  8.08it/s, est. speed input: 5551.78 toks/s, output: 10.84 toks/s]
Processed prompts:  24%|       | 31/128 [00:02<00:12,  7.90it/s, est. speed input: 5460.59 toks/s, output: 10.67 toks/s]
Processed prompts:  25%|       | 32/128 [00:03<00:12,  7.69it/s, est. speed input: 5371.37 toks/s, output: 10.49 toks/s]
Processed prompts:  26%|       | 33/128 [00:03<00:12,  7.53it/s, est. speed input: 5292.17 toks/s, output: 10.34 toks/s]
Processed prompts:  27%|       | 34/128 [00:03<00:12,  7.45it/s, est. speed input: 5225.47 toks/s, output: 10.21 toks/s]
Processed prompts:  27%|       | 35/128 [00:03<00:12,  7.36it/s, est. speed input: 5161.54 toks/s, output: 10.08 toks/s]
Processed prompts:  28%|       | 36/128 [00:03<00:12,  7.16it/s, est. speed input: 5088.76 toks/s, output: 9.94 toks/s] 
Processed prompts:  29%|       | 37/128 [00:03<00:12,  7.12it/s, est. speed input: 5031.74 toks/s, output: 9.83 toks/s]
Processed prompts:  30%|       | 38/128 [00:03<00:12,  7.12it/s, est. speed input: 4982.14 toks/s, output: 9.73 toks/s]
Processed prompts:  30%|       | 39/128 [00:04<00:12,  7.11it/s, est. speed input: 4935.11 toks/s, output: 9.64 toks/s]
Processed prompts:  31%|      | 40/128 [00:04<00:12,  7.08it/s, est. speed input: 4889.19 toks/s, output: 9.55 toks/s]
Processed prompts:  32%|      | 41/128 [00:04<00:12,  7.10it/s, est. speed input: 4849.37 toks/s, output: 9.47 toks/s]
Processed prompts:  33%|      | 42/128 [00:04<00:12,  7.10it/s, est. speed input: 4811.28 toks/s, output: 9.40 toks/s]
Processed prompts:  34%|      | 43/128 [00:04<00:11,  7.10it/s, est. speed input: 4775.44 toks/s, output: 9.33 toks/s]
Processed prompts:  34%|      | 44/128 [00:04<00:12,  6.96it/s, est. speed input: 4732.14 toks/s, output: 9.24 toks/s]
Processed prompts:  35%|      | 45/128 [00:04<00:11,  7.01it/s, est. speed input: 4701.01 toks/s, output: 9.18 toks/s]
Processed prompts:  36%|      | 46/128 [00:05<00:11,  7.06it/s, est. speed input: 4672.58 toks/s, output: 9.13 toks/s]
Processed prompts:  37%|      | 47/128 [00:05<00:11,  7.07it/s, est. speed input: 4644.39 toks/s, output: 9.07 toks/s]
Processed prompts:  38%|      | 48/128 [00:05<00:11,  7.06it/s, est. speed input: 4616.58 toks/s, output: 9.02 toks/s]
Processed prompts:  38%|      | 49/128 [00:05<00:11,  7.03it/s, est. speed input: 4589.08 toks/s, output: 8.96 toks/s]
Processed prompts:  39%|      | 50/128 [00:05<00:11,  7.05it/s, est. speed input: 4564.95 toks/s, output: 8.92 toks/s]
Processed prompts:  40%|      | 51/128 [00:05<00:11,  6.92it/s, est. speed input: 4534.45 toks/s, output: 8.86 toks/s]
Processed prompts:  41%|      | 52/128 [00:05<00:10,  6.93it/s, est. speed input: 4510.54 toks/s, output: 8.81 toks/s]
Processed prompts:  41%|     | 53/128 [00:06<00:10,  6.96it/s, est. speed input: 4489.43 toks/s, output: 8.77 toks/s]
Processed prompts:  42%|     | 54/128 [00:06<00:10,  7.01it/s, est. speed input: 4470.10 toks/s, output: 8.73 toks/s]
Processed prompts:  43%|     | 55/128 [00:06<00:10,  7.02it/s, est. speed input: 4450.72 toks/s, output: 8.69 toks/s]
Processed prompts:  44%|     | 56/128 [00:06<00:10,  7.06it/s, est. speed input: 4433.81 toks/s, output: 8.66 toks/s]
Processed prompts:  45%|     | 57/128 [00:06<00:10,  7.03it/s, est. speed input: 4415.05 toks/s, output: 8.62 toks/s]
Processed prompts:  45%|     | 58/128 [00:06<00:09,  7.06it/s, est. speed input: 4398.94 toks/s, output: 8.59 toks/s]
Processed prompts:  46%|     | 59/128 [00:06<00:10,  6.90it/s, est. speed input: 4375.78 toks/s, output: 8.55 toks/s]
Processed prompts:  47%|     | 60/128 [00:07<00:09,  6.97it/s, est. speed input: 4361.58 toks/s, output: 8.52 toks/s]
Processed prompts:  48%|     | 61/128 [00:07<00:09,  7.03it/s, est. speed input: 4348.02 toks/s, output: 8.49 toks/s]
Processed prompts:  48%|     | 62/128 [00:07<00:09,  7.00it/s, est. speed input: 4332.34 toks/s, output: 8.46 toks/s]
Processed prompts:  49%|     | 63/128 [00:07<00:09,  7.00it/s, est. speed input: 4318.25 toks/s, output: 8.43 toks/s]
Processed prompts:  50%|     | 64/128 [00:07<00:09,  7.04it/s, est. speed input: 4305.95 toks/s, output: 8.41 toks/s]
Processed prompts:  51%|     | 65/128 [00:07<00:08,  7.08it/s, est. speed input: 4294.52 toks/s, output: 8.39 toks/s]
Processed prompts:  52%|    | 66/128 [00:07<00:08,  7.00it/s, est. speed input: 4279.79 toks/s, output: 8.36 toks/s]
Processed prompts:  52%|    | 67/128 [00:08<00:08,  6.93it/s, est. speed input: 4264.64 toks/s, output: 8.33 toks/s]
Processed prompts:  53%|    | 68/128 [00:08<00:08,  6.97it/s, est. speed input: 4253.45 toks/s, output: 8.31 toks/s]
Processed prompts:  54%|    | 69/128 [00:08<00:08,  7.00it/s, est. speed input: 4242.90 toks/s, output: 8.29 toks/s]
Processed prompts:  55%|    | 70/128 [00:08<00:08,  7.02it/s, est. speed input: 4232.36 toks/s, output: 8.27 toks/s]
Processed prompts:  55%|    | 71/128 [00:08<00:08,  7.05it/s, est. speed input: 4222.87 toks/s, output: 8.25 toks/s]
Processed prompts:  56%|    | 72/128 [00:08<00:07,  7.03it/s, est. speed input: 4212.09 toks/s, output: 8.23 toks/s]
Processed prompts:  57%|    | 73/128 [00:08<00:07,  7.07it/s, est. speed input: 4203.72 toks/s, output: 8.21 toks/s]
Processed prompts:  58%|    | 74/128 [00:09<00:07,  6.92it/s, est. speed input: 4189.77 toks/s, output: 8.18 toks/s]
Processed prompts:  59%|    | 75/128 [00:09<00:07,  6.97it/s, est. speed input: 4181.28 toks/s, output: 8.17 toks/s]
Processed prompts:  59%|    | 76/128 [00:09<00:07,  7.00it/s, est. speed input: 4172.66 toks/s, output: 8.15 toks/s]
Processed prompts:  60%|    | 77/128 [00:09<00:07,  7.04it/s, est. speed input: 4165.09 toks/s, output: 8.13 toks/s]
Processed prompts:  61%|    | 78/128 [00:09<00:07,  7.07it/s, est. speed input: 4157.48 toks/s, output: 8.12 toks/s]
Processed prompts:  62%|   | 79/128 [00:09<00:06,  7.08it/s, est. speed input: 4149.91 toks/s, output: 8.11 toks/s]
Processed prompts:  62%|   | 80/128 [00:09<00:06,  7.08it/s, est. speed input: 4142.58 toks/s, output: 8.09 toks/s]
Processed prompts:  63%|   | 81/128 [00:10<00:06,  7.05it/s, est. speed input: 4134.44 toks/s, output: 8.08 toks/s]
Processed prompts:  64%|   | 82/128 [00:10<00:06,  6.90it/s, est. speed input: 4122.81 toks/s, output: 8.05 toks/s]
Processed prompts:  65%|   | 83/128 [00:10<00:06,  6.92it/s, est. speed input: 4115.16 toks/s, output: 8.04 toks/s]
Processed prompts:  66%|   | 84/128 [00:10<00:06,  6.99it/s, est. speed input: 4109.09 toks/s, output: 8.03 toks/s]
Processed prompts:  66%|   | 85/128 [00:10<00:06,  6.99it/s, est. speed input: 4101.96 toks/s, output: 8.01 toks/s]
Processed prompts:  67%|   | 86/128 [00:10<00:05,  7.04it/s, est. speed input: 4096.23 toks/s, output: 8.00 toks/s]
Processed prompts:  68%|   | 87/128 [00:10<00:05,  7.05it/s, est. speed input: 4090.04 toks/s, output: 7.99 toks/s]
Processed prompts:  69%|   | 88/128 [00:11<00:05,  7.06it/s, est. speed input: 4084.19 toks/s, output: 7.98 toks/s]
Processed prompts:  70%|   | 89/128 [00:11<00:05,  6.91it/s, est. speed input: 4074.49 toks/s, output: 7.96 toks/s]
Processed prompts:  70%|   | 90/128 [00:11<00:05,  6.95it/s, est. speed input: 4068.51 toks/s, output: 7.95 toks/s]
Processed prompts:  71%|   | 91/128 [00:11<00:05,  6.99it/s, est. speed input: 4063.14 toks/s, output: 7.94 toks/s]
Processed prompts:  72%|  | 92/128 [00:11<00:05,  7.01it/s, est. speed input: 4057.77 toks/s, output: 7.93 toks/s]
Processed prompts:  73%|  | 93/128 [00:11<00:04,  7.02it/s, est. speed input: 4052.29 toks/s, output: 7.91 toks/s]
Processed prompts:  73%|  | 94/128 [00:11<00:04,  7.09it/s, est. speed input: 4048.35 toks/s, output: 7.91 toks/s]
Processed prompts:  74%|  | 95/128 [00:12<00:04,  7.07it/s, est. speed input: 4043.00 toks/s, output: 7.90 toks/s]
Processed prompts:  75%|  | 96/128 [00:12<00:04,  7.05it/s, est. speed input: 4037.62 toks/s, output: 7.89 toks/s]
Processed prompts:  76%|  | 97/128 [00:12<00:04,  6.91it/s, est. speed input: 4029.64 toks/s, output: 7.87 toks/s]
Processed prompts:  77%|  | 98/128 [00:12<00:04,  6.96it/s, est. speed input: 4024.99 toks/s, output: 7.86 toks/s]
Processed prompts:  77%|  | 99/128 [00:12<00:04,  6.98it/s, est. speed input: 4020.24 toks/s, output: 7.85 toks/s]
Processed prompts:  78%|  | 100/128 [00:12<00:04,  6.99it/s, est. speed input: 4015.36 toks/s, output: 7.84 toks/s]
Processed prompts:  79%|  | 101/128 [00:12<00:03,  7.06it/s, est. speed input: 4012.08 toks/s, output: 7.84 toks/s]
Processed prompts:  80%|  | 102/128 [00:13<00:03,  7.10it/s, est. speed input: 4008.47 toks/s, output: 7.83 toks/s]
Processed prompts:  80%|  | 103/128 [00:13<00:03,  7.09it/s, est. speed input: 4004.40 toks/s, output: 7.82 toks/s]
Processed prompts:  81%| | 104/128 [00:13<00:03,  6.92it/s, est. speed input: 3996.96 toks/s, output: 7.81 toks/s]
Processed prompts:  82%| | 105/128 [00:13<00:03,  6.93it/s, est. speed input: 3992.26 toks/s, output: 7.80 toks/s]
Processed prompts:  83%| | 106/128 [00:13<00:03,  7.00it/s, est. speed input: 3988.90 toks/s, output: 7.79 toks/s]
Processed prompts:  84%| | 107/128 [00:13<00:02,  7.04it/s, est. speed input: 3985.47 toks/s, output: 7.78 toks/s]
Processed prompts:  84%| | 108/128 [00:13<00:02,  7.03it/s, est. speed input: 3981.44 toks/s, output: 7.78 toks/s]
Processed prompts:  85%| | 109/128 [00:14<00:02,  7.09it/s, est. speed input: 3978.70 toks/s, output: 7.77 toks/s]
Processed prompts:  86%| | 110/128 [00:14<00:02,  7.10it/s, est. speed input: 3975.46 toks/s, output: 7.76 toks/s]
Processed prompts:  87%| | 111/128 [00:14<00:02,  7.08it/s, est. speed input: 3971.75 toks/s, output: 7.76 toks/s]
Processed prompts:  88%| | 112/128 [00:14<00:02,  6.94it/s, est. speed input: 3965.75 toks/s, output: 7.75 toks/s]
Processed prompts:  88%| | 113/128 [00:14<00:02,  6.98it/s, est. speed input: 3962.35 toks/s, output: 7.74 toks/s]
Processed prompts:  89%| | 114/128 [00:14<00:01,  7.01it/s, est. speed input: 3959.12 toks/s, output: 7.73 toks/s]
Processed prompts:  90%| | 115/128 [00:14<00:01,  7.03it/s, est. speed input: 3956.03 toks/s, output: 7.73 toks/s]
Processed prompts:  91%| | 116/128 [00:15<00:01,  7.06it/s, est. speed input: 3953.16 toks/s, output: 7.72 toks/s]
Processed prompts:  91%|| 117/128 [00:15<00:01,  7.05it/s, est. speed input: 3949.79 toks/s, output: 7.71 toks/s]
Processed prompts:  92%|| 118/128 [00:15<00:01,  7.06it/s, est. speed input: 3946.83 toks/s, output: 7.71 toks/s]
Processed prompts:  93%|| 119/128 [00:15<00:01,  6.95it/s, est. speed input: 3941.89 toks/s, output: 7.70 toks/s]
Processed prompts:  94%|| 120/128 [00:15<00:01,  6.93it/s, est. speed input: 3938.05 toks/s, output: 7.69 toks/s]
Processed prompts:  95%|| 121/128 [00:15<00:01,  6.98it/s, est. speed input: 3935.31 toks/s, output: 7.69 toks/s]
Processed prompts:  95%|| 122/128 [00:15<00:00,  7.00it/s, est. speed input: 3932.39 toks/s, output: 7.68 toks/s]
Processed prompts:  96%|| 123/128 [00:16<00:00,  7.06it/s, est. speed input: 3930.23 toks/s, output: 7.68 toks/s]
Processed prompts:  97%|| 124/128 [00:16<00:00,  7.06it/s, est. speed input: 3927.47 toks/s, output: 7.67 toks/s]
Processed prompts:  98%|| 125/128 [00:16<00:00,  7.05it/s, est. speed input: 3924.67 toks/s, output: 7.67 toks/s]
Processed prompts:  98%|| 126/128 [00:16<00:00,  7.03it/s, est. speed input: 3921.56 toks/s, output: 7.66 toks/s]
Processed prompts:  99%|| 127/128 [00:16<00:00,  6.90it/s, est. speed input: 3916.63 toks/s, output: 7.65 toks/s]
Processed prompts: 100%|| 128/128 [00:16<00:00,  6.93it/s, est. speed input: 3913.79 toks/s, output: 7.64 toks/s]
Processed prompts: 100%|| 128/128 [00:16<00:00,  6.93it/s, est. speed input: 3913.79 toks/s, output: 7.64 toks/s]
Processed prompts: 100%|| 128/128 [00:16<00:00,  7.64it/s, est. speed input: 3913.79 toks/s, output: 7.64 toks/s]
[rank0]:[W127 09:53:10.219069457 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-27 09:53:26
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Qwen2.5-14B-FP8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-27 09:53:32 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-27 09:53:33 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=2455368) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2455368) WARNING 01-27 09:55:39 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 3.35 requests/s, 3435.51 total tokens/s, 3.35 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-27 09:53:32] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 09:53:32] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 09:53:32] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 09:53:32] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 09:53:32] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 09:53:32] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 09:53:32] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 09:53:32] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 09:53:32] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 09:53:32] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 09:53:32] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 09:53:32] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 09:53:32] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 09:53:32] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-27 09:53:36] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 09:53:36] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 09:53:36] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 09:53:36] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 09:53:36] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 09:53:36] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 09:53:36] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 09:53:36] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 09:53:36] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 09:53:36] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 09:53:36] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 09:53:36] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 09:53:36] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 09:53:36] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=2455368) [2026-01-27 09:53:37] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=2455368) [2026-01-27 09:53:37] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2455368) [2026-01-27 09:53:37] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=2455368) [2026-01-27 09:53:37] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=2455368) [2026-01-27 09:53:37] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=2455368) [2026-01-27 09:53:37] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=2455368) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=2455368) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:25,  8.49s/it]
(EngineCore_DP0 pid=2455368) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:43<00:48, 24.36s/it]
(EngineCore_DP0 pid=2455368) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [01:16<00:27, 27.95s/it]
(EngineCore_DP0 pid=2455368) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:50<00:00, 30.35s/it]
(EngineCore_DP0 pid=2455368) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:50<00:00, 27.55s/it]
(EngineCore_DP0 pid=2455368) 
(EngineCore_DP0 pid=2455368) [2026-01-27 09:55:29] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 6848] -> 1D uint8
(EngineCore_DP0 pid=2455368) [2026-01-27 09:55:29] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 30736384 bytes
(EngineCore_DP0 pid=2455368) [2026-01-27 09:55:29] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 6848] -> 1D uint8
(EngineCore_DP0 pid=2455368) [2026-01-27 09:55:29] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 21954560 bytes
(EngineCore_DP0 pid=2455368) [2026-01-27 09:55:29] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 6848] -> 1D uint8
(EngineCore_DP0 pid=2455368) [2026-01-27 09:55:29] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 118554624 bytes
(EngineCore_DP0 pid=2455368) [2026-01-27 09:55:29] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 18432] -> 1D uint8
(EngineCore_DP0 pid=2455368) [2026-01-27 09:55:29] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 58982400 bytes
(EngineCore_DP0 pid=2455368) 2026-01-27 09:55:37,527 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=2455368) 2026-01-27 09:55:37,705 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:   1%|          | 1/128 [00:01<02:16,  1.07s/it]
Adding requests:   2%|         | 2/128 [00:01<01:13,  1.71it/s]
Adding requests:   2%|         | 3/128 [00:01<00:47,  2.61it/s]
Adding requests:   3%|         | 4/128 [00:01<00:34,  3.57it/s]
Adding requests:   5%|         | 6/128 [00:01<00:21,  5.77it/s]
Adding requests:   6%|         | 8/128 [00:01<00:14,  8.05it/s]
Adding requests:   9%|         | 11/128 [00:01<00:09, 12.05it/s]
Adding requests:  10%|         | 13/128 [00:02<00:08, 13.54it/s]
Adding requests:  14%|        | 18/128 [00:02<00:05, 21.84it/s]
Adding requests:  29%|       | 37/128 [00:02<00:01, 63.46it/s]
Adding requests:  45%|     | 58/128 [00:02<00:00, 101.31it/s]
Adding requests:  67%|   | 86/128 [00:02<00:00, 149.29it/s]
Adding requests:  90%| | 115/128 [00:02<00:00, 187.62it/s]
Adding requests: 100%|| 128/128 [00:02<00:00, 48.64it/s] 

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   4%|         | 5/128 [00:00<00:02, 43.81it/s, est. speed input: 44877.05 toks/s, output: 43.82 toks/s]
Processed prompts:   8%|         | 10/128 [00:01<00:21,  5.61it/s, est. speed input: 6609.92 toks/s, output: 6.45 toks/s] 
Processed prompts:  10%|         | 13/128 [00:02<00:24,  4.68it/s, est. speed input: 5548.79 toks/s, output: 5.42 toks/s]
Processed prompts:  12%|        | 15/128 [00:02<00:26,  4.32it/s, est. speed input: 5166.58 toks/s, output: 5.05 toks/s]
Processed prompts:  12%|        | 16/128 [00:03<00:26,  4.19it/s, est. speed input: 5031.99 toks/s, output: 4.91 toks/s]
Processed prompts:  13%|        | 17/128 [00:03<00:27,  4.06it/s, est. speed input: 4919.24 toks/s, output: 4.80 toks/s]
Processed prompts:  14%|        | 18/128 [00:03<00:28,  3.90it/s, est. speed input: 4808.06 toks/s, output: 4.70 toks/s]
Processed prompts:  15%|        | 19/128 [00:04<00:28,  3.82it/s, est. speed input: 4726.16 toks/s, output: 4.62 toks/s]
Processed prompts:  16%|        | 20/128 [00:04<00:28,  3.74it/s, est. speed input: 4653.11 toks/s, output: 4.54 toks/s]
Processed prompts:  16%|        | 21/128 [00:04<00:29,  3.66it/s, est. speed input: 4584.41 toks/s, output: 4.48 toks/s]
Processed prompts:  17%|        | 22/128 [00:04<00:29,  3.61it/s, est. speed input: 4525.95 toks/s, output: 4.42 toks/s]
Processed prompts:  18%|        | 23/128 [00:05<00:29,  3.59it/s, est. speed input: 4476.59 toks/s, output: 4.37 toks/s]
Processed prompts:  19%|        | 24/128 [00:05<00:29,  3.58it/s, est. speed input: 4434.31 toks/s, output: 4.33 toks/s]
Processed prompts:  20%|        | 25/128 [00:05<00:29,  3.52it/s, est. speed input: 4385.84 toks/s, output: 4.28 toks/s]
Processed prompts:  20%|        | 26/128 [00:06<00:28,  3.52it/s, est. speed input: 4349.04 toks/s, output: 4.25 toks/s]
Processed prompts:  21%|        | 27/128 [00:06<00:28,  3.52it/s, est. speed input: 4316.65 toks/s, output: 4.22 toks/s]
Processed prompts:  22%|       | 28/128 [00:06<00:28,  3.52it/s, est. speed input: 4286.05 toks/s, output: 4.19 toks/s]
Processed prompts:  23%|       | 29/128 [00:06<00:28,  3.49it/s, est. speed input: 4252.82 toks/s, output: 4.15 toks/s]
Processed prompts:  23%|       | 30/128 [00:07<00:27,  3.50it/s, est. speed input: 4228.12 toks/s, output: 4.13 toks/s]
Processed prompts:  24%|       | 31/128 [00:07<00:27,  3.51it/s, est. speed input: 4205.58 toks/s, output: 4.11 toks/s]
Processed prompts:  25%|       | 32/128 [00:07<00:27,  3.51it/s, est. speed input: 4183.14 toks/s, output: 4.09 toks/s]
Processed prompts:  26%|       | 33/128 [00:08<00:27,  3.48it/s, est. speed input: 4157.99 toks/s, output: 4.06 toks/s]
Processed prompts:  27%|       | 34/128 [00:08<00:26,  3.49it/s, est. speed input: 4139.84 toks/s, output: 4.04 toks/s]
Processed prompts:  27%|       | 35/128 [00:08<00:26,  3.51it/s, est. speed input: 4122.82 toks/s, output: 4.03 toks/s]
Processed prompts:  28%|       | 36/128 [00:08<00:26,  3.51it/s, est. speed input: 4106.35 toks/s, output: 4.01 toks/s]
Processed prompts:  29%|       | 37/128 [00:09<00:26,  3.49it/s, est. speed input: 4087.86 toks/s, output: 3.99 toks/s]
Processed prompts:  30%|       | 38/128 [00:09<00:25,  3.49it/s, est. speed input: 4072.20 toks/s, output: 3.98 toks/s]
Processed prompts:  30%|       | 39/128 [00:09<00:25,  3.49it/s, est. speed input: 4058.45 toks/s, output: 3.96 toks/s]
Processed prompts:  31%|      | 40/128 [00:10<00:25,  3.47it/s, est. speed input: 4041.80 toks/s, output: 3.95 toks/s]
Processed prompts:  32%|      | 41/128 [00:10<00:24,  3.50it/s, est. speed input: 4031.79 toks/s, output: 3.94 toks/s]
Processed prompts:  33%|      | 42/128 [00:10<00:24,  3.51it/s, est. speed input: 4020.53 toks/s, output: 3.93 toks/s]
Processed prompts:  34%|      | 43/128 [00:10<00:24,  3.51it/s, est. speed input: 4009.50 toks/s, output: 3.92 toks/s]
Processed prompts:  34%|      | 44/128 [00:11<00:24,  3.47it/s, est. speed input: 3994.83 toks/s, output: 3.90 toks/s]
Processed prompts:  35%|      | 45/128 [00:11<00:23,  3.49it/s, est. speed input: 3985.55 toks/s, output: 3.89 toks/s]
Processed prompts:  36%|      | 46/128 [00:11<00:23,  3.49it/s, est. speed input: 3975.83 toks/s, output: 3.88 toks/s]
Processed prompts:  37%|      | 47/128 [00:12<00:23,  3.49it/s, est. speed input: 3966.81 toks/s, output: 3.87 toks/s]
Processed prompts:  38%|      | 48/128 [00:12<00:23,  3.46it/s, est. speed input: 3955.06 toks/s, output: 3.86 toks/s]
Processed prompts:  38%|      | 49/128 [00:12<00:22,  3.48it/s, est. speed input: 3947.27 toks/s, output: 3.85 toks/s]
Processed prompts:  39%|      | 50/128 [00:12<00:22,  3.49it/s, est. speed input: 3939.67 toks/s, output: 3.85 toks/s]
Processed prompts:  40%|      | 51/128 [00:13<00:22,  3.50it/s, est. speed input: 3932.32 toks/s, output: 3.84 toks/s]
Processed prompts:  41%|      | 52/128 [00:13<00:21,  3.48it/s, est. speed input: 3923.44 toks/s, output: 3.83 toks/s]
Processed prompts:  41%|     | 53/128 [00:13<00:21,  3.49it/s, est. speed input: 3916.46 toks/s, output: 3.82 toks/s]
Processed prompts:  42%|     | 54/128 [00:14<00:21,  3.50it/s, est. speed input: 3910.50 toks/s, output: 3.82 toks/s]
Processed prompts:  43%|     | 55/128 [00:14<00:21,  3.47it/s, est. speed input: 3901.87 toks/s, output: 3.81 toks/s]
Processed prompts:  44%|     | 56/128 [00:14<00:20,  3.49it/s, est. speed input: 3896.64 toks/s, output: 3.81 toks/s]
Processed prompts:  45%|     | 57/128 [00:15<00:20,  3.50it/s, est. speed input: 3891.12 toks/s, output: 3.80 toks/s]
Processed prompts:  45%|     | 58/128 [00:15<00:19,  3.50it/s, est. speed input: 3885.37 toks/s, output: 3.79 toks/s]
Processed prompts:  46%|     | 59/128 [00:15<00:19,  3.47it/s, est. speed input: 3877.94 toks/s, output: 3.79 toks/s]
Processed prompts:  47%|     | 60/128 [00:15<00:19,  3.48it/s, est. speed input: 3872.65 toks/s, output: 3.78 toks/s]
Processed prompts:  48%|     | 61/128 [00:16<00:19,  3.49it/s, est. speed input: 3867.92 toks/s, output: 3.78 toks/s]
Processed prompts:  48%|     | 62/128 [00:16<00:18,  3.50it/s, est. speed input: 3863.27 toks/s, output: 3.77 toks/s]
Processed prompts:  49%|     | 63/128 [00:16<00:18,  3.47it/s, est. speed input: 3856.84 toks/s, output: 3.77 toks/s]
Processed prompts:  50%|     | 64/128 [00:17<00:18,  3.47it/s, est. speed input: 3851.85 toks/s, output: 3.76 toks/s]
Processed prompts:  51%|     | 65/128 [00:17<00:18,  3.48it/s, est. speed input: 3847.48 toks/s, output: 3.76 toks/s]
Processed prompts:  52%|    | 66/128 [00:17<00:17,  3.48it/s, est. speed input: 3842.79 toks/s, output: 3.75 toks/s]
Processed prompts:  52%|    | 67/128 [00:17<00:17,  3.47it/s, est. speed input: 3837.71 toks/s, output: 3.75 toks/s]
Processed prompts:  53%|    | 68/128 [00:18<00:17,  3.48it/s, est. speed input: 3833.95 toks/s, output: 3.74 toks/s]
Processed prompts:  54%|    | 69/128 [00:18<00:16,  3.49it/s, est. speed input: 3830.39 toks/s, output: 3.74 toks/s]
Processed prompts:  55%|    | 70/128 [00:18<00:16,  3.46it/s, est. speed input: 3824.74 toks/s, output: 3.74 toks/s]
Processed prompts:  55%|    | 71/128 [00:19<00:16,  3.48it/s, est. speed input: 3821.25 toks/s, output: 3.73 toks/s]
Processed prompts:  56%|    | 72/128 [00:19<00:16,  3.48it/s, est. speed input: 3817.41 toks/s, output: 3.73 toks/s]
Processed prompts:  57%|    | 73/128 [00:19<00:15,  3.49it/s, est. speed input: 3814.23 toks/s, output: 3.72 toks/s]
Processed prompts:  58%|    | 74/128 [00:19<00:15,  3.46it/s, est. speed input: 3809.26 toks/s, output: 3.72 toks/s]
Processed prompts:  59%|    | 75/128 [00:20<00:15,  3.48it/s, est. speed input: 3806.35 toks/s, output: 3.72 toks/s]
Processed prompts:  59%|    | 76/128 [00:20<00:14,  3.49it/s, est. speed input: 3803.34 toks/s, output: 3.71 toks/s]
Processed prompts:  60%|    | 77/128 [00:20<00:14,  3.48it/s, est. speed input: 3799.76 toks/s, output: 3.71 toks/s]
Processed prompts:  61%|    | 78/128 [00:21<00:14,  3.46it/s, est. speed input: 3795.40 toks/s, output: 3.71 toks/s]
Processed prompts:  62%|   | 79/128 [00:21<00:14,  3.46it/s, est. speed input: 3792.30 toks/s, output: 3.70 toks/s]
Processed prompts:  62%|   | 80/128 [00:21<00:13,  3.47it/s, est. speed input: 3789.31 toks/s, output: 3.70 toks/s]
Processed prompts:  63%|   | 81/128 [00:21<00:13,  3.46it/s, est. speed input: 3785.56 toks/s, output: 3.70 toks/s]
Processed prompts:  64%|   | 82/128 [00:22<00:13,  3.46it/s, est. speed input: 3782.47 toks/s, output: 3.69 toks/s]
Processed prompts:  65%|   | 83/128 [00:22<00:12,  3.48it/s, est. speed input: 3780.18 toks/s, output: 3.69 toks/s]
Processed prompts:  66%|   | 84/128 [00:22<00:12,  3.49it/s, est. speed input: 3777.84 toks/s, output: 3.69 toks/s]
Processed prompts:  66%|   | 85/128 [00:23<00:12,  3.45it/s, est. speed input: 3773.48 toks/s, output: 3.69 toks/s]
Processed prompts:  67%|   | 86/128 [00:23<00:12,  3.47it/s, est. speed input: 3771.30 toks/s, output: 3.68 toks/s]
Processed prompts:  68%|   | 87/128 [00:23<00:11,  3.49it/s, est. speed input: 3769.60 toks/s, output: 3.68 toks/s]
Processed prompts:  69%|   | 88/128 [00:23<00:11,  3.48it/s, est. speed input: 3766.79 toks/s, output: 3.68 toks/s]
Processed prompts:  70%|   | 89/128 [00:24<00:11,  3.46it/s, est. speed input: 3763.36 toks/s, output: 3.68 toks/s]
Processed prompts:  70%|   | 90/128 [00:24<00:10,  3.47it/s, est. speed input: 3761.31 toks/s, output: 3.67 toks/s]
Processed prompts:  71%|   | 91/128 [00:24<00:10,  3.48it/s, est. speed input: 3759.25 toks/s, output: 3.67 toks/s]
Processed prompts:  72%|  | 92/128 [00:25<00:10,  3.48it/s, est. speed input: 3756.99 toks/s, output: 3.67 toks/s]
Processed prompts:  73%|  | 93/128 [00:25<00:10,  3.46it/s, est. speed input: 3754.01 toks/s, output: 3.67 toks/s]
Processed prompts:  73%|  | 94/128 [00:25<00:09,  3.47it/s, est. speed input: 3752.09 toks/s, output: 3.66 toks/s]
Processed prompts:  74%|  | 95/128 [00:25<00:09,  3.47it/s, est. speed input: 3749.90 toks/s, output: 3.66 toks/s]
Processed prompts:  75%|  | 96/128 [00:26<00:09,  3.45it/s, est. speed input: 3746.75 toks/s, output: 3.66 toks/s]
Processed prompts:  76%|  | 97/128 [00:26<00:08,  3.45it/s, est. speed input: 3744.46 toks/s, output: 3.66 toks/s]
Processed prompts:  77%|  | 98/128 [00:26<00:08,  3.47it/s, est. speed input: 3742.85 toks/s, output: 3.66 toks/s]
Processed prompts:  77%|  | 99/128 [00:27<00:08,  3.48it/s, est. speed input: 3741.46 toks/s, output: 3.65 toks/s]
Processed prompts:  78%|  | 100/128 [00:27<00:08,  3.45it/s, est. speed input: 3738.36 toks/s, output: 3.65 toks/s]
Processed prompts:  79%|  | 101/128 [00:27<00:07,  3.46it/s, est. speed input: 3736.65 toks/s, output: 3.65 toks/s]
Processed prompts:  80%|  | 102/128 [00:27<00:07,  3.49it/s, est. speed input: 3735.61 toks/s, output: 3.65 toks/s]
Processed prompts:  80%|  | 103/128 [00:28<00:07,  3.49it/s, est. speed input: 3734.20 toks/s, output: 3.65 toks/s]
Processed prompts:  81%| | 104/128 [00:28<00:06,  3.46it/s, est. speed input: 3731.33 toks/s, output: 3.64 toks/s]
Processed prompts:  82%| | 105/128 [00:28<00:06,  3.48it/s, est. speed input: 3730.16 toks/s, output: 3.64 toks/s]
Processed prompts:  83%| | 106/128 [00:29<00:06,  3.48it/s, est. speed input: 3728.52 toks/s, output: 3.64 toks/s]
Processed prompts:  84%| | 107/128 [00:29<00:06,  3.48it/s, est. speed input: 3726.97 toks/s, output: 3.64 toks/s]
Processed prompts:  84%| | 108/128 [00:29<00:05,  3.45it/s, est. speed input: 3724.35 toks/s, output: 3.64 toks/s]
Processed prompts:  85%| | 109/128 [00:29<00:05,  3.46it/s, est. speed input: 3722.92 toks/s, output: 3.64 toks/s]
Processed prompts:  86%| | 110/128 [00:30<00:05,  3.48it/s, est. speed input: 3721.92 toks/s, output: 3.63 toks/s]
Processed prompts:  87%| | 111/128 [00:30<00:04,  3.46it/s, est. speed input: 3719.53 toks/s, output: 3.63 toks/s]
Processed prompts:  88%| | 112/128 [00:30<00:04,  3.46it/s, est. speed input: 3717.83 toks/s, output: 3.63 toks/s]
Processed prompts:  88%| | 113/128 [00:31<00:04,  3.46it/s, est. speed input: 3716.34 toks/s, output: 3.63 toks/s]
Processed prompts:  89%| | 114/128 [00:31<00:04,  3.47it/s, est. speed input: 3714.94 toks/s, output: 3.63 toks/s]
Processed prompts:  90%| | 115/128 [00:31<00:03,  3.44it/s, est. speed input: 3712.61 toks/s, output: 3.63 toks/s]
Processed prompts:  91%| | 116/128 [00:32<00:03,  3.44it/s, est. speed input: 3710.97 toks/s, output: 3.62 toks/s]
Processed prompts:  91%|| 117/128 [00:32<00:03,  3.46it/s, est. speed input: 3709.99 toks/s, output: 3.62 toks/s]
Processed prompts:  92%|| 118/128 [00:32<00:02,  3.47it/s, est. speed input: 3708.60 toks/s, output: 3.62 toks/s]
Processed prompts:  93%|| 119/128 [00:32<00:02,  3.45it/s, est. speed input: 3706.62 toks/s, output: 3.62 toks/s]
Processed prompts:  94%|| 120/128 [00:33<00:02,  3.47it/s, est. speed input: 3705.72 toks/s, output: 3.62 toks/s]
Processed prompts:  95%|| 121/128 [00:33<00:02,  3.47it/s, est. speed input: 3704.53 toks/s, output: 3.62 toks/s]
Processed prompts:  95%|| 122/128 [00:33<00:01,  3.48it/s, est. speed input: 3703.40 toks/s, output: 3.62 toks/s]
Processed prompts:  96%|| 123/128 [00:34<00:01,  3.46it/s, est. speed input: 3701.68 toks/s, output: 3.61 toks/s]
Processed prompts:  97%|| 124/128 [00:34<00:01,  3.48it/s, est. speed input: 3700.96 toks/s, output: 3.61 toks/s]
Processed prompts:  98%|| 125/128 [00:34<00:00,  3.48it/s, est. speed input: 3699.84 toks/s, output: 3.61 toks/s]
Processed prompts:  98%|| 126/128 [00:34<00:00,  3.44it/s, est. speed input: 3697.58 toks/s, output: 3.61 toks/s]
Processed prompts:  99%|| 127/128 [00:35<00:00,  3.46it/s, est. speed input: 3696.60 toks/s, output: 3.61 toks/s]
Processed prompts: 100%|| 128/128 [00:35<00:00,  3.46it/s, est. speed input: 3695.29 toks/s, output: 3.61 toks/s]
Processed prompts: 100%|| 128/128 [00:35<00:00,  3.46it/s, est. speed input: 3695.29 toks/s, output: 3.61 toks/s]
Processed prompts: 100%|| 128/128 [00:35<00:00,  3.61it/s, est. speed input: 3695.29 toks/s, output: 3.61 toks/s]
[rank0]:[W127 09:56:18.751797733 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-27 09:56:33
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Qwen2.5-14B-FP8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-27 09:56:40 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-27 09:56:40 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=2460533) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2460533) WARNING 01-27 09:58:56 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 3.28 requests/s, 3357.41 total tokens/s, 3.28 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-27 09:56:40] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 09:56:40] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 09:56:40] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 09:56:40] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 09:56:40] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 09:56:40] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 09:56:40] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 09:56:40] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 09:56:40] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 09:56:40] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 09:56:40] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 09:56:40] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 09:56:40] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 09:56:40] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-27 09:56:43] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 09:56:43] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 09:56:43] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 09:56:43] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 09:56:43] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 09:56:43] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 09:56:43] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 09:56:43] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 09:56:43] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 09:56:43] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 09:56:43] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 09:56:43] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 09:56:43] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 09:56:43] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=2460533) [2026-01-27 09:56:44] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=2460533) [2026-01-27 09:56:44] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2460533) [2026-01-27 09:56:44] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=2460533) [2026-01-27 09:56:44] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=2460533) [2026-01-27 09:56:44] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=2460533) [2026-01-27 09:56:44] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=2460533) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=2460533) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:25,  8.58s/it]
(EngineCore_DP0 pid=2460533) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:44<00:48, 24.41s/it]
(EngineCore_DP0 pid=2460533) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [01:16<00:28, 28.16s/it]
(EngineCore_DP0 pid=2460533) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:51<00:00, 30.67s/it]
(EngineCore_DP0 pid=2460533) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:51<00:00, 27.80s/it]
(EngineCore_DP0 pid=2460533) 
(EngineCore_DP0 pid=2460533) [2026-01-27 09:58:37] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 6848] -> 1D uint8
(EngineCore_DP0 pid=2460533) [2026-01-27 09:58:37] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 30736384 bytes
(EngineCore_DP0 pid=2460533) [2026-01-27 09:58:37] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 6848] -> 1D uint8
(EngineCore_DP0 pid=2460533) [2026-01-27 09:58:37] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 21954560 bytes
(EngineCore_DP0 pid=2460533) [2026-01-27 09:58:37] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 6848] -> 1D uint8
(EngineCore_DP0 pid=2460533) [2026-01-27 09:58:37] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 118554624 bytes
(EngineCore_DP0 pid=2460533) [2026-01-27 09:58:37] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 18432] -> 1D uint8
(EngineCore_DP0 pid=2460533) [2026-01-27 09:58:37] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 58982400 bytes
(EngineCore_DP0 pid=2460533) 2026-01-27 09:58:47,186 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=2460533) 2026-01-27 09:58:47,716 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:   0%|          | 1/256 [00:01<05:05,  1.20s/it]
Adding requests:   1%|          | 2/256 [00:01<02:44,  1.54it/s]
Adding requests:   1%|          | 3/256 [00:01<01:47,  2.35it/s]
Adding requests:   2%|         | 4/256 [00:01<01:15,  3.32it/s]
Adding requests:   2%|         | 5/256 [00:01<00:57,  4.36it/s]
Adding requests:   3%|         | 7/256 [00:01<00:38,  6.52it/s]
Adding requests:   4%|         | 9/256 [00:02<00:28,  8.81it/s]
Adding requests:   5%|         | 12/256 [00:02<00:19, 12.57it/s]
Adding requests:   5%|         | 14/256 [00:02<00:17, 13.78it/s]
Adding requests:   7%|         | 19/256 [00:02<00:10, 21.89it/s]
Adding requests:  13%|        | 34/256 [00:02<00:04, 53.43it/s]
Adding requests:  20%|        | 50/256 [00:02<00:02, 81.15it/s]
Adding requests:  27%|       | 70/256 [00:02<00:01, 113.32it/s]
Adding requests:  38%|      | 96/256 [00:02<00:01, 152.68it/s]
Adding requests:  49%|     | 125/256 [00:02<00:00, 191.12it/s]
Adding requests:  61%|    | 156/256 [00:03<00:00, 224.36it/s]
Adding requests:  75%|  | 191/256 [00:03<00:00, 259.51it/s]
Adding requests:  85%| | 218/256 [00:03<00:00, 261.51it/s]
Adding requests:  98%|| 250/256 [00:03<00:00, 276.67it/s]
Adding requests: 100%|| 256/256 [00:03<00:00, 75.46it/s] 

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   3%|         | 8/256 [00:00<00:19, 13.05it/s, est. speed input: 13359.43 toks/s, output: 13.05 toks/s]
Processed prompts:   4%|         | 10/256 [00:01<00:33,  7.44it/s, est. speed input: 8494.71 toks/s, output: 8.30 toks/s] 
Processed prompts:   5%|         | 12/256 [00:01<00:43,  5.56it/s, est. speed input: 6802.44 toks/s, output: 6.64 toks/s]
Processed prompts:   5%|         | 14/256 [00:02<00:51,  4.72it/s, est. speed input: 5990.32 toks/s, output: 5.85 toks/s]
Processed prompts:   6%|         | 16/256 [00:02<00:56,  4.22it/s, est. speed input: 5476.61 toks/s, output: 5.35 toks/s]
Processed prompts:   7%|         | 18/256 [00:03<01:00,  3.93it/s, est. speed input: 5135.52 toks/s, output: 5.02 toks/s]
Processed prompts:   8%|         | 20/256 [00:04<01:02,  3.75it/s, est. speed input: 4897.69 toks/s, output: 4.78 toks/s]
Processed prompts:   9%|         | 22/256 [00:04<01:04,  3.62it/s, est. speed input: 4714.05 toks/s, output: 4.60 toks/s]
Processed prompts:   9%|         | 24/256 [00:05<01:05,  3.55it/s, est. speed input: 4576.70 toks/s, output: 4.47 toks/s]
Processed prompts:  10%|         | 26/256 [00:05<01:06,  3.47it/s, est. speed input: 4456.07 toks/s, output: 4.35 toks/s]
Processed prompts:  11%|         | 28/256 [00:06<01:06,  3.45it/s, est. speed input: 4367.70 toks/s, output: 4.27 toks/s]
Processed prompts:  12%|        | 30/256 [00:07<01:06,  3.41it/s, est. speed input: 4288.50 toks/s, output: 4.19 toks/s]
Processed prompts:  12%|        | 32/256 [00:07<01:05,  3.40it/s, est. speed input: 4224.84 toks/s, output: 4.13 toks/s]
Processed prompts:  13%|        | 34/256 [00:08<01:05,  3.38it/s, est. speed input: 4165.33 toks/s, output: 4.07 toks/s]
Processed prompts:  14%|        | 36/256 [00:08<01:05,  3.37it/s, est. speed input: 4117.30 toks/s, output: 4.02 toks/s]
Processed prompts:  15%|        | 38/256 [00:09<01:04,  3.37it/s, est. speed input: 4074.72 toks/s, output: 3.98 toks/s]
Processed prompts:  16%|        | 40/256 [00:10<01:04,  3.36it/s, est. speed input: 4036.22 toks/s, output: 3.94 toks/s]
Processed prompts:  16%|        | 42/256 [00:10<01:03,  3.36it/s, est. speed input: 4003.77 toks/s, output: 3.91 toks/s]
Processed prompts:  17%|        | 44/256 [00:11<01:03,  3.34it/s, est. speed input: 3970.51 toks/s, output: 3.88 toks/s]
Processed prompts:  18%|        | 46/256 [00:11<01:02,  3.35it/s, est. speed input: 3945.09 toks/s, output: 3.85 toks/s]
Processed prompts:  19%|        | 48/256 [00:12<01:02,  3.35it/s, est. speed input: 3920.09 toks/s, output: 3.83 toks/s]
Processed prompts:  20%|        | 50/256 [00:13<01:01,  3.36it/s, est. speed input: 3898.88 toks/s, output: 3.81 toks/s]
Processed prompts:  20%|        | 52/256 [00:13<01:01,  3.34it/s, est. speed input: 3876.45 toks/s, output: 3.79 toks/s]
Processed prompts:  21%|        | 54/256 [00:14<01:00,  3.34it/s, est. speed input: 3857.79 toks/s, output: 3.77 toks/s]
Processed prompts:  22%|       | 56/256 [00:14<00:59,  3.34it/s, est. speed input: 3840.18 toks/s, output: 3.75 toks/s]
Processed prompts:  23%|       | 58/256 [00:15<00:59,  3.34it/s, est. speed input: 3823.06 toks/s, output: 3.73 toks/s]
Processed prompts:  23%|       | 60/256 [00:16<00:58,  3.34it/s, est. speed input: 3808.72 toks/s, output: 3.72 toks/s]
Processed prompts:  24%|       | 62/256 [00:16<00:58,  3.34it/s, est. speed input: 3795.10 toks/s, output: 3.71 toks/s]
Processed prompts:  25%|       | 64/256 [00:17<00:57,  3.35it/s, est. speed input: 3783.33 toks/s, output: 3.69 toks/s]
Processed prompts:  26%|       | 66/256 [00:17<00:56,  3.35it/s, est. speed input: 3771.15 toks/s, output: 3.68 toks/s]
Processed prompts:  27%|       | 68/256 [00:18<00:56,  3.33it/s, est. speed input: 3758.32 toks/s, output: 3.67 toks/s]
Processed prompts:  27%|       | 70/256 [00:19<00:55,  3.33it/s, est. speed input: 3747.18 toks/s, output: 3.66 toks/s]
Processed prompts:  28%|       | 72/256 [00:19<00:55,  3.34it/s, est. speed input: 3738.12 toks/s, output: 3.65 toks/s]
Processed prompts:  29%|       | 74/256 [00:20<00:54,  3.33it/s, est. speed input: 3727.39 toks/s, output: 3.64 toks/s]
Processed prompts:  30%|       | 76/256 [00:20<00:53,  3.34it/s, est. speed input: 3719.16 toks/s, output: 3.63 toks/s]
Processed prompts:  30%|       | 78/256 [00:21<00:53,  3.33it/s, est. speed input: 3709.62 toks/s, output: 3.62 toks/s]
Processed prompts:  31%|      | 80/256 [00:22<00:53,  3.32it/s, est. speed input: 3700.83 toks/s, output: 3.61 toks/s]
Processed prompts:  32%|      | 82/256 [00:22<00:52,  3.33it/s, est. speed input: 3693.87 toks/s, output: 3.61 toks/s]
Processed prompts:  33%|      | 84/256 [00:23<00:51,  3.33it/s, est. speed input: 3686.13 toks/s, output: 3.60 toks/s]
Processed prompts:  34%|      | 86/256 [00:23<00:51,  3.33it/s, est. speed input: 3679.64 toks/s, output: 3.59 toks/s]
Processed prompts:  34%|      | 88/256 [00:24<00:50,  3.32it/s, est. speed input: 3671.91 toks/s, output: 3.59 toks/s]
Processed prompts:  35%|      | 90/256 [00:25<00:49,  3.33it/s, est. speed input: 3665.99 toks/s, output: 3.58 toks/s]
Processed prompts:  36%|      | 92/256 [00:25<00:49,  3.32it/s, est. speed input: 3659.15 toks/s, output: 3.57 toks/s]
Processed prompts:  37%|      | 94/256 [00:26<00:48,  3.32it/s, est. speed input: 3653.15 toks/s, output: 3.57 toks/s]
Processed prompts:  38%|      | 96/256 [00:26<00:48,  3.32it/s, est. speed input: 3647.56 toks/s, output: 3.56 toks/s]
Processed prompts:  38%|      | 98/256 [00:27<00:47,  3.31it/s, est. speed input: 3641.46 toks/s, output: 3.56 toks/s]
Processed prompts:  39%|      | 100/256 [00:28<00:46,  3.33it/s, est. speed input: 3637.34 toks/s, output: 3.55 toks/s]
Processed prompts:  40%|      | 102/256 [00:28<00:46,  3.32it/s, est. speed input: 3631.68 toks/s, output: 3.55 toks/s]
Processed prompts:  41%|      | 104/256 [00:29<00:45,  3.33it/s, est. speed input: 3627.59 toks/s, output: 3.54 toks/s]
Processed prompts:  41%|     | 106/256 [00:29<00:45,  3.32it/s, est. speed input: 3622.80 toks/s, output: 3.54 toks/s]
Processed prompts:  42%|     | 108/256 [00:30<00:44,  3.33it/s, est. speed input: 3618.93 toks/s, output: 3.53 toks/s]
Processed prompts:  43%|     | 110/256 [00:31<00:44,  3.32it/s, est. speed input: 3614.06 toks/s, output: 3.53 toks/s]
Processed prompts:  44%|     | 112/256 [00:31<00:43,  3.32it/s, est. speed input: 3609.83 toks/s, output: 3.53 toks/s]
Processed prompts:  45%|     | 114/256 [00:32<00:42,  3.33it/s, est. speed input: 3606.88 toks/s, output: 3.52 toks/s]
Processed prompts:  45%|     | 116/256 [00:32<00:42,  3.32it/s, est. speed input: 3602.65 toks/s, output: 3.52 toks/s]
Processed prompts:  46%|     | 118/256 [00:33<00:41,  3.33it/s, est. speed input: 3599.48 toks/s, output: 3.52 toks/s]
Processed prompts:  47%|     | 120/256 [00:34<00:40,  3.32it/s, est. speed input: 3595.62 toks/s, output: 3.51 toks/s]
Processed prompts:  48%|     | 122/256 [00:34<00:40,  3.33it/s, est. speed input: 3593.05 toks/s, output: 3.51 toks/s]
Processed prompts:  48%|     | 124/256 [00:35<00:39,  3.32it/s, est. speed input: 3589.40 toks/s, output: 3.51 toks/s]
Processed prompts:  49%|     | 126/256 [00:35<00:39,  3.32it/s, est. speed input: 3585.90 toks/s, output: 3.50 toks/s]
Processed prompts:  50%|     | 128/256 [00:36<00:38,  3.32it/s, est. speed input: 3583.17 toks/s, output: 3.50 toks/s]
Processed prompts:  51%|     | 130/256 [00:37<00:37,  3.32it/s, est. speed input: 3579.83 toks/s, output: 3.50 toks/s]
Processed prompts:  52%|    | 132/256 [00:37<00:37,  3.33it/s, est. speed input: 3577.54 toks/s, output: 3.49 toks/s]
Processed prompts:  52%|    | 134/256 [00:38<00:36,  3.32it/s, est. speed input: 3574.23 toks/s, output: 3.49 toks/s]
Processed prompts:  53%|    | 136/256 [00:38<00:36,  3.33it/s, est. speed input: 3572.36 toks/s, output: 3.49 toks/s]
Processed prompts:  54%|    | 138/256 [00:39<00:35,  3.32it/s, est. speed input: 3569.33 toks/s, output: 3.49 toks/s]
Processed prompts:  55%|    | 140/256 [00:40<00:34,  3.32it/s, est. speed input: 3566.97 toks/s, output: 3.48 toks/s]
Processed prompts:  55%|    | 142/256 [00:40<00:34,  3.33it/s, est. speed input: 3564.63 toks/s, output: 3.48 toks/s]
Processed prompts:  56%|    | 144/256 [00:41<00:33,  3.32it/s, est. speed input: 3561.89 toks/s, output: 3.48 toks/s]
Processed prompts:  57%|    | 146/256 [00:41<00:33,  3.33it/s, est. speed input: 3560.08 toks/s, output: 3.48 toks/s]
Processed prompts:  58%|    | 148/256 [00:42<00:32,  3.32it/s, est. speed input: 3557.60 toks/s, output: 3.47 toks/s]
Processed prompts:  59%|    | 150/256 [00:43<00:31,  3.33it/s, est. speed input: 3555.74 toks/s, output: 3.47 toks/s]
Processed prompts:  59%|    | 152/256 [00:43<00:31,  3.32it/s, est. speed input: 3553.30 toks/s, output: 3.47 toks/s]
Processed prompts:  60%|    | 154/256 [00:44<00:30,  3.32it/s, est. speed input: 3551.36 toks/s, output: 3.47 toks/s]
Processed prompts:  61%|    | 156/256 [00:45<00:30,  3.32it/s, est. speed input: 3549.23 toks/s, output: 3.47 toks/s]
Processed prompts:  62%|   | 158/256 [00:45<00:29,  3.31it/s, est. speed input: 3546.76 toks/s, output: 3.46 toks/s]
Processed prompts:  62%|   | 160/256 [00:46<00:28,  3.33it/s, est. speed input: 3545.45 toks/s, output: 3.46 toks/s]
Processed prompts:  63%|   | 162/256 [00:46<00:28,  3.31it/s, est. speed input: 3543.06 toks/s, output: 3.46 toks/s]
Processed prompts:  64%|   | 164/256 [00:47<00:27,  3.32it/s, est. speed input: 3541.55 toks/s, output: 3.46 toks/s]
Processed prompts:  65%|   | 166/256 [00:48<00:27,  3.31it/s, est. speed input: 3539.30 toks/s, output: 3.46 toks/s]
Processed prompts:  66%|   | 168/256 [00:48<00:26,  3.33it/s, est. speed input: 3538.15 toks/s, output: 3.46 toks/s]
Processed prompts:  66%|   | 170/256 [00:49<00:25,  3.32it/s, est. speed input: 3536.10 toks/s, output: 3.45 toks/s]
Processed prompts:  67%|   | 172/256 [00:49<00:25,  3.30it/s, est. speed input: 3533.83 toks/s, output: 3.45 toks/s]
Processed prompts:  68%|   | 174/256 [00:50<00:24,  3.32it/s, est. speed input: 3532.57 toks/s, output: 3.45 toks/s]
Processed prompts:  69%|   | 176/256 [00:51<00:24,  3.31it/s, est. speed input: 3530.50 toks/s, output: 3.45 toks/s]
Processed prompts:  70%|   | 178/256 [00:51<00:23,  3.32it/s, est. speed input: 3529.31 toks/s, output: 3.45 toks/s]
Processed prompts:  70%|   | 180/256 [00:52<00:22,  3.31it/s, est. speed input: 3527.38 toks/s, output: 3.44 toks/s]
Processed prompts:  71%|   | 182/256 [00:52<00:22,  3.32it/s, est. speed input: 3526.45 toks/s, output: 3.44 toks/s]
Processed prompts:  72%|  | 184/256 [00:53<00:21,  3.31it/s, est. speed input: 3524.67 toks/s, output: 3.44 toks/s]
Processed prompts:  73%|  | 186/256 [00:54<00:21,  3.32it/s, est. speed input: 3523.41 toks/s, output: 3.44 toks/s]
Processed prompts:  73%|  | 188/256 [00:54<00:20,  3.32it/s, est. speed input: 3522.09 toks/s, output: 3.44 toks/s]
Processed prompts:  74%|  | 190/256 [00:55<00:19,  3.31it/s, est. speed input: 3520.47 toks/s, output: 3.44 toks/s]
Processed prompts:  75%|  | 192/256 [00:55<00:19,  3.32it/s, est. speed input: 3519.40 toks/s, output: 3.44 toks/s]
Processed prompts:  76%|  | 194/256 [00:56<00:18,  3.31it/s, est. speed input: 3517.84 toks/s, output: 3.44 toks/s]
Processed prompts:  77%|  | 196/256 [00:57<00:18,  3.32it/s, est. speed input: 3516.89 toks/s, output: 3.43 toks/s]
Processed prompts:  77%|  | 198/256 [00:57<00:17,  3.31it/s, est. speed input: 3515.37 toks/s, output: 3.43 toks/s]
Processed prompts:  78%|  | 200/256 [00:58<00:16,  3.33it/s, est. speed input: 3514.57 toks/s, output: 3.43 toks/s]
Processed prompts:  79%|  | 202/256 [00:58<00:14,  3.76it/s, est. speed input: 3527.40 toks/s, output: 3.44 toks/s]
Processed prompts:  80%|  | 204/256 [00:59<00:14,  3.63it/s, est. speed input: 3526.32 toks/s, output: 3.44 toks/s]
Processed prompts:  80%|  | 206/256 [00:59<00:14,  3.52it/s, est. speed input: 3524.66 toks/s, output: 3.44 toks/s]
Processed prompts:  81%| | 208/256 [01:00<00:13,  3.46it/s, est. speed input: 3523.72 toks/s, output: 3.44 toks/s]
Processed prompts:  82%| | 210/256 [01:01<00:13,  3.41it/s, est. speed input: 3522.26 toks/s, output: 3.44 toks/s]
Processed prompts:  83%| | 212/256 [01:01<00:13,  3.37it/s, est. speed input: 3520.74 toks/s, output: 3.44 toks/s]
Processed prompts:  84%| | 214/256 [01:02<00:12,  3.37it/s, est. speed input: 3519.90 toks/s, output: 3.44 toks/s]
Processed prompts:  84%| | 216/256 [01:02<00:11,  3.34it/s, est. speed input: 3518.33 toks/s, output: 3.44 toks/s]
Processed prompts:  85%| | 218/256 [01:03<00:11,  3.34it/s, est. speed input: 3517.38 toks/s, output: 3.43 toks/s]
Processed prompts:  86%| | 220/256 [01:04<00:10,  3.33it/s, est. speed input: 3515.99 toks/s, output: 3.43 toks/s]
Processed prompts:  87%| | 222/256 [01:04<00:10,  3.33it/s, est. speed input: 3515.18 toks/s, output: 3.43 toks/s]
Processed prompts:  88%| | 224/256 [01:05<00:09,  3.32it/s, est. speed input: 3513.81 toks/s, output: 3.43 toks/s]
Processed prompts:  88%| | 226/256 [01:05<00:09,  3.31it/s, est. speed input: 3512.43 toks/s, output: 3.43 toks/s]
Processed prompts:  89%| | 228/256 [01:06<00:08,  3.32it/s, est. speed input: 3511.58 toks/s, output: 3.43 toks/s]
Processed prompts:  90%| | 230/256 [01:07<00:07,  3.31it/s, est. speed input: 3510.33 toks/s, output: 3.43 toks/s]
Processed prompts:  91%| | 232/256 [01:07<00:07,  3.32it/s, est. speed input: 3509.60 toks/s, output: 3.43 toks/s]
Processed prompts:  91%|| 234/256 [01:08<00:06,  3.31it/s, est. speed input: 3508.28 toks/s, output: 3.43 toks/s]
Processed prompts:  92%|| 236/256 [01:08<00:06,  3.32it/s, est. speed input: 3507.54 toks/s, output: 3.43 toks/s]
Processed prompts:  93%|| 238/256 [01:09<00:05,  3.31it/s, est. speed input: 3506.26 toks/s, output: 3.42 toks/s]
Processed prompts:  94%|| 240/256 [01:10<00:04,  3.30it/s, est. speed input: 3505.02 toks/s, output: 3.42 toks/s]
Processed prompts:  95%|| 242/256 [01:10<00:04,  3.31it/s, est. speed input: 3504.09 toks/s, output: 3.42 toks/s]
Processed prompts:  95%|| 244/256 [01:11<00:03,  3.30it/s, est. speed input: 3502.79 toks/s, output: 3.42 toks/s]
Processed prompts:  96%|| 246/256 [01:11<00:03,  3.31it/s, est. speed input: 3502.18 toks/s, output: 3.42 toks/s]
Processed prompts:  97%|| 248/256 [01:12<00:02,  3.29it/s, est. speed input: 3500.57 toks/s, output: 3.42 toks/s]
Processed prompts:  98%|| 250/256 [01:13<00:01,  3.30it/s, est. speed input: 3499.81 toks/s, output: 3.42 toks/s]
Processed prompts:  98%|| 252/256 [01:13<00:01,  3.29it/s, est. speed input: 3498.62 toks/s, output: 3.42 toks/s]
Processed prompts:  99%|| 254/256 [01:14<00:00,  3.30it/s, est. speed input: 3497.68 toks/s, output: 3.42 toks/s]
Processed prompts: 100%|| 256/256 [01:14<00:00,  3.90it/s, est. speed input: 3511.30 toks/s, output: 3.43 toks/s]
Processed prompts: 100%|| 256/256 [01:14<00:00,  3.90it/s, est. speed input: 3511.30 toks/s, output: 3.43 toks/s]
Processed prompts: 100%|| 256/256 [01:14<00:00,  3.43it/s, est. speed input: 3511.30 toks/s, output: 3.43 toks/s]
[rank0]:[W127 10:00:15.878380555 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-27 10:00:32
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Qwen2.5-14B-FP8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-27 10:00:40 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-27 10:00:40 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=2467069) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2467069) WARNING 01-27 10:02:46 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 3.44 requests/s, 3522.62 total tokens/s, 3.44 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-27 10:00:40] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 10:00:40] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 10:00:40] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 10:00:40] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 10:00:40] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 10:00:40] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 10:00:40] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 10:00:40] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 10:00:40] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 10:00:40] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 10:00:40] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 10:00:40] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 10:00:40] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 10:00:40] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-27 10:00:43] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 10:00:43] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 10:00:43] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 10:00:43] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 10:00:43] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 10:00:43] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 10:00:43] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 10:00:43] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 10:00:43] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 10:00:43] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 10:00:43] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 10:00:43] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 10:00:43] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 10:00:43] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=2467069) [2026-01-27 10:00:44] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=2467069) [2026-01-27 10:00:44] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2467069) [2026-01-27 10:00:44] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=2467069) [2026-01-27 10:00:44] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=2467069) [2026-01-27 10:00:44] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=2467069) [2026-01-27 10:00:44] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=2467069) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=2467069) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:25,  8.60s/it]
(EngineCore_DP0 pid=2467069) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:43<00:48, 24.23s/it]
(EngineCore_DP0 pid=2467069) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [01:15<00:27, 27.75s/it]
(EngineCore_DP0 pid=2467069) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:49<00:00, 30.16s/it]
(EngineCore_DP0 pid=2467069) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:49<00:00, 27.39s/it]
(EngineCore_DP0 pid=2467069) 
(EngineCore_DP0 pid=2467069) [2026-01-27 10:02:35] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 6848] -> 1D uint8
(EngineCore_DP0 pid=2467069) [2026-01-27 10:02:35] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 30736384 bytes
(EngineCore_DP0 pid=2467069) [2026-01-27 10:02:35] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 6848] -> 1D uint8
(EngineCore_DP0 pid=2467069) [2026-01-27 10:02:35] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 21954560 bytes
(EngineCore_DP0 pid=2467069) [2026-01-27 10:02:35] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 6848] -> 1D uint8
(EngineCore_DP0 pid=2467069) [2026-01-27 10:02:35] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 118554624 bytes
(EngineCore_DP0 pid=2467069) [2026-01-27 10:02:35] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 18432] -> 1D uint8
(EngineCore_DP0 pid=2467069) [2026-01-27 10:02:35] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 58982400 bytes
(EngineCore_DP0 pid=2467069) 2026-01-27 10:02:44,207 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=2467069) 2026-01-27 10:02:44,662 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   6%|         | 31/512 [00:00<00:01, 309.41it/s]
Adding requests:  14%|        | 70/512 [00:00<00:01, 354.78it/s]
Adding requests:  21%|        | 106/512 [00:00<00:01, 335.65it/s]
Adding requests:  29%|       | 151/512 [00:00<00:00, 378.44it/s]
Adding requests:  38%|      | 194/512 [00:00<00:00, 395.46it/s]
Adding requests:  46%|     | 237/512 [00:00<00:00, 403.80it/s]
Adding requests:  55%|    | 280/512 [00:00<00:00, 408.89it/s]
Adding requests:  63%|   | 324/512 [00:00<00:00, 416.08it/s]
Adding requests:  72%|  | 369/512 [00:00<00:00, 426.46it/s]
Adding requests:  81%|  | 413/512 [00:01<00:00, 428.16it/s]
Adding requests:  89%| | 456/512 [00:01<00:00, 423.69it/s]
Adding requests:  98%|| 500/512 [00:01<00:00, 427.99it/s]
Adding requests: 100%|| 512/512 [00:01<00:00, 407.26it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 2/512 [00:00<01:28,  5.76it/s, est. speed input: 5900.69 toks/s, output: 5.76 toks/s]
Processed prompts:   1%|          | 6/512 [00:01<02:10,  3.87it/s, est. speed input: 4092.77 toks/s, output: 4.00 toks/s]
Processed prompts:   2%|         | 10/512 [00:02<02:17,  3.64it/s, est. speed input: 3852.91 toks/s, output: 3.76 toks/s]
Processed prompts:   3%|         | 14/512 [00:03<02:19,  3.56it/s, est. speed input: 3758.02 toks/s, output: 3.67 toks/s]
Processed prompts:   4%|         | 18/512 [00:04<02:20,  3.53it/s, est. speed input: 3709.15 toks/s, output: 3.62 toks/s]
Processed prompts:   4%|         | 22/512 [00:06<02:20,  3.50it/s, est. speed input: 3674.89 toks/s, output: 3.59 toks/s]
Processed prompts:   5%|         | 26/512 [00:07<02:19,  3.48it/s, est. speed input: 3651.49 toks/s, output: 3.57 toks/s]
Processed prompts:   6%|         | 30/512 [00:08<02:18,  3.47it/s, est. speed input: 3636.87 toks/s, output: 3.55 toks/s]
Processed prompts:   7%|         | 34/512 [00:09<02:17,  3.47it/s, est. speed input: 3624.91 toks/s, output: 3.54 toks/s]
Processed prompts:   7%|         | 38/512 [00:10<02:16,  3.47it/s, est. speed input: 3616.08 toks/s, output: 3.53 toks/s]
Processed prompts:   8%|         | 42/512 [00:11<02:16,  3.46it/s, est. speed input: 3606.32 toks/s, output: 3.52 toks/s]
Processed prompts:   9%|         | 46/512 [00:13<02:15,  3.44it/s, est. speed input: 3596.28 toks/s, output: 3.51 toks/s]
Processed prompts:  10%|         | 50/512 [00:14<02:14,  3.45it/s, est. speed input: 3591.84 toks/s, output: 3.51 toks/s]
Processed prompts:  11%|         | 54/512 [00:15<02:12,  3.44it/s, est. speed input: 3586.37 toks/s, output: 3.50 toks/s]
Processed prompts:  11%|        | 58/512 [00:16<02:11,  3.45it/s, est. speed input: 3583.16 toks/s, output: 3.50 toks/s]
Processed prompts:  12%|        | 62/512 [00:17<02:10,  3.45it/s, est. speed input: 3579.60 toks/s, output: 3.50 toks/s]
Processed prompts:  13%|        | 66/512 [00:18<02:09,  3.44it/s, est. speed input: 3575.54 toks/s, output: 3.49 toks/s]
Processed prompts:  14%|        | 70/512 [00:20<02:08,  3.44it/s, est. speed input: 3572.40 toks/s, output: 3.49 toks/s]
Processed prompts:  14%|        | 74/512 [00:21<02:07,  3.44it/s, est. speed input: 3569.42 toks/s, output: 3.49 toks/s]
Processed prompts:  15%|        | 78/512 [00:22<02:06,  3.44it/s, est. speed input: 3566.61 toks/s, output: 3.48 toks/s]
Processed prompts:  16%|        | 82/512 [00:23<02:05,  3.44it/s, est. speed input: 3564.43 toks/s, output: 3.48 toks/s]
Processed prompts:  17%|        | 86/512 [00:24<02:04,  3.43it/s, est. speed input: 3561.26 toks/s, output: 3.48 toks/s]
Processed prompts:  18%|        | 90/512 [00:25<02:03,  3.43it/s, est. speed input: 3558.18 toks/s, output: 3.47 toks/s]
Processed prompts:  18%|        | 94/512 [00:27<02:01,  3.43it/s, est. speed input: 3556.61 toks/s, output: 3.47 toks/s]
Processed prompts:  19%|        | 98/512 [00:28<02:00,  3.43it/s, est. speed input: 3554.95 toks/s, output: 3.47 toks/s]
Processed prompts:  20%|        | 102/512 [00:29<01:59,  3.43it/s, est. speed input: 3553.46 toks/s, output: 3.47 toks/s]
Processed prompts:  21%|        | 106/512 [00:30<01:58,  3.44it/s, est. speed input: 3552.66 toks/s, output: 3.47 toks/s]
Processed prompts:  21%|       | 110/512 [00:31<01:56,  3.44it/s, est. speed input: 3551.43 toks/s, output: 3.47 toks/s]
Processed prompts:  22%|       | 114/512 [00:32<01:55,  3.44it/s, est. speed input: 3550.29 toks/s, output: 3.47 toks/s]
Processed prompts:  23%|       | 118/512 [00:34<01:54,  3.43it/s, est. speed input: 3548.91 toks/s, output: 3.47 toks/s]
Processed prompts:  24%|       | 122/512 [00:35<01:53,  3.43it/s, est. speed input: 3547.72 toks/s, output: 3.46 toks/s]
Processed prompts:  25%|       | 126/512 [00:36<01:52,  3.43it/s, est. speed input: 3546.67 toks/s, output: 3.46 toks/s]
Processed prompts:  25%|       | 130/512 [00:37<01:51,  3.42it/s, est. speed input: 3544.53 toks/s, output: 3.46 toks/s]
Processed prompts:  26%|       | 134/512 [00:38<01:50,  3.43it/s, est. speed input: 3543.93 toks/s, output: 3.46 toks/s]
Processed prompts:  27%|       | 138/512 [00:39<01:49,  3.43it/s, est. speed input: 3542.93 toks/s, output: 3.46 toks/s]
Processed prompts:  28%|       | 142/512 [00:41<01:47,  3.43it/s, est. speed input: 3542.32 toks/s, output: 3.46 toks/s]
Processed prompts:  29%|       | 146/512 [00:42<01:46,  3.43it/s, est. speed input: 3541.50 toks/s, output: 3.46 toks/s]
Processed prompts:  29%|       | 150/512 [00:43<01:45,  3.43it/s, est. speed input: 3540.91 toks/s, output: 3.46 toks/s]
Processed prompts:  30%|       | 154/512 [00:44<01:44,  3.43it/s, est. speed input: 3540.11 toks/s, output: 3.46 toks/s]
Processed prompts:  31%|       | 158/512 [00:45<01:43,  3.43it/s, est. speed input: 3539.63 toks/s, output: 3.46 toks/s]
Processed prompts:  32%|      | 162/512 [00:46<01:42,  3.43it/s, est. speed input: 3538.77 toks/s, output: 3.46 toks/s]
Processed prompts:  32%|      | 166/512 [00:48<01:40,  3.43it/s, est. speed input: 3538.47 toks/s, output: 3.46 toks/s]
Processed prompts:  33%|      | 170/512 [00:49<01:39,  3.42it/s, est. speed input: 3537.12 toks/s, output: 3.45 toks/s]
Processed prompts:  34%|      | 174/512 [00:50<01:38,  3.42it/s, est. speed input: 3536.34 toks/s, output: 3.45 toks/s]
Processed prompts:  35%|      | 178/512 [00:51<01:37,  3.42it/s, est. speed input: 3535.76 toks/s, output: 3.45 toks/s]
Processed prompts:  36%|      | 182/512 [00:52<01:36,  3.43it/s, est. speed input: 3535.19 toks/s, output: 3.45 toks/s]
Processed prompts:  36%|      | 186/512 [00:53<01:35,  3.42it/s, est. speed input: 3534.36 toks/s, output: 3.45 toks/s]
Processed prompts:  37%|      | 190/512 [00:55<01:33,  3.43it/s, est. speed input: 3533.97 toks/s, output: 3.45 toks/s]
Processed prompts:  38%|      | 194/512 [00:56<01:32,  3.42it/s, est. speed input: 3533.33 toks/s, output: 3.45 toks/s]
Processed prompts:  39%|      | 198/512 [00:57<01:31,  3.43it/s, est. speed input: 3532.84 toks/s, output: 3.45 toks/s]
Processed prompts:  39%|      | 202/512 [00:58<01:24,  3.66it/s, est. speed input: 3547.38 toks/s, output: 3.46 toks/s]
Processed prompts:  40%|      | 206/512 [00:59<01:25,  3.59it/s, est. speed input: 3546.64 toks/s, output: 3.46 toks/s]
Processed prompts:  41%|      | 210/512 [01:00<01:25,  3.53it/s, est. speed input: 3545.66 toks/s, output: 3.46 toks/s]
Processed prompts:  42%|     | 214/512 [01:01<01:25,  3.50it/s, est. speed input: 3544.93 toks/s, output: 3.46 toks/s]
Processed prompts:  43%|     | 218/512 [01:02<01:24,  3.47it/s, est. speed input: 3543.75 toks/s, output: 3.46 toks/s]
Processed prompts:  43%|     | 222/512 [01:04<01:24,  3.45it/s, est. speed input: 3542.65 toks/s, output: 3.46 toks/s]
Processed prompts:  44%|     | 226/512 [01:05<01:23,  3.44it/s, est. speed input: 3542.19 toks/s, output: 3.46 toks/s]
Processed prompts:  45%|     | 230/512 [01:06<01:22,  3.43it/s, est. speed input: 3541.29 toks/s, output: 3.46 toks/s]
Processed prompts:  46%|     | 234/512 [01:07<01:21,  3.43it/s, est. speed input: 3540.56 toks/s, output: 3.46 toks/s]
Processed prompts:  46%|     | 238/512 [01:08<01:19,  3.43it/s, est. speed input: 3539.96 toks/s, output: 3.46 toks/s]
Processed prompts:  47%|     | 242/512 [01:10<01:18,  3.43it/s, est. speed input: 3539.47 toks/s, output: 3.46 toks/s]
Processed prompts:  48%|     | 246/512 [01:11<01:17,  3.42it/s, est. speed input: 3538.74 toks/s, output: 3.46 toks/s]
Processed prompts:  49%|     | 250/512 [01:12<01:16,  3.43it/s, est. speed input: 3538.34 toks/s, output: 3.46 toks/s]
Processed prompts:  50%|     | 254/512 [01:13<01:15,  3.42it/s, est. speed input: 3537.51 toks/s, output: 3.45 toks/s]
Processed prompts:  50%|     | 258/512 [01:14<01:14,  3.41it/s, est. speed input: 3536.49 toks/s, output: 3.45 toks/s]
Processed prompts:  51%|     | 262/512 [01:15<01:13,  3.41it/s, est. speed input: 3535.92 toks/s, output: 3.45 toks/s]
Processed prompts:  52%|    | 266/512 [01:17<01:12,  3.41it/s, est. speed input: 3535.33 toks/s, output: 3.45 toks/s]
Processed prompts:  53%|    | 270/512 [01:18<01:10,  3.41it/s, est. speed input: 3534.67 toks/s, output: 3.45 toks/s]
Processed prompts:  54%|    | 274/512 [01:19<01:09,  3.42it/s, est. speed input: 3534.33 toks/s, output: 3.45 toks/s]
Processed prompts:  54%|    | 278/512 [01:20<01:08,  3.42it/s, est. speed input: 3533.97 toks/s, output: 3.45 toks/s]
Processed prompts:  55%|    | 282/512 [01:21<01:07,  3.42it/s, est. speed input: 3533.54 toks/s, output: 3.45 toks/s]
Processed prompts:  56%|    | 286/512 [01:22<01:06,  3.42it/s, est. speed input: 3533.15 toks/s, output: 3.45 toks/s]
Processed prompts:  57%|    | 290/512 [01:24<01:04,  3.42it/s, est. speed input: 3532.82 toks/s, output: 3.45 toks/s]
Processed prompts:  57%|    | 294/512 [01:25<01:03,  3.42it/s, est. speed input: 3532.41 toks/s, output: 3.45 toks/s]
Processed prompts:  58%|    | 298/512 [01:26<01:02,  3.41it/s, est. speed input: 3531.55 toks/s, output: 3.45 toks/s]
Processed prompts:  59%|    | 302/512 [01:27<01:01,  3.41it/s, est. speed input: 3531.10 toks/s, output: 3.45 toks/s]
Processed prompts:  60%|    | 306/512 [01:28<00:56,  3.66it/s, est. speed input: 3541.32 toks/s, output: 3.46 toks/s]
Processed prompts:  61%|    | 310/512 [01:29<00:56,  3.58it/s, est. speed input: 3540.62 toks/s, output: 3.46 toks/s]
Processed prompts:  61%|   | 314/512 [01:30<00:56,  3.53it/s, est. speed input: 3540.19 toks/s, output: 3.46 toks/s]
Processed prompts:  62%|   | 318/512 [01:31<00:55,  3.50it/s, est. speed input: 3539.62 toks/s, output: 3.46 toks/s]
Processed prompts:  63%|   | 322/512 [01:33<00:54,  3.47it/s, est. speed input: 3539.10 toks/s, output: 3.46 toks/s]
Processed prompts:  64%|   | 326/512 [01:34<00:53,  3.45it/s, est. speed input: 3538.56 toks/s, output: 3.46 toks/s]
Processed prompts:  64%|   | 330/512 [01:35<00:52,  3.44it/s, est. speed input: 3538.10 toks/s, output: 3.46 toks/s]
Processed prompts:  65%|   | 334/512 [01:36<00:51,  3.44it/s, est. speed input: 3537.70 toks/s, output: 3.45 toks/s]
Processed prompts:  66%|   | 338/512 [01:37<00:50,  3.43it/s, est. speed input: 3537.20 toks/s, output: 3.45 toks/s]
Processed prompts:  67%|   | 342/512 [01:39<00:49,  3.42it/s, est. speed input: 3536.66 toks/s, output: 3.45 toks/s]
Processed prompts:  68%|   | 346/512 [01:40<00:48,  3.41it/s, est. speed input: 3535.92 toks/s, output: 3.45 toks/s]
Processed prompts:  68%|   | 350/512 [01:41<00:47,  3.42it/s, est. speed input: 3535.57 toks/s, output: 3.45 toks/s]
Processed prompts:  69%|   | 354/512 [01:42<00:46,  3.42it/s, est. speed input: 3535.17 toks/s, output: 3.45 toks/s]
Processed prompts:  70%|   | 358/512 [01:43<00:45,  3.42it/s, est. speed input: 3534.73 toks/s, output: 3.45 toks/s]
Processed prompts:  71%|   | 362/512 [01:44<00:43,  3.42it/s, est. speed input: 3534.40 toks/s, output: 3.45 toks/s]
Processed prompts:  71%|  | 366/512 [01:46<00:42,  3.42it/s, est. speed input: 3534.00 toks/s, output: 3.45 toks/s]
Processed prompts:  72%|  | 370/512 [01:47<00:41,  3.42it/s, est. speed input: 3533.54 toks/s, output: 3.45 toks/s]
Processed prompts:  73%|  | 374/512 [01:48<00:40,  3.42it/s, est. speed input: 3533.16 toks/s, output: 3.45 toks/s]
Processed prompts:  74%|  | 378/512 [01:49<00:39,  3.41it/s, est. speed input: 3532.70 toks/s, output: 3.45 toks/s]
Processed prompts:  75%|  | 382/512 [01:50<00:38,  3.41it/s, est. speed input: 3532.28 toks/s, output: 3.45 toks/s]
Processed prompts:  75%|  | 386/512 [01:51<00:37,  3.40it/s, est. speed input: 3531.55 toks/s, output: 3.45 toks/s]
Processed prompts:  76%|  | 390/512 [01:53<00:35,  3.41it/s, est. speed input: 3531.17 toks/s, output: 3.45 toks/s]
Processed prompts:  77%|  | 394/512 [01:54<00:34,  3.41it/s, est. speed input: 3530.86 toks/s, output: 3.45 toks/s]
Processed prompts:  78%|  | 398/512 [01:55<00:33,  3.41it/s, est. speed input: 3530.58 toks/s, output: 3.45 toks/s]
Processed prompts:  79%|  | 402/512 [01:56<00:32,  3.41it/s, est. speed input: 3530.26 toks/s, output: 3.45 toks/s]
Processed prompts:  79%|  | 406/512 [01:57<00:31,  3.42it/s, est. speed input: 3530.04 toks/s, output: 3.45 toks/s]
Processed prompts:  80%|  | 410/512 [01:58<00:29,  3.42it/s, est. speed input: 3529.75 toks/s, output: 3.45 toks/s]
Processed prompts:  81%|  | 414/512 [02:00<00:28,  3.42it/s, est. speed input: 3529.42 toks/s, output: 3.45 toks/s]
Processed prompts:  82%| | 418/512 [02:01<00:27,  3.42it/s, est. speed input: 3529.13 toks/s, output: 3.45 toks/s]
Processed prompts:  82%| | 422/512 [02:02<00:26,  3.42it/s, est. speed input: 3528.81 toks/s, output: 3.45 toks/s]
Processed prompts:  83%| | 426/512 [02:03<00:25,  3.41it/s, est. speed input: 3528.23 toks/s, output: 3.45 toks/s]
Processed prompts:  84%| | 430/512 [02:04<00:24,  3.41it/s, est. speed input: 3527.96 toks/s, output: 3.45 toks/s]
Processed prompts:  85%| | 434/512 [02:05<00:21,  3.67it/s, est. speed input: 3535.26 toks/s, output: 3.45 toks/s]
Processed prompts:  86%| | 438/512 [02:06<00:20,  3.58it/s, est. speed input: 3534.61 toks/s, output: 3.45 toks/s]
Processed prompts:  86%| | 442/512 [02:08<00:19,  3.53it/s, est. speed input: 3534.34 toks/s, output: 3.45 toks/s]
Processed prompts:  87%| | 446/512 [02:09<00:18,  3.49it/s, est. speed input: 3533.94 toks/s, output: 3.45 toks/s]
Processed prompts:  88%| | 450/512 [02:10<00:17,  3.47it/s, est. speed input: 3533.53 toks/s, output: 3.45 toks/s]
Processed prompts:  89%| | 454/512 [02:11<00:16,  3.45it/s, est. speed input: 3533.17 toks/s, output: 3.45 toks/s]
Processed prompts:  89%| | 458/512 [02:12<00:15,  3.44it/s, est. speed input: 3532.76 toks/s, output: 3.45 toks/s]
Processed prompts:  90%| | 462/512 [02:13<00:14,  3.43it/s, est. speed input: 3532.49 toks/s, output: 3.45 toks/s]
Processed prompts:  91%| | 466/512 [02:15<00:13,  3.43it/s, est. speed input: 3532.20 toks/s, output: 3.45 toks/s]
Processed prompts:  92%|| 470/512 [02:16<00:12,  3.43it/s, est. speed input: 3531.96 toks/s, output: 3.45 toks/s]
Processed prompts:  93%|| 474/512 [02:17<00:11,  3.42it/s, est. speed input: 3531.51 toks/s, output: 3.45 toks/s]
Processed prompts:  93%|| 478/512 [02:18<00:09,  3.42it/s, est. speed input: 3531.29 toks/s, output: 3.45 toks/s]
Processed prompts:  94%|| 482/512 [02:19<00:08,  3.42it/s, est. speed input: 3531.02 toks/s, output: 3.45 toks/s]
Processed prompts:  95%|| 486/512 [02:20<00:07,  3.41it/s, est. speed input: 3530.64 toks/s, output: 3.45 toks/s]
Processed prompts:  96%|| 490/512 [02:22<00:06,  3.41it/s, est. speed input: 3530.35 toks/s, output: 3.45 toks/s]
Processed prompts:  96%|| 494/512 [02:23<00:05,  3.41it/s, est. speed input: 3530.07 toks/s, output: 3.45 toks/s]
Processed prompts:  97%|| 498/512 [02:24<00:04,  3.42it/s, est. speed input: 3529.90 toks/s, output: 3.45 toks/s]
Processed prompts:  98%|| 502/512 [02:25<00:02,  3.42it/s, est. speed input: 3529.74 toks/s, output: 3.45 toks/s]
Processed prompts:  99%|| 506/512 [02:26<00:01,  3.42it/s, est. speed input: 3529.43 toks/s, output: 3.45 toks/s]
Processed prompts: 100%|| 510/512 [02:27<00:00,  3.68it/s, est. speed input: 3535.79 toks/s, output: 3.45 toks/s]
Processed prompts: 100%|| 512/512 [02:27<00:00,  3.68it/s, est. speed input: 3549.65 toks/s, output: 3.47 toks/s]
Processed prompts: 100%|| 512/512 [02:27<00:00,  3.47it/s, est. speed input: 3549.65 toks/s, output: 3.47 toks/s]
[rank0]:[W127 10:05:15.427648422 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-27 10:05:19
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Qwen2.5-14B-FP8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-27 10:05:30 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-27 10:05:30 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=2474927) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2474927) WARNING 01-27 10:07:41 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 3.40 requests/s, 3489.77 total tokens/s, 3.40 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-27 10:05:30] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 10:05:30] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 10:05:30] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 10:05:30] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 10:05:30] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 10:05:30] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 10:05:30] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 10:05:30] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 10:05:30] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 10:05:30] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 10:05:30] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 10:05:30] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 10:05:30] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 10:05:30] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-27 10:05:34] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 10:05:34] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 10:05:34] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 10:05:34] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 10:05:34] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 10:05:34] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 10:05:34] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 10:05:34] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 10:05:34] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 10:05:34] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 10:05:34] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 10:05:34] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 10:05:34] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 10:05:34] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=2474927) [2026-01-27 10:05:35] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=2474927) [2026-01-27 10:05:35] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2474927) [2026-01-27 10:05:35] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=2474927) [2026-01-27 10:05:35] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=2474927) [2026-01-27 10:05:35] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=2474927) [2026-01-27 10:05:35] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=2474927) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=2474927) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:26,  8.70s/it]
(EngineCore_DP0 pid=2474927) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:44<00:49, 24.57s/it]
(EngineCore_DP0 pid=2474927) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [01:16<00:28, 28.11s/it]
(EngineCore_DP0 pid=2474927) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:50<00:00, 30.52s/it]
(EngineCore_DP0 pid=2474927) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:50<00:00, 27.73s/it]
(EngineCore_DP0 pid=2474927) 
(EngineCore_DP0 pid=2474927) [2026-01-27 10:07:27] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 6848] -> 1D uint8
(EngineCore_DP0 pid=2474927) [2026-01-27 10:07:27] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 30736384 bytes
(EngineCore_DP0 pid=2474927) [2026-01-27 10:07:27] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 6848] -> 1D uint8
(EngineCore_DP0 pid=2474927) [2026-01-27 10:07:27] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 21954560 bytes
(EngineCore_DP0 pid=2474927) [2026-01-27 10:07:27] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 6848] -> 1D uint8
(EngineCore_DP0 pid=2474927) [2026-01-27 10:07:27] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 118554624 bytes
(EngineCore_DP0 pid=2474927) [2026-01-27 10:07:27] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 18432] -> 1D uint8
(EngineCore_DP0 pid=2474927) [2026-01-27 10:07:27] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 58982400 bytes
(EngineCore_DP0 pid=2474927) 2026-01-27 10:07:37,525 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=2474927) 2026-01-27 10:07:38,451 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   0%|          | 1/1024 [00:00<09:41,  1.76it/s]
Adding requests:   0%|          | 2/1024 [00:00<05:07,  3.33it/s]
Adding requests:   0%|          | 4/1024 [00:00<02:45,  6.15it/s]
Adding requests:   1%|          | 6/1024 [00:00<01:53,  8.96it/s]
Adding requests:   1%|          | 9/1024 [00:01<01:13, 13.73it/s]
Adding requests:   1%|         | 15/1024 [00:01<00:40, 24.85it/s]
Adding requests:   3%|         | 27/1024 [00:01<00:20, 49.02it/s]
Adding requests:   4%|         | 45/1024 [00:01<00:11, 83.40it/s]
Adding requests:   7%|         | 69/1024 [00:01<00:07, 126.39it/s]
Adding requests:  10%|         | 101/1024 [00:01<00:05, 180.79it/s]
Adding requests:  14%|        | 140/1024 [00:01<00:03, 240.08it/s]
Adding requests:  18%|        | 181/1024 [00:01<00:02, 288.97it/s]
Adding requests:  22%|       | 226/1024 [00:01<00:02, 335.24it/s]
Adding requests:  26%|       | 268/1024 [00:01<00:02, 358.01it/s]
Adding requests:  31%|       | 314/1024 [00:02<00:01, 386.69it/s]
Adding requests:  35%|      | 359/1024 [00:02<00:01, 405.38it/s]
Adding requests:  40%|      | 405/1024 [00:02<00:01, 418.13it/s]
Adding requests:  44%|     | 449/1024 [00:02<00:01, 421.85it/s]
Adding requests:  48%|     | 495/1024 [00:02<00:01, 432.09it/s]
Adding requests:  53%|    | 539/1024 [00:02<00:01, 410.49it/s]
Adding requests:  57%|    | 581/1024 [00:02<00:01, 402.19it/s]
Adding requests:  61%|    | 623/1024 [00:02<00:00, 406.94it/s]
Adding requests:  65%|   | 664/1024 [00:02<00:00, 407.17it/s]
Adding requests:  69%|   | 708/1024 [00:03<00:00, 415.00it/s]
Adding requests:  73%|  | 750/1024 [00:03<00:00, 409.89it/s]
Adding requests:  77%|  | 792/1024 [00:03<00:00, 410.26it/s]
Adding requests:  82%| | 837/1024 [00:03<00:00, 419.44it/s]
Adding requests:  86%| | 879/1024 [00:03<00:00, 411.71it/s]
Adding requests:  90%| | 922/1024 [00:03<00:00, 416.37it/s]
Adding requests:  94%|| 964/1024 [00:03<00:00, 407.06it/s]
Adding requests:  98%|| 1005/1024 [00:03<00:00, 406.14it/s]
Adding requests: 100%|| 1024/1024 [00:03<00:00, 270.39it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 7/1024 [00:00<02:24,  7.02it/s, est. speed input: 7187.02 toks/s, output: 7.02 toks/s]
Processed prompts:   1%|         | 15/1024 [00:03<03:57,  4.26it/s, est. speed input: 4612.92 toks/s, output: 4.50 toks/s]
Processed prompts:   2%|         | 23/1024 [00:05<04:21,  3.82it/s, est. speed input: 4160.18 toks/s, output: 4.06 toks/s]
Processed prompts:   3%|         | 31/1024 [00:08<04:32,  3.65it/s, est. speed input: 3966.60 toks/s, output: 3.87 toks/s]
Processed prompts:   4%|         | 39/1024 [00:10<04:36,  3.57it/s, est. speed input: 3863.49 toks/s, output: 3.77 toks/s]
Processed prompts:   5%|         | 47/1024 [00:12<04:37,  3.51it/s, est. speed input: 3797.08 toks/s, output: 3.71 toks/s]
Processed prompts:   5%|         | 55/1024 [00:15<04:38,  3.48it/s, est. speed input: 3748.42 toks/s, output: 3.66 toks/s]
Processed prompts:   6%|         | 63/1024 [00:17<04:37,  3.46it/s, est. speed input: 3714.46 toks/s, output: 3.63 toks/s]
Processed prompts:   7%|         | 71/1024 [00:19<04:36,  3.45it/s, est. speed input: 3689.11 toks/s, output: 3.60 toks/s]
Processed prompts:   8%|         | 79/1024 [00:22<04:35,  3.43it/s, est. speed input: 3667.89 toks/s, output: 3.58 toks/s]
Processed prompts:   8%|         | 87/1024 [00:24<04:33,  3.43it/s, est. speed input: 3651.64 toks/s, output: 3.57 toks/s]
Processed prompts:   9%|         | 95/1024 [00:26<04:31,  3.42it/s, est. speed input: 3637.44 toks/s, output: 3.55 toks/s]
Processed prompts:  10%|         | 103/1024 [00:29<04:29,  3.42it/s, est. speed input: 3625.60 toks/s, output: 3.54 toks/s]
Processed prompts:  11%|         | 111/1024 [00:31<04:27,  3.42it/s, est. speed input: 3615.83 toks/s, output: 3.53 toks/s]
Processed prompts:  12%|        | 119/1024 [00:33<04:25,  3.41it/s, est. speed input: 3607.30 toks/s, output: 3.52 toks/s]
Processed prompts:  12%|        | 127/1024 [00:36<04:22,  3.41it/s, est. speed input: 3599.67 toks/s, output: 3.52 toks/s]
Processed prompts:  13%|        | 135/1024 [00:38<04:20,  3.41it/s, est. speed input: 3591.93 toks/s, output: 3.51 toks/s]
Processed prompts:  14%|        | 143/1024 [00:40<04:18,  3.41it/s, est. speed input: 3585.94 toks/s, output: 3.50 toks/s]
Processed prompts:  15%|        | 151/1024 [00:43<04:16,  3.41it/s, est. speed input: 3580.72 toks/s, output: 3.50 toks/s]
Processed prompts:  16%|        | 159/1024 [00:45<04:13,  3.41it/s, est. speed input: 3576.01 toks/s, output: 3.49 toks/s]
Processed prompts:  16%|        | 167/1024 [00:47<04:11,  3.41it/s, est. speed input: 3571.70 toks/s, output: 3.49 toks/s]
Processed prompts:  17%|        | 175/1024 [00:50<04:09,  3.40it/s, est. speed input: 3566.96 toks/s, output: 3.48 toks/s]
Processed prompts:  18%|        | 183/1024 [00:52<04:07,  3.40it/s, est. speed input: 3563.33 toks/s, output: 3.48 toks/s]
Processed prompts:  19%|        | 191/1024 [00:54<04:04,  3.40it/s, est. speed input: 3559.92 toks/s, output: 3.48 toks/s]
Processed prompts:  19%|        | 199/1024 [00:57<03:55,  3.51it/s, est. speed input: 3571.52 toks/s, output: 3.49 toks/s]
Processed prompts:  20%|        | 207/1024 [00:59<03:55,  3.48it/s, est. speed input: 3568.03 toks/s, output: 3.48 toks/s]
Processed prompts:  21%|        | 215/1024 [01:01<03:54,  3.45it/s, est. speed input: 3564.36 toks/s, output: 3.48 toks/s]
Processed prompts:  22%|       | 223/1024 [01:04<03:53,  3.43it/s, est. speed input: 3560.78 toks/s, output: 3.48 toks/s]
Processed prompts:  23%|       | 231/1024 [01:06<03:51,  3.42it/s, est. speed input: 3557.73 toks/s, output: 3.47 toks/s]
Processed prompts:  23%|       | 239/1024 [01:08<03:50,  3.41it/s, est. speed input: 3555.02 toks/s, output: 3.47 toks/s]
Processed prompts:  24%|       | 247/1024 [01:11<03:47,  3.41it/s, est. speed input: 3552.82 toks/s, output: 3.47 toks/s]
Processed prompts:  25%|       | 255/1024 [01:13<03:45,  3.40it/s, est. speed input: 3550.14 toks/s, output: 3.47 toks/s]
Processed prompts:  26%|       | 263/1024 [01:15<03:43,  3.40it/s, est. speed input: 3547.80 toks/s, output: 3.46 toks/s]
Processed prompts:  26%|       | 271/1024 [01:18<03:41,  3.40it/s, est. speed input: 3545.55 toks/s, output: 3.46 toks/s]
Processed prompts:  27%|       | 279/1024 [01:20<03:39,  3.40it/s, est. speed input: 3543.50 toks/s, output: 3.46 toks/s]
Processed prompts:  28%|       | 287/1024 [01:22<03:37,  3.40it/s, est. speed input: 3541.50 toks/s, output: 3.46 toks/s]
Processed prompts:  29%|       | 295/1024 [01:25<03:35,  3.39it/s, est. speed input: 3539.20 toks/s, output: 3.46 toks/s]
Processed prompts:  30%|       | 303/1024 [01:27<03:25,  3.50it/s, est. speed input: 3547.70 toks/s, output: 3.46 toks/s]
Processed prompts:  30%|       | 311/1024 [01:29<03:25,  3.47it/s, est. speed input: 3545.77 toks/s, output: 3.46 toks/s]
Processed prompts:  31%|       | 319/1024 [01:32<03:24,  3.45it/s, est. speed input: 3544.10 toks/s, output: 3.46 toks/s]
Processed prompts:  32%|      | 327/1024 [01:34<03:23,  3.43it/s, est. speed input: 3542.49 toks/s, output: 3.46 toks/s]
Processed prompts:  33%|      | 335/1024 [01:36<03:21,  3.42it/s, est. speed input: 3540.81 toks/s, output: 3.46 toks/s]
Processed prompts:  33%|      | 343/1024 [01:39<03:19,  3.41it/s, est. speed input: 3538.98 toks/s, output: 3.46 toks/s]
Processed prompts:  34%|      | 351/1024 [01:41<03:17,  3.40it/s, est. speed input: 3537.52 toks/s, output: 3.45 toks/s]
Processed prompts:  35%|      | 359/1024 [01:43<03:15,  3.40it/s, est. speed input: 3536.15 toks/s, output: 3.45 toks/s]
Processed prompts:  36%|      | 367/1024 [01:46<03:13,  3.40it/s, est. speed input: 3534.98 toks/s, output: 3.45 toks/s]
Processed prompts:  37%|      | 375/1024 [01:48<03:11,  3.40it/s, est. speed input: 3533.42 toks/s, output: 3.45 toks/s]
Processed prompts:  37%|      | 383/1024 [01:51<03:08,  3.40it/s, est. speed input: 3532.39 toks/s, output: 3.45 toks/s]
Processed prompts:  38%|      | 391/1024 [01:53<03:06,  3.40it/s, est. speed input: 3531.23 toks/s, output: 3.45 toks/s]
Processed prompts:  39%|      | 399/1024 [01:55<03:04,  3.40it/s, est. speed input: 3530.04 toks/s, output: 3.45 toks/s]
Processed prompts:  40%|      | 407/1024 [01:58<03:01,  3.40it/s, est. speed input: 3529.08 toks/s, output: 3.45 toks/s]
Processed prompts:  41%|      | 415/1024 [02:00<02:59,  3.39it/s, est. speed input: 3527.78 toks/s, output: 3.45 toks/s]
Processed prompts:  41%|     | 423/1024 [02:02<02:57,  3.39it/s, est. speed input: 3526.86 toks/s, output: 3.44 toks/s]
Processed prompts:  42%|     | 431/1024 [02:04<02:48,  3.51it/s, est. speed input: 3533.38 toks/s, output: 3.45 toks/s]
Processed prompts:  43%|     | 439/1024 [02:07<02:48,  3.48it/s, est. speed input: 3532.54 toks/s, output: 3.45 toks/s]
Processed prompts:  44%|     | 447/1024 [02:09<02:46,  3.46it/s, est. speed input: 3531.60 toks/s, output: 3.45 toks/s]
Processed prompts:  44%|     | 455/1024 [02:11<02:45,  3.44it/s, est. speed input: 3530.88 toks/s, output: 3.45 toks/s]
Processed prompts:  45%|     | 463/1024 [02:14<02:43,  3.43it/s, est. speed input: 3529.96 toks/s, output: 3.45 toks/s]
Processed prompts:  46%|     | 471/1024 [02:16<02:41,  3.42it/s, est. speed input: 3529.24 toks/s, output: 3.45 toks/s]
Processed prompts:  47%|     | 479/1024 [02:19<02:39,  3.42it/s, est. speed input: 3528.62 toks/s, output: 3.45 toks/s]
Processed prompts:  48%|     | 487/1024 [02:21<02:37,  3.42it/s, est. speed input: 3528.05 toks/s, output: 3.45 toks/s]
Processed prompts:  48%|     | 495/1024 [02:23<02:34,  3.41it/s, est. speed input: 3527.40 toks/s, output: 3.44 toks/s]
Processed prompts:  49%|     | 503/1024 [02:26<02:32,  3.41it/s, est. speed input: 3526.54 toks/s, output: 3.44 toks/s]
Processed prompts:  50%|     | 511/1024 [02:28<02:30,  3.41it/s, est. speed input: 3526.03 toks/s, output: 3.44 toks/s]
Processed prompts:  51%|     | 519/1024 [02:30<02:28,  3.41it/s, est. speed input: 3525.44 toks/s, output: 3.44 toks/s]
Processed prompts:  51%|    | 527/1024 [02:33<02:25,  3.41it/s, est. speed input: 3524.96 toks/s, output: 3.44 toks/s]
Processed prompts:  52%|    | 535/1024 [02:35<02:23,  3.41it/s, est. speed input: 3524.32 toks/s, output: 3.44 toks/s]
Processed prompts:  53%|    | 543/1024 [02:37<02:21,  3.40it/s, est. speed input: 3523.67 toks/s, output: 3.44 toks/s]
Processed prompts:  54%|    | 551/1024 [02:40<02:18,  3.40it/s, est. speed input: 3523.13 toks/s, output: 3.44 toks/s]
Processed prompts:  55%|    | 559/1024 [02:42<02:16,  3.40it/s, est. speed input: 3522.60 toks/s, output: 3.44 toks/s]
Processed prompts:  55%|    | 567/1024 [02:44<02:14,  3.41it/s, est. speed input: 3522.17 toks/s, output: 3.44 toks/s]
Processed prompts:  56%|    | 575/1024 [02:47<02:12,  3.40it/s, est. speed input: 3521.44 toks/s, output: 3.44 toks/s]
Processed prompts:  57%|    | 583/1024 [02:49<02:09,  3.40it/s, est. speed input: 3521.01 toks/s, output: 3.44 toks/s]
Processed prompts:  58%|    | 591/1024 [02:51<02:07,  3.40it/s, est. speed input: 3520.57 toks/s, output: 3.44 toks/s]
Processed prompts:  58%|    | 599/1024 [02:54<02:04,  3.41it/s, est. speed input: 3520.23 toks/s, output: 3.44 toks/s]
Processed prompts:  59%|    | 607/1024 [02:56<02:02,  3.41it/s, est. speed input: 3519.81 toks/s, output: 3.44 toks/s]
Processed prompts:  60%|    | 615/1024 [02:58<02:00,  3.40it/s, est. speed input: 3519.06 toks/s, output: 3.44 toks/s]
Processed prompts:  61%|    | 623/1024 [03:01<01:57,  3.40it/s, est. speed input: 3518.56 toks/s, output: 3.44 toks/s]
Processed prompts:  62%|   | 631/1024 [03:03<01:55,  3.40it/s, est. speed input: 3518.12 toks/s, output: 3.44 toks/s]
Processed prompts:  62%|   | 639/1024 [03:06<01:53,  3.40it/s, est. speed input: 3517.79 toks/s, output: 3.44 toks/s]
Processed prompts:  63%|   | 647/1024 [03:08<01:50,  3.40it/s, est. speed input: 3517.45 toks/s, output: 3.44 toks/s]
Processed prompts:  64%|   | 655/1024 [03:10<01:48,  3.40it/s, est. speed input: 3516.79 toks/s, output: 3.43 toks/s]
Processed prompts:  65%|   | 663/1024 [03:13<01:46,  3.40it/s, est. speed input: 3516.34 toks/s, output: 3.43 toks/s]
Processed prompts:  66%|   | 671/1024 [03:15<01:43,  3.40it/s, est. speed input: 3515.94 toks/s, output: 3.43 toks/s]
Processed prompts:  66%|   | 679/1024 [03:17<01:41,  3.40it/s, est. speed input: 3515.67 toks/s, output: 3.43 toks/s]
Processed prompts:  67%|   | 687/1024 [03:20<01:38,  3.40it/s, est. speed input: 3515.38 toks/s, output: 3.43 toks/s]
Processed prompts:  68%|   | 695/1024 [03:22<01:36,  3.40it/s, est. speed input: 3514.98 toks/s, output: 3.43 toks/s]
Processed prompts:  69%|   | 703/1024 [03:24<01:34,  3.40it/s, est. speed input: 3514.67 toks/s, output: 3.43 toks/s]
Processed prompts:  69%|   | 711/1024 [03:27<01:31,  3.40it/s, est. speed input: 3514.38 toks/s, output: 3.43 toks/s]
Processed prompts:  70%|   | 719/1024 [03:29<01:29,  3.40it/s, est. speed input: 3513.99 toks/s, output: 3.43 toks/s]
Processed prompts:  71%|   | 727/1024 [03:31<01:27,  3.41it/s, est. speed input: 3513.75 toks/s, output: 3.43 toks/s]
Processed prompts:  72%|  | 735/1024 [03:34<01:25,  3.40it/s, est. speed input: 3513.19 toks/s, output: 3.43 toks/s]
Processed prompts:  73%|  | 743/1024 [03:36<01:22,  3.40it/s, est. speed input: 3512.85 toks/s, output: 3.43 toks/s]
Processed prompts:  73%|  | 751/1024 [03:38<01:20,  3.40it/s, est. speed input: 3512.55 toks/s, output: 3.43 toks/s]
Processed prompts:  74%|  | 759/1024 [03:41<01:17,  3.40it/s, est. speed input: 3512.25 toks/s, output: 3.43 toks/s]
Processed prompts:  75%|  | 767/1024 [03:43<01:15,  3.40it/s, est. speed input: 3511.97 toks/s, output: 3.43 toks/s]
Processed prompts:  76%|  | 775/1024 [03:45<01:13,  3.40it/s, est. speed input: 3511.56 toks/s, output: 3.43 toks/s]
Processed prompts:  76%|  | 783/1024 [03:48<01:08,  3.52it/s, est. speed input: 3515.35 toks/s, output: 3.43 toks/s]
Processed prompts:  77%|  | 791/1024 [03:50<01:06,  3.48it/s, est. speed input: 3515.09 toks/s, output: 3.43 toks/s]
Processed prompts:  78%|  | 799/1024 [03:52<01:04,  3.46it/s, est. speed input: 3514.85 toks/s, output: 3.43 toks/s]
Processed prompts:  79%|  | 807/1024 [03:55<01:03,  3.44it/s, est. speed input: 3514.49 toks/s, output: 3.43 toks/s]
Processed prompts:  80%|  | 815/1024 [03:57<01:00,  3.43it/s, est. speed input: 3514.23 toks/s, output: 3.43 toks/s]
Processed prompts:  80%|  | 823/1024 [03:59<00:58,  3.42it/s, est. speed input: 3513.78 toks/s, output: 3.43 toks/s]
Processed prompts:  81%|  | 831/1024 [04:02<00:56,  3.42it/s, est. speed input: 3513.58 toks/s, output: 3.43 toks/s]
Processed prompts:  82%| | 839/1024 [04:04<00:54,  3.41it/s, est. speed input: 3513.32 toks/s, output: 3.43 toks/s]
Processed prompts:  83%| | 847/1024 [04:06<00:51,  3.41it/s, est. speed input: 3513.05 toks/s, output: 3.43 toks/s]
Processed prompts:  83%| | 855/1024 [04:09<00:49,  3.41it/s, est. speed input: 3512.73 toks/s, output: 3.43 toks/s]
Processed prompts:  84%| | 863/1024 [04:11<00:47,  3.40it/s, est. speed input: 3512.38 toks/s, output: 3.43 toks/s]
Processed prompts:  85%| | 871/1024 [04:13<00:44,  3.40it/s, est. speed input: 3512.12 toks/s, output: 3.43 toks/s]
Processed prompts:  86%| | 879/1024 [04:16<00:42,  3.40it/s, est. speed input: 3511.94 toks/s, output: 3.43 toks/s]
Processed prompts:  87%| | 887/1024 [04:18<00:40,  3.41it/s, est. speed input: 3511.72 toks/s, output: 3.43 toks/s]
Processed prompts:  87%| | 895/1024 [04:21<00:37,  3.40it/s, est. speed input: 3511.32 toks/s, output: 3.43 toks/s]
Processed prompts:  88%| | 903/1024 [04:23<00:35,  3.40it/s, est. speed input: 3511.08 toks/s, output: 3.43 toks/s]
Processed prompts:  89%| | 911/1024 [04:25<00:33,  3.40it/s, est. speed input: 3510.82 toks/s, output: 3.43 toks/s]
Processed prompts:  90%| | 919/1024 [04:28<00:30,  3.40it/s, est. speed input: 3510.61 toks/s, output: 3.43 toks/s]
Processed prompts:  91%| | 927/1024 [04:30<00:28,  3.40it/s, est. speed input: 3510.47 toks/s, output: 3.43 toks/s]
Processed prompts:  91%|| 935/1024 [04:32<00:26,  3.40it/s, est. speed input: 3510.12 toks/s, output: 3.43 toks/s]
Processed prompts:  92%|| 943/1024 [04:35<00:23,  3.40it/s, est. speed input: 3509.91 toks/s, output: 3.43 toks/s]
Processed prompts:  93%|| 951/1024 [04:37<00:21,  3.40it/s, est. speed input: 3509.75 toks/s, output: 3.43 toks/s]
Processed prompts:  94%|| 959/1024 [04:39<00:19,  3.40it/s, est. speed input: 3509.54 toks/s, output: 3.43 toks/s]
Processed prompts:  94%|| 967/1024 [04:42<00:16,  3.40it/s, est. speed input: 3509.32 toks/s, output: 3.43 toks/s]
Processed prompts:  95%|| 975/1024 [04:44<00:14,  3.40it/s, est. speed input: 3509.01 toks/s, output: 3.43 toks/s]
Processed prompts:  96%|| 983/1024 [04:46<00:12,  3.40it/s, est. speed input: 3508.85 toks/s, output: 3.43 toks/s]
Processed prompts:  97%|| 991/1024 [04:49<00:09,  3.40it/s, est. speed input: 3508.72 toks/s, output: 3.43 toks/s]
Processed prompts:  98%|| 999/1024 [04:51<00:07,  3.41it/s, est. speed input: 3508.57 toks/s, output: 3.43 toks/s]
Processed prompts:  98%|| 1007/1024 [04:53<00:04,  3.41it/s, est. speed input: 3508.42 toks/s, output: 3.43 toks/s]
Processed prompts:  99%|| 1015/1024 [04:56<00:02,  3.41it/s, est. speed input: 3508.30 toks/s, output: 3.43 toks/s]
Processed prompts: 100%|| 1023/1024 [04:56<00:00,  4.36it/s, est. speed input: 3528.33 toks/s, output: 3.45 toks/s]
Processed prompts: 100%|| 1024/1024 [04:56<00:00,  4.36it/s, est. speed input: 3531.78 toks/s, output: 3.45 toks/s]
Processed prompts: 100%|| 1024/1024 [04:56<00:00,  3.45it/s, est. speed input: 3531.78 toks/s, output: 3.45 toks/s]
[rank0]:[W127 10:12:42.505382727 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-27 10:12:56
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Qwen2.5-14B-FP8_M16384.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-27 10:13:09 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-27 10:13:09 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=2487258) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2487258) WARNING 01-27 10:15:24 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 3.41 requests/s, 3500.21 total tokens/s, 3.41 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-27 10:13:09] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 10:13:09] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 10:13:09] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 10:13:09] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 10:13:09] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 10:13:09] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 10:13:09] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 10:13:09] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 10:13:09] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 10:13:09] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 10:13:09] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 10:13:09] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 10:13:09] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 10:13:09] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-27 10:13:12] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 10:13:12] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 10:13:12] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 10:13:12] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 10:13:12] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 10:13:12] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 10:13:12] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 10:13:12] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 10:13:12] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 10:13:12] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 10:13:12] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 10:13:12] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 10:13:12] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 10:13:12] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=2487258) [2026-01-27 10:13:13] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=2487258) [2026-01-27 10:13:13] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2487258) [2026-01-27 10:13:13] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=2487258) [2026-01-27 10:13:13] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=2487258) [2026-01-27 10:13:13] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=2487258) [2026-01-27 10:13:13] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=2487258) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=2487258) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:26,  8.70s/it]
(EngineCore_DP0 pid=2487258) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:44<00:48, 24.41s/it]
(EngineCore_DP0 pid=2487258) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [01:16<00:28, 28.22s/it]
(EngineCore_DP0 pid=2487258) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:51<00:00, 30.68s/it]
(EngineCore_DP0 pid=2487258) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:51<00:00, 27.83s/it]
(EngineCore_DP0 pid=2487258) 
(EngineCore_DP0 pid=2487258) [2026-01-27 10:15:06] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 6848] -> 1D uint8
(EngineCore_DP0 pid=2487258) [2026-01-27 10:15:06] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 30736384 bytes
(EngineCore_DP0 pid=2487258) [2026-01-27 10:15:06] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 6848] -> 1D uint8
(EngineCore_DP0 pid=2487258) [2026-01-27 10:15:06] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 21954560 bytes
(EngineCore_DP0 pid=2487258) [2026-01-27 10:15:06] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 6848] -> 1D uint8
(EngineCore_DP0 pid=2487258) [2026-01-27 10:15:06] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 118554624 bytes
(EngineCore_DP0 pid=2487258) [2026-01-27 10:15:06] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 18432] -> 1D uint8
(EngineCore_DP0 pid=2487258) [2026-01-27 10:15:06] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 58982400 bytes
(EngineCore_DP0 pid=2487258) 2026-01-27 10:15:18,303 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=2487258) 2026-01-27 10:15:19,927 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   0%|          | 1/2048 [00:00<32:57,  1.04it/s]
Adding requests:   0%|          | 2/2048 [00:01<17:30,  1.95it/s]
Adding requests:   0%|          | 3/2048 [00:01<11:33,  2.95it/s]
Adding requests:   0%|          | 5/2048 [00:01<06:27,  5.27it/s]
Adding requests:   0%|          | 8/2048 [00:01<03:42,  9.18it/s]
Adding requests:   1%|          | 12/2048 [00:01<02:17, 14.80it/s]
Adding requests:   1%|          | 19/2048 [00:01<01:17, 26.16it/s]
Adding requests:   2%|         | 38/2048 [00:01<00:31, 63.55it/s]
Adding requests:   3%|         | 57/2048 [00:01<00:21, 94.64it/s]
Adding requests:   4%|         | 90/2048 [00:02<00:12, 154.65it/s]
Adding requests:   6%|         | 128/2048 [00:02<00:08, 215.33it/s]
Adding requests:   8%|         | 168/2048 [00:02<00:07, 266.62it/s]
Adding requests:  10%|         | 211/2048 [00:02<00:05, 310.70it/s]
Adding requests:  12%|        | 252/2048 [00:02<00:05, 336.80it/s]
Adding requests:  14%|        | 295/2048 [00:02<00:04, 362.55it/s]
Adding requests:  16%|        | 335/2048 [00:02<00:04, 373.10it/s]
Adding requests:  18%|        | 375/2048 [00:02<00:04, 380.06it/s]
Adding requests:  20%|        | 419/2048 [00:02<00:04, 397.01it/s]
Adding requests:  22%|       | 460/2048 [00:03<00:04, 396.77it/s]
Adding requests:  25%|       | 505/2048 [00:03<00:03, 412.36it/s]
Adding requests:  27%|       | 552/2048 [00:03<00:03, 428.59it/s]
Adding requests:  29%|       | 596/2048 [00:03<00:03, 418.78it/s]
Adding requests:  31%|       | 639/2048 [00:03<00:03, 419.57it/s]
Adding requests:  33%|      | 682/2048 [00:03<00:03, 414.69it/s]
Adding requests:  35%|      | 724/2048 [00:03<00:03, 405.02it/s]
Adding requests:  37%|      | 765/2048 [00:03<00:03, 398.11it/s]
Adding requests:  39%|      | 808/2048 [00:03<00:03, 405.83it/s]
Adding requests:  42%|     | 853/2048 [00:03<00:02, 405.16it/s]
Adding requests:  44%|     | 894/2048 [00:04<00:02, 400.49it/s]
Adding requests:  46%|     | 935/2048 [00:04<00:02, 402.83it/s]
Adding requests:  48%|     | 976/2048 [00:11<00:57, 18.66it/s] 
Adding requests:  49%|     | 1013/2048 [00:11<00:40, 25.25it/s]
Adding requests:  51%|    | 1053/2048 [00:11<00:28, 35.04it/s]
Adding requests:  53%|    | 1091/2048 [00:11<00:20, 47.43it/s]
Adding requests:  55%|    | 1133/2048 [00:11<00:13, 65.56it/s]
Adding requests:  57%|    | 1171/2048 [00:11<00:10, 85.96it/s]
Adding requests:  59%|    | 1212/2048 [00:11<00:07, 113.39it/s]
Adding requests:  61%|    | 1252/2048 [00:12<00:05, 144.41it/s]
Adding requests:  63%|   | 1291/2048 [00:12<00:04, 177.09it/s]
Adding requests:  65%|   | 1333/2048 [00:12<00:03, 215.76it/s]
Adding requests:  67%|   | 1376/2048 [00:12<00:02, 254.66it/s]
Adding requests:  69%|   | 1417/2048 [00:12<00:02, 287.10it/s]
Adding requests:  71%|  | 1460/2048 [00:12<00:01, 318.22it/s]
Adding requests:  73%|  | 1503/2048 [00:12<00:01, 344.58it/s]
Adding requests:  75%|  | 1545/2048 [00:12<00:01, 362.42it/s]
Adding requests:  77%|  | 1587/2048 [00:12<00:01, 370.67it/s]
Adding requests:  79%|  | 1628/2048 [00:13<00:01, 370.36it/s]
Adding requests:  81%| | 1668/2048 [00:13<00:01, 372.73it/s]
Adding requests:  84%| | 1711/2048 [00:13<00:00, 386.88it/s]
Adding requests:  86%| | 1752/2048 [00:13<00:00, 391.01it/s]
Adding requests:  88%| | 1796/2048 [00:13<00:00, 404.05it/s]
Adding requests:  90%| | 1838/2048 [00:13<00:00, 406.25it/s]
Adding requests:  92%|| 1880/2048 [00:13<00:00, 406.32it/s]
Adding requests:  94%|| 1923/2048 [00:13<00:00, 410.60it/s]
Adding requests:  96%|| 1966/2048 [00:13<00:00, 415.15it/s]
Adding requests:  98%|| 2008/2048 [00:13<00:00, 414.80it/s]
Adding requests: 100%|| 2048/2048 [00:14<00:00, 145.83it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 37/2048 [00:02<02:01, 16.60it/s, est. speed input: 16994.03 toks/s, output: 16.60 toks/s]
Processed prompts:   3%|         | 53/2048 [00:06<04:55,  6.74it/s, est. speed input: 7885.62 toks/s, output: 7.70 toks/s]  
Processed prompts:   3%|         | 69/2048 [00:11<06:33,  5.03it/s, est. speed input: 6121.04 toks/s, output: 5.98 toks/s]
Processed prompts:   4%|         | 85/2048 [00:16<07:31,  4.35it/s, est. speed input: 5367.89 toks/s, output: 5.24 toks/s]
Processed prompts:   5%|         | 101/2048 [00:20<08:06,  4.00it/s, est. speed input: 4952.33 toks/s, output: 4.84 toks/s]
Processed prompts:   6%|         | 117/2048 [00:25<08:28,  3.80it/s, est. speed input: 4687.35 toks/s, output: 4.58 toks/s]
Processed prompts:   6%|         | 133/2048 [00:30<08:41,  3.67it/s, est. speed input: 4504.89 toks/s, output: 4.40 toks/s]
Processed prompts:   7%|         | 149/2048 [00:34<08:48,  3.59it/s, est. speed input: 4370.13 toks/s, output: 4.27 toks/s]
Processed prompts:   8%|         | 165/2048 [00:39<08:52,  3.53it/s, est. speed input: 4266.72 toks/s, output: 4.17 toks/s]
Processed prompts:   9%|         | 181/2048 [00:44<08:53,  3.50it/s, est. speed input: 4184.87 toks/s, output: 4.09 toks/s]
Processed prompts:  10%|         | 197/2048 [00:48<08:45,  3.52it/s, est. speed input: 4137.65 toks/s, output: 4.04 toks/s]
Processed prompts:  10%|         | 213/2048 [00:53<08:45,  3.49it/s, est. speed input: 4081.30 toks/s, output: 3.99 toks/s]
Processed prompts:  11%|         | 229/2048 [00:58<08:44,  3.47it/s, est. speed input: 4034.04 toks/s, output: 3.94 toks/s]
Processed prompts:  12%|        | 245/2048 [01:02<08:42,  3.45it/s, est. speed input: 3993.75 toks/s, output: 3.90 toks/s]
Processed prompts:  13%|        | 261/2048 [01:07<08:39,  3.44it/s, est. speed input: 3959.02 toks/s, output: 3.87 toks/s]
Processed prompts:  14%|        | 277/2048 [01:12<08:36,  3.43it/s, est. speed input: 3928.49 toks/s, output: 3.84 toks/s]
Processed prompts:  14%|        | 293/2048 [01:16<08:24,  3.48it/s, est. speed input: 3913.99 toks/s, output: 3.82 toks/s]
Processed prompts:  15%|        | 309/2048 [01:21<08:23,  3.46it/s, est. speed input: 3889.84 toks/s, output: 3.80 toks/s]
Processed prompts:  16%|        | 325/2048 [01:26<08:20,  3.44it/s, est. speed input: 3868.33 toks/s, output: 3.78 toks/s]
Processed prompts:  17%|        | 341/2048 [01:30<08:16,  3.44it/s, est. speed input: 3849.42 toks/s, output: 3.76 toks/s]
Processed prompts:  17%|        | 357/2048 [01:35<08:13,  3.43it/s, est. speed input: 3832.01 toks/s, output: 3.74 toks/s]
Processed prompts:  18%|        | 373/2048 [01:40<08:09,  3.42it/s, est. speed input: 3816.21 toks/s, output: 3.73 toks/s]
Processed prompts:  19%|        | 389/2048 [01:44<08:05,  3.42it/s, est. speed input: 3801.71 toks/s, output: 3.71 toks/s]
Processed prompts:  20%|        | 405/2048 [01:49<08:00,  3.42it/s, est. speed input: 3788.25 toks/s, output: 3.70 toks/s]
Processed prompts:  21%|        | 421/2048 [01:53<07:49,  3.47it/s, est. speed input: 3784.09 toks/s, output: 3.70 toks/s]
Processed prompts:  21%|       | 437/2048 [01:58<07:46,  3.45it/s, est. speed input: 3772.76 toks/s, output: 3.68 toks/s]
Processed prompts:  22%|       | 453/2048 [02:03<07:43,  3.44it/s, est. speed input: 3762.14 toks/s, output: 3.67 toks/s]
Processed prompts:  23%|       | 469/2048 [02:07<07:39,  3.43it/s, est. speed input: 3752.49 toks/s, output: 3.66 toks/s]
Processed prompts:  24%|       | 485/2048 [02:12<07:36,  3.43it/s, est. speed input: 3743.16 toks/s, output: 3.66 toks/s]
Processed prompts:  24%|       | 501/2048 [02:17<07:31,  3.42it/s, est. speed input: 3734.83 toks/s, output: 3.65 toks/s]
Processed prompts:  25%|       | 517/2048 [02:22<07:27,  3.42it/s, est. speed input: 3726.79 toks/s, output: 3.64 toks/s]
Processed prompts:  26%|       | 533/2048 [02:26<07:23,  3.42it/s, est. speed input: 3719.27 toks/s, output: 3.63 toks/s]
Processed prompts:  27%|       | 549/2048 [02:31<07:18,  3.42it/s, est. speed input: 3712.33 toks/s, output: 3.63 toks/s]
Processed prompts:  28%|       | 565/2048 [02:36<07:14,  3.41it/s, est. speed input: 3705.50 toks/s, output: 3.62 toks/s]
Processed prompts:  28%|       | 581/2048 [02:40<07:09,  3.41it/s, est. speed input: 3699.40 toks/s, output: 3.61 toks/s]
Processed prompts:  29%|       | 597/2048 [02:45<07:05,  3.41it/s, est. speed input: 3693.36 toks/s, output: 3.61 toks/s]
Processed prompts:  30%|       | 613/2048 [02:50<07:00,  3.41it/s, est. speed input: 3687.93 toks/s, output: 3.60 toks/s]
Processed prompts:  31%|       | 629/2048 [02:54<06:56,  3.41it/s, est. speed input: 3682.62 toks/s, output: 3.60 toks/s]
Processed prompts:  31%|      | 645/2048 [02:59<06:51,  3.41it/s, est. speed input: 3677.70 toks/s, output: 3.59 toks/s]
Processed prompts:  32%|      | 661/2048 [03:04<06:46,  3.41it/s, est. speed input: 3672.95 toks/s, output: 3.59 toks/s]
Processed prompts:  33%|      | 677/2048 [03:08<06:42,  3.41it/s, est. speed input: 3668.29 toks/s, output: 3.58 toks/s]
Processed prompts:  34%|      | 693/2048 [03:13<06:37,  3.41it/s, est. speed input: 3664.15 toks/s, output: 3.58 toks/s]
Processed prompts:  35%|      | 709/2048 [03:18<06:32,  3.41it/s, est. speed input: 3660.04 toks/s, output: 3.57 toks/s]
Processed prompts:  35%|      | 725/2048 [03:23<06:28,  3.41it/s, est. speed input: 3656.09 toks/s, output: 3.57 toks/s]
Processed prompts:  36%|      | 741/2048 [03:27<06:23,  3.41it/s, est. speed input: 3652.36 toks/s, output: 3.57 toks/s]
Processed prompts:  37%|      | 757/2048 [03:32<06:18,  3.41it/s, est. speed input: 3648.81 toks/s, output: 3.56 toks/s]
Processed prompts:  38%|      | 773/2048 [03:36<06:08,  3.46it/s, est. speed input: 3649.40 toks/s, output: 3.56 toks/s]
Processed prompts:  39%|      | 789/2048 [03:41<06:05,  3.45it/s, est. speed input: 3645.99 toks/s, output: 3.56 toks/s]
Processed prompts:  39%|      | 805/2048 [03:46<06:01,  3.43it/s, est. speed input: 3642.79 toks/s, output: 3.56 toks/s]
Processed prompts:  40%|      | 821/2048 [03:50<05:58,  3.43it/s, est. speed input: 3639.73 toks/s, output: 3.55 toks/s]
Processed prompts:  41%|      | 837/2048 [03:55<05:54,  3.42it/s, est. speed input: 3636.61 toks/s, output: 3.55 toks/s]
Processed prompts:  42%|     | 853/2048 [04:00<05:49,  3.42it/s, est. speed input: 3633.83 toks/s, output: 3.55 toks/s]
Processed prompts:  42%|     | 869/2048 [04:05<05:45,  3.41it/s, est. speed input: 3630.83 toks/s, output: 3.55 toks/s]
Processed prompts:  43%|     | 885/2048 [04:09<05:40,  3.41it/s, est. speed input: 3628.22 toks/s, output: 3.54 toks/s]
Processed prompts:  44%|     | 901/2048 [04:14<05:36,  3.41it/s, est. speed input: 3625.64 toks/s, output: 3.54 toks/s]
Processed prompts:  45%|     | 917/2048 [04:19<05:31,  3.41it/s, est. speed input: 3623.17 toks/s, output: 3.54 toks/s]
Processed prompts:  46%|     | 933/2048 [04:23<05:27,  3.41it/s, est. speed input: 3620.80 toks/s, output: 3.54 toks/s]
Processed prompts:  46%|     | 949/2048 [04:28<05:22,  3.41it/s, est. speed input: 3618.41 toks/s, output: 3.53 toks/s]
Processed prompts:  47%|     | 965/2048 [04:33<05:17,  3.41it/s, est. speed input: 3616.28 toks/s, output: 3.53 toks/s]
Processed prompts:  48%|     | 981/2048 [04:37<05:13,  3.41it/s, est. speed input: 3614.05 toks/s, output: 3.53 toks/s]
Processed prompts:  49%|     | 997/2048 [04:42<05:08,  3.41it/s, est. speed input: 3612.13 toks/s, output: 3.53 toks/s]
Processed prompts:  49%|     | 1013/2048 [04:47<05:03,  3.41it/s, est. speed input: 3610.16 toks/s, output: 3.53 toks/s]
Processed prompts:  50%|     | 1029/2048 [04:52<04:58,  3.41it/s, est. speed input: 3608.22 toks/s, output: 3.52 toks/s]
Processed prompts:  51%|     | 1045/2048 [04:56<04:54,  3.41it/s, est. speed input: 3606.42 toks/s, output: 3.52 toks/s]
Processed prompts:  52%|    | 1061/2048 [05:01<04:49,  3.41it/s, est. speed input: 3604.58 toks/s, output: 3.52 toks/s]
Processed prompts:  53%|    | 1077/2048 [05:06<04:44,  3.41it/s, est. speed input: 3602.87 toks/s, output: 3.52 toks/s]
Processed prompts:  53%|    | 1093/2048 [05:10<04:40,  3.41it/s, est. speed input: 3601.08 toks/s, output: 3.52 toks/s]
Processed prompts:  54%|    | 1109/2048 [05:15<04:35,  3.41it/s, est. speed input: 3599.46 toks/s, output: 3.52 toks/s]
Processed prompts:  55%|    | 1125/2048 [05:20<04:30,  3.41it/s, est. speed input: 3597.81 toks/s, output: 3.51 toks/s]
Processed prompts:  56%|    | 1141/2048 [05:24<04:26,  3.41it/s, est. speed input: 3596.13 toks/s, output: 3.51 toks/s]
Processed prompts:  56%|    | 1157/2048 [05:29<04:21,  3.41it/s, est. speed input: 3594.64 toks/s, output: 3.51 toks/s]
Processed prompts:  57%|    | 1173/2048 [05:34<04:17,  3.40it/s, est. speed input: 3593.04 toks/s, output: 3.51 toks/s]
Processed prompts:  58%|    | 1189/2048 [05:38<04:12,  3.41it/s, est. speed input: 3591.64 toks/s, output: 3.51 toks/s]
Processed prompts:  59%|    | 1205/2048 [05:43<04:03,  3.46it/s, est. speed input: 3592.65 toks/s, output: 3.51 toks/s]
Processed prompts:  60%|    | 1221/2048 [05:48<04:00,  3.44it/s, est. speed input: 3591.13 toks/s, output: 3.51 toks/s]
Processed prompts:  60%|    | 1237/2048 [05:52<03:56,  3.43it/s, est. speed input: 3589.80 toks/s, output: 3.51 toks/s]
Processed prompts:  61%|    | 1253/2048 [05:57<03:52,  3.42it/s, est. speed input: 3588.42 toks/s, output: 3.50 toks/s]
Processed prompts:  62%|   | 1269/2048 [06:02<03:47,  3.42it/s, est. speed input: 3587.15 toks/s, output: 3.50 toks/s]
Processed prompts:  63%|   | 1285/2048 [06:06<03:43,  3.41it/s, est. speed input: 3585.79 toks/s, output: 3.50 toks/s]
Processed prompts:  64%|   | 1301/2048 [06:11<03:38,  3.41it/s, est. speed input: 3584.58 toks/s, output: 3.50 toks/s]
Processed prompts:  64%|   | 1317/2048 [06:16<03:34,  3.41it/s, est. speed input: 3583.40 toks/s, output: 3.50 toks/s]
Processed prompts:  65%|   | 1333/2048 [06:21<03:29,  3.41it/s, est. speed input: 3582.18 toks/s, output: 3.50 toks/s]
Processed prompts:  66%|   | 1349/2048 [06:25<03:25,  3.41it/s, est. speed input: 3581.05 toks/s, output: 3.50 toks/s]
Processed prompts:  67%|   | 1365/2048 [06:30<03:20,  3.41it/s, est. speed input: 3579.87 toks/s, output: 3.50 toks/s]
Processed prompts:  67%|   | 1381/2048 [06:35<03:15,  3.41it/s, est. speed input: 3578.81 toks/s, output: 3.49 toks/s]
Processed prompts:  68%|   | 1397/2048 [06:39<03:11,  3.40it/s, est. speed input: 3577.65 toks/s, output: 3.49 toks/s]
Processed prompts:  69%|   | 1413/2048 [06:44<03:06,  3.41it/s, est. speed input: 3576.66 toks/s, output: 3.49 toks/s]
Processed prompts:  70%|   | 1429/2048 [06:49<03:01,  3.41it/s, est. speed input: 3575.67 toks/s, output: 3.49 toks/s]
Processed prompts:  71%|   | 1445/2048 [06:53<02:57,  3.41it/s, est. speed input: 3574.64 toks/s, output: 3.49 toks/s]
Processed prompts:  71%|  | 1461/2048 [06:58<02:52,  3.41it/s, est. speed input: 3573.70 toks/s, output: 3.49 toks/s]
Processed prompts:  72%|  | 1477/2048 [07:03<02:47,  3.41it/s, est. speed input: 3572.74 toks/s, output: 3.49 toks/s]
Processed prompts:  73%|  | 1493/2048 [07:08<02:42,  3.41it/s, est. speed input: 3571.78 toks/s, output: 3.49 toks/s]
Processed prompts:  74%|  | 1509/2048 [07:12<02:38,  3.41it/s, est. speed input: 3570.94 toks/s, output: 3.49 toks/s]
Processed prompts:  74%|  | 1525/2048 [07:17<02:33,  3.41it/s, est. speed input: 3570.03 toks/s, output: 3.49 toks/s]
Processed prompts:  75%|  | 1541/2048 [07:22<02:28,  3.41it/s, est. speed input: 3569.19 toks/s, output: 3.49 toks/s]
Processed prompts:  76%|  | 1557/2048 [07:26<02:21,  3.46it/s, est. speed input: 3570.20 toks/s, output: 3.49 toks/s]
Processed prompts:  77%|  | 1573/2048 [07:31<02:18,  3.44it/s, est. speed input: 3569.30 toks/s, output: 3.49 toks/s]
Processed prompts:  78%|  | 1589/2048 [07:35<02:13,  3.43it/s, est. speed input: 3568.44 toks/s, output: 3.48 toks/s]
Processed prompts:  78%|  | 1605/2048 [07:40<02:09,  3.42it/s, est. speed input: 3567.65 toks/s, output: 3.48 toks/s]
Processed prompts:  79%|  | 1621/2048 [07:45<02:03,  3.47it/s, est. speed input: 3568.65 toks/s, output: 3.49 toks/s]
Processed prompts:  80%|  | 1637/2048 [07:49<01:59,  3.45it/s, est. speed input: 3567.75 toks/s, output: 3.48 toks/s]
Processed prompts:  81%|  | 1653/2048 [07:54<01:54,  3.44it/s, est. speed input: 3566.99 toks/s, output: 3.48 toks/s]
Processed prompts:  81%| | 1669/2048 [07:59<01:50,  3.43it/s, est. speed input: 3566.23 toks/s, output: 3.48 toks/s]
Processed prompts:  82%| | 1685/2048 [08:03<01:46,  3.42it/s, est. speed input: 3565.45 toks/s, output: 3.48 toks/s]
Processed prompts:  83%| | 1701/2048 [08:08<01:41,  3.42it/s, est. speed input: 3564.73 toks/s, output: 3.48 toks/s]
Processed prompts:  84%| | 1717/2048 [08:13<01:37,  3.41it/s, est. speed input: 3563.95 toks/s, output: 3.48 toks/s]
Processed prompts:  85%| | 1733/2048 [08:17<01:30,  3.46it/s, est. speed input: 3564.91 toks/s, output: 3.48 toks/s]
Processed prompts:  85%| | 1749/2048 [08:22<01:25,  3.50it/s, est. speed input: 3565.86 toks/s, output: 3.48 toks/s]
Processed prompts:  86%| | 1765/2048 [08:26<01:21,  3.47it/s, est. speed input: 3565.14 toks/s, output: 3.48 toks/s]
Processed prompts:  87%| | 1781/2048 [08:31<01:17,  3.45it/s, est. speed input: 3564.51 toks/s, output: 3.48 toks/s]
Processed prompts:  88%| | 1797/2048 [08:36<01:13,  3.44it/s, est. speed input: 3563.78 toks/s, output: 3.48 toks/s]
Processed prompts:  89%| | 1813/2048 [08:41<01:08,  3.43it/s, est. speed input: 3563.10 toks/s, output: 3.48 toks/s]
Processed prompts:  89%| | 1829/2048 [08:45<01:04,  3.42it/s, est. speed input: 3562.42 toks/s, output: 3.48 toks/s]
Processed prompts:  90%| | 1845/2048 [08:50<00:59,  3.42it/s, est. speed input: 3561.80 toks/s, output: 3.48 toks/s]
Processed prompts:  91%| | 1861/2048 [08:55<00:54,  3.42it/s, est. speed input: 3561.18 toks/s, output: 3.48 toks/s]
Processed prompts:  92%|| 1877/2048 [08:59<00:50,  3.41it/s, est. speed input: 3560.48 toks/s, output: 3.48 toks/s]
Processed prompts:  92%|| 1893/2048 [09:04<00:45,  3.41it/s, est. speed input: 3559.88 toks/s, output: 3.48 toks/s]
Processed prompts:  93%|| 1909/2048 [09:09<00:40,  3.41it/s, est. speed input: 3559.32 toks/s, output: 3.48 toks/s]
Processed prompts:  94%|| 1925/2048 [09:13<00:36,  3.41it/s, est. speed input: 3558.70 toks/s, output: 3.48 toks/s]
Processed prompts:  95%|| 1941/2048 [09:18<00:31,  3.41it/s, est. speed input: 3558.15 toks/s, output: 3.47 toks/s]
Processed prompts:  96%|| 1957/2048 [09:23<00:26,  3.41it/s, est. speed input: 3557.53 toks/s, output: 3.47 toks/s]
Processed prompts:  96%|| 1973/2048 [09:28<00:22,  3.41it/s, est. speed input: 3556.93 toks/s, output: 3.47 toks/s]
Processed prompts:  97%|| 1989/2048 [09:32<00:17,  3.41it/s, est. speed input: 3556.39 toks/s, output: 3.47 toks/s]
Processed prompts:  98%|| 2005/2048 [09:37<00:12,  3.40it/s, est. speed input: 3555.77 toks/s, output: 3.47 toks/s]
Processed prompts:  99%|| 2021/2048 [09:42<00:07,  3.41it/s, est. speed input: 3555.27 toks/s, output: 3.47 toks/s]
Processed prompts:  99%|| 2037/2048 [09:45<00:02,  3.68it/s, est. speed input: 3561.88 toks/s, output: 3.48 toks/s]
Processed prompts: 100%|| 2048/2048 [09:45<00:00,  3.68it/s, est. speed input: 3581.12 toks/s, output: 3.50 toks/s]
Processed prompts: 100%|| 2048/2048 [09:45<00:00,  3.50it/s, est. speed input: 3581.12 toks/s, output: 3.50 toks/s]
[rank0]:[W127 10:25:25.287571406 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-27 10:25:31
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Qwen2.5-14B-FP8_M32768.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-27 10:25:53 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-27 10:25:53 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=2507668) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2507668) WARNING 01-27 10:28:24 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 3.36 requests/s, 3445.06 total tokens/s, 3.36 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-27 10:25:52] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 10:25:52] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 10:25:52] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 10:25:52] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 10:25:52] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 10:25:52] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 10:25:52] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 10:25:52] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 10:25:52] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 10:25:52] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 10:25:52] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 10:25:52] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 10:25:52] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 10:25:52] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-27 10:25:56] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 10:25:56] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 10:25:56] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 10:25:56] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 10:25:56] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 10:25:56] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 10:25:56] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 10:25:56] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 10:25:56] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 10:25:56] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 10:25:56] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 10:25:56] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 10:25:56] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 10:25:56] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=2507668) [2026-01-27 10:25:57] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=2507668) [2026-01-27 10:25:57] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2507668) [2026-01-27 10:25:57] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=2507668) [2026-01-27 10:25:57] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=2507668) [2026-01-27 10:25:57] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=2507668) [2026-01-27 10:25:57] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=2507668) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=2507668) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:25,  8.53s/it]
(EngineCore_DP0 pid=2507668) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:44<00:48, 24.39s/it]
(EngineCore_DP0 pid=2507668) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [01:16<00:28, 28.25s/it]
(EngineCore_DP0 pid=2507668) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:51<00:00, 30.67s/it]
(EngineCore_DP0 pid=2507668) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:51<00:00, 27.81s/it]
(EngineCore_DP0 pid=2507668) 
(EngineCore_DP0 pid=2507668) [2026-01-27 10:27:50] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 6848] -> 1D uint8
(EngineCore_DP0 pid=2507668) [2026-01-27 10:27:50] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 30736384 bytes
(EngineCore_DP0 pid=2507668) [2026-01-27 10:27:50] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 6848] -> 1D uint8
(EngineCore_DP0 pid=2507668) [2026-01-27 10:27:50] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 21954560 bytes
(EngineCore_DP0 pid=2507668) [2026-01-27 10:27:50] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 6848] -> 1D uint8
(EngineCore_DP0 pid=2507668) [2026-01-27 10:27:50] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 118554624 bytes
(EngineCore_DP0 pid=2507668) [2026-01-27 10:27:50] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 18432] -> 1D uint8
(EngineCore_DP0 pid=2507668) [2026-01-27 10:27:50] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 58982400 bytes
(EngineCore_DP0 pid=2507668) 2026-01-27 10:28:06,686 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=2507668) 2026-01-27 10:28:10,508 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   0%|          | 1/4096 [00:00<51:51,  1.32it/s]
Adding requests:   0%|          | 2/4096 [00:00<28:53,  2.36it/s]
Adding requests:   0%|          | 3/4096 [00:01<19:01,  3.59it/s]
Adding requests:   0%|          | 5/4096 [00:01<10:54,  6.25it/s]
Adding requests:   0%|          | 8/4096 [00:01<06:24, 10.62it/s]
Adding requests:   0%|          | 12/4096 [00:01<04:13, 16.08it/s]
Adding requests:   0%|          | 18/4096 [00:01<02:40, 25.36it/s]
Adding requests:   1%|          | 33/4096 [00:01<01:14, 54.76it/s]
Adding requests:   1%|          | 48/4096 [00:01<00:51, 78.79it/s]
Adding requests:   2%|         | 66/4096 [00:01<00:38, 104.93it/s]
Adding requests:   2%|         | 90/4096 [00:01<00:28, 140.95it/s]
Adding requests:   3%|         | 120/4096 [00:02<00:21, 183.73it/s]
Adding requests:   4%|         | 156/4096 [00:02<00:16, 233.67it/s]
Adding requests:   5%|         | 199/4096 [00:02<00:13, 288.81it/s]
Adding requests:   6%|         | 240/4096 [00:02<00:11, 323.38it/s]
Adding requests:   7%|         | 282/4096 [00:02<00:10, 349.29it/s]
Adding requests:   8%|         | 325/4096 [00:02<00:10, 372.53it/s]
Adding requests:   9%|         | 372/4096 [00:02<00:09, 401.09it/s]
Adding requests:  10%|         | 420/4096 [00:02<00:08, 423.28it/s]
Adding requests:  11%|        | 464/4096 [00:02<00:08, 425.30it/s]
Adding requests:  12%|        | 511/4096 [00:02<00:08, 437.68it/s]
Adding requests:  14%|        | 555/4096 [00:03<00:08, 434.48it/s]
Adding requests:  15%|        | 599/4096 [00:03<00:08, 432.18it/s]
Adding requests:  16%|        | 643/4096 [00:03<00:08, 420.87it/s]
Adding requests:  17%|        | 687/4096 [00:03<00:07, 426.31it/s]
Adding requests:  18%|        | 730/4096 [00:03<00:08, 412.30it/s]
Adding requests:  19%|        | 774/4096 [00:03<00:07, 420.24it/s]
Adding requests:  20%|        | 817/4096 [00:03<00:07, 415.79it/s]
Adding requests:  21%|        | 863/4096 [00:03<00:07, 426.05it/s]
Adding requests:  22%|       | 907/4096 [00:03<00:07, 428.30it/s]
Adding requests:  23%|       | 950/4096 [00:04<00:07, 423.36it/s]
Adding requests:  24%|       | 993/4096 [00:04<00:07, 418.67it/s]
Adding requests:  25%|       | 1035/4096 [00:04<00:07, 416.72it/s]
Adding requests:  26%|       | 1077/4096 [00:04<00:07, 412.14it/s]
Adding requests:  27%|       | 1120/4096 [00:04<00:07, 414.35it/s]
Adding requests:  28%|       | 1163/4096 [00:04<00:07, 418.91it/s]
Adding requests:  29%|       | 1205/4096 [00:04<00:07, 389.83it/s]
Adding requests:  30%|       | 1249/4096 [00:04<00:07, 403.16it/s]
Adding requests:  31%|      | 1290/4096 [00:04<00:06, 401.89it/s]
Adding requests:  33%|      | 1336/4096 [00:04<00:06, 418.59it/s]
Adding requests:  34%|      | 1379/4096 [00:05<00:06, 416.92it/s]
Adding requests:  35%|      | 1423/4096 [00:05<00:06, 422.59it/s]
Adding requests:  36%|      | 1466/4096 [00:05<00:06, 416.77it/s]
Adding requests:  37%|      | 1512/4096 [00:05<00:06, 426.30it/s]
Adding requests:  38%|      | 1555/4096 [00:05<00:06, 410.73it/s]
Adding requests:  39%|      | 1597/4096 [00:05<00:06, 407.35it/s]
Adding requests:  40%|      | 1639/4096 [00:05<00:06, 408.69it/s]
Adding requests:  41%|      | 1680/4096 [00:05<00:06, 396.48it/s]
Adding requests:  42%|     | 1722/4096 [00:05<00:05, 400.71it/s]
Adding requests:  43%|     | 1769/4096 [00:06<00:05, 420.65it/s]
Adding requests:  44%|     | 1812/4096 [00:06<00:05, 416.55it/s]
Adding requests:  45%|     | 1856/4096 [00:06<00:05, 422.21it/s]
Adding requests:  46%|     | 1899/4096 [00:06<00:05, 422.80it/s]
Adding requests:  47%|     | 1944/4096 [00:06<00:05, 428.56it/s]
Adding requests:  49%|     | 1987/4096 [00:06<00:05, 420.56it/s]
Adding requests:  50%|     | 2030/4096 [00:06<00:05, 404.65it/s]
Adding requests:  51%|     | 2074/4096 [00:06<00:04, 412.51it/s]
Adding requests:  52%|    | 2116/4096 [00:06<00:04, 409.49it/s]
Adding requests:  53%|    | 2159/4096 [00:06<00:04, 413.52it/s]
Adding requests:  54%|    | 2201/4096 [00:07<00:04, 406.54it/s]
Adding requests:  55%|    | 2245/4096 [00:07<00:04, 415.60it/s]
Adding requests:  56%|    | 2290/4096 [00:07<00:04, 423.96it/s]
Adding requests:  57%|    | 2337/4096 [00:07<00:04, 434.80it/s]
Adding requests:  58%|    | 2381/4096 [00:07<00:03, 430.01it/s]
Adding requests:  59%|    | 2426/4096 [00:07<00:03, 435.27it/s]
Adding requests:  60%|    | 2470/4096 [00:07<00:04, 396.85it/s]
Adding requests:  61%|   | 2516/4096 [00:07<00:03, 411.83it/s]
Adding requests:  62%|   | 2560/4096 [00:07<00:03, 419.45it/s]
Adding requests:  64%|   | 2604/4096 [00:08<00:03, 424.92it/s]
Adding requests:  65%|   | 2647/4096 [00:08<00:03, 425.66it/s]
Adding requests:  66%|   | 2690/4096 [00:08<00:03, 417.47it/s]
Adding requests:  67%|   | 2732/4096 [00:08<00:03, 418.05it/s]
Adding requests:  68%|   | 2774/4096 [00:08<00:03, 410.45it/s]
Adding requests:  69%|   | 2820/4096 [00:08<00:03, 422.47it/s]
Adding requests:  70%|   | 2863/4096 [00:08<00:02, 418.89it/s]
Adding requests:  71%|   | 2910/4096 [00:08<00:02, 432.27it/s]
Adding requests:  72%|  | 2954/4096 [00:08<00:02, 429.40it/s]
Adding requests:  73%|  | 2999/4096 [00:08<00:02, 434.45it/s]
Adding requests:  74%|  | 3043/4096 [00:09<00:02, 423.84it/s]
Adding requests:  75%|  | 3089/4096 [00:09<00:02, 433.08it/s]
Adding requests:  76%|  | 3133/4096 [00:09<00:02, 411.65it/s]
Adding requests:  78%|  | 3175/4096 [00:09<00:02, 409.95it/s]
Adding requests:  79%|  | 3217/4096 [00:09<00:02, 409.71it/s]
Adding requests:  80%|  | 3260/4096 [00:09<00:02, 414.81it/s]
Adding requests:  81%|  | 3302/4096 [00:09<00:01, 401.51it/s]
Adding requests:  82%| | 3346/4096 [00:09<00:01, 409.46it/s]
Adding requests:  83%| | 3388/4096 [00:09<00:01, 406.93it/s]
Adding requests:  84%| | 3429/4096 [00:09<00:01, 398.61it/s]
Adding requests:  85%| | 3476/4096 [00:10<00:01, 416.98it/s]
Adding requests:  86%| | 3518/4096 [00:10<00:01, 402.96it/s]
Adding requests:  87%| | 3563/4096 [00:10<00:01, 413.99it/s]
Adding requests:  88%| | 3605/4096 [00:10<00:01, 398.53it/s]
Adding requests:  89%| | 3649/4096 [00:10<00:01, 408.33it/s]
Adding requests:  90%| | 3691/4096 [00:10<00:01, 403.74it/s]
Adding requests:  91%| | 3734/4096 [00:10<00:00, 409.79it/s]
Adding requests:  92%|| 3776/4096 [00:10<00:00, 400.74it/s]
Adding requests:  93%|| 3817/4096 [00:10<00:00, 371.97it/s]
Adding requests:  94%|| 3855/4096 [00:11<00:00, 372.18it/s]
Adding requests:  95%|| 3895/4096 [00:11<00:00, 378.72it/s]
Adding requests:  96%|| 3936/4096 [00:11<00:00, 386.01it/s]
Adding requests:  97%|| 3975/4096 [00:11<00:00, 378.65it/s]
Adding requests:  98%|| 4019/4096 [00:11<00:00, 394.20it/s]
Adding requests:  99%|| 4059/4096 [00:11<00:00, 383.81it/s]
Adding requests: 100%|| 4096/4096 [00:11<00:00, 350.16it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 37/4096 [00:09<17:06,  3.95it/s, est. speed input: 4047.16 toks/s, output: 3.95 toks/s]
Processed prompts:   2%|         | 69/4096 [00:18<18:35,  3.61it/s, est. speed input: 3748.26 toks/s, output: 3.66 toks/s]
Processed prompts:   2%|         | 101/4096 [00:28<19:01,  3.50it/s, est. speed input: 3648.70 toks/s, output: 3.56 toks/s]
Processed prompts:   3%|         | 133/4096 [00:37<19:09,  3.45it/s, est. speed input: 3597.91 toks/s, output: 3.51 toks/s]
Processed prompts:   4%|         | 165/4096 [00:47<19:10,  3.42it/s, est. speed input: 3566.62 toks/s, output: 3.48 toks/s]
Processed prompts:   5%|         | 197/4096 [00:56<19:00,  3.42it/s, est. speed input: 3557.18 toks/s, output: 3.47 toks/s]
Processed prompts:   6%|         | 229/4096 [01:06<18:57,  3.40it/s, est. speed input: 3540.14 toks/s, output: 3.46 toks/s]
Processed prompts:   6%|         | 261/4096 [01:15<18:52,  3.39it/s, est. speed input: 3527.13 toks/s, output: 3.44 toks/s]
Processed prompts:   7%|         | 293/4096 [01:25<18:38,  3.40it/s, est. speed input: 3526.13 toks/s, output: 3.44 toks/s]
Processed prompts:   8%|         | 325/4096 [01:34<18:33,  3.39it/s, est. speed input: 3517.30 toks/s, output: 3.43 toks/s]
Processed prompts:   9%|         | 357/4096 [01:44<18:26,  3.38it/s, est. speed input: 3509.97 toks/s, output: 3.43 toks/s]
Processed prompts:   9%|         | 389/4096 [01:53<18:18,  3.37it/s, est. speed input: 3504.41 toks/s, output: 3.42 toks/s]
Processed prompts:  10%|         | 421/4096 [02:02<18:03,  3.39it/s, est. speed input: 3505.43 toks/s, output: 3.42 toks/s]
Processed prompts:  11%|         | 453/4096 [02:12<17:57,  3.38it/s, est. speed input: 3500.66 toks/s, output: 3.42 toks/s]
Processed prompts:  12%|        | 485/4096 [02:22<17:49,  3.37it/s, est. speed input: 3496.58 toks/s, output: 3.41 toks/s]
Processed prompts:  13%|        | 517/4096 [02:31<17:41,  3.37it/s, est. speed input: 3493.00 toks/s, output: 3.41 toks/s]
Processed prompts:  13%|        | 549/4096 [02:41<17:33,  3.37it/s, est. speed input: 3489.84 toks/s, output: 3.41 toks/s]
Processed prompts:  14%|        | 581/4096 [02:50<17:24,  3.36it/s, est. speed input: 3487.04 toks/s, output: 3.41 toks/s]
Processed prompts:  15%|        | 613/4096 [03:00<17:16,  3.36it/s, est. speed input: 3484.32 toks/s, output: 3.40 toks/s]
Processed prompts:  16%|        | 645/4096 [03:09<17:07,  3.36it/s, est. speed input: 3481.91 toks/s, output: 3.40 toks/s]
Processed prompts:  17%|        | 677/4096 [03:19<16:57,  3.36it/s, est. speed input: 3479.76 toks/s, output: 3.40 toks/s]
Processed prompts:  17%|        | 709/4096 [03:28<16:48,  3.36it/s, est. speed input: 3477.86 toks/s, output: 3.40 toks/s]
Processed prompts:  18%|        | 741/4096 [03:38<16:39,  3.36it/s, est. speed input: 3476.04 toks/s, output: 3.39 toks/s]
Processed prompts:  19%|        | 773/4096 [03:47<16:23,  3.38it/s, est. speed input: 3477.61 toks/s, output: 3.40 toks/s]
Processed prompts:  20%|        | 805/4096 [03:57<16:15,  3.37it/s, est. speed input: 3475.98 toks/s, output: 3.39 toks/s]
Processed prompts:  20%|        | 837/4096 [04:06<16:07,  3.37it/s, est. speed input: 3474.44 toks/s, output: 3.39 toks/s]
Processed prompts:  21%|        | 869/4096 [04:16<15:59,  3.36it/s, est. speed input: 3473.05 toks/s, output: 3.39 toks/s]
Processed prompts:  22%|       | 901/4096 [04:25<15:50,  3.36it/s, est. speed input: 3471.73 toks/s, output: 3.39 toks/s]
Processed prompts:  23%|       | 933/4096 [04:35<15:41,  3.36it/s, est. speed input: 3470.46 toks/s, output: 3.39 toks/s]
Processed prompts:  24%|       | 965/4096 [04:44<15:32,  3.36it/s, est. speed input: 3469.34 toks/s, output: 3.39 toks/s]
Processed prompts:  24%|       | 997/4096 [04:54<15:22,  3.36it/s, est. speed input: 3468.34 toks/s, output: 3.39 toks/s]
Processed prompts:  25%|       | 1029/4096 [05:03<15:13,  3.36it/s, est. speed input: 3467.36 toks/s, output: 3.39 toks/s]
Processed prompts:  26%|       | 1061/4096 [05:13<15:04,  3.36it/s, est. speed input: 3466.39 toks/s, output: 3.39 toks/s]
Processed prompts:  27%|       | 1093/4096 [05:22<14:54,  3.36it/s, est. speed input: 3465.46 toks/s, output: 3.38 toks/s]
Processed prompts:  27%|       | 1125/4096 [05:32<14:45,  3.36it/s, est. speed input: 3464.63 toks/s, output: 3.38 toks/s]
Processed prompts:  28%|       | 1157/4096 [05:42<14:35,  3.36it/s, est. speed input: 3463.81 toks/s, output: 3.38 toks/s]
Processed prompts:  29%|       | 1189/4096 [05:51<14:20,  3.38it/s, est. speed input: 3465.21 toks/s, output: 3.38 toks/s]
Processed prompts:  30%|       | 1221/4096 [06:00<14:12,  3.37it/s, est. speed input: 3464.44 toks/s, output: 3.38 toks/s]
Processed prompts:  31%|       | 1253/4096 [06:10<14:04,  3.37it/s, est. speed input: 3463.62 toks/s, output: 3.38 toks/s]
Processed prompts:  31%|      | 1285/4096 [06:19<13:56,  3.36it/s, est. speed input: 3462.85 toks/s, output: 3.38 toks/s]
Processed prompts:  32%|      | 1317/4096 [06:29<13:47,  3.36it/s, est. speed input: 3462.11 toks/s, output: 3.38 toks/s]
Processed prompts:  33%|      | 1349/4096 [06:39<13:38,  3.36it/s, est. speed input: 3461.35 toks/s, output: 3.38 toks/s]
Processed prompts:  34%|      | 1381/4096 [06:48<13:28,  3.36it/s, est. speed input: 3460.79 toks/s, output: 3.38 toks/s]
Processed prompts:  34%|      | 1413/4096 [06:58<13:19,  3.36it/s, est. speed input: 3460.16 toks/s, output: 3.38 toks/s]
Processed prompts:  35%|      | 1445/4096 [07:07<13:10,  3.36it/s, est. speed input: 3459.63 toks/s, output: 3.38 toks/s]
Processed prompts:  36%|      | 1477/4096 [07:17<13:01,  3.35it/s, est. speed input: 3458.94 toks/s, output: 3.38 toks/s]
Processed prompts:  37%|      | 1509/4096 [07:26<12:51,  3.35it/s, est. speed input: 3458.43 toks/s, output: 3.38 toks/s]
Processed prompts:  38%|      | 1541/4096 [07:36<12:36,  3.38it/s, est. speed input: 3459.57 toks/s, output: 3.38 toks/s]
Processed prompts:  38%|      | 1573/4096 [07:45<12:28,  3.37it/s, est. speed input: 3459.08 toks/s, output: 3.38 toks/s]
Processed prompts:  39%|      | 1605/4096 [07:54<12:15,  3.39it/s, est. speed input: 3460.17 toks/s, output: 3.38 toks/s]
Processed prompts:  40%|      | 1637/4096 [08:04<12:07,  3.38it/s, est. speed input: 3459.65 toks/s, output: 3.38 toks/s]
Processed prompts:  41%|      | 1669/4096 [08:14<11:59,  3.37it/s, est. speed input: 3459.18 toks/s, output: 3.38 toks/s]
Processed prompts:  42%|     | 1701/4096 [08:23<11:51,  3.37it/s, est. speed input: 3458.69 toks/s, output: 3.38 toks/s]
Processed prompts:  42%|     | 1733/4096 [08:32<11:38,  3.39it/s, est. speed input: 3459.70 toks/s, output: 3.38 toks/s]
Processed prompts:  43%|     | 1765/4096 [08:42<11:30,  3.38it/s, est. speed input: 3459.21 toks/s, output: 3.38 toks/s]
Processed prompts:  44%|     | 1797/4096 [08:52<11:22,  3.37it/s, est. speed input: 3458.70 toks/s, output: 3.38 toks/s]
Processed prompts:  45%|     | 1829/4096 [09:01<11:14,  3.36it/s, est. speed input: 3458.21 toks/s, output: 3.38 toks/s]
Processed prompts:  45%|     | 1861/4096 [09:11<11:05,  3.36it/s, est. speed input: 3457.80 toks/s, output: 3.38 toks/s]
Processed prompts:  46%|     | 1893/4096 [09:20<10:56,  3.36it/s, est. speed input: 3457.39 toks/s, output: 3.38 toks/s]
Processed prompts:  47%|     | 1925/4096 [09:30<10:46,  3.36it/s, est. speed input: 3457.00 toks/s, output: 3.38 toks/s]
Processed prompts:  48%|     | 1957/4096 [09:39<10:37,  3.36it/s, est. speed input: 3456.59 toks/s, output: 3.38 toks/s]
Processed prompts:  49%|     | 1989/4096 [09:49<10:28,  3.35it/s, est. speed input: 3456.15 toks/s, output: 3.38 toks/s]
Processed prompts:  49%|     | 2021/4096 [09:58<10:19,  3.35it/s, est. speed input: 3455.68 toks/s, output: 3.37 toks/s]
Processed prompts:  50%|     | 2053/4096 [10:08<10:09,  3.35it/s, est. speed input: 3455.32 toks/s, output: 3.37 toks/s]
Processed prompts:  51%|     | 2085/4096 [10:17<09:59,  3.35it/s, est. speed input: 3455.00 toks/s, output: 3.37 toks/s]
Processed prompts:  52%|    | 2117/4096 [10:27<09:50,  3.35it/s, est. speed input: 3454.67 toks/s, output: 3.37 toks/s]
Processed prompts:  52%|    | 2149/4096 [10:37<09:40,  3.35it/s, est. speed input: 3454.34 toks/s, output: 3.37 toks/s]
Processed prompts:  53%|    | 2181/4096 [10:46<09:27,  3.37it/s, est. speed input: 3455.16 toks/s, output: 3.37 toks/s]
Processed prompts:  54%|    | 2213/4096 [10:55<09:19,  3.37it/s, est. speed input: 3454.85 toks/s, output: 3.37 toks/s]
Processed prompts:  55%|    | 2245/4096 [11:05<09:10,  3.36it/s, est. speed input: 3454.52 toks/s, output: 3.37 toks/s]
Processed prompts:  56%|    | 2277/4096 [11:15<09:01,  3.36it/s, est. speed input: 3454.21 toks/s, output: 3.37 toks/s]
Processed prompts:  56%|    | 2309/4096 [11:24<08:52,  3.36it/s, est. speed input: 3453.94 toks/s, output: 3.37 toks/s]
Processed prompts:  57%|    | 2341/4096 [11:34<08:42,  3.36it/s, est. speed input: 3453.63 toks/s, output: 3.37 toks/s]
Processed prompts:  58%|    | 2373/4096 [11:43<08:33,  3.36it/s, est. speed input: 3453.36 toks/s, output: 3.37 toks/s]
Processed prompts:  59%|    | 2405/4096 [11:53<08:24,  3.35it/s, est. speed input: 3453.10 toks/s, output: 3.37 toks/s]
Processed prompts:  59%|    | 2437/4096 [12:02<08:14,  3.35it/s, est. speed input: 3452.80 toks/s, output: 3.37 toks/s]
Processed prompts:  60%|    | 2469/4096 [12:12<08:05,  3.35it/s, est. speed input: 3452.57 toks/s, output: 3.37 toks/s]
Processed prompts:  61%|    | 2501/4096 [12:21<07:55,  3.35it/s, est. speed input: 3452.30 toks/s, output: 3.37 toks/s]
Processed prompts:  62%|   | 2533/4096 [12:31<07:46,  3.35it/s, est. speed input: 3452.04 toks/s, output: 3.37 toks/s]
Processed prompts:  63%|   | 2565/4096 [12:40<07:36,  3.35it/s, est. speed input: 3451.84 toks/s, output: 3.37 toks/s]
Processed prompts:  63%|   | 2597/4096 [12:50<07:24,  3.38it/s, est. speed input: 3452.57 toks/s, output: 3.37 toks/s]
Processed prompts:  64%|   | 2629/4096 [12:59<07:15,  3.37it/s, est. speed input: 3452.32 toks/s, output: 3.37 toks/s]
Processed prompts:  65%|   | 2661/4096 [13:09<07:06,  3.36it/s, est. speed input: 3452.11 toks/s, output: 3.37 toks/s]
Processed prompts:  66%|   | 2693/4096 [13:18<06:57,  3.36it/s, est. speed input: 3451.88 toks/s, output: 3.37 toks/s]
Processed prompts:  67%|   | 2725/4096 [13:28<06:45,  3.38it/s, est. speed input: 3452.57 toks/s, output: 3.37 toks/s]
Processed prompts:  67%|   | 2757/4096 [13:37<06:36,  3.37it/s, est. speed input: 3452.36 toks/s, output: 3.37 toks/s]
Processed prompts:  68%|   | 2789/4096 [13:47<06:28,  3.37it/s, est. speed input: 3452.10 toks/s, output: 3.37 toks/s]
Processed prompts:  69%|   | 2821/4096 [13:56<06:19,  3.36it/s, est. speed input: 3451.85 toks/s, output: 3.37 toks/s]
Processed prompts:  70%|   | 2853/4096 [14:06<06:10,  3.36it/s, est. speed input: 3451.61 toks/s, output: 3.37 toks/s]
Processed prompts:  70%|   | 2885/4096 [14:15<05:58,  3.38it/s, est. speed input: 3452.29 toks/s, output: 3.37 toks/s]
Processed prompts:  71%|   | 2917/4096 [14:25<05:47,  3.39it/s, est. speed input: 3452.93 toks/s, output: 3.37 toks/s]
Processed prompts:  72%|  | 2949/4096 [14:34<05:39,  3.38it/s, est. speed input: 3452.74 toks/s, output: 3.37 toks/s]
Processed prompts:  73%|  | 2981/4096 [14:44<05:30,  3.37it/s, est. speed input: 3452.50 toks/s, output: 3.37 toks/s]
Processed prompts:  74%|  | 3013/4096 [14:53<05:21,  3.37it/s, est. speed input: 3452.29 toks/s, output: 3.37 toks/s]
Processed prompts:  74%|  | 3045/4096 [15:03<05:12,  3.36it/s, est. speed input: 3452.06 toks/s, output: 3.37 toks/s]
Processed prompts:  75%|  | 3077/4096 [15:12<05:03,  3.36it/s, est. speed input: 3451.81 toks/s, output: 3.37 toks/s]
Processed prompts:  76%|  | 3109/4096 [15:22<04:54,  3.36it/s, est. speed input: 3451.63 toks/s, output: 3.37 toks/s]
Processed prompts:  77%|  | 3141/4096 [15:31<04:44,  3.36it/s, est. speed input: 3451.44 toks/s, output: 3.37 toks/s]
Processed prompts:  77%|  | 3173/4096 [15:41<04:35,  3.35it/s, est. speed input: 3451.24 toks/s, output: 3.37 toks/s]
Processed prompts:  78%|  | 3205/4096 [15:50<04:25,  3.35it/s, est. speed input: 3451.05 toks/s, output: 3.37 toks/s]
Processed prompts:  79%|  | 3237/4096 [16:00<04:16,  3.35it/s, est. speed input: 3450.84 toks/s, output: 3.37 toks/s]
Processed prompts:  80%|  | 3269/4096 [16:10<04:06,  3.35it/s, est. speed input: 3450.64 toks/s, output: 3.37 toks/s]
Processed prompts:  81%|  | 3301/4096 [16:19<03:57,  3.35it/s, est. speed input: 3450.45 toks/s, output: 3.37 toks/s]
Processed prompts:  81%| | 3333/4096 [16:29<03:47,  3.35it/s, est. speed input: 3450.28 toks/s, output: 3.37 toks/s]
Processed prompts:  82%| | 3365/4096 [16:38<03:38,  3.35it/s, est. speed input: 3450.09 toks/s, output: 3.37 toks/s]
Processed prompts:  83%| | 3397/4096 [16:48<03:28,  3.35it/s, est. speed input: 3449.88 toks/s, output: 3.37 toks/s]
Processed prompts:  84%| | 3429/4096 [16:57<03:19,  3.35it/s, est. speed input: 3449.74 toks/s, output: 3.37 toks/s]
Processed prompts:  84%| | 3461/4096 [17:07<03:09,  3.35it/s, est. speed input: 3449.58 toks/s, output: 3.37 toks/s]
Processed prompts:  85%| | 3493/4096 [17:16<02:59,  3.35it/s, est. speed input: 3449.40 toks/s, output: 3.37 toks/s]
Processed prompts:  86%| | 3525/4096 [17:26<02:50,  3.35it/s, est. speed input: 3449.23 toks/s, output: 3.37 toks/s]
Processed prompts:  87%| | 3557/4096 [17:36<02:40,  3.35it/s, est. speed input: 3449.07 toks/s, output: 3.37 toks/s]
Processed prompts:  88%| | 3589/4096 [17:45<02:31,  3.35it/s, est. speed input: 3448.93 toks/s, output: 3.37 toks/s]
Processed prompts:  88%| | 3621/4096 [17:55<02:21,  3.35it/s, est. speed input: 3448.78 toks/s, output: 3.37 toks/s]
Processed prompts:  89%| | 3653/4096 [18:04<02:12,  3.35it/s, est. speed input: 3448.64 toks/s, output: 3.37 toks/s]
Processed prompts:  90%| | 3685/4096 [18:13<02:01,  3.38it/s, est. speed input: 3449.22 toks/s, output: 3.37 toks/s]
Processed prompts:  91%| | 3717/4096 [18:23<01:52,  3.37it/s, est. speed input: 3449.08 toks/s, output: 3.37 toks/s]
Processed prompts:  92%|| 3749/4096 [18:33<01:43,  3.36it/s, est. speed input: 3448.91 toks/s, output: 3.37 toks/s]
Processed prompts:  92%|| 3781/4096 [18:42<01:33,  3.36it/s, est. speed input: 3448.78 toks/s, output: 3.37 toks/s]
Processed prompts:  93%|| 3813/4096 [18:52<01:24,  3.36it/s, est. speed input: 3448.66 toks/s, output: 3.37 toks/s]
Processed prompts:  94%|| 3845/4096 [19:01<01:14,  3.35it/s, est. speed input: 3448.46 toks/s, output: 3.37 toks/s]
Processed prompts:  95%|| 3877/4096 [19:11<01:05,  3.35it/s, est. speed input: 3448.31 toks/s, output: 3.37 toks/s]
Processed prompts:  95%|| 3909/4096 [19:20<00:55,  3.37it/s, est. speed input: 3448.66 toks/s, output: 3.37 toks/s]
Processed prompts:  96%|| 3941/4096 [19:30<00:46,  3.36it/s, est. speed input: 3448.51 toks/s, output: 3.37 toks/s]
Processed prompts:  97%|| 3973/4096 [19:39<00:36,  3.36it/s, est. speed input: 3448.40 toks/s, output: 3.37 toks/s]
Processed prompts:  98%|| 4005/4096 [19:49<00:26,  3.38it/s, est. speed input: 3448.90 toks/s, output: 3.37 toks/s]
Processed prompts:  99%|| 4037/4096 [19:58<00:17,  3.37it/s, est. speed input: 3448.76 toks/s, output: 3.37 toks/s]
Processed prompts:  99%|| 4069/4096 [20:06<00:07,  3.50it/s, est. speed input: 3452.15 toks/s, output: 3.37 toks/s]
Processed prompts: 100%|| 4096/4096 [20:06<00:00,  3.50it/s, est. speed input: 3475.06 toks/s, output: 3.39 toks/s]
Processed prompts: 100%|| 4096/4096 [20:06<00:00,  3.39it/s, est. speed input: 3475.06 toks/s, output: 3.39 toks/s]
[rank0]:[W127 10:48:51.014178685 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-27 10:48:59
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/Qwen2.5-14B-FP8_M65536.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-27 10:49:35 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-27 10:49:36 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=2527634) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2527634) WARNING 01-27 10:52:25 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 3.41 requests/s, 3493.96 total tokens/s, 3.41 output tokens/s
Total num prompt tokens:  8388608
Total num output tokens:  8192

STDERR:
[2026-01-27 10:49:35] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 10:49:35] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 10:49:35] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 10:49:35] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 10:49:35] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 10:49:35] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 10:49:35] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 10:49:35] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 10:49:35] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 10:49:35] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 10:49:35] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 10:49:35] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 10:49:35] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 10:49:35] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-27 10:49:39] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 10:49:39] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 10:49:39] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 10:49:39] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 10:49:39] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 10:49:39] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 10:49:39] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 10:49:39] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 10:49:39] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 10:49:39] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 10:49:39] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 10:49:39] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 10:49:39] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 10:49:39] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=2527634) [2026-01-27 10:49:40] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=2527634) [2026-01-27 10:49:41] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2527634) [2026-01-27 10:49:41] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=2527634) [2026-01-27 10:49:41] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=2527634) [2026-01-27 10:49:41] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=2527634) [2026-01-27 10:49:41] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=2527634) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=2527634) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:26,  8.68s/it]
(EngineCore_DP0 pid=2527634) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:43<00:48, 24.17s/it]
(EngineCore_DP0 pid=2527634) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [01:16<00:27, 27.92s/it]
(EngineCore_DP0 pid=2527634) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:50<00:00, 30.35s/it]
(EngineCore_DP0 pid=2527634) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:50<00:00, 27.54s/it]
(EngineCore_DP0 pid=2527634) 
(EngineCore_DP0 pid=2527634) [2026-01-27 10:51:32] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 6848] -> 1D uint8
(EngineCore_DP0 pid=2527634) [2026-01-27 10:51:32] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 30736384 bytes
(EngineCore_DP0 pid=2527634) [2026-01-27 10:51:32] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 6848] -> 1D uint8
(EngineCore_DP0 pid=2527634) [2026-01-27 10:51:32] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 21954560 bytes
(EngineCore_DP0 pid=2527634) [2026-01-27 10:51:32] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 6848] -> 1D uint8
(EngineCore_DP0 pid=2527634) [2026-01-27 10:51:32] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 118554624 bytes
(EngineCore_DP0 pid=2527634) [2026-01-27 10:51:32] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 18432] -> 1D uint8
(EngineCore_DP0 pid=2527634) [2026-01-27 10:51:32] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 58982400 bytes
(EngineCore_DP0 pid=2527634) 2026-01-27 10:51:56,398 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=2527634) 2026-01-27 10:52:03,972 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/8192 [00:00<?, ?it/s]
Adding requests:   0%|          | 1/8192 [00:00<1:56:05,  1.18it/s]
Adding requests:   0%|          | 2/8192 [00:01<1:04:32,  2.11it/s]
Adding requests:   0%|          | 3/8192 [00:01<43:00,  3.17it/s]  
Adding requests:   0%|          | 5/8192 [00:01<25:10,  5.42it/s]
Adding requests:   0%|          | 7/8192 [00:01<17:01,  8.01it/s]
Adding requests:   0%|          | 11/8192 [00:01<09:56, 13.71it/s]
Adding requests:   0%|          | 14/8192 [00:01<08:13, 16.58it/s]
Adding requests:   0%|          | 22/8192 [00:01<04:26, 30.70it/s]
Adding requests:   0%|          | 37/8192 [00:01<02:16, 59.61it/s]
Adding requests:   1%|          | 54/8192 [00:02<01:35, 85.18it/s]
Adding requests:   1%|          | 72/8192 [00:02<01:14, 109.60it/s]
Adding requests:   1%|          | 99/8192 [00:02<00:52, 152.90it/s]
Adding requests:   2%|         | 127/8192 [00:02<00:43, 186.66it/s]
Adding requests:   2%|         | 159/8192 [00:02<00:35, 223.55it/s]
Adding requests:   2%|         | 194/8192 [00:02<00:31, 257.82it/s]
Adding requests:   3%|         | 223/8192 [00:02<00:29, 266.06it/s]
Adding requests:   3%|         | 252/8192 [00:02<00:29, 272.22it/s]
Adding requests:   3%|         | 282/8192 [00:02<00:28, 278.83it/s]
Adding requests:   4%|         | 311/8192 [00:02<00:28, 277.71it/s]
Adding requests:   4%|         | 345/8192 [00:03<00:26, 294.12it/s]
Adding requests:   5%|         | 381/8192 [00:03<00:24, 312.54it/s]
Adding requests:   5%|         | 420/8192 [00:03<00:23, 334.25it/s]
Adding requests:   6%|         | 456/8192 [00:03<00:22, 340.00it/s]
Adding requests:   6%|         | 500/8192 [00:03<00:20, 367.97it/s]
Adding requests:   7%|         | 541/8192 [00:03<00:20, 378.35it/s]
Adding requests:   7%|         | 583/8192 [00:03<00:19, 387.97it/s]
Adding requests:   8%|         | 622/8192 [00:03<00:19, 382.85it/s]
Adding requests:   8%|         | 661/8192 [00:03<00:19, 376.96it/s]
Adding requests:   9%|         | 701/8192 [00:03<00:19, 382.63it/s]
Adding requests:   9%|         | 740/8192 [00:04<00:20, 364.42it/s]
Adding requests:  10%|         | 779/8192 [00:04<00:20, 370.32it/s]
Adding requests:  10%|         | 819/8192 [00:04<00:19, 377.04it/s]
Adding requests:  11%|         | 862/8192 [00:04<00:18, 389.74it/s]
Adding requests:  11%|         | 903/8192 [00:04<00:18, 395.56it/s]
Adding requests:  12%|        | 943/8192 [00:04<00:18, 385.77it/s]
Adding requests:  12%|        | 984/8192 [00:04<00:18, 390.30it/s]
Adding requests:  12%|        | 1024/8192 [00:04<00:19, 370.03it/s]
Adding requests:  13%|        | 1063/8192 [00:04<00:19, 374.43it/s]
Adding requests:  13%|        | 1103/8192 [00:05<00:18, 379.20it/s]
Adding requests:  14%|        | 1142/8192 [00:05<00:18, 380.98it/s]
Adding requests:  14%|        | 1182/8192 [00:05<00:18, 386.36it/s]
Adding requests:  15%|        | 1221/8192 [00:05<00:18, 377.02it/s]
Adding requests:  15%|        | 1259/8192 [00:05<00:18, 376.14it/s]
Adding requests:  16%|        | 1297/8192 [00:05<00:18, 370.92it/s]
Adding requests:  16%|        | 1338/8192 [00:05<00:18, 378.96it/s]
Adding requests:  17%|        | 1381/8192 [00:05<00:17, 393.70it/s]
Adding requests:  17%|        | 1421/8192 [00:05<00:18, 374.54it/s]
Adding requests:  18%|        | 1461/8192 [00:05<00:17, 379.31it/s]
Adding requests:  18%|        | 1501/8192 [00:06<00:17, 381.06it/s]
Adding requests:  19%|        | 1541/8192 [00:06<00:17, 384.10it/s]
Adding requests:  19%|        | 1580/8192 [00:06<00:17, 381.72it/s]
Adding requests:  20%|        | 1619/8192 [00:06<00:17, 366.71it/s]
Adding requests:  20%|        | 1659/8192 [00:06<00:17, 374.27it/s]
Adding requests:  21%|        | 1697/8192 [00:06<00:17, 368.36it/s]
Adding requests:  21%|        | 1739/8192 [00:06<00:16, 383.06it/s]
Adding requests:  22%|       | 1783/8192 [00:06<00:16, 397.91it/s]
Adding requests:  22%|       | 1823/8192 [00:06<00:16, 393.57it/s]
Adding requests:  23%|       | 1865/8192 [00:07<00:15, 401.13it/s]
Adding requests:  23%|       | 1906/8192 [00:07<00:16, 369.92it/s]
Adding requests:  24%|       | 1945/8192 [00:07<00:16, 373.23it/s]
Adding requests:  24%|       | 1983/8192 [00:07<00:16, 373.23it/s]
Adding requests:  25%|       | 2021/8192 [00:07<00:16, 365.29it/s]
Adding requests:  25%|       | 2061/8192 [00:07<00:16, 374.56it/s]
Adding requests:  26%|       | 2099/8192 [00:07<00:16, 369.42it/s]
Adding requests:  26%|       | 2139/8192 [00:07<00:16, 378.11it/s]
Adding requests:  27%|       | 2177/8192 [00:07<00:16, 371.98it/s]
Adding requests:  27%|       | 2215/8192 [00:07<00:16, 371.06it/s]
Adding requests:  28%|       | 2253/8192 [00:08<00:16, 364.19it/s]
Adding requests:  28%|       | 2292/8192 [00:08<00:15, 370.16it/s]
Adding requests:  28%|       | 2332/8192 [00:08<00:15, 376.90it/s]
Adding requests:  29%|       | 2371/8192 [00:08<00:15, 377.22it/s]
Adding requests:  29%|       | 2411/8192 [00:08<00:15, 382.41it/s]
Adding requests:  30%|       | 2450/8192 [00:08<00:14, 383.02it/s]
Adding requests:  30%|       | 2489/8192 [00:08<00:14, 382.18it/s]
Adding requests:  31%|       | 2533/8192 [00:08<00:14, 397.48it/s]
Adding requests:  31%|      | 2573/8192 [00:08<00:14, 393.54it/s]
Adding requests:  32%|      | 2614/8192 [00:09<00:14, 395.12it/s]
Adding requests:  32%|      | 2654/8192 [00:09<00:14, 389.37it/s]
Adding requests:  33%|      | 2693/8192 [00:09<00:14, 388.68it/s]
Adding requests:  33%|      | 2733/8192 [00:09<00:13, 390.40it/s]
Adding requests:  34%|      | 2773/8192 [00:09<00:14, 385.03it/s]
Adding requests:  34%|      | 2815/8192 [00:09<00:13, 388.43it/s]
Adding requests:  35%|      | 2854/8192 [00:09<00:14, 377.81it/s]
Adding requests:  35%|      | 2895/8192 [00:09<00:13, 386.94it/s]
Adding requests:  36%|      | 2934/8192 [00:09<00:13, 385.15it/s]
Adding requests:  36%|      | 2974/8192 [00:09<00:13, 388.45it/s]
Adding requests:  37%|      | 3015/8192 [00:10<00:13, 394.66it/s]
Adding requests:  37%|      | 3055/8192 [00:10<00:12, 395.52it/s]
Adding requests:  38%|      | 3096/8192 [00:10<00:12, 399.69it/s]
Adding requests:  38%|      | 3136/8192 [00:10<00:12, 399.22it/s]
Adding requests:  39%|      | 3176/8192 [00:10<00:12, 395.22it/s]
Adding requests:  39%|      | 3216/8192 [00:10<00:12, 386.84it/s]
Adding requests:  40%|      | 3255/8192 [00:10<00:13, 372.34it/s]
Adding requests:  40%|      | 3295/8192 [00:10<00:12, 377.20it/s]
Adding requests:  41%|      | 3333/8192 [00:10<00:13, 365.94it/s]
Adding requests:  41%|      | 3372/8192 [00:10<00:13, 370.07it/s]
Adding requests:  42%|     | 3416/8192 [00:11<00:12, 389.95it/s]
Adding requests:  42%|     | 3459/8192 [00:11<00:11, 398.68it/s]
Adding requests:  43%|     | 3499/8192 [00:11<00:12, 385.00it/s]
Adding requests:  43%|     | 3542/8192 [00:11<00:11, 396.27it/s]
Adding requests:  44%|     | 3585/8192 [00:11<00:11, 403.56it/s]
Adding requests:  44%|     | 3626/8192 [00:11<00:11, 387.96it/s]
Adding requests:  45%|     | 3665/8192 [00:11<00:11, 387.20it/s]
Adding requests:  45%|     | 3704/8192 [00:11<00:11, 383.53it/s]
Adding requests:  46%|     | 3750/8192 [00:11<00:10, 405.51it/s]
Adding requests:  46%|     | 3791/8192 [00:12<00:11, 369.65it/s]
Adding requests:  47%|     | 3829/8192 [00:12<00:11, 365.79it/s]
Adding requests:  47%|     | 3872/8192 [00:12<00:11, 383.10it/s]
Adding requests:  48%|     | 3911/8192 [00:12<00:11, 378.72it/s]
Adding requests:  48%|     | 3950/8192 [00:12<00:11, 369.98it/s]
Adding requests:  49%|     | 3988/8192 [00:12<00:11, 363.26it/s]
Adding requests:  49%|     | 4033/8192 [00:12<00:10, 386.55it/s]
Adding requests:  50%|     | 4072/8192 [00:12<00:11, 373.03it/s]
Adding requests:  50%|     | 4114/8192 [00:12<00:10, 383.15it/s]
Adding requests:  51%|     | 4154/8192 [00:13<00:10, 386.08it/s]
Adding requests:  51%|    | 4199/8192 [00:13<00:09, 402.67it/s]
Adding requests:  52%|    | 4240/8192 [00:13<00:09, 395.61it/s]
Adding requests:  52%|    | 4280/8192 [00:13<00:10, 385.45it/s]
Adding requests:  53%|    | 4324/8192 [00:13<00:09, 398.77it/s]
Adding requests:  53%|    | 4368/8192 [00:13<00:09, 407.28it/s]
Adding requests:  54%|    | 4409/8192 [00:13<00:09, 389.11it/s]
Adding requests:  54%|    | 4449/8192 [00:13<00:09, 384.28it/s]
Adding requests:  55%|    | 4495/8192 [00:13<00:09, 405.43it/s]
Adding requests:  55%|    | 4536/8192 [00:13<00:09, 390.93it/s]
Adding requests:  56%|    | 4576/8192 [00:14<00:09, 385.13it/s]
Adding requests:  56%|    | 4615/8192 [00:14<00:09, 374.25it/s]
Adding requests:  57%|    | 4654/8192 [00:14<00:09, 376.31it/s]
Adding requests:  57%|    | 4692/8192 [00:14<00:09, 370.60it/s]
Adding requests:  58%|    | 4731/8192 [00:14<00:09, 375.61it/s]
Adding requests:  58%|    | 4774/8192 [00:14<00:08, 389.29it/s]
Adding requests:  59%|    | 4814/8192 [00:14<00:08, 387.51it/s]
Adding requests:  59%|    | 4853/8192 [00:14<00:09, 369.44it/s]
Adding requests:  60%|    | 4891/8192 [00:14<00:08, 369.19it/s]
Adding requests:  60%|    | 4938/8192 [00:15<00:08, 395.55it/s]
Adding requests:  61%|    | 4978/8192 [00:15<00:08, 381.14it/s]
Adding requests:  61%|   | 5018/8192 [00:15<00:08, 385.85it/s]
Adding requests:  62%|   | 5057/8192 [00:15<00:08, 386.59it/s]
Adding requests:  62%|   | 5103/8192 [00:15<00:07, 405.59it/s]
Adding requests:  63%|   | 5144/8192 [00:15<00:07, 400.68it/s]
Adding requests:  63%|   | 5185/8192 [00:15<00:07, 399.11it/s]
Adding requests:  64%|   | 5226/8192 [00:15<00:07, 401.72it/s]
Adding requests:  64%|   | 5272/8192 [00:15<00:06, 417.39it/s]
Adding requests:  65%|   | 5314/8192 [00:15<00:07, 410.82it/s]
Adding requests:  65%|   | 5356/8192 [00:16<00:07, 402.96it/s]
Adding requests:  66%|   | 5399/8192 [00:16<00:06, 408.29it/s]
Adding requests:  66%|   | 5440/8192 [00:16<00:06, 406.44it/s]
Adding requests:  67%|   | 5481/8192 [00:16<00:06, 401.93it/s]
Adding requests:  67%|   | 5525/8192 [00:16<00:06, 410.95it/s]
Adding requests:  68%|   | 5569/8192 [00:16<00:06, 418.22it/s]
Adding requests:  68%|   | 5611/8192 [00:16<00:06, 413.01it/s]
Adding requests:  69%|   | 5653/8192 [00:16<00:06, 414.65it/s]
Adding requests:  70%|   | 5695/8192 [00:16<00:06, 410.74it/s]
Adding requests:  70%|   | 5744/8192 [00:16<00:05, 433.05it/s]
Adding requests:  71%|   | 5788/8192 [00:17<00:05, 414.72it/s]
Adding requests:  71%|   | 5830/8192 [00:17<00:05, 412.75it/s]
Adding requests:  72%|  | 5872/8192 [00:17<00:05, 413.64it/s]
Adding requests:  72%|  | 5918/8192 [00:17<00:05, 423.70it/s]
Adding requests:  73%|  | 5961/8192 [00:17<00:05, 418.51it/s]
Adding requests:  73%|  | 6003/8192 [00:17<00:05, 377.57it/s]
Adding requests:  74%|  | 6042/8192 [00:17<00:05, 379.42it/s]
Adding requests:  74%|  | 6081/8192 [00:17<00:05, 377.82it/s]
Adding requests:  75%|  | 6120/8192 [00:17<00:05, 379.77it/s]
Adding requests:  75%|  | 6163/8192 [00:18<00:05, 391.13it/s]
Adding requests:  76%|  | 6207/8192 [00:18<00:04, 403.67it/s]
Adding requests:  76%|  | 6248/8192 [00:18<00:04, 395.23it/s]
Adding requests:  77%|  | 6288/8192 [00:18<00:04, 396.30it/s]
Adding requests:  77%|  | 6331/8192 [00:18<00:04, 404.85it/s]
Adding requests:  78%|  | 6380/8192 [00:18<00:04, 427.68it/s]
Adding requests:  78%|  | 6423/8192 [00:18<00:04, 404.51it/s]
Adding requests:  79%|  | 6464/8192 [00:18<00:04, 390.11it/s]
Adding requests:  79%|  | 6507/8192 [00:18<00:04, 398.61it/s]
Adding requests:  80%|  | 6551/8192 [00:19<00:04, 407.33it/s]
Adding requests:  80%|  | 6592/8192 [00:19<00:04, 399.45it/s]
Adding requests:  81%|  | 6633/8192 [00:19<00:04, 382.18it/s]
Adding requests:  82%| | 6680/8192 [00:19<00:03, 406.31it/s]
Adding requests:  82%| | 6721/8192 [00:19<00:03, 393.87it/s]
Adding requests:  83%| | 6762/8192 [00:19<00:03, 396.37it/s]
Adding requests:  83%| | 6802/8192 [00:19<00:03, 390.22it/s]
Adding requests:  84%| | 6847/8192 [00:19<00:03, 405.96it/s]
Adding requests:  84%| | 6888/8192 [00:19<00:03, 398.79it/s]
Adding requests:  85%| | 6928/8192 [00:19<00:03, 395.91it/s]
Adding requests:  85%| | 6968/8192 [00:20<00:03, 395.05it/s]
Adding requests:  86%| | 7015/8192 [00:20<00:02, 416.86it/s]
Adding requests:  86%| | 7057/8192 [00:20<00:02, 397.88it/s]
Adding requests:  87%| | 7098/8192 [00:20<00:02, 390.99it/s]
Adding requests:  87%| | 7142/8192 [00:20<00:02, 404.19it/s]
Adding requests:  88%| | 7183/8192 [00:20<00:02, 395.04it/s]
Adding requests:  88%| | 7224/8192 [00:20<00:02, 398.71it/s]
Adding requests:  89%| | 7267/8192 [00:20<00:02, 407.08it/s]
Adding requests:  89%| | 7317/8192 [00:20<00:02, 432.22it/s]
Adding requests:  90%| | 7361/8192 [00:21<00:01, 423.87it/s]
Adding requests:  90%| | 7404/8192 [00:21<00:02, 375.88it/s]
Adding requests:  91%| | 7451/8192 [00:21<00:01, 401.08it/s]
Adding requests:  91%|| 7493/8192 [00:21<00:01, 402.38it/s]
Adding requests:  92%|| 7534/8192 [00:21<00:01, 387.06it/s]
Adding requests:  92%|| 7574/8192 [00:21<00:01, 389.51it/s]
Adding requests:  93%|| 7618/8192 [00:21<00:01, 399.61it/s]
Adding requests:  93%|| 7659/8192 [00:21<00:01, 395.37it/s]
Adding requests:  94%|| 7702/8192 [00:21<00:01, 402.84it/s]
Adding requests:  95%|| 7743/8192 [00:22<00:01, 386.95it/s]
Adding requests:  95%|| 7788/8192 [00:22<00:00, 404.53it/s]
Adding requests:  96%|| 7829/8192 [00:22<00:00, 391.54it/s]
Adding requests:  96%|| 7869/8192 [00:22<00:00, 383.17it/s]
Adding requests:  97%|| 7911/8192 [00:22<00:00, 393.36it/s]
Adding requests:  97%|| 7956/8192 [00:22<00:00, 406.58it/s]
Adding requests:  98%|| 7997/8192 [00:22<00:00, 405.30it/s]
Adding requests:  98%|| 8038/8192 [00:22<00:00, 399.26it/s]
Adding requests:  99%|| 8084/8192 [00:22<00:00, 416.14it/s]
Adding requests:  99%|| 8126/8192 [00:22<00:00, 403.89it/s]
Adding requests: 100%|| 8167/8192 [00:23<00:00, 405.06it/s]
Adding requests: 100%|| 8192/8192 [00:23<00:00, 353.93it/s]

Processed prompts:   0%|          | 0/8192 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 33/8192 [00:06<25:25,  5.35it/s, est. speed input: 5475.22 toks/s, output: 5.35 toks/s]
Processed prompts:   1%|          | 97/8192 [00:24<35:44,  3.77it/s, est. speed input: 3984.81 toks/s, output: 3.89 toks/s]
Processed prompts:   2%|         | 161/8192 [00:43<37:09,  3.60it/s, est. speed input: 3792.18 toks/s, output: 3.70 toks/s]
Processed prompts:   3%|         | 225/8192 [01:02<37:45,  3.52it/s, est. speed input: 3700.18 toks/s, output: 3.61 toks/s]
Processed prompts:   4%|         | 289/8192 [01:20<37:44,  3.49it/s, est. speed input: 3661.18 toks/s, output: 3.58 toks/s]
Processed prompts:   4%|         | 353/8192 [01:39<37:45,  3.46it/s, est. speed input: 3628.79 toks/s, output: 3.54 toks/s]
Processed prompts:   5%|         | 417/8192 [01:58<37:28,  3.46it/s, est. speed input: 3613.74 toks/s, output: 3.53 toks/s]
Processed prompts:   6%|         | 481/8192 [02:16<37:21,  3.44it/s, est. speed input: 3596.35 toks/s, output: 3.51 toks/s]
Processed prompts:   7%|         | 545/8192 [02:35<37:09,  3.43it/s, est. speed input: 3583.51 toks/s, output: 3.50 toks/s]
Processed prompts:   7%|         | 609/8192 [02:54<36:55,  3.42it/s, est. speed input: 3573.22 toks/s, output: 3.49 toks/s]
Processed prompts:   8%|         | 673/8192 [03:13<36:40,  3.42it/s, est. speed input: 3564.59 toks/s, output: 3.48 toks/s]
Processed prompts:   9%|         | 737/8192 [03:31<36:15,  3.43it/s, est. speed input: 3561.71 toks/s, output: 3.48 toks/s]
Processed prompts:  10%|         | 801/8192 [03:50<36:01,  3.42it/s, est. speed input: 3555.53 toks/s, output: 3.47 toks/s]
Processed prompts:  11%|         | 865/8192 [04:09<35:45,  3.41it/s, est. speed input: 3550.30 toks/s, output: 3.47 toks/s]
Processed prompts:  11%|        | 929/8192 [04:28<35:28,  3.41it/s, est. speed input: 3545.83 toks/s, output: 3.46 toks/s]
Processed prompts:  12%|        | 993/8192 [04:47<35:11,  3.41it/s, est. speed input: 3541.87 toks/s, output: 3.46 toks/s]
Processed prompts:  13%|        | 1057/8192 [05:05<34:54,  3.41it/s, est. speed input: 3538.25 toks/s, output: 3.46 toks/s]
Processed prompts:  14%|        | 1121/8192 [05:24<34:35,  3.41it/s, est. speed input: 3535.24 toks/s, output: 3.45 toks/s]
Processed prompts:  14%|        | 1185/8192 [05:43<34:09,  3.42it/s, est. speed input: 3534.96 toks/s, output: 3.45 toks/s]
Processed prompts:  15%|        | 1249/8192 [06:02<33:53,  3.41it/s, est. speed input: 3532.36 toks/s, output: 3.45 toks/s]
Processed prompts:  16%|        | 1313/8192 [06:20<33:36,  3.41it/s, est. speed input: 3530.04 toks/s, output: 3.45 toks/s]
Processed prompts:  17%|        | 1377/8192 [06:39<33:19,  3.41it/s, est. speed input: 3527.85 toks/s, output: 3.45 toks/s]
Processed prompts:  18%|        | 1441/8192 [06:58<33:02,  3.41it/s, est. speed input: 3525.74 toks/s, output: 3.44 toks/s]
Processed prompts:  18%|        | 1505/8192 [07:17<32:44,  3.40it/s, est. speed input: 3523.92 toks/s, output: 3.44 toks/s]
Processed prompts:  19%|        | 1569/8192 [07:35<32:12,  3.43it/s, est. speed input: 3525.59 toks/s, output: 3.44 toks/s]
Processed prompts:  20%|        | 1633/8192 [07:54<31:57,  3.42it/s, est. speed input: 3523.97 toks/s, output: 3.44 toks/s]
Processed prompts:  21%|        | 1697/8192 [08:13<31:41,  3.42it/s, est. speed input: 3522.54 toks/s, output: 3.44 toks/s]
Processed prompts:  21%|       | 1761/8192 [08:32<31:25,  3.41it/s, est. speed input: 3521.11 toks/s, output: 3.44 toks/s]
Processed prompts:  22%|       | 1825/8192 [08:50<31:08,  3.41it/s, est. speed input: 3519.77 toks/s, output: 3.44 toks/s]
Processed prompts:  23%|       | 1889/8192 [09:09<30:50,  3.41it/s, est. speed input: 3518.43 toks/s, output: 3.44 toks/s]
Processed prompts:  24%|       | 1953/8192 [09:28<30:32,  3.41it/s, est. speed input: 3517.34 toks/s, output: 3.43 toks/s]
Processed prompts:  25%|       | 2017/8192 [09:47<30:13,  3.40it/s, est. speed input: 3516.26 toks/s, output: 3.43 toks/s]
Processed prompts:  25%|       | 2081/8192 [10:06<29:55,  3.40it/s, est. speed input: 3515.18 toks/s, output: 3.43 toks/s]
Processed prompts:  26%|       | 2145/8192 [10:24<29:30,  3.42it/s, est. speed input: 3515.60 toks/s, output: 3.43 toks/s]
Processed prompts:  27%|       | 2209/8192 [10:43<29:13,  3.41it/s, est. speed input: 3514.68 toks/s, output: 3.43 toks/s]
Processed prompts:  28%|       | 2273/8192 [11:02<28:56,  3.41it/s, est. speed input: 3513.84 toks/s, output: 3.43 toks/s]
Processed prompts:  29%|       | 2337/8192 [11:21<28:38,  3.41it/s, est. speed input: 3513.01 toks/s, output: 3.43 toks/s]
Processed prompts:  29%|       | 2401/8192 [11:40<28:20,  3.41it/s, est. speed input: 3512.21 toks/s, output: 3.43 toks/s]
Processed prompts:  30%|       | 2465/8192 [11:58<28:02,  3.40it/s, est. speed input: 3511.43 toks/s, output: 3.43 toks/s]
Processed prompts:  31%|       | 2529/8192 [12:17<27:44,  3.40it/s, est. speed input: 3510.68 toks/s, output: 3.43 toks/s]
Processed prompts:  32%|      | 2593/8192 [12:36<27:19,  3.42it/s, est. speed input: 3511.12 toks/s, output: 3.43 toks/s]
Processed prompts:  32%|      | 2657/8192 [12:55<27:02,  3.41it/s, est. speed input: 3510.42 toks/s, output: 3.43 toks/s]
Processed prompts:  33%|      | 2721/8192 [13:13<26:39,  3.42it/s, est. speed input: 3510.76 toks/s, output: 3.43 toks/s]
Processed prompts:  34%|      | 2785/8192 [13:32<26:23,  3.41it/s, est. speed input: 3510.14 toks/s, output: 3.43 toks/s]
Processed prompts:  35%|      | 2849/8192 [13:51<26:06,  3.41it/s, est. speed input: 3509.51 toks/s, output: 3.43 toks/s]
Processed prompts:  36%|      | 2913/8192 [14:09<25:37,  3.43it/s, est. speed input: 3510.84 toks/s, output: 3.43 toks/s]
Processed prompts:  36%|      | 2977/8192 [14:28<25:23,  3.42it/s, est. speed input: 3510.22 toks/s, output: 3.43 toks/s]
Processed prompts:  37%|      | 3041/8192 [14:47<25:07,  3.42it/s, est. speed input: 3509.65 toks/s, output: 3.43 toks/s]
Processed prompts:  38%|      | 3105/8192 [15:06<24:51,  3.41it/s, est. speed input: 3509.06 toks/s, output: 3.43 toks/s]
Processed prompts:  39%|      | 3169/8192 [15:24<24:33,  3.41it/s, est. speed input: 3508.55 toks/s, output: 3.43 toks/s]
Processed prompts:  39%|      | 3233/8192 [15:43<24:15,  3.41it/s, est. speed input: 3508.05 toks/s, output: 3.43 toks/s]
Processed prompts:  40%|      | 3297/8192 [16:02<23:57,  3.41it/s, est. speed input: 3507.59 toks/s, output: 3.43 toks/s]
Processed prompts:  41%|      | 3361/8192 [16:21<23:38,  3.40it/s, est. speed input: 3507.16 toks/s, output: 3.42 toks/s]
Processed prompts:  42%|     | 3425/8192 [16:40<23:20,  3.40it/s, est. speed input: 3506.69 toks/s, output: 3.42 toks/s]
Processed prompts:  43%|     | 3489/8192 [16:58<23:02,  3.40it/s, est. speed input: 3506.24 toks/s, output: 3.42 toks/s]
Processed prompts:  43%|     | 3553/8192 [17:17<22:43,  3.40it/s, est. speed input: 3505.80 toks/s, output: 3.42 toks/s]
Processed prompts:  44%|     | 3617/8192 [17:36<22:24,  3.40it/s, est. speed input: 3505.42 toks/s, output: 3.42 toks/s]
Processed prompts:  45%|     | 3681/8192 [17:55<22:01,  3.41it/s, est. speed input: 3505.78 toks/s, output: 3.42 toks/s]
Processed prompts:  46%|     | 3745/8192 [18:14<21:44,  3.41it/s, est. speed input: 3505.36 toks/s, output: 3.42 toks/s]
Processed prompts:  46%|     | 3809/8192 [18:32<21:26,  3.41it/s, est. speed input: 3504.98 toks/s, output: 3.42 toks/s]
Processed prompts:  47%|     | 3873/8192 [18:51<21:03,  3.42it/s, est. speed input: 3505.35 toks/s, output: 3.42 toks/s]
Processed prompts:  48%|     | 3937/8192 [19:10<20:46,  3.41it/s, est. speed input: 3505.00 toks/s, output: 3.42 toks/s]
Processed prompts:  49%|     | 4001/8192 [19:28<20:24,  3.42it/s, est. speed input: 3505.33 toks/s, output: 3.42 toks/s]
Processed prompts:  50%|     | 4065/8192 [19:47<20:03,  3.43it/s, est. speed input: 3505.67 toks/s, output: 3.42 toks/s]
Processed prompts:  50%|     | 4129/8192 [20:06<19:47,  3.42it/s, est. speed input: 3505.30 toks/s, output: 3.42 toks/s]
Processed prompts:  51%|     | 4193/8192 [20:25<19:31,  3.41it/s, est. speed input: 3504.96 toks/s, output: 3.42 toks/s]
Processed prompts:  52%|    | 4257/8192 [20:43<19:13,  3.41it/s, est. speed input: 3504.61 toks/s, output: 3.42 toks/s]
Processed prompts:  53%|    | 4321/8192 [21:02<18:55,  3.41it/s, est. speed input: 3504.31 toks/s, output: 3.42 toks/s]
Processed prompts:  54%|    | 4385/8192 [21:21<18:37,  3.41it/s, est. speed input: 3504.01 toks/s, output: 3.42 toks/s]
Processed prompts:  54%|    | 4449/8192 [21:40<18:15,  3.42it/s, est. speed input: 3504.37 toks/s, output: 3.42 toks/s]
Processed prompts:  55%|    | 4513/8192 [21:58<17:53,  3.43it/s, est. speed input: 3504.67 toks/s, output: 3.42 toks/s]
Processed prompts:  56%|    | 4577/8192 [22:17<17:37,  3.42it/s, est. speed input: 3504.37 toks/s, output: 3.42 toks/s]
Processed prompts:  57%|    | 4641/8192 [22:36<17:20,  3.41it/s, est. speed input: 3504.08 toks/s, output: 3.42 toks/s]
Processed prompts:  57%|    | 4705/8192 [22:55<17:02,  3.41it/s, est. speed input: 3503.78 toks/s, output: 3.42 toks/s]
Processed prompts:  58%|    | 4769/8192 [23:13<16:44,  3.41it/s, est. speed input: 3503.51 toks/s, output: 3.42 toks/s]
Processed prompts:  59%|    | 4833/8192 [23:32<16:26,  3.41it/s, est. speed input: 3503.23 toks/s, output: 3.42 toks/s]
Processed prompts:  60%|    | 4897/8192 [23:51<16:07,  3.40it/s, est. speed input: 3502.96 toks/s, output: 3.42 toks/s]
Processed prompts:  61%|    | 4961/8192 [24:10<15:46,  3.42it/s, est. speed input: 3503.22 toks/s, output: 3.42 toks/s]
Processed prompts:  61%|   | 5025/8192 [24:28<15:28,  3.41it/s, est. speed input: 3502.98 toks/s, output: 3.42 toks/s]
Processed prompts:  62%|   | 5089/8192 [24:47<15:10,  3.41it/s, est. speed input: 3502.69 toks/s, output: 3.42 toks/s]
Processed prompts:  63%|   | 5153/8192 [25:06<14:48,  3.42it/s, est. speed input: 3503.02 toks/s, output: 3.42 toks/s]
Processed prompts:  64%|   | 5217/8192 [25:25<14:31,  3.41it/s, est. speed input: 3502.75 toks/s, output: 3.42 toks/s]
Processed prompts:  64%|   | 5281/8192 [25:43<14:10,  3.42it/s, est. speed input: 3503.02 toks/s, output: 3.42 toks/s]
Processed prompts:  65%|   | 5345/8192 [26:02<13:53,  3.42it/s, est. speed input: 3502.81 toks/s, output: 3.42 toks/s]
Processed prompts:  66%|   | 5409/8192 [26:21<13:35,  3.41it/s, est. speed input: 3502.56 toks/s, output: 3.42 toks/s]
Processed prompts:  67%|   | 5473/8192 [26:39<13:14,  3.42it/s, est. speed input: 3502.86 toks/s, output: 3.42 toks/s]
Processed prompts:  68%|   | 5537/8192 [26:58<12:54,  3.43it/s, est. speed input: 3503.17 toks/s, output: 3.42 toks/s]
Processed prompts:  68%|   | 5601/8192 [27:17<12:37,  3.42it/s, est. speed input: 3502.94 toks/s, output: 3.42 toks/s]
Processed prompts:  69%|   | 5665/8192 [27:36<12:20,  3.41it/s, est. speed input: 3502.70 toks/s, output: 3.42 toks/s]
Processed prompts:  70%|   | 5729/8192 [27:54<12:02,  3.41it/s, est. speed input: 3502.49 toks/s, output: 3.42 toks/s]
Processed prompts:  71%|   | 5793/8192 [28:13<11:43,  3.41it/s, est. speed input: 3502.26 toks/s, output: 3.42 toks/s]
Processed prompts:  71%|  | 5857/8192 [28:32<11:25,  3.41it/s, est. speed input: 3502.04 toks/s, output: 3.42 toks/s]
Processed prompts:  72%|  | 5921/8192 [28:51<11:04,  3.42it/s, est. speed input: 3502.34 toks/s, output: 3.42 toks/s]
Processed prompts:  73%|  | 5985/8192 [29:09<10:44,  3.43it/s, est. speed input: 3502.59 toks/s, output: 3.42 toks/s]
Processed prompts:  74%|  | 6049/8192 [29:28<10:26,  3.42it/s, est. speed input: 3502.38 toks/s, output: 3.42 toks/s]
Processed prompts:  75%|  | 6113/8192 [29:47<10:09,  3.41it/s, est. speed input: 3502.18 toks/s, output: 3.42 toks/s]
Processed prompts:  75%|  | 6177/8192 [30:06<09:51,  3.41it/s, est. speed input: 3501.96 toks/s, output: 3.42 toks/s]
Processed prompts:  76%|  | 6241/8192 [30:25<09:32,  3.41it/s, est. speed input: 3501.75 toks/s, output: 3.42 toks/s]
Processed prompts:  77%|  | 6305/8192 [30:43<09:14,  3.41it/s, est. speed input: 3501.57 toks/s, output: 3.42 toks/s]
Processed prompts:  78%|  | 6369/8192 [31:02<08:55,  3.40it/s, est. speed input: 3501.37 toks/s, output: 3.42 toks/s]
Processed prompts:  79%|  | 6433/8192 [31:21<08:36,  3.40it/s, est. speed input: 3501.19 toks/s, output: 3.42 toks/s]
Processed prompts:  79%|  | 6497/8192 [31:40<08:18,  3.40it/s, est. speed input: 3500.99 toks/s, output: 3.42 toks/s]
Processed prompts:  80%|  | 6561/8192 [31:59<07:59,  3.40it/s, est. speed input: 3500.82 toks/s, output: 3.42 toks/s]
Processed prompts:  81%|  | 6625/8192 [32:17<07:40,  3.40it/s, est. speed input: 3500.63 toks/s, output: 3.42 toks/s]
Processed prompts:  82%| | 6689/8192 [32:36<07:21,  3.40it/s, est. speed input: 3500.46 toks/s, output: 3.42 toks/s]
Processed prompts:  82%| | 6753/8192 [32:55<07:03,  3.40it/s, est. speed input: 3500.31 toks/s, output: 3.42 toks/s]
Processed prompts:  83%| | 6817/8192 [33:14<06:44,  3.40it/s, est. speed input: 3500.13 toks/s, output: 3.42 toks/s]
Processed prompts:  84%| | 6881/8192 [33:33<06:25,  3.40it/s, est. speed input: 3499.96 toks/s, output: 3.42 toks/s]
Processed prompts:  85%| | 6945/8192 [33:52<06:06,  3.40it/s, est. speed input: 3499.81 toks/s, output: 3.42 toks/s]
Processed prompts:  86%| | 7009/8192 [34:10<05:47,  3.40it/s, est. speed input: 3499.66 toks/s, output: 3.42 toks/s]
Processed prompts:  86%| | 7073/8192 [34:29<05:28,  3.40it/s, est. speed input: 3499.52 toks/s, output: 3.42 toks/s]
Processed prompts:  87%| | 7137/8192 [34:48<05:10,  3.40it/s, est. speed input: 3499.39 toks/s, output: 3.42 toks/s]
Processed prompts:  88%| | 7201/8192 [35:07<04:51,  3.40it/s, est. speed input: 3499.23 toks/s, output: 3.42 toks/s]
Processed prompts:  89%| | 7265/8192 [35:26<04:32,  3.40it/s, est. speed input: 3499.10 toks/s, output: 3.42 toks/s]
Processed prompts:  89%| | 7329/8192 [35:44<04:13,  3.40it/s, est. speed input: 3498.95 toks/s, output: 3.42 toks/s]
Processed prompts:  90%| | 7393/8192 [36:03<03:54,  3.40it/s, est. speed input: 3498.81 toks/s, output: 3.42 toks/s]
Processed prompts:  91%| | 7457/8192 [36:22<03:36,  3.40it/s, est. speed input: 3498.67 toks/s, output: 3.42 toks/s]
Processed prompts:  92%|| 7521/8192 [36:41<03:17,  3.40it/s, est. speed input: 3498.52 toks/s, output: 3.42 toks/s]
Processed prompts:  93%|| 7585/8192 [36:59<02:57,  3.41it/s, est. speed input: 3498.76 toks/s, output: 3.42 toks/s]
Processed prompts:  93%|| 7649/8192 [37:18<02:39,  3.41it/s, est. speed input: 3498.61 toks/s, output: 3.42 toks/s]
Processed prompts:  94%|| 7713/8192 [37:37<02:20,  3.41it/s, est. speed input: 3498.48 toks/s, output: 3.42 toks/s]
Processed prompts:  95%|| 7777/8192 [37:56<02:01,  3.40it/s, est. speed input: 3498.33 toks/s, output: 3.42 toks/s]
Processed prompts:  96%|| 7841/8192 [38:15<01:43,  3.40it/s, est. speed input: 3498.20 toks/s, output: 3.42 toks/s]
Processed prompts:  96%|| 7905/8192 [38:34<01:24,  3.40it/s, est. speed input: 3498.08 toks/s, output: 3.42 toks/s]
Processed prompts:  97%|| 7969/8192 [38:52<01:05,  3.40it/s, est. speed input: 3497.97 toks/s, output: 3.42 toks/s]
Processed prompts:  98%|| 8033/8192 [39:11<00:46,  3.40it/s, est. speed input: 3497.84 toks/s, output: 3.42 toks/s]
Processed prompts:  99%|| 8097/8192 [39:30<00:27,  3.40it/s, est. speed input: 3497.73 toks/s, output: 3.42 toks/s]
Processed prompts: 100%|| 8161/8192 [39:40<00:07,  3.99it/s, est. speed input: 3511.16 toks/s, output: 3.43 toks/s]
Processed prompts: 100%|| 8192/8192 [39:40<00:00,  3.99it/s, est. speed input: 3524.50 toks/s, output: 3.44 toks/s]
Processed prompts: 100%|| 8192/8192 [39:40<00:00,  3.44it/s, est. speed input: 3524.50 toks/s, output: 3.44 toks/s]
[rank0]:[W127 11:32:39.175697314 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-28 09:03:29
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_6
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_6 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/BitNet-2B-FP8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 09:03:32 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-28 09:03:33 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=3724204) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=3724204) WARNING 01-28 09:03:59 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 27.69 requests/s, 14205.57 total tokens/s, 27.69 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-28 09:03:32] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-28 09:03:32] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 09:03:32] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 09:03:32] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:03:32] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:03:32] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:03:32] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:03:32] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:03:32] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 09:03:32] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 09:03:32] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 09:03:32] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 09:03:32] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 09:03:32] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 09:03:36] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-28 09:03:36] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 09:03:36] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 09:03:36] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:03:36] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:03:36] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:03:36] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:03:36] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:03:36] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 09:03:36] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 09:03:36] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 09:03:36] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 09:03:36] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 09:03:36] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3724204) [2026-01-28 09:03:37] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3724204) [2026-01-28 09:03:37] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=3724204) [2026-01-28 09:03:37] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3724204) [2026-01-28 09:03:37] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=3724204) [2026-01-28 09:03:37] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: BitNet-2B-FP8
(EngineCore_DP0 pid=3724204) [2026-01-28 09:03:37] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=3724204) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3724204) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:15<00:00, 15.27s/it]
(EngineCore_DP0 pid=3724204) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:15<00:00, 15.27s/it]
(EngineCore_DP0 pid=3724204) 
(EngineCore_DP0 pid=3724204) [2026-01-28 09:03:53] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3840, 3424] -> 1D uint8
(EngineCore_DP0 pid=3724204) [2026-01-28 09:03:53] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8232960 bytes
(EngineCore_DP0 pid=3724204) [2026-01-28 09:03:53] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 3424] -> 1D uint8
(EngineCore_DP0 pid=3724204) [2026-01-28 09:03:53] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5488640 bytes
(EngineCore_DP0 pid=3724204) [2026-01-28 09:03:53] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [13824, 3424] -> 1D uint8
(EngineCore_DP0 pid=3724204) [2026-01-28 09:03:53] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 29638656 bytes
(EngineCore_DP0 pid=3724204) [2026-01-28 09:03:53] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 9216] -> 1D uint8
(EngineCore_DP0 pid=3724204) [2026-01-28 09:03:53] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14745600 bytes
(EngineCore_DP0 pid=3724204) 2026-01-28 09:03:59,025 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3724204) 2026-01-28 09:03:59,039 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 1296.39it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:19,  6.64it/s, est. speed input: 3400.12 toks/s, output: 6.64 toks/s]
Processed prompts:   3%|         | 4/128 [00:00<00:07, 17.71it/s, est. speed input: 8061.82 toks/s, output: 15.74 toks/s]
Processed prompts:   5%|         | 7/128 [00:00<00:05, 22.38it/s, est. speed input: 10022.31 toks/s, output: 19.57 toks/s]
Processed prompts:   8%|         | 10/128 [00:00<00:04, 24.88it/s, est. speed input: 11115.93 toks/s, output: 21.71 toks/s]
Processed prompts:  10%|         | 13/128 [00:00<00:04, 26.47it/s, est. speed input: 11837.55 toks/s, output: 23.12 toks/s]
Processed prompts:  12%|        | 16/128 [00:00<00:04, 27.57it/s, est. speed input: 12359.08 toks/s, output: 24.14 toks/s]
Processed prompts:  15%|        | 19/128 [00:00<00:03, 28.12it/s, est. speed input: 12711.60 toks/s, output: 24.83 toks/s]
Processed prompts:  17%|        | 22/128 [00:00<00:03, 27.90it/s, est. speed input: 12879.22 toks/s, output: 25.15 toks/s]
Processed prompts:  20%|        | 25/128 [00:00<00:03, 28.36it/s, est. speed input: 13106.59 toks/s, output: 25.60 toks/s]
Processed prompts:  22%|       | 28/128 [00:01<00:03, 28.64it/s, est. speed input: 13285.89 toks/s, output: 25.95 toks/s]
Processed prompts:  24%|       | 31/128 [00:01<00:03, 28.86it/s, est. speed input: 13436.50 toks/s, output: 26.24 toks/s]
Processed prompts:  27%|       | 34/128 [00:01<00:03, 28.96it/s, est. speed input: 13557.36 toks/s, output: 26.48 toks/s]
Processed prompts:  29%|       | 37/128 [00:01<00:03, 28.98it/s, est. speed input: 13654.19 toks/s, output: 26.67 toks/s]
Processed prompts:  31%|      | 40/128 [00:01<00:03, 29.06it/s, est. speed input: 13744.96 toks/s, output: 26.85 toks/s]
Processed prompts:  34%|      | 43/128 [00:01<00:02, 29.11it/s, est. speed input: 13823.96 toks/s, output: 27.00 toks/s]
Processed prompts:  36%|      | 46/128 [00:01<00:02, 29.14it/s, est. speed input: 13891.92 toks/s, output: 27.13 toks/s]
Processed prompts:  38%|      | 49/128 [00:01<00:02, 29.25it/s, est. speed input: 13960.94 toks/s, output: 27.27 toks/s]
Processed prompts:  41%|      | 52/128 [00:01<00:02, 29.01it/s, est. speed input: 13994.88 toks/s, output: 27.33 toks/s]
Processed prompts:  43%|     | 55/128 [00:02<00:02, 28.81it/s, est. speed input: 14022.21 toks/s, output: 27.39 toks/s]
Processed prompts:  45%|     | 58/128 [00:02<00:02, 29.03it/s, est. speed input: 14075.43 toks/s, output: 27.49 toks/s]
Processed prompts:  48%|     | 61/128 [00:02<00:02, 29.03it/s, est. speed input: 14112.52 toks/s, output: 27.56 toks/s]
Processed prompts:  50%|     | 64/128 [00:02<00:02, 29.06it/s, est. speed input: 14148.17 toks/s, output: 27.63 toks/s]
Processed prompts:  52%|    | 67/128 [00:02<00:02, 29.13it/s, est. speed input: 14184.41 toks/s, output: 27.70 toks/s]
Processed prompts:  55%|    | 70/128 [00:02<00:01, 29.21it/s, est. speed input: 14219.59 toks/s, output: 27.77 toks/s]
Processed prompts:  57%|    | 73/128 [00:02<00:01, 29.28it/s, est. speed input: 14252.66 toks/s, output: 27.84 toks/s]
Processed prompts:  59%|    | 76/128 [00:02<00:01, 29.29it/s, est. speed input: 14281.14 toks/s, output: 27.89 toks/s]
Processed prompts:  62%|   | 79/128 [00:02<00:01, 29.26it/s, est. speed input: 14305.14 toks/s, output: 27.94 toks/s]
Processed prompts:  64%|   | 82/128 [00:02<00:01, 29.15it/s, est. speed input: 14322.80 toks/s, output: 27.97 toks/s]
Processed prompts:  66%|   | 85/128 [00:03<00:01, 28.69it/s, est. speed input: 14316.86 toks/s, output: 27.96 toks/s]
Processed prompts:  69%|   | 88/128 [00:03<00:01, 28.71it/s, est. speed input: 14330.56 toks/s, output: 27.99 toks/s]
Processed prompts:  71%|   | 91/128 [00:03<00:01, 28.76it/s, est. speed input: 14345.05 toks/s, output: 28.02 toks/s]
Processed prompts:  73%|  | 94/128 [00:03<00:01, 28.93it/s, est. speed input: 14365.73 toks/s, output: 28.06 toks/s]
Processed prompts:  76%|  | 97/128 [00:03<00:01, 29.05it/s, est. speed input: 14385.02 toks/s, output: 28.10 toks/s]
Processed prompts:  78%|  | 100/128 [00:03<00:00, 29.00it/s, est. speed input: 14396.68 toks/s, output: 28.12 toks/s]
Processed prompts:  80%|  | 103/128 [00:03<00:00, 28.97it/s, est. speed input: 14408.01 toks/s, output: 28.14 toks/s]
Processed prompts:  83%| | 106/128 [00:03<00:00, 29.09it/s, est. speed input: 14425.11 toks/s, output: 28.17 toks/s]
Processed prompts:  85%| | 109/128 [00:03<00:00, 28.93it/s, est. speed input: 14430.63 toks/s, output: 28.18 toks/s]
Processed prompts:  88%| | 112/128 [00:03<00:00, 29.12it/s, est. speed input: 14448.92 toks/s, output: 28.22 toks/s]
Processed prompts:  90%| | 115/128 [00:04<00:00, 28.65it/s, est. speed input: 14440.32 toks/s, output: 28.20 toks/s]
Processed prompts:  92%|| 118/128 [00:04<00:00, 28.95it/s, est. speed input: 14458.79 toks/s, output: 28.24 toks/s]
Processed prompts:  95%|| 121/128 [00:04<00:00, 29.06it/s, est. speed input: 14472.09 toks/s, output: 28.27 toks/s]
Processed prompts:  97%|| 124/128 [00:04<00:00, 28.87it/s, est. speed input: 14474.06 toks/s, output: 28.27 toks/s]
Processed prompts:  99%|| 127/128 [00:04<00:00, 28.94it/s, est. speed input: 14483.93 toks/s, output: 28.29 toks/s]
Processed prompts: 100%|| 128/128 [00:04<00:00, 28.94it/s, est. speed input: 14491.83 toks/s, output: 28.30 toks/s]
Processed prompts: 100%|| 128/128 [00:04<00:00, 28.30it/s, est. speed input: 14491.83 toks/s, output: 28.30 toks/s]
[rank0]:[W128 09:04:04.525394958 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-28 09:04:06
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/BitNet-2B-FP8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 09:04:10 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-28 09:04:10 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=3724936) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=3724936) WARNING 01-28 09:04:36 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 15.10 requests/s, 15481.17 total tokens/s, 15.10 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-28 09:04:10] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-28 09:04:10] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 09:04:10] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 09:04:10] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:04:10] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:04:10] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:04:10] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:04:10] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:04:10] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 09:04:10] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 09:04:10] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 09:04:10] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 09:04:10] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 09:04:10] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 09:04:13] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-28 09:04:13] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 09:04:13] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 09:04:13] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:04:13] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:04:13] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:04:13] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:04:13] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:04:13] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 09:04:13] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 09:04:13] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 09:04:13] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 09:04:13] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 09:04:13] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3724936) [2026-01-28 09:04:14] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3724936) [2026-01-28 09:04:14] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=3724936) [2026-01-28 09:04:14] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3724936) [2026-01-28 09:04:14] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=3724936) [2026-01-28 09:04:14] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: BitNet-2B-FP8
(EngineCore_DP0 pid=3724936) [2026-01-28 09:04:14] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=3724936) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3724936) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:14<00:00, 14.53s/it]
(EngineCore_DP0 pid=3724936) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:14<00:00, 14.53s/it]
(EngineCore_DP0 pid=3724936) 
(EngineCore_DP0 pid=3724936) [2026-01-28 09:04:30] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3840, 3424] -> 1D uint8
(EngineCore_DP0 pid=3724936) [2026-01-28 09:04:30] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8232960 bytes
(EngineCore_DP0 pid=3724936) [2026-01-28 09:04:30] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 3424] -> 1D uint8
(EngineCore_DP0 pid=3724936) [2026-01-28 09:04:30] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5488640 bytes
(EngineCore_DP0 pid=3724936) [2026-01-28 09:04:30] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [13824, 3424] -> 1D uint8
(EngineCore_DP0 pid=3724936) [2026-01-28 09:04:30] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 29638656 bytes
(EngineCore_DP0 pid=3724936) [2026-01-28 09:04:30] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 9216] -> 1D uint8
(EngineCore_DP0 pid=3724936) [2026-01-28 09:04:30] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14745600 bytes
(EngineCore_DP0 pid=3724936) 2026-01-28 09:04:35,690 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3724936) 2026-01-28 09:04:35,704 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  57%|    | 73/128 [00:00<00:00, 726.14it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 729.11it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:14,  8.63it/s, est. speed input: 8841.73 toks/s, output: 8.63 toks/s]
Processed prompts:   2%|         | 3/128 [00:00<00:09, 12.86it/s, est. speed input: 12551.33 toks/s, output: 12.26 toks/s]
Processed prompts:   4%|         | 5/128 [00:00<00:08, 14.12it/s, est. speed input: 13718.66 toks/s, output: 13.40 toks/s]
Processed prompts:   5%|         | 7/128 [00:00<00:08, 14.63it/s, est. speed input: 14246.76 toks/s, output: 13.91 toks/s]
Processed prompts:   7%|         | 9/128 [00:00<00:07, 15.01it/s, est. speed input: 14610.09 toks/s, output: 14.27 toks/s]
Processed prompts:   9%|         | 11/128 [00:00<00:07, 15.25it/s, est. speed input: 14862.34 toks/s, output: 14.51 toks/s]
Processed prompts:  10%|         | 13/128 [00:00<00:07, 15.42it/s, est. speed input: 15046.70 toks/s, output: 14.69 toks/s]
Processed prompts:  12%|        | 15/128 [00:01<00:07, 15.30it/s, est. speed input: 15095.01 toks/s, output: 14.74 toks/s]
Processed prompts:  13%|        | 17/128 [00:01<00:07, 15.22it/s, est. speed input: 15130.51 toks/s, output: 14.78 toks/s]
Processed prompts:  15%|        | 19/128 [00:01<00:07, 15.31it/s, est. speed input: 15208.43 toks/s, output: 14.85 toks/s]
Processed prompts:  16%|        | 21/128 [00:01<00:06, 15.47it/s, est. speed input: 15298.32 toks/s, output: 14.94 toks/s]
Processed prompts:  18%|        | 23/128 [00:01<00:06, 15.45it/s, est. speed input: 15339.63 toks/s, output: 14.98 toks/s]
Processed prompts:  20%|        | 25/128 [00:01<00:06, 15.59it/s, est. speed input: 15411.38 toks/s, output: 15.05 toks/s]
Processed prompts:  21%|        | 27/128 [00:01<00:06, 15.71it/s, est. speed input: 15478.34 toks/s, output: 15.12 toks/s]
Processed prompts:  23%|       | 29/128 [00:01<00:06, 15.60it/s, est. speed input: 15495.86 toks/s, output: 15.13 toks/s]
Processed prompts:  24%|       | 31/128 [00:02<00:06, 15.57it/s, est. speed input: 15519.80 toks/s, output: 15.16 toks/s]
Processed prompts:  26%|       | 33/128 [00:02<00:06, 15.34it/s, est. speed input: 15499.84 toks/s, output: 15.14 toks/s]
Processed prompts:  27%|       | 35/128 [00:02<00:06, 15.49it/s, est. speed input: 15538.46 toks/s, output: 15.17 toks/s]
Processed prompts:  29%|       | 37/128 [00:02<00:05, 15.43it/s, est. speed input: 15545.70 toks/s, output: 15.18 toks/s]
Processed prompts:  30%|       | 39/128 [00:02<00:05, 15.51it/s, est. speed input: 15571.67 toks/s, output: 15.21 toks/s]
Processed prompts:  32%|      | 41/128 [00:02<00:05, 15.64it/s, est. speed input: 15607.34 toks/s, output: 15.24 toks/s]
Processed prompts:  34%|      | 43/128 [00:02<00:05, 15.63it/s, est. speed input: 15624.09 toks/s, output: 15.26 toks/s]
Processed prompts:  35%|      | 45/128 [00:02<00:05, 15.66it/s, est. speed input: 15645.40 toks/s, output: 15.28 toks/s]
Processed prompts:  37%|      | 47/128 [00:03<00:05, 15.73it/s, est. speed input: 15671.11 toks/s, output: 15.30 toks/s]
Processed prompts:  38%|      | 49/128 [00:03<00:05, 15.41it/s, est. speed input: 15645.09 toks/s, output: 15.28 toks/s]
Processed prompts:  40%|      | 51/128 [00:03<00:04, 15.52it/s, est. speed input: 15665.24 toks/s, output: 15.30 toks/s]
Processed prompts:  41%|     | 53/128 [00:03<00:04, 15.53it/s, est. speed input: 15674.99 toks/s, output: 15.31 toks/s]
Processed prompts:  43%|     | 55/128 [00:03<00:04, 15.60it/s, est. speed input: 15691.53 toks/s, output: 15.32 toks/s]
Processed prompts:  45%|     | 57/128 [00:03<00:04, 15.52it/s, est. speed input: 15691.94 toks/s, output: 15.32 toks/s]
Processed prompts:  46%|     | 59/128 [00:03<00:04, 15.48it/s, est. speed input: 15694.50 toks/s, output: 15.33 toks/s]
Processed prompts:  48%|     | 61/128 [00:03<00:04, 15.58it/s, est. speed input: 15710.83 toks/s, output: 15.34 toks/s]
Processed prompts:  49%|     | 63/128 [00:04<00:04, 15.56it/s, est. speed input: 15715.85 toks/s, output: 15.35 toks/s]
Processed prompts:  51%|     | 65/128 [00:04<00:04, 15.32it/s, est. speed input: 15697.35 toks/s, output: 15.33 toks/s]
Processed prompts:  52%|    | 67/128 [00:04<00:03, 15.36it/s, est. speed input: 15701.48 toks/s, output: 15.33 toks/s]
Processed prompts:  54%|    | 69/128 [00:04<00:03, 15.38it/s, est. speed input: 15704.46 toks/s, output: 15.34 toks/s]
Processed prompts:  55%|    | 71/128 [00:04<00:03, 15.50it/s, est. speed input: 15716.90 toks/s, output: 15.35 toks/s]
Processed prompts:  57%|    | 73/128 [00:04<00:03, 15.51it/s, est. speed input: 15722.30 toks/s, output: 15.35 toks/s]
Processed prompts:  59%|    | 75/128 [00:04<00:03, 15.53it/s, est. speed input: 15728.14 toks/s, output: 15.36 toks/s]
Processed prompts:  60%|    | 77/128 [00:05<00:03, 15.51it/s, est. speed input: 15730.95 toks/s, output: 15.36 toks/s]
Processed prompts:  62%|   | 79/128 [00:05<00:03, 15.51it/s, est. speed input: 15734.58 toks/s, output: 15.37 toks/s]
Processed prompts:  63%|   | 81/128 [00:05<00:03, 15.42it/s, est. speed input: 15731.02 toks/s, output: 15.36 toks/s]
Processed prompts:  65%|   | 83/128 [00:05<00:02, 15.32it/s, est. speed input: 15724.19 toks/s, output: 15.36 toks/s]
Processed prompts:  66%|   | 85/128 [00:05<00:02, 15.37it/s, est. speed input: 15726.89 toks/s, output: 15.36 toks/s]
Processed prompts:  68%|   | 87/128 [00:05<00:02, 15.52it/s, est. speed input: 15739.28 toks/s, output: 15.37 toks/s]
Processed prompts:  70%|   | 89/128 [00:05<00:02, 15.61it/s, est. speed input: 15749.60 toks/s, output: 15.38 toks/s]
Processed prompts:  71%|   | 91/128 [00:05<00:02, 15.67it/s, est. speed input: 15758.63 toks/s, output: 15.39 toks/s]
Processed prompts:  73%|  | 93/128 [00:06<00:02, 15.69it/s, est. speed input: 15765.99 toks/s, output: 15.40 toks/s]
Processed prompts:  74%|  | 95/128 [00:06<00:02, 15.66it/s, est. speed input: 15770.50 toks/s, output: 15.40 toks/s]
Processed prompts:  76%|  | 97/128 [00:06<00:01, 15.55it/s, est. speed input: 15767.87 toks/s, output: 15.40 toks/s]
Processed prompts:  77%|  | 99/128 [00:06<00:01, 15.49it/s, est. speed input: 15767.48 toks/s, output: 15.40 toks/s]
Processed prompts:  79%|  | 101/128 [00:06<00:01, 15.58it/s, est. speed input: 15775.23 toks/s, output: 15.41 toks/s]
Processed prompts:  80%|  | 103/128 [00:06<00:01, 15.64it/s, est. speed input: 15782.39 toks/s, output: 15.41 toks/s]
Processed prompts:  82%| | 105/128 [00:06<00:01, 15.67it/s, est. speed input: 15788.40 toks/s, output: 15.42 toks/s]
Processed prompts:  84%| | 107/128 [00:06<00:01, 15.51it/s, est. speed input: 15783.45 toks/s, output: 15.41 toks/s]
Processed prompts:  85%| | 109/128 [00:07<00:01, 15.45it/s, est. speed input: 15781.44 toks/s, output: 15.41 toks/s]
Processed prompts:  87%| | 111/128 [00:07<00:01, 15.59it/s, est. speed input: 15790.89 toks/s, output: 15.42 toks/s]
Processed prompts:  88%| | 113/128 [00:07<00:00, 15.35it/s, est. speed input: 15779.51 toks/s, output: 15.41 toks/s]
Processed prompts:  90%| | 115/128 [00:07<00:00, 15.38it/s, est. speed input: 15780.10 toks/s, output: 15.41 toks/s]
Processed prompts:  91%|| 117/128 [00:07<00:00, 15.46it/s, est. speed input: 15784.20 toks/s, output: 15.41 toks/s]
Processed prompts:  93%|| 119/128 [00:07<00:00, 15.52it/s, est. speed input: 15788.47 toks/s, output: 15.42 toks/s]
Processed prompts:  95%|| 121/128 [00:07<00:00, 15.53it/s, est. speed input: 15790.76 toks/s, output: 15.42 toks/s]
Processed prompts:  96%|| 123/128 [00:07<00:00, 15.60it/s, est. speed input: 15796.25 toks/s, output: 15.43 toks/s]
Processed prompts:  98%|| 125/128 [00:08<00:00, 15.48it/s, est. speed input: 15792.48 toks/s, output: 15.42 toks/s]
Processed prompts:  99%|| 127/128 [00:08<00:00, 15.44it/s, est. speed input: 15791.66 toks/s, output: 15.42 toks/s]
Processed prompts: 100%|| 128/128 [00:08<00:00, 15.44it/s, est. speed input: 15795.00 toks/s, output: 15.42 toks/s]
Processed prompts: 100%|| 128/128 [00:08<00:00, 15.42it/s, est. speed input: 15795.00 toks/s, output: 15.42 toks/s]
[rank0]:[W128 09:04:44.957443910 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-28 09:04:47
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/BitNet-2B-FP8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 09:04:51 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-28 09:04:51 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=3725693) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=3725693) WARNING 01-28 09:05:16 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 15.44 requests/s, 15828.01 total tokens/s, 15.44 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-28 09:04:51] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-28 09:04:51] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 09:04:51] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 09:04:51] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:04:51] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:04:51] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:04:51] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:04:51] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:04:51] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 09:04:51] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 09:04:51] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 09:04:51] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 09:04:51] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 09:04:51] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 09:04:54] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-28 09:04:54] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 09:04:54] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 09:04:54] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:04:54] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:04:54] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:04:54] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:04:54] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:04:54] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 09:04:54] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 09:04:54] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 09:04:54] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 09:04:54] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 09:04:54] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3725693) [2026-01-28 09:04:55] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3725693) [2026-01-28 09:04:55] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=3725693) [2026-01-28 09:04:55] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3725693) [2026-01-28 09:04:55] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=3725693) [2026-01-28 09:04:55] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: BitNet-2B-FP8
(EngineCore_DP0 pid=3725693) [2026-01-28 09:04:55] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=3725693) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3725693) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:14<00:00, 14.34s/it]
(EngineCore_DP0 pid=3725693) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:14<00:00, 14.34s/it]
(EngineCore_DP0 pid=3725693) 
(EngineCore_DP0 pid=3725693) [2026-01-28 09:05:10] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3840, 3424] -> 1D uint8
(EngineCore_DP0 pid=3725693) [2026-01-28 09:05:10] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8232960 bytes
(EngineCore_DP0 pid=3725693) [2026-01-28 09:05:10] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 3424] -> 1D uint8
(EngineCore_DP0 pid=3725693) [2026-01-28 09:05:10] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5488640 bytes
(EngineCore_DP0 pid=3725693) [2026-01-28 09:05:10] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [13824, 3424] -> 1D uint8
(EngineCore_DP0 pid=3725693) [2026-01-28 09:05:10] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 29638656 bytes
(EngineCore_DP0 pid=3725693) [2026-01-28 09:05:10] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 9216] -> 1D uint8
(EngineCore_DP0 pid=3725693) [2026-01-28 09:05:10] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14745600 bytes
(EngineCore_DP0 pid=3725693) 2026-01-28 09:05:16,251 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3725693) 2026-01-28 09:05:16,263 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  26%|       | 67/256 [00:00<00:00, 667.60it/s]
Adding requests:  52%|    | 134/256 [00:00<00:00, 642.81it/s]
Adding requests:  78%|  | 199/256 [00:00<00:00, 590.19it/s]
Adding requests: 100%|| 256/256 [00:00<00:00, 597.14it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 6/256 [00:00<00:06, 38.44it/s, est. speed input: 39376.04 toks/s, output: 38.45 toks/s]
Processed prompts:   4%|         | 10/256 [00:00<00:11, 21.97it/s, est. speed input: 24380.96 toks/s, output: 23.81 toks/s]
Processed prompts:   5%|         | 13/256 [00:00<00:10, 22.37it/s, est. speed input: 24227.35 toks/s, output: 23.66 toks/s]
Processed prompts:   6%|         | 16/256 [00:00<00:13, 17.26it/s, est. speed input: 20369.88 toks/s, output: 19.89 toks/s]
Processed prompts:   7%|         | 18/256 [00:00<00:14, 16.79it/s, est. speed input: 19738.49 toks/s, output: 19.28 toks/s]
Processed prompts:   8%|         | 20/256 [00:01<00:14, 16.47it/s, est. speed input: 19284.68 toks/s, output: 18.83 toks/s]
Processed prompts:   9%|         | 22/256 [00:01<00:14, 16.23it/s, est. speed input: 18927.31 toks/s, output: 18.48 toks/s]
Processed prompts:   9%|         | 24/256 [00:01<00:14, 15.90it/s, est. speed input: 18579.49 toks/s, output: 18.14 toks/s]
Processed prompts:  10%|         | 26/256 [00:01<00:14, 15.74it/s, est. speed input: 18323.63 toks/s, output: 17.89 toks/s]
Processed prompts:  11%|         | 28/256 [00:01<00:14, 15.75it/s, est. speed input: 18147.96 toks/s, output: 17.72 toks/s]
Processed prompts:  12%|        | 30/256 [00:01<00:14, 15.70it/s, est. speed input: 17984.64 toks/s, output: 17.56 toks/s]
Processed prompts:  12%|        | 32/256 [00:01<00:14, 15.74it/s, est. speed input: 17861.17 toks/s, output: 17.44 toks/s]
Processed prompts:  13%|        | 34/256 [00:01<00:14, 15.71it/s, est. speed input: 17741.73 toks/s, output: 17.33 toks/s]
Processed prompts:  14%|        | 36/256 [00:02<00:13, 15.77it/s, est. speed input: 17655.20 toks/s, output: 17.24 toks/s]
Processed prompts:  15%|        | 38/256 [00:02<00:13, 15.72it/s, est. speed input: 17558.41 toks/s, output: 17.15 toks/s]
Processed prompts:  16%|        | 40/256 [00:02<00:13, 15.62it/s, est. speed input: 17458.26 toks/s, output: 17.05 toks/s]
Processed prompts:  16%|        | 42/256 [00:02<00:13, 15.48it/s, est. speed input: 17354.56 toks/s, output: 16.95 toks/s]
Processed prompts:  17%|        | 44/256 [00:02<00:13, 15.51it/s, est. speed input: 17285.53 toks/s, output: 16.88 toks/s]
Processed prompts:  18%|        | 46/256 [00:02<00:13, 15.57it/s, est. speed input: 17229.46 toks/s, output: 16.83 toks/s]
Processed prompts:  19%|        | 48/256 [00:02<00:13, 15.57it/s, est. speed input: 17172.28 toks/s, output: 16.77 toks/s]
Processed prompts:  20%|        | 50/256 [00:02<00:13, 15.59it/s, est. speed input: 17123.11 toks/s, output: 16.72 toks/s]
Processed prompts:  20%|        | 52/256 [00:03<00:13, 15.66it/s, est. speed input: 17085.36 toks/s, output: 16.68 toks/s]
Processed prompts:  21%|        | 54/256 [00:03<00:12, 15.65it/s, est. speed input: 17042.40 toks/s, output: 16.64 toks/s]
Processed prompts:  22%|       | 56/256 [00:03<00:12, 15.65it/s, est. speed input: 17003.92 toks/s, output: 16.61 toks/s]
Processed prompts:  23%|       | 58/256 [00:03<00:12, 15.52it/s, est. speed input: 16951.10 toks/s, output: 16.55 toks/s]
Processed prompts:  23%|       | 60/256 [00:03<00:12, 15.57it/s, est. speed input: 16920.06 toks/s, output: 16.52 toks/s]
Processed prompts:  24%|       | 62/256 [00:03<00:12, 15.62it/s, est. speed input: 16892.61 toks/s, output: 16.50 toks/s]
Processed prompts:  25%|       | 64/256 [00:03<00:12, 15.62it/s, est. speed input: 16863.34 toks/s, output: 16.47 toks/s]
Processed prompts:  26%|       | 66/256 [00:04<00:12, 15.55it/s, est. speed input: 16828.01 toks/s, output: 16.43 toks/s]
Processed prompts:  27%|       | 68/256 [00:04<00:12, 15.62it/s, est. speed input: 16807.69 toks/s, output: 16.41 toks/s]
Processed prompts:  27%|       | 70/256 [00:04<00:11, 15.61it/s, est. speed input: 16782.54 toks/s, output: 16.39 toks/s]
Processed prompts:  28%|       | 72/256 [00:04<00:11, 15.58it/s, est. speed input: 16755.82 toks/s, output: 16.36 toks/s]
Processed prompts:  29%|       | 74/256 [00:04<00:11, 15.44it/s, est. speed input: 16718.55 toks/s, output: 16.33 toks/s]
Processed prompts:  30%|       | 76/256 [00:04<00:11, 15.54it/s, est. speed input: 16702.99 toks/s, output: 16.31 toks/s]
Processed prompts:  30%|       | 78/256 [00:04<00:11, 15.63it/s, est. speed input: 16690.64 toks/s, output: 16.30 toks/s]
Processed prompts:  31%|      | 80/256 [00:04<00:11, 15.63it/s, est. speed input: 16672.58 toks/s, output: 16.28 toks/s]
Processed prompts:  32%|      | 82/256 [00:05<00:11, 15.63it/s, est. speed input: 16655.56 toks/s, output: 16.27 toks/s]
Processed prompts:  33%|      | 84/256 [00:05<00:10, 15.65it/s, est. speed input: 16641.20 toks/s, output: 16.25 toks/s]
Processed prompts:  34%|      | 86/256 [00:05<00:10, 15.63it/s, est. speed input: 16624.59 toks/s, output: 16.23 toks/s]
Processed prompts:  34%|      | 88/256 [00:05<00:10, 15.67it/s, est. speed input: 16613.19 toks/s, output: 16.22 toks/s]
Processed prompts:  35%|      | 90/256 [00:05<00:10, 15.45it/s, est. speed input: 16582.10 toks/s, output: 16.19 toks/s]
Processed prompts:  36%|      | 92/256 [00:05<00:10, 15.46it/s, est. speed input: 16565.41 toks/s, output: 16.18 toks/s]
Processed prompts:  37%|      | 94/256 [00:05<00:10, 15.55it/s, est. speed input: 16556.55 toks/s, output: 16.17 toks/s]
Processed prompts:  38%|      | 96/256 [00:05<00:10, 15.66it/s, est. speed input: 16551.40 toks/s, output: 16.16 toks/s]
Processed prompts:  38%|      | 98/256 [00:06<00:10, 15.69it/s, est. speed input: 16542.56 toks/s, output: 16.15 toks/s]
Processed prompts:  39%|      | 100/256 [00:06<00:09, 15.64it/s, est. speed input: 16529.28 toks/s, output: 16.14 toks/s]
Processed prompts:  40%|      | 102/256 [00:06<00:09, 15.70it/s, est. speed input: 16523.39 toks/s, output: 16.14 toks/s]
Processed prompts:  41%|      | 104/256 [00:06<00:09, 15.66it/s, est. speed input: 16511.58 toks/s, output: 16.12 toks/s]
Processed prompts:  41%|     | 106/256 [00:06<00:09, 15.54it/s, est. speed input: 16493.77 toks/s, output: 16.11 toks/s]
Processed prompts:  42%|     | 108/256 [00:06<00:09, 15.45it/s, est. speed input: 16476.74 toks/s, output: 16.09 toks/s]
Processed prompts:  43%|     | 110/256 [00:06<00:09, 15.48it/s, est. speed input: 16466.69 toks/s, output: 16.08 toks/s]
Processed prompts:  44%|     | 112/256 [00:06<00:09, 15.47it/s, est. speed input: 16454.11 toks/s, output: 16.07 toks/s]
Processed prompts:  45%|     | 114/256 [00:07<00:09, 15.46it/s, est. speed input: 16442.39 toks/s, output: 16.06 toks/s]
Processed prompts:  45%|     | 116/256 [00:07<00:09, 15.49it/s, est. speed input: 16433.60 toks/s, output: 16.05 toks/s]
Processed prompts:  46%|     | 118/256 [00:07<00:08, 15.56it/s, est. speed input: 16427.92 toks/s, output: 16.04 toks/s]
Processed prompts:  47%|     | 120/256 [00:07<00:08, 15.61it/s, est. speed input: 16422.60 toks/s, output: 16.04 toks/s]
Processed prompts:  48%|     | 122/256 [00:07<00:08, 15.68it/s, est. speed input: 16419.40 toks/s, output: 16.03 toks/s]
Processed prompts:  48%|     | 124/256 [00:07<00:08, 15.47it/s, est. speed input: 16401.24 toks/s, output: 16.02 toks/s]
Processed prompts:  49%|     | 126/256 [00:07<00:08, 15.47it/s, est. speed input: 16391.69 toks/s, output: 16.01 toks/s]
Processed prompts:  50%|     | 128/256 [00:07<00:08, 15.59it/s, est. speed input: 16389.44 toks/s, output: 16.01 toks/s]
Processed prompts:  51%|     | 130/256 [00:08<00:08, 15.63it/s, est. speed input: 16385.22 toks/s, output: 16.00 toks/s]
Processed prompts:  52%|    | 132/256 [00:08<00:07, 15.69it/s, est. speed input: 16382.64 toks/s, output: 16.00 toks/s]
Processed prompts:  52%|    | 134/256 [00:08<00:07, 15.73it/s, est. speed input: 16380.06 toks/s, output: 16.00 toks/s]
Processed prompts:  53%|    | 136/256 [00:08<00:07, 15.69it/s, est. speed input: 16373.93 toks/s, output: 15.99 toks/s]
Processed prompts:  54%|    | 138/256 [00:08<00:07, 15.68it/s, est. speed input: 16368.84 toks/s, output: 15.99 toks/s]
Processed prompts:  55%|    | 140/256 [00:08<00:07, 15.50it/s, est. speed input: 16355.11 toks/s, output: 15.97 toks/s]
Processed prompts:  55%|    | 142/256 [00:08<00:07, 15.56it/s, est. speed input: 16351.11 toks/s, output: 15.97 toks/s]
Processed prompts:  56%|    | 144/256 [00:09<00:07, 15.59it/s, est. speed input: 16346.64 toks/s, output: 15.96 toks/s]
Processed prompts:  57%|    | 146/256 [00:09<00:07, 15.62it/s, est. speed input: 16342.76 toks/s, output: 15.96 toks/s]
Processed prompts:  58%|    | 148/256 [00:09<00:06, 15.60it/s, est. speed input: 16336.89 toks/s, output: 15.95 toks/s]
Processed prompts:  59%|    | 150/256 [00:09<00:06, 15.67it/s, est. speed input: 16335.14 toks/s, output: 15.95 toks/s]
Processed prompts:  59%|    | 152/256 [00:09<00:06, 15.62it/s, est. speed input: 16329.14 toks/s, output: 15.95 toks/s]
Processed prompts:  60%|    | 154/256 [00:09<00:06, 15.69it/s, est. speed input: 16327.64 toks/s, output: 15.94 toks/s]
Processed prompts:  61%|    | 156/256 [00:09<00:06, 15.49it/s, est. speed input: 16315.03 toks/s, output: 15.93 toks/s]
Processed prompts:  62%|   | 158/256 [00:09<00:06, 15.52it/s, est. speed input: 16310.79 toks/s, output: 15.93 toks/s]
Processed prompts:  62%|   | 160/256 [00:10<00:06, 15.53it/s, est. speed input: 16305.79 toks/s, output: 15.92 toks/s]
Processed prompts:  63%|   | 162/256 [00:10<00:06, 15.53it/s, est. speed input: 16300.59 toks/s, output: 15.92 toks/s]
Processed prompts:  64%|   | 164/256 [00:10<00:05, 15.61it/s, est. speed input: 16299.13 toks/s, output: 15.92 toks/s]
Processed prompts:  65%|   | 166/256 [00:10<00:05, 15.63it/s, est. speed input: 16296.00 toks/s, output: 15.91 toks/s]
Processed prompts:  66%|   | 168/256 [00:10<00:05, 15.62it/s, est. speed input: 16292.31 toks/s, output: 15.91 toks/s]
Processed prompts:  66%|   | 170/256 [00:10<00:05, 15.67it/s, est. speed input: 16290.87 toks/s, output: 15.91 toks/s]
Processed prompts:  67%|   | 172/256 [00:10<00:05, 15.53it/s, est. speed input: 16281.96 toks/s, output: 15.90 toks/s]
Processed prompts:  68%|   | 174/256 [00:10<00:05, 15.61it/s, est. speed input: 16280.77 toks/s, output: 15.90 toks/s]
Processed prompts:  69%|   | 176/256 [00:11<00:05, 15.55it/s, est. speed input: 16274.79 toks/s, output: 15.89 toks/s]
Processed prompts:  70%|   | 178/256 [00:11<00:05, 15.60it/s, est. speed input: 16272.85 toks/s, output: 15.89 toks/s]
Processed prompts:  70%|   | 180/256 [00:11<00:04, 15.60it/s, est. speed input: 16269.70 toks/s, output: 15.89 toks/s]
Processed prompts:  71%|   | 182/256 [00:11<00:04, 15.68it/s, est. speed input: 16269.24 toks/s, output: 15.89 toks/s]
Processed prompts:  72%|  | 184/256 [00:11<00:04, 15.69it/s, est. speed input: 16267.41 toks/s, output: 15.89 toks/s]
Processed prompts:  73%|  | 186/256 [00:11<00:04, 15.75it/s, est. speed input: 16267.57 toks/s, output: 15.89 toks/s]
Processed prompts:  73%|  | 188/256 [00:11<00:04, 15.66it/s, est. speed input: 16262.47 toks/s, output: 15.88 toks/s]
Processed prompts:  74%|  | 190/256 [00:11<00:04, 15.39it/s, est. speed input: 16249.91 toks/s, output: 15.87 toks/s]
Processed prompts:  75%|  | 192/256 [00:12<00:04, 15.49it/s, est. speed input: 16248.64 toks/s, output: 15.87 toks/s]
Processed prompts:  76%|  | 194/256 [00:12<00:03, 15.58it/s, est. speed input: 16247.88 toks/s, output: 15.87 toks/s]
Processed prompts:  77%|  | 196/256 [00:12<00:03, 15.56it/s, est. speed input: 16244.14 toks/s, output: 15.86 toks/s]
Processed prompts:  77%|  | 198/256 [00:12<00:03, 15.56it/s, est. speed input: 16240.85 toks/s, output: 15.86 toks/s]
Processed prompts:  78%|  | 200/256 [00:12<00:03, 15.64it/s, est. speed input: 16240.48 toks/s, output: 15.86 toks/s]
Processed prompts:  79%|  | 202/256 [00:12<00:03, 15.73it/s, est. speed input: 16241.38 toks/s, output: 15.86 toks/s]
Processed prompts:  80%|  | 204/256 [00:12<00:03, 15.67it/s, est. speed input: 16237.97 toks/s, output: 15.86 toks/s]
Processed prompts:  80%|  | 206/256 [00:12<00:03, 15.40it/s, est. speed input: 16226.68 toks/s, output: 15.85 toks/s]
Processed prompts:  81%| | 208/256 [00:13<00:03, 15.55it/s, est. speed input: 16227.42 toks/s, output: 15.85 toks/s]
Processed prompts:  82%| | 210/256 [00:13<00:02, 15.51it/s, est. speed input: 16223.21 toks/s, output: 15.84 toks/s]
Processed prompts:  83%| | 212/256 [00:13<00:02, 15.57it/s, est. speed input: 16221.85 toks/s, output: 15.84 toks/s]
Processed prompts:  84%| | 214/256 [00:13<00:02, 15.62it/s, est. speed input: 16220.78 toks/s, output: 15.84 toks/s]
Processed prompts:  84%| | 216/256 [00:13<00:02, 15.60it/s, est. speed input: 16217.96 toks/s, output: 15.84 toks/s]
Processed prompts:  85%| | 218/256 [00:13<00:02, 15.63it/s, est. speed input: 16216.78 toks/s, output: 15.84 toks/s]
Processed prompts:  86%| | 220/256 [00:13<00:02, 15.60it/s, est. speed input: 16213.94 toks/s, output: 15.83 toks/s]
Processed prompts:  87%| | 222/256 [00:14<00:02, 15.43it/s, est. speed input: 16206.27 toks/s, output: 15.83 toks/s]
Processed prompts:  88%| | 224/256 [00:14<00:02, 15.49it/s, est. speed input: 16204.42 toks/s, output: 15.82 toks/s]
Processed prompts:  88%| | 226/256 [00:14<00:01, 15.47it/s, est. speed input: 16200.84 toks/s, output: 15.82 toks/s]
Processed prompts:  89%| | 228/256 [00:14<00:01, 15.51it/s, est. speed input: 16198.85 toks/s, output: 15.82 toks/s]
Processed prompts:  90%| | 230/256 [00:14<00:01, 15.58it/s, est. speed input: 16198.05 toks/s, output: 15.82 toks/s]
Processed prompts:  91%| | 232/256 [00:14<00:01, 15.63it/s, est. speed input: 16197.37 toks/s, output: 15.82 toks/s]
Processed prompts:  91%|| 234/256 [00:14<00:01, 15.64it/s, est. speed input: 16196.00 toks/s, output: 15.82 toks/s]
Processed prompts:  92%|| 236/256 [00:14<00:01, 15.70it/s, est. speed input: 16196.19 toks/s, output: 15.82 toks/s]
Processed prompts:  93%|| 238/256 [00:15<00:01, 15.53it/s, est. speed input: 16190.33 toks/s, output: 15.81 toks/s]
Processed prompts:  94%|| 240/256 [00:15<00:01, 15.48it/s, est. speed input: 16186.32 toks/s, output: 15.81 toks/s]
Processed prompts:  95%|| 242/256 [00:15<00:00, 15.56it/s, est. speed input: 16185.74 toks/s, output: 15.81 toks/s]
Processed prompts:  95%|| 244/256 [00:15<00:00, 15.61it/s, est. speed input: 16185.11 toks/s, output: 15.81 toks/s]
Processed prompts:  96%|| 246/256 [00:15<00:00, 15.65it/s, est. speed input: 16184.68 toks/s, output: 15.81 toks/s]
Processed prompts:  97%|| 248/256 [00:15<00:00, 15.59it/s, est. speed input: 16181.56 toks/s, output: 15.80 toks/s]
Processed prompts:  98%|| 250/256 [00:15<00:00, 15.61it/s, est. speed input: 16180.38 toks/s, output: 15.80 toks/s]
Processed prompts:  98%|| 252/256 [00:15<00:00, 15.55it/s, est. speed input: 16177.02 toks/s, output: 15.80 toks/s]
Processed prompts:  99%|| 254/256 [00:16<00:00, 15.59it/s, est. speed input: 16176.31 toks/s, output: 15.80 toks/s]
Processed prompts: 100%|| 256/256 [00:16<00:00, 15.59it/s, est. speed input: 16233.65 toks/s, output: 15.85 toks/s]
Processed prompts: 100%|| 256/256 [00:16<00:00, 15.85it/s, est. speed input: 16233.65 toks/s, output: 15.85 toks/s]
[rank0]:[W128 09:05:33.759401795 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-28 09:05:35
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/BitNet-2B-FP8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 09:05:40 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-28 09:05:40 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=3726577) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=3726577) WARNING 01-28 09:06:06 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 14.52 requests/s, 14887.26 total tokens/s, 14.52 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-28 09:05:40] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-28 09:05:40] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 09:05:40] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 09:05:40] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:05:40] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:05:40] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:05:40] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:05:40] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:05:40] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 09:05:40] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 09:05:40] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 09:05:40] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 09:05:40] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 09:05:40] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 09:05:44] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-28 09:05:44] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 09:05:44] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 09:05:44] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:05:44] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:05:44] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:05:44] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:05:44] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:05:44] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 09:05:44] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 09:05:44] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 09:05:44] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 09:05:44] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 09:05:44] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3726577) [2026-01-28 09:05:45] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3726577) [2026-01-28 09:05:45] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=3726577) [2026-01-28 09:05:45] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3726577) [2026-01-28 09:05:45] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=3726577) [2026-01-28 09:05:45] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: BitNet-2B-FP8
(EngineCore_DP0 pid=3726577) [2026-01-28 09:05:45] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=3726577) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3726577) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:14<00:00, 14.36s/it]
(EngineCore_DP0 pid=3726577) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:14<00:00, 14.36s/it]
(EngineCore_DP0 pid=3726577) 
(EngineCore_DP0 pid=3726577) [2026-01-28 09:06:00] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3840, 3424] -> 1D uint8
(EngineCore_DP0 pid=3726577) [2026-01-28 09:06:00] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8232960 bytes
(EngineCore_DP0 pid=3726577) [2026-01-28 09:06:00] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 3424] -> 1D uint8
(EngineCore_DP0 pid=3726577) [2026-01-28 09:06:00] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5488640 bytes
(EngineCore_DP0 pid=3726577) [2026-01-28 09:06:00] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [13824, 3424] -> 1D uint8
(EngineCore_DP0 pid=3726577) [2026-01-28 09:06:00] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 29638656 bytes
(EngineCore_DP0 pid=3726577) [2026-01-28 09:06:00] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 9216] -> 1D uint8
(EngineCore_DP0 pid=3726577) [2026-01-28 09:06:00] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14745600 bytes
(EngineCore_DP0 pid=3726577) 2026-01-28 09:06:05,990 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3726577) 2026-01-28 09:06:06,002 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:  12%|        | 62/512 [00:00<00:00, 615.54it/s]
Adding requests:  24%|       | 124/512 [00:00<00:00, 583.27it/s]
Adding requests:  36%|      | 183/512 [00:00<00:00, 558.07it/s]
Adding requests:  47%|     | 241/512 [00:00<00:00, 564.69it/s]
Adding requests:  58%|    | 298/512 [00:00<00:00, 553.31it/s]
Adding requests:  69%|   | 355/512 [00:00<00:00, 555.46it/s]
Adding requests:  80%|  | 411/512 [00:00<00:00, 553.23it/s]
Adding requests:  91%| | 467/512 [00:00<00:00, 548.94it/s]
Adding requests: 100%|| 512/512 [00:00<00:00, 553.66it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   3%|         | 14/512 [00:00<00:12, 39.99it/s, est. speed input: 40953.09 toks/s, output: 39.99 toks/s]
Processed prompts:   4%|         | 18/512 [00:00<00:18, 26.51it/s, est. speed input: 29464.93 toks/s, output: 28.77 toks/s]
Processed prompts:   4%|         | 22/512 [00:00<00:22, 21.50it/s, est. speed input: 25124.60 toks/s, output: 24.54 toks/s]
Processed prompts:   5%|         | 26/512 [00:01<00:25, 18.96it/s, est. speed input: 22812.71 toks/s, output: 22.28 toks/s]
Processed prompts:   6%|         | 30/512 [00:01<00:27, 17.50it/s, est. speed input: 21368.72 toks/s, output: 20.87 toks/s]
Processed prompts:   7%|         | 34/512 [00:01<00:29, 16.42it/s, est. speed input: 20279.27 toks/s, output: 19.80 toks/s]
Processed prompts:   7%|         | 38/512 [00:01<00:29, 15.83it/s, est. speed input: 19546.67 toks/s, output: 19.09 toks/s]
Processed prompts:   8%|         | 42/512 [00:02<00:30, 15.47it/s, est. speed input: 19005.93 toks/s, output: 18.56 toks/s]
Processed prompts:   9%|         | 46/512 [00:02<00:30, 15.25it/s, est. speed input: 18589.66 toks/s, output: 18.15 toks/s]
Processed prompts:  10%|         | 50/512 [00:02<00:30, 14.99it/s, est. speed input: 18209.19 toks/s, output: 17.78 toks/s]
Processed prompts:  11%|         | 54/512 [00:03<00:30, 14.90it/s, est. speed input: 17929.97 toks/s, output: 17.51 toks/s]
Processed prompts:  11%|        | 58/512 [00:03<00:30, 14.85it/s, est. speed input: 17702.07 toks/s, output: 17.29 toks/s]
Processed prompts:  12%|        | 62/512 [00:03<00:30, 14.80it/s, est. speed input: 17499.92 toks/s, output: 17.09 toks/s]
Processed prompts:  13%|        | 66/512 [00:03<00:30, 14.68it/s, est. speed input: 17306.15 toks/s, output: 16.90 toks/s]
Processed prompts:  14%|        | 70/512 [00:04<00:30, 14.66it/s, est. speed input: 17151.99 toks/s, output: 16.75 toks/s]
Processed prompts:  14%|        | 74/512 [00:04<00:29, 14.70it/s, est. speed input: 17031.09 toks/s, output: 16.63 toks/s]
Processed prompts:  15%|        | 78/512 [00:04<00:29, 14.69it/s, est. speed input: 16914.22 toks/s, output: 16.52 toks/s]
Processed prompts:  16%|        | 82/512 [00:04<00:29, 14.62it/s, est. speed input: 16797.29 toks/s, output: 16.40 toks/s]
Processed prompts:  17%|        | 86/512 [00:05<00:29, 14.64it/s, est. speed input: 16707.59 toks/s, output: 16.32 toks/s]
Processed prompts:  18%|        | 90/512 [00:05<00:28, 14.69it/s, est. speed input: 16630.92 toks/s, output: 16.24 toks/s]
Processed prompts:  18%|        | 94/512 [00:05<00:28, 14.63it/s, est. speed input: 16545.61 toks/s, output: 16.16 toks/s]
Processed prompts:  19%|        | 98/512 [00:06<00:28, 14.67it/s, est. speed input: 16482.92 toks/s, output: 16.10 toks/s]
Processed prompts:  20%|        | 102/512 [00:06<00:27, 14.67it/s, est. speed input: 16419.38 toks/s, output: 16.03 toks/s]
Processed prompts:  21%|        | 106/512 [00:06<00:27, 14.64it/s, est. speed input: 16357.16 toks/s, output: 15.97 toks/s]
Processed prompts:  21%|       | 110/512 [00:06<00:27, 14.58it/s, est. speed input: 16294.66 toks/s, output: 15.91 toks/s]
Processed prompts:  22%|       | 114/512 [00:07<00:27, 14.59it/s, est. speed input: 16244.26 toks/s, output: 15.86 toks/s]
Processed prompts:  23%|       | 118/512 [00:07<00:26, 14.66it/s, est. speed input: 16205.39 toks/s, output: 15.83 toks/s]
Processed prompts:  24%|       | 122/512 [00:07<00:26, 14.68it/s, est. speed input: 16165.46 toks/s, output: 15.79 toks/s]
Processed prompts:  25%|       | 126/512 [00:08<00:26, 14.67it/s, est. speed input: 16125.88 toks/s, output: 15.75 toks/s]
Processed prompts:  25%|       | 130/512 [00:08<00:26, 14.69it/s, est. speed input: 16091.79 toks/s, output: 15.71 toks/s]
Processed prompts:  26%|       | 134/512 [00:08<00:25, 14.63it/s, est. speed input: 16051.73 toks/s, output: 15.68 toks/s]
Processed prompts:  27%|       | 138/512 [00:08<00:25, 14.65it/s, est. speed input: 16020.67 toks/s, output: 15.65 toks/s]
Processed prompts:  28%|       | 142/512 [00:09<00:25, 14.57it/s, est. speed input: 15980.90 toks/s, output: 15.61 toks/s]
Processed prompts:  29%|       | 146/512 [00:09<00:25, 14.63it/s, est. speed input: 15956.76 toks/s, output: 15.58 toks/s]
Processed prompts:  29%|       | 150/512 [00:09<00:24, 14.67it/s, est. speed input: 15932.51 toks/s, output: 15.56 toks/s]
Processed prompts:  30%|       | 154/512 [00:09<00:24, 14.68it/s, est. speed input: 15908.87 toks/s, output: 15.54 toks/s]
Processed prompts:  31%|       | 158/512 [00:10<00:24, 14.58it/s, est. speed input: 15875.76 toks/s, output: 15.50 toks/s]
Processed prompts:  32%|      | 162/512 [00:10<00:24, 14.58it/s, est. speed input: 15851.16 toks/s, output: 15.48 toks/s]
Processed prompts:  32%|      | 166/512 [00:10<00:23, 14.60it/s, est. speed input: 15829.06 toks/s, output: 15.46 toks/s]
Processed prompts:  33%|      | 170/512 [00:11<00:23, 14.66it/s, est. speed input: 15812.77 toks/s, output: 15.44 toks/s]
Processed prompts:  34%|      | 174/512 [00:11<00:23, 14.60it/s, est. speed input: 15788.55 toks/s, output: 15.42 toks/s]
Processed prompts:  35%|      | 178/512 [00:11<00:22, 14.62it/s, est. speed input: 15770.52 toks/s, output: 15.40 toks/s]
Processed prompts:  36%|      | 182/512 [00:11<00:22, 14.66it/s, est. speed input: 15755.02 toks/s, output: 15.39 toks/s]
Processed prompts:  36%|      | 186/512 [00:12<00:22, 14.61it/s, est. speed input: 15734.25 toks/s, output: 15.37 toks/s]
Processed prompts:  37%|      | 190/512 [00:12<00:22, 14.56it/s, est. speed input: 15713.32 toks/s, output: 15.35 toks/s]
Processed prompts:  38%|      | 194/512 [00:12<00:21, 14.64it/s, est. speed input: 15702.26 toks/s, output: 15.33 toks/s]
Processed prompts:  39%|      | 198/512 [00:12<00:21, 14.68it/s, est. speed input: 15689.70 toks/s, output: 15.32 toks/s]
Processed prompts:  39%|      | 202/512 [00:13<00:21, 14.71it/s, est. speed input: 15678.86 toks/s, output: 15.31 toks/s]
Processed prompts:  40%|      | 206/512 [00:13<00:20, 14.64it/s, est. speed input: 15660.92 toks/s, output: 15.29 toks/s]
Processed prompts:  41%|      | 210/512 [00:13<00:20, 14.68it/s, est. speed input: 15650.33 toks/s, output: 15.28 toks/s]
Processed prompts:  42%|     | 214/512 [00:14<00:20, 14.68it/s, est. speed input: 15638.59 toks/s, output: 15.27 toks/s]
Processed prompts:  43%|     | 218/512 [00:14<00:19, 14.72it/s, est. speed input: 15629.57 toks/s, output: 15.26 toks/s]
Processed prompts:  43%|     | 222/512 [00:14<00:19, 14.59it/s, est. speed input: 15610.85 toks/s, output: 15.24 toks/s]
Processed prompts:  44%|     | 226/512 [00:14<00:19, 14.64it/s, est. speed input: 15601.37 toks/s, output: 15.24 toks/s]
Processed prompts:  45%|     | 230/512 [00:15<00:19, 14.61it/s, est. speed input: 15588.73 toks/s, output: 15.22 toks/s]
Processed prompts:  46%|     | 234/512 [00:15<00:19, 14.56it/s, est. speed input: 15574.08 toks/s, output: 15.21 toks/s]
Processed prompts:  46%|     | 238/512 [00:15<00:18, 14.62it/s, est. speed input: 15566.13 toks/s, output: 15.20 toks/s]
Processed prompts:  47%|     | 242/512 [00:15<00:18, 14.67it/s, est. speed input: 15559.04 toks/s, output: 15.19 toks/s]
Processed prompts:  48%|     | 246/512 [00:16<00:18, 14.67it/s, est. speed input: 15549.79 toks/s, output: 15.19 toks/s]
Processed prompts:  49%|     | 250/512 [00:16<00:17, 14.56it/s, est. speed input: 15534.58 toks/s, output: 15.17 toks/s]
Processed prompts:  50%|     | 254/512 [00:16<00:17, 14.60it/s, est. speed input: 15526.47 toks/s, output: 15.16 toks/s]
Processed prompts:  50%|     | 258/512 [00:17<00:17, 14.59it/s, est. speed input: 15516.74 toks/s, output: 15.15 toks/s]
Processed prompts:  51%|     | 262/512 [00:17<00:17, 14.63it/s, est. speed input: 15510.14 toks/s, output: 15.15 toks/s]
Processed prompts:  52%|    | 266/512 [00:17<00:16, 14.54it/s, est. speed input: 15497.03 toks/s, output: 15.13 toks/s]
Processed prompts:  53%|    | 270/512 [00:17<00:16, 14.56it/s, est. speed input: 15488.52 toks/s, output: 15.13 toks/s]
Processed prompts:  54%|    | 274/512 [00:18<00:16, 14.56it/s, est. speed input: 15479.85 toks/s, output: 15.12 toks/s]
Processed prompts:  54%|    | 278/512 [00:18<00:16, 14.62it/s, est. speed input: 15474.67 toks/s, output: 15.11 toks/s]
Processed prompts:  55%|    | 282/512 [00:18<00:15, 14.58it/s, est. speed input: 15464.94 toks/s, output: 15.10 toks/s]
Processed prompts:  56%|    | 286/512 [00:18<00:15, 14.60it/s, est. speed input: 15458.29 toks/s, output: 15.10 toks/s]
Processed prompts:  57%|    | 290/512 [00:19<00:15, 14.63it/s, est. speed input: 15452.35 toks/s, output: 15.09 toks/s]
Processed prompts:  57%|    | 294/512 [00:19<00:14, 14.69it/s, est. speed input: 15449.05 toks/s, output: 15.09 toks/s]
Processed prompts:  58%|    | 298/512 [00:19<00:14, 14.61it/s, est. speed input: 15439.24 toks/s, output: 15.08 toks/s]
Processed prompts:  59%|    | 302/512 [00:20<00:14, 14.62it/s, est. speed input: 15433.06 toks/s, output: 15.07 toks/s]
Processed prompts:  60%|    | 306/512 [00:20<00:14, 14.67it/s, est. speed input: 15429.45 toks/s, output: 15.07 toks/s]
Processed prompts:  61%|    | 310/512 [00:20<00:13, 14.65it/s, est. speed input: 15423.02 toks/s, output: 15.06 toks/s]
Processed prompts:  61%|   | 314/512 [00:20<00:13, 14.60it/s, est. speed input: 15415.15 toks/s, output: 15.05 toks/s]
Processed prompts:  62%|   | 318/512 [00:21<00:13, 14.65it/s, est. speed input: 15411.49 toks/s, output: 15.05 toks/s]
Processed prompts:  63%|   | 322/512 [00:21<00:12, 14.65it/s, est. speed input: 15406.10 toks/s, output: 15.05 toks/s]
Processed prompts:  64%|   | 326/512 [00:21<00:12, 14.65it/s, est. speed input: 15401.26 toks/s, output: 15.04 toks/s]
Processed prompts:  64%|   | 330/512 [00:21<00:12, 14.55it/s, est. speed input: 15391.58 toks/s, output: 15.03 toks/s]
Processed prompts:  65%|   | 334/512 [00:22<00:12, 14.63it/s, est. speed input: 15389.25 toks/s, output: 15.03 toks/s]
Processed prompts:  66%|   | 338/512 [00:22<00:11, 14.62it/s, est. speed input: 15383.70 toks/s, output: 15.02 toks/s]
Processed prompts:  67%|   | 342/512 [00:22<00:11, 15.25it/s, est. speed input: 15404.38 toks/s, output: 15.04 toks/s]
Processed prompts:  68%|   | 346/512 [00:23<00:11, 14.94it/s, est. speed input: 15394.56 toks/s, output: 15.03 toks/s]
Processed prompts:  68%|   | 350/512 [00:23<00:10, 14.89it/s, est. speed input: 15391.34 toks/s, output: 15.03 toks/s]
Processed prompts:  69%|   | 354/512 [00:23<00:10, 14.80it/s, est. speed input: 15386.23 toks/s, output: 15.03 toks/s]
Processed prompts:  70%|   | 358/512 [00:23<00:10, 14.83it/s, est. speed input: 15384.79 toks/s, output: 15.02 toks/s]
Processed prompts:  71%|   | 362/512 [00:24<00:10, 14.69it/s, est. speed input: 15377.05 toks/s, output: 15.02 toks/s]
Processed prompts:  71%|  | 366/512 [00:24<00:09, 14.70it/s, est. speed input: 15373.82 toks/s, output: 15.01 toks/s]
Processed prompts:  72%|  | 370/512 [00:24<00:09, 14.70it/s, est. speed input: 15370.27 toks/s, output: 15.01 toks/s]
Processed prompts:  73%|  | 374/512 [00:24<00:09, 14.61it/s, est. speed input: 15363.38 toks/s, output: 15.00 toks/s]
Processed prompts:  74%|  | 378/512 [00:25<00:09, 14.59it/s, est. speed input: 15358.24 toks/s, output: 15.00 toks/s]
Processed prompts:  75%|  | 382/512 [00:25<00:08, 14.65it/s, est. speed input: 15355.85 toks/s, output: 15.00 toks/s]
Processed prompts:  75%|  | 386/512 [00:25<00:08, 14.67it/s, est. speed input: 15352.73 toks/s, output: 14.99 toks/s]
Processed prompts:  76%|  | 390/512 [00:26<00:08, 14.61it/s, est. speed input: 15347.36 toks/s, output: 14.99 toks/s]
Processed prompts:  77%|  | 394/512 [00:26<00:08, 14.63it/s, est. speed input: 15343.97 toks/s, output: 14.98 toks/s]
Processed prompts:  78%|  | 398/512 [00:26<00:07, 14.60it/s, est. speed input: 15339.12 toks/s, output: 14.98 toks/s]
Processed prompts:  79%|  | 402/512 [00:26<00:07, 14.62it/s, est. speed input: 15335.87 toks/s, output: 14.98 toks/s]
Processed prompts:  79%|  | 406/512 [00:27<00:07, 14.51it/s, est. speed input: 15328.15 toks/s, output: 14.97 toks/s]
Processed prompts:  80%|  | 410/512 [00:27<00:06, 14.60it/s, est. speed input: 15326.66 toks/s, output: 14.97 toks/s]
Processed prompts:  81%|  | 414/512 [00:27<00:06, 14.63it/s, est. speed input: 15324.14 toks/s, output: 14.96 toks/s]
Processed prompts:  82%| | 418/512 [00:27<00:06, 14.69it/s, est. speed input: 15322.56 toks/s, output: 14.96 toks/s]
Processed prompts:  82%| | 422/512 [00:28<00:06, 14.56it/s, est. speed input: 15315.70 toks/s, output: 14.96 toks/s]
Processed prompts:  83%| | 426/512 [00:28<00:05, 14.56it/s, est. speed input: 15311.72 toks/s, output: 14.95 toks/s]
Processed prompts:  84%| | 430/512 [00:28<00:05, 14.59it/s, est. speed input: 15308.75 toks/s, output: 14.95 toks/s]
Processed prompts:  85%| | 434/512 [00:29<00:05, 14.59it/s, est. speed input: 15305.49 toks/s, output: 14.95 toks/s]
Processed prompts:  86%| | 438/512 [00:29<00:05, 14.59it/s, est. speed input: 15301.83 toks/s, output: 14.94 toks/s]
Processed prompts:  86%| | 442/512 [00:29<00:04, 14.59it/s, est. speed input: 15298.48 toks/s, output: 14.94 toks/s]
Processed prompts:  87%| | 446/512 [00:29<00:04, 14.62it/s, est. speed input: 15296.07 toks/s, output: 14.94 toks/s]
Processed prompts:  88%| | 450/512 [00:30<00:04, 15.48it/s, est. speed input: 15318.89 toks/s, output: 14.96 toks/s]
Processed prompts:  89%| | 454/512 [00:30<00:03, 15.15it/s, est. speed input: 15313.92 toks/s, output: 14.95 toks/s]
Processed prompts:  89%| | 458/512 [00:30<00:03, 14.98it/s, est. speed input: 15310.72 toks/s, output: 14.95 toks/s]
Processed prompts:  90%| | 462/512 [00:30<00:03, 14.88it/s, est. speed input: 15308.02 toks/s, output: 14.95 toks/s]
Processed prompts:  91%| | 466/512 [00:31<00:03, 14.78it/s, est. speed input: 15304.52 toks/s, output: 14.95 toks/s]
Processed prompts:  92%|| 470/512 [00:31<00:03, 12.91it/s, est. speed input: 15239.68 toks/s, output: 14.88 toks/s]
Processed prompts:  93%|| 474/512 [00:31<00:02, 13.05it/s, est. speed input: 15225.23 toks/s, output: 14.87 toks/s]
Processed prompts:  93%|| 478/512 [00:32<00:02, 13.55it/s, est. speed input: 15225.32 toks/s, output: 14.87 toks/s]
Processed prompts:  94%|| 482/512 [00:32<00:02, 13.33it/s, est. speed input: 15205.43 toks/s, output: 14.85 toks/s]
Processed prompts:  95%|| 486/512 [00:32<00:01, 13.65it/s, est. speed input: 15201.99 toks/s, output: 14.85 toks/s]
Processed prompts:  96%|| 490/512 [00:33<00:01, 13.94it/s, est. speed input: 15200.59 toks/s, output: 14.84 toks/s]
Processed prompts:  96%|| 494/512 [00:33<00:01, 14.15it/s, est. speed input: 15199.01 toks/s, output: 14.84 toks/s]
Processed prompts:  97%|| 498/512 [00:33<00:00, 14.22it/s, est. speed input: 15195.19 toks/s, output: 14.84 toks/s]
Processed prompts:  98%|| 502/512 [00:33<00:00, 14.37it/s, est. speed input: 15194.40 toks/s, output: 14.84 toks/s]
Processed prompts:  99%|| 506/512 [00:34<00:00, 14.43it/s, est. speed input: 15192.12 toks/s, output: 14.84 toks/s]
Processed prompts: 100%|| 510/512 [00:34<00:00, 15.40it/s, est. speed input: 15214.49 toks/s, output: 14.86 toks/s]
Processed prompts: 100%|| 512/512 [00:34<00:00, 15.40it/s, est. speed input: 15274.10 toks/s, output: 14.92 toks/s]
Processed prompts: 100%|| 512/512 [00:34<00:00, 14.92it/s, est. speed input: 15274.10 toks/s, output: 14.92 toks/s]
[rank0]:[W128 09:06:42.274208660 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-28 09:06:44
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/BitNet-2B-FP8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 09:06:51 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-28 09:06:51 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=3727749) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=3727749) WARNING 01-28 09:07:17 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 14.63 requests/s, 14992.23 total tokens/s, 14.63 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-28 09:06:50] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-28 09:06:51] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 09:06:51] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 09:06:51] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:06:51] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:06:51] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:06:51] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:06:51] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:06:51] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 09:06:51] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 09:06:51] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 09:06:51] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 09:06:51] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 09:06:51] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 09:06:54] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-28 09:06:54] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 09:06:54] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 09:06:54] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:06:54] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:06:54] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:06:54] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:06:54] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:06:54] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 09:06:54] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 09:06:54] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 09:06:54] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 09:06:54] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 09:06:54] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3727749) [2026-01-28 09:06:55] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3727749) [2026-01-28 09:06:55] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=3727749) [2026-01-28 09:06:55] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3727749) [2026-01-28 09:06:55] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=3727749) [2026-01-28 09:06:55] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: BitNet-2B-FP8
(EngineCore_DP0 pid=3727749) [2026-01-28 09:06:55] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=3727749) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3727749) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:14<00:00, 14.68s/it]
(EngineCore_DP0 pid=3727749) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:14<00:00, 14.68s/it]
(EngineCore_DP0 pid=3727749) 
(EngineCore_DP0 pid=3727749) [2026-01-28 09:07:10] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3840, 3424] -> 1D uint8
(EngineCore_DP0 pid=3727749) [2026-01-28 09:07:10] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8232960 bytes
(EngineCore_DP0 pid=3727749) [2026-01-28 09:07:10] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 3424] -> 1D uint8
(EngineCore_DP0 pid=3727749) [2026-01-28 09:07:10] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5488640 bytes
(EngineCore_DP0 pid=3727749) [2026-01-28 09:07:10] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [13824, 3424] -> 1D uint8
(EngineCore_DP0 pid=3727749) [2026-01-28 09:07:10] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 29638656 bytes
(EngineCore_DP0 pid=3727749) [2026-01-28 09:07:10] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 9216] -> 1D uint8
(EngineCore_DP0 pid=3727749) [2026-01-28 09:07:10] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14745600 bytes
(EngineCore_DP0 pid=3727749) 2026-01-28 09:07:16,771 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3727749) 2026-01-28 09:07:16,824 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   6%|         | 60/1024 [00:00<00:01, 593.10it/s]
Adding requests:  12%|        | 120/1024 [00:00<00:01, 566.52it/s]
Adding requests:  17%|        | 177/1024 [00:00<00:01, 519.25it/s]
Adding requests:  22%|       | 230/1024 [00:00<00:01, 516.35it/s]
Adding requests:  28%|       | 282/1024 [00:00<00:01, 504.93it/s]
Adding requests:  33%|      | 333/1024 [00:00<00:01, 497.02it/s]
Adding requests:  37%|      | 383/1024 [00:00<00:01, 496.03it/s]
Adding requests:  42%|     | 433/1024 [00:00<00:01, 494.71it/s]
Adding requests:  47%|     | 483/1024 [00:00<00:01, 484.82it/s]
Adding requests:  52%|    | 532/1024 [00:01<00:01, 465.85it/s]
Adding requests:  57%|    | 582/1024 [00:01<00:00, 474.90it/s]
Adding requests:  62%|   | 632/1024 [00:01<00:00, 481.79it/s]
Adding requests:  67%|   | 683/1024 [00:01<00:00, 487.90it/s]
Adding requests:  72%|  | 733/1024 [00:01<00:00, 489.94it/s]
Adding requests:  76%|  | 783/1024 [00:01<00:00, 480.15it/s]
Adding requests:  81%| | 832/1024 [00:01<00:00, 467.15it/s]
Adding requests:  86%| | 884/1024 [00:01<00:00, 479.77it/s]
Adding requests:  91%| | 934/1024 [00:01<00:00, 485.45it/s]
Adding requests:  96%|| 983/1024 [00:02<00:00, 482.60it/s]
Adding requests: 100%|| 1024/1024 [00:02<00:00, 490.96it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   3%|         | 26/1024 [00:00<00:10, 94.59it/s, est. speed input: 96865.66 toks/s, output: 94.59 toks/s]
Processed prompts:   4%|         | 36/1024 [00:00<00:25, 38.44it/s, est. speed input: 45172.99 toks/s, output: 44.11 toks/s]
Processed prompts:   4%|         | 42/1024 [00:01<00:40, 24.23it/s, est. speed input: 31512.45 toks/s, output: 30.77 toks/s]
Processed prompts:   5%|         | 50/1024 [00:01<00:48, 20.23it/s, est. speed input: 26847.82 toks/s, output: 26.22 toks/s]
Processed prompts:   6%|         | 58/1024 [00:02<00:53, 18.12it/s, est. speed input: 24207.25 toks/s, output: 23.64 toks/s]
Processed prompts:   6%|         | 66/1024 [00:02<00:56, 16.99it/s, est. speed input: 22590.30 toks/s, output: 22.06 toks/s]
Processed prompts:   7%|         | 74/1024 [00:03<00:58, 16.19it/s, est. speed input: 21408.83 toks/s, output: 20.91 toks/s]
Processed prompts:   8%|         | 82/1024 [00:04<00:59, 15.77it/s, est. speed input: 20592.28 toks/s, output: 20.11 toks/s]
Processed prompts:   9%|         | 90/1024 [00:04<01:00, 15.40it/s, est. speed input: 19927.44 toks/s, output: 19.46 toks/s]
Processed prompts:  10%|         | 98/1024 [00:05<01:00, 15.20it/s, est. speed input: 19421.48 toks/s, output: 18.97 toks/s]
Processed prompts:  10%|         | 106/1024 [00:05<01:01, 15.01it/s, est. speed input: 18990.13 toks/s, output: 18.54 toks/s]
Processed prompts:  11%|         | 114/1024 [00:06<01:01, 14.92it/s, est. speed input: 18648.21 toks/s, output: 18.21 toks/s]
Processed prompts:  12%|        | 122/1024 [00:06<01:00, 14.82it/s, est. speed input: 18349.62 toks/s, output: 17.92 toks/s]
Processed prompts:  13%|        | 130/1024 [00:07<01:00, 14.78it/s, est. speed input: 18105.49 toks/s, output: 17.68 toks/s]
Processed prompts:  13%|        | 138/1024 [00:07<00:59, 14.78it/s, est. speed input: 17902.34 toks/s, output: 17.48 toks/s]
Processed prompts:  14%|        | 146/1024 [00:08<00:59, 14.77it/s, est. speed input: 17720.70 toks/s, output: 17.31 toks/s]
Processed prompts:  15%|        | 154/1024 [00:08<00:58, 14.75it/s, est. speed input: 17560.71 toks/s, output: 17.15 toks/s]
Processed prompts:  16%|        | 162/1024 [00:09<00:58, 14.76it/s, est. speed input: 17422.71 toks/s, output: 17.01 toks/s]
Processed prompts:  17%|        | 170/1024 [00:10<00:57, 14.73it/s, est. speed input: 17291.34 toks/s, output: 16.89 toks/s]
Processed prompts:  17%|        | 178/1024 [00:10<00:57, 14.72it/s, est. speed input: 17177.21 toks/s, output: 16.77 toks/s]
Processed prompts:  18%|        | 186/1024 [00:11<00:57, 14.69it/s, est. speed input: 17068.65 toks/s, output: 16.67 toks/s]
Processed prompts:  19%|        | 194/1024 [00:11<00:56, 14.74it/s, est. speed input: 16982.48 toks/s, output: 16.58 toks/s]
Processed prompts:  20%|        | 202/1024 [00:12<00:55, 14.69it/s, est. speed input: 16890.46 toks/s, output: 16.49 toks/s]
Processed prompts:  21%|        | 210/1024 [00:12<00:55, 14.68it/s, est. speed input: 16809.81 toks/s, output: 16.42 toks/s]
Processed prompts:  21%|       | 218/1024 [00:13<00:54, 14.66it/s, est. speed input: 16735.22 toks/s, output: 16.34 toks/s]
Processed prompts:  22%|       | 226/1024 [00:13<00:54, 14.71it/s, est. speed input: 16674.24 toks/s, output: 16.28 toks/s]
Processed prompts:  23%|       | 234/1024 [00:14<00:53, 14.69it/s, est. speed input: 16610.84 toks/s, output: 16.22 toks/s]
Processed prompts:  24%|       | 242/1024 [00:14<00:53, 14.70it/s, est. speed input: 16555.24 toks/s, output: 16.17 toks/s]
Processed prompts:  24%|       | 250/1024 [00:15<00:52, 14.65it/s, est. speed input: 16495.87 toks/s, output: 16.11 toks/s]
Processed prompts:  25%|       | 258/1024 [00:16<00:52, 14.67it/s, est. speed input: 16448.12 toks/s, output: 16.06 toks/s]
Processed prompts:  26%|       | 266/1024 [00:16<00:51, 14.65it/s, est. speed input: 16398.98 toks/s, output: 16.01 toks/s]
Processed prompts:  27%|       | 274/1024 [00:17<00:51, 14.66it/s, est. speed input: 16355.30 toks/s, output: 15.97 toks/s]
Processed prompts:  28%|       | 282/1024 [00:17<00:50, 14.65it/s, est. speed input: 16313.33 toks/s, output: 15.93 toks/s]
Processed prompts:  28%|       | 290/1024 [00:18<00:50, 14.61it/s, est. speed input: 16269.23 toks/s, output: 15.89 toks/s]
Processed prompts:  29%|       | 298/1024 [00:18<00:49, 14.65it/s, est. speed input: 16235.04 toks/s, output: 15.85 toks/s]
Processed prompts:  30%|       | 306/1024 [00:19<00:49, 14.65it/s, est. speed input: 16200.76 toks/s, output: 15.82 toks/s]
Processed prompts:  31%|       | 314/1024 [00:19<00:48, 14.68it/s, est. speed input: 16170.38 toks/s, output: 15.79 toks/s]
Processed prompts:  31%|      | 322/1024 [00:20<00:47, 14.65it/s, est. speed input: 16137.51 toks/s, output: 15.76 toks/s]
Processed prompts:  32%|      | 330/1024 [00:20<00:47, 14.66it/s, est. speed input: 16109.19 toks/s, output: 15.73 toks/s]
Processed prompts:  33%|      | 338/1024 [00:21<00:46, 14.89it/s, est. speed input: 16101.85 toks/s, output: 15.72 toks/s]
Processed prompts:  34%|      | 346/1024 [00:22<00:45, 14.85it/s, est. speed input: 16077.68 toks/s, output: 15.70 toks/s]
Processed prompts:  35%|      | 354/1024 [00:22<00:45, 14.77it/s, est. speed input: 16049.70 toks/s, output: 15.67 toks/s]
Processed prompts:  35%|      | 362/1024 [00:23<00:44, 14.77it/s, est. speed input: 16028.51 toks/s, output: 15.65 toks/s]
Processed prompts:  36%|      | 370/1024 [00:23<00:44, 14.71it/s, est. speed input: 16002.73 toks/s, output: 15.63 toks/s]
Processed prompts:  37%|      | 378/1024 [00:24<00:43, 14.72it/s, est. speed input: 15982.44 toks/s, output: 15.61 toks/s]
Processed prompts:  38%|      | 386/1024 [00:24<00:43, 14.70it/s, est. speed input: 15960.59 toks/s, output: 15.59 toks/s]
Processed prompts:  38%|      | 394/1024 [00:25<00:42, 14.70it/s, est. speed input: 15941.30 toks/s, output: 15.57 toks/s]
Processed prompts:  39%|      | 402/1024 [00:25<00:42, 14.67it/s, est. speed input: 15920.45 toks/s, output: 15.55 toks/s]
Processed prompts:  40%|      | 410/1024 [00:26<00:41, 14.71it/s, est. speed input: 15904.68 toks/s, output: 15.53 toks/s]
Processed prompts:  41%|      | 418/1024 [00:26<00:41, 14.69it/s, est. speed input: 15886.06 toks/s, output: 15.51 toks/s]
Processed prompts:  42%|     | 426/1024 [00:27<00:40, 14.70it/s, est. speed input: 15870.08 toks/s, output: 15.50 toks/s]
Processed prompts:  42%|     | 434/1024 [00:28<00:40, 14.70it/s, est. speed input: 15854.04 toks/s, output: 15.48 toks/s]
Processed prompts:  43%|     | 442/1024 [00:28<00:39, 14.73it/s, est. speed input: 15840.71 toks/s, output: 15.47 toks/s]
Processed prompts:  44%|     | 450/1024 [00:29<00:38, 15.08it/s, est. speed input: 15849.38 toks/s, output: 15.48 toks/s]
Processed prompts:  45%|     | 458/1024 [00:29<00:38, 14.73it/s, est. speed input: 15819.95 toks/s, output: 15.45 toks/s]
Processed prompts:  46%|     | 466/1024 [00:30<00:41, 13.33it/s, est. speed input: 15707.54 toks/s, output: 15.34 toks/s]
Processed prompts:  46%|     | 474/1024 [00:30<00:40, 13.70it/s, est. speed input: 15695.47 toks/s, output: 15.33 toks/s]
Processed prompts:  47%|     | 482/1024 [00:31<00:38, 13.96it/s, est. speed input: 15682.28 toks/s, output: 15.31 toks/s]
Processed prompts:  48%|     | 490/1024 [00:32<00:37, 14.19it/s, est. speed input: 15672.94 toks/s, output: 15.31 toks/s]
Processed prompts:  49%|     | 498/1024 [00:32<00:36, 14.27it/s, est. speed input: 15658.29 toks/s, output: 15.29 toks/s]
Processed prompts:  49%|     | 506/1024 [00:33<00:35, 14.39it/s, est. speed input: 15647.75 toks/s, output: 15.28 toks/s]
Processed prompts:  50%|     | 514/1024 [00:33<00:35, 14.50it/s, est. speed input: 15639.07 toks/s, output: 15.27 toks/s]
Processed prompts:  51%|     | 522/1024 [00:34<00:34, 14.52it/s, est. speed input: 15627.35 toks/s, output: 15.26 toks/s]
Processed prompts:  52%|    | 530/1024 [00:34<00:33, 14.54it/s, est. speed input: 15616.81 toks/s, output: 15.25 toks/s]
Processed prompts:  53%|    | 538/1024 [00:35<00:33, 14.57it/s, est. speed input: 15607.16 toks/s, output: 15.24 toks/s]
Processed prompts:  53%|    | 546/1024 [00:35<00:32, 14.60it/s, est. speed input: 15598.20 toks/s, output: 15.23 toks/s]
Processed prompts:  54%|    | 554/1024 [00:36<00:32, 14.60it/s, est. speed input: 15588.18 toks/s, output: 15.22 toks/s]
Processed prompts:  55%|    | 562/1024 [00:36<00:31, 14.66it/s, est. speed input: 15581.94 toks/s, output: 15.22 toks/s]
Processed prompts:  56%|    | 570/1024 [00:37<00:30, 14.65it/s, est. speed input: 15573.30 toks/s, output: 15.21 toks/s]
Processed prompts:  56%|    | 578/1024 [00:38<00:30, 14.64it/s, est. speed input: 15564.54 toks/s, output: 15.20 toks/s]
Processed prompts:  57%|    | 586/1024 [00:38<00:29, 14.64it/s, est. speed input: 15556.36 toks/s, output: 15.19 toks/s]
Processed prompts:  58%|    | 594/1024 [00:39<00:29, 14.67it/s, est. speed input: 15550.20 toks/s, output: 15.19 toks/s]
Processed prompts:  59%|    | 602/1024 [00:39<00:28, 14.63it/s, est. speed input: 15540.65 toks/s, output: 15.18 toks/s]
Processed prompts:  60%|    | 610/1024 [00:40<00:28, 14.67it/s, est. speed input: 15534.97 toks/s, output: 15.17 toks/s]
Processed prompts:  60%|    | 618/1024 [00:40<00:27, 14.69it/s, est. speed input: 15529.04 toks/s, output: 15.17 toks/s]
Processed prompts:  61%|    | 626/1024 [00:41<00:27, 14.72it/s, est. speed input: 15524.28 toks/s, output: 15.16 toks/s]
Processed prompts:  62%|   | 634/1024 [00:41<00:26, 14.70it/s, est. speed input: 15517.36 toks/s, output: 15.15 toks/s]
Processed prompts:  63%|   | 642/1024 [00:42<00:25, 14.73it/s, est. speed input: 15512.57 toks/s, output: 15.15 toks/s]
Processed prompts:  63%|   | 650/1024 [00:42<00:25, 14.69it/s, est. speed input: 15505.70 toks/s, output: 15.14 toks/s]
Processed prompts:  64%|   | 658/1024 [00:43<00:24, 14.72it/s, est. speed input: 15501.12 toks/s, output: 15.14 toks/s]
Processed prompts:  65%|   | 666/1024 [00:44<00:24, 14.67it/s, est. speed input: 15493.44 toks/s, output: 15.13 toks/s]
Processed prompts:  66%|   | 674/1024 [00:44<00:23, 14.67it/s, est. speed input: 15487.85 toks/s, output: 15.12 toks/s]
Processed prompts:  67%|   | 682/1024 [00:45<00:23, 14.66it/s, est. speed input: 15481.71 toks/s, output: 15.12 toks/s]
Processed prompts:  67%|   | 690/1024 [00:45<00:22, 14.66it/s, est. speed input: 15476.12 toks/s, output: 15.11 toks/s]
Processed prompts:  68%|   | 698/1024 [00:46<00:22, 14.63it/s, est. speed input: 15469.34 toks/s, output: 15.11 toks/s]
Processed prompts:  69%|   | 706/1024 [00:46<00:21, 14.67it/s, est. speed input: 15465.20 toks/s, output: 15.10 toks/s]
Processed prompts:  70%|   | 714/1024 [00:47<00:21, 14.62it/s, est. speed input: 15458.25 toks/s, output: 15.10 toks/s]
Processed prompts:  71%|   | 722/1024 [00:47<00:20, 14.65it/s, est. speed input: 15454.00 toks/s, output: 15.09 toks/s]
Processed prompts:  71%|  | 730/1024 [00:48<00:20, 14.66it/s, est. speed input: 15449.29 toks/s, output: 15.09 toks/s]
Processed prompts:  72%|  | 738/1024 [00:48<00:19, 14.70it/s, est. speed input: 15445.87 toks/s, output: 15.08 toks/s]
Processed prompts:  73%|  | 746/1024 [00:49<00:18, 14.67it/s, est. speed input: 15440.50 toks/s, output: 15.08 toks/s]
Processed prompts:  74%|  | 754/1024 [00:50<00:18, 14.69it/s, est. speed input: 15436.59 toks/s, output: 15.07 toks/s]
Processed prompts:  74%|  | 762/1024 [00:50<00:17, 14.66it/s, est. speed input: 15431.23 toks/s, output: 15.07 toks/s]
Processed prompts:  75%|  | 770/1024 [00:51<00:17, 14.69it/s, est. speed input: 15427.85 toks/s, output: 15.07 toks/s]
Processed prompts:  76%|  | 778/1024 [00:51<00:16, 14.66it/s, est. speed input: 15422.85 toks/s, output: 15.06 toks/s]
Processed prompts:  77%|  | 786/1024 [00:52<00:16, 14.67it/s, est. speed input: 15418.70 toks/s, output: 15.06 toks/s]
Processed prompts:  78%|  | 794/1024 [00:52<00:15, 14.63it/s, est. speed input: 15413.11 toks/s, output: 15.05 toks/s]
Processed prompts:  78%|  | 802/1024 [00:53<00:15, 14.67it/s, est. speed input: 15410.33 toks/s, output: 15.05 toks/s]
Processed prompts:  79%|  | 810/1024 [00:53<00:14, 14.66it/s, est. speed input: 15405.94 toks/s, output: 15.04 toks/s]
Processed prompts:  80%|  | 818/1024 [00:54<00:14, 14.62it/s, est. speed input: 15400.60 toks/s, output: 15.04 toks/s]
Processed prompts:  81%|  | 826/1024 [00:54<00:13, 14.64it/s, est. speed input: 15396.97 toks/s, output: 15.04 toks/s]
Processed prompts:  81%| | 834/1024 [00:55<00:12, 14.63it/s, est. speed input: 15392.65 toks/s, output: 15.03 toks/s]
Processed prompts:  82%| | 842/1024 [00:56<00:12, 14.69it/s, est. speed input: 15390.62 toks/s, output: 15.03 toks/s]
Processed prompts:  83%| | 850/1024 [00:56<00:11, 14.66it/s, est. speed input: 15386.28 toks/s, output: 15.03 toks/s]
Processed prompts:  84%| | 858/1024 [00:57<00:11, 14.70it/s, est. speed input: 15384.09 toks/s, output: 15.02 toks/s]
Processed prompts:  85%| | 866/1024 [00:57<00:10, 14.64it/s, est. speed input: 15378.80 toks/s, output: 15.02 toks/s]
Processed prompts:  85%| | 874/1024 [00:58<00:10, 14.66it/s, est. speed input: 15375.82 toks/s, output: 15.02 toks/s]
Processed prompts:  86%| | 882/1024 [00:58<00:09, 14.60it/s, est. speed input: 15370.67 toks/s, output: 15.01 toks/s]
Processed prompts:  87%| | 890/1024 [00:59<00:09, 14.62it/s, est. speed input: 15367.41 toks/s, output: 15.01 toks/s]
Processed prompts:  88%| | 898/1024 [00:59<00:08, 14.62it/s, est. speed input: 15363.72 toks/s, output: 15.00 toks/s]
Processed prompts:  88%| | 906/1024 [01:00<00:08, 14.62it/s, est. speed input: 15360.15 toks/s, output: 15.00 toks/s]
Processed prompts:  89%| | 914/1024 [01:00<00:07, 14.60it/s, est. speed input: 15355.92 toks/s, output: 15.00 toks/s]
Processed prompts:  90%| | 922/1024 [01:01<00:06, 14.61it/s, est. speed input: 15352.69 toks/s, output: 14.99 toks/s]
Processed prompts:  91%| | 930/1024 [01:02<00:06, 14.58it/s, est. speed input: 15348.40 toks/s, output: 14.99 toks/s]
Processed prompts:  92%|| 938/1024 [01:02<00:05, 14.87it/s, est. speed input: 15353.48 toks/s, output: 14.99 toks/s]
Processed prompts:  92%|| 946/1024 [01:03<00:05, 14.75it/s, est. speed input: 15348.78 toks/s, output: 14.99 toks/s]
Processed prompts:  93%|| 954/1024 [01:03<00:04, 14.72it/s, est. speed input: 15345.91 toks/s, output: 14.99 toks/s]
Processed prompts:  94%|| 962/1024 [01:04<00:04, 14.68it/s, est. speed input: 15342.21 toks/s, output: 14.98 toks/s]
Processed prompts:  95%|| 970/1024 [01:04<00:03, 14.65it/s, est. speed input: 15338.69 toks/s, output: 14.98 toks/s]
Processed prompts:  96%|| 978/1024 [01:05<00:03, 14.62it/s, est. speed input: 15335.14 toks/s, output: 14.98 toks/s]
Processed prompts:  96%|| 986/1024 [01:05<00:02, 15.15it/s, est. speed input: 15347.07 toks/s, output: 14.99 toks/s]
Processed prompts:  97%|| 994/1024 [01:06<00:02, 15.00it/s, est. speed input: 15344.21 toks/s, output: 14.98 toks/s]
Processed prompts:  98%|| 1002/1024 [01:06<00:01, 14.91it/s, est. speed input: 15341.98 toks/s, output: 14.98 toks/s]
Processed prompts:  99%|| 1010/1024 [01:07<00:00, 14.82it/s, est. speed input: 15338.92 toks/s, output: 14.98 toks/s]
Processed prompts:  99%|| 1018/1024 [01:07<00:00, 15.18it/s, est. speed input: 15347.34 toks/s, output: 14.99 toks/s]
Processed prompts: 100%|| 1024/1024 [01:07<00:00, 15.18it/s, est. speed input: 15437.76 toks/s, output: 15.08 toks/s]
Processed prompts: 100%|| 1024/1024 [01:07<00:00, 15.08it/s, est. speed input: 15437.76 toks/s, output: 15.08 toks/s]
[rank0]:[W128 09:08:28.160891811 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-28 09:08:30
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/BitNet-2B-FP8_M16384.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 09:08:39 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-28 09:08:39 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=3729442) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=3729442) WARNING 01-28 09:09:07 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 14.93 requests/s, 15301.94 total tokens/s, 14.93 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-28 09:08:39] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-28 09:08:39] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 09:08:39] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 09:08:39] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:08:39] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:08:39] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:08:39] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:08:39] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:08:39] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 09:08:39] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 09:08:39] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 09:08:39] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 09:08:39] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 09:08:39] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 09:08:42] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-28 09:08:42] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 09:08:42] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 09:08:42] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:08:42] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:08:42] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:08:42] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:08:42] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:08:42] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 09:08:42] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 09:08:42] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 09:08:42] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 09:08:42] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 09:08:42] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3729442) [2026-01-28 09:08:43] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3729442) [2026-01-28 09:08:43] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=3729442) [2026-01-28 09:08:43] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3729442) [2026-01-28 09:08:43] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=3729442) [2026-01-28 09:08:43] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: BitNet-2B-FP8
(EngineCore_DP0 pid=3729442) [2026-01-28 09:08:43] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=3729442) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3729442) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:14<00:00, 14.66s/it]
(EngineCore_DP0 pid=3729442) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:14<00:00, 14.66s/it]
(EngineCore_DP0 pid=3729442) 
(EngineCore_DP0 pid=3729442) [2026-01-28 09:08:59] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3840, 3424] -> 1D uint8
(EngineCore_DP0 pid=3729442) [2026-01-28 09:08:59] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8232960 bytes
(EngineCore_DP0 pid=3729442) [2026-01-28 09:08:59] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 3424] -> 1D uint8
(EngineCore_DP0 pid=3729442) [2026-01-28 09:08:59] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5488640 bytes
(EngineCore_DP0 pid=3729442) [2026-01-28 09:08:59] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [13824, 3424] -> 1D uint8
(EngineCore_DP0 pid=3729442) [2026-01-28 09:08:59] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 29638656 bytes
(EngineCore_DP0 pid=3729442) [2026-01-28 09:08:59] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 9216] -> 1D uint8
(EngineCore_DP0 pid=3729442) [2026-01-28 09:08:59] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14745600 bytes
(EngineCore_DP0 pid=3729442) 2026-01-28 09:09:05,793 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3729442) 2026-01-28 09:09:05,863 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   3%|         | 66/2048 [00:00<00:03, 654.01it/s]
Adding requests:   6%|         | 132/2048 [00:00<00:03, 604.79it/s]
Adding requests:   9%|         | 193/2048 [00:00<00:03, 543.45it/s]
Adding requests:  12%|        | 248/2048 [00:00<00:03, 540.96it/s]
Adding requests:  15%|        | 303/2048 [00:00<00:03, 527.60it/s]
Adding requests:  17%|        | 357/2048 [00:00<00:03, 529.33it/s]
Adding requests:  20%|        | 411/2048 [00:00<00:03, 518.15it/s]
Adding requests:  23%|       | 464/2048 [00:00<00:03, 520.36it/s]
Adding requests:  25%|       | 517/2048 [00:00<00:03, 502.76it/s]
Adding requests:  28%|       | 568/2048 [00:01<00:02, 497.78it/s]
Adding requests:  30%|       | 620/2048 [00:01<00:02, 504.07it/s]
Adding requests:  33%|      | 671/2048 [00:01<00:02, 505.48it/s]
Adding requests:  35%|      | 724/2048 [00:01<00:02, 511.00it/s]
Adding requests:  38%|      | 776/2048 [00:01<00:02, 486.98it/s]
Adding requests:  40%|      | 825/2048 [00:01<00:02, 481.83it/s]
Adding requests:  43%|     | 874/2048 [00:02<00:06, 195.38it/s]
Adding requests:  45%|     | 925/2048 [00:02<00:04, 239.77it/s]
Adding requests:  48%|     | 975/2048 [00:02<00:03, 282.60it/s]
Adding requests:  50%|     | 1028/2048 [00:02<00:03, 330.03it/s]
Adding requests:  53%|    | 1079/2048 [00:02<00:02, 368.54it/s]
Adding requests:  55%|    | 1131/2048 [00:02<00:02, 403.90it/s]
Adding requests:  58%|    | 1184/2048 [00:02<00:01, 435.15it/s]
Adding requests:  60%|    | 1235/2048 [00:02<00:01, 453.51it/s]
Adding requests:  63%|   | 1286/2048 [00:03<00:01, 460.97it/s]
Adding requests:  65%|   | 1338/2048 [00:03<00:01, 476.51it/s]
Adding requests:  68%|   | 1391/2048 [00:03<00:01, 490.57it/s]
Adding requests:  70%|   | 1442/2048 [00:03<00:01, 492.66it/s]
Adding requests:  73%|  | 1494/2048 [00:03<00:01, 499.67it/s]
Adding requests:  75%|  | 1545/2048 [00:03<00:01, 502.58it/s]
Adding requests:  78%|  | 1600/2048 [00:03<00:00, 514.73it/s]
Adding requests:  81%|  | 1653/2048 [00:03<00:00, 517.66it/s]
Adding requests:  83%| | 1706/2048 [00:03<00:00, 509.75it/s]
Adding requests:  86%| | 1758/2048 [00:03<00:00, 510.82it/s]
Adding requests:  88%| | 1812/2048 [00:04<00:00, 517.94it/s]
Adding requests:  91%| | 1864/2048 [00:04<00:00, 512.67it/s]
Adding requests:  94%|| 1917/2048 [00:04<00:00, 516.41it/s]
Adding requests:  96%|| 1969/2048 [00:04<00:00, 511.10it/s]
Adding requests:  99%|| 2021/2048 [00:04<00:00, 493.73it/s]
Adding requests: 100%|| 2048/2048 [00:04<00:00, 451.92it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   3%|         | 66/2048 [00:01<00:30, 65.11it/s, est. speed input: 66679.76 toks/s, output: 65.11 toks/s]
Processed prompts:   4%|         | 82/2048 [00:02<00:56, 34.98it/s, est. speed input: 40325.58 toks/s, output: 39.38 toks/s]
Processed prompts:   5%|         | 98/2048 [00:03<01:15, 25.69it/s, est. speed input: 31803.04 toks/s, output: 31.06 toks/s]
Processed prompts:   6%|         | 114/2048 [00:04<01:30, 21.40it/s, est. speed input: 27613.79 toks/s, output: 26.97 toks/s]
Processed prompts:   6%|         | 130/2048 [00:05<01:40, 19.07it/s, est. speed input: 25129.20 toks/s, output: 24.54 toks/s]
Processed prompts:   7%|         | 146/2048 [00:06<01:47, 17.68it/s, est. speed input: 23489.42 toks/s, output: 22.94 toks/s]
Processed prompts:   8%|         | 162/2048 [00:07<01:52, 16.80it/s, est. speed input: 22319.05 toks/s, output: 21.80 toks/s]
Processed prompts:   9%|         | 178/2048 [00:08<01:55, 16.20it/s, est. speed input: 21429.97 toks/s, output: 20.93 toks/s]
Processed prompts:   9%|         | 194/2048 [00:09<01:57, 15.81it/s, est. speed input: 20748.18 toks/s, output: 20.26 toks/s]
Processed prompts:  10%|         | 210/2048 [00:10<01:58, 15.55it/s, est. speed input: 20203.86 toks/s, output: 19.73 toks/s]
Processed prompts:  11%|         | 226/2048 [00:11<01:58, 15.37it/s, est. speed input: 19757.08 toks/s, output: 19.29 toks/s]
Processed prompts:  12%|        | 242/2048 [00:12<01:58, 15.25it/s, est. speed input: 19387.76 toks/s, output: 18.93 toks/s]
Processed prompts:  13%|        | 258/2048 [00:13<01:58, 15.17it/s, est. speed input: 19074.76 toks/s, output: 18.63 toks/s]
Processed prompts:  13%|        | 274/2048 [00:14<01:57, 15.12it/s, est. speed input: 18810.01 toks/s, output: 18.37 toks/s]
Processed prompts:  14%|        | 290/2048 [00:15<01:56, 15.06it/s, est. speed input: 18572.88 toks/s, output: 18.14 toks/s]
Processed prompts:  15%|        | 306/2048 [00:17<01:56, 15.02it/s, est. speed input: 18365.47 toks/s, output: 17.94 toks/s]
Processed prompts:  16%|        | 322/2048 [00:18<01:55, 14.99it/s, est. speed input: 18183.42 toks/s, output: 17.76 toks/s]
Processed prompts:  17%|        | 338/2048 [00:19<01:53, 15.10it/s, est. speed input: 18050.45 toks/s, output: 17.63 toks/s]
Processed prompts:  17%|        | 354/2048 [00:20<01:52, 15.04it/s, est. speed input: 17903.03 toks/s, output: 17.48 toks/s]
Processed prompts:  18%|        | 370/2048 [00:21<01:51, 15.01it/s, est. speed input: 17771.43 toks/s, output: 17.35 toks/s]
Processed prompts:  19%|        | 386/2048 [00:22<01:50, 14.98it/s, est. speed input: 17650.91 toks/s, output: 17.24 toks/s]
Processed prompts:  20%|        | 402/2048 [00:23<01:49, 14.97it/s, est. speed input: 17544.01 toks/s, output: 17.13 toks/s]
Processed prompts:  20%|        | 418/2048 [00:24<01:49, 14.95it/s, est. speed input: 17444.22 toks/s, output: 17.04 toks/s]
Processed prompts:  21%|        | 434/2048 [00:25<01:48, 14.94it/s, est. speed input: 17353.60 toks/s, output: 16.95 toks/s]
Processed prompts:  22%|       | 450/2048 [00:26<01:45, 15.10it/s, est. speed input: 17295.80 toks/s, output: 16.89 toks/s]
Processed prompts:  23%|       | 466/2048 [00:27<01:51, 14.22it/s, est. speed input: 17090.29 toks/s, output: 16.69 toks/s]
Processed prompts:  24%|       | 482/2048 [00:28<01:48, 14.43it/s, est. speed input: 17025.09 toks/s, output: 16.63 toks/s]
Processed prompts:  24%|       | 498/2048 [00:30<01:46, 14.58it/s, est. speed input: 16963.53 toks/s, output: 16.57 toks/s]
Processed prompts:  25%|       | 514/2048 [00:31<01:44, 14.67it/s, est. speed input: 16904.58 toks/s, output: 16.51 toks/s]
Processed prompts:  26%|       | 530/2048 [00:32<01:42, 14.75it/s, est. speed input: 16850.33 toks/s, output: 16.46 toks/s]
Processed prompts:  27%|       | 546/2048 [00:33<01:41, 14.80it/s, est. speed input: 16799.91 toks/s, output: 16.41 toks/s]
Processed prompts:  27%|       | 562/2048 [00:34<01:40, 14.83it/s, est. speed input: 16751.29 toks/s, output: 16.36 toks/s]
Processed prompts:  28%|       | 578/2048 [00:35<01:39, 14.84it/s, est. speed input: 16705.31 toks/s, output: 16.31 toks/s]
Processed prompts:  29%|       | 594/2048 [00:36<01:37, 14.88it/s, est. speed input: 16664.74 toks/s, output: 16.27 toks/s]
Processed prompts:  30%|       | 610/2048 [00:37<01:36, 14.89it/s, est. speed input: 16625.41 toks/s, output: 16.24 toks/s]
Processed prompts:  31%|       | 626/2048 [00:38<01:35, 14.91it/s, est. speed input: 16588.44 toks/s, output: 16.20 toks/s]
Processed prompts:  31%|      | 642/2048 [00:39<01:34, 14.90it/s, est. speed input: 16552.55 toks/s, output: 16.16 toks/s]
Processed prompts:  32%|      | 658/2048 [00:40<01:33, 14.92it/s, est. speed input: 16519.66 toks/s, output: 16.13 toks/s]
Processed prompts:  33%|      | 674/2048 [00:41<01:31, 14.94it/s, est. speed input: 16489.78 toks/s, output: 16.10 toks/s]
Processed prompts:  34%|      | 690/2048 [00:42<01:30, 14.93it/s, est. speed input: 16459.08 toks/s, output: 16.07 toks/s]
Processed prompts:  34%|      | 706/2048 [00:44<01:29, 14.92it/s, est. speed input: 16429.86 toks/s, output: 16.04 toks/s]
Processed prompts:  35%|      | 722/2048 [00:45<01:28, 14.91it/s, est. speed input: 16401.64 toks/s, output: 16.02 toks/s]
Processed prompts:  36%|      | 738/2048 [00:46<01:27, 14.90it/s, est. speed input: 16374.68 toks/s, output: 15.99 toks/s]
Processed prompts:  37%|      | 754/2048 [00:47<01:26, 14.91it/s, est. speed input: 16349.55 toks/s, output: 15.97 toks/s]
Processed prompts:  38%|      | 770/2048 [00:48<01:25, 14.92it/s, est. speed input: 16326.56 toks/s, output: 15.94 toks/s]
Processed prompts:  38%|      | 786/2048 [00:49<01:24, 14.91it/s, est. speed input: 16303.17 toks/s, output: 15.92 toks/s]
Processed prompts:  39%|      | 802/2048 [00:50<01:23, 14.91it/s, est. speed input: 16280.94 toks/s, output: 15.90 toks/s]
Processed prompts:  40%|      | 818/2048 [00:51<01:22, 14.93it/s, est. speed input: 16261.57 toks/s, output: 15.88 toks/s]
Processed prompts:  41%|      | 834/2048 [00:52<01:21, 14.92it/s, est. speed input: 16240.63 toks/s, output: 15.86 toks/s]
Processed prompts:  42%|     | 850/2048 [00:53<01:20, 14.91it/s, est. speed input: 16221.16 toks/s, output: 15.84 toks/s]
Processed prompts:  42%|     | 866/2048 [00:54<01:19, 14.92it/s, est. speed input: 16203.24 toks/s, output: 15.82 toks/s]
Processed prompts:  43%|     | 882/2048 [00:55<01:18, 14.92it/s, est. speed input: 16185.09 toks/s, output: 15.81 toks/s]
Processed prompts:  44%|     | 898/2048 [00:56<01:17, 14.92it/s, est. speed input: 16168.10 toks/s, output: 15.79 toks/s]
Processed prompts:  45%|     | 914/2048 [00:57<01:16, 14.91it/s, est. speed input: 16150.99 toks/s, output: 15.77 toks/s]
Processed prompts:  45%|     | 930/2048 [00:58<01:13, 15.13it/s, est. speed input: 16149.16 toks/s, output: 15.77 toks/s]
Processed prompts:  46%|     | 946/2048 [01:00<01:14, 14.76it/s, est. speed input: 16113.65 toks/s, output: 15.74 toks/s]
Processed prompts:  47%|     | 962/2048 [01:01<01:13, 14.80it/s, est. speed input: 16098.51 toks/s, output: 15.72 toks/s]
Processed prompts:  48%|     | 978/2048 [01:02<01:11, 15.05it/s, est. speed input: 16097.70 toks/s, output: 15.72 toks/s]
Processed prompts:  49%|     | 994/2048 [01:03<01:10, 15.01it/s, est. speed input: 16083.70 toks/s, output: 15.71 toks/s]
Processed prompts:  49%|     | 1010/2048 [01:04<01:09, 14.97it/s, est. speed input: 16069.47 toks/s, output: 15.69 toks/s]
Processed prompts:  50%|     | 1026/2048 [01:05<01:08, 14.95it/s, est. speed input: 16056.52 toks/s, output: 15.68 toks/s]
Processed prompts:  51%|     | 1042/2048 [01:06<01:07, 14.94it/s, est. speed input: 16044.02 toks/s, output: 15.67 toks/s]
Processed prompts:  52%|    | 1058/2048 [01:07<01:06, 14.92it/s, est. speed input: 16031.01 toks/s, output: 15.66 toks/s]
Processed prompts:  52%|    | 1074/2048 [01:08<01:05, 14.92it/s, est. speed input: 16019.01 toks/s, output: 15.64 toks/s]
Processed prompts:  53%|    | 1090/2048 [01:09<01:04, 14.91it/s, est. speed input: 16007.08 toks/s, output: 15.63 toks/s]
Processed prompts:  54%|    | 1106/2048 [01:10<01:03, 14.91it/s, est. speed input: 15995.82 toks/s, output: 15.62 toks/s]
Processed prompts:  55%|    | 1122/2048 [01:11<01:02, 14.90it/s, est. speed input: 15984.76 toks/s, output: 15.61 toks/s]
Processed prompts:  56%|    | 1138/2048 [01:12<01:01, 14.90it/s, est. speed input: 15973.86 toks/s, output: 15.60 toks/s]
Processed prompts:  56%|    | 1154/2048 [01:13<00:59, 15.14it/s, est. speed input: 15975.48 toks/s, output: 15.60 toks/s]
Processed prompts:  57%|    | 1170/2048 [01:15<00:58, 15.08it/s, est. speed input: 15965.78 toks/s, output: 15.59 toks/s]
Processed prompts:  58%|    | 1186/2048 [01:16<00:57, 15.02it/s, est. speed input: 15955.61 toks/s, output: 15.58 toks/s]
Processed prompts:  59%|    | 1202/2048 [01:17<00:56, 14.97it/s, est. speed input: 15945.28 toks/s, output: 15.57 toks/s]
Processed prompts:  59%|    | 1218/2048 [01:18<00:55, 14.96it/s, est. speed input: 15936.26 toks/s, output: 15.56 toks/s]
Processed prompts:  60%|    | 1234/2048 [01:19<00:54, 14.94it/s, est. speed input: 15927.17 toks/s, output: 15.55 toks/s]
Processed prompts:  61%|    | 1250/2048 [01:20<00:53, 14.93it/s, est. speed input: 15918.48 toks/s, output: 15.55 toks/s]
Processed prompts:  62%|   | 1266/2048 [01:21<00:51, 15.16it/s, est. speed input: 15920.39 toks/s, output: 15.55 toks/s]
Processed prompts:  63%|   | 1282/2048 [01:22<00:50, 15.07it/s, est. speed input: 15911.53 toks/s, output: 15.54 toks/s]
Processed prompts:  63%|   | 1298/2048 [01:23<00:49, 15.26it/s, est. speed input: 15913.96 toks/s, output: 15.54 toks/s]
Processed prompts:  64%|   | 1314/2048 [01:24<00:48, 15.15it/s, est. speed input: 15905.49 toks/s, output: 15.53 toks/s]
Processed prompts:  65%|   | 1330/2048 [01:25<00:47, 15.07it/s, est. speed input: 15897.28 toks/s, output: 15.52 toks/s]
Processed prompts:  66%|   | 1346/2048 [01:26<00:46, 15.02it/s, est. speed input: 15889.27 toks/s, output: 15.52 toks/s]
Processed prompts:  67%|   | 1362/2048 [01:27<00:45, 14.98it/s, est. speed input: 15881.49 toks/s, output: 15.51 toks/s]
Processed prompts:  67%|   | 1378/2048 [01:28<00:44, 14.95it/s, est. speed input: 15873.60 toks/s, output: 15.50 toks/s]
Processed prompts:  68%|   | 1394/2048 [01:29<00:43, 14.92it/s, est. speed input: 15865.78 toks/s, output: 15.49 toks/s]
Processed prompts:  69%|   | 1410/2048 [01:31<00:42, 14.92it/s, est. speed input: 15858.80 toks/s, output: 15.49 toks/s]
Processed prompts:  70%|   | 1426/2048 [01:32<00:41, 14.83it/s, est. speed input: 15848.27 toks/s, output: 15.48 toks/s]
Processed prompts:  70%|   | 1442/2048 [01:33<00:40, 14.85it/s, est. speed input: 15841.28 toks/s, output: 15.47 toks/s]
Processed prompts:  71%|   | 1458/2048 [01:34<00:39, 14.85it/s, est. speed input: 15834.12 toks/s, output: 15.46 toks/s]
Processed prompts:  72%|  | 1474/2048 [01:35<00:38, 14.87it/s, est. speed input: 15827.91 toks/s, output: 15.46 toks/s]
Processed prompts:  73%|  | 1490/2048 [01:36<00:37, 14.87it/s, est. speed input: 15821.26 toks/s, output: 15.45 toks/s]
Processed prompts:  74%|  | 1506/2048 [01:37<00:36, 14.88it/s, est. speed input: 15814.92 toks/s, output: 15.44 toks/s]
Processed prompts:  74%|  | 1522/2048 [01:38<00:35, 14.89it/s, est. speed input: 15808.95 toks/s, output: 15.44 toks/s]
Processed prompts:  75%|  | 1538/2048 [01:39<00:34, 14.89it/s, est. speed input: 15802.84 toks/s, output: 15.43 toks/s]
Processed prompts:  76%|  | 1554/2048 [01:40<00:33, 14.88it/s, est. speed input: 15796.79 toks/s, output: 15.43 toks/s]
Processed prompts:  77%|  | 1570/2048 [01:41<00:32, 14.89it/s, est. speed input: 15790.97 toks/s, output: 15.42 toks/s]
Processed prompts:  77%|  | 1586/2048 [01:42<00:30, 15.12it/s, est. speed input: 15793.92 toks/s, output: 15.42 toks/s]
Processed prompts:  78%|  | 1602/2048 [01:43<00:29, 15.06it/s, est. speed input: 15788.62 toks/s, output: 15.42 toks/s]
Processed prompts:  79%|  | 1618/2048 [01:44<00:28, 15.01it/s, est. speed input: 15783.16 toks/s, output: 15.41 toks/s]
Processed prompts:  80%|  | 1634/2048 [01:46<00:27, 14.97it/s, est. speed input: 15777.50 toks/s, output: 15.41 toks/s]
Processed prompts:  81%|  | 1650/2048 [01:47<00:26, 15.18it/s, est. speed input: 15780.35 toks/s, output: 15.41 toks/s]
Processed prompts:  81%| | 1666/2048 [01:48<00:25, 15.08it/s, est. speed input: 15774.72 toks/s, output: 15.40 toks/s]
Processed prompts:  82%| | 1682/2048 [01:49<00:24, 15.03it/s, est. speed input: 15769.72 toks/s, output: 15.40 toks/s]
Processed prompts:  83%| | 1698/2048 [01:50<00:23, 14.98it/s, est. speed input: 15764.43 toks/s, output: 15.39 toks/s]
Processed prompts:  84%| | 1714/2048 [01:51<00:22, 14.96it/s, est. speed input: 15759.49 toks/s, output: 15.39 toks/s]
Processed prompts:  84%| | 1730/2048 [01:52<00:21, 14.93it/s, est. speed input: 15754.47 toks/s, output: 15.39 toks/s]
Processed prompts:  85%| | 1746/2048 [01:53<00:20, 14.94it/s, est. speed input: 15750.40 toks/s, output: 15.38 toks/s]
Processed prompts:  86%| | 1762/2048 [01:54<00:19, 14.93it/s, est. speed input: 15745.88 toks/s, output: 15.38 toks/s]
Processed prompts:  87%| | 1778/2048 [01:55<00:18, 14.93it/s, est. speed input: 15741.52 toks/s, output: 15.37 toks/s]
Processed prompts:  88%| | 1794/2048 [01:56<00:17, 14.92it/s, est. speed input: 15736.96 toks/s, output: 15.37 toks/s]
Processed prompts:  88%| | 1810/2048 [01:57<00:15, 14.91it/s, est. speed input: 15732.65 toks/s, output: 15.36 toks/s]
Processed prompts:  89%| | 1826/2048 [01:58<00:14, 14.91it/s, est. speed input: 15728.50 toks/s, output: 15.36 toks/s]
Processed prompts:  90%| | 1842/2048 [01:59<00:13, 14.90it/s, est. speed input: 15724.12 toks/s, output: 15.36 toks/s]
Processed prompts:  91%| | 1858/2048 [02:01<00:12, 14.90it/s, est. speed input: 15719.83 toks/s, output: 15.35 toks/s]
Processed prompts:  92%|| 1874/2048 [02:02<00:11, 15.13it/s, est. speed input: 15722.94 toks/s, output: 15.35 toks/s]
Processed prompts:  92%|| 1890/2048 [02:03<00:10, 15.06it/s, est. speed input: 15718.78 toks/s, output: 15.35 toks/s]
Processed prompts:  93%|| 1906/2048 [02:04<00:09, 15.01it/s, est. speed input: 15714.72 toks/s, output: 15.35 toks/s]
Processed prompts:  94%|| 1922/2048 [02:05<00:08, 14.91it/s, est. speed input: 15708.84 toks/s, output: 15.34 toks/s]
Processed prompts:  95%|| 1938/2048 [02:06<00:07, 14.90it/s, est. speed input: 15704.66 toks/s, output: 15.34 toks/s]
Processed prompts:  95%|| 1954/2048 [02:07<00:06, 15.13it/s, est. speed input: 15707.64 toks/s, output: 15.34 toks/s]
Processed prompts:  96%|| 1970/2048 [02:08<00:05, 15.06it/s, est. speed input: 15703.77 toks/s, output: 15.34 toks/s]
Processed prompts:  97%|| 1986/2048 [02:09<00:04, 15.27it/s, est. speed input: 15707.35 toks/s, output: 15.34 toks/s]
Processed prompts:  98%|| 2002/2048 [02:10<00:03, 15.15it/s, est. speed input: 15703.51 toks/s, output: 15.34 toks/s]
Processed prompts:  99%|| 2018/2048 [02:11<00:01, 15.07it/s, est. speed input: 15699.87 toks/s, output: 15.33 toks/s]
Processed prompts:  99%|| 2034/2048 [02:12<00:00, 15.21it/s, est. speed input: 15701.45 toks/s, output: 15.33 toks/s]
Processed prompts: 100%|| 2048/2048 [02:12<00:00, 15.21it/s, est. speed input: 15809.50 toks/s, output: 15.44 toks/s]
Processed prompts: 100%|| 2048/2048 [02:12<00:00, 15.44it/s, est. speed input: 15809.50 toks/s, output: 15.44 toks/s]
[rank0]:[W128 09:11:25.073991550 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-28 09:11:27
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_6/json/BitNet-2B-FP8_M32768.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 09:11:42 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-28 09:11:42 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=3732122) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=3732122) WARNING 01-28 09:12:12 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 14.78 requests/s, 15152.57 total tokens/s, 14.78 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-28 09:11:41] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-28 09:11:42] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 09:11:42] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 09:11:42] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:11:42] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:11:42] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:11:42] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:11:42] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:11:42] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 09:11:42] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 09:11:42] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 09:11:42] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 09:11:42] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 09:11:42] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 09:11:45] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-28 09:11:45] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 09:11:45] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 09:11:45] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:11:45] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:11:45] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:11:45] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:11:45] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:11:45] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 09:11:45] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 09:11:45] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 09:11:45] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 09:11:45] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 09:11:45] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3732122) [2026-01-28 09:11:46] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3732122) [2026-01-28 09:11:46] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=3732122) [2026-01-28 09:11:46] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3732122) [2026-01-28 09:11:46] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=3732122) [2026-01-28 09:11:46] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: BitNet-2B-FP8
(EngineCore_DP0 pid=3732122) [2026-01-28 09:11:46] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=3732122) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3732122) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:14<00:00, 14.53s/it]
(EngineCore_DP0 pid=3732122) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:14<00:00, 14.53s/it]
(EngineCore_DP0 pid=3732122) 
(EngineCore_DP0 pid=3732122) [2026-01-28 09:12:01] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3840, 3424] -> 1D uint8
(EngineCore_DP0 pid=3732122) [2026-01-28 09:12:01] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8232960 bytes
(EngineCore_DP0 pid=3732122) [2026-01-28 09:12:01] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 3424] -> 1D uint8
(EngineCore_DP0 pid=3732122) [2026-01-28 09:12:01] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5488640 bytes
(EngineCore_DP0 pid=3732122) [2026-01-28 09:12:01] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [13824, 3424] -> 1D uint8
(EngineCore_DP0 pid=3732122) [2026-01-28 09:12:01] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 29638656 bytes
(EngineCore_DP0 pid=3732122) [2026-01-28 09:12:01] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 9216] -> 1D uint8
(EngineCore_DP0 pid=3732122) [2026-01-28 09:12:01] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14745600 bytes
(EngineCore_DP0 pid=3732122) 2026-01-28 09:12:09,373 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3732122) 2026-01-28 09:12:09,686 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   2%|         | 62/4096 [00:00<00:06, 615.13it/s]
Adding requests:   3%|         | 124/4096 [00:00<00:07, 558.68it/s]
Adding requests:   4%|         | 181/4096 [00:00<00:07, 521.61it/s]
Adding requests:   6%|         | 234/4096 [00:00<00:07, 518.51it/s]
Adding requests:   7%|         | 287/4096 [00:00<00:07, 513.72it/s]
Adding requests:   8%|         | 339/4096 [00:00<00:07, 511.14it/s]
Adding requests:  10%|         | 392/4096 [00:00<00:07, 515.53it/s]
Adding requests:  11%|         | 445/4096 [00:00<00:07, 516.40it/s]
Adding requests:  12%|        | 497/4096 [00:00<00:07, 512.55it/s]
Adding requests:  13%|        | 549/4096 [00:01<00:06, 508.68it/s]
Adding requests:  15%|        | 602/4096 [00:01<00:06, 514.76it/s]
Adding requests:  16%|        | 657/4096 [00:01<00:06, 522.03it/s]
Adding requests:  17%|        | 712/4096 [00:01<00:06, 527.78it/s]
Adding requests:  19%|        | 765/4096 [00:01<00:06, 521.91it/s]
Adding requests:  20%|        | 818/4096 [00:01<00:06, 510.27it/s]
Adding requests:  21%|        | 870/4096 [00:01<00:06, 504.83it/s]
Adding requests:  23%|       | 923/4096 [00:01<00:06, 510.77it/s]
Adding requests:  24%|       | 976/4096 [00:01<00:06, 514.36it/s]
Adding requests:  25%|       | 1029/4096 [00:01<00:05, 518.81it/s]
Adding requests:  26%|       | 1081/4096 [00:02<00:05, 518.21it/s]
Adding requests:  28%|       | 1133/4096 [00:02<00:05, 510.20it/s]
Adding requests:  29%|       | 1185/4096 [00:02<00:05, 489.22it/s]
Adding requests:  30%|       | 1235/4096 [00:02<00:05, 484.47it/s]
Adding requests:  31%|      | 1286/4096 [00:02<00:05, 489.90it/s]
Adding requests:  33%|      | 1338/4096 [00:02<00:05, 497.02it/s]
Adding requests:  34%|      | 1391/4096 [00:02<00:05, 506.29it/s]
Adding requests:  35%|      | 1444/4096 [00:02<00:05, 512.38it/s]
Adding requests:  37%|      | 1497/4096 [00:02<00:05, 515.83it/s]
Adding requests:  38%|      | 1550/4096 [00:03<00:04, 519.41it/s]
Adding requests:  39%|      | 1604/4096 [00:03<00:04, 524.09it/s]
Adding requests:  40%|      | 1657/4096 [00:03<00:04, 525.02it/s]
Adding requests:  42%|     | 1710/4096 [00:03<00:04, 525.80it/s]
Adding requests:  43%|     | 1764/4096 [00:03<00:04, 527.51it/s]
Adding requests:  44%|     | 1819/4096 [00:03<00:04, 532.60it/s]
Adding requests:  46%|     | 1873/4096 [00:03<00:04, 521.12it/s]
Adding requests:  47%|     | 1926/4096 [00:03<00:04, 512.12it/s]
Adding requests:  48%|     | 1978/4096 [00:03<00:04, 507.88it/s]
Adding requests:  50%|     | 2033/4096 [00:03<00:03, 517.62it/s]
Adding requests:  51%|     | 2088/4096 [00:04<00:03, 524.14it/s]
Adding requests:  52%|    | 2141/4096 [00:04<00:03, 521.71it/s]
Adding requests:  54%|    | 2194/4096 [00:04<00:03, 521.28it/s]
Adding requests:  55%|    | 2249/4096 [00:04<00:03, 527.02it/s]
Adding requests:  56%|    | 2302/4096 [00:04<00:03, 519.89it/s]
Adding requests:  57%|    | 2355/4096 [00:04<00:03, 510.03it/s]
Adding requests:  59%|    | 2407/4096 [00:04<00:03, 512.10it/s]
Adding requests:  60%|    | 2459/4096 [00:04<00:03, 476.15it/s]
Adding requests:  61%|   | 2511/4096 [00:04<00:03, 487.51it/s]
Adding requests:  63%|   | 2562/4096 [00:04<00:03, 492.91it/s]
Adding requests:  64%|   | 2617/4096 [00:05<00:02, 507.32it/s]
Adding requests:  65%|   | 2672/4096 [00:05<00:02, 519.28it/s]
Adding requests:  67%|   | 2725/4096 [00:05<00:02, 516.15it/s]
Adding requests:  68%|   | 2777/4096 [00:05<00:02, 513.27it/s]
Adding requests:  69%|   | 2829/4096 [00:05<00:02, 512.24it/s]
Adding requests:  70%|   | 2884/4096 [00:05<00:02, 520.78it/s]
Adding requests:  72%|  | 2937/4096 [00:05<00:02, 514.77it/s]
Adding requests:  73%|  | 2989/4096 [00:05<00:02, 515.16it/s]
Adding requests:  74%|  | 3041/4096 [00:05<00:02, 502.88it/s]
Adding requests:  76%|  | 3093/4096 [00:06<00:01, 506.69it/s]
Adding requests:  77%|  | 3145/4096 [00:06<00:01, 508.19it/s]
Adding requests:  78%|  | 3199/4096 [00:06<00:01, 516.37it/s]
Adding requests:  79%|  | 3252/4096 [00:06<00:01, 520.15it/s]
Adding requests:  81%|  | 3305/4096 [00:06<00:01, 517.73it/s]
Adding requests:  82%| | 3358/4096 [00:06<00:01, 520.37it/s]
Adding requests:  83%| | 3412/4096 [00:06<00:01, 524.02it/s]
Adding requests:  85%| | 3465/4096 [00:06<00:01, 515.81it/s]
Adding requests:  86%| | 3517/4096 [00:06<00:01, 513.67it/s]
Adding requests:  87%| | 3569/4096 [00:06<00:01, 509.64it/s]
Adding requests:  88%| | 3621/4096 [00:07<00:00, 512.57it/s]
Adding requests:  90%| | 3676/4096 [00:07<00:00, 521.24it/s]
Adding requests:  91%| | 3730/4096 [00:07<00:00, 524.14it/s]
Adding requests:  92%|| 3788/4096 [00:07<00:00, 539.87it/s]
Adding requests:  94%|| 3843/4096 [00:07<00:00, 494.74it/s]
Adding requests:  95%|| 3897/4096 [00:07<00:00, 506.16it/s]
Adding requests:  96%|| 3952/4096 [00:07<00:00, 517.01it/s]
Adding requests:  98%|| 4007/4096 [00:07<00:00, 524.33it/s]
Adding requests:  99%|| 4060/4096 [00:07<00:00, 511.25it/s]
Adding requests: 100%|| 4096/4096 [00:07<00:00, 514.45it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 98/4096 [00:00<00:35, 112.45it/s, est. speed input: 115157.82 toks/s, output: 112.45 toks/s]
Processed prompts:   3%|         | 130/4096 [00:03<01:48, 36.39it/s, est. speed input: 43991.39 toks/s, output: 42.96 toks/s]  
Processed prompts:   4%|         | 162/4096 [00:05<02:37, 25.02it/s, est. speed input: 31994.71 toks/s, output: 31.24 toks/s]
Processed prompts:   5%|         | 194/4096 [00:07<03:08, 20.65it/s, est. speed input: 27061.95 toks/s, output: 26.43 toks/s]
Processed prompts:   6%|         | 226/4096 [00:09<03:30, 18.43it/s, est. speed input: 24356.08 toks/s, output: 23.79 toks/s]
Processed prompts:   6%|         | 258/4096 [00:11<03:43, 17.16it/s, est. speed input: 22661.60 toks/s, output: 22.13 toks/s]
Processed prompts:   7%|         | 290/4096 [00:13<03:52, 16.38it/s, est. speed input: 21492.03 toks/s, output: 20.99 toks/s]
Processed prompts:   8%|         | 322/4096 [00:15<03:56, 15.94it/s, est. speed input: 20671.17 toks/s, output: 20.19 toks/s]
Processed prompts:   9%|         | 354/4096 [00:18<03:59, 15.59it/s, est. speed input: 20020.94 toks/s, output: 19.55 toks/s]
Processed prompts:   9%|         | 386/4096 [00:20<04:01, 15.35it/s, est. speed input: 19504.91 toks/s, output: 19.05 toks/s]
Processed prompts:  10%|         | 418/4096 [00:22<04:02, 15.18it/s, est. speed input: 19085.03 toks/s, output: 18.64 toks/s]
Processed prompts:  11%|         | 450/4096 [00:25<04:18, 14.09it/s, est. speed input: 18372.50 toks/s, output: 17.94 toks/s]
Processed prompts:  12%|        | 482/4096 [00:27<04:12, 14.30it/s, est. speed input: 18118.50 toks/s, output: 17.69 toks/s]
Processed prompts:  13%|        | 514/4096 [00:29<04:07, 14.44it/s, est. speed input: 17900.58 toks/s, output: 17.48 toks/s]
Processed prompts:  13%|        | 546/4096 [00:31<04:03, 14.56it/s, est. speed input: 17715.86 toks/s, output: 17.30 toks/s]
Processed prompts:  14%|        | 578/4096 [00:33<04:00, 14.62it/s, est. speed input: 17549.33 toks/s, output: 17.14 toks/s]
Processed prompts:  15%|        | 610/4096 [00:35<03:57, 14.68it/s, est. speed input: 17406.87 toks/s, output: 17.00 toks/s]
Processed prompts:  16%|        | 642/4096 [00:38<03:54, 14.73it/s, est. speed input: 17281.91 toks/s, output: 16.88 toks/s]
Processed prompts:  16%|        | 674/4096 [00:40<03:51, 14.76it/s, est. speed input: 17170.00 toks/s, output: 16.77 toks/s]
Processed prompts:  17%|        | 706/4096 [00:42<03:49, 14.78it/s, est. speed input: 17068.53 toks/s, output: 16.67 toks/s]
Processed prompts:  18%|        | 738/4096 [00:44<03:47, 14.79it/s, est. speed input: 16975.84 toks/s, output: 16.58 toks/s]
Processed prompts:  19%|        | 770/4096 [00:46<03:44, 14.79it/s, est. speed input: 16891.26 toks/s, output: 16.50 toks/s]
Processed prompts:  20%|        | 802/4096 [00:48<03:42, 14.80it/s, est. speed input: 16814.75 toks/s, output: 16.42 toks/s]
Processed prompts:  20%|        | 834/4096 [00:50<03:40, 14.80it/s, est. speed input: 16745.66 toks/s, output: 16.35 toks/s]
Processed prompts:  21%|        | 866/4096 [00:53<03:38, 14.81it/s, est. speed input: 16681.56 toks/s, output: 16.29 toks/s]
Processed prompts:  22%|       | 898/4096 [00:55<03:36, 14.80it/s, est. speed input: 16621.32 toks/s, output: 16.23 toks/s]
Processed prompts:  23%|       | 930/4096 [00:57<03:39, 14.44it/s, est. speed input: 16514.59 toks/s, output: 16.13 toks/s]
Processed prompts:  23%|       | 962/4096 [00:59<03:34, 14.64it/s, est. speed input: 16477.66 toks/s, output: 16.09 toks/s]
Processed prompts:  24%|       | 994/4096 [01:01<03:31, 14.69it/s, est. speed input: 16432.13 toks/s, output: 16.05 toks/s]
Processed prompts:  25%|       | 1026/4096 [01:04<03:28, 14.72it/s, est. speed input: 16388.25 toks/s, output: 16.00 toks/s]
Processed prompts:  26%|       | 1058/4096 [01:06<03:26, 14.74it/s, est. speed input: 16347.77 toks/s, output: 15.96 toks/s]
Processed prompts:  27%|       | 1090/4096 [01:08<03:23, 14.76it/s, est. speed input: 16310.95 toks/s, output: 15.93 toks/s]
Processed prompts:  27%|       | 1122/4096 [01:10<03:21, 14.78it/s, est. speed input: 16276.33 toks/s, output: 15.89 toks/s]
Processed prompts:  28%|       | 1154/4096 [01:12<03:17, 14.88it/s, est. speed input: 16252.76 toks/s, output: 15.87 toks/s]
Processed prompts:  29%|       | 1186/4096 [01:14<03:16, 14.84it/s, est. speed input: 16220.04 toks/s, output: 15.84 toks/s]
Processed prompts:  30%|       | 1218/4096 [01:17<03:14, 14.83it/s, est. speed input: 16190.12 toks/s, output: 15.81 toks/s]
Processed prompts:  31%|       | 1250/4096 [01:19<03:10, 14.91it/s, est. speed input: 16170.42 toks/s, output: 15.79 toks/s]
Processed prompts:  31%|      | 1282/4096 [01:21<03:07, 14.97it/s, est. speed input: 16152.29 toks/s, output: 15.77 toks/s]
Processed prompts:  32%|      | 1314/4096 [01:23<03:06, 14.92it/s, est. speed input: 16126.62 toks/s, output: 15.75 toks/s]
Processed prompts:  33%|      | 1346/4096 [01:25<03:04, 14.89it/s, est. speed input: 16102.39 toks/s, output: 15.72 toks/s]
Processed prompts:  34%|      | 1378/4096 [01:27<03:02, 14.86it/s, est. speed input: 16079.23 toks/s, output: 15.70 toks/s]
Processed prompts:  34%|      | 1410/4096 [01:30<03:06, 14.42it/s, est. speed input: 16019.13 toks/s, output: 15.64 toks/s]
Processed prompts:  35%|      | 1442/4096 [01:32<03:02, 14.53it/s, est. speed input: 15999.22 toks/s, output: 15.62 toks/s]
Processed prompts:  36%|      | 1474/4096 [01:34<02:59, 14.61it/s, est. speed input: 15979.97 toks/s, output: 15.61 toks/s]
Processed prompts:  37%|      | 1506/4096 [01:36<02:56, 14.67it/s, est. speed input: 15961.31 toks/s, output: 15.59 toks/s]
Processed prompts:  38%|      | 1538/4096 [01:38<02:53, 14.71it/s, est. speed input: 15944.28 toks/s, output: 15.57 toks/s]
Processed prompts:  38%|      | 1570/4096 [01:40<02:50, 14.83it/s, est. speed input: 15934.49 toks/s, output: 15.56 toks/s]
Processed prompts:  39%|      | 1602/4096 [01:43<02:48, 14.82it/s, est. speed input: 15917.72 toks/s, output: 15.54 toks/s]
Processed prompts:  40%|      | 1634/4096 [01:45<02:45, 14.90it/s, est. speed input: 15908.44 toks/s, output: 15.54 toks/s]
Processed prompts:  41%|      | 1666/4096 [01:47<02:43, 14.88it/s, est. speed input: 15893.89 toks/s, output: 15.52 toks/s]
Processed prompts:  41%|     | 1698/4096 [01:49<02:41, 14.84it/s, est. speed input: 15878.44 toks/s, output: 15.51 toks/s]
Processed prompts:  42%|     | 1730/4096 [01:51<02:39, 14.83it/s, est. speed input: 15864.40 toks/s, output: 15.49 toks/s]
Processed prompts:  43%|     | 1762/4096 [01:53<02:37, 14.83it/s, est. speed input: 15851.27 toks/s, output: 15.48 toks/s]
Processed prompts:  44%|     | 1794/4096 [01:55<02:35, 14.81it/s, est. speed input: 15837.58 toks/s, output: 15.47 toks/s]
Processed prompts:  45%|     | 1826/4096 [01:58<02:33, 14.81it/s, est. speed input: 15825.50 toks/s, output: 15.45 toks/s]
Processed prompts:  45%|     | 1858/4096 [02:00<02:30, 14.90it/s, est. speed input: 15819.11 toks/s, output: 15.45 toks/s]
Processed prompts:  46%|     | 1890/4096 [02:02<02:28, 14.87it/s, est. speed input: 15807.58 toks/s, output: 15.44 toks/s]
Processed prompts:  47%|     | 1922/4096 [02:04<02:29, 14.51it/s, est. speed input: 15775.14 toks/s, output: 15.41 toks/s]
Processed prompts:  48%|     | 1954/4096 [02:06<02:25, 14.68it/s, est. speed input: 15769.85 toks/s, output: 15.40 toks/s]
Processed prompts:  48%|     | 1986/4096 [02:08<02:22, 14.81it/s, est. speed input: 15765.02 toks/s, output: 15.40 toks/s]
Processed prompts:  49%|     | 2018/4096 [02:11<02:20, 14.81it/s, est. speed input: 15755.19 toks/s, output: 15.39 toks/s]
Processed prompts:  50%|     | 2050/4096 [02:13<02:18, 14.82it/s, est. speed input: 15745.93 toks/s, output: 15.38 toks/s]
Processed prompts:  51%|     | 2082/4096 [02:15<02:16, 14.81it/s, est. speed input: 15736.21 toks/s, output: 15.37 toks/s]
Processed prompts:  52%|    | 2114/4096 [02:17<02:13, 14.81it/s, est. speed input: 15727.51 toks/s, output: 15.36 toks/s]
Processed prompts:  52%|    | 2146/4096 [02:19<02:11, 14.81it/s, est. speed input: 15718.67 toks/s, output: 15.35 toks/s]
Processed prompts:  53%|    | 2178/4096 [02:21<02:09, 14.80it/s, est. speed input: 15709.65 toks/s, output: 15.34 toks/s]
Processed prompts:  54%|    | 2210/4096 [02:24<02:05, 15.00it/s, est. speed input: 15712.09 toks/s, output: 15.34 toks/s]
Processed prompts:  55%|    | 2242/4096 [02:26<02:04, 14.94it/s, est. speed input: 15703.75 toks/s, output: 15.34 toks/s]
Processed prompts:  56%|    | 2274/4096 [02:28<02:01, 14.99it/s, est. speed input: 15700.37 toks/s, output: 15.33 toks/s]
Processed prompts:  56%|    | 2306/4096 [02:30<01:59, 14.93it/s, est. speed input: 15692.70 toks/s, output: 15.32 toks/s]
Processed prompts:  57%|    | 2338/4096 [02:32<01:57, 14.98it/s, est. speed input: 15689.46 toks/s, output: 15.32 toks/s]
Processed prompts:  58%|    | 2370/4096 [02:34<01:53, 15.15it/s, est. speed input: 15692.70 toks/s, output: 15.32 toks/s]
Processed prompts:  59%|    | 2402/4096 [02:36<01:54, 14.82it/s, est. speed input: 15674.37 toks/s, output: 15.31 toks/s]
Processed prompts:  59%|    | 2434/4096 [02:39<01:52, 14.80it/s, est. speed input: 15666.99 toks/s, output: 15.30 toks/s]
Processed prompts:  60%|    | 2466/4096 [02:41<01:50, 14.80it/s, est. speed input: 15660.07 toks/s, output: 15.29 toks/s]
Processed prompts:  61%|    | 2498/4096 [02:43<01:47, 14.90it/s, est. speed input: 15657.84 toks/s, output: 15.29 toks/s]
Processed prompts:  62%|   | 2530/4096 [02:45<01:45, 14.87it/s, est. speed input: 15651.15 toks/s, output: 15.28 toks/s]
Processed prompts:  63%|   | 2562/4096 [02:47<01:42, 14.93it/s, est. speed input: 15648.56 toks/s, output: 15.28 toks/s]
Processed prompts:  63%|   | 2594/4096 [02:49<01:40, 14.89it/s, est. speed input: 15642.20 toks/s, output: 15.28 toks/s]
Processed prompts:  64%|   | 2626/4096 [02:51<01:38, 14.86it/s, est. speed input: 15635.91 toks/s, output: 15.27 toks/s]
Processed prompts:  65%|   | 2658/4096 [02:54<01:36, 14.84it/s, est. speed input: 15629.91 toks/s, output: 15.26 toks/s]
Processed prompts:  66%|   | 2690/4096 [02:56<01:34, 14.92it/s, est. speed input: 15627.88 toks/s, output: 15.26 toks/s]
Processed prompts:  66%|   | 2722/4096 [02:58<01:32, 14.88it/s, est. speed input: 15622.19 toks/s, output: 15.26 toks/s]
Processed prompts:  67%|   | 2754/4096 [03:00<01:30, 14.85it/s, est. speed input: 15616.32 toks/s, output: 15.25 toks/s]
Processed prompts:  68%|   | 2786/4096 [03:02<01:28, 14.83it/s, est. speed input: 15610.66 toks/s, output: 15.24 toks/s]
Processed prompts:  69%|   | 2818/4096 [03:04<01:26, 14.82it/s, est. speed input: 15605.29 toks/s, output: 15.24 toks/s]
Processed prompts:  70%|   | 2850/4096 [03:07<01:23, 14.90it/s, est. speed input: 15603.64 toks/s, output: 15.24 toks/s]
Processed prompts:  70%|   | 2882/4096 [03:09<01:23, 14.55it/s, est. speed input: 15585.44 toks/s, output: 15.22 toks/s]
Processed prompts:  71%|   | 2914/4096 [03:11<01:20, 14.62it/s, est. speed input: 15580.34 toks/s, output: 15.22 toks/s]
Processed prompts:  72%|  | 2946/4096 [03:13<01:18, 14.67it/s, est. speed input: 15575.71 toks/s, output: 15.21 toks/s]
Processed prompts:  73%|  | 2978/4096 [03:15<01:16, 14.70it/s, est. speed input: 15570.68 toks/s, output: 15.21 toks/s]
Processed prompts:  73%|  | 3010/4096 [03:18<01:13, 14.73it/s, est. speed input: 15566.09 toks/s, output: 15.20 toks/s]
Processed prompts:  74%|  | 3042/4096 [03:20<01:11, 14.76it/s, est. speed input: 15561.87 toks/s, output: 15.20 toks/s]
Processed prompts:  75%|  | 3074/4096 [03:22<01:09, 14.77it/s, est. speed input: 15557.50 toks/s, output: 15.19 toks/s]
Processed prompts:  76%|  | 3106/4096 [03:24<01:05, 15.00it/s, est. speed input: 15561.37 toks/s, output: 15.20 toks/s]
Processed prompts:  77%|  | 3138/4096 [03:26<01:03, 15.04it/s, est. speed input: 15560.58 toks/s, output: 15.20 toks/s]
Processed prompts:  77%|  | 3170/4096 [03:28<01:01, 14.96it/s, est. speed input: 15556.14 toks/s, output: 15.19 toks/s]
Processed prompts:  78%|  | 3202/4096 [03:30<00:59, 14.91it/s, est. speed input: 15552.07 toks/s, output: 15.19 toks/s]
Processed prompts:  79%|  | 3234/4096 [03:32<00:57, 14.96it/s, est. speed input: 15550.94 toks/s, output: 15.19 toks/s]
Processed prompts:  80%|  | 3266/4096 [03:35<00:55, 14.91it/s, est. speed input: 15546.91 toks/s, output: 15.18 toks/s]
Processed prompts:  81%|  | 3298/4096 [03:37<00:53, 14.88it/s, est. speed input: 15542.96 toks/s, output: 15.18 toks/s]
Processed prompts:  81%| | 3330/4096 [03:39<00:51, 14.85it/s, est. speed input: 15539.07 toks/s, output: 15.17 toks/s]
Processed prompts:  82%| | 3362/4096 [03:41<00:50, 14.48it/s, est. speed input: 15522.97 toks/s, output: 15.16 toks/s]
Processed prompts:  83%| | 3394/4096 [03:43<00:48, 14.58it/s, est. speed input: 15519.50 toks/s, output: 15.16 toks/s]
Processed prompts:  84%| | 3426/4096 [03:46<00:45, 14.73it/s, est. speed input: 15519.04 toks/s, output: 15.16 toks/s]
Processed prompts:  84%| | 3458/4096 [03:48<00:43, 14.75it/s, est. speed input: 15515.49 toks/s, output: 15.15 toks/s]
Processed prompts:  85%| | 3490/4096 [03:50<00:40, 14.99it/s, est. speed input: 15519.53 toks/s, output: 15.16 toks/s]
Processed prompts:  86%| | 3522/4096 [03:52<00:38, 14.93it/s, est. speed input: 15516.09 toks/s, output: 15.15 toks/s]
Processed prompts:  87%| | 3554/4096 [03:54<00:36, 14.90it/s, est. speed input: 15512.96 toks/s, output: 15.15 toks/s]
Processed prompts:  88%| | 3586/4096 [03:56<00:34, 14.87it/s, est. speed input: 15509.77 toks/s, output: 15.15 toks/s]
Processed prompts:  88%| | 3618/4096 [03:58<00:32, 14.84it/s, est. speed input: 15506.28 toks/s, output: 15.14 toks/s]
Processed prompts:  89%| | 3650/4096 [04:01<00:30, 14.83it/s, est. speed input: 15503.18 toks/s, output: 15.14 toks/s]
Processed prompts:  90%| | 3682/4096 [04:03<00:27, 14.83it/s, est. speed input: 15500.32 toks/s, output: 15.14 toks/s]
Processed prompts:  91%| | 3714/4096 [04:05<00:25, 14.90it/s, est. speed input: 15499.79 toks/s, output: 15.14 toks/s]
Processed prompts:  91%|| 3746/4096 [04:07<00:23, 14.87it/s, est. speed input: 15496.61 toks/s, output: 15.13 toks/s]
Processed prompts:  92%|| 3778/4096 [04:09<00:21, 14.84it/s, est. speed input: 15493.41 toks/s, output: 15.13 toks/s]
Processed prompts:  93%|| 3810/4096 [04:11<00:19, 14.83it/s, est. speed input: 15490.67 toks/s, output: 15.13 toks/s]
Processed prompts:  94%|| 3842/4096 [04:14<00:17, 14.51it/s, est. speed input: 15478.41 toks/s, output: 15.12 toks/s]
Processed prompts:  95%|| 3874/4096 [04:16<00:15, 14.60it/s, est. speed input: 15475.68 toks/s, output: 15.11 toks/s]
Processed prompts:  95%|| 3906/4096 [04:18<00:12, 14.66it/s, est. speed input: 15473.14 toks/s, output: 15.11 toks/s]
Processed prompts:  96%|| 3938/4096 [04:20<00:10, 14.70it/s, est. speed input: 15470.43 toks/s, output: 15.11 toks/s]
Processed prompts:  97%|| 3970/4096 [04:22<00:08, 14.73it/s, est. speed input: 15467.85 toks/s, output: 15.11 toks/s]
Processed prompts:  98%|| 4002/4096 [04:24<00:06, 14.75it/s, est. speed input: 15465.15 toks/s, output: 15.10 toks/s]
Processed prompts:  98%|| 4034/4096 [04:26<00:04, 15.09it/s, est. speed input: 15471.65 toks/s, output: 15.11 toks/s]
Processed prompts:  99%|| 4066/4096 [04:29<00:01, 15.09it/s, est. speed input: 15471.65 toks/s, output: 15.11 toks/s]
Processed prompts: 100%|| 4096/4096 [04:29<00:00, 15.09it/s, est. speed input: 15585.79 toks/s, output: 15.22 toks/s]
Processed prompts: 100%|| 4096/4096 [04:29<00:00, 15.22it/s, est. speed input: 15585.79 toks/s, output: 15.22 toks/s]
[rank0]:[W128 09:16:50.288392234 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

